Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.53473
Policy Entropy: 2.21581
Value Function Loss: 0.01876

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.20582
Value Function Update Magnitude: 0.18984

Collected Steps per Second: 6,908.59434
Overall Steps per Second: 3,737.59861

Timestep Collection Time: 7.24113
Timestep Consumption Time: 6.14340
PPO Batch Consumption Time: 2.46919
Total Iteration Time: 13.38453

Cumulative Model Updates: 227,882
Cumulative Timesteps: 1,900,596,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.66451
Policy Entropy: 2.23951
Value Function Loss: 0.01788

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.45056
Value Function Update Magnitude: 0.39177

Collected Steps per Second: 18,900.15983
Overall Steps per Second: 10,696.45363

Timestep Collection Time: 2.64728
Timestep Consumption Time: 2.03035
PPO Batch Consumption Time: 0.31113
Total Iteration Time: 4.67763

Cumulative Model Updates: 227,886
Cumulative Timesteps: 1,900,646,942

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1900646942...
Checkpoint 1900646942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.69474
Policy Entropy: 2.22623
Value Function Loss: 0.01513

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.14183
Policy Update Magnitude: 0.62265
Value Function Update Magnitude: 0.60991

Collected Steps per Second: 19,886.30898
Overall Steps per Second: 10,144.84643

Timestep Collection Time: 2.51580
Timestep Consumption Time: 2.41577
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.93157

Cumulative Model Updates: 227,892
Cumulative Timesteps: 1,900,696,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.51461
Policy Entropy: 2.25500
Value Function Loss: 0.01385

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.55091
Value Function Update Magnitude: 0.58016

Collected Steps per Second: 21,184.27401
Overall Steps per Second: 10,259.57466

Timestep Collection Time: 2.36147
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.30170
Total Iteration Time: 4.87603

Cumulative Model Updates: 227,898
Cumulative Timesteps: 1,900,746,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1900746998...
Checkpoint 1900746998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.00752
Policy Entropy: 2.25178
Value Function Loss: 0.01508

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.53415
Value Function Update Magnitude: 0.59409

Collected Steps per Second: 21,362.54769
Overall Steps per Second: 10,324.10013

Timestep Collection Time: 2.34139
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.84478

Cumulative Model Updates: 227,904
Cumulative Timesteps: 1,900,797,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.49883
Policy Entropy: 2.28035
Value Function Loss: 0.01568

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.54325
Value Function Update Magnitude: 0.60025

Collected Steps per Second: 21,297.71150
Overall Steps per Second: 10,213.21776

Timestep Collection Time: 2.34936
Timestep Consumption Time: 2.54978
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.89914

Cumulative Model Updates: 227,910
Cumulative Timesteps: 1,900,847,052

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1900847052...
Checkpoint 1900847052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.00408
Policy Entropy: 2.24741
Value Function Loss: 0.01605

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.59215

Collected Steps per Second: 21,244.81556
Overall Steps per Second: 10,190.41009

Timestep Collection Time: 2.35474
Timestep Consumption Time: 2.55439
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.90913

Cumulative Model Updates: 227,916
Cumulative Timesteps: 1,900,897,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.88234
Policy Entropy: 2.24358
Value Function Loss: 0.01418

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.53076
Value Function Update Magnitude: 0.57754

Collected Steps per Second: 21,474.68275
Overall Steps per Second: 10,474.14291

Timestep Collection Time: 2.32916
Timestep Consumption Time: 2.44622
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.77538

Cumulative Model Updates: 227,922
Cumulative Timesteps: 1,900,947,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1900947096...
Checkpoint 1900947096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.09830
Policy Entropy: 2.20734
Value Function Loss: 0.01498

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.53755
Value Function Update Magnitude: 0.56666

Collected Steps per Second: 19,331.51523
Overall Steps per Second: 9,619.71833

Timestep Collection Time: 2.58676
Timestep Consumption Time: 2.61152
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 5.19828

Cumulative Model Updates: 227,928
Cumulative Timesteps: 1,900,997,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.75177
Policy Entropy: 2.23589
Value Function Loss: 0.01698

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.60354

Collected Steps per Second: 20,376.96987
Overall Steps per Second: 9,974.78655

Timestep Collection Time: 2.45395
Timestep Consumption Time: 2.55909
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 5.01304

Cumulative Model Updates: 227,934
Cumulative Timesteps: 1,901,047,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1901047106...
Checkpoint 1901047106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.23783
Policy Entropy: 2.23515
Value Function Loss: 0.01743

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.55528
Value Function Update Magnitude: 0.63476

Collected Steps per Second: 19,730.03324
Overall Steps per Second: 9,775.20240

Timestep Collection Time: 2.53482
Timestep Consumption Time: 2.58140
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 5.11621

Cumulative Model Updates: 227,940
Cumulative Timesteps: 1,901,097,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.03877
Policy Entropy: 2.26763
Value Function Loss: 0.01588

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.53601
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 20,357.33210
Overall Steps per Second: 10,076.52000

Timestep Collection Time: 2.45739
Timestep Consumption Time: 2.50722
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.96461

Cumulative Model Updates: 227,946
Cumulative Timesteps: 1,901,147,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1901147144...
Checkpoint 1901147144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.46160
Policy Entropy: 2.26368
Value Function Loss: 0.01483

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.52986
Value Function Update Magnitude: 0.58623

Collected Steps per Second: 18,673.60997
Overall Steps per Second: 9,375.01839

Timestep Collection Time: 2.67865
Timestep Consumption Time: 2.65681
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 5.33546

Cumulative Model Updates: 227,952
Cumulative Timesteps: 1,901,197,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.81312
Policy Entropy: 2.25972
Value Function Loss: 0.01477

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.52812
Value Function Update Magnitude: 0.58281

Collected Steps per Second: 14,123.79050
Overall Steps per Second: 6,881.95502

Timestep Collection Time: 3.54168
Timestep Consumption Time: 3.72689
PPO Batch Consumption Time: 0.48486
Total Iteration Time: 7.26857

Cumulative Model Updates: 227,958
Cumulative Timesteps: 1,901,247,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1901247186...
Checkpoint 1901247186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.94661
Policy Entropy: 2.25555
Value Function Loss: 0.01481

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.52326
Value Function Update Magnitude: 0.57413

Collected Steps per Second: 16,045.35096
Overall Steps per Second: 7,638.34624

Timestep Collection Time: 3.11903
Timestep Consumption Time: 3.43291
PPO Batch Consumption Time: 0.44310
Total Iteration Time: 6.55194

Cumulative Model Updates: 227,964
Cumulative Timesteps: 1,901,297,232

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.77163
Policy Entropy: 2.26174
Value Function Loss: 0.01447

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.58324

Collected Steps per Second: 14,715.55913
Overall Steps per Second: 7,125.85333

Timestep Collection Time: 3.39776
Timestep Consumption Time: 3.61894
PPO Batch Consumption Time: 0.47400
Total Iteration Time: 7.01670

Cumulative Model Updates: 227,970
Cumulative Timesteps: 1,901,347,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1901347232...
Checkpoint 1901347232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.22089
Policy Entropy: 2.22120
Value Function Loss: 0.01477

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.59686

Collected Steps per Second: 15,683.83791
Overall Steps per Second: 7,629.97214

Timestep Collection Time: 3.18863
Timestep Consumption Time: 3.36578
PPO Batch Consumption Time: 0.43064
Total Iteration Time: 6.55441

Cumulative Model Updates: 227,976
Cumulative Timesteps: 1,901,397,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.51968
Policy Entropy: 2.19425
Value Function Loss: 0.01518

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.60267

Collected Steps per Second: 16,620.45112
Overall Steps per Second: 7,859.89338

Timestep Collection Time: 3.00930
Timestep Consumption Time: 3.35414
PPO Batch Consumption Time: 0.42627
Total Iteration Time: 6.36345

Cumulative Model Updates: 227,982
Cumulative Timesteps: 1,901,447,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1901447258...
Checkpoint 1901447258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.88284
Policy Entropy: 2.21769
Value Function Loss: 0.01497

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.53204
Value Function Update Magnitude: 0.59963

Collected Steps per Second: 16,263.83949
Overall Steps per Second: 7,840.76868

Timestep Collection Time: 3.07480
Timestep Consumption Time: 3.30315
PPO Batch Consumption Time: 0.41853
Total Iteration Time: 6.37795

Cumulative Model Updates: 227,988
Cumulative Timesteps: 1,901,497,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.60942
Policy Entropy: 2.25447
Value Function Loss: 0.01483

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.52758
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 15,928.94990
Overall Steps per Second: 7,437.92479

Timestep Collection Time: 3.13944
Timestep Consumption Time: 3.58394
PPO Batch Consumption Time: 0.46811
Total Iteration Time: 6.72338

Cumulative Model Updates: 227,994
Cumulative Timesteps: 1,901,547,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1901547274...
Checkpoint 1901547274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.11214
Policy Entropy: 2.30650
Value Function Loss: 0.01451

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.52599
Value Function Update Magnitude: 0.56120

Collected Steps per Second: 15,510.38905
Overall Steps per Second: 7,364.22743

Timestep Collection Time: 3.22571
Timestep Consumption Time: 3.56821
PPO Batch Consumption Time: 0.47809
Total Iteration Time: 6.79392

Cumulative Model Updates: 228,000
Cumulative Timesteps: 1,901,597,306

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.47262
Policy Entropy: 2.28797
Value Function Loss: 0.01521

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.52723
Value Function Update Magnitude: 0.55447

Collected Steps per Second: 16,013.81831
Overall Steps per Second: 7,808.35581

Timestep Collection Time: 3.12293
Timestep Consumption Time: 3.28175
PPO Batch Consumption Time: 0.41721
Total Iteration Time: 6.40468

Cumulative Model Updates: 228,006
Cumulative Timesteps: 1,901,647,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1901647316...
Checkpoint 1901647316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.85758
Policy Entropy: 2.28733
Value Function Loss: 0.01550

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.53142
Value Function Update Magnitude: 0.56244

Collected Steps per Second: 16,221.01899
Overall Steps per Second: 7,475.62398

Timestep Collection Time: 3.08279
Timestep Consumption Time: 3.60642
PPO Batch Consumption Time: 0.46905
Total Iteration Time: 6.68921

Cumulative Model Updates: 228,012
Cumulative Timesteps: 1,901,697,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.32587
Policy Entropy: 2.26480
Value Function Loss: 0.01655

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.58376

Collected Steps per Second: 15,433.25002
Overall Steps per Second: 7,199.31738

Timestep Collection Time: 3.23989
Timestep Consumption Time: 3.70549
PPO Batch Consumption Time: 0.48704
Total Iteration Time: 6.94538

Cumulative Model Updates: 228,018
Cumulative Timesteps: 1,901,747,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1901747324...
Checkpoint 1901747324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.66193
Policy Entropy: 2.27464
Value Function Loss: 0.01612

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.54394
Value Function Update Magnitude: 0.58865

Collected Steps per Second: 15,061.68372
Overall Steps per Second: 7,621.35532

Timestep Collection Time: 3.32154
Timestep Consumption Time: 3.24265
PPO Batch Consumption Time: 0.42404
Total Iteration Time: 6.56419

Cumulative Model Updates: 228,024
Cumulative Timesteps: 1,901,797,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.47494
Policy Entropy: 2.27910
Value Function Loss: 0.01612

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.52900
Value Function Update Magnitude: 0.58696

Collected Steps per Second: 15,897.02608
Overall Steps per Second: 7,693.53875

Timestep Collection Time: 3.14562
Timestep Consumption Time: 3.35412
PPO Batch Consumption Time: 0.42200
Total Iteration Time: 6.49974

Cumulative Model Updates: 228,030
Cumulative Timesteps: 1,901,847,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1901847358...
Checkpoint 1901847358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.54784
Policy Entropy: 2.26134
Value Function Loss: 0.01486

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.52801
Value Function Update Magnitude: 0.59318

Collected Steps per Second: 16,366.25532
Overall Steps per Second: 7,796.00597

Timestep Collection Time: 3.05507
Timestep Consumption Time: 3.35847
PPO Batch Consumption Time: 0.42717
Total Iteration Time: 6.41354

Cumulative Model Updates: 228,036
Cumulative Timesteps: 1,901,897,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.61928
Policy Entropy: 2.23542
Value Function Loss: 0.01507

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 15,498.95602
Overall Steps per Second: 7,456.25407

Timestep Collection Time: 3.22654
Timestep Consumption Time: 3.48031
PPO Batch Consumption Time: 0.46375
Total Iteration Time: 6.70685

Cumulative Model Updates: 228,042
Cumulative Timesteps: 1,901,947,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1901947366...
Checkpoint 1901947366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.09001
Policy Entropy: 2.28226
Value Function Loss: 0.01439

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.60766

Collected Steps per Second: 15,872.55718
Overall Steps per Second: 7,345.94721

Timestep Collection Time: 3.15249
Timestep Consumption Time: 3.65916
PPO Batch Consumption Time: 0.48050
Total Iteration Time: 6.81165

Cumulative Model Updates: 228,048
Cumulative Timesteps: 1,901,997,404

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.90722
Policy Entropy: 2.26705
Value Function Loss: 0.01565

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.60009

Collected Steps per Second: 16,053.80146
Overall Steps per Second: 7,615.43993

Timestep Collection Time: 3.11465
Timestep Consumption Time: 3.45122
PPO Batch Consumption Time: 0.44348
Total Iteration Time: 6.56587

Cumulative Model Updates: 228,054
Cumulative Timesteps: 1,902,047,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1902047406...
Checkpoint 1902047406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.10082
Policy Entropy: 2.27967
Value Function Loss: 0.01459

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.52913
Value Function Update Magnitude: 0.59655

Collected Steps per Second: 15,377.32028
Overall Steps per Second: 7,179.57209

Timestep Collection Time: 3.25297
Timestep Consumption Time: 3.71430
PPO Batch Consumption Time: 0.49365
Total Iteration Time: 6.96727

Cumulative Model Updates: 228,060
Cumulative Timesteps: 1,902,097,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.46385
Policy Entropy: 2.23480
Value Function Loss: 0.01501

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.59560

Collected Steps per Second: 15,343.50420
Overall Steps per Second: 7,227.52667

Timestep Collection Time: 3.25923
Timestep Consumption Time: 3.65987
PPO Batch Consumption Time: 0.49333
Total Iteration Time: 6.91910

Cumulative Model Updates: 228,066
Cumulative Timesteps: 1,902,147,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1902147436...
Checkpoint 1902147436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.53066
Policy Entropy: 2.23962
Value Function Loss: 0.01436

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.54299
Value Function Update Magnitude: 0.60615

Collected Steps per Second: 15,263.89247
Overall Steps per Second: 7,350.23240

Timestep Collection Time: 3.27701
Timestep Consumption Time: 3.52821
PPO Batch Consumption Time: 0.45549
Total Iteration Time: 6.80523

Cumulative Model Updates: 228,072
Cumulative Timesteps: 1,902,197,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.13074
Policy Entropy: 2.25115
Value Function Loss: 0.01492

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.61657

Collected Steps per Second: 16,141.25079
Overall Steps per Second: 7,643.70620

Timestep Collection Time: 3.09815
Timestep Consumption Time: 3.44423
PPO Batch Consumption Time: 0.43548
Total Iteration Time: 6.54238

Cumulative Model Updates: 228,078
Cumulative Timesteps: 1,902,247,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1902247464...
Checkpoint 1902247464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.91989
Policy Entropy: 2.24774
Value Function Loss: 0.01466

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.62617

Collected Steps per Second: 15,897.30702
Overall Steps per Second: 7,743.06843

Timestep Collection Time: 3.14707
Timestep Consumption Time: 3.31419
PPO Batch Consumption Time: 0.42066
Total Iteration Time: 6.46126

Cumulative Model Updates: 228,084
Cumulative Timesteps: 1,902,297,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.55517
Policy Entropy: 2.25250
Value Function Loss: 0.01468

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.53628
Value Function Update Magnitude: 0.62807

Collected Steps per Second: 15,972.79329
Overall Steps per Second: 7,262.27012

Timestep Collection Time: 3.13070
Timestep Consumption Time: 3.75503
PPO Batch Consumption Time: 0.50307
Total Iteration Time: 6.88573

Cumulative Model Updates: 228,090
Cumulative Timesteps: 1,902,347,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1902347500...
Checkpoint 1902347500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.93831
Policy Entropy: 2.24806
Value Function Loss: 0.01355

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.52265
Value Function Update Magnitude: 0.62988

Collected Steps per Second: 15,940.01114
Overall Steps per Second: 7,503.78056

Timestep Collection Time: 3.14002
Timestep Consumption Time: 3.53021
PPO Batch Consumption Time: 0.45604
Total Iteration Time: 6.67024

Cumulative Model Updates: 228,096
Cumulative Timesteps: 1,902,397,552

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.09239
Policy Entropy: 2.26953
Value Function Loss: 0.01426

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.52438
Value Function Update Magnitude: 0.61721

Collected Steps per Second: 15,479.42474
Overall Steps per Second: 7,162.35475

Timestep Collection Time: 3.23022
Timestep Consumption Time: 3.75100
PPO Batch Consumption Time: 0.48890
Total Iteration Time: 6.98122

Cumulative Model Updates: 228,102
Cumulative Timesteps: 1,902,447,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1902447554...
Checkpoint 1902447554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.17107
Policy Entropy: 2.27075
Value Function Loss: 0.01532

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.59691

Collected Steps per Second: 15,913.01057
Overall Steps per Second: 7,508.83632

Timestep Collection Time: 3.14208
Timestep Consumption Time: 3.51674
PPO Batch Consumption Time: 0.45797
Total Iteration Time: 6.65882

Cumulative Model Updates: 228,108
Cumulative Timesteps: 1,902,497,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.89059
Policy Entropy: 2.25438
Value Function Loss: 0.01693

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 15,876.34481
Overall Steps per Second: 7,589.58713

Timestep Collection Time: 3.15035
Timestep Consumption Time: 3.43973
PPO Batch Consumption Time: 0.45554
Total Iteration Time: 6.59008

Cumulative Model Updates: 228,114
Cumulative Timesteps: 1,902,547,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1902547570...
Checkpoint 1902547570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.46479
Policy Entropy: 2.24356
Value Function Loss: 0.01726

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.60328

Collected Steps per Second: 15,489.99048
Overall Steps per Second: 7,515.69984

Timestep Collection Time: 3.22918
Timestep Consumption Time: 3.42622
PPO Batch Consumption Time: 0.44073
Total Iteration Time: 6.65540

Cumulative Model Updates: 228,120
Cumulative Timesteps: 1,902,597,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.81026
Policy Entropy: 2.23609
Value Function Loss: 0.01670

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.55178
Value Function Update Magnitude: 0.60648

Collected Steps per Second: 19,932.93900
Overall Steps per Second: 9,872.64084

Timestep Collection Time: 2.50972
Timestep Consumption Time: 2.55742
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 5.06713

Cumulative Model Updates: 228,126
Cumulative Timesteps: 1,902,647,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1902647616...
Checkpoint 1902647616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.24671
Policy Entropy: 2.26693
Value Function Loss: 0.01645

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.54805
Value Function Update Magnitude: 0.61390

Collected Steps per Second: 19,634.19303
Overall Steps per Second: 9,785.33251

Timestep Collection Time: 2.54739
Timestep Consumption Time: 2.56393
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 5.11132

Cumulative Model Updates: 228,132
Cumulative Timesteps: 1,902,697,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.90114
Policy Entropy: 2.28716
Value Function Loss: 0.01537

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.60994

Collected Steps per Second: 21,857.54705
Overall Steps per Second: 10,449.43129

Timestep Collection Time: 2.28772
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.78533

Cumulative Model Updates: 228,138
Cumulative Timesteps: 1,902,747,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1902747636...
Checkpoint 1902747636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.35101
Policy Entropy: 2.31176
Value Function Loss: 0.01532

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.58575

Collected Steps per Second: 22,190.09049
Overall Steps per Second: 10,354.84636

Timestep Collection Time: 2.25371
Timestep Consumption Time: 2.57591
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.82962

Cumulative Model Updates: 228,144
Cumulative Timesteps: 1,902,797,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.63015
Policy Entropy: 2.28784
Value Function Loss: 0.01502

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.53160
Value Function Update Magnitude: 0.56520

Collected Steps per Second: 21,861.90674
Overall Steps per Second: 10,449.91879

Timestep Collection Time: 2.28772
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.78607

Cumulative Model Updates: 228,150
Cumulative Timesteps: 1,902,847,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1902847660...
Checkpoint 1902847660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.91682
Policy Entropy: 2.26548
Value Function Loss: 0.01501

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.52337
Value Function Update Magnitude: 0.56790

Collected Steps per Second: 21,070.76293
Overall Steps per Second: 10,214.69608

Timestep Collection Time: 2.37391
Timestep Consumption Time: 2.52296
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.89687

Cumulative Model Updates: 228,156
Cumulative Timesteps: 1,902,897,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.24107
Policy Entropy: 2.25339
Value Function Loss: 0.01552

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.52706
Value Function Update Magnitude: 0.57239

Collected Steps per Second: 21,678.94580
Overall Steps per Second: 10,366.32268

Timestep Collection Time: 2.30703
Timestep Consumption Time: 2.51763
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.82466

Cumulative Model Updates: 228,162
Cumulative Timesteps: 1,902,947,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1902947694...
Checkpoint 1902947694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.50990
Policy Entropy: 2.27151
Value Function Loss: 0.01536

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.52649
Value Function Update Magnitude: 0.57581

Collected Steps per Second: 21,038.44128
Overall Steps per Second: 10,210.08842

Timestep Collection Time: 2.37746
Timestep Consumption Time: 2.52142
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.89888

Cumulative Model Updates: 228,168
Cumulative Timesteps: 1,902,997,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.31979
Policy Entropy: 2.27477
Value Function Loss: 0.01598

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.15418
Policy Update Magnitude: 0.52933
Value Function Update Magnitude: 0.59892

Collected Steps per Second: 21,658.34174
Overall Steps per Second: 10,331.23436

Timestep Collection Time: 2.30895
Timestep Consumption Time: 2.53152
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.84047

Cumulative Model Updates: 228,174
Cumulative Timesteps: 1,903,047,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1903047720...
Checkpoint 1903047720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.03687
Policy Entropy: 2.28469
Value Function Loss: 0.01606

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.14984
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.61409

Collected Steps per Second: 21,306.15813
Overall Steps per Second: 10,224.13510

Timestep Collection Time: 2.34787
Timestep Consumption Time: 2.54487
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.89274

Cumulative Model Updates: 228,180
Cumulative Timesteps: 1,903,097,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.01732
Policy Entropy: 2.27055
Value Function Loss: 0.01622

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.60440

Collected Steps per Second: 21,829.21738
Overall Steps per Second: 10,426.88861

Timestep Collection Time: 2.29170
Timestep Consumption Time: 2.50609
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.79779

Cumulative Model Updates: 228,186
Cumulative Timesteps: 1,903,147,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1903147770...
Checkpoint 1903147770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.04068
Policy Entropy: 2.24798
Value Function Loss: 0.01560

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.59599

Collected Steps per Second: 21,279.04713
Overall Steps per Second: 10,570.04327

Timestep Collection Time: 2.35039
Timestep Consumption Time: 2.38129
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.73167

Cumulative Model Updates: 228,192
Cumulative Timesteps: 1,903,197,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.18797
Policy Entropy: 2.23549
Value Function Loss: 0.01531

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.57988

Collected Steps per Second: 21,909.85837
Overall Steps per Second: 10,408.41070

Timestep Collection Time: 2.28336
Timestep Consumption Time: 2.52314
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.80650

Cumulative Model Updates: 228,198
Cumulative Timesteps: 1,903,247,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1903247812...
Checkpoint 1903247812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.22987
Policy Entropy: 2.21664
Value Function Loss: 0.01618

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.54887
Value Function Update Magnitude: 0.56901

Collected Steps per Second: 20,869.33386
Overall Steps per Second: 10,208.54815

Timestep Collection Time: 2.39643
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.89903

Cumulative Model Updates: 228,204
Cumulative Timesteps: 1,903,297,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.52469
Policy Entropy: 2.22714
Value Function Loss: 0.01751

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.55975
Value Function Update Magnitude: 0.58499

Collected Steps per Second: 21,934.92513
Overall Steps per Second: 10,522.20514

Timestep Collection Time: 2.28002
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.75300

Cumulative Model Updates: 228,210
Cumulative Timesteps: 1,903,347,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1903347836...
Checkpoint 1903347836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.74636
Policy Entropy: 2.25710
Value Function Loss: 0.01686

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.59940

Collected Steps per Second: 21,972.43277
Overall Steps per Second: 10,542.56710

Timestep Collection Time: 2.27558
Timestep Consumption Time: 2.46710
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.74268

Cumulative Model Updates: 228,216
Cumulative Timesteps: 1,903,397,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.47245
Policy Entropy: 2.29420
Value Function Loss: 0.01679

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.61881

Collected Steps per Second: 21,815.94274
Overall Steps per Second: 10,405.50398

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.51355
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.80573

Cumulative Model Updates: 228,222
Cumulative Timesteps: 1,903,447,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1903447842...
Checkpoint 1903447842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.56908
Policy Entropy: 2.29267
Value Function Loss: 0.01556

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.54700
Value Function Update Magnitude: 0.60295

Collected Steps per Second: 21,126.71236
Overall Steps per Second: 10,245.04557

Timestep Collection Time: 2.36686
Timestep Consumption Time: 2.51394
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.88080

Cumulative Model Updates: 228,228
Cumulative Timesteps: 1,903,497,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.23811
Policy Entropy: 2.25525
Value Function Loss: 0.01635

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 20,201.41217
Overall Steps per Second: 10,131.47660

Timestep Collection Time: 2.47527
Timestep Consumption Time: 2.46024
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.93551

Cumulative Model Updates: 228,234
Cumulative Timesteps: 1,903,547,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1903547850...
Checkpoint 1903547850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.21520
Policy Entropy: 2.23190
Value Function Loss: 0.01588

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.62893

Collected Steps per Second: 21,031.42183
Overall Steps per Second: 10,200.14808

Timestep Collection Time: 2.37825
Timestep Consumption Time: 2.52540
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.90365

Cumulative Model Updates: 228,240
Cumulative Timesteps: 1,903,597,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.66533
Policy Entropy: 2.22821
Value Function Loss: 0.01509

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.63204

Collected Steps per Second: 21,182.01809
Overall Steps per Second: 10,223.62802

Timestep Collection Time: 2.36172
Timestep Consumption Time: 2.53145
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.89317

Cumulative Model Updates: 228,246
Cumulative Timesteps: 1,903,647,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1903647894...
Checkpoint 1903647894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.75712
Policy Entropy: 2.23271
Value Function Loss: 0.01522

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.63192

Collected Steps per Second: 21,514.84628
Overall Steps per Second: 10,424.79878

Timestep Collection Time: 2.32519
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.79875

Cumulative Model Updates: 228,252
Cumulative Timesteps: 1,903,697,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.77648
Policy Entropy: 2.24340
Value Function Loss: 0.01576

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.61782

Collected Steps per Second: 21,122.85730
Overall Steps per Second: 10,447.79369

Timestep Collection Time: 2.36710
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.78570

Cumulative Model Updates: 228,258
Cumulative Timesteps: 1,903,747,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1903747920...
Checkpoint 1903747920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.03070
Policy Entropy: 2.24636
Value Function Loss: 0.01714

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.60090

Collected Steps per Second: 21,597.71708
Overall Steps per Second: 10,313.33000

Timestep Collection Time: 2.31524
Timestep Consumption Time: 2.53324
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.84848

Cumulative Model Updates: 228,264
Cumulative Timesteps: 1,903,797,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.39860
Policy Entropy: 2.26969
Value Function Loss: 0.01628

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.59109

Collected Steps per Second: 21,785.34383
Overall Steps per Second: 10,382.15409

Timestep Collection Time: 2.29521
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.81615

Cumulative Model Updates: 228,270
Cumulative Timesteps: 1,903,847,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1903847926...
Checkpoint 1903847926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.10711
Policy Entropy: 2.25506
Value Function Loss: 0.01636

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.58850

Collected Steps per Second: 21,831.48158
Overall Steps per Second: 10,556.13609

Timestep Collection Time: 2.29128
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.73867

Cumulative Model Updates: 228,276
Cumulative Timesteps: 1,903,897,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.79624
Policy Entropy: 2.29178
Value Function Loss: 0.01596

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.11563
Policy Update Magnitude: 0.54339
Value Function Update Magnitude: 0.59043

Collected Steps per Second: 22,310.06105
Overall Steps per Second: 10,532.79571

Timestep Collection Time: 2.24186
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.74860

Cumulative Model Updates: 228,282
Cumulative Timesteps: 1,903,947,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1903947964...
Checkpoint 1903947964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.87526
Policy Entropy: 2.24981
Value Function Loss: 0.01707

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.63780

Collected Steps per Second: 21,762.33124
Overall Steps per Second: 10,651.36334

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.39812
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.69705

Cumulative Model Updates: 228,288
Cumulative Timesteps: 1,903,997,994

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.85788
Policy Entropy: 2.24341
Value Function Loss: 0.01689

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.63382

Collected Steps per Second: 22,111.24751
Overall Steps per Second: 10,460.18017

Timestep Collection Time: 2.26220
Timestep Consumption Time: 2.51975
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.78194

Cumulative Model Updates: 228,294
Cumulative Timesteps: 1,904,048,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1904048014...
Checkpoint 1904048014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.04412
Policy Entropy: 2.21774
Value Function Loss: 0.01695

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.62086

Collected Steps per Second: 21,929.13899
Overall Steps per Second: 10,315.57866

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.56769
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.84839

Cumulative Model Updates: 228,300
Cumulative Timesteps: 1,904,098,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.53290
Policy Entropy: 2.24708
Value Function Loss: 0.01649

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.62276

Collected Steps per Second: 22,012.52963
Overall Steps per Second: 10,374.42378

Timestep Collection Time: 2.27234
Timestep Consumption Time: 2.54913
PPO Batch Consumption Time: 0.30119
Total Iteration Time: 4.82147

Cumulative Model Updates: 228,306
Cumulative Timesteps: 1,904,148,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1904148048...
Checkpoint 1904148048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.72496
Policy Entropy: 2.27731
Value Function Loss: 0.01574

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.62427

Collected Steps per Second: 21,795.82509
Overall Steps per Second: 10,673.72867

Timestep Collection Time: 2.29567
Timestep Consumption Time: 2.39210
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.68777

Cumulative Model Updates: 228,312
Cumulative Timesteps: 1,904,198,084

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.47370
Policy Entropy: 2.27781
Value Function Loss: 0.01630

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.62850

Collected Steps per Second: 22,113.29553
Overall Steps per Second: 10,425.96995

Timestep Collection Time: 2.26181
Timestep Consumption Time: 2.53544
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.79725

Cumulative Model Updates: 228,318
Cumulative Timesteps: 1,904,248,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1904248100...
Checkpoint 1904248100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.39034
Policy Entropy: 2.26110
Value Function Loss: 0.01628

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.55373
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 21,882.43366
Overall Steps per Second: 10,373.62152

Timestep Collection Time: 2.28521
Timestep Consumption Time: 2.53528
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.82050

Cumulative Model Updates: 228,324
Cumulative Timesteps: 1,904,298,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.84132
Policy Entropy: 2.24037
Value Function Loss: 0.01507

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.63998

Collected Steps per Second: 22,179.13776
Overall Steps per Second: 10,385.81325

Timestep Collection Time: 2.25464
Timestep Consumption Time: 2.56020
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 4.81484

Cumulative Model Updates: 228,330
Cumulative Timesteps: 1,904,348,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1904348112...
Checkpoint 1904348112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.70855
Policy Entropy: 2.23607
Value Function Loss: 0.01503

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.60825

Collected Steps per Second: 21,577.72485
Overall Steps per Second: 10,251.76963

Timestep Collection Time: 2.31915
Timestep Consumption Time: 2.56215
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.88130

Cumulative Model Updates: 228,336
Cumulative Timesteps: 1,904,398,154

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.27544
Policy Entropy: 2.21426
Value Function Loss: 0.01547

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.54562
Value Function Update Magnitude: 0.59291

Collected Steps per Second: 21,454.71826
Overall Steps per Second: 10,379.62557

Timestep Collection Time: 2.33142
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.81906

Cumulative Model Updates: 228,342
Cumulative Timesteps: 1,904,448,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1904448174...
Checkpoint 1904448174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.29169
Policy Entropy: 2.20752
Value Function Loss: 0.01630

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.61039

Collected Steps per Second: 21,752.82152
Overall Steps per Second: 10,550.50348

Timestep Collection Time: 2.29966
Timestep Consumption Time: 2.44173
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.74139

Cumulative Model Updates: 228,348
Cumulative Timesteps: 1,904,498,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.90099
Policy Entropy: 2.21662
Value Function Loss: 0.01593

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 21,729.85472
Overall Steps per Second: 10,519.25783

Timestep Collection Time: 2.30218
Timestep Consumption Time: 2.45348
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.75566

Cumulative Model Updates: 228,354
Cumulative Timesteps: 1,904,548,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1904548224...
Checkpoint 1904548224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.79890
Policy Entropy: 2.24697
Value Function Loss: 0.01643

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.64257

Collected Steps per Second: 22,469.65332
Overall Steps per Second: 10,485.12545

Timestep Collection Time: 2.22549
Timestep Consumption Time: 2.54374
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.76923

Cumulative Model Updates: 228,360
Cumulative Timesteps: 1,904,598,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.60518
Policy Entropy: 2.22810
Value Function Loss: 0.01696

Mean KL Divergence: 0.03107
SB3 Clip Fraction: 0.18637
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.65240

Collected Steps per Second: 21,610.56680
Overall Steps per Second: 10,140.31115

Timestep Collection Time: 2.31378
Timestep Consumption Time: 2.61724
PPO Batch Consumption Time: 0.30671
Total Iteration Time: 4.93101

Cumulative Model Updates: 228,366
Cumulative Timesteps: 1,904,648,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1904648232...
Checkpoint 1904648232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.88942
Policy Entropy: 2.22754
Value Function Loss: 0.01635

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.15454
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.64991

Collected Steps per Second: 21,320.76707
Overall Steps per Second: 10,381.96457

Timestep Collection Time: 2.34541
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.81662

Cumulative Model Updates: 228,372
Cumulative Timesteps: 1,904,698,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.07826
Policy Entropy: 2.21681
Value Function Loss: 0.01597

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.57031
Value Function Update Magnitude: 0.63743

Collected Steps per Second: 21,788.43753
Overall Steps per Second: 10,389.52106

Timestep Collection Time: 2.29608
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.30337
Total Iteration Time: 4.81524

Cumulative Model Updates: 228,378
Cumulative Timesteps: 1,904,748,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1904748266...
Checkpoint 1904748266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.51238
Policy Entropy: 2.23429
Value Function Loss: 0.01520

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 21,846.47187
Overall Steps per Second: 10,316.89996

Timestep Collection Time: 2.28989
Timestep Consumption Time: 2.55905
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.84894

Cumulative Model Updates: 228,384
Cumulative Timesteps: 1,904,798,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.92307
Policy Entropy: 2.24263
Value Function Loss: 0.01556

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.63542

Collected Steps per Second: 22,183.20369
Overall Steps per Second: 10,416.23650

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.54716
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.80193

Cumulative Model Updates: 228,390
Cumulative Timesteps: 1,904,848,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1904848310...
Checkpoint 1904848310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.39042
Policy Entropy: 2.24992
Value Function Loss: 0.01569

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.54593
Value Function Update Magnitude: 0.64868

Collected Steps per Second: 21,810.52741
Overall Steps per Second: 10,467.18996

Timestep Collection Time: 2.29467
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.78142

Cumulative Model Updates: 228,396
Cumulative Timesteps: 1,904,898,358

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.85049
Policy Entropy: 2.25733
Value Function Loss: 0.01530

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.64661

Collected Steps per Second: 20,361.88618
Overall Steps per Second: 10,071.72896

Timestep Collection Time: 2.45734
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.96797

Cumulative Model Updates: 228,402
Cumulative Timesteps: 1,904,948,394

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1904948394...
Checkpoint 1904948394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.80317
Policy Entropy: 2.24328
Value Function Loss: 0.01592

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.62685

Collected Steps per Second: 21,396.94058
Overall Steps per Second: 10,467.83037

Timestep Collection Time: 2.33800
Timestep Consumption Time: 2.44103
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.77902

Cumulative Model Updates: 228,408
Cumulative Timesteps: 1,904,998,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.05269
Policy Entropy: 2.22135
Value Function Loss: 0.01656

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.54874
Value Function Update Magnitude: 0.63851

Collected Steps per Second: 21,356.05483
Overall Steps per Second: 10,308.89272

Timestep Collection Time: 2.34219
Timestep Consumption Time: 2.50993
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.85212

Cumulative Model Updates: 228,414
Cumulative Timesteps: 1,905,048,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1905048440...
Checkpoint 1905048440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.91480
Policy Entropy: 2.20693
Value Function Loss: 0.01632

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.55498
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 21,473.03860
Overall Steps per Second: 10,238.46772

Timestep Collection Time: 2.32971
Timestep Consumption Time: 2.55637
PPO Batch Consumption Time: 0.29980
Total Iteration Time: 4.88608

Cumulative Model Updates: 228,420
Cumulative Timesteps: 1,905,098,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.66400
Policy Entropy: 2.20129
Value Function Loss: 0.01589

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.54886
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 21,749.85191
Overall Steps per Second: 10,453.90977

Timestep Collection Time: 2.29933
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.78386

Cumulative Model Updates: 228,426
Cumulative Timesteps: 1,905,148,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1905148476...
Checkpoint 1905148476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.18181
Policy Entropy: 2.21387
Value Function Loss: 0.01481

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.61664

Collected Steps per Second: 22,301.92163
Overall Steps per Second: 10,609.00607

Timestep Collection Time: 2.24268
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.71449

Cumulative Model Updates: 228,432
Cumulative Timesteps: 1,905,198,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.71655
Policy Entropy: 2.20801
Value Function Loss: 0.01526

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.59349

Collected Steps per Second: 22,091.27563
Overall Steps per Second: 10,491.68105

Timestep Collection Time: 2.26460
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.76835

Cumulative Model Updates: 228,438
Cumulative Timesteps: 1,905,248,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1905248520...
Checkpoint 1905248520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.25537
Policy Entropy: 2.20754
Value Function Loss: 0.01612

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.61464

Collected Steps per Second: 21,757.98423
Overall Steps per Second: 10,308.30997

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.55347
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.85240

Cumulative Model Updates: 228,444
Cumulative Timesteps: 1,905,298,540

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.62016
Policy Entropy: 2.19364
Value Function Loss: 0.01782

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.56944
Value Function Update Magnitude: 0.64144

Collected Steps per Second: 22,064.48587
Overall Steps per Second: 10,753.98473

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.38450
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.65167

Cumulative Model Updates: 228,450
Cumulative Timesteps: 1,905,348,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1905348564...
Checkpoint 1905348564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.69799
Policy Entropy: 2.20327
Value Function Loss: 0.01755

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.57152
Value Function Update Magnitude: 0.65969

Collected Steps per Second: 21,921.02759
Overall Steps per Second: 10,261.42929

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.59263
PPO Batch Consumption Time: 0.30727
Total Iteration Time: 4.87437

Cumulative Model Updates: 228,456
Cumulative Timesteps: 1,905,398,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.62861
Policy Entropy: 2.20486
Value Function Loss: 0.01612

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.65081

Collected Steps per Second: 21,112.29448
Overall Steps per Second: 10,009.06882

Timestep Collection Time: 2.36829
Timestep Consumption Time: 2.62718
PPO Batch Consumption Time: 0.31035
Total Iteration Time: 4.99547

Cumulative Model Updates: 228,462
Cumulative Timesteps: 1,905,448,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1905448582...
Checkpoint 1905448582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.14025
Policy Entropy: 2.21828
Value Function Loss: 0.01593

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.54896
Value Function Update Magnitude: 0.64285

Collected Steps per Second: 21,249.97191
Overall Steps per Second: 10,248.78189

Timestep Collection Time: 2.35407
Timestep Consumption Time: 2.52690
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.88097

Cumulative Model Updates: 228,468
Cumulative Timesteps: 1,905,498,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.36940
Policy Entropy: 2.22971
Value Function Loss: 0.01632

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.65267

Collected Steps per Second: 19,620.35930
Overall Steps per Second: 9,934.31276

Timestep Collection Time: 2.54980
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 5.03588

Cumulative Model Updates: 228,474
Cumulative Timesteps: 1,905,548,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1905548634...
Checkpoint 1905548634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.86107
Policy Entropy: 2.22330
Value Function Loss: 0.01740

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.65753

Collected Steps per Second: 21,231.10074
Overall Steps per Second: 10,354.65801

Timestep Collection Time: 2.35560
Timestep Consumption Time: 2.47430
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.82990

Cumulative Model Updates: 228,480
Cumulative Timesteps: 1,905,598,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.64147
Policy Entropy: 2.23595
Value Function Loss: 0.01679

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.55543
Value Function Update Magnitude: 0.65816

Collected Steps per Second: 21,671.71234
Overall Steps per Second: 10,402.82960

Timestep Collection Time: 2.30799
Timestep Consumption Time: 2.50013
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.80811

Cumulative Model Updates: 228,486
Cumulative Timesteps: 1,905,648,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1905648664...
Checkpoint 1905648664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.18289
Policy Entropy: 2.21167
Value Function Loss: 0.01663

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.55186
Value Function Update Magnitude: 0.63606

Collected Steps per Second: 20,811.86145
Overall Steps per Second: 10,255.53263

Timestep Collection Time: 2.40373
Timestep Consumption Time: 2.47423
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.87795

Cumulative Model Updates: 228,492
Cumulative Timesteps: 1,905,698,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.68185
Policy Entropy: 2.19390
Value Function Loss: 0.01649

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.55380
Value Function Update Magnitude: 0.62436

Collected Steps per Second: 18,997.34601
Overall Steps per Second: 9,477.62569

Timestep Collection Time: 2.63332
Timestep Consumption Time: 2.64501
PPO Batch Consumption Time: 0.31144
Total Iteration Time: 5.27833

Cumulative Model Updates: 228,498
Cumulative Timesteps: 1,905,748,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1905748716...
Checkpoint 1905748716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.10289
Policy Entropy: 2.19340
Value Function Loss: 0.01616

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.61472

Collected Steps per Second: 21,287.22120
Overall Steps per Second: 10,406.90846

Timestep Collection Time: 2.35024
Timestep Consumption Time: 2.45715
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.80738

Cumulative Model Updates: 228,504
Cumulative Timesteps: 1,905,798,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.74520
Policy Entropy: 2.21714
Value Function Loss: 0.01631

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.54579
Value Function Update Magnitude: 0.60957

Collected Steps per Second: 21,696.27719
Overall Steps per Second: 10,432.91769

Timestep Collection Time: 2.30519
Timestep Consumption Time: 2.48868
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.79387

Cumulative Model Updates: 228,510
Cumulative Timesteps: 1,905,848,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1905848760...
Checkpoint 1905848760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.39075
Policy Entropy: 2.20790
Value Function Loss: 0.01643

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.56103
Value Function Update Magnitude: 0.61917

Collected Steps per Second: 21,565.28222
Overall Steps per Second: 10,166.73060

Timestep Collection Time: 2.31873
Timestep Consumption Time: 2.59967
PPO Batch Consumption Time: 0.30552
Total Iteration Time: 4.91840

Cumulative Model Updates: 228,516
Cumulative Timesteps: 1,905,898,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.38437
Policy Entropy: 2.21082
Value Function Loss: 0.01574

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.15591
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.62376

Collected Steps per Second: 20,736.83533
Overall Steps per Second: 10,001.75851

Timestep Collection Time: 2.41117
Timestep Consumption Time: 2.58795
PPO Batch Consumption Time: 0.30195
Total Iteration Time: 4.99912

Cumulative Model Updates: 228,522
Cumulative Timesteps: 1,905,948,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1905948764...
Checkpoint 1905948764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.80745
Policy Entropy: 2.20304
Value Function Loss: 0.01645

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.55562
Value Function Update Magnitude: 0.61466

Collected Steps per Second: 21,341.18144
Overall Steps per Second: 10,221.45429

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.55011
PPO Batch Consumption Time: 0.30805
Total Iteration Time: 4.89422

Cumulative Model Updates: 228,528
Cumulative Timesteps: 1,905,998,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.30864
Policy Entropy: 2.22069
Value Function Loss: 0.01675

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.56417
Value Function Update Magnitude: 0.62189

Collected Steps per Second: 21,427.47815
Overall Steps per Second: 10,129.33610

Timestep Collection Time: 2.33373
Timestep Consumption Time: 2.60302
PPO Batch Consumption Time: 0.30596
Total Iteration Time: 4.93675

Cumulative Model Updates: 228,534
Cumulative Timesteps: 1,906,048,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1906048796...
Checkpoint 1906048796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.33401
Policy Entropy: 2.20712
Value Function Loss: 0.01615

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.55084
Value Function Update Magnitude: 0.62389

Collected Steps per Second: 20,842.90940
Overall Steps per Second: 10,224.30847

Timestep Collection Time: 2.39899
Timestep Consumption Time: 2.49151
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.89050

Cumulative Model Updates: 228,540
Cumulative Timesteps: 1,906,098,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.26053
Policy Entropy: 2.21726
Value Function Loss: 0.01578

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.60377

Collected Steps per Second: 21,124.07237
Overall Steps per Second: 10,278.78248

Timestep Collection Time: 2.36716
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.86478

Cumulative Model Updates: 228,546
Cumulative Timesteps: 1,906,148,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1906148802...
Checkpoint 1906148802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.28044
Policy Entropy: 2.23303
Value Function Loss: 0.01593

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.60111

Collected Steps per Second: 21,374.68171
Overall Steps per Second: 10,471.39975

Timestep Collection Time: 2.33987
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.77625

Cumulative Model Updates: 228,552
Cumulative Timesteps: 1,906,198,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.78829
Policy Entropy: 2.21066
Value Function Loss: 0.01780

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,278.40027
Overall Steps per Second: 10,453.73289

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.53947
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.78451

Cumulative Model Updates: 228,558
Cumulative Timesteps: 1,906,248,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1906248832...
Checkpoint 1906248832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.66819
Policy Entropy: 2.20767
Value Function Loss: 0.01820

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.56277
Value Function Update Magnitude: 0.62242

Collected Steps per Second: 21,777.49958
Overall Steps per Second: 10,509.74048

Timestep Collection Time: 2.29668
Timestep Consumption Time: 2.46233
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.75901

Cumulative Model Updates: 228,564
Cumulative Timesteps: 1,906,298,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.57913
Policy Entropy: 2.20846
Value Function Loss: 0.01795

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.62172

Collected Steps per Second: 22,156.70268
Overall Steps per Second: 10,569.75582

Timestep Collection Time: 2.25738
Timestep Consumption Time: 2.47462
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.73199

Cumulative Model Updates: 228,570
Cumulative Timesteps: 1,906,348,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1906348864...
Checkpoint 1906348864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.70233
Policy Entropy: 2.25627
Value Function Loss: 0.01768

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.60330

Collected Steps per Second: 21,853.06455
Overall Steps per Second: 10,554.51062

Timestep Collection Time: 2.28883
Timestep Consumption Time: 2.45018
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.73902

Cumulative Model Updates: 228,576
Cumulative Timesteps: 1,906,398,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.30112
Policy Entropy: 2.24049
Value Function Loss: 0.01632

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.58934

Collected Steps per Second: 22,907.52523
Overall Steps per Second: 10,526.07829

Timestep Collection Time: 2.18321
Timestep Consumption Time: 2.56803
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 4.75125

Cumulative Model Updates: 228,582
Cumulative Timesteps: 1,906,448,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1906448894...
Checkpoint 1906448894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.26193
Policy Entropy: 2.23144
Value Function Loss: 0.01631

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.59562

Collected Steps per Second: 21,219.08497
Overall Steps per Second: 10,206.38770

Timestep Collection Time: 2.35675
Timestep Consumption Time: 2.54293
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.89968

Cumulative Model Updates: 228,588
Cumulative Timesteps: 1,906,498,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.57087
Policy Entropy: 2.21716
Value Function Loss: 0.01591

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.61118

Collected Steps per Second: 21,943.05257
Overall Steps per Second: 10,493.24129

Timestep Collection Time: 2.27935
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.76650

Cumulative Model Updates: 228,594
Cumulative Timesteps: 1,906,548,918

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1906548918...
Checkpoint 1906548918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.96717
Policy Entropy: 2.23969
Value Function Loss: 0.01625

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.54580
Value Function Update Magnitude: 0.61399

Collected Steps per Second: 21,639.97134
Overall Steps per Second: 10,375.29154

Timestep Collection Time: 2.31266
Timestep Consumption Time: 2.51091
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.82358

Cumulative Model Updates: 228,600
Cumulative Timesteps: 1,906,598,964

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.17135
Policy Entropy: 2.22892
Value Function Loss: 0.01619

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.62053

Collected Steps per Second: 21,682.78307
Overall Steps per Second: 10,416.69010

Timestep Collection Time: 2.30635
Timestep Consumption Time: 2.49441
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.80076

Cumulative Model Updates: 228,606
Cumulative Timesteps: 1,906,648,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1906648972...
Checkpoint 1906648972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.28074
Policy Entropy: 2.22759
Value Function Loss: 0.01600

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.60991

Collected Steps per Second: 20,569.50660
Overall Steps per Second: 10,101.77210

Timestep Collection Time: 2.43214
Timestep Consumption Time: 2.52025
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.95240

Cumulative Model Updates: 228,612
Cumulative Timesteps: 1,906,699,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.50453
Policy Entropy: 2.20261
Value Function Loss: 0.01644

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.61163

Collected Steps per Second: 21,974.84631
Overall Steps per Second: 10,319.15888

Timestep Collection Time: 2.27624
Timestep Consumption Time: 2.57106
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.84729

Cumulative Model Updates: 228,618
Cumulative Timesteps: 1,906,749,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1906749020...
Checkpoint 1906749020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.02175
Policy Entropy: 2.20921
Value Function Loss: 0.01624

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.60688

Collected Steps per Second: 21,624.65544
Overall Steps per Second: 10,373.07638

Timestep Collection Time: 2.31338
Timestep Consumption Time: 2.50930
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.82268

Cumulative Model Updates: 228,624
Cumulative Timesteps: 1,906,799,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.02636
Policy Entropy: 2.20077
Value Function Loss: 0.01709

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.60362

Collected Steps per Second: 22,262.79663
Overall Steps per Second: 10,649.47371

Timestep Collection Time: 2.24608
Timestep Consumption Time: 2.44936
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.69544

Cumulative Model Updates: 228,630
Cumulative Timesteps: 1,906,849,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1906849050...
Checkpoint 1906849050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.04270
Policy Entropy: 2.21875
Value Function Loss: 0.01645

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.60691

Collected Steps per Second: 21,824.27953
Overall Steps per Second: 10,451.65321

Timestep Collection Time: 2.29332
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.78872

Cumulative Model Updates: 228,636
Cumulative Timesteps: 1,906,899,100

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.88466
Policy Entropy: 2.24817
Value Function Loss: 0.01642

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.62185

Collected Steps per Second: 22,221.34367
Overall Steps per Second: 10,458.63533

Timestep Collection Time: 2.25117
Timestep Consumption Time: 2.53186
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.78303

Cumulative Model Updates: 228,642
Cumulative Timesteps: 1,906,949,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1906949124...
Checkpoint 1906949124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.92156
Policy Entropy: 2.22995
Value Function Loss: 0.01650

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.61923

Collected Steps per Second: 21,011.41470
Overall Steps per Second: 10,108.82964

Timestep Collection Time: 2.37966
Timestep Consumption Time: 2.56651
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.94617

Cumulative Model Updates: 228,648
Cumulative Timesteps: 1,906,999,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.07039
Policy Entropy: 2.22279
Value Function Loss: 0.01659

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.55006
Value Function Update Magnitude: 0.63589

Collected Steps per Second: 22,037.74592
Overall Steps per Second: 10,603.72494

Timestep Collection Time: 2.26938
Timestep Consumption Time: 2.44708
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.71646

Cumulative Model Updates: 228,654
Cumulative Timesteps: 1,907,049,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1907049136...
Checkpoint 1907049136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.81648
Policy Entropy: 2.16786
Value Function Loss: 0.01709

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.63817

Collected Steps per Second: 22,583.60646
Overall Steps per Second: 10,646.04117

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.70015

Cumulative Model Updates: 228,660
Cumulative Timesteps: 1,907,099,174

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.10507
Policy Entropy: 2.18826
Value Function Loss: 0.01710

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.55409
Value Function Update Magnitude: 0.61961

Collected Steps per Second: 22,021.96702
Overall Steps per Second: 10,469.45764

Timestep Collection Time: 2.27137
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.77771

Cumulative Model Updates: 228,666
Cumulative Timesteps: 1,907,149,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1907149194...
Checkpoint 1907149194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.92198
Policy Entropy: 2.20699
Value Function Loss: 0.01665

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.55433
Value Function Update Magnitude: 0.61836

Collected Steps per Second: 21,816.11717
Overall Steps per Second: 10,486.93203

Timestep Collection Time: 2.29280
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.76975

Cumulative Model Updates: 228,672
Cumulative Timesteps: 1,907,199,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.46926
Policy Entropy: 2.24157
Value Function Loss: 0.01608

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.55274
Value Function Update Magnitude: 0.61869

Collected Steps per Second: 22,360.82124
Overall Steps per Second: 10,599.05248

Timestep Collection Time: 2.23641
Timestep Consumption Time: 2.48175
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.71816

Cumulative Model Updates: 228,678
Cumulative Timesteps: 1,907,249,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1907249222...
Checkpoint 1907249222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.08849
Policy Entropy: 2.24448
Value Function Loss: 0.01577

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.54443
Value Function Update Magnitude: 0.60660

Collected Steps per Second: 21,960.90331
Overall Steps per Second: 10,422.27441

Timestep Collection Time: 2.27796
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.79991

Cumulative Model Updates: 228,684
Cumulative Timesteps: 1,907,299,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.95773
Policy Entropy: 2.21688
Value Function Loss: 0.01571

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 21,909.33247
Overall Steps per Second: 10,377.61445

Timestep Collection Time: 2.28222
Timestep Consumption Time: 2.53603
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.81826

Cumulative Model Updates: 228,690
Cumulative Timesteps: 1,907,349,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1907349250...
Checkpoint 1907349250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.30986
Policy Entropy: 2.23448
Value Function Loss: 0.01539

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.53126
Value Function Update Magnitude: 0.58409

Collected Steps per Second: 21,596.69305
Overall Steps per Second: 10,528.73182

Timestep Collection Time: 2.31563
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.74986

Cumulative Model Updates: 228,696
Cumulative Timesteps: 1,907,399,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.98960
Policy Entropy: 2.24710
Value Function Loss: 0.01546

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.53149
Value Function Update Magnitude: 0.57530

Collected Steps per Second: 21,968.53960
Overall Steps per Second: 10,533.14048

Timestep Collection Time: 2.27698
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.74901

Cumulative Model Updates: 228,702
Cumulative Timesteps: 1,907,449,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1907449282...
Checkpoint 1907449282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.18985
Policy Entropy: 2.30149
Value Function Loss: 0.01507

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.52944
Value Function Update Magnitude: 0.56354

Collected Steps per Second: 21,939.50315
Overall Steps per Second: 10,436.22062

Timestep Collection Time: 2.27918
Timestep Consumption Time: 2.51221
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.79139

Cumulative Model Updates: 228,708
Cumulative Timesteps: 1,907,499,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.16144
Policy Entropy: 2.29285
Value Function Loss: 0.01602

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.53838
Value Function Update Magnitude: 0.56618

Collected Steps per Second: 20,990.31643
Overall Steps per Second: 9,958.40492

Timestep Collection Time: 2.38310
Timestep Consumption Time: 2.63999
PPO Batch Consumption Time: 0.30396
Total Iteration Time: 5.02309

Cumulative Model Updates: 228,714
Cumulative Timesteps: 1,907,549,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1907549308...
Checkpoint 1907549308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.02981
Policy Entropy: 2.27182
Value Function Loss: 0.01770

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.60385

Collected Steps per Second: 20,724.85942
Overall Steps per Second: 10,056.67985

Timestep Collection Time: 2.41256
Timestep Consumption Time: 2.55926
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.97182

Cumulative Model Updates: 228,720
Cumulative Timesteps: 1,907,599,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.06110
Policy Entropy: 2.23395
Value Function Loss: 0.01834

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 20,943.69351
Overall Steps per Second: 10,126.51685

Timestep Collection Time: 2.38735
Timestep Consumption Time: 2.55018
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.93753

Cumulative Model Updates: 228,726
Cumulative Timesteps: 1,907,649,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1907649308...
Checkpoint 1907649308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.77635
Policy Entropy: 2.20981
Value Function Loss: 0.01867

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.61568

Collected Steps per Second: 20,706.79291
Overall Steps per Second: 9,969.95098

Timestep Collection Time: 2.41496
Timestep Consumption Time: 2.60072
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 5.01567

Cumulative Model Updates: 228,732
Cumulative Timesteps: 1,907,699,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.13704
Policy Entropy: 2.22347
Value Function Loss: 0.01701

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.54756
Value Function Update Magnitude: 0.63046

Collected Steps per Second: 19,968.15873
Overall Steps per Second: 9,749.38392

Timestep Collection Time: 2.50499
Timestep Consumption Time: 2.62559
PPO Batch Consumption Time: 0.30525
Total Iteration Time: 5.13058

Cumulative Model Updates: 228,738
Cumulative Timesteps: 1,907,749,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1907749334...
Checkpoint 1907749334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.51087
Policy Entropy: 2.24896
Value Function Loss: 0.01606

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.62406

Collected Steps per Second: 20,596.16383
Overall Steps per Second: 10,141.29652

Timestep Collection Time: 2.42861
Timestep Consumption Time: 2.50370
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.93231

Cumulative Model Updates: 228,744
Cumulative Timesteps: 1,907,799,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.80021
Policy Entropy: 2.25211
Value Function Loss: 0.01604

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.60966

Collected Steps per Second: 21,589.48739
Overall Steps per Second: 10,190.96302

Timestep Collection Time: 2.31724
Timestep Consumption Time: 2.59182
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.90906

Cumulative Model Updates: 228,750
Cumulative Timesteps: 1,907,849,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1907849382...
Checkpoint 1907849382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.31975
Policy Entropy: 2.22361
Value Function Loss: 0.01733

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.61801

Collected Steps per Second: 20,775.42332
Overall Steps per Second: 10,018.05506

Timestep Collection Time: 2.40707
Timestep Consumption Time: 2.58471
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.99179

Cumulative Model Updates: 228,756
Cumulative Timesteps: 1,907,899,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.00397
Policy Entropy: 2.18486
Value Function Loss: 0.01849

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.55135
Value Function Update Magnitude: 0.62126

Collected Steps per Second: 20,831.47207
Overall Steps per Second: 10,101.59473

Timestep Collection Time: 2.40204
Timestep Consumption Time: 2.55144
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.95348

Cumulative Model Updates: 228,762
Cumulative Timesteps: 1,907,949,428

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1907949428...
Checkpoint 1907949428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.29815
Policy Entropy: 2.18189
Value Function Loss: 0.01880

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.55014
Value Function Update Magnitude: 0.62300

Collected Steps per Second: 20,981.17295
Overall Steps per Second: 10,285.03025

Timestep Collection Time: 2.38357
Timestep Consumption Time: 2.47884
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.86241

Cumulative Model Updates: 228,768
Cumulative Timesteps: 1,907,999,438

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.50276
Policy Entropy: 2.22025
Value Function Loss: 0.01803

Mean KL Divergence: 0.02843
SB3 Clip Fraction: 0.17000
Policy Update Magnitude: 0.52939
Value Function Update Magnitude: 0.63669

Collected Steps per Second: 20,592.87761
Overall Steps per Second: 10,125.55453

Timestep Collection Time: 2.42919
Timestep Consumption Time: 2.51118
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.94037

Cumulative Model Updates: 228,774
Cumulative Timesteps: 1,908,049,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1908049462...
Checkpoint 1908049462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.05242
Policy Entropy: 2.26118
Value Function Loss: 0.01630

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.15601
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.64174

Collected Steps per Second: 20,856.57018
Overall Steps per Second: 10,019.82454

Timestep Collection Time: 2.39867
Timestep Consumption Time: 2.59423
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.99290

Cumulative Model Updates: 228,780
Cumulative Timesteps: 1,908,099,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.08862
Policy Entropy: 2.25626
Value Function Loss: 0.01739

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 20,353.87094
Overall Steps per Second: 10,044.19688

Timestep Collection Time: 2.45801
Timestep Consumption Time: 2.52298
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.98099

Cumulative Model Updates: 228,786
Cumulative Timesteps: 1,908,149,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1908149520...
Checkpoint 1908149520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.74704
Policy Entropy: 2.22879
Value Function Loss: 0.01718

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.60721

Collected Steps per Second: 20,351.06420
Overall Steps per Second: 10,134.64410

Timestep Collection Time: 2.45835
Timestep Consumption Time: 2.47818
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.93653

Cumulative Model Updates: 228,792
Cumulative Timesteps: 1,908,199,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.36420
Policy Entropy: 2.21159
Value Function Loss: 0.01669

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.59396

Collected Steps per Second: 20,569.45563
Overall Steps per Second: 10,164.20990

Timestep Collection Time: 2.43176
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.92119

Cumulative Model Updates: 228,798
Cumulative Timesteps: 1,908,249,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1908249570...
Checkpoint 1908249570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.61075
Policy Entropy: 2.22392
Value Function Loss: 0.01661

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.56116
Value Function Update Magnitude: 0.61359

Collected Steps per Second: 20,776.37127
Overall Steps per Second: 10,082.27155

Timestep Collection Time: 2.40716
Timestep Consumption Time: 2.55323
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.96039

Cumulative Model Updates: 228,804
Cumulative Timesteps: 1,908,299,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.47170
Policy Entropy: 2.23381
Value Function Loss: 0.01756

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.65110

Collected Steps per Second: 21,256.77280
Overall Steps per Second: 10,395.65838

Timestep Collection Time: 2.35285
Timestep Consumption Time: 2.45820
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.81105

Cumulative Model Updates: 228,810
Cumulative Timesteps: 1,908,349,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1908349596...
Checkpoint 1908349596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.47531
Policy Entropy: 2.23653
Value Function Loss: 0.01782

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.55914
Value Function Update Magnitude: 0.65501

Collected Steps per Second: 20,749.62975
Overall Steps per Second: 10,106.86829

Timestep Collection Time: 2.41007
Timestep Consumption Time: 2.53786
PPO Batch Consumption Time: 0.30478
Total Iteration Time: 4.94792

Cumulative Model Updates: 228,816
Cumulative Timesteps: 1,908,399,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.95822
Policy Entropy: 2.24723
Value Function Loss: 0.01807

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.63810

Collected Steps per Second: 21,337.46096
Overall Steps per Second: 9,961.89711

Timestep Collection Time: 2.34414
Timestep Consumption Time: 2.67679
PPO Batch Consumption Time: 0.30998
Total Iteration Time: 5.02093

Cumulative Model Updates: 228,822
Cumulative Timesteps: 1,908,449,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1908449622...
Checkpoint 1908449622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.07328
Policy Entropy: 2.24546
Value Function Loss: 0.01786

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.64209

Collected Steps per Second: 20,537.60967
Overall Steps per Second: 9,739.38764

Timestep Collection Time: 2.43514
Timestep Consumption Time: 2.69988
PPO Batch Consumption Time: 0.31261
Total Iteration Time: 5.13503

Cumulative Model Updates: 228,828
Cumulative Timesteps: 1,908,499,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.10384
Policy Entropy: 2.22078
Value Function Loss: 0.01770

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.65467

Collected Steps per Second: 20,776.99705
Overall Steps per Second: 10,158.50864

Timestep Collection Time: 2.40757
Timestep Consumption Time: 2.51658
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.92415

Cumulative Model Updates: 228,834
Cumulative Timesteps: 1,908,549,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1908549656...
Checkpoint 1908549656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.73000
Policy Entropy: 2.20185
Value Function Loss: 0.01771

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.64810

Collected Steps per Second: 21,063.34741
Overall Steps per Second: 10,151.72174

Timestep Collection Time: 2.37465
Timestep Consumption Time: 2.55240
PPO Batch Consumption Time: 0.30301
Total Iteration Time: 4.92705

Cumulative Model Updates: 228,840
Cumulative Timesteps: 1,908,599,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.77590
Policy Entropy: 2.20484
Value Function Loss: 0.01737

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.56422
Value Function Update Magnitude: 0.61553

Collected Steps per Second: 20,973.95514
Overall Steps per Second: 10,191.36342

Timestep Collection Time: 2.38496
Timestep Consumption Time: 2.52332
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.90827

Cumulative Model Updates: 228,846
Cumulative Timesteps: 1,908,649,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1908649696...
Checkpoint 1908649696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.37598
Policy Entropy: 2.21521
Value Function Loss: 0.01823

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.60679

Collected Steps per Second: 20,203.32147
Overall Steps per Second: 10,033.49452

Timestep Collection Time: 2.47623
Timestep Consumption Time: 2.50987
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.98610

Cumulative Model Updates: 228,852
Cumulative Timesteps: 1,908,699,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.83237
Policy Entropy: 2.23710
Value Function Loss: 0.01697

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.16736
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.61371

Collected Steps per Second: 21,371.52786
Overall Steps per Second: 10,268.16533

Timestep Collection Time: 2.34022
Timestep Consumption Time: 2.53057
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.87078

Cumulative Model Updates: 228,858
Cumulative Timesteps: 1,908,749,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1908749738...
Checkpoint 1908749738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.38370
Policy Entropy: 2.23595
Value Function Loss: 0.01757

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.17014
Policy Update Magnitude: 0.48249
Value Function Update Magnitude: 0.62037

Collected Steps per Second: 21,269.02307
Overall Steps per Second: 10,501.54242

Timestep Collection Time: 2.35112
Timestep Consumption Time: 2.41066
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.76178

Cumulative Model Updates: 228,864
Cumulative Timesteps: 1,908,799,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.85478
Policy Entropy: 2.25297
Value Function Loss: 0.01665

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.52365
Value Function Update Magnitude: 0.63181

Collected Steps per Second: 22,067.38854
Overall Steps per Second: 10,422.18846

Timestep Collection Time: 2.26606
Timestep Consumption Time: 2.53197
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.79803

Cumulative Model Updates: 228,870
Cumulative Timesteps: 1,908,849,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1908849750...
Checkpoint 1908849750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.07863
Policy Entropy: 2.24536
Value Function Loss: 0.01746

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.55857
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 21,247.20354
Overall Steps per Second: 10,388.93557

Timestep Collection Time: 2.35400
Timestep Consumption Time: 2.46035
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.81435

Cumulative Model Updates: 228,876
Cumulative Timesteps: 1,908,899,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.27926
Policy Entropy: 2.23213
Value Function Loss: 0.01712

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.62138

Collected Steps per Second: 21,396.98400
Overall Steps per Second: 10,336.81470

Timestep Collection Time: 2.33753
Timestep Consumption Time: 2.50110
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.83863

Cumulative Model Updates: 228,882
Cumulative Timesteps: 1,908,949,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1908949782...
Checkpoint 1908949782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.41300
Policy Entropy: 2.23664
Value Function Loss: 0.01707

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.55313
Value Function Update Magnitude: 0.61603

Collected Steps per Second: 21,705.75350
Overall Steps per Second: 10,563.75772

Timestep Collection Time: 2.30418
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.73449

Cumulative Model Updates: 228,888
Cumulative Timesteps: 1,908,999,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.78985
Policy Entropy: 2.23330
Value Function Loss: 0.01631

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 21,858.39640
Overall Steps per Second: 10,473.97425

Timestep Collection Time: 2.28791
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.77469

Cumulative Model Updates: 228,894
Cumulative Timesteps: 1,909,049,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1909049806...
Checkpoint 1909049806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.15922
Policy Entropy: 2.25121
Value Function Loss: 0.01698

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 21,422.94970
Overall Steps per Second: 10,235.50020

Timestep Collection Time: 2.33469
Timestep Consumption Time: 2.55183
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.88652

Cumulative Model Updates: 228,900
Cumulative Timesteps: 1,909,099,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.05850
Policy Entropy: 2.24070
Value Function Loss: 0.01789

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.56914
Value Function Update Magnitude: 0.62740

Collected Steps per Second: 22,219.98953
Overall Steps per Second: 10,445.53718

Timestep Collection Time: 2.25239
Timestep Consumption Time: 2.53894
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.79133

Cumulative Model Updates: 228,906
Cumulative Timesteps: 1,909,149,870

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1909149870...
Checkpoint 1909149870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.13852
Policy Entropy: 2.23502
Value Function Loss: 0.01807

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.63391

Collected Steps per Second: 20,656.40937
Overall Steps per Second: 10,141.47652

Timestep Collection Time: 2.42094
Timestep Consumption Time: 2.51009
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.93104

Cumulative Model Updates: 228,912
Cumulative Timesteps: 1,909,199,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.96036
Policy Entropy: 2.21612
Value Function Loss: 0.01776

Mean KL Divergence: 0.03007
SB3 Clip Fraction: 0.17988
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.63782

Collected Steps per Second: 20,916.45053
Overall Steps per Second: 10,093.47081

Timestep Collection Time: 2.39228
Timestep Consumption Time: 2.56518
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.95746

Cumulative Model Updates: 228,918
Cumulative Timesteps: 1,909,249,916

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1909249916...
Checkpoint 1909249916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.30807
Policy Entropy: 2.25531
Value Function Loss: 0.01653

Mean KL Divergence: 0.02817
SB3 Clip Fraction: 0.17218
Policy Update Magnitude: 0.54936
Value Function Update Magnitude: 0.64473

Collected Steps per Second: 20,636.07186
Overall Steps per Second: 10,137.96808

Timestep Collection Time: 2.42323
Timestep Consumption Time: 2.50931
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.93255

Cumulative Model Updates: 228,924
Cumulative Timesteps: 1,909,299,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.68136
Policy Entropy: 2.24552
Value Function Loss: 0.01679

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.16134
Policy Update Magnitude: 0.55317
Value Function Update Magnitude: 0.67644

Collected Steps per Second: 21,957.11501
Overall Steps per Second: 10,575.43819

Timestep Collection Time: 2.27780
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.72926

Cumulative Model Updates: 228,930
Cumulative Timesteps: 1,909,349,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1909349936...
Checkpoint 1909349936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.54984
Policy Entropy: 2.26626
Value Function Loss: 0.01651

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.55745
Value Function Update Magnitude: 0.68260

Collected Steps per Second: 20,792.28485
Overall Steps per Second: 10,204.72469

Timestep Collection Time: 2.40493
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.90008

Cumulative Model Updates: 228,936
Cumulative Timesteps: 1,909,399,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.09145
Policy Entropy: 2.23819
Value Function Loss: 0.01687

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.67075

Collected Steps per Second: 21,999.07877
Overall Steps per Second: 10,570.91611

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.73223

Cumulative Model Updates: 228,942
Cumulative Timesteps: 1,909,449,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1909449964...
Checkpoint 1909449964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.63663
Policy Entropy: 2.24732
Value Function Loss: 0.01618

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.64469

Collected Steps per Second: 21,395.12748
Overall Steps per Second: 10,276.76014

Timestep Collection Time: 2.33698
Timestep Consumption Time: 2.52837
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.86535

Cumulative Model Updates: 228,948
Cumulative Timesteps: 1,909,499,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.17795
Policy Entropy: 2.24451
Value Function Loss: 0.01745

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.55719
Value Function Update Magnitude: 0.63951

Collected Steps per Second: 21,764.93117
Overall Steps per Second: 10,281.81707

Timestep Collection Time: 2.29746
Timestep Consumption Time: 2.56589
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.86334

Cumulative Model Updates: 228,954
Cumulative Timesteps: 1,909,549,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1909549968...
Checkpoint 1909549968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.52104
Policy Entropy: 2.22379
Value Function Loss: 0.01714

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.63256

Collected Steps per Second: 21,422.27477
Overall Steps per Second: 10,296.08637

Timestep Collection Time: 2.33514
Timestep Consumption Time: 2.52341
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.85855

Cumulative Model Updates: 228,960
Cumulative Timesteps: 1,909,599,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.19602
Policy Entropy: 2.24609
Value Function Loss: 0.01671

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.62127

Collected Steps per Second: 22,164.02826
Overall Steps per Second: 10,691.74381

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.67800

Cumulative Model Updates: 228,966
Cumulative Timesteps: 1,909,650,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1909650008...
Checkpoint 1909650008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.55179
Policy Entropy: 2.24467
Value Function Loss: 0.01618

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.61585

Collected Steps per Second: 21,673.75274
Overall Steps per Second: 10,308.31889

Timestep Collection Time: 2.30786
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.85239

Cumulative Model Updates: 228,972
Cumulative Timesteps: 1,909,700,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.42443
Policy Entropy: 2.26114
Value Function Loss: 0.01623

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.61052

Collected Steps per Second: 21,611.65896
Overall Steps per Second: 10,254.61246

Timestep Collection Time: 2.31394
Timestep Consumption Time: 2.56270
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 4.87663

Cumulative Model Updates: 228,978
Cumulative Timesteps: 1,909,750,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1909750036...
Checkpoint 1909750036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.29051
Policy Entropy: 2.23063
Value Function Loss: 0.01632

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 21,172.26183
Overall Steps per Second: 10,210.99734

Timestep Collection Time: 2.36253
Timestep Consumption Time: 2.53611
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.89864

Cumulative Model Updates: 228,984
Cumulative Timesteps: 1,909,800,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.14865
Policy Entropy: 2.20902
Value Function Loss: 0.01633

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.60013

Collected Steps per Second: 21,195.30217
Overall Steps per Second: 10,374.97124

Timestep Collection Time: 2.36024
Timestep Consumption Time: 2.46156
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.82180

Cumulative Model Updates: 228,990
Cumulative Timesteps: 1,909,850,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1909850082...
Checkpoint 1909850082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.59419
Policy Entropy: 2.17432
Value Function Loss: 0.01694

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.54504
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 21,443.53758
Overall Steps per Second: 10,393.84406

Timestep Collection Time: 2.33236
Timestep Consumption Time: 2.47953
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.81189

Cumulative Model Updates: 228,996
Cumulative Timesteps: 1,909,900,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.78545
Policy Entropy: 2.21664
Value Function Loss: 0.01653

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.61223

Collected Steps per Second: 21,054.44249
Overall Steps per Second: 10,011.21081

Timestep Collection Time: 2.37508
Timestep Consumption Time: 2.61992
PPO Batch Consumption Time: 0.30729
Total Iteration Time: 4.99500

Cumulative Model Updates: 229,002
Cumulative Timesteps: 1,909,950,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1909950102...
Checkpoint 1909950102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.30364
Policy Entropy: 2.23630
Value Function Loss: 0.01711

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.53992
Value Function Update Magnitude: 0.63009

Collected Steps per Second: 20,068.97758
Overall Steps per Second: 9,903.14342

Timestep Collection Time: 2.49240
Timestep Consumption Time: 2.55852
PPO Batch Consumption Time: 0.30110
Total Iteration Time: 5.05092

Cumulative Model Updates: 229,008
Cumulative Timesteps: 1,910,000,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.21259
Policy Entropy: 2.30053
Value Function Loss: 0.01630

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 21,864.54404
Overall Steps per Second: 10,403.26385

Timestep Collection Time: 2.28763
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.80791

Cumulative Model Updates: 229,014
Cumulative Timesteps: 1,910,050,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1910050140...
Checkpoint 1910050140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.20350
Policy Entropy: 2.27303
Value Function Loss: 0.01623

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.53290
Value Function Update Magnitude: 0.59909

Collected Steps per Second: 20,494.14657
Overall Steps per Second: 10,010.33145

Timestep Collection Time: 2.43982
Timestep Consumption Time: 2.55522
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.99504

Cumulative Model Updates: 229,020
Cumulative Timesteps: 1,910,100,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.80484
Policy Entropy: 2.30266
Value Function Loss: 0.01518

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.53170
Value Function Update Magnitude: 0.57972

Collected Steps per Second: 21,009.24418
Overall Steps per Second: 10,020.39874

Timestep Collection Time: 2.38114
Timestep Consumption Time: 2.61127
PPO Batch Consumption Time: 0.30282
Total Iteration Time: 4.99242

Cumulative Model Updates: 229,026
Cumulative Timesteps: 1,910,150,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1910150168...
Checkpoint 1910150168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.05795
Policy Entropy: 2.26393
Value Function Loss: 0.01536

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.53359
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 22,055.19268
Overall Steps per Second: 10,531.40037

Timestep Collection Time: 2.26713
Timestep Consumption Time: 2.48077
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.74790

Cumulative Model Updates: 229,032
Cumulative Timesteps: 1,910,200,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.08652
Policy Entropy: 2.26893
Value Function Loss: 0.01522

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.53590
Value Function Update Magnitude: 0.58146

Collected Steps per Second: 21,547.66809
Overall Steps per Second: 10,357.38636

Timestep Collection Time: 2.32146
Timestep Consumption Time: 2.50814
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.82960

Cumulative Model Updates: 229,038
Cumulative Timesteps: 1,910,250,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1910250192...
Checkpoint 1910250192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.36026
Policy Entropy: 2.25410
Value Function Loss: 0.01535

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.53140
Value Function Update Magnitude: 0.59345

Collected Steps per Second: 21,432.36727
Overall Steps per Second: 10,235.42145

Timestep Collection Time: 2.33413
Timestep Consumption Time: 2.55340
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.88754

Cumulative Model Updates: 229,044
Cumulative Timesteps: 1,910,300,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.88512
Policy Entropy: 2.28345
Value Function Loss: 0.01576

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.61917

Collected Steps per Second: 20,623.78412
Overall Steps per Second: 10,063.31722

Timestep Collection Time: 2.42536
Timestep Consumption Time: 2.54517
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.97053

Cumulative Model Updates: 229,050
Cumulative Timesteps: 1,910,350,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1910350238...
Checkpoint 1910350238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.38787
Policy Entropy: 2.23912
Value Function Loss: 0.01780

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.62371

Collected Steps per Second: 21,209.69107
Overall Steps per Second: 10,292.99136

Timestep Collection Time: 2.35826
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.85942

Cumulative Model Updates: 229,056
Cumulative Timesteps: 1,910,400,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.94496
Policy Entropy: 2.22994
Value Function Loss: 0.01833

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.64184

Collected Steps per Second: 20,208.26138
Overall Steps per Second: 9,909.97269

Timestep Collection Time: 2.47493
Timestep Consumption Time: 2.57191
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 5.04684

Cumulative Model Updates: 229,062
Cumulative Timesteps: 1,910,450,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1910450270...
Checkpoint 1910450270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.48437
Policy Entropy: 2.20743
Value Function Loss: 0.01864

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.64836

Collected Steps per Second: 20,631.66653
Overall Steps per Second: 9,879.64674

Timestep Collection Time: 2.42346
Timestep Consumption Time: 2.63745
PPO Batch Consumption Time: 0.30686
Total Iteration Time: 5.06091

Cumulative Model Updates: 229,068
Cumulative Timesteps: 1,910,500,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.64733
Policy Entropy: 2.22946
Value Function Loss: 0.01676

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.63493

Collected Steps per Second: 21,623.82099
Overall Steps per Second: 10,175.50943

Timestep Collection Time: 2.31319
Timestep Consumption Time: 2.60253
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.91572

Cumulative Model Updates: 229,074
Cumulative Timesteps: 1,910,550,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1910550290...
Checkpoint 1910550290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.25104
Policy Entropy: 2.21872
Value Function Loss: 0.01740

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.62541

Collected Steps per Second: 21,528.12416
Overall Steps per Second: 10,422.16519

Timestep Collection Time: 2.32384
Timestep Consumption Time: 2.47631
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.80015

Cumulative Model Updates: 229,080
Cumulative Timesteps: 1,910,600,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.31574
Policy Entropy: 2.21843
Value Function Loss: 0.01779

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 20,615.70531
Overall Steps per Second: 10,232.79747

Timestep Collection Time: 2.42601
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.88762

Cumulative Model Updates: 229,086
Cumulative Timesteps: 1,910,650,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1910650332...
Checkpoint 1910650332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.52992
Policy Entropy: 2.21142
Value Function Loss: 0.01808

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.14967
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.63349

Collected Steps per Second: 21,890.89704
Overall Steps per Second: 10,442.88233

Timestep Collection Time: 2.28433
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.78852

Cumulative Model Updates: 229,092
Cumulative Timesteps: 1,910,700,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.98359
Policy Entropy: 2.22152
Value Function Loss: 0.01737

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.62367

Collected Steps per Second: 21,418.61594
Overall Steps per Second: 10,257.75143

Timestep Collection Time: 2.33554
Timestep Consumption Time: 2.54116
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.87670

Cumulative Model Updates: 229,098
Cumulative Timesteps: 1,910,750,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1910750362...
Checkpoint 1910750362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.61309
Policy Entropy: 2.22504
Value Function Loss: 0.01759

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.60346

Collected Steps per Second: 21,669.36328
Overall Steps per Second: 10,453.32236

Timestep Collection Time: 2.30814
Timestep Consumption Time: 2.47656
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.78470

Cumulative Model Updates: 229,104
Cumulative Timesteps: 1,910,800,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.38529
Policy Entropy: 2.23761
Value Function Loss: 0.01794

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.60557

Collected Steps per Second: 20,847.76696
Overall Steps per Second: 10,415.86004

Timestep Collection Time: 2.39949
Timestep Consumption Time: 2.40319
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.80268

Cumulative Model Updates: 229,110
Cumulative Timesteps: 1,910,850,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1910850402...
Checkpoint 1910850402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.88721
Policy Entropy: 2.23949
Value Function Loss: 0.01774

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.60957

Collected Steps per Second: 20,964.89062
Overall Steps per Second: 10,114.87142

Timestep Collection Time: 2.38504
Timestep Consumption Time: 2.55838
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.94341

Cumulative Model Updates: 229,116
Cumulative Timesteps: 1,910,900,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.66888
Policy Entropy: 2.24010
Value Function Loss: 0.01769

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.54929
Value Function Update Magnitude: 0.60949

Collected Steps per Second: 19,860.38737
Overall Steps per Second: 9,777.04858

Timestep Collection Time: 2.51898
Timestep Consumption Time: 2.59790
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 5.11688

Cumulative Model Updates: 229,122
Cumulative Timesteps: 1,910,950,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1910950432...
Checkpoint 1910950432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.53083
Policy Entropy: 2.23474
Value Function Loss: 0.01970

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.63279

Collected Steps per Second: 21,568.42407
Overall Steps per Second: 10,689.28656

Timestep Collection Time: 2.31959
Timestep Consumption Time: 2.36079
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.68039

Cumulative Model Updates: 229,128
Cumulative Timesteps: 1,911,000,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.23155
Policy Entropy: 2.23916
Value Function Loss: 0.01885

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.56359
Value Function Update Magnitude: 0.65474

Collected Steps per Second: 21,599.48870
Overall Steps per Second: 10,259.48723

Timestep Collection Time: 2.31505
Timestep Consumption Time: 2.55887
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.87393

Cumulative Model Updates: 229,134
Cumulative Timesteps: 1,911,050,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1911050466...
Checkpoint 1911050466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.72135
Policy Entropy: 2.22084
Value Function Loss: 0.01867

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.55466
Value Function Update Magnitude: 0.65808

Collected Steps per Second: 21,110.97943
Overall Steps per Second: 10,166.98614

Timestep Collection Time: 2.36938
Timestep Consumption Time: 2.55046
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.91985

Cumulative Model Updates: 229,140
Cumulative Timesteps: 1,911,100,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.92594
Policy Entropy: 2.24138
Value Function Loss: 0.01632

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.54593
Value Function Update Magnitude: 0.65436

Collected Steps per Second: 20,284.89685
Overall Steps per Second: 10,030.62543

Timestep Collection Time: 2.46617
Timestep Consumption Time: 2.52116
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.98733

Cumulative Model Updates: 229,146
Cumulative Timesteps: 1,911,150,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1911150512...
Checkpoint 1911150512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.38577
Policy Entropy: 2.23598
Value Function Loss: 0.01679

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.64398

Collected Steps per Second: 21,183.47762
Overall Steps per Second: 10,260.85180

Timestep Collection Time: 2.36099
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.87425

Cumulative Model Updates: 229,152
Cumulative Timesteps: 1,911,200,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.09881
Policy Entropy: 2.25179
Value Function Loss: 0.01735

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.53318
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 22,733.99670
Overall Steps per Second: 10,320.68777

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.64656
PPO Batch Consumption Time: 0.31090
Total Iteration Time: 4.84696

Cumulative Model Updates: 229,158
Cumulative Timesteps: 1,911,250,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1911250550...
Checkpoint 1911250550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.66761
Policy Entropy: 2.25260
Value Function Loss: 0.01687

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.62487

Collected Steps per Second: 21,262.47926
Overall Steps per Second: 10,254.62032

Timestep Collection Time: 2.35231
Timestep Consumption Time: 2.52510
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.87741

Cumulative Model Updates: 229,164
Cumulative Timesteps: 1,911,300,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.29553
Policy Entropy: 2.25313
Value Function Loss: 0.01712

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.53876
Value Function Update Magnitude: 0.63727

Collected Steps per Second: 22,811.45558
Overall Steps per Second: 10,543.21434

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.55163
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.74447

Cumulative Model Updates: 229,170
Cumulative Timesteps: 1,911,350,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1911350588...
Checkpoint 1911350588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.76295
Policy Entropy: 2.26790
Value Function Loss: 0.01604

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.53807
Value Function Update Magnitude: 0.63667

Collected Steps per Second: 22,330.23224
Overall Steps per Second: 10,647.49074

Timestep Collection Time: 2.23983
Timestep Consumption Time: 2.45761
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.69744

Cumulative Model Updates: 229,176
Cumulative Timesteps: 1,911,400,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.29511
Policy Entropy: 2.25513
Value Function Loss: 0.01697

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.62929

Collected Steps per Second: 22,651.12535
Overall Steps per Second: 10,537.57450

Timestep Collection Time: 2.20837
Timestep Consumption Time: 2.53865
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.74701

Cumulative Model Updates: 229,182
Cumulative Timesteps: 1,911,450,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1911450626...
Checkpoint 1911450626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.70083
Policy Entropy: 2.26817
Value Function Loss: 0.01611

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 22,426.39320
Overall Steps per Second: 10,649.15146

Timestep Collection Time: 2.23085
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.69803

Cumulative Model Updates: 229,188
Cumulative Timesteps: 1,911,500,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.51290
Policy Entropy: 2.23569
Value Function Loss: 0.01623

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.64714

Collected Steps per Second: 22,524.05623
Overall Steps per Second: 10,488.26027

Timestep Collection Time: 2.22038
Timestep Consumption Time: 2.54800
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.76838

Cumulative Model Updates: 229,194
Cumulative Timesteps: 1,911,550,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1911550668...
Checkpoint 1911550668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.32265
Policy Entropy: 2.23154
Value Function Loss: 0.01630

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.65000

Collected Steps per Second: 22,448.71365
Overall Steps per Second: 10,577.39269

Timestep Collection Time: 2.22855
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.72971

Cumulative Model Updates: 229,200
Cumulative Timesteps: 1,911,600,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.49547
Policy Entropy: 2.23964
Value Function Loss: 0.01746

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.66335

Collected Steps per Second: 22,983.02808
Overall Steps per Second: 10,850.58288

Timestep Collection Time: 2.17561
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.60823

Cumulative Model Updates: 229,206
Cumulative Timesteps: 1,911,650,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1911650698...
Checkpoint 1911650698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.30491
Policy Entropy: 2.27555
Value Function Loss: 0.01643

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.54786
Value Function Update Magnitude: 0.66206

Collected Steps per Second: 21,893.76373
Overall Steps per Second: 10,170.23111

Timestep Collection Time: 2.28476
Timestep Consumption Time: 2.63371
PPO Batch Consumption Time: 0.31025
Total Iteration Time: 4.91847

Cumulative Model Updates: 229,212
Cumulative Timesteps: 1,911,700,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.16880
Policy Entropy: 2.29353
Value Function Loss: 0.01688

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11810
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.66763

Collected Steps per Second: 22,319.46843
Overall Steps per Second: 10,622.57033

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.46775
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.70884

Cumulative Model Updates: 229,218
Cumulative Timesteps: 1,911,750,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1911750740...
Checkpoint 1911750740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.85658
Policy Entropy: 2.27517
Value Function Loss: 0.01667

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.67716

Collected Steps per Second: 22,211.92577
Overall Steps per Second: 10,577.26976

Timestep Collection Time: 2.25212
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.72939

Cumulative Model Updates: 229,224
Cumulative Timesteps: 1,911,800,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.65719
Policy Entropy: 2.23502
Value Function Loss: 0.01881

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.55690
Value Function Update Magnitude: 0.67480

Collected Steps per Second: 22,909.13598
Overall Steps per Second: 10,844.06343

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.42906
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.61229

Cumulative Model Updates: 229,230
Cumulative Timesteps: 1,911,850,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1911850780...
Checkpoint 1911850780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.66576
Policy Entropy: 2.22100
Value Function Loss: 0.01779

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.64880

Collected Steps per Second: 22,436.12778
Overall Steps per Second: 10,584.81640

Timestep Collection Time: 2.22908
Timestep Consumption Time: 2.49580
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.72488

Cumulative Model Updates: 229,236
Cumulative Timesteps: 1,911,900,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.02720
Policy Entropy: 2.21535
Value Function Loss: 0.01882

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.55919
Value Function Update Magnitude: 0.65039

Collected Steps per Second: 22,935.97023
Overall Steps per Second: 10,599.79367

Timestep Collection Time: 2.18024
Timestep Consumption Time: 2.53740
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.71764

Cumulative Model Updates: 229,242
Cumulative Timesteps: 1,911,950,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1911950798...
Checkpoint 1911950798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.63927
Policy Entropy: 2.26881
Value Function Loss: 0.01780

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.68045

Collected Steps per Second: 22,606.48986
Overall Steps per Second: 10,639.16332

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.70056

Cumulative Model Updates: 229,248
Cumulative Timesteps: 1,912,000,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.35968
Policy Entropy: 2.26880
Value Function Loss: 0.01830

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.68205

Collected Steps per Second: 23,490.52766
Overall Steps per Second: 10,790.59523

Timestep Collection Time: 2.12928
Timestep Consumption Time: 2.50605
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.63533

Cumulative Model Updates: 229,254
Cumulative Timesteps: 1,912,050,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1912050826...
Checkpoint 1912050826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.23277
Policy Entropy: 2.29859
Value Function Loss: 0.01692

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.66677

Collected Steps per Second: 22,057.34513
Overall Steps per Second: 10,333.91817

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.57234
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.83979

Cumulative Model Updates: 229,260
Cumulative Timesteps: 1,912,100,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.84457
Policy Entropy: 2.26646
Value Function Loss: 0.01669

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.64765

Collected Steps per Second: 22,592.78269
Overall Steps per Second: 10,541.09870

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.53095
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.74467

Cumulative Model Updates: 229,266
Cumulative Timesteps: 1,912,150,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1912150854...
Checkpoint 1912150854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.85604
Policy Entropy: 2.28466
Value Function Loss: 0.01646

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 22,637.09478
Overall Steps per Second: 10,576.91281

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.51871
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.72766

Cumulative Model Updates: 229,272
Cumulative Timesteps: 1,912,200,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.49988
Policy Entropy: 2.28639
Value Function Loss: 0.01639

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 22,903.82577
Overall Steps per Second: 10,693.52461

Timestep Collection Time: 2.18383
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.67741

Cumulative Model Updates: 229,278
Cumulative Timesteps: 1,912,250,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1912250876...
Checkpoint 1912250876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.26877
Policy Entropy: 2.29956
Value Function Loss: 0.01591

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.52947
Value Function Update Magnitude: 0.61172

Collected Steps per Second: 22,117.74708
Overall Steps per Second: 10,375.33161

Timestep Collection Time: 2.26108
Timestep Consumption Time: 2.55901
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.82009

Cumulative Model Updates: 229,284
Cumulative Timesteps: 1,912,300,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.67575
Policy Entropy: 2.27808
Value Function Loss: 0.01606

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.52801
Value Function Update Magnitude: 0.60214

Collected Steps per Second: 22,429.86061
Overall Steps per Second: 10,428.72505

Timestep Collection Time: 2.23006
Timestep Consumption Time: 2.56630
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.79637

Cumulative Model Updates: 229,290
Cumulative Timesteps: 1,912,350,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1912350906...
Checkpoint 1912350906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.72504
Policy Entropy: 2.24206
Value Function Loss: 0.01620

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 22,620.97847
Overall Steps per Second: 10,568.86487

Timestep Collection Time: 2.21078
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.73182

Cumulative Model Updates: 229,296
Cumulative Timesteps: 1,912,400,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.46597
Policy Entropy: 2.22034
Value Function Loss: 0.01768

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.62731

Collected Steps per Second: 23,433.31614
Overall Steps per Second: 10,824.16887

Timestep Collection Time: 2.13525
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.62262

Cumulative Model Updates: 229,302
Cumulative Timesteps: 1,912,450,952

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1912450952...
Checkpoint 1912450952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.93567
Policy Entropy: 2.22744
Value Function Loss: 0.01754

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.64050

Collected Steps per Second: 22,102.46066
Overall Steps per Second: 10,537.38493

Timestep Collection Time: 2.26264
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.74596

Cumulative Model Updates: 229,308
Cumulative Timesteps: 1,912,500,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.30241
Policy Entropy: 2.22629
Value Function Loss: 0.01793

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.63587

Collected Steps per Second: 22,693.25451
Overall Steps per Second: 10,580.12631

Timestep Collection Time: 2.20330
Timestep Consumption Time: 2.52254
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.72584

Cumulative Model Updates: 229,314
Cumulative Timesteps: 1,912,550,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1912550962...
Checkpoint 1912550962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.10005
Policy Entropy: 2.26785
Value Function Loss: 0.01612

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.54461
Value Function Update Magnitude: 0.63129

Collected Steps per Second: 22,593.52515
Overall Steps per Second: 10,627.79332

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.70728

Cumulative Model Updates: 229,320
Cumulative Timesteps: 1,912,600,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.65063
Policy Entropy: 2.28117
Value Function Loss: 0.01608

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.62742

Collected Steps per Second: 22,421.78607
Overall Steps per Second: 10,731.01976

Timestep Collection Time: 2.23006
Timestep Consumption Time: 2.42951
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.65958

Cumulative Model Updates: 229,326
Cumulative Timesteps: 1,912,650,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1912650992...
Checkpoint 1912650992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.43467
Policy Entropy: 2.31761
Value Function Loss: 0.01520

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.53317
Value Function Update Magnitude: 0.62496

Collected Steps per Second: 22,367.96442
Overall Steps per Second: 10,375.17235

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.58499
PPO Batch Consumption Time: 0.30392
Total Iteration Time: 4.82132

Cumulative Model Updates: 229,332
Cumulative Timesteps: 1,912,701,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.06877
Policy Entropy: 2.29585
Value Function Loss: 0.01649

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.52570
Value Function Update Magnitude: 0.60404

Collected Steps per Second: 22,392.53704
Overall Steps per Second: 10,429.27620

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.56274
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.79688

Cumulative Model Updates: 229,338
Cumulative Timesteps: 1,912,751,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1912751042...
Checkpoint 1912751042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.80592
Policy Entropy: 2.29359
Value Function Loss: 0.01658

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.52594
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 21,451.75579
Overall Steps per Second: 10,566.49439

Timestep Collection Time: 2.33184
Timestep Consumption Time: 2.40218
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.73402

Cumulative Model Updates: 229,344
Cumulative Timesteps: 1,912,801,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.88028
Policy Entropy: 2.25415
Value Function Loss: 0.01686

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.53242
Value Function Update Magnitude: 0.59996

Collected Steps per Second: 22,433.67763
Overall Steps per Second: 10,573.86666

Timestep Collection Time: 2.22906
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.72921

Cumulative Model Updates: 229,350
Cumulative Timesteps: 1,912,851,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1912851070...
Checkpoint 1912851070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.96262
Policy Entropy: 2.26782
Value Function Loss: 0.01579

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.53317
Value Function Update Magnitude: 0.62075

Collected Steps per Second: 20,897.09696
Overall Steps per Second: 10,200.11631

Timestep Collection Time: 2.39344
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.90347

Cumulative Model Updates: 229,356
Cumulative Timesteps: 1,912,901,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.87025
Policy Entropy: 2.25830
Value Function Loss: 0.01633

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.61464

Collected Steps per Second: 21,828.64193
Overall Steps per Second: 10,431.81686

Timestep Collection Time: 2.29130
Timestep Consumption Time: 2.50326
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.79456

Cumulative Model Updates: 229,362
Cumulative Timesteps: 1,912,951,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1912951102...
Checkpoint 1912951102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.98221
Policy Entropy: 2.29026
Value Function Loss: 0.01639

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.54127
Value Function Update Magnitude: 0.58898

Collected Steps per Second: 20,155.13205
Overall Steps per Second: 10,179.02878

Timestep Collection Time: 2.48125
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.91304

Cumulative Model Updates: 229,368
Cumulative Timesteps: 1,913,001,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.79260
Policy Entropy: 2.27286
Value Function Loss: 0.01699

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12512
Policy Update Magnitude: 0.54187
Value Function Update Magnitude: 0.58216

Collected Steps per Second: 21,831.81721
Overall Steps per Second: 10,314.31581

Timestep Collection Time: 2.29051
Timestep Consumption Time: 2.55770
PPO Batch Consumption Time: 0.30281
Total Iteration Time: 4.84821

Cumulative Model Updates: 229,374
Cumulative Timesteps: 1,913,051,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1913051118...
Checkpoint 1913051118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.84181
Policy Entropy: 2.26852
Value Function Loss: 0.01701

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.60757

Collected Steps per Second: 21,958.15211
Overall Steps per Second: 10,317.78642

Timestep Collection Time: 2.27779
Timestep Consumption Time: 2.56976
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.84755

Cumulative Model Updates: 229,380
Cumulative Timesteps: 1,913,101,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.49460
Policy Entropy: 2.25303
Value Function Loss: 0.01735

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.63041

Collected Steps per Second: 22,888.28906
Overall Steps per Second: 10,654.87165

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.50957
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.69532

Cumulative Model Updates: 229,386
Cumulative Timesteps: 1,913,151,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1913151162...
Checkpoint 1913151162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.96000
Policy Entropy: 2.26708
Value Function Loss: 0.01755

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.63532

Collected Steps per Second: 21,931.04678
Overall Steps per Second: 10,491.23475

Timestep Collection Time: 2.28051
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.76722

Cumulative Model Updates: 229,392
Cumulative Timesteps: 1,913,201,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.15278
Policy Entropy: 2.26110
Value Function Loss: 0.01804

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.53717
Value Function Update Magnitude: 0.63243

Collected Steps per Second: 22,451.36353
Overall Steps per Second: 10,200.05624

Timestep Collection Time: 2.22766
Timestep Consumption Time: 2.67565
PPO Batch Consumption Time: 0.31402
Total Iteration Time: 4.90331

Cumulative Model Updates: 229,398
Cumulative Timesteps: 1,913,251,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1913251190...
Checkpoint 1913251190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.63967
Policy Entropy: 2.25641
Value Function Loss: 0.01806

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.62442

Collected Steps per Second: 22,443.89912
Overall Steps per Second: 10,480.40170

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.54303
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.77081

Cumulative Model Updates: 229,404
Cumulative Timesteps: 1,913,301,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.00661
Policy Entropy: 2.26073
Value Function Loss: 0.01724

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.53873
Value Function Update Magnitude: 0.61950

Collected Steps per Second: 20,704.60978
Overall Steps per Second: 10,383.57826

Timestep Collection Time: 2.41637
Timestep Consumption Time: 2.40181
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.81818

Cumulative Model Updates: 229,410
Cumulative Timesteps: 1,913,351,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1913351220...
Checkpoint 1913351220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.74176
Policy Entropy: 2.25344
Value Function Loss: 0.01666

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.53484
Value Function Update Magnitude: 0.60998

Collected Steps per Second: 22,080.74425
Overall Steps per Second: 10,740.48642

Timestep Collection Time: 2.26568
Timestep Consumption Time: 2.39221
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.65789

Cumulative Model Updates: 229,416
Cumulative Timesteps: 1,913,401,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.84883
Policy Entropy: 2.23207
Value Function Loss: 0.01665

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.61085

Collected Steps per Second: 22,619.85310
Overall Steps per Second: 10,659.73346

Timestep Collection Time: 2.21045
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.69055

Cumulative Model Updates: 229,422
Cumulative Timesteps: 1,913,451,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1913451248...
Checkpoint 1913451248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.59584
Policy Entropy: 2.23088
Value Function Loss: 0.01705

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.52892
Value Function Update Magnitude: 0.61732

Collected Steps per Second: 22,491.29255
Overall Steps per Second: 10,424.86916

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.57468
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.79910

Cumulative Model Updates: 229,428
Cumulative Timesteps: 1,913,501,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.46850
Policy Entropy: 2.24632
Value Function Loss: 0.01663

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 22,001.12424
Overall Steps per Second: 10,425.51406

Timestep Collection Time: 2.27388
Timestep Consumption Time: 2.52473
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.79861

Cumulative Model Updates: 229,434
Cumulative Timesteps: 1,913,551,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1913551306...
Checkpoint 1913551306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.39421
Policy Entropy: 2.23787
Value Function Loss: 0.01777

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.62080

Collected Steps per Second: 22,548.72662
Overall Steps per Second: 10,615.80454

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.71090

Cumulative Model Updates: 229,440
Cumulative Timesteps: 1,913,601,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.84436
Policy Entropy: 2.22383
Value Function Loss: 0.01757

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.64120

Collected Steps per Second: 21,238.36002
Overall Steps per Second: 10,174.47158

Timestep Collection Time: 2.35527
Timestep Consumption Time: 2.56116
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 4.91642

Cumulative Model Updates: 229,446
Cumulative Timesteps: 1,913,651,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1913651338...
Checkpoint 1913651338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.52678
Policy Entropy: 2.19993
Value Function Loss: 0.01840

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.56104
Value Function Update Magnitude: 0.67873

Collected Steps per Second: 21,656.12168
Overall Steps per Second: 10,531.81540

Timestep Collection Time: 2.30919
Timestep Consumption Time: 2.43909
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.74828

Cumulative Model Updates: 229,452
Cumulative Timesteps: 1,913,701,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.26815
Policy Entropy: 2.21655
Value Function Loss: 0.01851

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.67306

Collected Steps per Second: 21,991.73170
Overall Steps per Second: 10,492.06906

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.49202
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.76569

Cumulative Model Updates: 229,458
Cumulative Timesteps: 1,913,751,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1913751348...
Checkpoint 1913751348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.60818
Policy Entropy: 2.23753
Value Function Loss: 0.01782

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.64870

Collected Steps per Second: 21,799.51966
Overall Steps per Second: 10,268.19078

Timestep Collection Time: 2.29400
Timestep Consumption Time: 2.57619
PPO Batch Consumption Time: 0.30131
Total Iteration Time: 4.87019

Cumulative Model Updates: 229,464
Cumulative Timesteps: 1,913,801,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.29104
Policy Entropy: 2.25154
Value Function Loss: 0.01669

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.60948

Collected Steps per Second: 22,470.98632
Overall Steps per Second: 10,444.51698

Timestep Collection Time: 2.22580
Timestep Consumption Time: 2.56293
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.78873

Cumulative Model Updates: 229,470
Cumulative Timesteps: 1,913,851,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1913851372...
Checkpoint 1913851372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.11954
Policy Entropy: 2.25301
Value Function Loss: 0.01665

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.52852
Value Function Update Magnitude: 0.58031

Collected Steps per Second: 21,796.79401
Overall Steps per Second: 10,533.82862

Timestep Collection Time: 2.29483
Timestep Consumption Time: 2.45368
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.74851

Cumulative Model Updates: 229,476
Cumulative Timesteps: 1,913,901,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.74484
Policy Entropy: 2.24715
Value Function Loss: 0.01569

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.52603
Value Function Update Magnitude: 0.57642

Collected Steps per Second: 22,489.40395
Overall Steps per Second: 10,701.38546

Timestep Collection Time: 2.22345
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.67267

Cumulative Model Updates: 229,482
Cumulative Timesteps: 1,913,951,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1913951396...
Checkpoint 1913951396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.03837
Policy Entropy: 2.24031
Value Function Loss: 0.01691

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.53436
Value Function Update Magnitude: 0.57695

Collected Steps per Second: 22,733.39609
Overall Steps per Second: 10,442.99668

Timestep Collection Time: 2.19985
Timestep Consumption Time: 2.58901
PPO Batch Consumption Time: 0.30107
Total Iteration Time: 4.78886

Cumulative Model Updates: 229,488
Cumulative Timesteps: 1,914,001,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.27553
Policy Entropy: 2.25230
Value Function Loss: 0.01695

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.53931
Value Function Update Magnitude: 0.62171

Collected Steps per Second: 22,542.60927
Overall Steps per Second: 10,741.45114

Timestep Collection Time: 2.21864
Timestep Consumption Time: 2.43752
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.65617

Cumulative Model Updates: 229,494
Cumulative Timesteps: 1,914,051,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1914051420...
Checkpoint 1914051420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.89179
Policy Entropy: 2.26443
Value Function Loss: 0.01757

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.64045

Collected Steps per Second: 21,648.94922
Overall Steps per Second: 10,357.30786

Timestep Collection Time: 2.31023
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.82886

Cumulative Model Updates: 229,500
Cumulative Timesteps: 1,914,101,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.81237
Policy Entropy: 2.26699
Value Function Loss: 0.01677

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.61827

Collected Steps per Second: 22,781.47944
Overall Steps per Second: 10,893.68393

Timestep Collection Time: 2.19547
Timestep Consumption Time: 2.39582
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.59128

Cumulative Model Updates: 229,506
Cumulative Timesteps: 1,914,151,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1914151450...
Checkpoint 1914151450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.39024
Policy Entropy: 2.23253
Value Function Loss: 0.01585

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.60179

Collected Steps per Second: 22,578.72787
Overall Steps per Second: 10,645.34339

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.48261
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.69727

Cumulative Model Updates: 229,512
Cumulative Timesteps: 1,914,201,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.47854
Policy Entropy: 2.21239
Value Function Loss: 0.01536

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.52942
Value Function Update Magnitude: 0.58815

Collected Steps per Second: 22,410.65749
Overall Steps per Second: 10,500.03218

Timestep Collection Time: 2.23242
Timestep Consumption Time: 2.53233
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.76475

Cumulative Model Updates: 229,518
Cumulative Timesteps: 1,914,251,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1914251484...
Checkpoint 1914251484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.81096
Policy Entropy: 2.22899
Value Function Loss: 0.01586

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.53426
Value Function Update Magnitude: 0.58899

Collected Steps per Second: 21,929.98132
Overall Steps per Second: 10,511.26496

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.47721
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.75756

Cumulative Model Updates: 229,524
Cumulative Timesteps: 1,914,301,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.70355
Policy Entropy: 2.21884
Value Function Loss: 0.01712

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.61423

Collected Steps per Second: 22,902.97235
Overall Steps per Second: 10,799.65214

Timestep Collection Time: 2.18365
Timestep Consumption Time: 2.44724
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.63089

Cumulative Model Updates: 229,530
Cumulative Timesteps: 1,914,351,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1914351504...
Checkpoint 1914351504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.34949
Policy Entropy: 2.21502
Value Function Loss: 0.01842

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.55469
Value Function Update Magnitude: 0.64265

Collected Steps per Second: 22,826.06324
Overall Steps per Second: 10,615.71463

Timestep Collection Time: 2.19109
Timestep Consumption Time: 2.52023
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.71132

Cumulative Model Updates: 229,536
Cumulative Timesteps: 1,914,401,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.97171
Policy Entropy: 2.19342
Value Function Loss: 0.01853

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.65187

Collected Steps per Second: 22,933.34458
Overall Steps per Second: 10,735.24588

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.65979

Cumulative Model Updates: 229,542
Cumulative Timesteps: 1,914,451,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1914451542...
Checkpoint 1914451542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.14668
Policy Entropy: 2.22562
Value Function Loss: 0.01674

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.62787

Collected Steps per Second: 21,696.41708
Overall Steps per Second: 10,402.24351

Timestep Collection Time: 2.30536
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.80839

Cumulative Model Updates: 229,548
Cumulative Timesteps: 1,914,501,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.29891
Policy Entropy: 2.22568
Value Function Loss: 0.01639

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.59600

Collected Steps per Second: 22,772.79307
Overall Steps per Second: 10,767.61679

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.44942
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.64634

Cumulative Model Updates: 229,554
Cumulative Timesteps: 1,914,551,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1914551590...
Checkpoint 1914551590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.33537
Policy Entropy: 2.23779
Value Function Loss: 0.01636

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.53698
Value Function Update Magnitude: 0.59434

Collected Steps per Second: 22,053.73537
Overall Steps per Second: 10,345.16556

Timestep Collection Time: 2.26810
Timestep Consumption Time: 2.56701
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.83511

Cumulative Model Updates: 229,560
Cumulative Timesteps: 1,914,601,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.66465
Policy Entropy: 2.24192
Value Function Loss: 0.01719

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.59131

Collected Steps per Second: 23,010.48635
Overall Steps per Second: 10,756.75155

Timestep Collection Time: 2.17423
Timestep Consumption Time: 2.47681
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.65103

Cumulative Model Updates: 229,566
Cumulative Timesteps: 1,914,651,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1914651640...
Checkpoint 1914651640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.63650
Policy Entropy: 2.25432
Value Function Loss: 0.01717

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.59782

Collected Steps per Second: 21,735.33235
Overall Steps per Second: 10,413.04228

Timestep Collection Time: 2.30151
Timestep Consumption Time: 2.50247
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.80398

Cumulative Model Updates: 229,572
Cumulative Timesteps: 1,914,701,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.99433
Policy Entropy: 2.25332
Value Function Loss: 0.01792

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.63602

Collected Steps per Second: 22,887.50983
Overall Steps per Second: 10,694.16983

Timestep Collection Time: 2.18591
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 4.67825

Cumulative Model Updates: 229,578
Cumulative Timesteps: 1,914,751,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1914751694...
Checkpoint 1914751694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.81417
Policy Entropy: 2.23660
Value Function Loss: 0.01692

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.15577
Policy Update Magnitude: 0.53197
Value Function Update Magnitude: 0.64189

Collected Steps per Second: 20,791.46366
Overall Steps per Second: 10,219.52062

Timestep Collection Time: 2.40483
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.89260

Cumulative Model Updates: 229,584
Cumulative Timesteps: 1,914,801,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.74211
Policy Entropy: 2.21553
Value Function Loss: 0.01763

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.51971
Value Function Update Magnitude: 0.61328

Collected Steps per Second: 20,708.52411
Overall Steps per Second: 9,915.71543

Timestep Collection Time: 2.41572
Timestep Consumption Time: 2.62940
PPO Batch Consumption Time: 0.30871
Total Iteration Time: 5.04512

Cumulative Model Updates: 229,590
Cumulative Timesteps: 1,914,851,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1914851720...
Checkpoint 1914851720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.35882
Policy Entropy: 2.23140
Value Function Loss: 0.01689

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.15942
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.61340

Collected Steps per Second: 20,475.03539
Overall Steps per Second: 9,993.66447

Timestep Collection Time: 2.44356
Timestep Consumption Time: 2.56281
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 5.00637

Cumulative Model Updates: 229,596
Cumulative Timesteps: 1,914,901,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.63941
Policy Entropy: 2.22322
Value Function Loss: 0.01809

Mean KL Divergence: 0.02523
SB3 Clip Fraction: 0.16401
Policy Update Magnitude: 0.56417
Value Function Update Magnitude: 0.61680

Collected Steps per Second: 22,067.15154
Overall Steps per Second: 10,746.89918

Timestep Collection Time: 2.26654
Timestep Consumption Time: 2.38746
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.65399

Cumulative Model Updates: 229,602
Cumulative Timesteps: 1,914,951,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1914951768...
Checkpoint 1914951768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.53660
Policy Entropy: 2.23213
Value Function Loss: 0.01895

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.15616
Policy Update Magnitude: 0.57160
Value Function Update Magnitude: 0.60791

Collected Steps per Second: 21,695.62808
Overall Steps per Second: 10,354.29709

Timestep Collection Time: 2.30507
Timestep Consumption Time: 2.52481
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.82988

Cumulative Model Updates: 229,608
Cumulative Timesteps: 1,915,001,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.65609
Policy Entropy: 2.22720
Value Function Loss: 0.01874

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.57097
Value Function Update Magnitude: 0.60709

Collected Steps per Second: 22,166.63719
Overall Steps per Second: 10,390.09759

Timestep Collection Time: 2.25600
Timestep Consumption Time: 2.55704
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.81304

Cumulative Model Updates: 229,614
Cumulative Timesteps: 1,915,051,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1915051786...
Checkpoint 1915051786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.41121
Policy Entropy: 2.23318
Value Function Loss: 0.01803

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.55588
Value Function Update Magnitude: 0.61097

Collected Steps per Second: 21,370.57943
Overall Steps per Second: 10,184.21914

Timestep Collection Time: 2.34004
Timestep Consumption Time: 2.57030
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 4.91034

Cumulative Model Updates: 229,620
Cumulative Timesteps: 1,915,101,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.35687
Policy Entropy: 2.23800
Value Function Loss: 0.01710

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.59682

Collected Steps per Second: 22,864.27195
Overall Steps per Second: 10,937.42215

Timestep Collection Time: 2.18726
Timestep Consumption Time: 2.38512
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.57238

Cumulative Model Updates: 229,626
Cumulative Timesteps: 1,915,151,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1915151804...
Checkpoint 1915151804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.83850
Policy Entropy: 2.22309
Value Function Loss: 0.01612

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.53533
Value Function Update Magnitude: 0.57643

Collected Steps per Second: 22,685.44874
Overall Steps per Second: 10,518.42178

Timestep Collection Time: 2.20458
Timestep Consumption Time: 2.55012
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.75471

Cumulative Model Updates: 229,632
Cumulative Timesteps: 1,915,201,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.44102
Policy Entropy: 2.25084
Value Function Loss: 0.01500

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.52493
Value Function Update Magnitude: 0.54739

Collected Steps per Second: 22,218.79403
Overall Steps per Second: 10,476.62088

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.52249
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.77310

Cumulative Model Updates: 229,638
Cumulative Timesteps: 1,915,251,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1915251822...
Checkpoint 1915251822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.12450
Policy Entropy: 2.22954
Value Function Loss: 0.01664

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.52353
Value Function Update Magnitude: 0.54541

Collected Steps per Second: 22,204.47746
Overall Steps per Second: 10,551.19134

Timestep Collection Time: 2.25306
Timestep Consumption Time: 2.48840
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.74146

Cumulative Model Updates: 229,644
Cumulative Timesteps: 1,915,301,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.35986
Policy Entropy: 2.24953
Value Function Loss: 0.01687

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.57719

Collected Steps per Second: 23,790.91879
Overall Steps per Second: 10,852.00825

Timestep Collection Time: 2.10274
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.60984

Cumulative Model Updates: 229,650
Cumulative Timesteps: 1,915,351,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1915351876...
Checkpoint 1915351876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.81722
Policy Entropy: 2.24319
Value Function Loss: 0.01741

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 22,748.86862
Overall Steps per Second: 10,625.02003

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.50917
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.70813

Cumulative Model Updates: 229,656
Cumulative Timesteps: 1,915,401,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.46279
Policy Entropy: 2.26313
Value Function Loss: 0.01715

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.53996
Value Function Update Magnitude: 0.58404

Collected Steps per Second: 22,787.31815
Overall Steps per Second: 10,732.47190

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.66062

Cumulative Model Updates: 229,662
Cumulative Timesteps: 1,915,451,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1915451920...
Checkpoint 1915451920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.26573
Policy Entropy: 2.23510
Value Function Loss: 0.01855

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.58745

Collected Steps per Second: 22,342.64570
Overall Steps per Second: 10,556.26501

Timestep Collection Time: 2.23823
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 4.73728

Cumulative Model Updates: 229,668
Cumulative Timesteps: 1,915,501,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.26561
Policy Entropy: 2.21841
Value Function Loss: 0.01840

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.59701

Collected Steps per Second: 22,319.15164
Overall Steps per Second: 10,497.85453

Timestep Collection Time: 2.24104
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.76459

Cumulative Model Updates: 229,674
Cumulative Timesteps: 1,915,551,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1915551946...
Checkpoint 1915551946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.41651
Policy Entropy: 2.21014
Value Function Loss: 0.01716

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 21,271.46467
Overall Steps per Second: 10,078.15325

Timestep Collection Time: 2.35113
Timestep Consumption Time: 2.61129
PPO Batch Consumption Time: 0.30802
Total Iteration Time: 4.96242

Cumulative Model Updates: 229,680
Cumulative Timesteps: 1,915,601,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.69512
Policy Entropy: 2.22081
Value Function Loss: 0.01655

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.54390
Value Function Update Magnitude: 0.59729

Collected Steps per Second: 22,164.33342
Overall Steps per Second: 10,428.61047

Timestep Collection Time: 2.25678
Timestep Consumption Time: 2.53964
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.79642

Cumulative Model Updates: 229,686
Cumulative Timesteps: 1,915,651,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1915651978...
Checkpoint 1915651978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.87065
Policy Entropy: 2.21131
Value Function Loss: 0.01748

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.55037
Value Function Update Magnitude: 0.60284

Collected Steps per Second: 20,451.30828
Overall Steps per Second: 10,316.19552

Timestep Collection Time: 2.44581
Timestep Consumption Time: 2.40288
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.84869

Cumulative Model Updates: 229,692
Cumulative Timesteps: 1,915,701,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.87672
Policy Entropy: 2.21818
Value Function Loss: 0.01682

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.60789

Collected Steps per Second: 22,627.70117
Overall Steps per Second: 10,514.43263

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.54681
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.75746

Cumulative Model Updates: 229,698
Cumulative Timesteps: 1,915,752,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1915752020...
Checkpoint 1915752020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.40348
Policy Entropy: 2.21714
Value Function Loss: 0.01774

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.60725

Collected Steps per Second: 22,342.04509
Overall Steps per Second: 10,612.04908

Timestep Collection Time: 2.23793
Timestep Consumption Time: 2.47369
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.71163

Cumulative Model Updates: 229,704
Cumulative Timesteps: 1,915,802,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.75404
Policy Entropy: 2.22441
Value Function Loss: 0.01694

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.60128

Collected Steps per Second: 22,648.03732
Overall Steps per Second: 10,621.76707

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.70920

Cumulative Model Updates: 229,710
Cumulative Timesteps: 1,915,852,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1915852040...
Checkpoint 1915852040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.19412
Policy Entropy: 2.19697
Value Function Loss: 0.01843

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.54160
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 22,291.72703
Overall Steps per Second: 10,571.78153

Timestep Collection Time: 2.24307
Timestep Consumption Time: 2.48669
PPO Batch Consumption Time: 0.30087
Total Iteration Time: 4.72976

Cumulative Model Updates: 229,716
Cumulative Timesteps: 1,915,902,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.22327
Policy Entropy: 2.21989
Value Function Loss: 0.01703

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.61773

Collected Steps per Second: 23,014.33471
Overall Steps per Second: 10,707.67243

Timestep Collection Time: 2.17256
Timestep Consumption Time: 2.49699
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.66955

Cumulative Model Updates: 229,722
Cumulative Timesteps: 1,915,952,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1915952042...
Checkpoint 1915952042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.40131
Policy Entropy: 2.23986
Value Function Loss: 0.01671

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.60523

Collected Steps per Second: 21,900.98136
Overall Steps per Second: 10,360.32136

Timestep Collection Time: 2.28337
Timestep Consumption Time: 2.54351
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.82688

Cumulative Model Updates: 229,728
Cumulative Timesteps: 1,916,002,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.85330
Policy Entropy: 2.23733
Value Function Loss: 0.01648

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.16968
Policy Update Magnitude: 0.50729
Value Function Update Magnitude: 0.61355

Collected Steps per Second: 22,755.42544
Overall Steps per Second: 10,769.16280

Timestep Collection Time: 2.19816
Timestep Consumption Time: 2.44659
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.64474

Cumulative Model Updates: 229,734
Cumulative Timesteps: 1,916,052,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1916052070...
Checkpoint 1916052070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.50965
Policy Entropy: 2.23010
Value Function Loss: 0.01813

Mean KL Divergence: 0.03053
SB3 Clip Fraction: 0.17631
Policy Update Magnitude: 0.50478
Value Function Update Magnitude: 0.62325

Collected Steps per Second: 22,471.61425
Overall Steps per Second: 10,754.48717

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.65015

Cumulative Model Updates: 229,740
Cumulative Timesteps: 1,916,102,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.05745
Policy Entropy: 2.22045
Value Function Loss: 0.01826

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.16758
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.65561

Collected Steps per Second: 23,071.43230
Overall Steps per Second: 10,800.04016

Timestep Collection Time: 2.16727
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.62980

Cumulative Model Updates: 229,746
Cumulative Timesteps: 1,916,152,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1916152082...
Checkpoint 1916152082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.39205
Policy Entropy: 2.22480
Value Function Loss: 0.01866

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.16937
Policy Update Magnitude: 0.54503
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,207.37133
Overall Steps per Second: 10,486.72334

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.51733
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.76965

Cumulative Model Updates: 229,752
Cumulative Timesteps: 1,916,202,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.20919
Policy Entropy: 2.22557
Value Function Loss: 0.01840

Mean KL Divergence: 0.02684
SB3 Clip Fraction: 0.16770
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.61910

Collected Steps per Second: 22,821.12852
Overall Steps per Second: 10,724.06735

Timestep Collection Time: 2.19113
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.66278

Cumulative Model Updates: 229,758
Cumulative Timesteps: 1,916,252,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1916252104...
Checkpoint 1916252104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.88924
Policy Entropy: 2.21372
Value Function Loss: 0.01879

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.16415
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.59868

Collected Steps per Second: 22,308.52765
Overall Steps per Second: 10,617.68770

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.46881
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.71101

Cumulative Model Updates: 229,764
Cumulative Timesteps: 1,916,302,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.44984
Policy Entropy: 2.23694
Value Function Loss: 0.01756

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.56170
Value Function Update Magnitude: 0.61662

Collected Steps per Second: 23,013.07161
Overall Steps per Second: 10,671.59417

Timestep Collection Time: 2.17337
Timestep Consumption Time: 2.51346
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.68683

Cumulative Model Updates: 229,770
Cumulative Timesteps: 1,916,352,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1916352140...
Checkpoint 1916352140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.80622
Policy Entropy: 2.22154
Value Function Loss: 0.01735

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.55639
Value Function Update Magnitude: 0.61929

Collected Steps per Second: 22,304.01888
Overall Steps per Second: 10,443.55854

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.54711
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.78994

Cumulative Model Updates: 229,776
Cumulative Timesteps: 1,916,402,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.67131
Policy Entropy: 2.23324
Value Function Loss: 0.01863

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.55348
Value Function Update Magnitude: 0.61531

Collected Steps per Second: 22,620.18551
Overall Steps per Second: 10,569.17646

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.52083
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.73168

Cumulative Model Updates: 229,782
Cumulative Timesteps: 1,916,452,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1916452174...
Checkpoint 1916452174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.73087
Policy Entropy: 2.24732
Value Function Loss: 0.01907

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.55493
Value Function Update Magnitude: 0.62453

Collected Steps per Second: 23,323.90012
Overall Steps per Second: 10,716.70722

Timestep Collection Time: 2.14441
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.66711

Cumulative Model Updates: 229,788
Cumulative Timesteps: 1,916,502,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.00357
Policy Entropy: 2.22310
Value Function Loss: 0.01854

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.63135

Collected Steps per Second: 22,912.11350
Overall Steps per Second: 10,754.93576

Timestep Collection Time: 2.18278
Timestep Consumption Time: 2.46737
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.65014

Cumulative Model Updates: 229,794
Cumulative Timesteps: 1,916,552,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1916552202...
Checkpoint 1916552202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.85630
Policy Entropy: 2.21713
Value Function Loss: 0.01789

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.56435
Value Function Update Magnitude: 0.63048

Collected Steps per Second: 22,027.93802
Overall Steps per Second: 10,533.93848

Timestep Collection Time: 2.27093
Timestep Consumption Time: 2.47791
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.74884

Cumulative Model Updates: 229,800
Cumulative Timesteps: 1,916,602,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.31187
Policy Entropy: 2.19093
Value Function Loss: 0.01773

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.63655

Collected Steps per Second: 22,610.53563
Overall Steps per Second: 10,529.06433

Timestep Collection Time: 2.21251
Timestep Consumption Time: 2.53872
PPO Batch Consumption Time: 0.29991
Total Iteration Time: 4.75123

Cumulative Model Updates: 229,806
Cumulative Timesteps: 1,916,652,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1916652252...
Checkpoint 1916652252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.07498
Policy Entropy: 2.19138
Value Function Loss: 0.01824

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.64754

Collected Steps per Second: 20,754.87207
Overall Steps per Second: 10,022.23276

Timestep Collection Time: 2.41013
Timestep Consumption Time: 2.58097
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.99110

Cumulative Model Updates: 229,812
Cumulative Timesteps: 1,916,702,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.36445
Policy Entropy: 2.19428
Value Function Loss: 0.01909

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.64399

Collected Steps per Second: 22,634.99752
Overall Steps per Second: 10,614.61669

Timestep Collection Time: 2.20994
Timestep Consumption Time: 2.50262
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.71256

Cumulative Model Updates: 229,818
Cumulative Timesteps: 1,916,752,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1916752296...
Checkpoint 1916752296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.38997
Policy Entropy: 2.19937
Value Function Loss: 0.01883

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.64941

Collected Steps per Second: 21,540.92377
Overall Steps per Second: 10,105.43624

Timestep Collection Time: 2.32172
Timestep Consumption Time: 2.62730
PPO Batch Consumption Time: 0.30681
Total Iteration Time: 4.94902

Cumulative Model Updates: 229,824
Cumulative Timesteps: 1,916,802,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.60862
Policy Entropy: 2.22183
Value Function Loss: 0.01848

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.64750

Collected Steps per Second: 21,675.49514
Overall Steps per Second: 10,239.23829

Timestep Collection Time: 2.30731
Timestep Consumption Time: 2.57704
PPO Batch Consumption Time: 0.30414
Total Iteration Time: 4.88435

Cumulative Model Updates: 229,830
Cumulative Timesteps: 1,916,852,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1916852320...
Checkpoint 1916852320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.84566
Policy Entropy: 2.19904
Value Function Loss: 0.01741

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.55362
Value Function Update Magnitude: 0.64315

Collected Steps per Second: 22,704.18415
Overall Steps per Second: 10,545.89488

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.54037
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.74384

Cumulative Model Updates: 229,836
Cumulative Timesteps: 1,916,902,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.57470
Policy Entropy: 2.18436
Value Function Loss: 0.01832

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.56256
Value Function Update Magnitude: 0.62512

Collected Steps per Second: 23,044.27333
Overall Steps per Second: 10,955.11309

Timestep Collection Time: 2.17104
Timestep Consumption Time: 2.39578
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.56682

Cumulative Model Updates: 229,842
Cumulative Timesteps: 1,916,952,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1916952378...
Checkpoint 1916952378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.92948
Policy Entropy: 2.20401
Value Function Loss: 0.01704

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.55403
Value Function Update Magnitude: 0.62154

Collected Steps per Second: 20,979.60461
Overall Steps per Second: 10,071.10737

Timestep Collection Time: 2.38441
Timestep Consumption Time: 2.58267
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.96708

Cumulative Model Updates: 229,848
Cumulative Timesteps: 1,917,002,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.51606
Policy Entropy: 2.22479
Value Function Loss: 0.01717

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.60077

Collected Steps per Second: 21,636.74145
Overall Steps per Second: 10,280.40622

Timestep Collection Time: 2.31162
Timestep Consumption Time: 2.55355
PPO Batch Consumption Time: 0.30052
Total Iteration Time: 4.86518

Cumulative Model Updates: 229,854
Cumulative Timesteps: 1,917,052,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1917052418...
Checkpoint 1917052418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.64182
Policy Entropy: 2.24797
Value Function Loss: 0.01708

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.51274
Value Function Update Magnitude: 0.58709

Collected Steps per Second: 22,106.73899
Overall Steps per Second: 10,513.75246

Timestep Collection Time: 2.26284
Timestep Consumption Time: 2.49512
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.75796

Cumulative Model Updates: 229,860
Cumulative Timesteps: 1,917,102,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.55589
Policy Entropy: 2.23726
Value Function Loss: 0.01704

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.52495
Value Function Update Magnitude: 0.58876

Collected Steps per Second: 22,465.56525
Overall Steps per Second: 10,465.80839

Timestep Collection Time: 2.22670
Timestep Consumption Time: 2.55306
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.77976

Cumulative Model Updates: 229,866
Cumulative Timesteps: 1,917,152,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1917152466...
Checkpoint 1917152466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.60033
Policy Entropy: 2.22658
Value Function Loss: 0.01747

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.53497
Value Function Update Magnitude: 0.59142

Collected Steps per Second: 21,668.32682
Overall Steps per Second: 10,329.18429

Timestep Collection Time: 2.30752
Timestep Consumption Time: 2.53314
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.84065

Cumulative Model Updates: 229,872
Cumulative Timesteps: 1,917,202,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.05019
Policy Entropy: 2.21951
Value Function Loss: 0.01747

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.58244

Collected Steps per Second: 22,456.33494
Overall Steps per Second: 10,717.19611

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.43964
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.66689

Cumulative Model Updates: 229,878
Cumulative Timesteps: 1,917,252,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1917252482...
Checkpoint 1917252482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.11697
Policy Entropy: 2.19489
Value Function Loss: 0.01770

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12186
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 22,088.04075
Overall Steps per Second: 10,356.89018

Timestep Collection Time: 2.26385
Timestep Consumption Time: 2.56424
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 4.82809

Cumulative Model Updates: 229,884
Cumulative Timesteps: 1,917,302,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.82732
Policy Entropy: 2.18954
Value Function Loss: 0.01862

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.55673
Value Function Update Magnitude: 0.61378

Collected Steps per Second: 22,669.98294
Overall Steps per Second: 10,503.45206

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.55539
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.76148

Cumulative Model Updates: 229,890
Cumulative Timesteps: 1,917,352,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1917352498...
Checkpoint 1917352498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.42161
Policy Entropy: 2.20992
Value Function Loss: 0.01798

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.61526

Collected Steps per Second: 21,865.55586
Overall Steps per Second: 10,573.31210

Timestep Collection Time: 2.28707
Timestep Consumption Time: 2.44258
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.72964

Cumulative Model Updates: 229,896
Cumulative Timesteps: 1,917,402,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.39197
Policy Entropy: 2.23101
Value Function Loss: 0.01750

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.60867

Collected Steps per Second: 22,493.88973
Overall Steps per Second: 10,710.41438

Timestep Collection Time: 2.22371
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.67022

Cumulative Model Updates: 229,902
Cumulative Timesteps: 1,917,452,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1917452526...
Checkpoint 1917452526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.58268
Policy Entropy: 2.25057
Value Function Loss: 0.01714

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.59407

Collected Steps per Second: 21,776.93027
Overall Steps per Second: 10,278.45520

Timestep Collection Time: 2.29619
Timestep Consumption Time: 2.56874
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.86493

Cumulative Model Updates: 229,908
Cumulative Timesteps: 1,917,502,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.47046
Policy Entropy: 2.23021
Value Function Loss: 0.01651

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.58628

Collected Steps per Second: 22,317.02418
Overall Steps per Second: 10,510.88327

Timestep Collection Time: 2.24107
Timestep Consumption Time: 2.51724
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.75831

Cumulative Model Updates: 229,914
Cumulative Timesteps: 1,917,552,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1917552544...
Checkpoint 1917552544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.72275
Policy Entropy: 2.24343
Value Function Loss: 0.01591

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.58530

Collected Steps per Second: 22,074.53281
Overall Steps per Second: 10,528.10911

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.74919

Cumulative Model Updates: 229,920
Cumulative Timesteps: 1,917,602,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.72551
Policy Entropy: 2.22747
Value Function Loss: 0.01692

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.58618

Collected Steps per Second: 21,625.33623
Overall Steps per Second: 10,431.66070

Timestep Collection Time: 2.31257
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.79406

Cumulative Model Updates: 229,926
Cumulative Timesteps: 1,917,652,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1917652554...
Checkpoint 1917652554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.08372
Policy Entropy: 2.21633
Value Function Loss: 0.01735

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.54930
Value Function Update Magnitude: 0.61268

Collected Steps per Second: 21,138.31080
Overall Steps per Second: 10,172.49587

Timestep Collection Time: 2.36670
Timestep Consumption Time: 2.55127
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.91797

Cumulative Model Updates: 229,932
Cumulative Timesteps: 1,917,702,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.97461
Policy Entropy: 2.18686
Value Function Loss: 0.01806

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.62710

Collected Steps per Second: 22,247.87616
Overall Steps per Second: 10,574.30966

Timestep Collection Time: 2.24821
Timestep Consumption Time: 2.48193
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.73014

Cumulative Model Updates: 229,938
Cumulative Timesteps: 1,917,752,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1917752600...
Checkpoint 1917752600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.17299
Policy Entropy: 2.19758
Value Function Loss: 0.01752

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.63006

Collected Steps per Second: 22,295.57302
Overall Steps per Second: 10,668.49382

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.44498
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.68838

Cumulative Model Updates: 229,944
Cumulative Timesteps: 1,917,802,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.99130
Policy Entropy: 2.18016
Value Function Loss: 0.01823

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.63012

Collected Steps per Second: 21,535.53997
Overall Steps per Second: 10,555.93657

Timestep Collection Time: 2.32267
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.73857

Cumulative Model Updates: 229,950
Cumulative Timesteps: 1,917,852,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1917852638...
Checkpoint 1917852638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.40333
Policy Entropy: 2.20203
Value Function Loss: 0.01779

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 21,868.61860
Overall Steps per Second: 10,470.77728

Timestep Collection Time: 2.28775
Timestep Consumption Time: 2.49031
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.77806

Cumulative Model Updates: 229,956
Cumulative Timesteps: 1,917,902,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.96919
Policy Entropy: 2.19237
Value Function Loss: 0.01876

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.55951
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 22,153.06640
Overall Steps per Second: 10,501.64024

Timestep Collection Time: 2.25838
Timestep Consumption Time: 2.50564
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.76402

Cumulative Model Updates: 229,962
Cumulative Timesteps: 1,917,952,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1917952698...
Checkpoint 1917952698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.74310
Policy Entropy: 2.17452
Value Function Loss: 0.01938

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.56342
Value Function Update Magnitude: 0.60360

Collected Steps per Second: 22,055.17356
Overall Steps per Second: 10,507.16546

Timestep Collection Time: 2.26795
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.76056

Cumulative Model Updates: 229,968
Cumulative Timesteps: 1,918,002,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.71985
Policy Entropy: 2.16567
Value Function Loss: 0.01909

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.60890

Collected Steps per Second: 23,821.76394
Overall Steps per Second: 10,777.25739

Timestep Collection Time: 2.09984
Timestep Consumption Time: 2.54160
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.64144

Cumulative Model Updates: 229,974
Cumulative Timesteps: 1,918,052,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1918052740...
Checkpoint 1918052740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.35180
Policy Entropy: 2.17228
Value Function Loss: 0.01826

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.59693

Collected Steps per Second: 22,412.59134
Overall Steps per Second: 10,604.38598

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.71692

Cumulative Model Updates: 229,980
Cumulative Timesteps: 1,918,102,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.20861
Policy Entropy: 2.20713
Value Function Loss: 0.01841

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 22,620.07434
Overall Steps per Second: 10,667.16467

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.68859

Cumulative Model Updates: 229,986
Cumulative Timesteps: 1,918,152,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1918152774...
Checkpoint 1918152774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.88686
Policy Entropy: 2.23261
Value Function Loss: 0.01734

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 22,535.23920
Overall Steps per Second: 10,884.16953

Timestep Collection Time: 2.21884
Timestep Consumption Time: 2.37518
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.59401

Cumulative Model Updates: 229,992
Cumulative Timesteps: 1,918,202,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.77619
Policy Entropy: 2.24206
Value Function Loss: 0.01636

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.60408

Collected Steps per Second: 22,956.54802
Overall Steps per Second: 10,663.69555

Timestep Collection Time: 2.17881
Timestep Consumption Time: 2.51168
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.69049

Cumulative Model Updates: 229,998
Cumulative Timesteps: 1,918,252,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1918252794...
Checkpoint 1918252794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.65062
Policy Entropy: 2.26202
Value Function Loss: 0.01569

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.52532
Value Function Update Magnitude: 0.59832

Collected Steps per Second: 22,537.40940
Overall Steps per Second: 10,525.30447

Timestep Collection Time: 2.21853
Timestep Consumption Time: 2.53192
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.75046

Cumulative Model Updates: 230,004
Cumulative Timesteps: 1,918,302,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.63770
Policy Entropy: 2.22782
Value Function Loss: 0.01534

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.52832
Value Function Update Magnitude: 0.58479

Collected Steps per Second: 22,365.32752
Overall Steps per Second: 10,394.14364

Timestep Collection Time: 2.23560
Timestep Consumption Time: 2.57480
PPO Batch Consumption Time: 0.30520
Total Iteration Time: 4.81040

Cumulative Model Updates: 230,010
Cumulative Timesteps: 1,918,352,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1918352794...
Checkpoint 1918352794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.38749
Policy Entropy: 2.20615
Value Function Loss: 0.01670

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.53901
Value Function Update Magnitude: 0.56700

Collected Steps per Second: 20,802.37556
Overall Steps per Second: 10,192.49081

Timestep Collection Time: 2.40549
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.90950

Cumulative Model Updates: 230,016
Cumulative Timesteps: 1,918,402,834

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.90097
Policy Entropy: 2.16634
Value Function Loss: 0.01789

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.56380

Collected Steps per Second: 18,917.52588
Overall Steps per Second: 9,606.14627

Timestep Collection Time: 2.64326
Timestep Consumption Time: 2.56215
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 5.20542

Cumulative Model Updates: 230,022
Cumulative Timesteps: 1,918,452,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1918452838...
Checkpoint 1918452838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.00970
Policy Entropy: 2.18912
Value Function Loss: 0.01975

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.55972
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 22,002.33575
Overall Steps per Second: 10,318.08043

Timestep Collection Time: 2.27276
Timestep Consumption Time: 2.57369
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.84644

Cumulative Model Updates: 230,028
Cumulative Timesteps: 1,918,502,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.33525
Policy Entropy: 2.20379
Value Function Loss: 0.02003

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 20,063.39284
Overall Steps per Second: 9,717.69592

Timestep Collection Time: 2.49230
Timestep Consumption Time: 2.65336
PPO Batch Consumption Time: 0.30619
Total Iteration Time: 5.14566

Cumulative Model Updates: 230,034
Cumulative Timesteps: 1,918,552,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1918552848...
Checkpoint 1918552848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.99519
Policy Entropy: 2.23703
Value Function Loss: 0.01882

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.63601

Collected Steps per Second: 20,575.92257
Overall Steps per Second: 10,057.77458

Timestep Collection Time: 2.43032
Timestep Consumption Time: 2.54156
PPO Batch Consumption Time: 0.30653
Total Iteration Time: 4.97188

Cumulative Model Updates: 230,040
Cumulative Timesteps: 1,918,602,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.02678
Policy Entropy: 2.23011
Value Function Loss: 0.01896

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.62836

Collected Steps per Second: 20,972.88473
Overall Steps per Second: 9,993.66011

Timestep Collection Time: 2.38489
Timestep Consumption Time: 2.62008
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 5.00497

Cumulative Model Updates: 230,046
Cumulative Timesteps: 1,918,652,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1918652872...
Checkpoint 1918652872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.83441
Policy Entropy: 2.24005
Value Function Loss: 0.01760

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.55372
Value Function Update Magnitude: 0.63741

Collected Steps per Second: 21,416.59007
Overall Steps per Second: 10,213.54459

Timestep Collection Time: 2.33464
Timestep Consumption Time: 2.56082
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.89546

Cumulative Model Updates: 230,052
Cumulative Timesteps: 1,918,702,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.66129
Policy Entropy: 2.24051
Value Function Loss: 0.01800

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.62322

Collected Steps per Second: 21,377.95734
Overall Steps per Second: 10,409.79089

Timestep Collection Time: 2.34007
Timestep Consumption Time: 2.46559
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.80567

Cumulative Model Updates: 230,058
Cumulative Timesteps: 1,918,752,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1918752898...
Checkpoint 1918752898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.60582
Policy Entropy: 2.23476
Value Function Loss: 0.01747

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11847
Policy Update Magnitude: 0.56109
Value Function Update Magnitude: 0.59023

Collected Steps per Second: 21,518.11108
Overall Steps per Second: 10,473.42139

Timestep Collection Time: 2.32418
Timestep Consumption Time: 2.45095
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.77513

Cumulative Model Updates: 230,064
Cumulative Timesteps: 1,918,802,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.47263
Policy Entropy: 2.23352
Value Function Loss: 0.01802

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.58941

Collected Steps per Second: 22,502.86987
Overall Steps per Second: 10,493.47370

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.54435
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.76753

Cumulative Model Updates: 230,070
Cumulative Timesteps: 1,918,852,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1918852938...
Checkpoint 1918852938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.08641
Policy Entropy: 2.22621
Value Function Loss: 0.01742

Mean KL Divergence: 0.02963
SB3 Clip Fraction: 0.16623
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.58732

Collected Steps per Second: 21,639.78240
Overall Steps per Second: 10,327.15554

Timestep Collection Time: 2.31065
Timestep Consumption Time: 2.53115
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.84180

Cumulative Model Updates: 230,076
Cumulative Timesteps: 1,918,902,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.17153
Policy Entropy: 2.21690
Value Function Loss: 0.01809

Mean KL Divergence: 0.02724
SB3 Clip Fraction: 0.16087
Policy Update Magnitude: 0.56367
Value Function Update Magnitude: 0.57624

Collected Steps per Second: 21,344.04949
Overall Steps per Second: 10,241.48959

Timestep Collection Time: 2.34323
Timestep Consumption Time: 2.54024
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.88347

Cumulative Model Updates: 230,082
Cumulative Timesteps: 1,918,952,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1918952954...
Checkpoint 1918952954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.72976
Policy Entropy: 2.18512
Value Function Loss: 0.01876

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.15916
Policy Update Magnitude: 0.57590
Value Function Update Magnitude: 0.57909

Collected Steps per Second: 22,055.93073
Overall Steps per Second: 10,576.57493

Timestep Collection Time: 2.26805
Timestep Consumption Time: 2.46165
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.72970

Cumulative Model Updates: 230,088
Cumulative Timesteps: 1,919,002,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.72348
Policy Entropy: 2.19397
Value Function Loss: 0.01885

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.57064
Value Function Update Magnitude: 0.57262

Collected Steps per Second: 22,306.39111
Overall Steps per Second: 10,276.53427

Timestep Collection Time: 2.24232
Timestep Consumption Time: 2.62489
PPO Batch Consumption Time: 0.30904
Total Iteration Time: 4.86721

Cumulative Model Updates: 230,094
Cumulative Timesteps: 1,919,052,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1919052996...
Checkpoint 1919052996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.14447
Policy Entropy: 2.20224
Value Function Loss: 0.01897

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.57183
Value Function Update Magnitude: 0.57269

Collected Steps per Second: 20,754.93610
Overall Steps per Second: 9,982.55488

Timestep Collection Time: 2.40926
Timestep Consumption Time: 2.59988
PPO Batch Consumption Time: 0.30333
Total Iteration Time: 5.00914

Cumulative Model Updates: 230,100
Cumulative Timesteps: 1,919,103,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.38450
Policy Entropy: 2.21043
Value Function Loss: 0.01891

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.57482
Value Function Update Magnitude: 0.58927

Collected Steps per Second: 21,196.82836
Overall Steps per Second: 10,134.14964

Timestep Collection Time: 2.35979
Timestep Consumption Time: 2.57600
PPO Batch Consumption Time: 0.30077
Total Iteration Time: 4.93579

Cumulative Model Updates: 230,106
Cumulative Timesteps: 1,919,153,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1919153020...
Checkpoint 1919153020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.39648
Policy Entropy: 2.20964
Value Function Loss: 0.01801

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.60070

Collected Steps per Second: 21,721.16262
Overall Steps per Second: 10,438.34604

Timestep Collection Time: 2.30255
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.30118
Total Iteration Time: 4.79137

Cumulative Model Updates: 230,112
Cumulative Timesteps: 1,919,203,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.89571
Policy Entropy: 2.22405
Value Function Loss: 0.01830

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.59910

Collected Steps per Second: 21,787.27637
Overall Steps per Second: 10,473.67417

Timestep Collection Time: 2.29538
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.77483

Cumulative Model Updates: 230,118
Cumulative Timesteps: 1,919,253,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1919253044...
Checkpoint 1919253044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.04010
Policy Entropy: 2.21958
Value Function Loss: 0.01778

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.58163

Collected Steps per Second: 22,317.22168
Overall Steps per Second: 10,572.93685

Timestep Collection Time: 2.24069
Timestep Consumption Time: 2.48893
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.72962

Cumulative Model Updates: 230,124
Cumulative Timesteps: 1,919,303,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.59216
Policy Entropy: 2.22528
Value Function Loss: 0.01792

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.57460

Collected Steps per Second: 22,711.20646
Overall Steps per Second: 10,538.75981

Timestep Collection Time: 2.20253
Timestep Consumption Time: 2.54395
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.74648

Cumulative Model Updates: 230,130
Cumulative Timesteps: 1,919,353,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1919353072...
Checkpoint 1919353072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.65947
Policy Entropy: 2.23544
Value Function Loss: 0.01751

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.58040

Collected Steps per Second: 21,049.24501
Overall Steps per Second: 10,399.66837

Timestep Collection Time: 2.37595
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.80900

Cumulative Model Updates: 230,136
Cumulative Timesteps: 1,919,403,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.07202
Policy Entropy: 2.27470
Value Function Loss: 0.01696

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.55147
Value Function Update Magnitude: 0.58483

Collected Steps per Second: 21,994.64449
Overall Steps per Second: 10,418.15259

Timestep Collection Time: 2.27455
Timestep Consumption Time: 2.52745
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.80200

Cumulative Model Updates: 230,142
Cumulative Timesteps: 1,919,453,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1919453112...
Checkpoint 1919453112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.33693
Policy Entropy: 2.27698
Value Function Loss: 0.01701

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.58394

Collected Steps per Second: 22,194.33898
Overall Steps per Second: 10,461.36672

Timestep Collection Time: 2.25472
Timestep Consumption Time: 2.52879
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.78351

Cumulative Model Updates: 230,148
Cumulative Timesteps: 1,919,503,154

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.02120
Policy Entropy: 2.26574
Value Function Loss: 0.01812

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.53210
Value Function Update Magnitude: 0.58759

Collected Steps per Second: 21,106.56945
Overall Steps per Second: 10,350.00484

Timestep Collection Time: 2.37045
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.83401

Cumulative Model Updates: 230,154
Cumulative Timesteps: 1,919,553,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1919553186...
Checkpoint 1919553186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.48491
Policy Entropy: 2.22425
Value Function Loss: 0.01795

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.60028

Collected Steps per Second: 20,440.28358
Overall Steps per Second: 10,006.93810

Timestep Collection Time: 2.44654
Timestep Consumption Time: 2.55079
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.99733

Cumulative Model Updates: 230,160
Cumulative Timesteps: 1,919,603,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.16327
Policy Entropy: 2.21267
Value Function Loss: 0.01812

Mean KL Divergence: 0.03027
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.52716
Value Function Update Magnitude: 0.61476

Collected Steps per Second: 22,478.80070
Overall Steps per Second: 10,271.40651

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.64494
PPO Batch Consumption Time: 0.30704
Total Iteration Time: 4.87041

Cumulative Model Updates: 230,166
Cumulative Timesteps: 1,919,653,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1919653220...
Checkpoint 1919653220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.55187
Policy Entropy: 2.21694
Value Function Loss: 0.01765

Mean KL Divergence: 0.02681
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.55398
Value Function Update Magnitude: 0.61721

Collected Steps per Second: 21,145.45504
Overall Steps per Second: 10,261.21106

Timestep Collection Time: 2.36580
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.87525

Cumulative Model Updates: 230,172
Cumulative Timesteps: 1,919,703,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.78452
Policy Entropy: 2.21824
Value Function Loss: 0.01912

Mean KL Divergence: 0.02723
SB3 Clip Fraction: 0.16339
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.63137

Collected Steps per Second: 20,260.05426
Overall Steps per Second: 9,871.26463

Timestep Collection Time: 2.46870
Timestep Consumption Time: 2.59813
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 5.06683

Cumulative Model Updates: 230,178
Cumulative Timesteps: 1,919,753,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1919753262...
Checkpoint 1919753262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.42803
Policy Entropy: 2.21403
Value Function Loss: 0.01883

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.65486

Collected Steps per Second: 21,602.06969
Overall Steps per Second: 10,333.07875

Timestep Collection Time: 2.31478
Timestep Consumption Time: 2.52444
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.83922

Cumulative Model Updates: 230,184
Cumulative Timesteps: 1,919,803,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.37569
Policy Entropy: 2.19830
Value Function Loss: 0.01790

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.57385
Value Function Update Magnitude: 0.65917

Collected Steps per Second: 21,053.93116
Overall Steps per Second: 10,283.82408

Timestep Collection Time: 2.37485
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.86200

Cumulative Model Updates: 230,190
Cumulative Timesteps: 1,919,853,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1919853266...
Checkpoint 1919853266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.26208
Policy Entropy: 2.21559
Value Function Loss: 0.01664

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.55473
Value Function Update Magnitude: 0.63764

Collected Steps per Second: 21,039.11068
Overall Steps per Second: 10,198.63132

Timestep Collection Time: 2.37776
Timestep Consumption Time: 2.52741
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.90517

Cumulative Model Updates: 230,196
Cumulative Timesteps: 1,919,903,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.20827
Policy Entropy: 2.21194
Value Function Loss: 0.01716

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.63192

Collected Steps per Second: 23,494.45319
Overall Steps per Second: 10,669.63685

Timestep Collection Time: 2.12850
Timestep Consumption Time: 2.55844
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.68694

Cumulative Model Updates: 230,202
Cumulative Timesteps: 1,919,953,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1919953300...
Checkpoint 1919953300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.74857
Policy Entropy: 2.24111
Value Function Loss: 0.01732

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.54109
Value Function Update Magnitude: 0.64213

Collected Steps per Second: 22,791.17434
Overall Steps per Second: 10,585.75969

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.53051
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.72522

Cumulative Model Updates: 230,208
Cumulative Timesteps: 1,920,003,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.93063
Policy Entropy: 2.23253
Value Function Loss: 0.01690

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.63164

Collected Steps per Second: 22,759.30729
Overall Steps per Second: 10,727.79797

Timestep Collection Time: 2.19734
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.66172

Cumulative Model Updates: 230,214
Cumulative Timesteps: 1,920,053,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1920053330...
Checkpoint 1920053330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.25499
Policy Entropy: 2.24879
Value Function Loss: 0.01781

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.62194

Collected Steps per Second: 20,162.26305
Overall Steps per Second: 10,017.10028

Timestep Collection Time: 2.48097
Timestep Consumption Time: 2.51269
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.99366

Cumulative Model Updates: 230,220
Cumulative Timesteps: 1,920,103,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.06530
Policy Entropy: 2.23894
Value Function Loss: 0.01769

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.62107

Collected Steps per Second: 21,411.05597
Overall Steps per Second: 10,058.70204

Timestep Collection Time: 2.33590
Timestep Consumption Time: 2.63632
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.97221

Cumulative Model Updates: 230,226
Cumulative Timesteps: 1,920,153,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1920153366...
Checkpoint 1920153366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.08654
Policy Entropy: 2.22241
Value Function Loss: 0.01877

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.63798

Collected Steps per Second: 20,425.90991
Overall Steps per Second: 10,242.83094

Timestep Collection Time: 2.44875
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.88322

Cumulative Model Updates: 230,232
Cumulative Timesteps: 1,920,203,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.91430
Policy Entropy: 2.20188
Value Function Loss: 0.01859

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 23,002.49276
Overall Steps per Second: 10,624.63397

Timestep Collection Time: 2.17394
Timestep Consumption Time: 2.53267
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.70661

Cumulative Model Updates: 230,238
Cumulative Timesteps: 1,920,253,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1920253390...
Checkpoint 1920253390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.32416
Policy Entropy: 2.22501
Value Function Loss: 0.01820

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.15081
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.63187

Collected Steps per Second: 23,064.23749
Overall Steps per Second: 10,599.37824

Timestep Collection Time: 2.16812
Timestep Consumption Time: 2.54971
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.71782

Cumulative Model Updates: 230,244
Cumulative Timesteps: 1,920,303,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.25303
Policy Entropy: 2.22798
Value Function Loss: 0.01747

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.60261

Collected Steps per Second: 22,752.55003
Overall Steps per Second: 10,561.42520

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.53777
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.73629

Cumulative Model Updates: 230,250
Cumulative Timesteps: 1,920,353,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1920353418...
Checkpoint 1920353418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.03822
Policy Entropy: 2.24497
Value Function Loss: 0.01644

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.53437
Value Function Update Magnitude: 0.59376

Collected Steps per Second: 22,308.80618
Overall Steps per Second: 10,604.74354

Timestep Collection Time: 2.24145
Timestep Consumption Time: 2.47380
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.71525

Cumulative Model Updates: 230,256
Cumulative Timesteps: 1,920,403,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.00489
Policy Entropy: 2.18468
Value Function Loss: 0.01830

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.17695
Policy Update Magnitude: 0.50552
Value Function Update Magnitude: 0.58343

Collected Steps per Second: 23,000.01550
Overall Steps per Second: 10,822.70189

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.44708
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.62195

Cumulative Model Updates: 230,262
Cumulative Timesteps: 1,920,453,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1920453444...
Checkpoint 1920453444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.87843
Policy Entropy: 2.20059
Value Function Loss: 0.01836

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.15728
Policy Update Magnitude: 0.51243
Value Function Update Magnitude: 0.58934

Collected Steps per Second: 22,496.19387
Overall Steps per Second: 10,464.77389

Timestep Collection Time: 2.22260
Timestep Consumption Time: 2.55534
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.77793

Cumulative Model Updates: 230,268
Cumulative Timesteps: 1,920,503,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.37510
Policy Entropy: 2.19402
Value Function Loss: 0.01921

Mean KL Divergence: 0.02693
SB3 Clip Fraction: 0.16768
Policy Update Magnitude: 0.56999
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 21,175.84142
Overall Steps per Second: 10,251.40100

Timestep Collection Time: 2.36165
Timestep Consumption Time: 2.51670
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.87836

Cumulative Model Updates: 230,274
Cumulative Timesteps: 1,920,553,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1920553454...
Checkpoint 1920553454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.05489
Policy Entropy: 2.19769
Value Function Loss: 0.01788

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.60652

Collected Steps per Second: 21,478.79557
Overall Steps per Second: 10,386.00228

Timestep Collection Time: 2.32806
Timestep Consumption Time: 2.48649
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.81456

Cumulative Model Updates: 230,280
Cumulative Timesteps: 1,920,603,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.75309
Policy Entropy: 2.16216
Value Function Loss: 0.01765

Mean KL Divergence: 0.02421
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.56728
Value Function Update Magnitude: 0.60295

Collected Steps per Second: 22,879.87972
Overall Steps per Second: 10,778.12599

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.63940

Cumulative Model Updates: 230,286
Cumulative Timesteps: 1,920,653,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1920653462...
Checkpoint 1920653462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.22294
Policy Entropy: 2.14599
Value Function Loss: 0.01753

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.55837
Value Function Update Magnitude: 0.60677

Collected Steps per Second: 22,257.52421
Overall Steps per Second: 10,554.69478

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.49090
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.73742

Cumulative Model Updates: 230,292
Cumulative Timesteps: 1,920,703,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.10222
Policy Entropy: 2.16671
Value Function Loss: 0.01840

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.61654

Collected Steps per Second: 21,986.76645
Overall Steps per Second: 10,336.41196

Timestep Collection Time: 2.27510
Timestep Consumption Time: 2.56430
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.83940

Cumulative Model Updates: 230,298
Cumulative Timesteps: 1,920,753,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1920753486...
Checkpoint 1920753486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.57353
Policy Entropy: 2.18265
Value Function Loss: 0.01823

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.64514

Collected Steps per Second: 21,087.16332
Overall Steps per Second: 10,379.92230

Timestep Collection Time: 2.37225
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.81930

Cumulative Model Updates: 230,304
Cumulative Timesteps: 1,920,803,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.66686
Policy Entropy: 2.20624
Value Function Loss: 0.01873

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.57445
Value Function Update Magnitude: 0.63758

Collected Steps per Second: 23,401.01413
Overall Steps per Second: 10,831.57477

Timestep Collection Time: 2.13751
Timestep Consumption Time: 2.48047
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.61798

Cumulative Model Updates: 230,310
Cumulative Timesteps: 1,920,853,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1920853530...
Checkpoint 1920853530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.78171
Policy Entropy: 2.22904
Value Function Loss: 0.01778

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.63422

Collected Steps per Second: 22,474.36070
Overall Steps per Second: 10,632.42636

Timestep Collection Time: 2.22556
Timestep Consumption Time: 2.47873
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.70429

Cumulative Model Updates: 230,316
Cumulative Timesteps: 1,920,903,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.79015
Policy Entropy: 2.23102
Value Function Loss: 0.01766

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.64395

Collected Steps per Second: 22,160.66924
Overall Steps per Second: 10,489.42248

Timestep Collection Time: 2.25670
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.76766

Cumulative Model Updates: 230,322
Cumulative Timesteps: 1,920,953,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1920953558...
Checkpoint 1920953558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.03107
Policy Entropy: 2.21770
Value Function Loss: 0.01737

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.55812
Value Function Update Magnitude: 0.66733

Collected Steps per Second: 22,495.27166
Overall Steps per Second: 10,741.32100

Timestep Collection Time: 2.22367
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.65697

Cumulative Model Updates: 230,328
Cumulative Timesteps: 1,921,003,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.14656
Policy Entropy: 2.18589
Value Function Loss: 0.01760

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.67606

Collected Steps per Second: 22,190.00990
Overall Steps per Second: 10,373.42893

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.56797
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.82232

Cumulative Model Updates: 230,334
Cumulative Timesteps: 1,921,053,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1921053604...
Checkpoint 1921053604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.31432
Policy Entropy: 2.18761
Value Function Loss: 0.01686

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.56373
Value Function Update Magnitude: 0.68168

Collected Steps per Second: 22,172.98439
Overall Steps per Second: 10,381.01324

Timestep Collection Time: 2.25572
Timestep Consumption Time: 2.56231
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.81803

Cumulative Model Updates: 230,340
Cumulative Timesteps: 1,921,103,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.39474
Policy Entropy: 2.19549
Value Function Loss: 0.01730

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.56541
Value Function Update Magnitude: 0.64379

Collected Steps per Second: 21,968.56624
Overall Steps per Second: 10,235.33097

Timestep Collection Time: 2.27689
Timestep Consumption Time: 2.61010
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.88699

Cumulative Model Updates: 230,346
Cumulative Timesteps: 1,921,153,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1921153640...
Checkpoint 1921153640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.90396
Policy Entropy: 2.21268
Value Function Loss: 0.01719

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.63312

Collected Steps per Second: 21,911.85346
Overall Steps per Second: 10,333.52709

Timestep Collection Time: 2.28278
Timestep Consumption Time: 2.55777
PPO Batch Consumption Time: 0.30395
Total Iteration Time: 4.84055

Cumulative Model Updates: 230,352
Cumulative Timesteps: 1,921,203,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.20147
Policy Entropy: 2.18015
Value Function Loss: 0.01788

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.63632

Collected Steps per Second: 21,770.68120
Overall Steps per Second: 10,323.26581

Timestep Collection Time: 2.29713
Timestep Consumption Time: 2.54727
PPO Batch Consumption Time: 0.30158
Total Iteration Time: 4.84440

Cumulative Model Updates: 230,358
Cumulative Timesteps: 1,921,253,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1921253670...
Checkpoint 1921253670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.53739
Policy Entropy: 2.18351
Value Function Loss: 0.01746

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.61948

Collected Steps per Second: 21,864.30332
Overall Steps per Second: 10,275.36929

Timestep Collection Time: 2.28692
Timestep Consumption Time: 2.57928
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.86620

Cumulative Model Updates: 230,364
Cumulative Timesteps: 1,921,303,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.29539
Policy Entropy: 2.19971
Value Function Loss: 0.01722

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.60604

Collected Steps per Second: 21,884.64931
Overall Steps per Second: 10,357.65953

Timestep Collection Time: 2.28608
Timestep Consumption Time: 2.54416
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.83024

Cumulative Model Updates: 230,370
Cumulative Timesteps: 1,921,353,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1921353702...
Checkpoint 1921353702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.78691
Policy Entropy: 2.22332
Value Function Loss: 0.01769

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 21,367.59258
Overall Steps per Second: 10,218.48025

Timestep Collection Time: 2.34027
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.89368

Cumulative Model Updates: 230,376
Cumulative Timesteps: 1,921,403,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.76735
Policy Entropy: 2.22303
Value Function Loss: 0.01883

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.62054

Collected Steps per Second: 22,643.05935
Overall Steps per Second: 10,643.34261

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69796

Cumulative Model Updates: 230,382
Cumulative Timesteps: 1,921,453,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1921453710...
Checkpoint 1921453710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.48560
Policy Entropy: 2.21433
Value Function Loss: 0.01889

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.56250
Value Function Update Magnitude: 0.62333

Collected Steps per Second: 22,018.57188
Overall Steps per Second: 10,477.08657

Timestep Collection Time: 2.27163
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.77404

Cumulative Model Updates: 230,388
Cumulative Timesteps: 1,921,503,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.73720
Policy Entropy: 2.20222
Value Function Loss: 0.01751

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.56120
Value Function Update Magnitude: 0.62053

Collected Steps per Second: 21,115.90460
Overall Steps per Second: 10,164.03892

Timestep Collection Time: 2.36911
Timestep Consumption Time: 2.55275
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.92186

Cumulative Model Updates: 230,394
Cumulative Timesteps: 1,921,553,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1921553754...
Checkpoint 1921553754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.31275
Policy Entropy: 2.18757
Value Function Loss: 0.01797

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.61790

Collected Steps per Second: 21,679.21600
Overall Steps per Second: 10,324.26524

Timestep Collection Time: 2.30709
Timestep Consumption Time: 2.53741
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.84451

Cumulative Model Updates: 230,400
Cumulative Timesteps: 1,921,603,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.82459
Policy Entropy: 2.18307
Value Function Loss: 0.01753

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.56049
Value Function Update Magnitude: 0.64757

Collected Steps per Second: 22,057.55832
Overall Steps per Second: 10,353.85232

Timestep Collection Time: 2.26770
Timestep Consumption Time: 2.56335
PPO Batch Consumption Time: 0.30188
Total Iteration Time: 4.83105

Cumulative Model Updates: 230,406
Cumulative Timesteps: 1,921,653,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1921653790...
Checkpoint 1921653790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.86110
Policy Entropy: 2.20998
Value Function Loss: 0.01829

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.56515
Value Function Update Magnitude: 0.63344

Collected Steps per Second: 22,779.55776
Overall Steps per Second: 10,612.48840

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.71388

Cumulative Model Updates: 230,412
Cumulative Timesteps: 1,921,703,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.65437
Policy Entropy: 2.23053
Value Function Loss: 0.01818

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.56625
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,199.87090
Overall Steps per Second: 10,345.09468

Timestep Collection Time: 2.25371
Timestep Consumption Time: 2.58260
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.83630

Cumulative Model Updates: 230,418
Cumulative Timesteps: 1,921,753,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1921753848...
Checkpoint 1921753848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.51987
Policy Entropy: 2.22352
Value Function Loss: 0.01761

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.63923

Collected Steps per Second: 22,212.53614
Overall Steps per Second: 10,224.66518

Timestep Collection Time: 2.25134
Timestep Consumption Time: 2.63958
PPO Batch Consumption Time: 0.31258
Total Iteration Time: 4.89092

Cumulative Model Updates: 230,424
Cumulative Timesteps: 1,921,803,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.34238
Policy Entropy: 2.23290
Value Function Loss: 0.01728

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.62151

Collected Steps per Second: 22,055.25197
Overall Steps per Second: 10,503.30381

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.76269

Cumulative Model Updates: 230,430
Cumulative Timesteps: 1,921,853,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1921853880...
Checkpoint 1921853880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.58247
Policy Entropy: 2.22139
Value Function Loss: 0.01719

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.61799

Collected Steps per Second: 22,019.80964
Overall Steps per Second: 10,261.02045

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.60379
PPO Batch Consumption Time: 0.30864
Total Iteration Time: 4.87593

Cumulative Model Updates: 230,436
Cumulative Timesteps: 1,921,903,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.06029
Policy Entropy: 2.25340
Value Function Loss: 0.01673

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.60849

Collected Steps per Second: 21,430.91771
Overall Steps per Second: 10,383.60249

Timestep Collection Time: 2.33317
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.81548

Cumulative Model Updates: 230,442
Cumulative Timesteps: 1,921,953,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1921953914...
Checkpoint 1921953914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.69293
Policy Entropy: 2.26281
Value Function Loss: 0.01726

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.55023
Value Function Update Magnitude: 0.60609

Collected Steps per Second: 21,790.11180
Overall Steps per Second: 10,203.05262

Timestep Collection Time: 2.29517
Timestep Consumption Time: 2.60650
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 4.90167

Cumulative Model Updates: 230,448
Cumulative Timesteps: 1,922,003,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.38109
Policy Entropy: 2.26549
Value Function Loss: 0.01702

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.61981

Collected Steps per Second: 22,737.69548
Overall Steps per Second: 10,634.59809

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.70182

Cumulative Model Updates: 230,454
Cumulative Timesteps: 1,922,053,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1922053928...
Checkpoint 1922053928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.03581
Policy Entropy: 2.23256
Value Function Loss: 0.01718

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.55728
Value Function Update Magnitude: 0.62678

Collected Steps per Second: 22,099.56468
Overall Steps per Second: 10,409.77598

Timestep Collection Time: 2.26339
Timestep Consumption Time: 2.54171
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.80510

Cumulative Model Updates: 230,460
Cumulative Timesteps: 1,922,103,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.20979
Policy Entropy: 2.21224
Value Function Loss: 0.01699

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.63210

Collected Steps per Second: 22,024.27963
Overall Steps per Second: 10,232.97887

Timestep Collection Time: 2.27113
Timestep Consumption Time: 2.61699
PPO Batch Consumption Time: 0.30609
Total Iteration Time: 4.88812

Cumulative Model Updates: 230,466
Cumulative Timesteps: 1,922,153,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1922153968...
Checkpoint 1922153968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.00158
Policy Entropy: 2.20583
Value Function Loss: 0.01651

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.61987

Collected Steps per Second: 22,425.35508
Overall Steps per Second: 10,582.53601

Timestep Collection Time: 2.22962
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.72477

Cumulative Model Updates: 230,472
Cumulative Timesteps: 1,922,203,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.78199
Policy Entropy: 2.21607
Value Function Loss: 0.01722

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.61142

Collected Steps per Second: 21,446.75479
Overall Steps per Second: 10,493.97950

Timestep Collection Time: 2.33145
Timestep Consumption Time: 2.43338
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.76483

Cumulative Model Updates: 230,478
Cumulative Timesteps: 1,922,253,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1922253970...
Checkpoint 1922253970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.08565
Policy Entropy: 2.21062
Value Function Loss: 0.01732

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.54285
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 21,874.60130
Overall Steps per Second: 10,553.30161

Timestep Collection Time: 2.28713
Timestep Consumption Time: 2.45357
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.74070

Cumulative Model Updates: 230,484
Cumulative Timesteps: 1,922,304,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.44053
Policy Entropy: 2.21711
Value Function Loss: 0.01759

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.16193
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.63402

Collected Steps per Second: 22,169.58326
Overall Steps per Second: 10,604.37294

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.46078
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71711

Cumulative Model Updates: 230,490
Cumulative Timesteps: 1,922,354,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1922354022...
Checkpoint 1922354022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.85295
Policy Entropy: 2.18641
Value Function Loss: 0.01738

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.16396
Policy Update Magnitude: 0.56877
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 19,009.67708
Overall Steps per Second: 9,537.48244

Timestep Collection Time: 2.63119
Timestep Consumption Time: 2.61317
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 5.24436

Cumulative Model Updates: 230,496
Cumulative Timesteps: 1,922,404,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.63562
Policy Entropy: 2.19613
Value Function Loss: 0.01748

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.15738
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.66367

Collected Steps per Second: 21,169.71007
Overall Steps per Second: 10,092.96472

Timestep Collection Time: 2.36272
Timestep Consumption Time: 2.59301
PPO Batch Consumption Time: 0.30503
Total Iteration Time: 4.95573

Cumulative Model Updates: 230,502
Cumulative Timesteps: 1,922,454,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1922454058...
Checkpoint 1922454058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.13888
Policy Entropy: 2.19705
Value Function Loss: 0.01828

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.57009
Value Function Update Magnitude: 0.66508

Collected Steps per Second: 22,477.12638
Overall Steps per Second: 10,261.14884

Timestep Collection Time: 2.22511
Timestep Consumption Time: 2.64901
PPO Batch Consumption Time: 0.31025
Total Iteration Time: 4.87411

Cumulative Model Updates: 230,508
Cumulative Timesteps: 1,922,504,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.38715
Policy Entropy: 2.21818
Value Function Loss: 0.01763

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.15460
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.65673

Collected Steps per Second: 21,025.37384
Overall Steps per Second: 10,120.15539

Timestep Collection Time: 2.37808
Timestep Consumption Time: 2.56256
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.94064

Cumulative Model Updates: 230,514
Cumulative Timesteps: 1,922,554,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1922554072...
Checkpoint 1922554072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.45935
Policy Entropy: 2.23346
Value Function Loss: 0.01750

Mean KL Divergence: 0.03006
SB3 Clip Fraction: 0.17114
Policy Update Magnitude: 0.51717
Value Function Update Magnitude: 0.63444

Collected Steps per Second: 21,673.80947
Overall Steps per Second: 10,356.91832

Timestep Collection Time: 2.30850
Timestep Consumption Time: 2.52247
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.83097

Cumulative Model Updates: 230,520
Cumulative Timesteps: 1,922,604,106

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.79626
Policy Entropy: 2.24329
Value Function Loss: 0.01680

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.17106
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.61837

Collected Steps per Second: 22,344.87978
Overall Steps per Second: 10,519.65390

Timestep Collection Time: 2.23774
Timestep Consumption Time: 2.51546
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.75320

Cumulative Model Updates: 230,526
Cumulative Timesteps: 1,922,654,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1922654108...
Checkpoint 1922654108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.98336
Policy Entropy: 2.22126
Value Function Loss: 0.01664

Mean KL Divergence: 0.02579
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.55522
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 20,079.63992
Overall Steps per Second: 9,907.52167

Timestep Collection Time: 2.49028
Timestep Consumption Time: 2.55679
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 5.04707

Cumulative Model Updates: 230,532
Cumulative Timesteps: 1,922,704,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.09866
Policy Entropy: 2.22508
Value Function Loss: 0.01629

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.59618

Collected Steps per Second: 22,415.97472
Overall Steps per Second: 10,562.63162

Timestep Collection Time: 2.23127
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.73518

Cumulative Model Updates: 230,538
Cumulative Timesteps: 1,922,754,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1922754128...
Checkpoint 1922754128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.46971
Policy Entropy: 2.25432
Value Function Loss: 0.01645

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.58136

Collected Steps per Second: 21,357.35290
Overall Steps per Second: 10,130.03643

Timestep Collection Time: 2.34196
Timestep Consumption Time: 2.59564
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 4.93759

Cumulative Model Updates: 230,544
Cumulative Timesteps: 1,922,804,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.11153
Policy Entropy: 2.26650
Value Function Loss: 0.01839

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.55018
Value Function Update Magnitude: 0.57805

Collected Steps per Second: 21,870.04778
Overall Steps per Second: 10,282.11990

Timestep Collection Time: 2.28742
Timestep Consumption Time: 2.57792
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 4.86534

Cumulative Model Updates: 230,550
Cumulative Timesteps: 1,922,854,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1922854172...
Checkpoint 1922854172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.51658
Policy Entropy: 2.25883
Value Function Loss: 0.01779

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.55362
Value Function Update Magnitude: 0.59750

Collected Steps per Second: 22,733.72988
Overall Steps per Second: 10,572.90583

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.53020
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.73001

Cumulative Model Updates: 230,556
Cumulative Timesteps: 1,922,904,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.72962
Policy Entropy: 2.23827
Value Function Loss: 0.01812

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.60695

Collected Steps per Second: 21,901.67359
Overall Steps per Second: 10,396.58753

Timestep Collection Time: 2.28366
Timestep Consumption Time: 2.52715
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.81081

Cumulative Model Updates: 230,562
Cumulative Timesteps: 1,922,954,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1922954198...
Checkpoint 1922954198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.70173
Policy Entropy: 2.22568
Value Function Loss: 0.01726

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.55733
Value Function Update Magnitude: 0.61476

Collected Steps per Second: 21,855.47495
Overall Steps per Second: 10,489.21041

Timestep Collection Time: 2.28885
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.76909

Cumulative Model Updates: 230,568
Cumulative Timesteps: 1,923,004,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.88689
Policy Entropy: 2.21347
Value Function Loss: 0.01727

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.63881

Collected Steps per Second: 21,890.60822
Overall Steps per Second: 10,318.78146

Timestep Collection Time: 2.28546
Timestep Consumption Time: 2.56299
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.84844

Cumulative Model Updates: 230,574
Cumulative Timesteps: 1,923,054,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1923054252...
Checkpoint 1923054252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.14618
Policy Entropy: 2.23013
Value Function Loss: 0.01684

Mean KL Divergence: 0.03154
SB3 Clip Fraction: 0.17731
Policy Update Magnitude: 0.49700
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 22,607.61261
Overall Steps per Second: 10,498.31328

Timestep Collection Time: 2.21244
Timestep Consumption Time: 2.55194
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.76438

Cumulative Model Updates: 230,580
Cumulative Timesteps: 1,923,104,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.42648
Policy Entropy: 2.22504
Value Function Loss: 0.01710

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.52743
Value Function Update Magnitude: 0.63371

Collected Steps per Second: 22,187.40459
Overall Steps per Second: 10,516.81179

Timestep Collection Time: 2.25371
Timestep Consumption Time: 2.50096
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.75467

Cumulative Model Updates: 230,586
Cumulative Timesteps: 1,923,154,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1923154274...
Checkpoint 1923154274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.42067
Policy Entropy: 2.21491
Value Function Loss: 0.01766

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.62388

Collected Steps per Second: 21,941.78864
Overall Steps per Second: 10,583.63845

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.44669
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.72654

Cumulative Model Updates: 230,592
Cumulative Timesteps: 1,923,204,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.32984
Policy Entropy: 2.18644
Value Function Loss: 0.01788

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.15635
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,420.03593
Overall Steps per Second: 10,546.27325

Timestep Collection Time: 2.23050
Timestep Consumption Time: 2.51126
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.74177

Cumulative Model Updates: 230,598
Cumulative Timesteps: 1,923,254,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1923254306...
Checkpoint 1923254306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.96297
Policy Entropy: 2.21924
Value Function Loss: 0.01782

Mean KL Divergence: 0.02994
SB3 Clip Fraction: 0.17039
Policy Update Magnitude: 0.53890
Value Function Update Magnitude: 0.62457

Collected Steps per Second: 22,955.91214
Overall Steps per Second: 10,431.01082

Timestep Collection Time: 2.17905
Timestep Consumption Time: 2.61646
PPO Batch Consumption Time: 0.30967
Total Iteration Time: 4.79551

Cumulative Model Updates: 230,604
Cumulative Timesteps: 1,923,304,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.28207
Policy Entropy: 2.21648
Value Function Loss: 0.01798

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.15197
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.64520

Collected Steps per Second: 21,895.26546
Overall Steps per Second: 10,354.18416

Timestep Collection Time: 2.28378
Timestep Consumption Time: 2.54557
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.82935

Cumulative Model Updates: 230,610
Cumulative Timesteps: 1,923,354,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1923354332...
Checkpoint 1923354332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.06628
Policy Entropy: 2.21995
Value Function Loss: 0.01765

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.64832

Collected Steps per Second: 20,213.27450
Overall Steps per Second: 9,810.44806

Timestep Collection Time: 2.47412
Timestep Consumption Time: 2.62351
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 5.09763

Cumulative Model Updates: 230,616
Cumulative Timesteps: 1,923,404,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.46616
Policy Entropy: 2.19427
Value Function Loss: 0.01775

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.63873

Collected Steps per Second: 20,916.60517
Overall Steps per Second: 10,150.90207

Timestep Collection Time: 2.39111
Timestep Consumption Time: 2.53594
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.92705

Cumulative Model Updates: 230,622
Cumulative Timesteps: 1,923,454,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1923454356...
Checkpoint 1923454356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.08884
Policy Entropy: 2.18179
Value Function Loss: 0.01656

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.61808

Collected Steps per Second: 21,584.25497
Overall Steps per Second: 10,459.34945

Timestep Collection Time: 2.31743
Timestep Consumption Time: 2.46489
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.78232

Cumulative Model Updates: 230,628
Cumulative Timesteps: 1,923,504,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.58351
Policy Entropy: 2.20581
Value Function Loss: 0.01639

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.54537
Value Function Update Magnitude: 0.59764

Collected Steps per Second: 22,209.67918
Overall Steps per Second: 10,507.71757

Timestep Collection Time: 2.25127
Timestep Consumption Time: 2.50714
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.75841

Cumulative Model Updates: 230,634
Cumulative Timesteps: 1,923,554,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1923554376...
Checkpoint 1923554376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.61270
Policy Entropy: 2.21268
Value Function Loss: 0.01638

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.58979

Collected Steps per Second: 20,845.61839
Overall Steps per Second: 9,977.30499

Timestep Collection Time: 2.39926
Timestep Consumption Time: 2.61352
PPO Batch Consumption Time: 0.30384
Total Iteration Time: 5.01278

Cumulative Model Updates: 230,640
Cumulative Timesteps: 1,923,604,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.25650
Policy Entropy: 2.24878
Value Function Loss: 0.01661

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.53923
Value Function Update Magnitude: 0.58992

Collected Steps per Second: 21,577.72967
Overall Steps per Second: 10,451.67526

Timestep Collection Time: 2.31822
Timestep Consumption Time: 2.46780
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.78603

Cumulative Model Updates: 230,646
Cumulative Timesteps: 1,923,654,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1923654412...
Checkpoint 1923654412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.11235
Policy Entropy: 2.22587
Value Function Loss: 0.01613

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.53982
Value Function Update Magnitude: 0.59651

Collected Steps per Second: 22,828.60801
Overall Steps per Second: 10,527.08622

Timestep Collection Time: 2.19129
Timestep Consumption Time: 2.56065
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.75193

Cumulative Model Updates: 230,652
Cumulative Timesteps: 1,923,704,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.89828
Policy Entropy: 2.22098
Value Function Loss: 0.01670

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.53664
Value Function Update Magnitude: 0.60102

Collected Steps per Second: 22,663.92191
Overall Steps per Second: 10,478.88614

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.56535
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.77150

Cumulative Model Updates: 230,658
Cumulative Timesteps: 1,923,754,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1923754436...
Checkpoint 1923754436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.53587
Policy Entropy: 2.23685
Value Function Loss: 0.01583

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.53383
Value Function Update Magnitude: 0.61161

Collected Steps per Second: 21,968.62209
Overall Steps per Second: 10,314.45281

Timestep Collection Time: 2.27616
Timestep Consumption Time: 2.57180
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 4.84795

Cumulative Model Updates: 230,664
Cumulative Timesteps: 1,923,804,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.82892
Policy Entropy: 2.25045
Value Function Loss: 0.01605

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.53343
Value Function Update Magnitude: 0.60497

Collected Steps per Second: 22,427.99628
Overall Steps per Second: 10,614.61210

Timestep Collection Time: 2.23016
Timestep Consumption Time: 2.48202
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.71218

Cumulative Model Updates: 230,670
Cumulative Timesteps: 1,923,854,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1923854458...
Checkpoint 1923854458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.21543
Policy Entropy: 2.28796
Value Function Loss: 0.01600

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.53053
Value Function Update Magnitude: 0.61221

Collected Steps per Second: 22,302.21607
Overall Steps per Second: 10,351.09292

Timestep Collection Time: 2.24301
Timestep Consumption Time: 2.58972
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.83273

Cumulative Model Updates: 230,676
Cumulative Timesteps: 1,923,904,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.09838
Policy Entropy: 2.26128
Value Function Loss: 0.01561

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.53189
Value Function Update Magnitude: 0.63257

Collected Steps per Second: 22,028.85237
Overall Steps per Second: 10,326.54765

Timestep Collection Time: 2.27030
Timestep Consumption Time: 2.57276
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.84305

Cumulative Model Updates: 230,682
Cumulative Timesteps: 1,923,954,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1923954494...
Checkpoint 1923954494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.75887
Policy Entropy: 2.27006
Value Function Loss: 0.01584

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.53566
Value Function Update Magnitude: 0.62440

Collected Steps per Second: 21,873.56334
Overall Steps per Second: 10,489.46607

Timestep Collection Time: 2.28742
Timestep Consumption Time: 2.48251
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.76993

Cumulative Model Updates: 230,688
Cumulative Timesteps: 1,924,004,528

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.50467
Policy Entropy: 2.28858
Value Function Loss: 0.01641

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.61951

Collected Steps per Second: 22,071.30063
Overall Steps per Second: 10,487.78389

Timestep Collection Time: 2.26539
Timestep Consumption Time: 2.50207
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.76745

Cumulative Model Updates: 230,694
Cumulative Timesteps: 1,924,054,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1924054528...
Checkpoint 1924054528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.38088
Policy Entropy: 2.28270
Value Function Loss: 0.01817

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.61521

Collected Steps per Second: 22,183.81268
Overall Steps per Second: 10,524.69897

Timestep Collection Time: 2.25390
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.75073

Cumulative Model Updates: 230,700
Cumulative Timesteps: 1,924,104,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.82942
Policy Entropy: 2.24965
Value Function Loss: 0.01797

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.62530

Collected Steps per Second: 21,900.21674
Overall Steps per Second: 10,507.08443

Timestep Collection Time: 2.28454
Timestep Consumption Time: 2.47720
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.76174

Cumulative Model Updates: 230,706
Cumulative Timesteps: 1,924,154,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1924154560...
Checkpoint 1924154560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.39909
Policy Entropy: 2.24042
Value Function Loss: 0.01861

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.55825
Value Function Update Magnitude: 0.62893

Collected Steps per Second: 21,835.61799
Overall Steps per Second: 10,555.98135

Timestep Collection Time: 2.29020
Timestep Consumption Time: 2.44721
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.73741

Cumulative Model Updates: 230,712
Cumulative Timesteps: 1,924,204,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.86787
Policy Entropy: 2.22832
Value Function Loss: 0.01828

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.61498

Collected Steps per Second: 21,334.85096
Overall Steps per Second: 10,275.13553

Timestep Collection Time: 2.34471
Timestep Consumption Time: 2.52374
PPO Batch Consumption Time: 0.30267
Total Iteration Time: 4.86845

Cumulative Model Updates: 230,718
Cumulative Timesteps: 1,924,254,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1924254592...
Checkpoint 1924254592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.63651
Policy Entropy: 2.26415
Value Function Loss: 0.01748

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.60897

Collected Steps per Second: 22,094.93972
Overall Steps per Second: 10,557.96628

Timestep Collection Time: 2.26495
Timestep Consumption Time: 2.47497
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.73993

Cumulative Model Updates: 230,724
Cumulative Timesteps: 1,924,304,636

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.39434
Policy Entropy: 2.22107
Value Function Loss: 0.01759

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.60374

Collected Steps per Second: 22,120.58942
Overall Steps per Second: 10,336.65023

Timestep Collection Time: 2.26034
Timestep Consumption Time: 2.57682
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.83716

Cumulative Model Updates: 230,730
Cumulative Timesteps: 1,924,354,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1924354636...
Checkpoint 1924354636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.46509
Policy Entropy: 2.19411
Value Function Loss: 0.01786

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.54400
Value Function Update Magnitude: 0.61555

Collected Steps per Second: 22,006.04447
Overall Steps per Second: 10,478.92207

Timestep Collection Time: 2.27219
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.77167

Cumulative Model Updates: 230,736
Cumulative Timesteps: 1,924,404,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.60603
Policy Entropy: 2.17008
Value Function Loss: 0.01811

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.60322

Collected Steps per Second: 22,494.70062
Overall Steps per Second: 10,427.12539

Timestep Collection Time: 2.22328
Timestep Consumption Time: 2.57306
PPO Batch Consumption Time: 0.30765
Total Iteration Time: 4.79634

Cumulative Model Updates: 230,742
Cumulative Timesteps: 1,924,454,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1924454650...
Checkpoint 1924454650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.64436
Policy Entropy: 2.22259
Value Function Loss: 0.01677

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.53863
Value Function Update Magnitude: 0.59799

Collected Steps per Second: 21,822.86314
Overall Steps per Second: 10,435.48375

Timestep Collection Time: 2.29182
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.79269

Cumulative Model Updates: 230,748
Cumulative Timesteps: 1,924,504,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.08538
Policy Entropy: 2.25135
Value Function Loss: 0.01608

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.53440
Value Function Update Magnitude: 0.58254

Collected Steps per Second: 21,866.12981
Overall Steps per Second: 10,267.78381

Timestep Collection Time: 2.28719
Timestep Consumption Time: 2.58358
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.87077

Cumulative Model Updates: 230,754
Cumulative Timesteps: 1,924,554,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1924554676...
Checkpoint 1924554676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.48892
Policy Entropy: 2.26860
Value Function Loss: 0.01580

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.53570
Value Function Update Magnitude: 0.59471

Collected Steps per Second: 18,638.29650
Overall Steps per Second: 9,745.85975

Timestep Collection Time: 2.68265
Timestep Consumption Time: 2.44774
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 5.13038

Cumulative Model Updates: 230,760
Cumulative Timesteps: 1,924,604,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.12072
Policy Entropy: 2.21869
Value Function Loss: 0.01737

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.61505

Collected Steps per Second: 22,714.74758
Overall Steps per Second: 10,609.06479

Timestep Collection Time: 2.20139
Timestep Consumption Time: 2.51194
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.71333

Cumulative Model Updates: 230,766
Cumulative Timesteps: 1,924,654,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1924654680...
Checkpoint 1924654680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.33003
Policy Entropy: 2.22420
Value Function Loss: 0.01721

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 23,043.64444
Overall Steps per Second: 10,589.28644

Timestep Collection Time: 2.17058
Timestep Consumption Time: 2.55288
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.72345

Cumulative Model Updates: 230,772
Cumulative Timesteps: 1,924,704,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.16261
Policy Entropy: 2.21172
Value Function Loss: 0.01732

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.53745
Value Function Update Magnitude: 0.62215

Collected Steps per Second: 22,015.25064
Overall Steps per Second: 10,154.13299

Timestep Collection Time: 2.27197
Timestep Consumption Time: 2.65391
PPO Batch Consumption Time: 0.30246
Total Iteration Time: 4.92588

Cumulative Model Updates: 230,778
Cumulative Timesteps: 1,924,754,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1924754716...
Checkpoint 1924754716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.41967
Policy Entropy: 2.24005
Value Function Loss: 0.01624

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.62339

Collected Steps per Second: 20,683.94503
Overall Steps per Second: 9,965.88546

Timestep Collection Time: 2.41772
Timestep Consumption Time: 2.60020
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 5.01792

Cumulative Model Updates: 230,784
Cumulative Timesteps: 1,924,804,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.63676
Policy Entropy: 2.22467
Value Function Loss: 0.01656

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.62483

Collected Steps per Second: 22,332.21311
Overall Steps per Second: 10,610.86100

Timestep Collection Time: 2.23928
Timestep Consumption Time: 2.47363
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.71291

Cumulative Model Updates: 230,790
Cumulative Timesteps: 1,924,854,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1924854732...
Checkpoint 1924854732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.28696
Policy Entropy: 2.22555
Value Function Loss: 0.01705

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.62255

Collected Steps per Second: 22,097.43595
Overall Steps per Second: 10,342.31255

Timestep Collection Time: 2.26316
Timestep Consumption Time: 2.57232
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.83548

Cumulative Model Updates: 230,796
Cumulative Timesteps: 1,924,904,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.49145
Policy Entropy: 2.23562
Value Function Loss: 0.01625

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.61435

Collected Steps per Second: 22,129.29394
Overall Steps per Second: 10,530.98822

Timestep Collection Time: 2.25945
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.74789

Cumulative Model Updates: 230,802
Cumulative Timesteps: 1,924,954,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1924954742...
Checkpoint 1924954742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.31199
Policy Entropy: 2.24732
Value Function Loss: 0.01705

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.60138

Collected Steps per Second: 21,612.73891
Overall Steps per Second: 10,289.67374

Timestep Collection Time: 2.31364
Timestep Consumption Time: 2.54599
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 4.85963

Cumulative Model Updates: 230,808
Cumulative Timesteps: 1,925,004,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.35846
Policy Entropy: 2.24346
Value Function Loss: 0.01675

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.60945

Collected Steps per Second: 19,953.46267
Overall Steps per Second: 10,026.25586

Timestep Collection Time: 2.50603
Timestep Consumption Time: 2.48127
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.98731

Cumulative Model Updates: 230,814
Cumulative Timesteps: 1,925,054,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1925054750...
Checkpoint 1925054750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.55354
Policy Entropy: 2.22116
Value Function Loss: 0.01701

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.61279

Collected Steps per Second: 22,306.24095
Overall Steps per Second: 10,474.77590

Timestep Collection Time: 2.24278
Timestep Consumption Time: 2.53326
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.77604

Cumulative Model Updates: 230,820
Cumulative Timesteps: 1,925,104,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.29589
Policy Entropy: 2.22094
Value Function Loss: 0.01616

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.54273
Value Function Update Magnitude: 0.59863

Collected Steps per Second: 21,886.78264
Overall Steps per Second: 10,113.80866

Timestep Collection Time: 2.28485
Timestep Consumption Time: 2.65968
PPO Batch Consumption Time: 0.31462
Total Iteration Time: 4.94453

Cumulative Model Updates: 230,826
Cumulative Timesteps: 1,925,154,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1925154786...
Checkpoint 1925154786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.11063
Policy Entropy: 2.22028
Value Function Loss: 0.01617

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.53473
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 21,963.32852
Overall Steps per Second: 10,697.32740

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.39821
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.67537

Cumulative Model Updates: 230,832
Cumulative Timesteps: 1,925,204,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.84739
Policy Entropy: 2.21216
Value Function Loss: 0.01729

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.57997

Collected Steps per Second: 21,957.56332
Overall Steps per Second: 10,270.60602

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.59114
PPO Batch Consumption Time: 0.31608
Total Iteration Time: 4.86826

Cumulative Model Updates: 230,838
Cumulative Timesteps: 1,925,254,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1925254800...
Checkpoint 1925254800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.35682
Policy Entropy: 2.20009
Value Function Loss: 0.01764

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 22,251.85559
Overall Steps per Second: 10,423.30638

Timestep Collection Time: 2.24889
Timestep Consumption Time: 2.55208
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.80097

Cumulative Model Updates: 230,844
Cumulative Timesteps: 1,925,304,842

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.56260
Policy Entropy: 2.21346
Value Function Loss: 0.01709

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.61723

Collected Steps per Second: 22,606.70296
Overall Steps per Second: 10,506.86327

Timestep Collection Time: 2.21173
Timestep Consumption Time: 2.54706
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.75879

Cumulative Model Updates: 230,850
Cumulative Timesteps: 1,925,354,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1925354842...
Checkpoint 1925354842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.33505
Policy Entropy: 2.22822
Value Function Loss: 0.01654

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.53853
Value Function Update Magnitude: 0.61208

Collected Steps per Second: 22,484.99633
Overall Steps per Second: 10,661.19242

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.69047

Cumulative Model Updates: 230,856
Cumulative Timesteps: 1,925,404,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.67644
Policy Entropy: 2.23004
Value Function Loss: 0.01613

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.53216
Value Function Update Magnitude: 0.58876

Collected Steps per Second: 23,123.78799
Overall Steps per Second: 10,878.73090

Timestep Collection Time: 2.16314
Timestep Consumption Time: 2.43482
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.59796

Cumulative Model Updates: 230,862
Cumulative Timesteps: 1,925,454,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1925454868...
Checkpoint 1925454868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.05457
Policy Entropy: 2.20570
Value Function Loss: 0.01679

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.58632

Collected Steps per Second: 22,338.25469
Overall Steps per Second: 10,645.74637

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.69765

Cumulative Model Updates: 230,868
Cumulative Timesteps: 1,925,504,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.47364
Policy Entropy: 2.22242
Value Function Loss: 0.01686

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.59364

Collected Steps per Second: 22,679.08943
Overall Steps per Second: 10,534.28597

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.54214
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.74717

Cumulative Model Updates: 230,874
Cumulative Timesteps: 1,925,554,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1925554886...
Checkpoint 1925554886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.85225
Policy Entropy: 2.23177
Value Function Loss: 0.01672

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.59386

Collected Steps per Second: 22,094.81603
Overall Steps per Second: 10,551.68044

Timestep Collection Time: 2.26316
Timestep Consumption Time: 2.47581
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.73896

Cumulative Model Updates: 230,880
Cumulative Timesteps: 1,925,604,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.10070
Policy Entropy: 2.23217
Value Function Loss: 0.01662

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.53340
Value Function Update Magnitude: 0.59563

Collected Steps per Second: 22,541.98651
Overall Steps per Second: 10,789.39183

Timestep Collection Time: 2.21835
Timestep Consumption Time: 2.41639
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.63474

Cumulative Model Updates: 230,886
Cumulative Timesteps: 1,925,654,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1925654896...
Checkpoint 1925654896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.58295
Policy Entropy: 2.19160
Value Function Loss: 0.01664

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.53544
Value Function Update Magnitude: 0.58867

Collected Steps per Second: 22,234.51939
Overall Steps per Second: 10,395.36483

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.56108
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.80984

Cumulative Model Updates: 230,892
Cumulative Timesteps: 1,925,704,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.76081
Policy Entropy: 2.19111
Value Function Loss: 0.01739

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.57390

Collected Steps per Second: 21,763.62076
Overall Steps per Second: 10,359.31854

Timestep Collection Time: 2.29842
Timestep Consumption Time: 2.53027
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.82870

Cumulative Model Updates: 230,898
Cumulative Timesteps: 1,925,754,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1925754918...
Checkpoint 1925754918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.11868
Policy Entropy: 2.20764
Value Function Loss: 0.01727

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.59036

Collected Steps per Second: 21,438.54497
Overall Steps per Second: 10,139.89759

Timestep Collection Time: 2.33346
Timestep Consumption Time: 2.60012
PPO Batch Consumption Time: 0.30874
Total Iteration Time: 4.93358

Cumulative Model Updates: 230,904
Cumulative Timesteps: 1,925,804,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.53255
Policy Entropy: 2.24575
Value Function Loss: 0.01714

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 22,360.24834
Overall Steps per Second: 10,499.61810

Timestep Collection Time: 2.23647
Timestep Consumption Time: 2.52637
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.76284

Cumulative Model Updates: 230,910
Cumulative Timesteps: 1,925,854,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1925854952...
Checkpoint 1925854952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.90471
Policy Entropy: 2.24192
Value Function Loss: 0.01649

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.58747

Collected Steps per Second: 22,261.47973
Overall Steps per Second: 10,582.33856

Timestep Collection Time: 2.24693
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.72674

Cumulative Model Updates: 230,916
Cumulative Timesteps: 1,925,904,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.87104
Policy Entropy: 2.23302
Value Function Loss: 0.01699

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.54178
Value Function Update Magnitude: 0.60627

Collected Steps per Second: 22,463.69020
Overall Steps per Second: 10,588.07535

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.49718
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.72362

Cumulative Model Updates: 230,922
Cumulative Timesteps: 1,925,954,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1925954986...
Checkpoint 1925954986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.76838
Policy Entropy: 2.18281
Value Function Loss: 0.01719

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.60688

Collected Steps per Second: 22,261.94974
Overall Steps per Second: 10,535.58813

Timestep Collection Time: 2.24697
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.74791

Cumulative Model Updates: 230,928
Cumulative Timesteps: 1,926,005,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.13363
Policy Entropy: 2.18403
Value Function Loss: 0.01667

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.59825

Collected Steps per Second: 22,836.70895
Overall Steps per Second: 10,520.78230

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.56417
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.75459

Cumulative Model Updates: 230,934
Cumulative Timesteps: 1,926,055,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1926055030...
Checkpoint 1926055030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.77048
Policy Entropy: 2.19165
Value Function Loss: 0.01647

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.52865
Value Function Update Magnitude: 0.58147

Collected Steps per Second: 22,226.99110
Overall Steps per Second: 10,582.75170

Timestep Collection Time: 2.25024
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.72618

Cumulative Model Updates: 230,940
Cumulative Timesteps: 1,926,105,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.08058
Policy Entropy: 2.23723
Value Function Loss: 0.01634

Mean KL Divergence: 0.02779
SB3 Clip Fraction: 0.16093
Policy Update Magnitude: 0.50262
Value Function Update Magnitude: 0.58950

Collected Steps per Second: 22,382.10635
Overall Steps per Second: 10,487.48739

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.53406
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.76835

Cumulative Model Updates: 230,946
Cumulative Timesteps: 1,926,155,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1926155054...
Checkpoint 1926155054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.39855
Policy Entropy: 2.23003
Value Function Loss: 0.01785

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.15589
Policy Update Magnitude: 0.52998
Value Function Update Magnitude: 0.60430

Collected Steps per Second: 22,177.23034
Overall Steps per Second: 10,628.79386

Timestep Collection Time: 2.25493
Timestep Consumption Time: 2.45003
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.70496

Cumulative Model Updates: 230,952
Cumulative Timesteps: 1,926,205,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.28775
Policy Entropy: 2.18967
Value Function Loss: 0.01837

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.62070

Collected Steps per Second: 22,079.69543
Overall Steps per Second: 10,646.39586

Timestep Collection Time: 2.26543
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.69830

Cumulative Model Updates: 230,958
Cumulative Timesteps: 1,926,255,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1926255082...
Checkpoint 1926255082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.08783
Policy Entropy: 2.16683
Value Function Loss: 0.01871

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.62861

Collected Steps per Second: 21,894.73692
Overall Steps per Second: 10,455.49620

Timestep Collection Time: 2.28575
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.78657

Cumulative Model Updates: 230,964
Cumulative Timesteps: 1,926,305,128

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.50748
Policy Entropy: 2.16556
Value Function Loss: 0.01860

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.56080
Value Function Update Magnitude: 0.63850

Collected Steps per Second: 21,580.17565
Overall Steps per Second: 10,179.28492

Timestep Collection Time: 2.31731
Timestep Consumption Time: 2.59541
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.91272

Cumulative Model Updates: 230,970
Cumulative Timesteps: 1,926,355,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1926355136...
Checkpoint 1926355136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.54962
Policy Entropy: 2.17397
Value Function Loss: 0.01877

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.65820

Collected Steps per Second: 22,100.01471
Overall Steps per Second: 10,572.53998

Timestep Collection Time: 2.26371
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.73188

Cumulative Model Updates: 230,976
Cumulative Timesteps: 1,926,405,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.97923
Policy Entropy: 2.16038
Value Function Loss: 0.01895

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.56584
Value Function Update Magnitude: 0.67090

Collected Steps per Second: 22,260.53875
Overall Steps per Second: 10,464.20263

Timestep Collection Time: 2.24667
Timestep Consumption Time: 2.53268
PPO Batch Consumption Time: 0.30597
Total Iteration Time: 4.77934

Cumulative Model Updates: 230,982
Cumulative Timesteps: 1,926,455,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1926455176...
Checkpoint 1926455176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.11097
Policy Entropy: 2.18069
Value Function Loss: 0.01848

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.67254

Collected Steps per Second: 21,808.32751
Overall Steps per Second: 10,275.25420

Timestep Collection Time: 2.29408
Timestep Consumption Time: 2.57490
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.86898

Cumulative Model Updates: 230,988
Cumulative Timesteps: 1,926,505,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.96864
Policy Entropy: 2.19356
Value Function Loss: 0.01863

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.64296

Collected Steps per Second: 21,356.52381
Overall Steps per Second: 10,282.31698

Timestep Collection Time: 2.34298
Timestep Consumption Time: 2.52343
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.86641

Cumulative Model Updates: 230,994
Cumulative Timesteps: 1,926,555,244

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1926555244...
Checkpoint 1926555244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.90593
Policy Entropy: 2.20937
Value Function Loss: 0.01789

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.63261

Collected Steps per Second: 21,755.09614
Overall Steps per Second: 10,679.36908

Timestep Collection Time: 2.29840
Timestep Consumption Time: 2.38371
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.68211

Cumulative Model Updates: 231,000
Cumulative Timesteps: 1,926,605,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.11104
Policy Entropy: 2.21004
Value Function Loss: 0.01823

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.56372
Value Function Update Magnitude: 0.64347

Collected Steps per Second: 22,746.36399
Overall Steps per Second: 10,555.44511

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.53945
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.73822

Cumulative Model Updates: 231,006
Cumulative Timesteps: 1,926,655,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1926655260...
Checkpoint 1926655260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.37856
Policy Entropy: 2.24463
Value Function Loss: 0.01744

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.55216
Value Function Update Magnitude: 0.63268

Collected Steps per Second: 22,423.95565
Overall Steps per Second: 10,575.10856

Timestep Collection Time: 2.23110
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.73092

Cumulative Model Updates: 231,012
Cumulative Timesteps: 1,926,705,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.02826
Policy Entropy: 2.25757
Value Function Loss: 0.01661

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.62446

Collected Steps per Second: 22,220.56441
Overall Steps per Second: 10,520.58510

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.75354

Cumulative Model Updates: 231,018
Cumulative Timesteps: 1,926,755,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1926755300...
Checkpoint 1926755300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.31407
Policy Entropy: 2.22699
Value Function Loss: 0.01625

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.53936
Value Function Update Magnitude: 0.62191

Collected Steps per Second: 21,900.34834
Overall Steps per Second: 10,739.45558

Timestep Collection Time: 2.28343
Timestep Consumption Time: 2.37304
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.65647

Cumulative Model Updates: 231,024
Cumulative Timesteps: 1,926,805,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.63366
Policy Entropy: 2.18639
Value Function Loss: 0.01725

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.62297

Collected Steps per Second: 21,583.18705
Overall Steps per Second: 10,324.61798

Timestep Collection Time: 2.31745
Timestep Consumption Time: 2.52709
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.84454

Cumulative Model Updates: 231,030
Cumulative Timesteps: 1,926,855,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1926855326...
Checkpoint 1926855326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.46827
Policy Entropy: 2.16372
Value Function Loss: 0.01671

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.63837

Collected Steps per Second: 21,689.28963
Overall Steps per Second: 10,146.25623

Timestep Collection Time: 2.30630
Timestep Consumption Time: 2.62379
PPO Batch Consumption Time: 0.30883
Total Iteration Time: 4.93009

Cumulative Model Updates: 231,036
Cumulative Timesteps: 1,926,905,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.23978
Policy Entropy: 2.18636
Value Function Loss: 0.01698

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.65135

Collected Steps per Second: 21,215.53970
Overall Steps per Second: 10,263.61229

Timestep Collection Time: 2.35723
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.87255

Cumulative Model Updates: 231,042
Cumulative Timesteps: 1,926,955,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1926955358...
Checkpoint 1926955358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.80214
Policy Entropy: 2.18668
Value Function Loss: 0.01700

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.64359

Collected Steps per Second: 22,531.18918
Overall Steps per Second: 10,731.93164

Timestep Collection Time: 2.21986
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.66048

Cumulative Model Updates: 231,048
Cumulative Timesteps: 1,927,005,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.37513
Policy Entropy: 2.19074
Value Function Loss: 0.01749

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.54938
Value Function Update Magnitude: 0.63205

Collected Steps per Second: 23,006.99925
Overall Steps per Second: 10,773.36284

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.46852
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.64238

Cumulative Model Updates: 231,054
Cumulative Timesteps: 1,927,055,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1927055388...
Checkpoint 1927055388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.25149
Policy Entropy: 2.15666
Value Function Loss: 0.01771

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.62495

Collected Steps per Second: 22,126.36530
Overall Steps per Second: 10,502.70430

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.76182

Cumulative Model Updates: 231,060
Cumulative Timesteps: 1,927,105,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.42497
Policy Entropy: 2.15733
Value Function Loss: 0.01846

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.55431
Value Function Update Magnitude: 0.64202

Collected Steps per Second: 21,958.08429
Overall Steps per Second: 10,483.51470

Timestep Collection Time: 2.27798
Timestep Consumption Time: 2.49332
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.77130

Cumulative Model Updates: 231,066
Cumulative Timesteps: 1,927,155,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1927155420...
Checkpoint 1927155420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.86261
Policy Entropy: 2.14973
Value Function Loss: 0.01825

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.66094

Collected Steps per Second: 21,291.69563
Overall Steps per Second: 10,293.10850

Timestep Collection Time: 2.34918
Timestep Consumption Time: 2.51019
PPO Batch Consumption Time: 0.30356
Total Iteration Time: 4.85937

Cumulative Model Updates: 231,072
Cumulative Timesteps: 1,927,205,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69812
Policy Entropy: 2.17310
Value Function Loss: 0.01788

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 21,211.70339
Overall Steps per Second: 10,270.14861

Timestep Collection Time: 2.35785
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.86984

Cumulative Model Updates: 231,078
Cumulative Timesteps: 1,927,255,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1927255452...
Checkpoint 1927255452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.47635
Policy Entropy: 2.17701
Value Function Loss: 0.01814

Mean KL Divergence: 0.02922
SB3 Clip Fraction: 0.16792
Policy Update Magnitude: 0.52753
Value Function Update Magnitude: 0.62962

Collected Steps per Second: 22,335.04696
Overall Steps per Second: 10,355.31491

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.59094
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.83056

Cumulative Model Updates: 231,084
Cumulative Timesteps: 1,927,305,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.23876
Policy Entropy: 2.18483
Value Function Loss: 0.01873

Mean KL Divergence: 0.02808
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.65074

Collected Steps per Second: 21,485.64528
Overall Steps per Second: 10,594.98444

Timestep Collection Time: 2.32862
Timestep Consumption Time: 2.39361
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.72223

Cumulative Model Updates: 231,090
Cumulative Timesteps: 1,927,355,506

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1927355506...
Checkpoint 1927355506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.20946
Policy Entropy: 2.18366
Value Function Loss: 0.01857

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.56339
Value Function Update Magnitude: 0.63705

Collected Steps per Second: 21,799.16818
Overall Steps per Second: 10,385.54256

Timestep Collection Time: 2.29504
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.81727

Cumulative Model Updates: 231,096
Cumulative Timesteps: 1,927,405,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.28106
Policy Entropy: 2.17519
Value Function Loss: 0.01836

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.56608
Value Function Update Magnitude: 0.63260

Collected Steps per Second: 22,778.30154
Overall Steps per Second: 10,529.83385

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.55416
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.74993

Cumulative Model Updates: 231,102
Cumulative Timesteps: 1,927,455,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1927455552...
Checkpoint 1927455552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.04765
Policy Entropy: 2.14388
Value Function Loss: 0.01853

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.56781
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 21,193.42072
Overall Steps per Second: 10,338.48815

Timestep Collection Time: 2.36054
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.83901

Cumulative Model Updates: 231,108
Cumulative Timesteps: 1,927,505,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.38579
Policy Entropy: 2.13917
Value Function Loss: 0.01836

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.56269
Value Function Update Magnitude: 0.63711

Collected Steps per Second: 22,059.93997
Overall Steps per Second: 10,396.24910

Timestep Collection Time: 2.26691
Timestep Consumption Time: 2.54328
PPO Batch Consumption Time: 0.30974
Total Iteration Time: 4.81020

Cumulative Model Updates: 231,114
Cumulative Timesteps: 1,927,555,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1927555588...
Checkpoint 1927555588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.38784
Policy Entropy: 2.14989
Value Function Loss: 0.01704

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.61649

Collected Steps per Second: 22,472.51705
Overall Steps per Second: 10,668.02587

Timestep Collection Time: 2.22521
Timestep Consumption Time: 2.46226
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.68747

Cumulative Model Updates: 231,120
Cumulative Timesteps: 1,927,605,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.87534
Policy Entropy: 2.19273
Value Function Loss: 0.01588

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.53324
Value Function Update Magnitude: 0.58797

Collected Steps per Second: 22,388.62841
Overall Steps per Second: 10,470.27572

Timestep Collection Time: 2.23471
Timestep Consumption Time: 2.54377
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.77848

Cumulative Model Updates: 231,126
Cumulative Timesteps: 1,927,655,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1927655626...
Checkpoint 1927655626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.36594
Policy Entropy: 2.19904
Value Function Loss: 0.01573

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.56467

Collected Steps per Second: 22,215.42307
Overall Steps per Second: 10,381.87879

Timestep Collection Time: 2.25159
Timestep Consumption Time: 2.56642
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.81801

Cumulative Model Updates: 231,132
Cumulative Timesteps: 1,927,705,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.21377
Policy Entropy: 2.21715
Value Function Loss: 0.01669

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.52376
Value Function Update Magnitude: 0.55728

Collected Steps per Second: 21,683.47221
Overall Steps per Second: 10,486.59363

Timestep Collection Time: 2.30627
Timestep Consumption Time: 2.46248
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76876

Cumulative Model Updates: 231,138
Cumulative Timesteps: 1,927,755,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1927755654...
Checkpoint 1927755654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.72228
Policy Entropy: 2.19329
Value Function Loss: 0.01846

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.58088

Collected Steps per Second: 20,566.64640
Overall Steps per Second: 9,998.74026

Timestep Collection Time: 2.43132
Timestep Consumption Time: 2.56971
PPO Batch Consumption Time: 0.30156
Total Iteration Time: 5.00103

Cumulative Model Updates: 231,144
Cumulative Timesteps: 1,927,805,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.68718
Policy Entropy: 2.19918
Value Function Loss: 0.01901

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.60935

Collected Steps per Second: 20,697.01208
Overall Steps per Second: 10,070.53339

Timestep Collection Time: 2.41687
Timestep Consumption Time: 2.55029
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.96716

Cumulative Model Updates: 231,150
Cumulative Timesteps: 1,927,855,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1927855680...
Checkpoint 1927855680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.05223
Policy Entropy: 2.17871
Value Function Loss: 0.01909

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.55442
Value Function Update Magnitude: 0.61971

Collected Steps per Second: 21,273.30777
Overall Steps per Second: 10,202.50645

Timestep Collection Time: 2.35093
Timestep Consumption Time: 2.55101
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.90193

Cumulative Model Updates: 231,156
Cumulative Timesteps: 1,927,905,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.72387
Policy Entropy: 2.17228
Value Function Loss: 0.01786

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.61386

Collected Steps per Second: 22,250.26433
Overall Steps per Second: 10,608.35363

Timestep Collection Time: 2.24860
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.71628

Cumulative Model Updates: 231,162
Cumulative Timesteps: 1,927,955,724

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1927955724...
Checkpoint 1927955724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.05846
Policy Entropy: 2.16642
Value Function Loss: 0.01719

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.61494

Collected Steps per Second: 22,308.23508
Overall Steps per Second: 10,496.07401

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.52317
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.76521

Cumulative Model Updates: 231,168
Cumulative Timesteps: 1,928,005,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.12837
Policy Entropy: 2.16333
Value Function Loss: 0.01732

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.54291
Value Function Update Magnitude: 0.60950

Collected Steps per Second: 22,310.25919
Overall Steps per Second: 10,305.88375

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.61110
PPO Batch Consumption Time: 0.30559
Total Iteration Time: 4.85276

Cumulative Model Updates: 231,174
Cumulative Timesteps: 1,928,055,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1928055752...
Checkpoint 1928055752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.34803
Policy Entropy: 2.15683
Value Function Loss: 0.01791

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.61844

Collected Steps per Second: 20,410.68642
Overall Steps per Second: 10,268.83651

Timestep Collection Time: 2.45077
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.87124

Cumulative Model Updates: 231,180
Cumulative Timesteps: 1,928,105,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.13187
Policy Entropy: 2.18129
Value Function Loss: 0.01696

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.64336

Collected Steps per Second: 20,910.37676
Overall Steps per Second: 10,430.11974

Timestep Collection Time: 2.39240
Timestep Consumption Time: 2.40390
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.79630

Cumulative Model Updates: 231,186
Cumulative Timesteps: 1,928,155,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1928155800...
Checkpoint 1928155800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.28924
Policy Entropy: 2.20885
Value Function Loss: 0.01591

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.63471

Collected Steps per Second: 21,937.08128
Overall Steps per Second: 10,338.96886

Timestep Collection Time: 2.28070
Timestep Consumption Time: 2.55846
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.83917

Cumulative Model Updates: 231,192
Cumulative Timesteps: 1,928,205,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.66135
Policy Entropy: 2.19508
Value Function Loss: 0.01588

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.53302
Value Function Update Magnitude: 0.60473

Collected Steps per Second: 20,634.21820
Overall Steps per Second: 10,066.19901

Timestep Collection Time: 2.42423
Timestep Consumption Time: 2.54508
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.96930

Cumulative Model Updates: 231,198
Cumulative Timesteps: 1,928,255,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1928255854...
Checkpoint 1928255854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.55871
Policy Entropy: 2.17633
Value Function Loss: 0.01740

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.58223

Collected Steps per Second: 20,910.03529
Overall Steps per Second: 10,642.29337

Timestep Collection Time: 2.39330
Timestep Consumption Time: 2.30907
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.70237

Cumulative Model Updates: 231,204
Cumulative Timesteps: 1,928,305,898

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.23548
Policy Entropy: 2.15379
Value Function Loss: 0.01899

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.58169

Collected Steps per Second: 22,627.37249
Overall Steps per Second: 10,494.82170

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.55577
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.76654

Cumulative Model Updates: 231,210
Cumulative Timesteps: 1,928,355,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1928355922...
Checkpoint 1928355922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.91333
Policy Entropy: 2.18017
Value Function Loss: 0.01843

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 22,610.93887
Overall Steps per Second: 10,564.98201

Timestep Collection Time: 2.21273
Timestep Consumption Time: 2.52291
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.73564

Cumulative Model Updates: 231,216
Cumulative Timesteps: 1,928,405,954

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.68267
Policy Entropy: 2.16037
Value Function Loss: 0.01922

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.60376

Collected Steps per Second: 22,659.09859
Overall Steps per Second: 10,526.47886

Timestep Collection Time: 2.20715
Timestep Consumption Time: 2.54392
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.75107

Cumulative Model Updates: 231,222
Cumulative Timesteps: 1,928,455,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1928455966...
Checkpoint 1928455966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.60846
Policy Entropy: 2.13623
Value Function Loss: 0.01944

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 22,218.17717
Overall Steps per Second: 10,586.39955

Timestep Collection Time: 2.25131
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.72493

Cumulative Model Updates: 231,228
Cumulative Timesteps: 1,928,505,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.92650
Policy Entropy: 2.12281
Value Function Loss: 0.01938

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 22,863.87496
Overall Steps per Second: 10,579.23199

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.54020
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.72775

Cumulative Model Updates: 231,234
Cumulative Timesteps: 1,928,556,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1928556002...
Checkpoint 1928556002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.54891
Policy Entropy: 2.16204
Value Function Loss: 0.01868

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.66178

Collected Steps per Second: 22,608.45093
Overall Steps per Second: 10,507.95805

Timestep Collection Time: 2.21156
Timestep Consumption Time: 2.54674
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.75830

Cumulative Model Updates: 231,240
Cumulative Timesteps: 1,928,606,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.78691
Policy Entropy: 2.17434
Value Function Loss: 0.01854

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.65120

Collected Steps per Second: 23,018.30929
Overall Steps per Second: 10,831.36733

Timestep Collection Time: 2.17262
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.61715

Cumulative Model Updates: 231,246
Cumulative Timesteps: 1,928,656,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1928656012...
Checkpoint 1928656012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.30452
Policy Entropy: 2.18424
Value Function Loss: 0.01796

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.65767

Collected Steps per Second: 22,303.04695
Overall Steps per Second: 10,743.26258

Timestep Collection Time: 2.24203
Timestep Consumption Time: 2.41243
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.65445

Cumulative Model Updates: 231,252
Cumulative Timesteps: 1,928,706,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.47344
Policy Entropy: 2.17975
Value Function Loss: 0.01888

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.63767

Collected Steps per Second: 22,453.30598
Overall Steps per Second: 10,499.23960

Timestep Collection Time: 2.22809
Timestep Consumption Time: 2.53683
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.76492

Cumulative Model Updates: 231,258
Cumulative Timesteps: 1,928,756,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1928756044...
Checkpoint 1928756044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.71462
Policy Entropy: 2.18715
Value Function Loss: 0.01810

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.62919

Collected Steps per Second: 22,064.29503
Overall Steps per Second: 10,548.89791

Timestep Collection Time: 2.26656
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.74078

Cumulative Model Updates: 231,264
Cumulative Timesteps: 1,928,806,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.73196
Policy Entropy: 2.19255
Value Function Loss: 0.01778

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.62577

Collected Steps per Second: 22,361.60771
Overall Steps per Second: 10,493.39188

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.52974
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.76643

Cumulative Model Updates: 231,270
Cumulative Timesteps: 1,928,856,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1928856070...
Checkpoint 1928856070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.87406
Policy Entropy: 2.20211
Value Function Loss: 0.01704

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 21,836.46009
Overall Steps per Second: 10,693.88234

Timestep Collection Time: 2.29085
Timestep Consumption Time: 2.38697
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.67781

Cumulative Model Updates: 231,276
Cumulative Timesteps: 1,928,906,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.00154
Policy Entropy: 2.18408
Value Function Loss: 0.01790

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.54433
Value Function Update Magnitude: 0.60555

Collected Steps per Second: 22,269.30071
Overall Steps per Second: 10,439.50953

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.54446
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.78988

Cumulative Model Updates: 231,282
Cumulative Timesteps: 1,928,956,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1928956098...
Checkpoint 1928956098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.65782
Policy Entropy: 2.15396
Value Function Loss: 0.01868

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.62129

Collected Steps per Second: 22,188.00245
Overall Steps per Second: 10,551.87180

Timestep Collection Time: 2.25464
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.74096

Cumulative Model Updates: 231,288
Cumulative Timesteps: 1,929,006,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.72732
Policy Entropy: 2.11960
Value Function Loss: 0.01838

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.63153

Collected Steps per Second: 22,392.54790
Overall Steps per Second: 10,598.05278

Timestep Collection Time: 2.23289
Timestep Consumption Time: 2.48496
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 4.71785

Cumulative Model Updates: 231,294
Cumulative Timesteps: 1,929,056,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1929056124...
Checkpoint 1929056124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.32795
Policy Entropy: 2.14823
Value Function Loss: 0.01823

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.63697

Collected Steps per Second: 22,322.59909
Overall Steps per Second: 10,573.57021

Timestep Collection Time: 2.24069
Timestep Consumption Time: 2.48979
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.73047

Cumulative Model Updates: 231,300
Cumulative Timesteps: 1,929,106,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.50450
Policy Entropy: 2.17200
Value Function Loss: 0.01795

Mean KL Divergence: 0.02872
SB3 Clip Fraction: 0.16760
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.62830

Collected Steps per Second: 16,077.59241
Overall Steps per Second: 9,018.57214

Timestep Collection Time: 3.11266
Timestep Consumption Time: 2.43634
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 5.54899

Cumulative Model Updates: 231,306
Cumulative Timesteps: 1,929,156,186

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1929156186...
Checkpoint 1929156186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.82951
Policy Entropy: 2.18680
Value Function Loss: 0.01783

Mean KL Divergence: 0.02759
SB3 Clip Fraction: 0.15986
Policy Update Magnitude: 0.48168
Value Function Update Magnitude: 0.60805

Collected Steps per Second: 22,494.90547
Overall Steps per Second: 10,522.59478

Timestep Collection Time: 2.22273
Timestep Consumption Time: 2.52895
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.75168

Cumulative Model Updates: 231,312
Cumulative Timesteps: 1,929,206,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.78949
Policy Entropy: 2.14435
Value Function Loss: 0.01796

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.51217
Value Function Update Magnitude: 0.59299

Collected Steps per Second: 22,809.53405
Overall Steps per Second: 10,952.85311

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.37362
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.56630

Cumulative Model Updates: 231,318
Cumulative Timesteps: 1,929,256,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1929256200...
Checkpoint 1929256200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.57657
Policy Entropy: 2.14073
Value Function Loss: 0.01920

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.16262
Policy Update Magnitude: 0.51936
Value Function Update Magnitude: 0.61384

Collected Steps per Second: 22,831.72465
Overall Steps per Second: 10,662.24644

Timestep Collection Time: 2.19029
Timestep Consumption Time: 2.49991
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.69019

Cumulative Model Updates: 231,324
Cumulative Timesteps: 1,929,306,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.36275
Policy Entropy: 2.14132
Value Function Loss: 0.01972

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 22,842.65872
Overall Steps per Second: 10,676.67733

Timestep Collection Time: 2.18959
Timestep Consumption Time: 2.49502
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.68460

Cumulative Model Updates: 231,330
Cumulative Timesteps: 1,929,356,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1929356224...
Checkpoint 1929356224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.95672
Policy Entropy: 2.18685
Value Function Loss: 0.01818

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.63103

Collected Steps per Second: 22,635.15928
Overall Steps per Second: 10,838.98462

Timestep Collection Time: 2.20931
Timestep Consumption Time: 2.40441
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.61372

Cumulative Model Updates: 231,336
Cumulative Timesteps: 1,929,406,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.78942
Policy Entropy: 2.19604
Value Function Loss: 0.01728

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.62950

Collected Steps per Second: 22,372.39711
Overall Steps per Second: 10,857.54486

Timestep Collection Time: 2.23615
Timestep Consumption Time: 2.37152
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.60767

Cumulative Model Updates: 231,342
Cumulative Timesteps: 1,929,456,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1929456260...
Checkpoint 1929456260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.15886
Policy Entropy: 2.19354
Value Function Loss: 0.01736

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.61972

Collected Steps per Second: 22,131.64523
Overall Steps per Second: 10,636.71079

Timestep Collection Time: 2.25993
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.70221

Cumulative Model Updates: 231,348
Cumulative Timesteps: 1,929,506,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.21772
Policy Entropy: 2.20277
Value Function Loss: 0.01726

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.55199
Value Function Update Magnitude: 0.62046

Collected Steps per Second: 22,585.90603
Overall Steps per Second: 10,559.81885

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.52146
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.73550

Cumulative Model Updates: 231,354
Cumulative Timesteps: 1,929,556,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1929556282...
Checkpoint 1929556282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.22410
Policy Entropy: 2.18618
Value Function Loss: 0.01709

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.63059

Collected Steps per Second: 22,160.86659
Overall Steps per Second: 10,661.21418

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.43454
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.69159

Cumulative Model Updates: 231,360
Cumulative Timesteps: 1,929,606,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.32803
Policy Entropy: 2.19652
Value Function Loss: 0.01624

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.63184

Collected Steps per Second: 22,686.77374
Overall Steps per Second: 10,857.77603

Timestep Collection Time: 2.20454
Timestep Consumption Time: 2.40174
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.60628

Cumulative Model Updates: 231,366
Cumulative Timesteps: 1,929,656,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1929656314...
Checkpoint 1929656314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.58871
Policy Entropy: 2.15712
Value Function Loss: 0.01769

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.54728
Value Function Update Magnitude: 0.64381

Collected Steps per Second: 21,974.63408
Overall Steps per Second: 10,581.08295

Timestep Collection Time: 2.27571
Timestep Consumption Time: 2.45046
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.72617

Cumulative Model Updates: 231,372
Cumulative Timesteps: 1,929,706,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.67614
Policy Entropy: 2.16409
Value Function Loss: 0.01821

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.64988

Collected Steps per Second: 22,678.88591
Overall Steps per Second: 10,569.68635

Timestep Collection Time: 2.20496
Timestep Consumption Time: 2.52612
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.73108

Cumulative Model Updates: 231,378
Cumulative Timesteps: 1,929,756,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1929756328...
Checkpoint 1929756328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.12170
Policy Entropy: 2.15867
Value Function Loss: 0.01871

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.64279

Collected Steps per Second: 22,727.55977
Overall Steps per Second: 10,852.68533

Timestep Collection Time: 2.20112
Timestep Consumption Time: 2.40843
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.60955

Cumulative Model Updates: 231,384
Cumulative Timesteps: 1,929,806,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.55464
Policy Entropy: 2.15672
Value Function Loss: 0.01875

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.56215
Value Function Update Magnitude: 0.63369

Collected Steps per Second: 22,479.55231
Overall Steps per Second: 10,678.10012

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.45981
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.68548

Cumulative Model Updates: 231,390
Cumulative Timesteps: 1,929,856,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1929856386...
Checkpoint 1929856386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.89672
Policy Entropy: 2.15966
Value Function Loss: 0.01772

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.55703
Value Function Update Magnitude: 0.63825

Collected Steps per Second: 22,508.68586
Overall Steps per Second: 10,653.57161

Timestep Collection Time: 2.22154
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.69364

Cumulative Model Updates: 231,396
Cumulative Timesteps: 1,929,906,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.90802
Policy Entropy: 2.14818
Value Function Loss: 0.01795

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.63181

Collected Steps per Second: 22,738.15816
Overall Steps per Second: 10,800.36249

Timestep Collection Time: 2.19956
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.63077

Cumulative Model Updates: 231,402
Cumulative Timesteps: 1,929,956,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1929956404...
Checkpoint 1929956404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.27243
Policy Entropy: 2.15327
Value Function Loss: 0.01722

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.62080

Collected Steps per Second: 21,378.85813
Overall Steps per Second: 10,448.32545

Timestep Collection Time: 2.33960
Timestep Consumption Time: 2.44758
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.78718

Cumulative Model Updates: 231,408
Cumulative Timesteps: 1,930,006,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.94334
Policy Entropy: 2.16218
Value Function Loss: 0.01744

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.55114
Value Function Update Magnitude: 0.60584

Collected Steps per Second: 22,472.94942
Overall Steps per Second: 10,703.22638

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.44659
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.67149

Cumulative Model Updates: 231,414
Cumulative Timesteps: 1,930,056,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1930056422...
Checkpoint 1930056422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.79693
Policy Entropy: 2.16238
Value Function Loss: 0.01765

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.59807

Collected Steps per Second: 21,862.38123
Overall Steps per Second: 10,448.92164

Timestep Collection Time: 2.28841
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.78805

Cumulative Model Updates: 231,420
Cumulative Timesteps: 1,930,106,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.63866
Policy Entropy: 2.16461
Value Function Loss: 0.01781

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.59831

Collected Steps per Second: 22,805.02126
Overall Steps per Second: 10,689.44002

Timestep Collection Time: 2.19267
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67789

Cumulative Model Updates: 231,426
Cumulative Timesteps: 1,930,156,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1930156456...
Checkpoint 1930156456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.48867
Policy Entropy: 2.17374
Value Function Loss: 0.01776

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.54294
Value Function Update Magnitude: 0.60485

Collected Steps per Second: 22,392.04270
Overall Steps per Second: 10,723.02322

Timestep Collection Time: 2.23356
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.66417

Cumulative Model Updates: 231,432
Cumulative Timesteps: 1,930,206,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.82111
Policy Entropy: 2.17404
Value Function Loss: 0.01646

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.61539

Collected Steps per Second: 22,924.05084
Overall Steps per Second: 10,724.47112

Timestep Collection Time: 2.18251
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.66522

Cumulative Model Updates: 231,438
Cumulative Timesteps: 1,930,256,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1930256502...
Checkpoint 1930256502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.74052
Policy Entropy: 2.17312
Value Function Loss: 0.01646

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.53414
Value Function Update Magnitude: 0.62485

Collected Steps per Second: 22,410.47973
Overall Steps per Second: 10,644.18313

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.69890

Cumulative Model Updates: 231,444
Cumulative Timesteps: 1,930,306,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.98108
Policy Entropy: 2.15432
Value Function Loss: 0.01644

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.53888
Value Function Update Magnitude: 0.62284

Collected Steps per Second: 22,751.25565
Overall Steps per Second: 10,676.22414

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.48562
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.68330

Cumulative Model Updates: 231,450
Cumulative Timesteps: 1,930,356,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1930356518...
Checkpoint 1930356518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.53156
Policy Entropy: 2.15106
Value Function Loss: 0.01741

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.61578

Collected Steps per Second: 23,589.68346
Overall Steps per Second: 10,977.33245

Timestep Collection Time: 2.12016
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.55612

Cumulative Model Updates: 231,456
Cumulative Timesteps: 1,930,406,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.70720
Policy Entropy: 2.13939
Value Function Loss: 0.01669

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.61987

Collected Steps per Second: 22,792.27878
Overall Steps per Second: 10,660.74338

Timestep Collection Time: 2.19469
Timestep Consumption Time: 2.49748
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.69217

Cumulative Model Updates: 231,462
Cumulative Timesteps: 1,930,456,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1930456554...
Checkpoint 1930456554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.96741
Policy Entropy: 2.15066
Value Function Loss: 0.01694

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.61284

Collected Steps per Second: 22,404.01945
Overall Steps per Second: 10,779.13453

Timestep Collection Time: 2.23290
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.64100

Cumulative Model Updates: 231,468
Cumulative Timesteps: 1,930,506,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.15707
Policy Entropy: 2.17800
Value Function Loss: 0.01731

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 22,056.95283
Overall Steps per Second: 10,632.71340

Timestep Collection Time: 2.26795
Timestep Consumption Time: 2.43678
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.70473

Cumulative Model Updates: 231,474
Cumulative Timesteps: 1,930,556,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1930556604...
Checkpoint 1930556604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.47732
Policy Entropy: 2.18741
Value Function Loss: 0.01802

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.63478

Collected Steps per Second: 22,386.20936
Overall Steps per Second: 10,560.51515

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73727

Cumulative Model Updates: 231,480
Cumulative Timesteps: 1,930,606,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.28525
Policy Entropy: 2.20487
Value Function Loss: 0.01787

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.55238
Value Function Update Magnitude: 0.63776

Collected Steps per Second: 21,561.54622
Overall Steps per Second: 10,460.52759

Timestep Collection Time: 2.31950
Timestep Consumption Time: 2.46152
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.78102

Cumulative Model Updates: 231,486
Cumulative Timesteps: 1,930,656,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1930656644...
Checkpoint 1930656644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.82568
Policy Entropy: 2.20258
Value Function Loss: 0.01720

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.54842
Value Function Update Magnitude: 0.62285

Collected Steps per Second: 22,256.48526
Overall Steps per Second: 10,634.80670

Timestep Collection Time: 2.24726
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.70305

Cumulative Model Updates: 231,492
Cumulative Timesteps: 1,930,706,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.61831
Policy Entropy: 2.19962
Value Function Loss: 0.01719

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.60891

Collected Steps per Second: 22,678.09920
Overall Steps per Second: 10,913.82697

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.37676
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.58171

Cumulative Model Updates: 231,498
Cumulative Timesteps: 1,930,756,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1930756664...
Checkpoint 1930756664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.21525
Policy Entropy: 2.18275
Value Function Loss: 0.01749

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.54017
Value Function Update Magnitude: 0.61142

Collected Steps per Second: 22,872.33481
Overall Steps per Second: 10,647.56764

Timestep Collection Time: 2.18657
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.69704

Cumulative Model Updates: 231,504
Cumulative Timesteps: 1,930,806,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.66399
Policy Entropy: 2.15107
Value Function Loss: 0.01704

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.54408
Value Function Update Magnitude: 0.60868

Collected Steps per Second: 22,792.90510
Overall Steps per Second: 10,640.01279

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.70093

Cumulative Model Updates: 231,510
Cumulative Timesteps: 1,930,856,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1930856694...
Checkpoint 1930856694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.52186
Policy Entropy: 2.17553
Value Function Loss: 0.01763

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.61797

Collected Steps per Second: 22,599.66232
Overall Steps per Second: 10,793.13931

Timestep Collection Time: 2.21348
Timestep Consumption Time: 2.42131
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.63480

Cumulative Model Updates: 231,516
Cumulative Timesteps: 1,930,906,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.95908
Policy Entropy: 2.18354
Value Function Loss: 0.01737

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.62905

Collected Steps per Second: 22,568.44389
Overall Steps per Second: 10,928.51468

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.36150
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.57866

Cumulative Model Updates: 231,522
Cumulative Timesteps: 1,930,956,756

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1930956756...
Checkpoint 1930956756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.67990
Policy Entropy: 2.19415
Value Function Loss: 0.01800

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.55217
Value Function Update Magnitude: 0.64396

Collected Steps per Second: 22,431.74434
Overall Steps per Second: 10,685.16011

Timestep Collection Time: 2.23103
Timestep Consumption Time: 2.45266
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.68369

Cumulative Model Updates: 231,528
Cumulative Timesteps: 1,931,006,802

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.80588
Policy Entropy: 2.17055
Value Function Loss: 0.01778

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.56125
Value Function Update Magnitude: 0.64472

Collected Steps per Second: 22,229.24441
Overall Steps per Second: 10,518.13677

Timestep Collection Time: 2.24938
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.75388

Cumulative Model Updates: 231,534
Cumulative Timesteps: 1,931,056,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1931056804...
Checkpoint 1931056804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.85786
Policy Entropy: 2.15668
Value Function Loss: 0.01777

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.64937

Collected Steps per Second: 22,085.04540
Overall Steps per Second: 10,612.00673

Timestep Collection Time: 2.26425
Timestep Consumption Time: 2.44796
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.71221

Cumulative Model Updates: 231,540
Cumulative Timesteps: 1,931,106,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.46204
Policy Entropy: 2.20851
Value Function Loss: 0.01605

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.65367

Collected Steps per Second: 22,476.37407
Overall Steps per Second: 10,559.73569

Timestep Collection Time: 2.22456
Timestep Consumption Time: 2.51041
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.73497

Cumulative Model Updates: 231,546
Cumulative Timesteps: 1,931,156,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1931156810...
Checkpoint 1931156810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.89137
Policy Entropy: 2.21000
Value Function Loss: 0.01678

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.55551
Value Function Update Magnitude: 0.64112

Collected Steps per Second: 22,529.80106
Overall Steps per Second: 10,555.57989

Timestep Collection Time: 2.21990
Timestep Consumption Time: 2.51825
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.73816

Cumulative Model Updates: 231,552
Cumulative Timesteps: 1,931,206,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.59011
Policy Entropy: 2.22168
Value Function Loss: 0.01635

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.55057
Value Function Update Magnitude: 0.63010

Collected Steps per Second: 21,864.85057
Overall Steps per Second: 10,259.98919

Timestep Collection Time: 2.28769
Timestep Consumption Time: 2.58756
PPO Batch Consumption Time: 0.30680
Total Iteration Time: 4.87525

Cumulative Model Updates: 231,558
Cumulative Timesteps: 1,931,256,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1931256844...
Checkpoint 1931256844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.26672
Policy Entropy: 2.19105
Value Function Loss: 0.01715

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.54432
Value Function Update Magnitude: 0.61266

Collected Steps per Second: 22,260.60787
Overall Steps per Second: 10,726.90841

Timestep Collection Time: 2.24621
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.66136

Cumulative Model Updates: 231,564
Cumulative Timesteps: 1,931,306,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.35115
Policy Entropy: 2.20086
Value Function Loss: 0.01734

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.60315

Collected Steps per Second: 22,983.27613
Overall Steps per Second: 10,619.35453

Timestep Collection Time: 2.17549
Timestep Consumption Time: 2.53289
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.70838

Cumulative Model Updates: 231,570
Cumulative Timesteps: 1,931,356,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1931356846...
Checkpoint 1931356846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.39061
Policy Entropy: 2.19165
Value Function Loss: 0.01795

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.58544

Collected Steps per Second: 22,338.26804
Overall Steps per Second: 10,584.48679

Timestep Collection Time: 2.23831
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.72389

Cumulative Model Updates: 231,576
Cumulative Timesteps: 1,931,406,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.24729
Policy Entropy: 2.17171
Value Function Loss: 0.01740

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.59299

Collected Steps per Second: 22,780.04768
Overall Steps per Second: 10,801.16362

Timestep Collection Time: 2.19534
Timestep Consumption Time: 2.43471
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.63006

Cumulative Model Updates: 231,582
Cumulative Timesteps: 1,931,456,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1931456856...
Checkpoint 1931456856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.14160
Policy Entropy: 2.19522
Value Function Loss: 0.01603

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.59841

Collected Steps per Second: 23,181.82932
Overall Steps per Second: 10,737.12699

Timestep Collection Time: 2.15824
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.65972

Cumulative Model Updates: 231,588
Cumulative Timesteps: 1,931,506,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.09939
Policy Entropy: 2.20021
Value Function Loss: 0.01613

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11733
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.60145

Collected Steps per Second: 22,842.45222
Overall Steps per Second: 10,697.20571

Timestep Collection Time: 2.18899
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.67430

Cumulative Model Updates: 231,594
Cumulative Timesteps: 1,931,556,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1931556890...
Checkpoint 1931556890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.25220
Policy Entropy: 2.20220
Value Function Loss: 0.01568

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.60444

Collected Steps per Second: 22,857.20555
Overall Steps per Second: 10,797.45822

Timestep Collection Time: 2.18758
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.63090

Cumulative Model Updates: 231,600
Cumulative Timesteps: 1,931,606,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.63784
Policy Entropy: 2.18711
Value Function Loss: 0.01624

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.57690

Collected Steps per Second: 22,363.42252
Overall Steps per Second: 10,841.96002

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.37611
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.61208

Cumulative Model Updates: 231,606
Cumulative Timesteps: 1,931,656,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1931656896...
Checkpoint 1931656896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.75462
Policy Entropy: 2.19745
Value Function Loss: 0.01677

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.53608
Value Function Update Magnitude: 0.56973

Collected Steps per Second: 21,901.83087
Overall Steps per Second: 10,466.23447

Timestep Collection Time: 2.28419
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.77994

Cumulative Model Updates: 231,612
Cumulative Timesteps: 1,931,706,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69010
Policy Entropy: 2.19793
Value Function Loss: 0.01761

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.54127
Value Function Update Magnitude: 0.59171

Collected Steps per Second: 22,517.24559
Overall Steps per Second: 10,716.01491

Timestep Collection Time: 2.22070
Timestep Consumption Time: 2.44559
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.66629

Cumulative Model Updates: 231,618
Cumulative Timesteps: 1,931,756,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1931756928...
Checkpoint 1931756928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.91241
Policy Entropy: 2.21683
Value Function Loss: 0.01768

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.61413

Collected Steps per Second: 22,302.85443
Overall Steps per Second: 10,687.38695

Timestep Collection Time: 2.24294
Timestep Consumption Time: 2.43772
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.68066

Cumulative Model Updates: 231,624
Cumulative Timesteps: 1,931,806,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.47724
Policy Entropy: 2.20969
Value Function Loss: 0.01746

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.53857
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 22,611.75538
Overall Steps per Second: 10,841.91487

Timestep Collection Time: 2.21230
Timestep Consumption Time: 2.40164
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.61395

Cumulative Model Updates: 231,630
Cumulative Timesteps: 1,931,856,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1931856976...
Checkpoint 1931856976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.11077
Policy Entropy: 2.20915
Value Function Loss: 0.01855

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.61960

Collected Steps per Second: 22,537.95188
Overall Steps per Second: 10,626.85908

Timestep Collection Time: 2.21848
Timestep Consumption Time: 2.48658
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.70506

Cumulative Model Updates: 231,636
Cumulative Timesteps: 1,931,906,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.87503
Policy Entropy: 2.19441
Value Function Loss: 0.01913

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 22,553.90275
Overall Steps per Second: 10,388.09603

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.59681
PPO Batch Consumption Time: 0.30707
Total Iteration Time: 4.81416

Cumulative Model Updates: 231,642
Cumulative Timesteps: 1,931,956,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1931956986...
Checkpoint 1931956986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.30895
Policy Entropy: 2.19583
Value Function Loss: 0.01891

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.62606

Collected Steps per Second: 22,455.89124
Overall Steps per Second: 10,786.96195

Timestep Collection Time: 2.22659
Timestep Consumption Time: 2.40864
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.63523

Cumulative Model Updates: 231,648
Cumulative Timesteps: 1,932,006,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.76214
Policy Entropy: 2.19784
Value Function Loss: 0.01891

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 22,733.30091
Overall Steps per Second: 10,666.57001

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.48952
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.69017

Cumulative Model Updates: 231,654
Cumulative Timesteps: 1,932,057,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1932057014...
Checkpoint 1932057014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.96516
Policy Entropy: 2.16599
Value Function Loss: 0.01761

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.64800

Collected Steps per Second: 22,632.35776
Overall Steps per Second: 10,758.48711

Timestep Collection Time: 2.20923
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.64749

Cumulative Model Updates: 231,660
Cumulative Timesteps: 1,932,107,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.82828
Policy Entropy: 2.14697
Value Function Loss: 0.01674

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.63617

Collected Steps per Second: 22,210.95022
Overall Steps per Second: 10,585.34490

Timestep Collection Time: 2.25258
Timestep Consumption Time: 2.47395
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.72653

Cumulative Model Updates: 231,666
Cumulative Timesteps: 1,932,157,046

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1932157046...
Checkpoint 1932157046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.63287
Policy Entropy: 2.18092
Value Function Loss: 0.01566

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.60437

Collected Steps per Second: 21,830.22981
Overall Steps per Second: 10,655.44445

Timestep Collection Time: 2.29150
Timestep Consumption Time: 2.40319
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69469

Cumulative Model Updates: 231,672
Cumulative Timesteps: 1,932,207,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.05186
Policy Entropy: 2.19590
Value Function Loss: 0.01593

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.53290
Value Function Update Magnitude: 0.59343

Collected Steps per Second: 22,611.77582
Overall Steps per Second: 10,590.04037

Timestep Collection Time: 2.21230
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.72368

Cumulative Model Updates: 231,678
Cumulative Timesteps: 1,932,257,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1932257094...
Checkpoint 1932257094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.63535
Policy Entropy: 2.20001
Value Function Loss: 0.01594

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.54017
Value Function Update Magnitude: 0.59408

Collected Steps per Second: 22,400.73041
Overall Steps per Second: 10,521.12478

Timestep Collection Time: 2.23350
Timestep Consumption Time: 2.52189
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.75539

Cumulative Model Updates: 231,684
Cumulative Timesteps: 1,932,307,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.19108
Policy Entropy: 2.17722
Value Function Loss: 0.01642

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.61646

Collected Steps per Second: 22,396.90211
Overall Steps per Second: 10,810.19798

Timestep Collection Time: 2.23254
Timestep Consumption Time: 2.39291
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.62545

Cumulative Model Updates: 231,690
Cumulative Timesteps: 1,932,357,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1932357128...
Checkpoint 1932357128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.55542
Policy Entropy: 2.19123
Value Function Loss: 0.01608

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.62529

Collected Steps per Second: 22,722.56062
Overall Steps per Second: 10,727.17718

Timestep Collection Time: 2.20178
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.66386

Cumulative Model Updates: 231,696
Cumulative Timesteps: 1,932,407,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.77615
Policy Entropy: 2.20138
Value Function Loss: 0.01657

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.52883
Value Function Update Magnitude: 0.60667

Collected Steps per Second: 22,886.14375
Overall Steps per Second: 10,783.90538

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.45309
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.63895

Cumulative Model Updates: 231,702
Cumulative Timesteps: 1,932,457,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1932457184...
Checkpoint 1932457184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.84838
Policy Entropy: 2.22652
Value Function Loss: 0.01650

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.53467
Value Function Update Magnitude: 0.59674

Collected Steps per Second: 22,675.42444
Overall Steps per Second: 10,751.61983

Timestep Collection Time: 2.20574
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.65195

Cumulative Model Updates: 231,708
Cumulative Timesteps: 1,932,507,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.52811
Policy Entropy: 2.20607
Value Function Loss: 0.01671

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.59399

Collected Steps per Second: 23,090.88200
Overall Steps per Second: 10,936.02656

Timestep Collection Time: 2.16674
Timestep Consumption Time: 2.40823
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.57497

Cumulative Model Updates: 231,714
Cumulative Timesteps: 1,932,557,232

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1932557232...
Checkpoint 1932557232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.54427
Policy Entropy: 2.17971
Value Function Loss: 0.01785

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.60743

Collected Steps per Second: 22,475.41387
Overall Steps per Second: 10,655.30555

Timestep Collection Time: 2.22554
Timestep Consumption Time: 2.46883
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.69438

Cumulative Model Updates: 231,720
Cumulative Timesteps: 1,932,607,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.79428
Policy Entropy: 2.17254
Value Function Loss: 0.01874

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.14947
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.63022

Collected Steps per Second: 21,870.14103
Overall Steps per Second: 10,450.32218

Timestep Collection Time: 2.28714
Timestep Consumption Time: 2.49932
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.78646

Cumulative Model Updates: 231,726
Cumulative Timesteps: 1,932,657,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1932657272...
Checkpoint 1932657272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.49081
Policy Entropy: 2.19364
Value Function Loss: 0.01811

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.16993
Policy Update Magnitude: 0.52578
Value Function Update Magnitude: 0.62363

Collected Steps per Second: 22,055.03971
Overall Steps per Second: 10,566.75082

Timestep Collection Time: 2.26778
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.73334

Cumulative Model Updates: 231,732
Cumulative Timesteps: 1,932,707,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.65909
Policy Entropy: 2.18618
Value Function Loss: 0.01702

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.15808
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.62150

Collected Steps per Second: 22,108.70202
Overall Steps per Second: 10,661.98036

Timestep Collection Time: 2.26164
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68975

Cumulative Model Updates: 231,738
Cumulative Timesteps: 1,932,757,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1932757290...
Checkpoint 1932757290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.06239
Policy Entropy: 2.17410
Value Function Loss: 0.01569

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.59130

Collected Steps per Second: 22,429.42353
Overall Steps per Second: 10,554.11776

Timestep Collection Time: 2.23055
Timestep Consumption Time: 2.50978
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.74033

Cumulative Model Updates: 231,744
Cumulative Timesteps: 1,932,807,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.20588
Policy Entropy: 2.12192
Value Function Loss: 0.01798

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.14185
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.58248

Collected Steps per Second: 22,343.47791
Overall Steps per Second: 10,522.29798

Timestep Collection Time: 2.23788
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75200

Cumulative Model Updates: 231,750
Cumulative Timesteps: 1,932,857,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1932857322...
Checkpoint 1932857322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.08871
Policy Entropy: 2.17579
Value Function Loss: 0.01815

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.60527

Collected Steps per Second: 22,223.48436
Overall Steps per Second: 10,745.66251

Timestep Collection Time: 2.25014
Timestep Consumption Time: 2.40346
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.65360

Cumulative Model Updates: 231,756
Cumulative Timesteps: 1,932,907,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.10967
Policy Entropy: 2.19340
Value Function Loss: 0.01979

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 23,215.35821
Overall Steps per Second: 10,665.64222

Timestep Collection Time: 2.15452
Timestep Consumption Time: 2.53512
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.68964

Cumulative Model Updates: 231,762
Cumulative Timesteps: 1,932,957,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1932957346...
Checkpoint 1932957346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.00247
Policy Entropy: 2.23441
Value Function Loss: 0.01784

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.53469
Value Function Update Magnitude: 0.59675

Collected Steps per Second: 22,488.46099
Overall Steps per Second: 10,610.18470

Timestep Collection Time: 2.22372
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.71321

Cumulative Model Updates: 231,768
Cumulative Timesteps: 1,933,007,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.91437
Policy Entropy: 2.18830
Value Function Loss: 0.01781

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.60114

Collected Steps per Second: 22,338.78462
Overall Steps per Second: 10,577.12826

Timestep Collection Time: 2.23844
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.72756

Cumulative Model Updates: 231,774
Cumulative Timesteps: 1,933,057,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1933057358...
Checkpoint 1933057358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.40966
Policy Entropy: 2.17725
Value Function Loss: 0.01781

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.54280
Value Function Update Magnitude: 0.60605

Collected Steps per Second: 22,537.11388
Overall Steps per Second: 10,917.13087

Timestep Collection Time: 2.21963
Timestep Consumption Time: 2.36253
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.58216

Cumulative Model Updates: 231,780
Cumulative Timesteps: 1,933,107,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.78493
Policy Entropy: 2.18104
Value Function Loss: 0.01737

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.57853

Collected Steps per Second: 22,887.66934
Overall Steps per Second: 10,651.76150

Timestep Collection Time: 2.18572
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69650

Cumulative Model Updates: 231,786
Cumulative Timesteps: 1,933,157,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1933157408...
Checkpoint 1933157408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.60748
Policy Entropy: 2.21438
Value Function Loss: 0.01689

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.53253
Value Function Update Magnitude: 0.56126

Collected Steps per Second: 22,192.39512
Overall Steps per Second: 10,555.21454

Timestep Collection Time: 2.25365
Timestep Consumption Time: 2.48467
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.73832

Cumulative Model Updates: 231,792
Cumulative Timesteps: 1,933,207,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.23763
Policy Entropy: 2.21439
Value Function Loss: 0.01683

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.53050
Value Function Update Magnitude: 0.57101

Collected Steps per Second: 22,652.60245
Overall Steps per Second: 10,627.37186

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.49868
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70690

Cumulative Model Updates: 231,798
Cumulative Timesteps: 1,933,257,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1933257444...
Checkpoint 1933257444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.79931
Policy Entropy: 2.19089
Value Function Loss: 0.01726

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.58299

Collected Steps per Second: 22,768.88093
Overall Steps per Second: 10,809.98297

Timestep Collection Time: 2.19668
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.62683

Cumulative Model Updates: 231,804
Cumulative Timesteps: 1,933,307,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.64837
Policy Entropy: 2.17371
Value Function Loss: 0.01843

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.54867
Value Function Update Magnitude: 0.58560

Collected Steps per Second: 22,518.51590
Overall Steps per Second: 10,542.53331

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.74516

Cumulative Model Updates: 231,810
Cumulative Timesteps: 1,933,357,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1933357486...
Checkpoint 1933357486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.76569
Policy Entropy: 2.18038
Value Function Loss: 0.01800

Mean KL Divergence: 0.05045
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.59319

Collected Steps per Second: 22,031.05140
Overall Steps per Second: 10,679.32772

Timestep Collection Time: 2.27098
Timestep Consumption Time: 2.41396
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.68494

Cumulative Model Updates: 231,816
Cumulative Timesteps: 1,933,407,518

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.80481
Policy Entropy: 2.19902
Value Function Loss: 0.01787

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.60289

Collected Steps per Second: 22,548.18986
Overall Steps per Second: 10,911.07831

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.36521
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.58287

Cumulative Model Updates: 231,822
Cumulative Timesteps: 1,933,457,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1933457522...
Checkpoint 1933457522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.22926
Policy Entropy: 2.20998
Value Function Loss: 0.01666

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.57925

Collected Steps per Second: 22,812.44715
Overall Steps per Second: 10,651.44346

Timestep Collection Time: 2.19301
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.69683

Cumulative Model Updates: 231,828
Cumulative Timesteps: 1,933,507,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.07195
Policy Entropy: 2.20380
Value Function Loss: 0.01695

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.53360
Value Function Update Magnitude: 0.57078

Collected Steps per Second: 22,962.36031
Overall Steps per Second: 10,804.41861

Timestep Collection Time: 2.17765
Timestep Consumption Time: 2.45046
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.62811

Cumulative Model Updates: 231,834
Cumulative Timesteps: 1,933,557,554

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1933557554...
Checkpoint 1933557554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.91212
Policy Entropy: 2.18960
Value Function Loss: 0.01656

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.53266
Value Function Update Magnitude: 0.58135

Collected Steps per Second: 22,124.63248
Overall Steps per Second: 10,678.33465

Timestep Collection Time: 2.26128
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.68519

Cumulative Model Updates: 231,840
Cumulative Timesteps: 1,933,607,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.43276
Policy Entropy: 2.14868
Value Function Loss: 0.01805

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.53968
Value Function Update Magnitude: 0.58278

Collected Steps per Second: 22,806.81744
Overall Steps per Second: 10,965.61531

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.36776
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.56044

Cumulative Model Updates: 231,846
Cumulative Timesteps: 1,933,657,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1933657592...
Checkpoint 1933657592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.91684
Policy Entropy: 2.16139
Value Function Loss: 0.01723

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.60251

Collected Steps per Second: 22,158.23868
Overall Steps per Second: 10,635.26619

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.70247

Cumulative Model Updates: 231,852
Cumulative Timesteps: 1,933,707,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.91110
Policy Entropy: 2.15863
Value Function Loss: 0.01720

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 22,928.84161
Overall Steps per Second: 10,811.05055

Timestep Collection Time: 2.18144
Timestep Consumption Time: 2.44512
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.62656

Cumulative Model Updates: 231,858
Cumulative Timesteps: 1,933,757,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1933757622...
Checkpoint 1933757622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.35043
Policy Entropy: 2.18023
Value Function Loss: 0.01692

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.60964

Collected Steps per Second: 22,021.71419
Overall Steps per Second: 10,668.06917

Timestep Collection Time: 2.27103
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.68801

Cumulative Model Updates: 231,864
Cumulative Timesteps: 1,933,807,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.14923
Policy Entropy: 2.17852
Value Function Loss: 0.01774

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.55541
Value Function Update Magnitude: 0.59066

Collected Steps per Second: 22,265.89889
Overall Steps per Second: 10,701.46961

Timestep Collection Time: 2.24631
Timestep Consumption Time: 2.42745
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.67375

Cumulative Model Updates: 231,870
Cumulative Timesteps: 1,933,857,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1933857650...
Checkpoint 1933857650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.94038
Policy Entropy: 2.18051
Value Function Loss: 0.01770

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.56640

Collected Steps per Second: 22,135.28245
Overall Steps per Second: 10,434.99560

Timestep Collection Time: 2.25947
Timestep Consumption Time: 2.53344
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.79291

Cumulative Model Updates: 231,876
Cumulative Timesteps: 1,933,907,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.70921
Policy Entropy: 2.20866
Value Function Loss: 0.01709

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.54509

Collected Steps per Second: 22,281.17425
Overall Steps per Second: 10,443.41137

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.54366
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.78771

Cumulative Model Updates: 231,882
Cumulative Timesteps: 1,933,957,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1933957664...
Checkpoint 1933957664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.90502
Policy Entropy: 2.19755
Value Function Loss: 0.01745

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.54094
Value Function Update Magnitude: 0.53136

Collected Steps per Second: 22,098.79999
Overall Steps per Second: 10,583.05828

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.46216
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.72491

Cumulative Model Updates: 231,888
Cumulative Timesteps: 1,934,007,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.56157
Policy Entropy: 2.20252
Value Function Loss: 0.01731

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.54717

Collected Steps per Second: 22,833.06783
Overall Steps per Second: 10,749.31784

Timestep Collection Time: 2.19077
Timestep Consumption Time: 2.46273
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.65350

Cumulative Model Updates: 231,894
Cumulative Timesteps: 1,934,057,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1934057690...
Checkpoint 1934057690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.76742
Policy Entropy: 2.20213
Value Function Loss: 0.01711

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.53471
Value Function Update Magnitude: 0.55417

Collected Steps per Second: 22,520.63236
Overall Steps per Second: 10,542.38817

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.74466

Cumulative Model Updates: 231,900
Cumulative Timesteps: 1,934,107,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.15310
Policy Entropy: 2.21182
Value Function Loss: 0.01651

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.52917
Value Function Update Magnitude: 0.54799

Collected Steps per Second: 23,147.19987
Overall Steps per Second: 10,820.24048

Timestep Collection Time: 2.16035
Timestep Consumption Time: 2.46118
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.62152

Cumulative Model Updates: 231,906
Cumulative Timesteps: 1,934,157,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1934157716...
Checkpoint 1934157716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.46849
Policy Entropy: 2.22317
Value Function Loss: 0.01639

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.51990
Value Function Update Magnitude: 0.57311

Collected Steps per Second: 22,349.53445
Overall Steps per Second: 10,721.52945

Timestep Collection Time: 2.23906
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.66743

Cumulative Model Updates: 231,912
Cumulative Timesteps: 1,934,207,758

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.36471
Policy Entropy: 2.22087
Value Function Loss: 0.01575

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.52760
Value Function Update Magnitude: 0.57710

Collected Steps per Second: 22,959.23403
Overall Steps per Second: 10,937.43037

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.39455
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.57310

Cumulative Model Updates: 231,918
Cumulative Timesteps: 1,934,257,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1934257776...
Checkpoint 1934257776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.37571
Policy Entropy: 2.20506
Value Function Loss: 0.01693

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.53462
Value Function Update Magnitude: 0.58547

Collected Steps per Second: 22,511.56752
Overall Steps per Second: 10,671.23534

Timestep Collection Time: 2.22224
Timestep Consumption Time: 2.46569
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.68793

Cumulative Model Updates: 231,924
Cumulative Timesteps: 1,934,307,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.98631
Policy Entropy: 2.17075
Value Function Loss: 0.01736

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.59121

Collected Steps per Second: 22,941.07182
Overall Steps per Second: 10,807.10251

Timestep Collection Time: 2.18046
Timestep Consumption Time: 2.44817
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.62862

Cumulative Model Updates: 231,930
Cumulative Timesteps: 1,934,357,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1934357824...
Checkpoint 1934357824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.12709
Policy Entropy: 2.17376
Value Function Loss: 0.01743

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.58093

Collected Steps per Second: 21,824.76900
Overall Steps per Second: 10,746.68263

Timestep Collection Time: 2.29217
Timestep Consumption Time: 2.36285
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.65502

Cumulative Model Updates: 231,936
Cumulative Timesteps: 1,934,407,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.09180
Policy Entropy: 2.16672
Value Function Loss: 0.01655

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.58581

Collected Steps per Second: 22,566.22904
Overall Steps per Second: 10,620.35707

Timestep Collection Time: 2.21703
Timestep Consumption Time: 2.49373
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.71076

Cumulative Model Updates: 231,942
Cumulative Timesteps: 1,934,457,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1934457880...
Checkpoint 1934457880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.05247
Policy Entropy: 2.16055
Value Function Loss: 0.01798

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.55440
Value Function Update Magnitude: 0.61163

Collected Steps per Second: 21,955.46424
Overall Steps per Second: 10,442.70756

Timestep Collection Time: 2.27743
Timestep Consumption Time: 2.51079
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.78822

Cumulative Model Updates: 231,948
Cumulative Timesteps: 1,934,507,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.10591
Policy Entropy: 2.12682
Value Function Loss: 0.01861

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,256.70476
Overall Steps per Second: 10,524.28607

Timestep Collection Time: 2.24777
Timestep Consumption Time: 2.50580
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.75358

Cumulative Model Updates: 231,954
Cumulative Timesteps: 1,934,557,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1934557910...
Checkpoint 1934557910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.81030
Policy Entropy: 2.15841
Value Function Loss: 0.01803

Mean KL Divergence: 0.02568
SB3 Clip Fraction: 0.15826
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.61336

Collected Steps per Second: 21,755.60086
Overall Steps per Second: 10,540.30963

Timestep Collection Time: 2.29872
Timestep Consumption Time: 2.44592
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.74464

Cumulative Model Updates: 231,960
Cumulative Timesteps: 1,934,607,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.79472
Policy Entropy: 2.21854
Value Function Loss: 0.01749

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.15709
Policy Update Magnitude: 0.51688
Value Function Update Magnitude: 0.58135

Collected Steps per Second: 22,974.28915
Overall Steps per Second: 10,634.81554

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.52519
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70154

Cumulative Model Updates: 231,966
Cumulative Timesteps: 1,934,657,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1934657920...
Checkpoint 1934657920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.78709
Policy Entropy: 2.22077
Value Function Loss: 0.01753

Mean KL Divergence: 0.02698
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.58623

Collected Steps per Second: 22,809.63410
Overall Steps per Second: 10,566.19527

Timestep Collection Time: 2.19258
Timestep Consumption Time: 2.54063
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.73321

Cumulative Model Updates: 231,972
Cumulative Timesteps: 1,934,707,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.62257
Policy Entropy: 2.18610
Value Function Loss: 0.01780

Mean KL Divergence: 0.02574
SB3 Clip Fraction: 0.16124
Policy Update Magnitude: 0.55954
Value Function Update Magnitude: 0.60365

Collected Steps per Second: 22,961.01262
Overall Steps per Second: 10,801.98920

Timestep Collection Time: 2.17952
Timestep Consumption Time: 2.45333
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.63285

Cumulative Model Updates: 231,978
Cumulative Timesteps: 1,934,757,976

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1934757976...
Checkpoint 1934757976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.62287
Policy Entropy: 2.14767
Value Function Loss: 0.01730

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.59704

Collected Steps per Second: 22,228.37702
Overall Steps per Second: 10,713.35448

Timestep Collection Time: 2.25046
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.66931

Cumulative Model Updates: 231,984
Cumulative Timesteps: 1,934,808,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.09251
Policy Entropy: 2.16873
Value Function Loss: 0.01781

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.55462
Value Function Update Magnitude: 0.58491

Collected Steps per Second: 22,763.21383
Overall Steps per Second: 10,887.17786

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.39651
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.59348

Cumulative Model Updates: 231,990
Cumulative Timesteps: 1,934,858,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1934858010...
Checkpoint 1934858010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.53730
Policy Entropy: 2.19043
Value Function Loss: 0.01784

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.59446

Collected Steps per Second: 22,347.22042
Overall Steps per Second: 10,686.80671

Timestep Collection Time: 2.23804
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.67998

Cumulative Model Updates: 231,996
Cumulative Timesteps: 1,934,908,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.18108
Policy Entropy: 2.23231
Value Function Loss: 0.01825

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.60342

Collected Steps per Second: 22,673.38989
Overall Steps per Second: 10,808.19888

Timestep Collection Time: 2.20664
Timestep Consumption Time: 2.42244
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.62908

Cumulative Model Updates: 232,002
Cumulative Timesteps: 1,934,958,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1934958056...
Checkpoint 1934958056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.64228
Policy Entropy: 2.19767
Value Function Loss: 0.02048

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.56022
Value Function Update Magnitude: 0.62134

Collected Steps per Second: 22,190.46563
Overall Steps per Second: 10,709.52177

Timestep Collection Time: 2.25367
Timestep Consumption Time: 2.41601
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.66968

Cumulative Model Updates: 232,008
Cumulative Timesteps: 1,935,008,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.60342
Policy Entropy: 2.19241
Value Function Loss: 0.01900

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.63324

Collected Steps per Second: 22,265.07647
Overall Steps per Second: 10,473.09371

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.52938
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.77586

Cumulative Model Updates: 232,014
Cumulative Timesteps: 1,935,058,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1935058084...
Checkpoint 1935058084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.51166
Policy Entropy: 2.13518
Value Function Loss: 0.01949

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.56458
Value Function Update Magnitude: 0.63346

Collected Steps per Second: 22,166.52228
Overall Steps per Second: 10,567.24621

Timestep Collection Time: 2.25638
Timestep Consumption Time: 2.47674
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.73312

Cumulative Model Updates: 232,020
Cumulative Timesteps: 1,935,108,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.62976
Policy Entropy: 2.13848
Value Function Loss: 0.01771

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.62282

Collected Steps per Second: 22,716.75269
Overall Steps per Second: 10,611.87975

Timestep Collection Time: 2.20208
Timestep Consumption Time: 2.51189
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.71396

Cumulative Model Updates: 232,026
Cumulative Timesteps: 1,935,158,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1935158124...
Checkpoint 1935158124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.55683
Policy Entropy: 2.12348
Value Function Loss: 0.01814

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.56691
Value Function Update Magnitude: 0.60881

Collected Steps per Second: 22,372.39231
Overall Steps per Second: 10,747.93190

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.65373

Cumulative Model Updates: 232,032
Cumulative Timesteps: 1,935,208,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.87638
Policy Entropy: 2.14104
Value Function Loss: 0.01780

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.57375

Collected Steps per Second: 23,046.82725
Overall Steps per Second: 10,692.78179

Timestep Collection Time: 2.16958
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.67624

Cumulative Model Updates: 232,038
Cumulative Timesteps: 1,935,258,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1935258144...
Checkpoint 1935258144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.59848
Policy Entropy: 2.14844
Value Function Loss: 0.01772

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.55493
Value Function Update Magnitude: 0.56972

Collected Steps per Second: 22,239.75991
Overall Steps per Second: 10,695.93684

Timestep Collection Time: 2.24912
Timestep Consumption Time: 2.42742
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.67654

Cumulative Model Updates: 232,044
Cumulative Timesteps: 1,935,308,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.91041
Policy Entropy: 2.14667
Value Function Loss: 0.01805

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.55478
Value Function Update Magnitude: 0.58784

Collected Steps per Second: 22,961.39162
Overall Steps per Second: 10,903.90438

Timestep Collection Time: 2.17870
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.58790

Cumulative Model Updates: 232,050
Cumulative Timesteps: 1,935,358,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1935358190...
Checkpoint 1935358190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.06872
Policy Entropy: 2.15371
Value Function Loss: 0.01751

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.59004

Collected Steps per Second: 22,369.30729
Overall Steps per Second: 10,618.11822

Timestep Collection Time: 2.23565
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.70987

Cumulative Model Updates: 232,056
Cumulative Timesteps: 1,935,408,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.12104
Policy Entropy: 2.16405
Value Function Loss: 0.01810

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.58509

Collected Steps per Second: 23,136.69165
Overall Steps per Second: 10,828.04152

Timestep Collection Time: 2.16237
Timestep Consumption Time: 2.45804
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.62041

Cumulative Model Updates: 232,062
Cumulative Timesteps: 1,935,458,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1935458230...
Checkpoint 1935458230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.60650
Policy Entropy: 2.18273
Value Function Loss: 0.01824

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.55409
Value Function Update Magnitude: 0.59470

Collected Steps per Second: 21,810.76718
Overall Steps per Second: 10,440.22765

Timestep Collection Time: 2.29355
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.79147

Cumulative Model Updates: 232,068
Cumulative Timesteps: 1,935,508,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.21273
Policy Entropy: 2.18086
Value Function Loss: 0.01854

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.57566

Collected Steps per Second: 22,787.19411
Overall Steps per Second: 10,747.50759

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.45822
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.65261

Cumulative Model Updates: 232,074
Cumulative Timesteps: 1,935,558,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1935558258...
Checkpoint 1935558258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.59395
Policy Entropy: 2.19834
Value Function Loss: 0.01843

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.55495
Value Function Update Magnitude: 0.57222

Collected Steps per Second: 21,890.00426
Overall Steps per Second: 10,593.61128

Timestep Collection Time: 2.28433
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.72020

Cumulative Model Updates: 232,080
Cumulative Timesteps: 1,935,608,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.00633
Policy Entropy: 2.18148
Value Function Loss: 0.01846

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.55707
Value Function Update Magnitude: 0.58714

Collected Steps per Second: 23,763.44962
Overall Steps per Second: 10,883.86105

Timestep Collection Time: 2.10458
Timestep Consumption Time: 2.49048
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.59506

Cumulative Model Updates: 232,086
Cumulative Timesteps: 1,935,658,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1935658274...
Checkpoint 1935658274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.88811
Policy Entropy: 2.18787
Value Function Loss: 0.01811

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.56170
Value Function Update Magnitude: 0.61015

Collected Steps per Second: 22,445.94279
Overall Steps per Second: 10,660.14795

Timestep Collection Time: 2.22864
Timestep Consumption Time: 2.46397
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.69262

Cumulative Model Updates: 232,092
Cumulative Timesteps: 1,935,708,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.71638
Policy Entropy: 2.19306
Value Function Loss: 0.01919

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.56888
Value Function Update Magnitude: 0.63262

Collected Steps per Second: 22,073.86655
Overall Steps per Second: 10,444.16564

Timestep Collection Time: 2.26576
Timestep Consumption Time: 2.52295
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.78870

Cumulative Model Updates: 232,098
Cumulative Timesteps: 1,935,758,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1935758312...
Checkpoint 1935758312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.56536
Policy Entropy: 2.18520
Value Function Loss: 0.01888

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.64364

Collected Steps per Second: 21,760.17915
Overall Steps per Second: 10,742.20447

Timestep Collection Time: 2.29778
Timestep Consumption Time: 2.35676
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.65454

Cumulative Model Updates: 232,104
Cumulative Timesteps: 1,935,808,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.27711
Policy Entropy: 2.19342
Value Function Loss: 0.01894

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.63598

Collected Steps per Second: 23,216.18655
Overall Steps per Second: 10,848.62080

Timestep Collection Time: 2.15384
Timestep Consumption Time: 2.45541
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.60925

Cumulative Model Updates: 232,110
Cumulative Timesteps: 1,935,858,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1935858316...
Checkpoint 1935858316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.16727
Policy Entropy: 2.19653
Value Function Loss: 0.01843

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.62501

Collected Steps per Second: 22,477.57030
Overall Steps per Second: 10,471.22962

Timestep Collection Time: 2.22488
Timestep Consumption Time: 2.55106
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.77594

Cumulative Model Updates: 232,116
Cumulative Timesteps: 1,935,908,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.75716
Policy Entropy: 2.22284
Value Function Loss: 0.01774

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.60023

Collected Steps per Second: 22,975.98802
Overall Steps per Second: 10,638.60965

Timestep Collection Time: 2.17714
Timestep Consumption Time: 2.52479
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.70193

Cumulative Model Updates: 232,122
Cumulative Timesteps: 1,935,958,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1935958348...
Checkpoint 1935958348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.32288
Policy Entropy: 2.19566
Value Function Loss: 0.01777

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.57349

Collected Steps per Second: 22,454.37236
Overall Steps per Second: 10,751.94892

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.65162

Cumulative Model Updates: 232,128
Cumulative Timesteps: 1,936,008,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.75326
Policy Entropy: 2.18479
Value Function Loss: 0.01685

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.56962

Collected Steps per Second: 23,330.71927
Overall Steps per Second: 10,789.81455

Timestep Collection Time: 2.14404
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.63604

Cumulative Model Updates: 232,134
Cumulative Timesteps: 1,936,058,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1936058384...
Checkpoint 1936058384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.35472
Policy Entropy: 2.19363
Value Function Loss: 0.01586

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.52763
Value Function Update Magnitude: 0.56409

Collected Steps per Second: 22,643.93784
Overall Steps per Second: 10,624.49163

Timestep Collection Time: 2.20845
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.70686

Cumulative Model Updates: 232,140
Cumulative Timesteps: 1,936,108,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.44539
Policy Entropy: 2.20057
Value Function Loss: 0.01713

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.52630
Value Function Update Magnitude: 0.57272

Collected Steps per Second: 22,774.42847
Overall Steps per Second: 10,816.63449

Timestep Collection Time: 2.19606
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.62380

Cumulative Model Updates: 232,146
Cumulative Timesteps: 1,936,158,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1936158406...
Checkpoint 1936158406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.21078
Policy Entropy: 2.22174
Value Function Loss: 0.01664

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.52913
Value Function Update Magnitude: 0.58621

Collected Steps per Second: 22,384.77492
Overall Steps per Second: 10,769.70082

Timestep Collection Time: 2.23509
Timestep Consumption Time: 2.41054
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.64563

Cumulative Model Updates: 232,152
Cumulative Timesteps: 1,936,208,438

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.59991
Policy Entropy: 2.19988
Value Function Loss: 0.01721

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.53160
Value Function Update Magnitude: 0.59876

Collected Steps per Second: 22,683.12914
Overall Steps per Second: 10,652.78697

Timestep Collection Time: 2.20463
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.69436

Cumulative Model Updates: 232,158
Cumulative Timesteps: 1,936,258,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1936258446...
Checkpoint 1936258446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.64161
Policy Entropy: 2.20201
Value Function Loss: 0.01733

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.52661
Value Function Update Magnitude: 0.58062

Collected Steps per Second: 22,176.86060
Overall Steps per Second: 10,457.41905

Timestep Collection Time: 2.25550
Timestep Consumption Time: 2.52770
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.78321

Cumulative Model Updates: 232,164
Cumulative Timesteps: 1,936,308,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.86523
Policy Entropy: 2.19788
Value Function Loss: 0.01868

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.51584
Value Function Update Magnitude: 0.61047

Collected Steps per Second: 22,416.97710
Overall Steps per Second: 10,654.39143

Timestep Collection Time: 2.23152
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.69515

Cumulative Model Updates: 232,170
Cumulative Timesteps: 1,936,358,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1936358490...
Checkpoint 1936358490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.81478
Policy Entropy: 2.20600
Value Function Loss: 0.01790

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.53744
Value Function Update Magnitude: 0.61745

Collected Steps per Second: 22,369.23421
Overall Steps per Second: 10,888.85926

Timestep Collection Time: 2.23772
Timestep Consumption Time: 2.35928
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.59699

Cumulative Model Updates: 232,176
Cumulative Timesteps: 1,936,408,546

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.04027
Policy Entropy: 2.21270
Value Function Loss: 0.01722

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 22,772.43674
Overall Steps per Second: 10,600.68957

Timestep Collection Time: 2.19669
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71894

Cumulative Model Updates: 232,182
Cumulative Timesteps: 1,936,458,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1936458570...
Checkpoint 1936458570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.99199
Policy Entropy: 2.20052
Value Function Loss: 0.01660

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 22,658.06168
Overall Steps per Second: 10,519.19681

Timestep Collection Time: 2.20698
Timestep Consumption Time: 2.54680
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.75379

Cumulative Model Updates: 232,188
Cumulative Timesteps: 1,936,508,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.51579
Policy Entropy: 2.19695
Value Function Loss: 0.01726

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.53313
Value Function Update Magnitude: 0.61243

Collected Steps per Second: 22,868.24313
Overall Steps per Second: 10,834.29745

Timestep Collection Time: 2.18661
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.61534

Cumulative Model Updates: 232,194
Cumulative Timesteps: 1,936,558,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1936558580...
Checkpoint 1936558580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.24081
Policy Entropy: 2.19380
Value Function Loss: 0.01740

Mean KL Divergence: 0.03650
SB3 Clip Fraction: 0.19642
Policy Update Magnitude: 0.48763
Value Function Update Magnitude: 0.60166

Collected Steps per Second: 22,325.60033
Overall Steps per Second: 10,521.46241

Timestep Collection Time: 2.24030
Timestep Consumption Time: 2.51341
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.75371

Cumulative Model Updates: 232,200
Cumulative Timesteps: 1,936,608,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.76467
Policy Entropy: 2.20048
Value Function Loss: 0.01880

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.16838
Policy Update Magnitude: 0.51998
Value Function Update Magnitude: 0.61601

Collected Steps per Second: 23,600.47093
Overall Steps per Second: 10,955.09172

Timestep Collection Time: 2.11920
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.56537

Cumulative Model Updates: 232,206
Cumulative Timesteps: 1,936,658,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1936658610...
Checkpoint 1936658610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.91873
Policy Entropy: 2.16508
Value Function Loss: 0.01813

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.17592
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.62310

Collected Steps per Second: 22,477.14410
Overall Steps per Second: 10,702.72682

Timestep Collection Time: 2.22573
Timestep Consumption Time: 2.44860
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.67432

Cumulative Model Updates: 232,212
Cumulative Timesteps: 1,936,708,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.58935
Policy Entropy: 2.16292
Value Function Loss: 0.01859

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.16527
Policy Update Magnitude: 0.55588
Value Function Update Magnitude: 0.61090

Collected Steps per Second: 22,796.10459
Overall Steps per Second: 10,719.13749

Timestep Collection Time: 2.19388
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.66567

Cumulative Model Updates: 232,218
Cumulative Timesteps: 1,936,758,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1936758650...
Checkpoint 1936758650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.19039
Policy Entropy: 2.14735
Value Function Loss: 0.01932

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.60921

Collected Steps per Second: 22,040.96400
Overall Steps per Second: 10,515.90574

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.75603

Cumulative Model Updates: 232,224
Cumulative Timesteps: 1,936,808,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.48560
Policy Entropy: 2.19425
Value Function Loss: 0.01872

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.58195
Value Function Update Magnitude: 0.60221

Collected Steps per Second: 23,375.90413
Overall Steps per Second: 10,853.96053

Timestep Collection Time: 2.13895
Timestep Consumption Time: 2.46766
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.60661

Cumulative Model Updates: 232,230
Cumulative Timesteps: 1,936,858,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1936858664...
Checkpoint 1936858664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.04080
Policy Entropy: 2.22892
Value Function Loss: 0.01798

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.60076

Collected Steps per Second: 22,263.11252
Overall Steps per Second: 10,559.38828

Timestep Collection Time: 2.24623
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.73588

Cumulative Model Updates: 232,236
Cumulative Timesteps: 1,936,908,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.63639
Policy Entropy: 2.25585
Value Function Loss: 0.01665

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.60035

Collected Steps per Second: 22,820.33889
Overall Steps per Second: 10,514.90794

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.56454
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.75591

Cumulative Model Updates: 232,242
Cumulative Timesteps: 1,936,958,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1936958680...
Checkpoint 1936958680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.92586
Policy Entropy: 2.24044
Value Function Loss: 0.01688

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.53825
Value Function Update Magnitude: 0.58319

Collected Steps per Second: 22,627.13046
Overall Steps per Second: 10,753.72394

Timestep Collection Time: 2.21036
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.65085

Cumulative Model Updates: 232,248
Cumulative Timesteps: 1,937,008,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.27832
Policy Entropy: 2.22560
Value Function Loss: 0.01665

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.57052

Collected Steps per Second: 23,101.30037
Overall Steps per Second: 10,757.37797

Timestep Collection Time: 2.16447
Timestep Consumption Time: 2.48369
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.64816

Cumulative Model Updates: 232,254
Cumulative Timesteps: 1,937,058,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1937058696...
Checkpoint 1937058696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.01288
Policy Entropy: 2.21706
Value Function Loss: 0.01822

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.54464
Value Function Update Magnitude: 0.58840

Collected Steps per Second: 22,358.68878
Overall Steps per Second: 10,683.82709

Timestep Collection Time: 2.23698
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.68147

Cumulative Model Updates: 232,260
Cumulative Timesteps: 1,937,108,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.95897
Policy Entropy: 2.22178
Value Function Loss: 0.01850

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 22,810.84751
Overall Steps per Second: 10,665.72273

Timestep Collection Time: 2.19273
Timestep Consumption Time: 2.49687
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.68960

Cumulative Model Updates: 232,266
Cumulative Timesteps: 1,937,158,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1937158730...
Checkpoint 1937158730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.47506
Policy Entropy: 2.17695
Value Function Loss: 0.01808

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.65710

Collected Steps per Second: 22,940.77192
Overall Steps per Second: 10,878.58660

Timestep Collection Time: 2.18005
Timestep Consumption Time: 2.41724
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.59729

Cumulative Model Updates: 232,272
Cumulative Timesteps: 1,937,208,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.68632
Policy Entropy: 2.16787
Value Function Loss: 0.01755

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.63085

Collected Steps per Second: 22,719.32144
Overall Steps per Second: 10,723.08671

Timestep Collection Time: 2.20147
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.66433

Cumulative Model Updates: 232,278
Cumulative Timesteps: 1,937,258,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1937258758...
Checkpoint 1937258758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.88595
Policy Entropy: 2.15799
Value Function Loss: 0.01739

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.61712

Collected Steps per Second: 21,704.40208
Overall Steps per Second: 10,397.69133

Timestep Collection Time: 2.30497
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.81145

Cumulative Model Updates: 232,284
Cumulative Timesteps: 1,937,308,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.32298
Policy Entropy: 2.19447
Value Function Loss: 0.01715

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.54962
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 22,249.01473
Overall Steps per Second: 10,456.56894

Timestep Collection Time: 2.24756
Timestep Consumption Time: 2.53470
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.78226

Cumulative Model Updates: 232,290
Cumulative Timesteps: 1,937,358,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1937358792...
Checkpoint 1937358792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.77166
Policy Entropy: 2.20287
Value Function Loss: 0.01756

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.54713
Value Function Update Magnitude: 0.61402

Collected Steps per Second: 21,981.87862
Overall Steps per Second: 10,653.92841

Timestep Collection Time: 2.27551
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.69498

Cumulative Model Updates: 232,296
Cumulative Timesteps: 1,937,408,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.96243
Policy Entropy: 2.22999
Value Function Loss: 0.01735

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.59784

Collected Steps per Second: 23,545.31855
Overall Steps per Second: 10,886.28871

Timestep Collection Time: 2.12458
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.59514

Cumulative Model Updates: 232,302
Cumulative Timesteps: 1,937,458,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1937458836...
Checkpoint 1937458836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.32912
Policy Entropy: 2.23587
Value Function Loss: 0.01731

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.59554

Collected Steps per Second: 22,047.61361
Overall Steps per Second: 10,557.17403

Timestep Collection Time: 2.26900
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.73858

Cumulative Model Updates: 232,308
Cumulative Timesteps: 1,937,508,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.81095
Policy Entropy: 2.24326
Value Function Loss: 0.01745

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.53684
Value Function Update Magnitude: 0.59935

Collected Steps per Second: 22,437.73739
Overall Steps per Second: 10,527.53322

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.52197
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75116

Cumulative Model Updates: 232,314
Cumulative Timesteps: 1,937,558,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1937558880...
Checkpoint 1937558880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.74083
Policy Entropy: 2.20391
Value Function Loss: 0.01698

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.60427

Collected Steps per Second: 22,494.66379
Overall Steps per Second: 10,651.90834

Timestep Collection Time: 2.22293
Timestep Consumption Time: 2.47144
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69437

Cumulative Model Updates: 232,320
Cumulative Timesteps: 1,937,608,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.73757
Policy Entropy: 2.19256
Value Function Loss: 0.01639

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.59670

Collected Steps per Second: 23,019.30083
Overall Steps per Second: 10,810.47688

Timestep Collection Time: 2.17261
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.62625

Cumulative Model Updates: 232,326
Cumulative Timesteps: 1,937,658,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1937658896...
Checkpoint 1937658896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.60413
Policy Entropy: 2.17793
Value Function Loss: 0.01725

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.59511

Collected Steps per Second: 22,328.31814
Overall Steps per Second: 10,637.13808

Timestep Collection Time: 2.24038
Timestep Consumption Time: 2.46239
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.70277

Cumulative Model Updates: 232,332
Cumulative Timesteps: 1,937,708,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.51201
Policy Entropy: 2.18019
Value Function Loss: 0.01756

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.60188

Collected Steps per Second: 22,518.32823
Overall Steps per Second: 10,499.22007

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.54184
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.76226

Cumulative Model Updates: 232,338
Cumulative Timesteps: 1,937,758,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1937758920...
Checkpoint 1937758920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.57981
Policy Entropy: 2.19706
Value Function Loss: 0.01747

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.53495
Value Function Update Magnitude: 0.60343

Collected Steps per Second: 22,698.27709
Overall Steps per Second: 10,790.96254

Timestep Collection Time: 2.20378
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.63555

Cumulative Model Updates: 232,344
Cumulative Timesteps: 1,937,808,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.52193
Policy Entropy: 2.20723
Value Function Loss: 0.01621

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.59518

Collected Steps per Second: 23,106.98530
Overall Steps per Second: 10,822.79726

Timestep Collection Time: 2.16428
Timestep Consumption Time: 2.45652
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.62080

Cumulative Model Updates: 232,350
Cumulative Timesteps: 1,937,858,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1937858952...
Checkpoint 1937858952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.75050
Policy Entropy: 2.21450
Value Function Loss: 0.01695

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.58351

Collected Steps per Second: 22,381.89793
Overall Steps per Second: 10,546.61714

Timestep Collection Time: 2.23538
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.74389

Cumulative Model Updates: 232,356
Cumulative Timesteps: 1,937,908,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.39561
Policy Entropy: 2.19504
Value Function Loss: 0.01832

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 22,073.03312
Overall Steps per Second: 10,556.93008

Timestep Collection Time: 2.26639
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.73869

Cumulative Model Updates: 232,362
Cumulative Timesteps: 1,937,959,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1937959010...
Checkpoint 1937959010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.38696
Policy Entropy: 2.20276
Value Function Loss: 0.01856

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.61352

Collected Steps per Second: 22,192.18568
Overall Steps per Second: 10,643.14795

Timestep Collection Time: 2.25422
Timestep Consumption Time: 2.44608
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.70030

Cumulative Model Updates: 232,368
Cumulative Timesteps: 1,938,009,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.97620
Policy Entropy: 2.21209
Value Function Loss: 0.01787

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.54388
Value Function Update Magnitude: 0.61587

Collected Steps per Second: 23,215.81740
Overall Steps per Second: 10,847.91530

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.60936

Cumulative Model Updates: 232,374
Cumulative Timesteps: 1,938,059,038

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1938059038...
Checkpoint 1938059038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.27370
Policy Entropy: 2.19470
Value Function Loss: 0.01876

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.55031
Value Function Update Magnitude: 0.60094

Collected Steps per Second: 22,191.89246
Overall Steps per Second: 10,616.67535

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.71051

Cumulative Model Updates: 232,380
Cumulative Timesteps: 1,938,109,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.25775
Policy Entropy: 2.18603
Value Function Loss: 0.01937

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.56505
Value Function Update Magnitude: 0.60554

Collected Steps per Second: 22,643.98207
Overall Steps per Second: 10,610.54518

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.50550
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71474

Cumulative Model Updates: 232,386
Cumulative Timesteps: 1,938,159,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1938159074...
Checkpoint 1938159074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.29288
Policy Entropy: 2.16686
Value Function Loss: 0.01958

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.64200

Collected Steps per Second: 22,649.74684
Overall Steps per Second: 10,646.68907

Timestep Collection Time: 2.20806
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.69742

Cumulative Model Updates: 232,392
Cumulative Timesteps: 1,938,209,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.98929
Policy Entropy: 2.17463
Value Function Loss: 0.01917

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.56678
Value Function Update Magnitude: 0.67253

Collected Steps per Second: 23,715.86962
Overall Steps per Second: 10,807.93693

Timestep Collection Time: 2.10930
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.62845

Cumulative Model Updates: 232,398
Cumulative Timesteps: 1,938,259,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1938259110...
Checkpoint 1938259110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.50379
Policy Entropy: 2.20067
Value Function Loss: 0.01887

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.67907

Collected Steps per Second: 22,611.84796
Overall Steps per Second: 10,600.89676

Timestep Collection Time: 2.21150
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.71715

Cumulative Model Updates: 232,404
Cumulative Timesteps: 1,938,309,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.51635
Policy Entropy: 2.19802
Value Function Loss: 0.01883

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.64770

Collected Steps per Second: 22,540.15794
Overall Steps per Second: 10,587.96317

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.72499

Cumulative Model Updates: 232,410
Cumulative Timesteps: 1,938,359,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1938359144...
Checkpoint 1938359144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.00357
Policy Entropy: 2.19412
Value Function Loss: 0.01828

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.55257
Value Function Update Magnitude: 0.61642

Collected Steps per Second: 22,778.85651
Overall Steps per Second: 10,956.66838

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.36870
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.56398

Cumulative Model Updates: 232,416
Cumulative Timesteps: 1,938,409,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.76545
Policy Entropy: 2.17791
Value Function Loss: 0.01760

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12186
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 22,383.17903
Overall Steps per Second: 10,503.82520

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.52766
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.76265

Cumulative Model Updates: 232,422
Cumulative Timesteps: 1,938,459,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1938459176...
Checkpoint 1938459176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.50095
Policy Entropy: 2.18962
Value Function Loss: 0.01707

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.54628
Value Function Update Magnitude: 0.62330

Collected Steps per Second: 22,263.55024
Overall Steps per Second: 10,648.19544

Timestep Collection Time: 2.24717
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.69845

Cumulative Model Updates: 232,428
Cumulative Timesteps: 1,938,509,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.21795
Policy Entropy: 2.18342
Value Function Loss: 0.01805

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.63070

Collected Steps per Second: 22,216.01063
Overall Steps per Second: 10,384.09867

Timestep Collection Time: 2.25063
Timestep Consumption Time: 2.56443
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.81505

Cumulative Model Updates: 232,434
Cumulative Timesteps: 1,938,559,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1938559206...
Checkpoint 1938559206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.13627
Policy Entropy: 2.19635
Value Function Loss: 0.01802

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.55129
Value Function Update Magnitude: 0.65139

Collected Steps per Second: 22,375.75300
Overall Steps per Second: 10,597.75756

Timestep Collection Time: 2.23492
Timestep Consumption Time: 2.48381
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.71873

Cumulative Model Updates: 232,440
Cumulative Timesteps: 1,938,609,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.41666
Policy Entropy: 2.19505
Value Function Loss: 0.01870

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.55847
Value Function Update Magnitude: 0.64273

Collected Steps per Second: 22,885.31737
Overall Steps per Second: 10,588.66368

Timestep Collection Time: 2.18516
Timestep Consumption Time: 2.53763
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.72279

Cumulative Model Updates: 232,446
Cumulative Timesteps: 1,938,659,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1938659222...
Checkpoint 1938659222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.45312
Policy Entropy: 2.20557
Value Function Loss: 0.01814

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.63007

Collected Steps per Second: 22,549.46586
Overall Steps per Second: 10,567.86699

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.73511

Cumulative Model Updates: 232,452
Cumulative Timesteps: 1,938,709,262

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.24482
Policy Entropy: 2.20951
Value Function Loss: 0.01711

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.54425
Value Function Update Magnitude: 0.60440

Collected Steps per Second: 22,529.28868
Overall Steps per Second: 10,613.04236

Timestep Collection Time: 2.22058
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.71382

Cumulative Model Updates: 232,458
Cumulative Timesteps: 1,938,759,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1938759290...
Checkpoint 1938759290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.49144
Policy Entropy: 2.18537
Value Function Loss: 0.01712

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.16390
Policy Update Magnitude: 0.52933
Value Function Update Magnitude: 0.58757

Collected Steps per Second: 23,494.98326
Overall Steps per Second: 10,945.59519

Timestep Collection Time: 2.12922
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.57042

Cumulative Model Updates: 232,464
Cumulative Timesteps: 1,938,809,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.15877
Policy Entropy: 2.17235
Value Function Loss: 0.01857

Mean KL Divergence: 0.03282
SB3 Clip Fraction: 0.18793
Policy Update Magnitude: 0.52049
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 22,891.28844
Overall Steps per Second: 10,666.00709

Timestep Collection Time: 2.18520
Timestep Consumption Time: 2.50465
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.68985

Cumulative Model Updates: 232,470
Cumulative Timesteps: 1,938,859,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1938859338...
Checkpoint 1938859338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.87961
Policy Entropy: 2.18560
Value Function Loss: 0.01946

Mean KL Divergence: 0.02975
SB3 Clip Fraction: 0.17575
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.62132

Collected Steps per Second: 22,832.61594
Overall Steps per Second: 10,702.52644

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.67254

Cumulative Model Updates: 232,476
Cumulative Timesteps: 1,938,909,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.60013
Policy Entropy: 2.20506
Value Function Loss: 0.01928

Mean KL Divergence: 0.02768
SB3 Clip Fraction: 0.15992
Policy Update Magnitude: 0.56930
Value Function Update Magnitude: 0.64356

Collected Steps per Second: 22,616.82988
Overall Steps per Second: 10,747.94060

Timestep Collection Time: 2.21172
Timestep Consumption Time: 2.44239
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.65410

Cumulative Model Updates: 232,482
Cumulative Timesteps: 1,938,959,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1938959368...
Checkpoint 1938959368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.37678
Policy Entropy: 2.23567
Value Function Loss: 0.01776

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.55845
Value Function Update Magnitude: 0.61927

Collected Steps per Second: 22,551.00703
Overall Steps per Second: 10,567.10407

Timestep Collection Time: 2.21782
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.73299

Cumulative Model Updates: 232,488
Cumulative Timesteps: 1,939,009,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.32685
Policy Entropy: 2.22211
Value Function Loss: 0.01709

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.54103
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 22,417.04215
Overall Steps per Second: 10,542.77543

Timestep Collection Time: 2.23089
Timestep Consumption Time: 2.51264
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.74353

Cumulative Model Updates: 232,494
Cumulative Timesteps: 1,939,059,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1939059392...
Checkpoint 1939059392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.18077
Policy Entropy: 2.23524
Value Function Loss: 0.01736

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.52978
Value Function Update Magnitude: 0.57160

Collected Steps per Second: 21,962.97878
Overall Steps per Second: 10,540.58254

Timestep Collection Time: 2.27710
Timestep Consumption Time: 2.46760
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.74471

Cumulative Model Updates: 232,500
Cumulative Timesteps: 1,939,109,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.86296
Policy Entropy: 2.19284
Value Function Loss: 0.01900

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53794
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 22,318.89329
Overall Steps per Second: 10,856.88644

Timestep Collection Time: 2.24070
Timestep Consumption Time: 2.36559
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.60629

Cumulative Model Updates: 232,506
Cumulative Timesteps: 1,939,159,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1939159414...
Checkpoint 1939159414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.73822
Policy Entropy: 2.19415
Value Function Loss: 0.01806

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.58789

Collected Steps per Second: 22,475.73208
Overall Steps per Second: 10,693.72369

Timestep Collection Time: 2.22605
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.67863

Cumulative Model Updates: 232,512
Cumulative Timesteps: 1,939,209,446

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.73577
Policy Entropy: 2.19171
Value Function Loss: 0.01788

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.53016
Value Function Update Magnitude: 0.58495

Collected Steps per Second: 22,688.99308
Overall Steps per Second: 10,518.72287

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.55114
PPO Batch Consumption Time: 0.29920
Total Iteration Time: 4.75609

Cumulative Model Updates: 232,518
Cumulative Timesteps: 1,939,259,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1939259474...
Checkpoint 1939259474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.50738
Policy Entropy: 2.20776
Value Function Loss: 0.01739

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.11810
Policy Update Magnitude: 0.54461
Value Function Update Magnitude: 0.60225

Collected Steps per Second: 22,388.86314
Overall Steps per Second: 10,543.79473

Timestep Collection Time: 2.23388
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.74345

Cumulative Model Updates: 232,524
Cumulative Timesteps: 1,939,309,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.48898
Policy Entropy: 2.19450
Value Function Loss: 0.01860

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.62771

Collected Steps per Second: 22,293.68201
Overall Steps per Second: 10,711.01202

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.66828

Cumulative Model Updates: 232,530
Cumulative Timesteps: 1,939,359,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1939359490...
Checkpoint 1939359490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.35068
Policy Entropy: 2.13903
Value Function Loss: 0.01930

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.54989
Value Function Update Magnitude: 0.65458

Collected Steps per Second: 22,946.45472
Overall Steps per Second: 10,820.09749

Timestep Collection Time: 2.17951
Timestep Consumption Time: 2.44263
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.62214

Cumulative Model Updates: 232,536
Cumulative Timesteps: 1,939,409,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.73024
Policy Entropy: 2.16127
Value Function Loss: 0.01849

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.53796
Value Function Update Magnitude: 0.65790

Collected Steps per Second: 22,962.27798
Overall Steps per Second: 10,691.51903

Timestep Collection Time: 2.17879
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.67941

Cumulative Model Updates: 232,542
Cumulative Timesteps: 1,939,459,532

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1939459532...
Checkpoint 1939459532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.67568
Policy Entropy: 2.16615
Value Function Loss: 0.01789

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.63512

Collected Steps per Second: 22,617.82253
Overall Steps per Second: 10,929.65976

Timestep Collection Time: 2.21082
Timestep Consumption Time: 2.36425
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.57507

Cumulative Model Updates: 232,548
Cumulative Timesteps: 1,939,509,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.49531
Policy Entropy: 2.20091
Value Function Loss: 0.01871

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.63192

Collected Steps per Second: 21,954.43929
Overall Steps per Second: 10,436.57350

Timestep Collection Time: 2.27845
Timestep Consumption Time: 2.51451
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.79295

Cumulative Model Updates: 232,554
Cumulative Timesteps: 1,939,559,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1939559558...
Checkpoint 1939559558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.38803
Policy Entropy: 2.18312
Value Function Loss: 0.01854

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.63849

Collected Steps per Second: 21,982.51246
Overall Steps per Second: 10,593.70932

Timestep Collection Time: 2.27490
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.72054

Cumulative Model Updates: 232,560
Cumulative Timesteps: 1,939,609,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.50057
Policy Entropy: 2.19538
Value Function Loss: 0.01838

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.63534

Collected Steps per Second: 22,463.16629
Overall Steps per Second: 10,587.71625

Timestep Collection Time: 2.22693
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.72472

Cumulative Model Updates: 232,566
Cumulative Timesteps: 1,939,659,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1939659590...
Checkpoint 1939659590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.10873
Policy Entropy: 2.18515
Value Function Loss: 0.01809

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.54153
Value Function Update Magnitude: 0.62536

Collected Steps per Second: 22,614.55870
Overall Steps per Second: 10,649.39580

Timestep Collection Time: 2.21211
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.69754

Cumulative Model Updates: 232,572
Cumulative Timesteps: 1,939,709,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.90859
Policy Entropy: 2.15501
Value Function Loss: 0.01885

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.62430

Collected Steps per Second: 23,028.68346
Overall Steps per Second: 10,802.13427

Timestep Collection Time: 2.17207
Timestep Consumption Time: 2.45849
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.63057

Cumulative Model Updates: 232,578
Cumulative Timesteps: 1,939,759,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1939759636...
Checkpoint 1939759636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.04724
Policy Entropy: 2.14785
Value Function Loss: 0.01888

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.55244
Value Function Update Magnitude: 0.61218

Collected Steps per Second: 22,511.36155
Overall Steps per Second: 10,677.77326

Timestep Collection Time: 2.22199
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.68450

Cumulative Model Updates: 232,584
Cumulative Timesteps: 1,939,809,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.64943
Policy Entropy: 2.15549
Value Function Loss: 0.01875

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.55311
Value Function Update Magnitude: 0.60139

Collected Steps per Second: 22,964.94511
Overall Steps per Second: 10,841.30847

Timestep Collection Time: 2.17819
Timestep Consumption Time: 2.43583
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.61402

Cumulative Model Updates: 232,590
Cumulative Timesteps: 1,939,859,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1939859678...
Checkpoint 1939859678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.00287
Policy Entropy: 2.20469
Value Function Loss: 0.01763

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.59484

Collected Steps per Second: 22,249.10111
Overall Steps per Second: 10,729.75350

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.41266
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.65994

Cumulative Model Updates: 232,596
Cumulative Timesteps: 1,939,909,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.09794
Policy Entropy: 2.20650
Value Function Loss: 0.01761

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.61043

Collected Steps per Second: 22,221.49542
Overall Steps per Second: 10,496.05322

Timestep Collection Time: 2.25034
Timestep Consumption Time: 2.51392
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.76427

Cumulative Model Updates: 232,602
Cumulative Timesteps: 1,939,959,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1939959684...
Checkpoint 1939959684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.64144
Policy Entropy: 2.21657
Value Function Loss: 0.01669

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.61313

Collected Steps per Second: 22,618.71341
Overall Steps per Second: 10,562.43275

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.52330
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.73395

Cumulative Model Updates: 232,608
Cumulative Timesteps: 1,940,009,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.11796
Policy Entropy: 2.22297
Value Function Loss: 0.01680

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.52883
Value Function Update Magnitude: 0.60252

Collected Steps per Second: 22,967.46628
Overall Steps per Second: 10,888.68072

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.41503
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.59211

Cumulative Model Updates: 232,614
Cumulative Timesteps: 1,940,059,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1940059688...
Checkpoint 1940059688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.62005
Policy Entropy: 2.23879
Value Function Loss: 0.01660

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.52714
Value Function Update Magnitude: 0.60298

Collected Steps per Second: 22,502.88225
Overall Steps per Second: 10,724.14128

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.66480

Cumulative Model Updates: 232,620
Cumulative Timesteps: 1,940,109,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.85376
Policy Entropy: 2.23225
Value Function Loss: 0.01679

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.53182
Value Function Update Magnitude: 0.59173

Collected Steps per Second: 22,471.52538
Overall Steps per Second: 10,604.97245

Timestep Collection Time: 2.22539
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.71552

Cumulative Model Updates: 232,626
Cumulative Timesteps: 1,940,159,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1940159722...
Checkpoint 1940159722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.83381
Policy Entropy: 2.20854
Value Function Loss: 0.01794

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.59009

Collected Steps per Second: 22,364.21882
Overall Steps per Second: 10,540.37533

Timestep Collection Time: 2.23688
Timestep Consumption Time: 2.50925
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.74613

Cumulative Model Updates: 232,632
Cumulative Timesteps: 1,940,209,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.22357
Policy Entropy: 2.19388
Value Function Loss: 0.01788

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.58598

Collected Steps per Second: 22,108.71371
Overall Steps per Second: 10,551.83850

Timestep Collection Time: 2.26237
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.74022

Cumulative Model Updates: 232,638
Cumulative Timesteps: 1,940,259,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1940259766...
Checkpoint 1940259766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.97294
Policy Entropy: 2.20166
Value Function Loss: 0.01804

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.54220
Value Function Update Magnitude: 0.60484

Collected Steps per Second: 22,034.96622
Overall Steps per Second: 10,689.92792

Timestep Collection Time: 2.27039
Timestep Consumption Time: 2.40953
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.67992

Cumulative Model Updates: 232,644
Cumulative Timesteps: 1,940,309,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.95786
Policy Entropy: 2.18314
Value Function Loss: 0.01754

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.62097

Collected Steps per Second: 22,610.79813
Overall Steps per Second: 10,544.75363

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.53279
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.74625

Cumulative Model Updates: 232,650
Cumulative Timesteps: 1,940,359,842

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1940359842...
Checkpoint 1940359842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.53871
Policy Entropy: 2.18181
Value Function Loss: 0.01790

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.16478
Policy Update Magnitude: 0.52603
Value Function Update Magnitude: 0.62313

Collected Steps per Second: 22,432.02009
Overall Steps per Second: 10,575.42884

Timestep Collection Time: 2.22967
Timestep Consumption Time: 2.49978
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.72945

Cumulative Model Updates: 232,656
Cumulative Timesteps: 1,940,409,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.50414
Policy Entropy: 2.18187
Value Function Loss: 0.01789

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.54416
Value Function Update Magnitude: 0.61687

Collected Steps per Second: 23,037.08927
Overall Steps per Second: 10,832.14150

Timestep Collection Time: 2.17154
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.61829

Cumulative Model Updates: 232,662
Cumulative Timesteps: 1,940,459,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1940459884...
Checkpoint 1940459884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.62458
Policy Entropy: 2.20843
Value Function Loss: 0.01740

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.60240

Collected Steps per Second: 22,322.07812
Overall Steps per Second: 10,688.94086

Timestep Collection Time: 2.24056
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.67904

Cumulative Model Updates: 232,668
Cumulative Timesteps: 1,940,509,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.54799
Policy Entropy: 2.20430
Value Function Loss: 0.01770

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.60910

Collected Steps per Second: 22,911.08047
Overall Steps per Second: 10,641.23402

Timestep Collection Time: 2.18314
Timestep Consumption Time: 2.51726
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.70039

Cumulative Model Updates: 232,674
Cumulative Timesteps: 1,940,559,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1940559916...
Checkpoint 1940559916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.15958
Policy Entropy: 2.21418
Value Function Loss: 0.01774

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.54328
Value Function Update Magnitude: 0.59265

Collected Steps per Second: 22,752.66895
Overall Steps per Second: 10,752.73788

Timestep Collection Time: 2.19807
Timestep Consumption Time: 2.45302
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.65109

Cumulative Model Updates: 232,680
Cumulative Timesteps: 1,940,609,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.67945
Policy Entropy: 2.18827
Value Function Loss: 0.01843

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.59264

Collected Steps per Second: 22,955.35035
Overall Steps per Second: 10,726.45295

Timestep Collection Time: 2.17866
Timestep Consumption Time: 2.48383
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.66249

Cumulative Model Updates: 232,686
Cumulative Timesteps: 1,940,659,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1940659940...
Checkpoint 1940659940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.83676
Policy Entropy: 2.18208
Value Function Loss: 0.01862

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.59824

Collected Steps per Second: 22,460.69569
Overall Steps per Second: 10,889.06299

Timestep Collection Time: 2.22647
Timestep Consumption Time: 2.36603
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.59250

Cumulative Model Updates: 232,692
Cumulative Timesteps: 1,940,709,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.82457
Policy Entropy: 2.19942
Value Function Loss: 0.01886

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.62195

Collected Steps per Second: 22,296.00736
Overall Steps per Second: 10,557.48613

Timestep Collection Time: 2.24345
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.73787

Cumulative Model Updates: 232,698
Cumulative Timesteps: 1,940,759,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1940759968...
Checkpoint 1940759968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.11578
Policy Entropy: 2.21548
Value Function Loss: 0.01885

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.63503

Collected Steps per Second: 21,855.70272
Overall Steps per Second: 10,494.90263

Timestep Collection Time: 2.28837
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.76555

Cumulative Model Updates: 232,704
Cumulative Timesteps: 1,940,809,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.06644
Policy Entropy: 2.24491
Value Function Loss: 0.01835

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.63183

Collected Steps per Second: 22,592.02756
Overall Steps per Second: 10,800.57287

Timestep Collection Time: 2.21414
Timestep Consumption Time: 2.41728
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.63142

Cumulative Model Updates: 232,710
Cumulative Timesteps: 1,940,860,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1940860004...
Checkpoint 1940860004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.17354
Policy Entropy: 2.22257
Value Function Loss: 0.01920

Mean KL Divergence: 0.03384
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.55568
Value Function Update Magnitude: 0.62729

Collected Steps per Second: 22,356.85491
Overall Steps per Second: 10,537.63951

Timestep Collection Time: 2.23779
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.74774

Cumulative Model Updates: 232,716
Cumulative Timesteps: 1,940,910,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.26424
Policy Entropy: 2.23612
Value Function Loss: 0.01821

Mean KL Divergence: 0.03890
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.61886

Collected Steps per Second: 22,889.40026
Overall Steps per Second: 10,732.94535

Timestep Collection Time: 2.18485
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.65949

Cumulative Model Updates: 232,722
Cumulative Timesteps: 1,940,960,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1940960044...
Checkpoint 1940960044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.43842
Policy Entropy: 2.20080
Value Function Loss: 0.01844

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.61352

Collected Steps per Second: 22,389.59343
Overall Steps per Second: 10,765.61547

Timestep Collection Time: 2.23434
Timestep Consumption Time: 2.41249
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.64683

Cumulative Model Updates: 232,728
Cumulative Timesteps: 1,941,010,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.65895
Policy Entropy: 2.19713
Value Function Loss: 0.01808

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.60693

Collected Steps per Second: 23,036.00896
Overall Steps per Second: 10,851.03078

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.61081

Cumulative Model Updates: 232,734
Cumulative Timesteps: 1,941,060,102

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1941060102...
Checkpoint 1941060102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.05697
Policy Entropy: 2.17314
Value Function Loss: 0.01847

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.55659
Value Function Update Magnitude: 0.62574

Collected Steps per Second: 22,382.95733
Overall Steps per Second: 10,703.86140

Timestep Collection Time: 2.23411
Timestep Consumption Time: 2.43766
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.67177

Cumulative Model Updates: 232,740
Cumulative Timesteps: 1,941,110,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.53829
Policy Entropy: 2.18151
Value Function Loss: 0.01881

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.62951

Collected Steps per Second: 23,019.52018
Overall Steps per Second: 10,819.96673

Timestep Collection Time: 2.17207
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.62109

Cumulative Model Updates: 232,746
Cumulative Timesteps: 1,941,160,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1941160108...
Checkpoint 1941160108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.75241
Policy Entropy: 2.18429
Value Function Loss: 0.01971

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.63485

Collected Steps per Second: 22,295.65935
Overall Steps per Second: 10,577.64317

Timestep Collection Time: 2.24304
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.72790

Cumulative Model Updates: 232,752
Cumulative Timesteps: 1,941,210,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.30277
Policy Entropy: 2.17947
Value Function Loss: 0.01871

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.56827
Value Function Update Magnitude: 0.63889

Collected Steps per Second: 23,027.66464
Overall Steps per Second: 10,833.68076

Timestep Collection Time: 2.17217
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.61708

Cumulative Model Updates: 232,758
Cumulative Timesteps: 1,941,260,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1941260138...
Checkpoint 1941260138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.46951
Policy Entropy: 2.18117
Value Function Loss: 0.01868

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.61337

Collected Steps per Second: 22,596.31088
Overall Steps per Second: 10,750.38061

Timestep Collection Time: 2.21293
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.65137

Cumulative Model Updates: 232,764
Cumulative Timesteps: 1,941,310,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.43842
Policy Entropy: 2.20471
Value Function Loss: 0.01792

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.55467
Value Function Update Magnitude: 0.60097

Collected Steps per Second: 22,767.96246
Overall Steps per Second: 10,637.06356

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.70243

Cumulative Model Updates: 232,770
Cumulative Timesteps: 1,941,360,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1941360162...
Checkpoint 1941360162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.51716
Policy Entropy: 2.23538
Value Function Loss: 0.01765

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.59278

Collected Steps per Second: 22,086.14223
Overall Steps per Second: 10,540.25133

Timestep Collection Time: 2.26404
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.74410

Cumulative Model Updates: 232,776
Cumulative Timesteps: 1,941,410,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.46133
Policy Entropy: 2.23477
Value Function Loss: 0.01692

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.53175
Value Function Update Magnitude: 0.57246

Collected Steps per Second: 22,651.10172
Overall Steps per Second: 10,865.52306

Timestep Collection Time: 2.20846
Timestep Consumption Time: 2.39546
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.60392

Cumulative Model Updates: 232,782
Cumulative Timesteps: 1,941,460,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1941460190...
Checkpoint 1941460190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.40607
Policy Entropy: 2.20463
Value Function Loss: 0.01782

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.55394

Collected Steps per Second: 22,444.18524
Overall Steps per Second: 10,624.14651

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.70626

Cumulative Model Updates: 232,788
Cumulative Timesteps: 1,941,510,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.88208
Policy Entropy: 2.20090
Value Function Loss: 0.01793

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.55080

Collected Steps per Second: 22,854.93747
Overall Steps per Second: 10,649.33446

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.50762
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.69550

Cumulative Model Updates: 232,794
Cumulative Timesteps: 1,941,560,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1941560194...
Checkpoint 1941560194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.78546
Policy Entropy: 2.23516
Value Function Loss: 0.01830

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.53406
Value Function Update Magnitude: 0.56206

Collected Steps per Second: 22,180.27361
Overall Steps per Second: 10,472.93133

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.77440

Cumulative Model Updates: 232,800
Cumulative Timesteps: 1,941,610,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.30451
Policy Entropy: 2.27521
Value Function Loss: 0.01673

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.53019
Value Function Update Magnitude: 0.56453

Collected Steps per Second: 22,865.29793
Overall Steps per Second: 10,825.53795

Timestep Collection Time: 2.18759
Timestep Consumption Time: 2.43296
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.62056

Cumulative Model Updates: 232,806
Cumulative Timesteps: 1,941,660,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1941660216...
Checkpoint 1941660216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.43723
Policy Entropy: 2.28030
Value Function Loss: 0.01737

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.57752

Collected Steps per Second: 23,173.53340
Overall Steps per Second: 10,760.80389

Timestep Collection Time: 2.15850
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.64835

Cumulative Model Updates: 232,812
Cumulative Timesteps: 1,941,710,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.97803
Policy Entropy: 2.23272
Value Function Loss: 0.01597

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.52470
Value Function Update Magnitude: 0.58454

Collected Steps per Second: 23,157.36640
Overall Steps per Second: 10,750.96145

Timestep Collection Time: 2.15931
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.65112

Cumulative Model Updates: 232,818
Cumulative Timesteps: 1,941,760,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1941760240...
Checkpoint 1941760240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.94489
Policy Entropy: 2.20159
Value Function Loss: 0.01705

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.53457
Value Function Update Magnitude: 0.57825

Collected Steps per Second: 22,603.38899
Overall Steps per Second: 10,755.39417

Timestep Collection Time: 2.21241
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.64957

Cumulative Model Updates: 232,824
Cumulative Timesteps: 1,941,810,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.15139
Policy Entropy: 2.19571
Value Function Loss: 0.01872

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.55543
Value Function Update Magnitude: 0.59696

Collected Steps per Second: 22,331.28828
Overall Steps per Second: 10,597.06203

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.48027
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.72018

Cumulative Model Updates: 232,830
Cumulative Timesteps: 1,941,860,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1941860268...
Checkpoint 1941860268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.81483
Policy Entropy: 2.20810
Value Function Loss: 0.01919

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.56687
Value Function Update Magnitude: 0.62054

Collected Steps per Second: 23,472.97563
Overall Steps per Second: 10,990.92700

Timestep Collection Time: 2.13122
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.55157

Cumulative Model Updates: 232,836
Cumulative Timesteps: 1,941,910,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.29405
Policy Entropy: 2.20710
Value Function Loss: 0.01893

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.55679
Value Function Update Magnitude: 0.62887

Collected Steps per Second: 22,924.84756
Overall Steps per Second: 10,862.06772

Timestep Collection Time: 2.18191
Timestep Consumption Time: 2.42310
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60502

Cumulative Model Updates: 232,842
Cumulative Timesteps: 1,941,960,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1941960314...
Checkpoint 1941960314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.29238
Policy Entropy: 2.21560
Value Function Loss: 0.01737

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.62595

Collected Steps per Second: 22,788.46560
Overall Steps per Second: 10,711.64450

Timestep Collection Time: 2.19515
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.67006

Cumulative Model Updates: 232,848
Cumulative Timesteps: 1,942,010,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.07593
Policy Entropy: 2.25389
Value Function Loss: 0.01736

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.54183
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 23,123.05769
Overall Steps per Second: 10,870.92928

Timestep Collection Time: 2.16347
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.60181

Cumulative Model Updates: 232,854
Cumulative Timesteps: 1,942,060,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1942060364...
Checkpoint 1942060364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.91255
Policy Entropy: 2.26738
Value Function Loss: 0.01792

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.62559

Collected Steps per Second: 22,495.89170
Overall Steps per Second: 10,741.92933

Timestep Collection Time: 2.22343
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.65633

Cumulative Model Updates: 232,860
Cumulative Timesteps: 1,942,110,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.83198
Policy Entropy: 2.27296
Value Function Loss: 0.01783

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.63463

Collected Steps per Second: 23,153.29770
Overall Steps per Second: 10,916.99816

Timestep Collection Time: 2.16038
Timestep Consumption Time: 2.42146
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.58185

Cumulative Model Updates: 232,866
Cumulative Timesteps: 1,942,160,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1942160402...
Checkpoint 1942160402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.00032
Policy Entropy: 2.25671
Value Function Loss: 0.01763

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.53898
Value Function Update Magnitude: 0.61998

Collected Steps per Second: 23,012.68868
Overall Steps per Second: 10,949.04978

Timestep Collection Time: 2.17376
Timestep Consumption Time: 2.39504
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.56880

Cumulative Model Updates: 232,872
Cumulative Timesteps: 1,942,210,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.40437
Policy Entropy: 2.26636
Value Function Loss: 0.01711

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.53053
Value Function Update Magnitude: 0.60188

Collected Steps per Second: 22,801.53035
Overall Steps per Second: 10,977.37155

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.36360
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.55792

Cumulative Model Updates: 232,878
Cumulative Timesteps: 1,942,260,460

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1942260460...
Checkpoint 1942260460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.32948
Policy Entropy: 2.24355
Value Function Loss: 0.01765

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.53055
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,343.95945
Overall Steps per Second: 10,705.44879

Timestep Collection Time: 2.23810
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.67127

Cumulative Model Updates: 232,884
Cumulative Timesteps: 1,942,310,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.56893
Policy Entropy: 2.25480
Value Function Loss: 0.01712

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.59391

Collected Steps per Second: 23,020.35808
Overall Steps per Second: 10,840.87713

Timestep Collection Time: 2.17216
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61254

Cumulative Model Updates: 232,890
Cumulative Timesteps: 1,942,360,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1942360472...
Checkpoint 1942360472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.62598
Policy Entropy: 2.23777
Value Function Loss: 0.01717

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.61236

Collected Steps per Second: 22,252.95383
Overall Steps per Second: 10,695.39280

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.67585

Cumulative Model Updates: 232,896
Cumulative Timesteps: 1,942,410,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.07371
Policy Entropy: 2.23470
Value Function Loss: 0.01727

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.59964

Collected Steps per Second: 23,106.58896
Overall Steps per Second: 10,868.44598

Timestep Collection Time: 2.16475
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.60231

Cumulative Model Updates: 232,902
Cumulative Timesteps: 1,942,460,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1942460502...
Checkpoint 1942460502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.94804
Policy Entropy: 2.21512
Value Function Loss: 0.01716

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.53613
Value Function Update Magnitude: 0.59997

Collected Steps per Second: 22,454.98265
Overall Steps per Second: 10,626.26418

Timestep Collection Time: 2.22801
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.70815

Cumulative Model Updates: 232,908
Cumulative Timesteps: 1,942,510,532

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.47003
Policy Entropy: 2.22291
Value Function Loss: 0.01778

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.54171
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 23,147.05874
Overall Steps per Second: 10,725.60221

Timestep Collection Time: 2.16097
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.66361

Cumulative Model Updates: 232,914
Cumulative Timesteps: 1,942,560,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1942560552...
Checkpoint 1942560552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.55898
Policy Entropy: 2.25112
Value Function Loss: 0.01782

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.54399
Value Function Update Magnitude: 0.61463

Collected Steps per Second: 22,938.90157
Overall Steps per Second: 10,832.64111

Timestep Collection Time: 2.17988
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.61605

Cumulative Model Updates: 232,920
Cumulative Timesteps: 1,942,610,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.32031
Policy Entropy: 2.26826
Value Function Loss: 0.01675

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.52906
Value Function Update Magnitude: 0.58860

Collected Steps per Second: 23,547.01013
Overall Steps per Second: 10,898.01899

Timestep Collection Time: 2.12426
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.58983

Cumulative Model Updates: 232,926
Cumulative Timesteps: 1,942,660,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1942660576...
Checkpoint 1942660576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.56051
Policy Entropy: 2.25131
Value Function Loss: 0.01715

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.52549
Value Function Update Magnitude: 0.56042

Collected Steps per Second: 22,701.65692
Overall Steps per Second: 10,649.45110

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.49369
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.69714

Cumulative Model Updates: 232,932
Cumulative Timesteps: 1,942,710,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.50361
Policy Entropy: 2.22920
Value Function Loss: 0.01635

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.54762

Collected Steps per Second: 23,353.51182
Overall Steps per Second: 10,951.79923

Timestep Collection Time: 2.14203
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.56765

Cumulative Model Updates: 232,938
Cumulative Timesteps: 1,942,760,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1942760622...
Checkpoint 1942760622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.68295
Policy Entropy: 2.20437
Value Function Loss: 0.01701

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.53062
Value Function Update Magnitude: 0.54212

Collected Steps per Second: 22,407.67712
Overall Steps per Second: 10,762.52558

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.64575

Cumulative Model Updates: 232,944
Cumulative Timesteps: 1,942,810,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.84801
Policy Entropy: 2.21990
Value Function Loss: 0.01682

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.53192
Value Function Update Magnitude: 0.55802

Collected Steps per Second: 22,705.06705
Overall Steps per Second: 10,793.16467

Timestep Collection Time: 2.20286
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.63404

Cumulative Model Updates: 232,950
Cumulative Timesteps: 1,942,860,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1942860638...
Checkpoint 1942860638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.86678
Policy Entropy: 2.20685
Value Function Loss: 0.01822

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.54340
Value Function Update Magnitude: 0.57345

Collected Steps per Second: 22,424.41478
Overall Steps per Second: 10,681.65903

Timestep Collection Time: 2.23043
Timestep Consumption Time: 2.45199
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.68242

Cumulative Model Updates: 232,956
Cumulative Timesteps: 1,942,910,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.51112
Policy Entropy: 2.22131
Value Function Loss: 0.01818

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.53445
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 22,592.30585
Overall Steps per Second: 10,667.20010

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.68914

Cumulative Model Updates: 232,962
Cumulative Timesteps: 1,942,960,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1942960674...
Checkpoint 1942960674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.44389
Policy Entropy: 2.25334
Value Function Loss: 0.01812

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.60112

Collected Steps per Second: 22,371.40668
Overall Steps per Second: 10,774.17861

Timestep Collection Time: 2.23562
Timestep Consumption Time: 2.40640
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.64202

Cumulative Model Updates: 232,968
Cumulative Timesteps: 1,943,010,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.16306
Policy Entropy: 2.25917
Value Function Loss: 0.01723

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.52087
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 23,995.10136
Overall Steps per Second: 10,976.15854

Timestep Collection Time: 2.08384
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.55551

Cumulative Model Updates: 232,974
Cumulative Timesteps: 1,943,060,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1943060690...
Checkpoint 1943060690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.59061
Policy Entropy: 2.24294
Value Function Loss: 0.01799

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.52933
Value Function Update Magnitude: 0.59775

Collected Steps per Second: 22,779.79939
Overall Steps per Second: 10,646.23407

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.69931

Cumulative Model Updates: 232,980
Cumulative Timesteps: 1,943,110,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.78176
Policy Entropy: 2.20361
Value Function Loss: 0.01827

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.61752

Collected Steps per Second: 23,098.75303
Overall Steps per Second: 10,917.64047

Timestep Collection Time: 2.16583
Timestep Consumption Time: 2.41648
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.58231

Cumulative Model Updates: 232,986
Cumulative Timesteps: 1,943,160,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1943160748...
Checkpoint 1943160748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.78596
Policy Entropy: 2.20939
Value Function Loss: 0.01817

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.54134
Value Function Update Magnitude: 0.62249

Collected Steps per Second: 22,723.34500
Overall Steps per Second: 10,879.14614

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.39576
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.59632

Cumulative Model Updates: 232,992
Cumulative Timesteps: 1,943,210,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.89836
Policy Entropy: 2.21621
Value Function Loss: 0.01749

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.62278

Collected Steps per Second: 23,570.28547
Overall Steps per Second: 10,870.59997

Timestep Collection Time: 2.12148
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.59993

Cumulative Model Updates: 232,998
Cumulative Timesteps: 1,943,260,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1943260756...
Checkpoint 1943260756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.73276
Policy Entropy: 2.22994
Value Function Loss: 0.01755

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.62005

Collected Steps per Second: 22,783.27734
Overall Steps per Second: 10,806.26133

Timestep Collection Time: 2.19556
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.62898

Cumulative Model Updates: 233,004
Cumulative Timesteps: 1,943,310,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.19268
Policy Entropy: 2.20508
Value Function Loss: 0.01757

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.62172

Collected Steps per Second: 22,532.21422
Overall Steps per Second: 10,652.39204

Timestep Collection Time: 2.22002
Timestep Consumption Time: 2.47583
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.69585

Cumulative Model Updates: 233,010
Cumulative Timesteps: 1,943,360,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1943360800...
Checkpoint 1943360800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.82580
Policy Entropy: 2.18911
Value Function Loss: 0.01784

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.54715
Value Function Update Magnitude: 0.61684

Collected Steps per Second: 21,509.23814
Overall Steps per Second: 10,533.90227

Timestep Collection Time: 2.32551
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.74848

Cumulative Model Updates: 233,016
Cumulative Timesteps: 1,943,410,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.48618
Policy Entropy: 2.21457
Value Function Loss: 0.01730

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.54313
Value Function Update Magnitude: 0.60352

Collected Steps per Second: 23,030.03289
Overall Steps per Second: 10,821.86427

Timestep Collection Time: 2.17169
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.62157

Cumulative Model Updates: 233,022
Cumulative Timesteps: 1,943,460,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1943460834...
Checkpoint 1943460834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.85747
Policy Entropy: 2.27036
Value Function Loss: 0.01745

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.53598
Value Function Update Magnitude: 0.58755

Collected Steps per Second: 22,468.95650
Overall Steps per Second: 10,667.49720

Timestep Collection Time: 2.22618
Timestep Consumption Time: 2.46283
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.68901

Cumulative Model Updates: 233,028
Cumulative Timesteps: 1,943,510,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.26630
Policy Entropy: 2.30030
Value Function Loss: 0.01716

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.52166
Value Function Update Magnitude: 0.58318

Collected Steps per Second: 23,373.75794
Overall Steps per Second: 10,967.99775

Timestep Collection Time: 2.13915
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.55872

Cumulative Model Updates: 233,034
Cumulative Timesteps: 1,943,560,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1943560854...
Checkpoint 1943560854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.73934
Policy Entropy: 2.29484
Value Function Loss: 0.01713

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.52637
Value Function Update Magnitude: 0.59057

Collected Steps per Second: 22,752.01347
Overall Steps per Second: 10,866.01888

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.40389
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.60150

Cumulative Model Updates: 233,040
Cumulative Timesteps: 1,943,610,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.97895
Policy Entropy: 2.25800
Value Function Loss: 0.01724

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.53322
Value Function Update Magnitude: 0.59690

Collected Steps per Second: 23,478.58462
Overall Steps per Second: 10,824.69205

Timestep Collection Time: 2.12994
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.61981

Cumulative Model Updates: 233,046
Cumulative Timesteps: 1,943,660,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1943660862...
Checkpoint 1943660862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.53999
Policy Entropy: 2.26165
Value Function Loss: 0.01779

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 22,779.61813
Overall Steps per Second: 10,700.56039

Timestep Collection Time: 2.19530
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.67340

Cumulative Model Updates: 233,052
Cumulative Timesteps: 1,943,710,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.90861
Policy Entropy: 2.25695
Value Function Loss: 0.01864

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.54922
Value Function Update Magnitude: 0.59306

Collected Steps per Second: 22,882.66911
Overall Steps per Second: 10,907.90954

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.39944
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.58511

Cumulative Model Updates: 233,058
Cumulative Timesteps: 1,943,760,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1943760884...
Checkpoint 1943760884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.45315
Policy Entropy: 2.26224
Value Function Loss: 0.01833

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.61154

Collected Steps per Second: 22,468.35828
Overall Steps per Second: 10,641.01071

Timestep Collection Time: 2.22642
Timestep Consumption Time: 2.47464
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.70106

Cumulative Model Updates: 233,064
Cumulative Timesteps: 1,943,810,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.29952
Policy Entropy: 2.23252
Value Function Loss: 0.01825

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.60470

Collected Steps per Second: 23,119.93985
Overall Steps per Second: 10,725.26431

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.66245

Cumulative Model Updates: 233,070
Cumulative Timesteps: 1,943,860,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1943860914...
Checkpoint 1943860914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.91576
Policy Entropy: 2.25651
Value Function Loss: 0.01824

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.54186
Value Function Update Magnitude: 0.59293

Collected Steps per Second: 22,512.67322
Overall Steps per Second: 10,586.85818

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.72454

Cumulative Model Updates: 233,076
Cumulative Timesteps: 1,943,910,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.90972
Policy Entropy: 2.25034
Value Function Loss: 0.01857

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.52412
Value Function Update Magnitude: 0.59029

Collected Steps per Second: 23,463.16151
Overall Steps per Second: 10,996.52586

Timestep Collection Time: 2.13202
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.54907

Cumulative Model Updates: 233,082
Cumulative Timesteps: 1,943,960,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1943960956...
Checkpoint 1943960956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.98659
Policy Entropy: 2.29490
Value Function Loss: 0.01842

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.58231

Collected Steps per Second: 22,600.74645
Overall Steps per Second: 10,601.87746

Timestep Collection Time: 2.21364
Timestep Consumption Time: 2.50533
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71898

Cumulative Model Updates: 233,088
Cumulative Timesteps: 1,944,010,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.21378
Policy Entropy: 2.28206
Value Function Loss: 0.01784

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.53575
Value Function Update Magnitude: 0.58512

Collected Steps per Second: 23,463.98843
Overall Steps per Second: 10,945.10785

Timestep Collection Time: 2.13203
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.57063

Cumulative Model Updates: 233,094
Cumulative Timesteps: 1,944,061,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1944061012...
Checkpoint 1944061012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.38859
Policy Entropy: 2.28443
Value Function Loss: 0.01698

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.53355
Value Function Update Magnitude: 0.58081

Collected Steps per Second: 22,488.83684
Overall Steps per Second: 10,609.57889

Timestep Collection Time: 2.22439
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.71498

Cumulative Model Updates: 233,100
Cumulative Timesteps: 1,944,111,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.77939
Policy Entropy: 2.25035
Value Function Loss: 0.01739

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.57660

Collected Steps per Second: 23,307.42439
Overall Steps per Second: 10,938.96909

Timestep Collection Time: 2.14541
Timestep Consumption Time: 2.42577
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.57118

Cumulative Model Updates: 233,106
Cumulative Timesteps: 1,944,161,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1944161040...
Checkpoint 1944161040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.50832
Policy Entropy: 2.22431
Value Function Loss: 0.01761

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.53480
Value Function Update Magnitude: 0.57073

Collected Steps per Second: 22,950.81892
Overall Steps per Second: 10,704.45925

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.67357

Cumulative Model Updates: 233,112
Cumulative Timesteps: 1,944,211,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.95579
Policy Entropy: 2.23161
Value Function Loss: 0.01774

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.57704

Collected Steps per Second: 23,441.26950
Overall Steps per Second: 10,850.89252

Timestep Collection Time: 2.13308
Timestep Consumption Time: 2.47502
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.60810

Cumulative Model Updates: 233,118
Cumulative Timesteps: 1,944,261,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1944261070...
Checkpoint 1944261070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.04727
Policy Entropy: 2.23854
Value Function Loss: 0.01776

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.58367

Collected Steps per Second: 22,367.09058
Overall Steps per Second: 10,597.73591

Timestep Collection Time: 2.23605
Timestep Consumption Time: 2.48326
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.71931

Cumulative Model Updates: 233,124
Cumulative Timesteps: 1,944,311,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.71513
Policy Entropy: 2.23064
Value Function Loss: 0.01835

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.59467

Collected Steps per Second: 22,808.27203
Overall Steps per Second: 10,958.48308

Timestep Collection Time: 2.19227
Timestep Consumption Time: 2.37058
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.56286

Cumulative Model Updates: 233,130
Cumulative Timesteps: 1,944,361,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1944361086...
Checkpoint 1944361086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.43199
Policy Entropy: 2.23541
Value Function Loss: 0.01827

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.52542
Value Function Update Magnitude: 0.61670

Collected Steps per Second: 22,521.39091
Overall Steps per Second: 10,614.46741

Timestep Collection Time: 2.22118
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.71281

Cumulative Model Updates: 233,136
Cumulative Timesteps: 1,944,411,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.85888
Policy Entropy: 2.24206
Value Function Loss: 0.01859

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.53275
Value Function Update Magnitude: 0.61685

Collected Steps per Second: 22,949.90035
Overall Steps per Second: 10,816.11999

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.44534
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62513

Cumulative Model Updates: 233,142
Cumulative Timesteps: 1,944,461,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1944461136...
Checkpoint 1944461136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.50729
Policy Entropy: 2.26888
Value Function Loss: 0.01894

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.54894
Value Function Update Magnitude: 0.60935

Collected Steps per Second: 22,469.18035
Overall Steps per Second: 10,729.97604

Timestep Collection Time: 2.22598
Timestep Consumption Time: 2.43535
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.66133

Cumulative Model Updates: 233,148
Cumulative Timesteps: 1,944,511,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.07428
Policy Entropy: 2.27209
Value Function Loss: 0.01863

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.60117

Collected Steps per Second: 23,354.62356
Overall Steps per Second: 10,945.33190

Timestep Collection Time: 2.14090
Timestep Consumption Time: 2.42725
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.56816

Cumulative Model Updates: 233,154
Cumulative Timesteps: 1,944,561,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1944561152...
Checkpoint 1944561152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.67027
Policy Entropy: 2.27793
Value Function Loss: 0.01780

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.53803
Value Function Update Magnitude: 0.58752

Collected Steps per Second: 23,105.83211
Overall Steps per Second: 10,796.83123

Timestep Collection Time: 2.16422
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.63154

Cumulative Model Updates: 233,160
Cumulative Timesteps: 1,944,611,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.19633
Policy Entropy: 2.28684
Value Function Loss: 0.01785

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.53031
Value Function Update Magnitude: 0.59152

Collected Steps per Second: 23,500.73121
Overall Steps per Second: 10,799.51010

Timestep Collection Time: 2.12819
Timestep Consumption Time: 2.50295
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.63114

Cumulative Model Updates: 233,166
Cumulative Timesteps: 1,944,661,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1944661172...
Checkpoint 1944661172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.35052
Policy Entropy: 2.27444
Value Function Loss: 0.01782

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.53496
Value Function Update Magnitude: 0.61104

Collected Steps per Second: 22,787.27303
Overall Steps per Second: 10,716.78360

Timestep Collection Time: 2.19438
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.66595

Cumulative Model Updates: 233,172
Cumulative Timesteps: 1,944,711,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.50888
Policy Entropy: 2.26051
Value Function Loss: 0.01864

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.63712

Collected Steps per Second: 23,196.96605
Overall Steps per Second: 10,785.26624

Timestep Collection Time: 2.15597
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.63707

Cumulative Model Updates: 233,178
Cumulative Timesteps: 1,944,761,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1944761188...
Checkpoint 1944761188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.92556
Policy Entropy: 2.27147
Value Function Loss: 0.01819

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.64043

Collected Steps per Second: 23,139.88150
Overall Steps per Second: 10,820.93292

Timestep Collection Time: 2.16146
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.62215

Cumulative Model Updates: 233,184
Cumulative Timesteps: 1,944,811,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.62346
Policy Entropy: 2.25203
Value Function Loss: 0.01861

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.61951

Collected Steps per Second: 23,371.63079
Overall Steps per Second: 10,728.54819

Timestep Collection Time: 2.14063
Timestep Consumption Time: 2.52263
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.66326

Cumulative Model Updates: 233,190
Cumulative Timesteps: 1,944,861,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1944861234...
Checkpoint 1944861234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.41341
Policy Entropy: 2.27378
Value Function Loss: 0.01722

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.54150
Value Function Update Magnitude: 0.60196

Collected Steps per Second: 22,226.44946
Overall Steps per Second: 10,605.35166

Timestep Collection Time: 2.25101
Timestep Consumption Time: 2.46661
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.71762

Cumulative Model Updates: 233,196
Cumulative Timesteps: 1,944,911,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.53862
Policy Entropy: 2.24533
Value Function Loss: 0.01798

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.59081

Collected Steps per Second: 22,646.90873
Overall Steps per Second: 10,840.53099

Timestep Collection Time: 2.20895
Timestep Consumption Time: 2.40576
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61472

Cumulative Model Updates: 233,202
Cumulative Timesteps: 1,944,961,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1944961292...
Checkpoint 1944961292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.32640
Policy Entropy: 2.27321
Value Function Loss: 0.01785

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.59657

Collected Steps per Second: 22,512.38951
Overall Steps per Second: 10,740.41609

Timestep Collection Time: 2.22224
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.65792

Cumulative Model Updates: 233,208
Cumulative Timesteps: 1,945,011,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.10295
Policy Entropy: 2.27319
Value Function Loss: 0.01758

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.58482

Collected Steps per Second: 23,533.95505
Overall Steps per Second: 10,888.29506

Timestep Collection Time: 2.12544
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.59392

Cumulative Model Updates: 233,214
Cumulative Timesteps: 1,945,061,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1945061340...
Checkpoint 1945061340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.17163
Policy Entropy: 2.29066
Value Function Loss: 0.01674

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.52490
Value Function Update Magnitude: 0.57804

Collected Steps per Second: 22,529.77250
Overall Steps per Second: 10,637.16576

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.48161
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.70125

Cumulative Model Updates: 233,220
Cumulative Timesteps: 1,945,111,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.18029
Policy Entropy: 2.25830
Value Function Loss: 0.01672

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.51984
Value Function Update Magnitude: 0.57706

Collected Steps per Second: 23,519.58863
Overall Steps per Second: 10,961.41710

Timestep Collection Time: 2.12631
Timestep Consumption Time: 2.43605
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.56237

Cumulative Model Updates: 233,226
Cumulative Timesteps: 1,945,161,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1945161358...
Checkpoint 1945161358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.28594
Policy Entropy: 2.25689
Value Function Loss: 0.01672

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.52748
Value Function Update Magnitude: 0.56655

Collected Steps per Second: 22,702.90145
Overall Steps per Second: 10,632.51204

Timestep Collection Time: 2.20351
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.70500

Cumulative Model Updates: 233,232
Cumulative Timesteps: 1,945,211,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.34075
Policy Entropy: 2.24738
Value Function Loss: 0.01773

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.56324

Collected Steps per Second: 23,432.64391
Overall Steps per Second: 10,893.93008

Timestep Collection Time: 2.13488
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.59210

Cumulative Model Updates: 233,238
Cumulative Timesteps: 1,945,261,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1945261410...
Checkpoint 1945261410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.62521
Policy Entropy: 2.26431
Value Function Loss: 0.01706

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.53514
Value Function Update Magnitude: 0.56323

Collected Steps per Second: 22,571.55065
Overall Steps per Second: 10,614.23501

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.71084

Cumulative Model Updates: 233,244
Cumulative Timesteps: 1,945,311,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.95554
Policy Entropy: 2.24276
Value Function Loss: 0.01862

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.53601
Value Function Update Magnitude: 0.56845

Collected Steps per Second: 22,689.01489
Overall Steps per Second: 10,986.34333

Timestep Collection Time: 2.20389
Timestep Consumption Time: 2.34758
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.55147

Cumulative Model Updates: 233,250
Cumulative Timesteps: 1,945,361,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1945361416...
Checkpoint 1945361416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.66056
Policy Entropy: 2.25220
Value Function Loss: 0.01766

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.58584

Collected Steps per Second: 22,278.00287
Overall Steps per Second: 10,607.82831

Timestep Collection Time: 2.24455
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.71388

Cumulative Model Updates: 233,256
Cumulative Timesteps: 1,945,411,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.30363
Policy Entropy: 2.26492
Value Function Loss: 0.01697

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.52473
Value Function Update Magnitude: 0.60459

Collected Steps per Second: 23,239.32772
Overall Steps per Second: 10,876.99763

Timestep Collection Time: 2.15204
Timestep Consumption Time: 2.44592
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.59796

Cumulative Model Updates: 233,262
Cumulative Timesteps: 1,945,461,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1945461432...
Checkpoint 1945461432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.20823
Policy Entropy: 2.26072
Value Function Loss: 0.01708

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.52897
Value Function Update Magnitude: 0.59577

Collected Steps per Second: 22,187.10940
Overall Steps per Second: 10,632.08353

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.70275

Cumulative Model Updates: 233,268
Cumulative Timesteps: 1,945,511,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.34797
Policy Entropy: 2.24986
Value Function Loss: 0.01701

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.11733
Policy Update Magnitude: 0.52576
Value Function Update Magnitude: 0.59673

Collected Steps per Second: 23,089.58450
Overall Steps per Second: 10,963.57451

Timestep Collection Time: 2.16660
Timestep Consumption Time: 2.39632
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.56293

Cumulative Model Updates: 233,274
Cumulative Timesteps: 1,945,561,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1945561458...
Checkpoint 1945561458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.23717
Policy Entropy: 2.24814
Value Function Loss: 0.01762

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.53225
Value Function Update Magnitude: 0.61018

Collected Steps per Second: 22,980.78376
Overall Steps per Second: 10,699.58772

Timestep Collection Time: 2.17590
Timestep Consumption Time: 2.49755
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.67345

Cumulative Model Updates: 233,280
Cumulative Timesteps: 1,945,611,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.88922
Policy Entropy: 2.26953
Value Function Loss: 0.01683

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.61135

Collected Steps per Second: 23,329.10095
Overall Steps per Second: 10,824.78546

Timestep Collection Time: 2.14410
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.62088

Cumulative Model Updates: 233,286
Cumulative Timesteps: 1,945,661,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1945661482...
Checkpoint 1945661482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.25567
Policy Entropy: 2.27083
Value Function Loss: 0.01711

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.52839
Value Function Update Magnitude: 0.59435

Collected Steps per Second: 22,330.48148
Overall Steps per Second: 10,615.51050

Timestep Collection Time: 2.23981
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.71160

Cumulative Model Updates: 233,292
Cumulative Timesteps: 1,945,711,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.52391
Policy Entropy: 2.27582
Value Function Loss: 0.01638

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.52279
Value Function Update Magnitude: 0.57684

Collected Steps per Second: 24,035.41253
Overall Steps per Second: 10,942.23285

Timestep Collection Time: 2.08060
Timestep Consumption Time: 2.48959
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.57018

Cumulative Model Updates: 233,298
Cumulative Timesteps: 1,945,761,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1945761506...
Checkpoint 1945761506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.23879
Policy Entropy: 2.26435
Value Function Loss: 0.01754

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.52810
Value Function Update Magnitude: 0.57863

Collected Steps per Second: 22,897.52789
Overall Steps per Second: 10,690.10368

Timestep Collection Time: 2.18452
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.67909

Cumulative Model Updates: 233,304
Cumulative Timesteps: 1,945,811,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.74114
Policy Entropy: 2.27256
Value Function Loss: 0.01774

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.53357
Value Function Update Magnitude: 0.58054

Collected Steps per Second: 22,764.20974
Overall Steps per Second: 10,787.36137

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.43999
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.63765

Cumulative Model Updates: 233,310
Cumulative Timesteps: 1,945,861,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1945861554...
Checkpoint 1945861554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.53841
Policy Entropy: 2.24596
Value Function Loss: 0.01856

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.58828

Collected Steps per Second: 22,377.59058
Overall Steps per Second: 10,728.31774

Timestep Collection Time: 2.23465
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.66112

Cumulative Model Updates: 233,316
Cumulative Timesteps: 1,945,911,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.65512
Policy Entropy: 2.25731
Value Function Loss: 0.01750

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.52835
Value Function Update Magnitude: 0.58972

Collected Steps per Second: 23,199.85076
Overall Steps per Second: 10,927.98826

Timestep Collection Time: 2.15544
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.57596

Cumulative Model Updates: 233,322
Cumulative Timesteps: 1,945,961,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1945961566...
Checkpoint 1945961566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.78543
Policy Entropy: 2.24593
Value Function Loss: 0.01812

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.53350
Value Function Update Magnitude: 0.58205

Collected Steps per Second: 22,715.91118
Overall Steps per Second: 10,651.39648

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.49392
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.69572

Cumulative Model Updates: 233,328
Cumulative Timesteps: 1,946,011,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.55367
Policy Entropy: 2.26821
Value Function Loss: 0.01766

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.53005
Value Function Update Magnitude: 0.59369

Collected Steps per Second: 22,991.99152
Overall Steps per Second: 10,832.32517

Timestep Collection Time: 2.17502
Timestep Consumption Time: 2.44153
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.61655

Cumulative Model Updates: 233,334
Cumulative Timesteps: 1,946,061,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1946061590...
Checkpoint 1946061590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.32618
Policy Entropy: 2.26525
Value Function Loss: 0.01790

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.53171
Value Function Update Magnitude: 0.60832

Collected Steps per Second: 22,858.67417
Overall Steps per Second: 10,975.89389

Timestep Collection Time: 2.18823
Timestep Consumption Time: 2.36903
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.55726

Cumulative Model Updates: 233,340
Cumulative Timesteps: 1,946,111,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.59585
Policy Entropy: 2.28898
Value Function Loss: 0.01767

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.52868
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 23,329.50666
Overall Steps per Second: 10,845.04738

Timestep Collection Time: 2.14372
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.61151

Cumulative Model Updates: 233,346
Cumulative Timesteps: 1,946,161,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1946161622...
Checkpoint 1946161622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.93976
Policy Entropy: 2.25747
Value Function Loss: 0.01905

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.53895
Value Function Update Magnitude: 0.61205

Collected Steps per Second: 22,969.30082
Overall Steps per Second: 10,878.92222

Timestep Collection Time: 2.17760
Timestep Consumption Time: 2.42010
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.59770

Cumulative Model Updates: 233,352
Cumulative Timesteps: 1,946,211,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.49150
Policy Entropy: 2.23628
Value Function Loss: 0.01918

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.54709
Value Function Update Magnitude: 0.62477

Collected Steps per Second: 23,277.03977
Overall Steps per Second: 10,917.69583

Timestep Collection Time: 2.14898
Timestep Consumption Time: 2.43275
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.58174

Cumulative Model Updates: 233,358
Cumulative Timesteps: 1,946,261,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1946261662...
Checkpoint 1946261662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.66103
Policy Entropy: 2.22112
Value Function Loss: 0.01904

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.62791

Collected Steps per Second: 22,576.26974
Overall Steps per Second: 10,601.16985

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.50225
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.71740

Cumulative Model Updates: 233,364
Cumulative Timesteps: 1,946,311,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.34633
Policy Entropy: 2.23037
Value Function Loss: 0.01858

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.63062

Collected Steps per Second: 22,795.27414
Overall Steps per Second: 10,669.57490

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.68922

Cumulative Model Updates: 233,370
Cumulative Timesteps: 1,946,361,704

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1946361704...
Checkpoint 1946361704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.62063
Policy Entropy: 2.23257
Value Function Loss: 0.01813

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.62155

Collected Steps per Second: 22,404.29136
Overall Steps per Second: 10,788.79632

Timestep Collection Time: 2.23288
Timestep Consumption Time: 2.40397
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.63685

Cumulative Model Updates: 233,376
Cumulative Timesteps: 1,946,411,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.24617
Policy Entropy: 2.22249
Value Function Loss: 0.01942

Mean KL Divergence: 0.02966
SB3 Clip Fraction: 0.16940
Policy Update Magnitude: 0.51495
Value Function Update Magnitude: 0.61578

Collected Steps per Second: 22,786.34283
Overall Steps per Second: 10,966.49950

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.36618
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.56153

Cumulative Model Updates: 233,382
Cumulative Timesteps: 1,946,461,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1946461754...
Checkpoint 1946461754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.74809
Policy Entropy: 2.23818
Value Function Loss: 0.01833

Mean KL Divergence: 0.02589
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.62126

Collected Steps per Second: 22,675.34024
Overall Steps per Second: 10,663.53908

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.48523
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.69150

Cumulative Model Updates: 233,388
Cumulative Timesteps: 1,946,511,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.39417
Policy Entropy: 2.27109
Value Function Loss: 0.01813

Mean KL Divergence: 0.02577
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.54355
Value Function Update Magnitude: 0.63224

Collected Steps per Second: 23,008.09070
Overall Steps per Second: 10,674.34300

Timestep Collection Time: 2.17350
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.68488

Cumulative Model Updates: 233,394
Cumulative Timesteps: 1,946,561,790

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1946561790...
Checkpoint 1946561790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.24159
Policy Entropy: 2.24029
Value Function Loss: 0.01746

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.15903
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.63000

Collected Steps per Second: 22,908.68691
Overall Steps per Second: 10,900.29179

Timestep Collection Time: 2.18336
Timestep Consumption Time: 2.40532
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.58868

Cumulative Model Updates: 233,400
Cumulative Timesteps: 1,946,611,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.90043
Policy Entropy: 2.21803
Value Function Loss: 0.01835

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 24,189.98775
Overall Steps per Second: 10,938.11910

Timestep Collection Time: 2.06763
Timestep Consumption Time: 2.50500
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.57263

Cumulative Model Updates: 233,406
Cumulative Timesteps: 1,946,661,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1946661824...
Checkpoint 1946661824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.15892
Policy Entropy: 2.18665
Value Function Loss: 0.01923

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.61740

Collected Steps per Second: 22,776.72003
Overall Steps per Second: 10,588.90384

Timestep Collection Time: 2.19628
Timestep Consumption Time: 2.52791
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.72419

Cumulative Model Updates: 233,412
Cumulative Timesteps: 1,946,711,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.04056
Policy Entropy: 2.24244
Value Function Loss: 0.01850

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.61629

Collected Steps per Second: 23,143.46877
Overall Steps per Second: 10,910.88739

Timestep Collection Time: 2.16078
Timestep Consumption Time: 2.42253
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.58331

Cumulative Model Updates: 233,418
Cumulative Timesteps: 1,946,761,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1946761856...
Checkpoint 1946761856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.56183
Policy Entropy: 2.28057
Value Function Loss: 0.01789

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.54164
Value Function Update Magnitude: 0.62296

Collected Steps per Second: 22,730.00429
Overall Steps per Second: 10,643.37615

Timestep Collection Time: 2.20070
Timestep Consumption Time: 2.49912
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.69982

Cumulative Model Updates: 233,424
Cumulative Timesteps: 1,946,811,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.53689
Policy Entropy: 2.29390
Value Function Loss: 0.01790

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.53302
Value Function Update Magnitude: 0.62357

Collected Steps per Second: 22,794.23370
Overall Steps per Second: 10,919.86195

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.38661
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.58138

Cumulative Model Updates: 233,430
Cumulative Timesteps: 1,946,861,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1946861906...
Checkpoint 1946861906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.20936
Policy Entropy: 2.27175
Value Function Loss: 0.01715

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.53093
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 22,175.87780
Overall Steps per Second: 10,687.43582

Timestep Collection Time: 2.25606
Timestep Consumption Time: 2.42514
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.68120

Cumulative Model Updates: 233,436
Cumulative Timesteps: 1,946,911,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.95563
Policy Entropy: 2.25110
Value Function Loss: 0.01853

Mean KL Divergence: 0.02707
SB3 Clip Fraction: 0.16951
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.62244

Collected Steps per Second: 22,873.14976
Overall Steps per Second: 10,789.21808

Timestep Collection Time: 2.18606
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.63444

Cumulative Model Updates: 233,442
Cumulative Timesteps: 1,946,961,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1946961938...
Checkpoint 1946961938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.06520
Policy Entropy: 2.24805
Value Function Loss: 0.01826

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.51335
Value Function Update Magnitude: 0.60649

Collected Steps per Second: 22,321.80109
Overall Steps per Second: 10,690.02939

Timestep Collection Time: 2.24104
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.67950

Cumulative Model Updates: 233,448
Cumulative Timesteps: 1,947,011,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.98654
Policy Entropy: 2.27248
Value Function Loss: 0.01889

Mean KL Divergence: 0.02393
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.51218
Value Function Update Magnitude: 0.60905

Collected Steps per Second: 24,334.19519
Overall Steps per Second: 10,974.42067

Timestep Collection Time: 2.05579
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.55842

Cumulative Model Updates: 233,454
Cumulative Timesteps: 1,947,061,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1947061988...
Checkpoint 1947061988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.19879
Policy Entropy: 2.27406
Value Function Loss: 0.01947

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.16106
Policy Update Magnitude: 0.51059
Value Function Update Magnitude: 0.63350

Collected Steps per Second: 22,275.21378
Overall Steps per Second: 10,578.65411

Timestep Collection Time: 2.24572
Timestep Consumption Time: 2.48304
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.72877

Cumulative Model Updates: 233,460
Cumulative Timesteps: 1,947,112,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.33081
Policy Entropy: 2.27845
Value Function Loss: 0.01962

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.17310
Policy Update Magnitude: 0.53651
Value Function Update Magnitude: 0.64176

Collected Steps per Second: 23,328.63412
Overall Steps per Second: 10,913.15555

Timestep Collection Time: 2.14440
Timestep Consumption Time: 2.43961
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.58401

Cumulative Model Updates: 233,466
Cumulative Timesteps: 1,947,162,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1947162038...
Checkpoint 1947162038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.40375
Policy Entropy: 2.27467
Value Function Loss: 0.01803

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.62568

Collected Steps per Second: 22,778.29739
Overall Steps per Second: 10,694.87294

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.67663

Cumulative Model Updates: 233,472
Cumulative Timesteps: 1,947,212,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.34818
Policy Entropy: 2.28565
Value Function Loss: 0.01703

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.53092
Value Function Update Magnitude: 0.59736

Collected Steps per Second: 23,343.90083
Overall Steps per Second: 10,852.54384

Timestep Collection Time: 2.14223
Timestep Consumption Time: 2.46572
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60795

Cumulative Model Updates: 233,478
Cumulative Timesteps: 1,947,262,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1947262062...
Checkpoint 1947262062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.76760
Policy Entropy: 2.28691
Value Function Loss: 0.01671

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.52574
Value Function Update Magnitude: 0.58072

Collected Steps per Second: 22,294.92448
Overall Steps per Second: 10,701.30053

Timestep Collection Time: 2.24266
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.67233

Cumulative Model Updates: 233,484
Cumulative Timesteps: 1,947,312,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.68404
Policy Entropy: 2.26260
Value Function Loss: 0.01804

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.54176
Value Function Update Magnitude: 0.57905

Collected Steps per Second: 22,928.91198
Overall Steps per Second: 10,942.37382

Timestep Collection Time: 2.18109
Timestep Consumption Time: 2.38922
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.57031

Cumulative Model Updates: 233,490
Cumulative Timesteps: 1,947,362,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1947362072...
Checkpoint 1947362072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.13421
Policy Entropy: 2.24518
Value Function Loss: 0.01851

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.59781

Collected Steps per Second: 22,679.71447
Overall Steps per Second: 10,979.07116

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.35007
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.55521

Cumulative Model Updates: 233,496
Cumulative Timesteps: 1,947,412,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.81048
Policy Entropy: 2.23824
Value Function Loss: 0.01981

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.56043
Value Function Update Magnitude: 0.62513

Collected Steps per Second: 23,065.50368
Overall Steps per Second: 10,915.80576

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.41326
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.58143

Cumulative Model Updates: 233,502
Cumulative Timesteps: 1,947,462,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1947462094...
Checkpoint 1947462094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.80094
Policy Entropy: 2.26751
Value Function Loss: 0.01842

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.63709

Collected Steps per Second: 22,776.34468
Overall Steps per Second: 10,683.54978

Timestep Collection Time: 2.19552
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.68065

Cumulative Model Updates: 233,508
Cumulative Timesteps: 1,947,512,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.16487
Policy Entropy: 2.29518
Value Function Loss: 0.01699

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 23,190.13630
Overall Steps per Second: 10,976.88697

Timestep Collection Time: 2.15669
Timestep Consumption Time: 2.39961
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.55630

Cumulative Model Updates: 233,514
Cumulative Timesteps: 1,947,562,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1947562114...
Checkpoint 1947562114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.92730
Policy Entropy: 2.30662
Value Function Loss: 0.01588

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.52351
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 22,926.13423
Overall Steps per Second: 11,030.57464

Timestep Collection Time: 2.18144
Timestep Consumption Time: 2.35250
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.53394

Cumulative Model Updates: 233,520
Cumulative Timesteps: 1,947,612,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.57256
Policy Entropy: 2.29335
Value Function Loss: 0.01566

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.51508
Value Function Update Magnitude: 0.57865

Collected Steps per Second: 23,217.65195
Overall Steps per Second: 10,901.90088

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.43311
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.58691

Cumulative Model Updates: 233,526
Cumulative Timesteps: 1,947,662,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1947662132...
Checkpoint 1947662132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.32843
Policy Entropy: 2.27100
Value Function Loss: 0.01569

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.51146
Value Function Update Magnitude: 0.56667

Collected Steps per Second: 22,703.56401
Overall Steps per Second: 10,703.23096

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.67149

Cumulative Model Updates: 233,532
Cumulative Timesteps: 1,947,712,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.57039
Policy Entropy: 2.25399
Value Function Loss: 0.01795

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.53490
Value Function Update Magnitude: 0.59250

Collected Steps per Second: 23,075.74233
Overall Steps per Second: 10,897.91038

Timestep Collection Time: 2.16747
Timestep Consumption Time: 2.42203
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.58950

Cumulative Model Updates: 233,538
Cumulative Timesteps: 1,947,762,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1947762148...
Checkpoint 1947762148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.76282
Policy Entropy: 2.23322
Value Function Loss: 0.01768

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.62126

Collected Steps per Second: 22,435.58504
Overall Steps per Second: 10,774.86278

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.41279
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.64229

Cumulative Model Updates: 233,544
Cumulative Timesteps: 1,947,812,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.61379
Policy Entropy: 2.20136
Value Function Loss: 0.01866

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.54429
Value Function Update Magnitude: 0.63902

Collected Steps per Second: 23,105.56789
Overall Steps per Second: 10,813.16992

Timestep Collection Time: 2.16519
Timestep Consumption Time: 2.46139
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.62658

Cumulative Model Updates: 233,550
Cumulative Timesteps: 1,947,862,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1947862196...
Checkpoint 1947862196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.58514
Policy Entropy: 2.23455
Value Function Loss: 0.01777

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.63659

Collected Steps per Second: 22,165.20553
Overall Steps per Second: 10,632.14506

Timestep Collection Time: 2.25696
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.70517

Cumulative Model Updates: 233,556
Cumulative Timesteps: 1,947,912,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.03892
Policy Entropy: 2.24767
Value Function Loss: 0.01862

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.64078

Collected Steps per Second: 23,264.60080
Overall Steps per Second: 10,873.44532

Timestep Collection Time: 2.14962
Timestep Consumption Time: 2.44966
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.59928

Cumulative Model Updates: 233,562
Cumulative Timesteps: 1,947,962,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1947962232...
Checkpoint 1947962232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.82899
Policy Entropy: 2.29606
Value Function Loss: 0.01717

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.53502
Value Function Update Magnitude: 0.63993

Collected Steps per Second: 23,117.18474
Overall Steps per Second: 10,636.61260

Timestep Collection Time: 2.16384
Timestep Consumption Time: 2.53897
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.70281

Cumulative Model Updates: 233,568
Cumulative Timesteps: 1,948,012,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.25691
Policy Entropy: 2.28891
Value Function Loss: 0.01731

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.53364
Value Function Update Magnitude: 0.64011

Collected Steps per Second: 23,451.42664
Overall Steps per Second: 10,970.75952

Timestep Collection Time: 2.13232
Timestep Consumption Time: 2.42579
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.55812

Cumulative Model Updates: 233,574
Cumulative Timesteps: 1,948,062,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1948062260...
Checkpoint 1948062260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.37747
Policy Entropy: 2.29818
Value Function Loss: 0.01647

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.52617
Value Function Update Magnitude: 0.64427

Collected Steps per Second: 22,708.90240
Overall Steps per Second: 10,600.72889

Timestep Collection Time: 2.20204
Timestep Consumption Time: 2.51518
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.71722

Cumulative Model Updates: 233,580
Cumulative Timesteps: 1,948,112,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.38206
Policy Entropy: 2.28649
Value Function Loss: 0.01692

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.51877
Value Function Update Magnitude: 0.64329

Collected Steps per Second: 23,270.92057
Overall Steps per Second: 10,879.37629

Timestep Collection Time: 2.14860
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.59585

Cumulative Model Updates: 233,586
Cumulative Timesteps: 1,948,162,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1948162266...
Checkpoint 1948162266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.19573
Policy Entropy: 2.27050
Value Function Loss: 0.01743

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.63503

Collected Steps per Second: 23,112.32761
Overall Steps per Second: 10,727.97007

Timestep Collection Time: 2.16343
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.66090

Cumulative Model Updates: 233,592
Cumulative Timesteps: 1,948,212,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.61376
Policy Entropy: 2.27321
Value Function Loss: 0.01848

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.63871

Collected Steps per Second: 23,462.49212
Overall Steps per Second: 10,876.33212

Timestep Collection Time: 2.13183
Timestep Consumption Time: 2.46696
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.59879

Cumulative Model Updates: 233,598
Cumulative Timesteps: 1,948,262,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1948262286...
Checkpoint 1948262286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.37574
Policy Entropy: 2.25386
Value Function Loss: 0.01835

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.55375
Value Function Update Magnitude: 0.64470

Collected Steps per Second: 22,219.74566
Overall Steps per Second: 10,629.39432

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.45388
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.70431

Cumulative Model Updates: 233,604
Cumulative Timesteps: 1,948,312,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.24100
Policy Entropy: 2.25087
Value Function Loss: 0.01822

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.64469

Collected Steps per Second: 22,798.28997
Overall Steps per Second: 10,899.20109

Timestep Collection Time: 2.19367
Timestep Consumption Time: 2.39492
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.58859

Cumulative Model Updates: 233,610
Cumulative Timesteps: 1,948,362,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1948362302...
Checkpoint 1948362302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.96100
Policy Entropy: 2.23233
Value Function Loss: 0.01768

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,456.29600
Overall Steps per Second: 10,613.01009

Timestep Collection Time: 2.22717
Timestep Consumption Time: 2.48535
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.71252

Cumulative Model Updates: 233,616
Cumulative Timesteps: 1,948,412,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.47708
Policy Entropy: 2.26542
Value Function Loss: 0.01735

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.52761
Value Function Update Magnitude: 0.60525

Collected Steps per Second: 22,927.70892
Overall Steps per Second: 10,844.96876

Timestep Collection Time: 2.18164
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61228

Cumulative Model Updates: 233,622
Cumulative Timesteps: 1,948,462,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1948462336...
Checkpoint 1948462336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.30525
Policy Entropy: 2.26250
Value Function Loss: 0.01870

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.53288
Value Function Update Magnitude: 0.60242

Collected Steps per Second: 22,300.15493
Overall Steps per Second: 10,696.68964

Timestep Collection Time: 2.24330
Timestep Consumption Time: 2.43347
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.67677

Cumulative Model Updates: 233,628
Cumulative Timesteps: 1,948,512,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.22485
Policy Entropy: 2.28346
Value Function Loss: 0.01811

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.62225

Collected Steps per Second: 23,292.55173
Overall Steps per Second: 10,943.86683

Timestep Collection Time: 2.14721
Timestep Consumption Time: 2.42284
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.57005

Cumulative Model Updates: 233,634
Cumulative Timesteps: 1,948,562,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1948562376...
Checkpoint 1948562376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.48524
Policy Entropy: 2.24597
Value Function Loss: 0.01835

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.15387
Policy Update Magnitude: 0.51819
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 22,973.19352
Overall Steps per Second: 10,677.33145

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.68413

Cumulative Model Updates: 233,640
Cumulative Timesteps: 1,948,612,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.44456
Policy Entropy: 2.25847
Value Function Loss: 0.01715

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.49745
Value Function Update Magnitude: 0.60148

Collected Steps per Second: 23,127.60164
Overall Steps per Second: 10,866.98351

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.60220

Cumulative Model Updates: 233,646
Cumulative Timesteps: 1,948,662,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1948662402...
Checkpoint 1948662402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.37475
Policy Entropy: 2.25952
Value Function Loss: 0.01717

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.15942
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.58123

Collected Steps per Second: 22,592.13377
Overall Steps per Second: 10,629.26571

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.49083
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.70399

Cumulative Model Updates: 233,652
Cumulative Timesteps: 1,948,712,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.96010
Policy Entropy: 2.27358
Value Function Loss: 0.01785

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.51986
Value Function Update Magnitude: 0.59185

Collected Steps per Second: 24,253.83939
Overall Steps per Second: 10,953.33102

Timestep Collection Time: 2.06169
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.56519

Cumulative Model Updates: 233,658
Cumulative Timesteps: 1,948,762,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1948762406...
Checkpoint 1948762406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.51799
Policy Entropy: 2.25948
Value Function Loss: 0.01742

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.59702

Collected Steps per Second: 23,159.43815
Overall Steps per Second: 10,778.13572

Timestep Collection Time: 2.15981
Timestep Consumption Time: 2.48107
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.64088

Cumulative Model Updates: 233,664
Cumulative Timesteps: 1,948,812,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.13685
Policy Entropy: 2.25101
Value Function Loss: 0.01897

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.59885

Collected Steps per Second: 22,843.27001
Overall Steps per Second: 10,729.41922

Timestep Collection Time: 2.18935
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.66120

Cumulative Model Updates: 233,670
Cumulative Timesteps: 1,948,862,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1948862438...
Checkpoint 1948862438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.59413
Policy Entropy: 2.22148
Value Function Loss: 0.01943

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.55439
Value Function Update Magnitude: 0.61164

Collected Steps per Second: 22,212.31574
Overall Steps per Second: 10,643.35514

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.70021

Cumulative Model Updates: 233,676
Cumulative Timesteps: 1,948,912,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.51355
Policy Entropy: 2.23054
Value Function Loss: 0.01924

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.55673
Value Function Update Magnitude: 0.62204

Collected Steps per Second: 22,948.91439
Overall Steps per Second: 10,852.77230

Timestep Collection Time: 2.17910
Timestep Consumption Time: 2.42875
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.60785

Cumulative Model Updates: 233,682
Cumulative Timesteps: 1,948,962,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1948962472...
Checkpoint 1948962472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.40218
Policy Entropy: 2.25421
Value Function Loss: 0.01833

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.54650
Value Function Update Magnitude: 0.62861

Collected Steps per Second: 22,461.23860
Overall Steps per Second: 10,659.42475

Timestep Collection Time: 2.22624
Timestep Consumption Time: 2.46482
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.69106

Cumulative Model Updates: 233,688
Cumulative Timesteps: 1,949,012,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.80696
Policy Entropy: 2.27124
Value Function Loss: 0.01743

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.53423
Value Function Update Magnitude: 0.61070

Collected Steps per Second: 23,217.13852
Overall Steps per Second: 10,826.21142

Timestep Collection Time: 2.15358
Timestep Consumption Time: 2.46484
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61842

Cumulative Model Updates: 233,694
Cumulative Timesteps: 1,949,062,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1949062476...
Checkpoint 1949062476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.26159
Policy Entropy: 2.25432
Value Function Loss: 0.01761

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.52844
Value Function Update Magnitude: 0.59195

Collected Steps per Second: 22,764.21432
Overall Steps per Second: 10,702.45760

Timestep Collection Time: 2.19696
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.67295

Cumulative Model Updates: 233,700
Cumulative Timesteps: 1,949,112,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.95753
Policy Entropy: 2.23819
Value Function Loss: 0.01684

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.52400
Value Function Update Magnitude: 0.58333

Collected Steps per Second: 23,173.55431
Overall Steps per Second: 10,944.82675

Timestep Collection Time: 2.15927
Timestep Consumption Time: 2.41257
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.57184

Cumulative Model Updates: 233,706
Cumulative Timesteps: 1,949,162,526

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1949162526...
Checkpoint 1949162526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.52465
Policy Entropy: 2.25558
Value Function Loss: 0.01729

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.52938
Value Function Update Magnitude: 0.57647

Collected Steps per Second: 21,652.65174
Overall Steps per Second: 10,526.19597

Timestep Collection Time: 2.31057
Timestep Consumption Time: 2.44233
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.75290

Cumulative Model Updates: 233,712
Cumulative Timesteps: 1,949,212,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.93252
Policy Entropy: 2.27109
Value Function Loss: 0.01822

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.52950
Value Function Update Magnitude: 0.59055

Collected Steps per Second: 22,739.32698
Overall Steps per Second: 10,656.43195

Timestep Collection Time: 2.19971
Timestep Consumption Time: 2.49417
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.69388

Cumulative Model Updates: 233,718
Cumulative Timesteps: 1,949,262,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1949262576...
Checkpoint 1949262576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.46918
Policy Entropy: 2.27692
Value Function Loss: 0.01873

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.60534

Collected Steps per Second: 22,681.31662
Overall Steps per Second: 10,713.48567

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.66758

Cumulative Model Updates: 233,724
Cumulative Timesteps: 1,949,312,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.12685
Policy Entropy: 2.24894
Value Function Loss: 0.01869

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.53579
Value Function Update Magnitude: 0.60560

Collected Steps per Second: 23,855.08653
Overall Steps per Second: 10,808.19956

Timestep Collection Time: 2.09674
Timestep Consumption Time: 2.53104
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.62778

Cumulative Model Updates: 233,730
Cumulative Timesteps: 1,949,362,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1949362600...
Checkpoint 1949362600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.01144
Policy Entropy: 2.24111
Value Function Loss: 0.01907

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 22,767.99417
Overall Steps per Second: 10,619.04347

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.51266
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.70890

Cumulative Model Updates: 233,736
Cumulative Timesteps: 1,949,412,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.49982
Policy Entropy: 2.24116
Value Function Loss: 0.01853

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.53235
Value Function Update Magnitude: 0.62020

Collected Steps per Second: 23,352.06118
Overall Steps per Second: 10,870.20102

Timestep Collection Time: 2.14148
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.60047

Cumulative Model Updates: 233,742
Cumulative Timesteps: 1,949,462,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1949462612...
Checkpoint 1949462612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.26477
Policy Entropy: 2.25595
Value Function Loss: 0.01901

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.62111

Collected Steps per Second: 22,694.16768
Overall Steps per Second: 10,693.14751

Timestep Collection Time: 2.20339
Timestep Consumption Time: 2.47288
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.67627

Cumulative Model Updates: 233,748
Cumulative Timesteps: 1,949,512,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.63433
Policy Entropy: 2.22862
Value Function Loss: 0.01833

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.62732

Collected Steps per Second: 23,305.55360
Overall Steps per Second: 10,923.92930

Timestep Collection Time: 2.14550
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.57729

Cumulative Model Updates: 233,754
Cumulative Timesteps: 1,949,562,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1949562618...
Checkpoint 1949562618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.98537
Policy Entropy: 2.21886
Value Function Loss: 0.01702

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.62048

Collected Steps per Second: 23,015.85563
Overall Steps per Second: 10,720.14492

Timestep Collection Time: 2.17328
Timestep Consumption Time: 2.49270
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.66598

Cumulative Model Updates: 233,760
Cumulative Timesteps: 1,949,612,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.97589
Policy Entropy: 2.23392
Value Function Loss: 0.01694

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.60185

Collected Steps per Second: 23,347.47994
Overall Steps per Second: 10,839.33821

Timestep Collection Time: 2.14259
Timestep Consumption Time: 2.47246
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.61504

Cumulative Model Updates: 233,766
Cumulative Timesteps: 1,949,662,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1949662662...
Checkpoint 1949662662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.91506
Policy Entropy: 2.26144
Value Function Loss: 0.01678

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.52824
Value Function Update Magnitude: 0.58022

Collected Steps per Second: 22,646.58132
Overall Steps per Second: 10,658.62074

Timestep Collection Time: 2.20810
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.69160

Cumulative Model Updates: 233,772
Cumulative Timesteps: 1,949,712,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.26160
Policy Entropy: 2.25099
Value Function Loss: 0.01736

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.52514
Value Function Update Magnitude: 0.57784

Collected Steps per Second: 23,076.19325
Overall Steps per Second: 10,852.53798

Timestep Collection Time: 2.16700
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.60777

Cumulative Model Updates: 233,778
Cumulative Timesteps: 1,949,762,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1949762674...
Checkpoint 1949762674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.50304
Policy Entropy: 2.20807
Value Function Loss: 0.01725

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.52508
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 22,365.36797
Overall Steps per Second: 10,650.91278

Timestep Collection Time: 2.23614
Timestep Consumption Time: 2.45942
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.69556

Cumulative Model Updates: 233,784
Cumulative Timesteps: 1,949,812,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.48613
Policy Entropy: 2.19626
Value Function Loss: 0.01723

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.52847
Value Function Update Magnitude: 0.58633

Collected Steps per Second: 22,732.70639
Overall Steps per Second: 10,793.07616

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.63390

Cumulative Model Updates: 233,790
Cumulative Timesteps: 1,949,862,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1949862700...
Checkpoint 1949862700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.01505
Policy Entropy: 2.21103
Value Function Loss: 0.01819

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.54081
Value Function Update Magnitude: 0.59902

Collected Steps per Second: 22,316.30599
Overall Steps per Second: 10,678.64860

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.68243

Cumulative Model Updates: 233,796
Cumulative Timesteps: 1,949,912,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.19074
Policy Entropy: 2.23300
Value Function Loss: 0.01873

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.55087
Value Function Update Magnitude: 0.61659

Collected Steps per Second: 24,203.41362
Overall Steps per Second: 10,922.13989

Timestep Collection Time: 2.06582
Timestep Consumption Time: 2.51203
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.57786

Cumulative Model Updates: 233,802
Cumulative Timesteps: 1,949,962,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1949962702...
Checkpoint 1949962702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.92940
Policy Entropy: 2.22750
Value Function Loss: 0.01890

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.55610
Value Function Update Magnitude: 0.63448

Collected Steps per Second: 23,041.50120
Overall Steps per Second: 10,697.29473

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.50418
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.67427

Cumulative Model Updates: 233,808
Cumulative Timesteps: 1,950,012,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.00691
Policy Entropy: 2.20068
Value Function Loss: 0.01914

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.65342

Collected Steps per Second: 23,147.23744
Overall Steps per Second: 10,881.83440

Timestep Collection Time: 2.16052
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.59573

Cumulative Model Updates: 233,814
Cumulative Timesteps: 1,950,062,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1950062714...
Checkpoint 1950062714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.46892
Policy Entropy: 2.23775
Value Function Loss: 0.01816

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.66422

Collected Steps per Second: 23,027.96360
Overall Steps per Second: 11,072.66081

Timestep Collection Time: 2.17214
Timestep Consumption Time: 2.34529
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.51743

Cumulative Model Updates: 233,820
Cumulative Timesteps: 1,950,112,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.60594
Policy Entropy: 2.25888
Value Function Loss: 0.01750

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.63779

Collected Steps per Second: 22,812.26997
Overall Steps per Second: 10,697.92015

Timestep Collection Time: 2.19250
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.67530

Cumulative Model Updates: 233,826
Cumulative Timesteps: 1,950,162,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1950162750...
Checkpoint 1950162750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.01228
Policy Entropy: 2.25543
Value Function Loss: 0.01835

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.53261
Value Function Update Magnitude: 0.60059

Collected Steps per Second: 22,588.63356
Overall Steps per Second: 10,642.84798

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.69968

Cumulative Model Updates: 233,832
Cumulative Timesteps: 1,950,212,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.05821
Policy Entropy: 2.22464
Value Function Loss: 0.01830

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.60181

Collected Steps per Second: 23,059.74173
Overall Steps per Second: 10,759.24729

Timestep Collection Time: 2.16854
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.64772

Cumulative Model Updates: 233,838
Cumulative Timesteps: 1,950,262,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1950262774...
Checkpoint 1950262774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.92205
Policy Entropy: 2.22714
Value Function Loss: 0.01815

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.54273
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 22,559.74984
Overall Steps per Second: 10,662.30640

Timestep Collection Time: 2.21678
Timestep Consumption Time: 2.47357
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.69035

Cumulative Model Updates: 233,844
Cumulative Timesteps: 1,950,312,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.92618
Policy Entropy: 2.22197
Value Function Loss: 0.01705

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.54572
Value Function Update Magnitude: 0.60050

Collected Steps per Second: 23,990.87938
Overall Steps per Second: 10,818.56223

Timestep Collection Time: 2.08521
Timestep Consumption Time: 2.53888
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.62409

Cumulative Model Updates: 233,850
Cumulative Timesteps: 1,950,362,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1950362810...
Checkpoint 1950362810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.09432
Policy Entropy: 2.20786
Value Function Loss: 0.01762

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.54435
Value Function Update Magnitude: 0.58911

Collected Steps per Second: 22,836.48497
Overall Steps per Second: 10,632.64221

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.51453
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.70532

Cumulative Model Updates: 233,856
Cumulative Timesteps: 1,950,412,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.94515
Policy Entropy: 2.17999
Value Function Loss: 0.01873

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.54979
Value Function Update Magnitude: 0.60238

Collected Steps per Second: 23,158.35069
Overall Steps per Second: 10,961.05956

Timestep Collection Time: 2.15905
Timestep Consumption Time: 2.40255
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.56160

Cumulative Model Updates: 233,862
Cumulative Timesteps: 1,950,462,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1950462840...
Checkpoint 1950462840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.66246
Policy Entropy: 2.19050
Value Function Loss: 0.01923

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.61957

Collected Steps per Second: 22,875.86080
Overall Steps per Second: 11,022.39066

Timestep Collection Time: 2.18571
Timestep Consumption Time: 2.35051
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.53622

Cumulative Model Updates: 233,868
Cumulative Timesteps: 1,950,512,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69336
Policy Entropy: 2.19908
Value Function Loss: 0.01964

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.62563

Collected Steps per Second: 23,211.00195
Overall Steps per Second: 10,912.39055

Timestep Collection Time: 2.15432
Timestep Consumption Time: 2.42799
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.58231

Cumulative Model Updates: 233,874
Cumulative Timesteps: 1,950,562,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1950562844...
Checkpoint 1950562844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.12573
Policy Entropy: 2.25122
Value Function Loss: 0.01851

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 23,093.72188
Overall Steps per Second: 10,686.67851

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.67910

Cumulative Model Updates: 233,880
Cumulative Timesteps: 1,950,612,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.47989
Policy Entropy: 2.26248
Value Function Loss: 0.01863

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.60502

Collected Steps per Second: 22,746.50574
Overall Steps per Second: 10,859.06534

Timestep Collection Time: 2.19911
Timestep Consumption Time: 2.40737
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60647

Cumulative Model Updates: 233,886
Cumulative Timesteps: 1,950,662,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1950662870...
Checkpoint 1950662870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.88433
Policy Entropy: 2.29348
Value Function Loss: 0.01684

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.53831
Value Function Update Magnitude: 0.62927

Collected Steps per Second: 22,527.84045
Overall Steps per Second: 10,817.47344

Timestep Collection Time: 2.22010
Timestep Consumption Time: 2.40335
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.62345

Cumulative Model Updates: 233,892
Cumulative Timesteps: 1,950,712,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.48809
Policy Entropy: 2.27554
Value Function Loss: 0.01693

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.53082
Value Function Update Magnitude: 0.62590

Collected Steps per Second: 23,138.71823
Overall Steps per Second: 10,766.57344

Timestep Collection Time: 2.16166
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.64567

Cumulative Model Updates: 233,898
Cumulative Timesteps: 1,950,762,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1950762902...
Checkpoint 1950762902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.74620
Policy Entropy: 2.27493
Value Function Loss: 0.01608

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.52316
Value Function Update Magnitude: 0.60707

Collected Steps per Second: 22,578.84816
Overall Steps per Second: 10,690.24766

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.68015

Cumulative Model Updates: 233,904
Cumulative Timesteps: 1,950,812,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.42656
Policy Entropy: 2.23818
Value Function Loss: 0.01741

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.61867

Collected Steps per Second: 23,286.27877
Overall Steps per Second: 10,856.65870

Timestep Collection Time: 2.14796
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.60713

Cumulative Model Updates: 233,910
Cumulative Timesteps: 1,950,862,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1950862952...
Checkpoint 1950862952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.47526
Policy Entropy: 2.23376
Value Function Loss: 0.01686

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.53737
Value Function Update Magnitude: 0.64357

Collected Steps per Second: 22,697.51811
Overall Steps per Second: 10,908.83510

Timestep Collection Time: 2.20332
Timestep Consumption Time: 2.38103
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.58436

Cumulative Model Updates: 233,916
Cumulative Timesteps: 1,950,912,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.89731
Policy Entropy: 2.22351
Value Function Loss: 0.01717

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.63044

Collected Steps per Second: 23,011.89185
Overall Steps per Second: 10,669.54556

Timestep Collection Time: 2.17331
Timestep Consumption Time: 2.51405
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.68736

Cumulative Model Updates: 233,922
Cumulative Timesteps: 1,950,962,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1950962974...
Checkpoint 1950962974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.91019
Policy Entropy: 2.22835
Value Function Loss: 0.01774

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.62144

Collected Steps per Second: 22,961.10278
Overall Steps per Second: 10,639.64059

Timestep Collection Time: 2.17855
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.70147

Cumulative Model Updates: 233,928
Cumulative Timesteps: 1,951,012,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.52212
Policy Entropy: 2.23783
Value Function Loss: 0.01720

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.61285

Collected Steps per Second: 23,000.51687
Overall Steps per Second: 10,944.69549

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.39475
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.56879

Cumulative Model Updates: 233,934
Cumulative Timesteps: 1,951,063,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1951063000...
Checkpoint 1951063000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.99021
Policy Entropy: 2.24679
Value Function Loss: 0.01661

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.52680
Value Function Update Magnitude: 0.59727

Collected Steps per Second: 22,682.14352
Overall Steps per Second: 10,873.52766

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.39510
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.60053

Cumulative Model Updates: 233,940
Cumulative Timesteps: 1,951,113,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.20411
Policy Entropy: 2.22817
Value Function Loss: 0.01684

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.52913
Value Function Update Magnitude: 0.58467

Collected Steps per Second: 22,744.25270
Overall Steps per Second: 10,677.70179

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68284

Cumulative Model Updates: 233,946
Cumulative Timesteps: 1,951,163,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1951163026...
Checkpoint 1951163026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.17275
Policy Entropy: 2.23991
Value Function Loss: 0.01775

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.53569
Value Function Update Magnitude: 0.56779

Collected Steps per Second: 22,345.64367
Overall Steps per Second: 10,644.43133

Timestep Collection Time: 2.23757
Timestep Consumption Time: 2.45972
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.69729

Cumulative Model Updates: 233,952
Cumulative Timesteps: 1,951,213,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.41956
Policy Entropy: 2.23506
Value Function Loss: 0.01750

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.57670

Collected Steps per Second: 22,679.87376
Overall Steps per Second: 10,838.62502

Timestep Collection Time: 2.20574
Timestep Consumption Time: 2.40979
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61553

Cumulative Model Updates: 233,958
Cumulative Timesteps: 1,951,263,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1951263052...
Checkpoint 1951263052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.14586
Policy Entropy: 2.23945
Value Function Loss: 0.01645

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.58173

Collected Steps per Second: 22,238.33975
Overall Steps per Second: 10,715.51075

Timestep Collection Time: 2.24945
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.66837

Cumulative Model Updates: 233,964
Cumulative Timesteps: 1,951,313,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.12217
Policy Entropy: 2.21202
Value Function Loss: 0.01636

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.58167

Collected Steps per Second: 23,324.38037
Overall Steps per Second: 10,879.10920

Timestep Collection Time: 2.14428
Timestep Consumption Time: 2.45297
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.59725

Cumulative Model Updates: 233,970
Cumulative Timesteps: 1,951,363,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1951363090...
Checkpoint 1951363090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.12770
Policy Entropy: 2.18976
Value Function Loss: 0.01842

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.59660

Collected Steps per Second: 22,764.13397
Overall Steps per Second: 10,645.62194

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.69902

Cumulative Model Updates: 233,976
Cumulative Timesteps: 1,951,413,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.82852
Policy Entropy: 2.19690
Value Function Loss: 0.01893

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 22,950.69689
Overall Steps per Second: 10,893.01746

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.41200
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59101

Cumulative Model Updates: 233,982
Cumulative Timesteps: 1,951,463,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1951463124...
Checkpoint 1951463124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.95771
Policy Entropy: 2.19747
Value Function Loss: 0.01899

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.55664
Value Function Update Magnitude: 0.64470

Collected Steps per Second: 22,834.18466
Overall Steps per Second: 10,884.85494

Timestep Collection Time: 2.19101
Timestep Consumption Time: 2.40528
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.59629

Cumulative Model Updates: 233,988
Cumulative Timesteps: 1,951,513,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.53131
Policy Entropy: 2.22069
Value Function Loss: 0.01762

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 23,382.24873
Overall Steps per Second: 10,786.76547

Timestep Collection Time: 2.13957
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.63791

Cumulative Model Updates: 233,994
Cumulative Timesteps: 1,951,563,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1951563182...
Checkpoint 1951563182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.82561
Policy Entropy: 2.22173
Value Function Loss: 0.01682

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.53351
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 22,785.35913
Overall Steps per Second: 10,652.65091

Timestep Collection Time: 2.19501
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.69498

Cumulative Model Updates: 234,000
Cumulative Timesteps: 1,951,613,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.91767
Policy Entropy: 2.20700
Value Function Loss: 0.01816

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.61881

Collected Steps per Second: 22,735.98675
Overall Steps per Second: 10,882.41839

Timestep Collection Time: 2.20048
Timestep Consumption Time: 2.39685
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.59732

Cumulative Model Updates: 234,006
Cumulative Timesteps: 1,951,663,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1951663226...
Checkpoint 1951663226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.20144
Policy Entropy: 2.19233
Value Function Loss: 0.01899

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.63625

Collected Steps per Second: 22,724.08307
Overall Steps per Second: 10,998.82339

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.34713
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.54885

Cumulative Model Updates: 234,012
Cumulative Timesteps: 1,951,713,258

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.96884
Policy Entropy: 2.19423
Value Function Loss: 0.01922

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.65995

Collected Steps per Second: 22,774.71626
Overall Steps per Second: 10,676.23740

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.68517

Cumulative Model Updates: 234,018
Cumulative Timesteps: 1,951,763,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1951763278...
Checkpoint 1951763278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.47575
Policy Entropy: 2.21336
Value Function Loss: 0.01810

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.65212

Collected Steps per Second: 22,579.48825
Overall Steps per Second: 10,845.44345

Timestep Collection Time: 2.21502
Timestep Consumption Time: 2.39650
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61152

Cumulative Model Updates: 234,024
Cumulative Timesteps: 1,951,813,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.01934
Policy Entropy: 2.21961
Value Function Loss: 0.01757

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.55567
Value Function Update Magnitude: 0.64339

Collected Steps per Second: 22,966.28955
Overall Steps per Second: 10,977.01708

Timestep Collection Time: 2.17745
Timestep Consumption Time: 2.37825
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.55570

Cumulative Model Updates: 234,030
Cumulative Timesteps: 1,951,863,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1951863300...
Checkpoint 1951863300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.39661
Policy Entropy: 2.21478
Value Function Loss: 0.01846

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.54997
Value Function Update Magnitude: 0.62552

Collected Steps per Second: 23,160.69266
Overall Steps per Second: 10,764.37733

Timestep Collection Time: 2.15935
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.64607

Cumulative Model Updates: 234,036
Cumulative Timesteps: 1,951,913,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.18314
Policy Entropy: 2.23171
Value Function Loss: 0.01829

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.54466
Value Function Update Magnitude: 0.62196

Collected Steps per Second: 23,100.23988
Overall Steps per Second: 10,796.40531

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.63284

Cumulative Model Updates: 234,042
Cumulative Timesteps: 1,951,963,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1951963330...
Checkpoint 1951963330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.20372
Policy Entropy: 2.21980
Value Function Loss: 0.01893

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.53249
Value Function Update Magnitude: 0.62032

Collected Steps per Second: 22,889.86149
Overall Steps per Second: 10,732.85691

Timestep Collection Time: 2.18542
Timestep Consumption Time: 2.47541
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.66083

Cumulative Model Updates: 234,048
Cumulative Timesteps: 1,952,013,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.75397
Policy Entropy: 2.23400
Value Function Loss: 0.01919

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.53206
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 23,221.90003
Overall Steps per Second: 10,948.94929

Timestep Collection Time: 2.15374
Timestep Consumption Time: 2.41418
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.56793

Cumulative Model Updates: 234,054
Cumulative Timesteps: 1,952,063,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1952063368...
Checkpoint 1952063368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.38279
Policy Entropy: 2.23362
Value Function Loss: 0.01942

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.63938

Collected Steps per Second: 23,021.73449
Overall Steps per Second: 10,876.31678

Timestep Collection Time: 2.17316
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59990

Cumulative Model Updates: 234,060
Cumulative Timesteps: 1,952,113,398

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.16293
Policy Entropy: 2.24041
Value Function Loss: 0.01960

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.65329

Collected Steps per Second: 22,723.53502
Overall Steps per Second: 10,606.86412

Timestep Collection Time: 2.20115
Timestep Consumption Time: 2.51447
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.71563

Cumulative Model Updates: 234,066
Cumulative Timesteps: 1,952,163,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1952163416...
Checkpoint 1952163416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.71944
Policy Entropy: 2.22748
Value Function Loss: 0.01963

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.65748

Collected Steps per Second: 22,680.91788
Overall Steps per Second: 10,724.48782

Timestep Collection Time: 2.20458
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.66241

Cumulative Model Updates: 234,072
Cumulative Timesteps: 1,952,213,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.62016
Policy Entropy: 2.20594
Value Function Loss: 0.01965

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.56240
Value Function Update Magnitude: 0.65354

Collected Steps per Second: 22,456.98726
Overall Steps per Second: 10,791.98142

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.63548

Cumulative Model Updates: 234,078
Cumulative Timesteps: 1,952,263,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1952263444...
Checkpoint 1952263444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.59506
Policy Entropy: 2.21487
Value Function Loss: 0.01953

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.64096

Collected Steps per Second: 22,736.11085
Overall Steps per Second: 10,640.17281

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.50033
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.69974

Cumulative Model Updates: 234,084
Cumulative Timesteps: 1,952,313,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.29518
Policy Entropy: 2.23537
Value Function Loss: 0.01915

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.62248

Collected Steps per Second: 23,485.11257
Overall Steps per Second: 10,866.38404

Timestep Collection Time: 2.12969
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.60282

Cumulative Model Updates: 234,090
Cumulative Timesteps: 1,952,363,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1952363466...
Checkpoint 1952363466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.78200
Policy Entropy: 2.25075
Value Function Loss: 0.01882

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.55434
Value Function Update Magnitude: 0.61112

Collected Steps per Second: 22,617.94148
Overall Steps per Second: 10,588.38536

Timestep Collection Time: 2.21125
Timestep Consumption Time: 2.51222
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.72348

Cumulative Model Updates: 234,096
Cumulative Timesteps: 1,952,413,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.16866
Policy Entropy: 2.24152
Value Function Loss: 0.01899

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.62683

Collected Steps per Second: 22,903.05078
Overall Steps per Second: 11,009.09901

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.35868
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.54188

Cumulative Model Updates: 234,102
Cumulative Timesteps: 1,952,463,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1952463482...
Checkpoint 1952463482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.28657
Policy Entropy: 2.22811
Value Function Loss: 0.01870

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.55528
Value Function Update Magnitude: 0.63795

Collected Steps per Second: 23,000.70153
Overall Steps per Second: 10,717.54392

Timestep Collection Time: 2.17411
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.66581

Cumulative Model Updates: 234,108
Cumulative Timesteps: 1,952,513,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.45939
Policy Entropy: 2.22953
Value Function Loss: 0.01828

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.63972

Collected Steps per Second: 22,907.47680
Overall Steps per Second: 10,843.87469

Timestep Collection Time: 2.18418
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61403

Cumulative Model Updates: 234,114
Cumulative Timesteps: 1,952,563,522

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1952563522...
Checkpoint 1952563522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.89724
Policy Entropy: 2.22574
Value Function Loss: 0.01744

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.63803

Collected Steps per Second: 22,848.62069
Overall Steps per Second: 11,009.28209

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.35359
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.54217

Cumulative Model Updates: 234,120
Cumulative Timesteps: 1,952,613,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.15917
Policy Entropy: 2.21344
Value Function Loss: 0.01698

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.63148

Collected Steps per Second: 22,403.25510
Overall Steps per Second: 10,571.45377

Timestep Collection Time: 2.23226
Timestep Consumption Time: 2.49840
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.73066

Cumulative Model Updates: 234,126
Cumulative Timesteps: 1,952,663,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1952663538...
Checkpoint 1952663538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.42091
Policy Entropy: 2.20575
Value Function Loss: 0.01656

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.63554

Collected Steps per Second: 22,191.22214
Overall Steps per Second: 10,569.02672

Timestep Collection Time: 2.25404
Timestep Consumption Time: 2.47865
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.73270

Cumulative Model Updates: 234,132
Cumulative Timesteps: 1,952,713,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.79634
Policy Entropy: 2.19014
Value Function Loss: 0.01798

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.11733
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.63812

Collected Steps per Second: 22,841.79692
Overall Steps per Second: 10,864.93812

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.41309
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60214

Cumulative Model Updates: 234,138
Cumulative Timesteps: 1,952,763,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1952763560...
Checkpoint 1952763560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.76607
Policy Entropy: 2.21214
Value Function Loss: 0.01771

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.62384

Collected Steps per Second: 22,707.43349
Overall Steps per Second: 10,740.07423

Timestep Collection Time: 2.20236
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.65639

Cumulative Model Updates: 234,144
Cumulative Timesteps: 1,952,813,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.08271
Policy Entropy: 2.23117
Value Function Loss: 0.01883

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.54211
Value Function Update Magnitude: 0.62158

Collected Steps per Second: 23,140.06778
Overall Steps per Second: 10,886.72573

Timestep Collection Time: 2.16145
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59422

Cumulative Model Updates: 234,150
Cumulative Timesteps: 1,952,863,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1952863586...
Checkpoint 1952863586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.11073
Policy Entropy: 2.27502
Value Function Loss: 0.01692

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.62687

Collected Steps per Second: 22,782.18973
Overall Steps per Second: 10,633.62096

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.70282

Cumulative Model Updates: 234,156
Cumulative Timesteps: 1,952,913,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.63792
Policy Entropy: 2.26420
Value Function Loss: 0.01678

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.52269
Value Function Update Magnitude: 0.62058

Collected Steps per Second: 23,267.99631
Overall Steps per Second: 10,888.65109

Timestep Collection Time: 2.15008
Timestep Consumption Time: 2.44443
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.59451

Cumulative Model Updates: 234,162
Cumulative Timesteps: 1,952,963,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1952963622...
Checkpoint 1952963622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.38095
Policy Entropy: 2.22016
Value Function Loss: 0.01804

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.61801

Collected Steps per Second: 22,800.84463
Overall Steps per Second: 10,973.59990

Timestep Collection Time: 2.19334
Timestep Consumption Time: 2.36396
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.55730

Cumulative Model Updates: 234,168
Cumulative Timesteps: 1,953,013,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.72382
Policy Entropy: 2.20621
Value Function Loss: 0.01812

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.54294
Value Function Update Magnitude: 0.62465

Collected Steps per Second: 22,536.10677
Overall Steps per Second: 10,548.49540

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.52236
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.74191

Cumulative Model Updates: 234,174
Cumulative Timesteps: 1,953,063,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1953063652...
Checkpoint 1953063652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.27361
Policy Entropy: 2.20546
Value Function Loss: 0.01745

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.53283
Value Function Update Magnitude: 0.59990

Collected Steps per Second: 22,873.68145
Overall Steps per Second: 10,671.90852

Timestep Collection Time: 2.18723
Timestep Consumption Time: 2.50078
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.68801

Cumulative Model Updates: 234,180
Cumulative Timesteps: 1,953,113,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.11299
Policy Entropy: 2.24459
Value Function Loss: 0.01646

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.53818
Value Function Update Magnitude: 0.59088

Collected Steps per Second: 22,729.62909
Overall Steps per Second: 10,842.01506

Timestep Collection Time: 2.20100
Timestep Consumption Time: 2.41327
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.61427

Cumulative Model Updates: 234,186
Cumulative Timesteps: 1,953,163,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1953163710...
Checkpoint 1953163710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.79213
Policy Entropy: 2.24333
Value Function Loss: 0.01635

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.53827
Value Function Update Magnitude: 0.59463

Collected Steps per Second: 22,574.84310
Overall Steps per Second: 10,764.74741

Timestep Collection Time: 2.21512
Timestep Consumption Time: 2.43023
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.64535

Cumulative Model Updates: 234,192
Cumulative Timesteps: 1,953,213,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.46977
Policy Entropy: 2.25187
Value Function Loss: 0.01722

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.54606
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 22,745.29963
Overall Steps per Second: 10,816.44662

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.42472
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.62333

Cumulative Model Updates: 234,198
Cumulative Timesteps: 1,953,263,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1953263724...
Checkpoint 1953263724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.26461
Policy Entropy: 2.22119
Value Function Loss: 0.01807

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.61180

Collected Steps per Second: 22,556.71314
Overall Steps per Second: 10,697.94371

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.67492

Cumulative Model Updates: 234,204
Cumulative Timesteps: 1,953,313,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.42645
Policy Entropy: 2.19571
Value Function Loss: 0.01806

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.55521
Value Function Update Magnitude: 0.62217

Collected Steps per Second: 23,087.91306
Overall Steps per Second: 10,856.52212

Timestep Collection Time: 2.16659
Timestep Consumption Time: 2.44096
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60755

Cumulative Model Updates: 234,210
Cumulative Timesteps: 1,953,363,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1953363758...
Checkpoint 1953363758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.48569
Policy Entropy: 2.15658
Value Function Loss: 0.01725

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.61797

Collected Steps per Second: 23,875.02674
Overall Steps per Second: 11,085.70594

Timestep Collection Time: 2.09642
Timestep Consumption Time: 2.41859
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.51500

Cumulative Model Updates: 234,216
Cumulative Timesteps: 1,953,413,810

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.86817
Policy Entropy: 2.18262
Value Function Loss: 0.01733

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.60778

Collected Steps per Second: 22,577.91174
Overall Steps per Second: 10,613.98474

Timestep Collection Time: 2.21500
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.71171

Cumulative Model Updates: 234,222
Cumulative Timesteps: 1,953,463,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1953463820...
Checkpoint 1953463820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.57079
Policy Entropy: 2.20811
Value Function Loss: 0.01716

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.60307

Collected Steps per Second: 22,704.36756
Overall Steps per Second: 10,722.54932

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.66568

Cumulative Model Updates: 234,228
Cumulative Timesteps: 1,953,513,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.95713
Policy Entropy: 2.21661
Value Function Loss: 0.01840

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.59959

Collected Steps per Second: 22,999.97651
Overall Steps per Second: 10,708.28065

Timestep Collection Time: 2.17505
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.67171

Cumulative Model Updates: 234,234
Cumulative Timesteps: 1,953,563,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1953563874...
Checkpoint 1953563874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.72523
Policy Entropy: 2.20290
Value Function Loss: 0.01777

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 22,931.01517
Overall Steps per Second: 11,062.32524

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.33958
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.52021

Cumulative Model Updates: 234,240
Cumulative Timesteps: 1,953,613,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.29363
Policy Entropy: 2.18427
Value Function Loss: 0.01846

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.54878
Value Function Update Magnitude: 0.59730

Collected Steps per Second: 22,469.04174
Overall Steps per Second: 10,576.45440

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73013

Cumulative Model Updates: 234,246
Cumulative Timesteps: 1,953,663,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1953663906...
Checkpoint 1953663906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.42756
Policy Entropy: 2.18920
Value Function Loss: 0.01677

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.60220

Collected Steps per Second: 22,469.49519
Overall Steps per Second: 10,564.16159

Timestep Collection Time: 2.22586
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.73431

Cumulative Model Updates: 234,252
Cumulative Timesteps: 1,953,713,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.51483
Policy Entropy: 2.18996
Value Function Loss: 0.01766

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.59666

Collected Steps per Second: 22,876.87343
Overall Steps per Second: 10,881.33670

Timestep Collection Time: 2.18579
Timestep Consumption Time: 2.40960
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.59539

Cumulative Model Updates: 234,258
Cumulative Timesteps: 1,953,763,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1953763924...
Checkpoint 1953763924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.74020
Policy Entropy: 2.20798
Value Function Loss: 0.01621

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.59329

Collected Steps per Second: 22,640.01578
Overall Steps per Second: 10,826.15812

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.41064
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.61974

Cumulative Model Updates: 234,264
Cumulative Timesteps: 1,953,813,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69290
Policy Entropy: 2.20542
Value Function Loss: 0.01802

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.53873
Value Function Update Magnitude: 0.60854

Collected Steps per Second: 23,165.91302
Overall Steps per Second: 10,770.70273

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.64445

Cumulative Model Updates: 234,270
Cumulative Timesteps: 1,953,863,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1953863962...
Checkpoint 1953863962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.58332
Policy Entropy: 2.18437
Value Function Loss: 0.01757

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.61416

Collected Steps per Second: 22,879.88918
Overall Steps per Second: 10,672.46357

Timestep Collection Time: 2.18620
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68683

Cumulative Model Updates: 234,276
Cumulative Timesteps: 1,953,913,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.65729
Policy Entropy: 2.15628
Value Function Loss: 0.01841

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.54938
Value Function Update Magnitude: 0.61668

Collected Steps per Second: 23,418.29016
Overall Steps per Second: 10,879.33984

Timestep Collection Time: 2.13534
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.59642

Cumulative Model Updates: 234,282
Cumulative Timesteps: 1,953,963,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1953963988...
Checkpoint 1953963988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.29947
Policy Entropy: 2.16639
Value Function Loss: 0.01703

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.62012

Collected Steps per Second: 22,847.69915
Overall Steps per Second: 11,011.66818

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.35336
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.54282

Cumulative Model Updates: 234,288
Cumulative Timesteps: 1,954,014,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.62149
Policy Entropy: 2.17032
Value Function Loss: 0.01794

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.63191

Collected Steps per Second: 22,896.62077
Overall Steps per Second: 10,729.14920

Timestep Collection Time: 2.18417
Timestep Consumption Time: 2.47697
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.66113

Cumulative Model Updates: 234,294
Cumulative Timesteps: 1,954,064,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1954064022...
Checkpoint 1954064022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.64003
Policy Entropy: 2.19465
Value Function Loss: 0.01726

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.62184

Collected Steps per Second: 22,954.81547
Overall Steps per Second: 10,940.43617

Timestep Collection Time: 2.17819
Timestep Consumption Time: 2.39201
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.57020

Cumulative Model Updates: 234,300
Cumulative Timesteps: 1,954,114,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.45161
Policy Entropy: 2.16812
Value Function Loss: 0.01761

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.54812
Value Function Update Magnitude: 0.62186

Collected Steps per Second: 22,397.23977
Overall Steps per Second: 10,901.95432

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.35523
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.58890

Cumulative Model Updates: 234,306
Cumulative Timesteps: 1,954,164,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1954164050...
Checkpoint 1954164050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.74566
Policy Entropy: 2.14324
Value Function Loss: 0.01715

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.61866

Collected Steps per Second: 22,669.17061
Overall Steps per Second: 10,634.23786

Timestep Collection Time: 2.20564
Timestep Consumption Time: 2.49616
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.70179

Cumulative Model Updates: 234,312
Cumulative Timesteps: 1,954,214,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.86459
Policy Entropy: 2.12653
Value Function Loss: 0.01823

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.55234
Value Function Update Magnitude: 0.61561

Collected Steps per Second: 22,581.94457
Overall Steps per Second: 10,775.55250

Timestep Collection Time: 2.21416
Timestep Consumption Time: 2.42598
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.64013

Cumulative Model Updates: 234,318
Cumulative Timesteps: 1,954,264,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1954264050...
Checkpoint 1954264050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.81180
Policy Entropy: 2.14090
Value Function Loss: 0.01817

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.61362

Collected Steps per Second: 22,545.97956
Overall Steps per Second: 10,753.35092

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.64990

Cumulative Model Updates: 234,324
Cumulative Timesteps: 1,954,314,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.00519
Policy Entropy: 2.16787
Value Function Loss: 0.01770

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.54299
Value Function Update Magnitude: 0.61391

Collected Steps per Second: 24,130.18335
Overall Steps per Second: 10,933.17776

Timestep Collection Time: 2.07292
Timestep Consumption Time: 2.50214
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.57507

Cumulative Model Updates: 234,330
Cumulative Timesteps: 1,954,364,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1954364072...
Checkpoint 1954364072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.86062
Policy Entropy: 2.16718
Value Function Loss: 0.01783

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.55532
Value Function Update Magnitude: 0.61831

Collected Steps per Second: 22,756.29439
Overall Steps per Second: 10,599.60459

Timestep Collection Time: 2.19781
Timestep Consumption Time: 2.52067
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.71848

Cumulative Model Updates: 234,336
Cumulative Timesteps: 1,954,414,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.72619
Policy Entropy: 2.16402
Value Function Loss: 0.01831

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.55667
Value Function Update Magnitude: 0.62923

Collected Steps per Second: 22,611.09077
Overall Steps per Second: 10,743.06223

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.65845

Cumulative Model Updates: 234,342
Cumulative Timesteps: 1,954,464,132

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1954464132...
Checkpoint 1954464132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.85439
Policy Entropy: 2.19244
Value Function Loss: 0.01828

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.63321

Collected Steps per Second: 22,806.99106
Overall Steps per Second: 10,913.95978

Timestep Collection Time: 2.19275
Timestep Consumption Time: 2.38946
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.58220

Cumulative Model Updates: 234,348
Cumulative Timesteps: 1,954,514,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.72340
Policy Entropy: 2.20211
Value Function Loss: 0.01808

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.63565

Collected Steps per Second: 23,996.60696
Overall Steps per Second: 10,904.22532

Timestep Collection Time: 2.08379
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.58575

Cumulative Model Updates: 234,354
Cumulative Timesteps: 1,954,564,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1954564146...
Checkpoint 1954564146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.14664
Policy Entropy: 2.19896
Value Function Loss: 0.01754

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.62191

Collected Steps per Second: 22,928.34729
Overall Steps per Second: 10,721.46938

Timestep Collection Time: 2.18202
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.66634

Cumulative Model Updates: 234,360
Cumulative Timesteps: 1,954,614,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.30570
Policy Entropy: 2.20674
Value Function Loss: 0.01670

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.54528
Value Function Update Magnitude: 0.60145

Collected Steps per Second: 22,974.29459
Overall Steps per Second: 10,812.46199

Timestep Collection Time: 2.17669
Timestep Consumption Time: 2.44834
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.62503

Cumulative Model Updates: 234,366
Cumulative Timesteps: 1,954,664,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1954664184...
Checkpoint 1954664184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.58380
Policy Entropy: 2.21516
Value Function Loss: 0.01595

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.53320
Value Function Update Magnitude: 0.58050

Collected Steps per Second: 22,415.53699
Overall Steps per Second: 10,584.55417

Timestep Collection Time: 2.23104
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.72481

Cumulative Model Updates: 234,372
Cumulative Timesteps: 1,954,714,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.90214
Policy Entropy: 2.23438
Value Function Loss: 0.01554

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.52913
Value Function Update Magnitude: 0.56095

Collected Steps per Second: 23,102.36604
Overall Steps per Second: 10,872.11962

Timestep Collection Time: 2.16454
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.59947

Cumulative Model Updates: 234,378
Cumulative Timesteps: 1,954,764,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1954764200...
Checkpoint 1954764200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.72535
Policy Entropy: 2.19281
Value Function Loss: 0.01719

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.55634

Collected Steps per Second: 22,799.90844
Overall Steps per Second: 10,687.47994

Timestep Collection Time: 2.19361
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.67968

Cumulative Model Updates: 234,384
Cumulative Timesteps: 1,954,814,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.33991
Policy Entropy: 2.19770
Value Function Loss: 0.01698

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.53552
Value Function Update Magnitude: 0.54981

Collected Steps per Second: 23,267.31469
Overall Steps per Second: 10,920.79093

Timestep Collection Time: 2.14971
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.58007

Cumulative Model Updates: 234,390
Cumulative Timesteps: 1,954,864,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1954864232...
Checkpoint 1954864232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.64537
Policy Entropy: 2.19755
Value Function Loss: 0.01700

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.52874
Value Function Update Magnitude: 0.54671

Collected Steps per Second: 22,651.93648
Overall Steps per Second: 10,883.77881

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.38801
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.59657

Cumulative Model Updates: 234,396
Cumulative Timesteps: 1,954,914,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.10246
Policy Entropy: 2.18515
Value Function Loss: 0.01705

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.54173

Collected Steps per Second: 23,120.18882
Overall Steps per Second: 10,765.57880

Timestep Collection Time: 2.16270
Timestep Consumption Time: 2.48192
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.64462

Cumulative Model Updates: 234,402
Cumulative Timesteps: 1,954,964,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1954964262...
Checkpoint 1954964262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.11974
Policy Entropy: 2.16097
Value Function Loss: 0.01768

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.55483

Collected Steps per Second: 22,035.76268
Overall Steps per Second: 10,516.29578

Timestep Collection Time: 2.26922
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.75491

Cumulative Model Updates: 234,408
Cumulative Timesteps: 1,955,014,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.41454
Policy Entropy: 2.13904
Value Function Loss: 0.01929

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.54827
Value Function Update Magnitude: 0.59221

Collected Steps per Second: 22,799.35551
Overall Steps per Second: 10,882.66617

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.40209
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.59575

Cumulative Model Updates: 234,414
Cumulative Timesteps: 1,955,064,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1955064280...
Checkpoint 1955064280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.69990
Policy Entropy: 2.13536
Value Function Loss: 0.01770

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.62000

Collected Steps per Second: 22,529.57987
Overall Steps per Second: 10,768.39730

Timestep Collection Time: 2.22055
Timestep Consumption Time: 2.42527
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.64582

Cumulative Model Updates: 234,420
Cumulative Timesteps: 1,955,114,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.32494
Policy Entropy: 2.12569
Value Function Loss: 0.01822

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.54864
Value Function Update Magnitude: 0.60897

Collected Steps per Second: 23,006.80680
Overall Steps per Second: 10,773.18908

Timestep Collection Time: 2.17449
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.64375

Cumulative Model Updates: 234,426
Cumulative Timesteps: 1,955,164,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1955164336...
Checkpoint 1955164336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.51568
Policy Entropy: 2.14869
Value Function Loss: 0.01799

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.55423
Value Function Update Magnitude: 0.59236

Collected Steps per Second: 22,839.54791
Overall Steps per Second: 10,683.94937

Timestep Collection Time: 2.19050
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68273

Cumulative Model Updates: 234,432
Cumulative Timesteps: 1,955,214,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.11251
Policy Entropy: 2.18117
Value Function Loss: 0.01829

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.60191

Collected Steps per Second: 22,802.96313
Overall Steps per Second: 10,826.27003

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.42706
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62098

Cumulative Model Updates: 234,438
Cumulative Timesteps: 1,955,264,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1955264394...
Checkpoint 1955264394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.79725
Policy Entropy: 2.15802
Value Function Loss: 0.01856

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.55646
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,731.73000
Overall Steps per Second: 10,809.80724

Timestep Collection Time: 2.20018
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.62672

Cumulative Model Updates: 234,444
Cumulative Timesteps: 1,955,314,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.89295
Policy Entropy: 2.14118
Value Function Loss: 0.01813

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 23,167.34407
Overall Steps per Second: 10,859.60043

Timestep Collection Time: 2.15951
Timestep Consumption Time: 2.44748
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.60698

Cumulative Model Updates: 234,450
Cumulative Timesteps: 1,955,364,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1955364438...
Checkpoint 1955364438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.27253
Policy Entropy: 2.13572
Value Function Loss: 0.01818

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.64016

Collected Steps per Second: 22,600.05380
Overall Steps per Second: 10,604.45567

Timestep Collection Time: 2.21265
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.71557

Cumulative Model Updates: 234,456
Cumulative Timesteps: 1,955,414,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.97186
Policy Entropy: 2.13616
Value Function Loss: 0.01867

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.55024
Value Function Update Magnitude: 0.64105

Collected Steps per Second: 22,780.61457
Overall Steps per Second: 10,963.65146

Timestep Collection Time: 2.19485
Timestep Consumption Time: 2.36568
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.56052

Cumulative Model Updates: 234,462
Cumulative Timesteps: 1,955,464,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1955464444...
Checkpoint 1955464444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.92571
Policy Entropy: 2.12747
Value Function Loss: 0.01807

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.55604
Value Function Update Magnitude: 0.64281

Collected Steps per Second: 22,671.22654
Overall Steps per Second: 10,668.02984

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.68709

Cumulative Model Updates: 234,468
Cumulative Timesteps: 1,955,514,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.13383
Policy Entropy: 2.14402
Value Function Loss: 0.01821

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.64054

Collected Steps per Second: 23,088.00471
Overall Steps per Second: 10,826.82795

Timestep Collection Time: 2.16693
Timestep Consumption Time: 2.45400
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.62093

Cumulative Model Updates: 234,474
Cumulative Timesteps: 1,955,564,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1955564476...
Checkpoint 1955564476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.95452
Policy Entropy: 2.17419
Value Function Loss: 0.01729

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.62217

Collected Steps per Second: 22,332.81911
Overall Steps per Second: 10,626.93295

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.46686
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.70634

Cumulative Model Updates: 234,480
Cumulative Timesteps: 1,955,614,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.66625
Policy Entropy: 2.15986
Value Function Loss: 0.01792

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.60860

Collected Steps per Second: 23,028.43385
Overall Steps per Second: 10,950.66132

Timestep Collection Time: 2.17149
Timestep Consumption Time: 2.39499
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.56648

Cumulative Model Updates: 234,486
Cumulative Timesteps: 1,955,664,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1955664496...
Checkpoint 1955664496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.21665
Policy Entropy: 2.14556
Value Function Loss: 0.01742

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.53843
Value Function Update Magnitude: 0.60070

Collected Steps per Second: 22,857.64733
Overall Steps per Second: 10,615.57698

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.52372
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.71213

Cumulative Model Updates: 234,492
Cumulative Timesteps: 1,955,714,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.87330
Policy Entropy: 2.13111
Value Function Loss: 0.01753

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.61526

Collected Steps per Second: 23,085.42544
Overall Steps per Second: 10,865.04540

Timestep Collection Time: 2.16691
Timestep Consumption Time: 2.43721
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60412

Cumulative Model Updates: 234,498
Cumulative Timesteps: 1,955,764,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1955764542...
Checkpoint 1955764542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.01195
Policy Entropy: 2.13529
Value Function Loss: 0.01768

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 22,892.57529
Overall Steps per Second: 10,738.15222

Timestep Collection Time: 2.18499
Timestep Consumption Time: 2.47317
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.65816

Cumulative Model Updates: 234,504
Cumulative Timesteps: 1,955,814,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.97568
Policy Entropy: 2.11222
Value Function Loss: 0.01908

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 22,914.15475
Overall Steps per Second: 10,838.13933

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.61500

Cumulative Model Updates: 234,510
Cumulative Timesteps: 1,955,864,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1955864580...
Checkpoint 1955864580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.18022
Policy Entropy: 2.14481
Value Function Loss: 0.01828

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.61811

Collected Steps per Second: 22,858.35138
Overall Steps per Second: 10,649.85446

Timestep Collection Time: 2.18826
Timestep Consumption Time: 2.50852
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.69678

Cumulative Model Updates: 234,516
Cumulative Timesteps: 1,955,914,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.06313
Policy Entropy: 2.15837
Value Function Loss: 0.01804

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.55145
Value Function Update Magnitude: 0.61690

Collected Steps per Second: 23,322.95996
Overall Steps per Second: 10,910.66587

Timestep Collection Time: 2.14475
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.58469

Cumulative Model Updates: 234,522
Cumulative Timesteps: 1,955,964,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1955964622...
Checkpoint 1955964622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.79354
Policy Entropy: 2.19723
Value Function Loss: 0.01751

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.61021

Collected Steps per Second: 22,627.42469
Overall Steps per Second: 10,623.91502

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.49785
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.70862

Cumulative Model Updates: 234,528
Cumulative Timesteps: 1,956,014,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.02167
Policy Entropy: 2.18031
Value Function Loss: 0.01763

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.52445
Value Function Update Magnitude: 0.60397

Collected Steps per Second: 22,307.03052
Overall Steps per Second: 10,877.93390

Timestep Collection Time: 2.24252
Timestep Consumption Time: 2.35615
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59867

Cumulative Model Updates: 234,534
Cumulative Timesteps: 1,956,064,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1956064670...
Checkpoint 1956064670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.55518
Policy Entropy: 2.18430
Value Function Loss: 0.01645

Mean KL Divergence: 0.03115
SB3 Clip Fraction: 0.16918
Policy Update Magnitude: 0.50641
Value Function Update Magnitude: 0.59470

Collected Steps per Second: 22,499.08600
Overall Steps per Second: 10,705.87008

Timestep Collection Time: 2.22347
Timestep Consumption Time: 2.44930
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.67276

Cumulative Model Updates: 234,540
Cumulative Timesteps: 1,956,114,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.06780
Policy Entropy: 2.15586
Value Function Loss: 0.01671

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.15425
Policy Update Magnitude: 0.51719
Value Function Update Magnitude: 0.58669

Collected Steps per Second: 22,864.27698
Overall Steps per Second: 10,822.48507

Timestep Collection Time: 2.18795
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62241

Cumulative Model Updates: 234,546
Cumulative Timesteps: 1,956,164,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1956164722...
Checkpoint 1956164722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.94939
Policy Entropy: 2.17944
Value Function Loss: 0.01599

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.53174
Value Function Update Magnitude: 0.58361

Collected Steps per Second: 22,567.31254
Overall Steps per Second: 10,770.49354

Timestep Collection Time: 2.21559
Timestep Consumption Time: 2.42672
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.64231

Cumulative Model Updates: 234,552
Cumulative Timesteps: 1,956,214,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.82909
Policy Entropy: 2.18171
Value Function Loss: 0.01584

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.59997

Collected Steps per Second: 23,125.30467
Overall Steps per Second: 10,887.24495

Timestep Collection Time: 2.16317
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.59473

Cumulative Model Updates: 234,558
Cumulative Timesteps: 1,956,264,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1956264746...
Checkpoint 1956264746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.28295
Policy Entropy: 2.18147
Value Function Loss: 0.01678

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.60981

Collected Steps per Second: 23,017.87209
Overall Steps per Second: 10,740.54447

Timestep Collection Time: 2.17240
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65563

Cumulative Model Updates: 234,564
Cumulative Timesteps: 1,956,314,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.69447
Policy Entropy: 2.12806
Value Function Loss: 0.01863

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.56238
Value Function Update Magnitude: 0.61861

Collected Steps per Second: 23,147.00808
Overall Steps per Second: 10,784.12674

Timestep Collection Time: 2.16037
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.63700

Cumulative Model Updates: 234,570
Cumulative Timesteps: 1,956,364,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1956364756...
Checkpoint 1956364756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.18469
Policy Entropy: 2.14071
Value Function Loss: 0.01809

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.63505

Collected Steps per Second: 23,049.19920
Overall Steps per Second: 10,823.30261

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.62133

Cumulative Model Updates: 234,576
Cumulative Timesteps: 1,956,414,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.70819
Policy Entropy: 2.17186
Value Function Loss: 0.01734

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.64268

Collected Steps per Second: 23,228.56102
Overall Steps per Second: 11,105.42270

Timestep Collection Time: 2.15347
Timestep Consumption Time: 2.35082
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.50429

Cumulative Model Updates: 234,582
Cumulative Timesteps: 1,956,464,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1956464796...
Checkpoint 1956464796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.11478
Policy Entropy: 2.20369
Value Function Loss: 0.01631

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.53667
Value Function Update Magnitude: 0.62006

Collected Steps per Second: 22,499.75032
Overall Steps per Second: 10,729.29669

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.66349

Cumulative Model Updates: 234,588
Cumulative Timesteps: 1,956,514,832

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.23691
Policy Entropy: 2.19038
Value Function Loss: 0.01697

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.53936
Value Function Update Magnitude: 0.58880

Collected Steps per Second: 22,536.33957
Overall Steps per Second: 10,613.60962

Timestep Collection Time: 2.21997
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.71376

Cumulative Model Updates: 234,594
Cumulative Timesteps: 1,956,564,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1956564862...
Checkpoint 1956564862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.57762
Policy Entropy: 2.16375
Value Function Loss: 0.01846

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 22,580.42601
Overall Steps per Second: 10,843.33542

Timestep Collection Time: 2.21528
Timestep Consumption Time: 2.39787
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61316

Cumulative Model Updates: 234,600
Cumulative Timesteps: 1,956,614,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.97239
Policy Entropy: 2.16662
Value Function Loss: 0.01765

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.64072

Collected Steps per Second: 22,535.79675
Overall Steps per Second: 10,913.56652

Timestep Collection Time: 2.21896
Timestep Consumption Time: 2.36304
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.58200

Cumulative Model Updates: 234,606
Cumulative Timesteps: 1,956,664,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1956664890...
Checkpoint 1956664890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.05077
Policy Entropy: 2.16489
Value Function Loss: 0.01787

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.63611

Collected Steps per Second: 22,647.20981
Overall Steps per Second: 10,750.42489

Timestep Collection Time: 2.20787
Timestep Consumption Time: 2.44330
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.65117

Cumulative Model Updates: 234,612
Cumulative Timesteps: 1,956,714,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.33443
Policy Entropy: 2.16871
Value Function Loss: 0.01788

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.60898

Collected Steps per Second: 23,215.65989
Overall Steps per Second: 10,865.22198

Timestep Collection Time: 2.15467
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.60386

Cumulative Model Updates: 234,618
Cumulative Timesteps: 1,956,764,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1956764914...
Checkpoint 1956764914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.87641
Policy Entropy: 2.16399
Value Function Loss: 0.01766

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.58013

Collected Steps per Second: 22,798.56796
Overall Steps per Second: 10,706.30751

Timestep Collection Time: 2.19452
Timestep Consumption Time: 2.47861
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.67313

Cumulative Model Updates: 234,624
Cumulative Timesteps: 1,956,814,946

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.36905
Policy Entropy: 2.15746
Value Function Loss: 0.01759

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.56400

Collected Steps per Second: 23,871.25558
Overall Steps per Second: 10,859.14236

Timestep Collection Time: 2.09524
Timestep Consumption Time: 2.51065
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.60589

Cumulative Model Updates: 234,630
Cumulative Timesteps: 1,956,864,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1956864962...
Checkpoint 1956864962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.75659
Policy Entropy: 2.16683
Value Function Loss: 0.01633

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.56345

Collected Steps per Second: 22,642.43284
Overall Steps per Second: 10,653.15566

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.48630
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.69551

Cumulative Model Updates: 234,636
Cumulative Timesteps: 1,956,914,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.46770
Policy Entropy: 2.13696
Value Function Loss: 0.01696

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.54170
Value Function Update Magnitude: 0.56467

Collected Steps per Second: 23,076.76941
Overall Steps per Second: 10,842.17314

Timestep Collection Time: 2.16746
Timestep Consumption Time: 2.44582
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.61328

Cumulative Model Updates: 234,642
Cumulative Timesteps: 1,956,965,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1956965002...
Checkpoint 1956965002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.82597
Policy Entropy: 2.14388
Value Function Loss: 0.01677

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.52897
Value Function Update Magnitude: 0.57026

Collected Steps per Second: 22,532.92291
Overall Steps per Second: 10,741.73788

Timestep Collection Time: 2.21969
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.65623

Cumulative Model Updates: 234,648
Cumulative Timesteps: 1,957,015,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.35563
Policy Entropy: 2.13035
Value Function Loss: 0.01845

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.53631
Value Function Update Magnitude: 0.57615

Collected Steps per Second: 23,499.92255
Overall Steps per Second: 10,929.31433

Timestep Collection Time: 2.12784
Timestep Consumption Time: 2.44738
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.57522

Cumulative Model Updates: 234,654
Cumulative Timesteps: 1,957,065,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1957065022...
Checkpoint 1957065022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.20132
Policy Entropy: 2.14877
Value Function Loss: 0.01759

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.57907

Collected Steps per Second: 22,629.70000
Overall Steps per Second: 10,626.03799

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.70693

Cumulative Model Updates: 234,660
Cumulative Timesteps: 1,957,115,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.11170
Policy Entropy: 2.14201
Value Function Loss: 0.01787

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.58698

Collected Steps per Second: 22,811.05438
Overall Steps per Second: 10,869.84475

Timestep Collection Time: 2.19201
Timestep Consumption Time: 2.40806
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.60007

Cumulative Model Updates: 234,666
Cumulative Timesteps: 1,957,165,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1957165040...
Checkpoint 1957165040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.91117
Policy Entropy: 2.13970
Value Function Loss: 0.01691

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.53945
Value Function Update Magnitude: 0.58085

Collected Steps per Second: 22,358.09050
Overall Steps per Second: 10,719.92082

Timestep Collection Time: 2.23677
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.66515

Cumulative Model Updates: 234,672
Cumulative Timesteps: 1,957,215,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.62805
Policy Entropy: 2.18612
Value Function Loss: 0.01648

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.53371
Value Function Update Magnitude: 0.57682

Collected Steps per Second: 23,616.26795
Overall Steps per Second: 10,883.76105

Timestep Collection Time: 2.11752
Timestep Consumption Time: 2.47721
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.59474

Cumulative Model Updates: 234,678
Cumulative Timesteps: 1,957,265,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1957265058...
Checkpoint 1957265058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.24867
Policy Entropy: 2.15962
Value Function Loss: 0.01917

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.53308
Value Function Update Magnitude: 0.59612

Collected Steps per Second: 22,770.19947
Overall Steps per Second: 10,611.23285

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.51724
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.71406

Cumulative Model Updates: 234,684
Cumulative Timesteps: 1,957,315,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.20457
Policy Entropy: 2.13569
Value Function Loss: 0.01888

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.51818
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 23,134.76426
Overall Steps per Second: 10,936.74302

Timestep Collection Time: 2.16177
Timestep Consumption Time: 2.41107
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.57284

Cumulative Model Updates: 234,690
Cumulative Timesteps: 1,957,365,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1957365092...
Checkpoint 1957365092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.20365
Policy Entropy: 2.08016
Value Function Loss: 0.02051

Mean KL Divergence: 0.03108
SB3 Clip Fraction: 0.17160
Policy Update Magnitude: 0.50080
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 22,928.76677
Overall Steps per Second: 11,017.65525

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.35864
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.54035

Cumulative Model Updates: 234,696
Cumulative Timesteps: 1,957,415,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.95514
Policy Entropy: 2.10166
Value Function Loss: 0.01939

Mean KL Divergence: 0.03458
SB3 Clip Fraction: 0.18132
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.62765

Collected Steps per Second: 23,236.99163
Overall Steps per Second: 10,933.14868

Timestep Collection Time: 2.15269
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.57526

Cumulative Model Updates: 234,702
Cumulative Timesteps: 1,957,465,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1957465138...
Checkpoint 1957465138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.08423
Policy Entropy: 2.13276
Value Function Loss: 0.01907

Mean KL Divergence: 0.03507
SB3 Clip Fraction: 0.18367
Policy Update Magnitude: 0.52274
Value Function Update Magnitude: 0.59783

Collected Steps per Second: 22,968.68510
Overall Steps per Second: 10,720.15391

Timestep Collection Time: 2.17723
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.66486

Cumulative Model Updates: 234,708
Cumulative Timesteps: 1,957,515,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.74012
Policy Entropy: 2.17436
Value Function Loss: 0.01866

Mean KL Divergence: 0.03097
SB3 Clip Fraction: 0.16012
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 22,788.65389
Overall Steps per Second: 10,859.53707

Timestep Collection Time: 2.19504
Timestep Consumption Time: 2.41123
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60627

Cumulative Model Updates: 234,714
Cumulative Timesteps: 1,957,565,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1957565168...
Checkpoint 1957565168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.69307
Policy Entropy: 2.17989
Value Function Loss: 0.01774

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.55228
Value Function Update Magnitude: 0.59453

Collected Steps per Second: 22,605.25087
Overall Steps per Second: 10,838.42665

Timestep Collection Time: 2.21249
Timestep Consumption Time: 2.40201
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.61451

Cumulative Model Updates: 234,720
Cumulative Timesteps: 1,957,615,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.17290
Policy Entropy: 2.17474
Value Function Loss: 0.01775

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.53863
Value Function Update Magnitude: 0.59919

Collected Steps per Second: 22,476.59108
Overall Steps per Second: 10,722.18586

Timestep Collection Time: 2.22560
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.66547

Cumulative Model Updates: 234,726
Cumulative Timesteps: 1,957,665,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1957665206...
Checkpoint 1957665206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.40585
Policy Entropy: 2.11055
Value Function Loss: 0.01907

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.60178

Collected Steps per Second: 22,675.10571
Overall Steps per Second: 10,687.27362

Timestep Collection Time: 2.20559
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.67958

Cumulative Model Updates: 234,732
Cumulative Timesteps: 1,957,715,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.42792
Policy Entropy: 2.09590
Value Function Loss: 0.01909

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.56418
Value Function Update Magnitude: 0.59750

Collected Steps per Second: 23,250.31372
Overall Steps per Second: 10,910.34241

Timestep Collection Time: 2.15128
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.58446

Cumulative Model Updates: 234,738
Cumulative Timesteps: 1,957,765,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1957765236...
Checkpoint 1957765236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.30718
Policy Entropy: 2.09809
Value Function Loss: 0.01950

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.55936
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 23,001.68441
Overall Steps per Second: 11,036.51599

Timestep Collection Time: 2.17471
Timestep Consumption Time: 2.35770
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.53241

Cumulative Model Updates: 234,744
Cumulative Timesteps: 1,957,815,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.22790
Policy Entropy: 2.15279
Value Function Loss: 0.01827

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.59221

Collected Steps per Second: 23,226.33958
Overall Steps per Second: 10,914.15951

Timestep Collection Time: 2.15307
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.58194

Cumulative Model Updates: 234,750
Cumulative Timesteps: 1,957,865,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1957865266...
Checkpoint 1957865266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.52607
Policy Entropy: 2.18387
Value Function Loss: 0.01756

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.54962
Value Function Update Magnitude: 0.57918

Collected Steps per Second: 22,891.73325
Overall Steps per Second: 10,673.43092

Timestep Collection Time: 2.18472
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.68565

Cumulative Model Updates: 234,756
Cumulative Timesteps: 1,957,915,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.29391
Policy Entropy: 2.18213
Value Function Loss: 0.01734

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.58424

Collected Steps per Second: 22,872.94780
Overall Steps per Second: 10,853.55252

Timestep Collection Time: 2.18651
Timestep Consumption Time: 2.42138
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60789

Cumulative Model Updates: 234,762
Cumulative Timesteps: 1,957,965,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1957965290...
Checkpoint 1957965290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.42669
Policy Entropy: 2.15573
Value Function Loss: 0.01783

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.61011

Collected Steps per Second: 23,001.78014
Overall Steps per Second: 11,076.11603

Timestep Collection Time: 2.17427
Timestep Consumption Time: 2.34103
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.51530

Cumulative Model Updates: 234,768
Cumulative Timesteps: 1,958,015,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.39641
Policy Entropy: 2.10735
Value Function Loss: 0.01927

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.65567

Collected Steps per Second: 22,293.28940
Overall Steps per Second: 10,545.23251

Timestep Collection Time: 2.24292
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.74167

Cumulative Model Updates: 234,774
Cumulative Timesteps: 1,958,065,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1958065304...
Checkpoint 1958065304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.29949
Policy Entropy: 2.14406
Value Function Loss: 0.01822

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.67734

Collected Steps per Second: 22,687.49833
Overall Steps per Second: 10,655.61813

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.48940
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.69405

Cumulative Model Updates: 234,780
Cumulative Timesteps: 1,958,115,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.52528
Policy Entropy: 2.12877
Value Function Loss: 0.01867

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.14911
Policy Update Magnitude: 0.55889
Value Function Update Magnitude: 0.67830

Collected Steps per Second: 22,495.19329
Overall Steps per Second: 10,811.45306

Timestep Collection Time: 2.22314
Timestep Consumption Time: 2.40251
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62565

Cumulative Model Updates: 234,786
Cumulative Timesteps: 1,958,165,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1958165332...
Checkpoint 1958165332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.61130
Policy Entropy: 2.16407
Value Function Loss: 0.01770

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.65538

Collected Steps per Second: 22,766.90855
Overall Steps per Second: 10,856.61727

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.41028
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.60733

Cumulative Model Updates: 234,792
Cumulative Timesteps: 1,958,215,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.53963
Policy Entropy: 2.15283
Value Function Loss: 0.01782

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.64622

Collected Steps per Second: 23,381.53211
Overall Steps per Second: 10,735.71645

Timestep Collection Time: 2.13878
Timestep Consumption Time: 2.51931
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.65810

Cumulative Model Updates: 234,798
Cumulative Timesteps: 1,958,265,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1958265360...
Checkpoint 1958265360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.88329
Policy Entropy: 2.19750
Value Function Loss: 0.01727

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.63956

Collected Steps per Second: 22,491.92367
Overall Steps per Second: 10,631.30984

Timestep Collection Time: 2.22400
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.70516

Cumulative Model Updates: 234,804
Cumulative Timesteps: 1,958,315,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.69927
Policy Entropy: 2.17631
Value Function Loss: 0.01737

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.55904
Value Function Update Magnitude: 0.65696

Collected Steps per Second: 23,331.03677
Overall Steps per Second: 10,929.08759

Timestep Collection Time: 2.14393
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.57678

Cumulative Model Updates: 234,810
Cumulative Timesteps: 1,958,365,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1958365402...
Checkpoint 1958365402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.68426
Policy Entropy: 2.16991
Value Function Loss: 0.01762

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.55338
Value Function Update Magnitude: 0.65844

Collected Steps per Second: 22,830.59577
Overall Steps per Second: 11,011.78043

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.35092
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.54132

Cumulative Model Updates: 234,816
Cumulative Timesteps: 1,958,415,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.94636
Policy Entropy: 2.16496
Value Function Loss: 0.01735

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.54444
Value Function Update Magnitude: 0.64515

Collected Steps per Second: 23,192.33068
Overall Steps per Second: 10,805.15870

Timestep Collection Time: 2.15614
Timestep Consumption Time: 2.47183
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.62797

Cumulative Model Updates: 234,822
Cumulative Timesteps: 1,958,465,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1958465416...
Checkpoint 1958465416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.30618
Policy Entropy: 2.17620
Value Function Loss: 0.01697

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.54027
Value Function Update Magnitude: 0.60809

Collected Steps per Second: 22,649.80331
Overall Steps per Second: 10,809.40002

Timestep Collection Time: 2.20850
Timestep Consumption Time: 2.41914
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.62764

Cumulative Model Updates: 234,828
Cumulative Timesteps: 1,958,515,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.48961
Policy Entropy: 2.17144
Value Function Loss: 0.01703

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.55183
Value Function Update Magnitude: 0.61203

Collected Steps per Second: 22,879.02685
Overall Steps per Second: 10,713.11340

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.66904

Cumulative Model Updates: 234,834
Cumulative Timesteps: 1,958,565,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1958565458...
Checkpoint 1958565458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.42907
Policy Entropy: 2.14740
Value Function Loss: 0.01699

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.63269

Collected Steps per Second: 22,701.58381
Overall Steps per Second: 10,852.06436

Timestep Collection Time: 2.20267
Timestep Consumption Time: 2.40512
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.60779

Cumulative Model Updates: 234,840
Cumulative Timesteps: 1,958,615,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.92277
Policy Entropy: 2.16777
Value Function Loss: 0.01744

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.64683

Collected Steps per Second: 23,273.47562
Overall Steps per Second: 10,919.57171

Timestep Collection Time: 2.14931
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.58095

Cumulative Model Updates: 234,846
Cumulative Timesteps: 1,958,665,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1958665484...
Checkpoint 1958665484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.61796
Policy Entropy: 2.17164
Value Function Loss: 0.01775

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.65831

Collected Steps per Second: 22,756.25931
Overall Steps per Second: 10,662.28862

Timestep Collection Time: 2.19772
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.69055

Cumulative Model Updates: 234,852
Cumulative Timesteps: 1,958,715,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.64187
Policy Entropy: 2.20194
Value Function Loss: 0.01820

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.56119
Value Function Update Magnitude: 0.67823

Collected Steps per Second: 23,198.75464
Overall Steps per Second: 10,865.92819

Timestep Collection Time: 2.15598
Timestep Consumption Time: 2.44703
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.60301

Cumulative Model Updates: 234,858
Cumulative Timesteps: 1,958,765,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1958765512...
Checkpoint 1958765512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.70613
Policy Entropy: 2.16137
Value Function Loss: 0.01832

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.55810
Value Function Update Magnitude: 0.68372

Collected Steps per Second: 22,869.06793
Overall Steps per Second: 10,925.87064

Timestep Collection Time: 2.18680
Timestep Consumption Time: 2.39041
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.57721

Cumulative Model Updates: 234,864
Cumulative Timesteps: 1,958,815,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.91037
Policy Entropy: 2.19872
Value Function Loss: 0.01822

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.67603

Collected Steps per Second: 22,344.18490
Overall Steps per Second: 10,623.08051

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.70711

Cumulative Model Updates: 234,870
Cumulative Timesteps: 1,958,865,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1958865526...
Checkpoint 1958865526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.73145
Policy Entropy: 2.20966
Value Function Loss: 0.01781

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.67961

Collected Steps per Second: 23,025.60310
Overall Steps per Second: 10,674.39766

Timestep Collection Time: 2.17210
Timestep Consumption Time: 2.51331
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.68542

Cumulative Model Updates: 234,876
Cumulative Timesteps: 1,958,915,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.22276
Policy Entropy: 2.23047
Value Function Loss: 0.01846

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.55568
Value Function Update Magnitude: 0.70304

Collected Steps per Second: 22,849.83162
Overall Steps per Second: 10,859.71499

Timestep Collection Time: 2.18873
Timestep Consumption Time: 2.41655
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.60528

Cumulative Model Updates: 234,882
Cumulative Timesteps: 1,958,965,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1958965552...
Checkpoint 1958965552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.50208
Policy Entropy: 2.20555
Value Function Loss: 0.01833

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.70532

Collected Steps per Second: 22,829.47860
Overall Steps per Second: 10,871.45852

Timestep Collection Time: 2.19068
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.60030

Cumulative Model Updates: 234,888
Cumulative Timesteps: 1,959,015,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.80872
Policy Entropy: 2.17730
Value Function Loss: 0.01839

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.56646
Value Function Update Magnitude: 0.68709

Collected Steps per Second: 22,665.34959
Overall Steps per Second: 10,734.05018

Timestep Collection Time: 2.20680
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.65975

Cumulative Model Updates: 234,894
Cumulative Timesteps: 1,959,065,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1959065582...
Checkpoint 1959065582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.06020
Policy Entropy: 2.19252
Value Function Loss: 0.01770

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.68521

Collected Steps per Second: 22,457.74173
Overall Steps per Second: 10,648.13035

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.69622

Cumulative Model Updates: 234,900
Cumulative Timesteps: 1,959,115,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.81690
Policy Entropy: 2.17639
Value Function Loss: 0.01794

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.56401
Value Function Update Magnitude: 0.68233

Collected Steps per Second: 22,698.51101
Overall Steps per Second: 10,832.34290

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.41418
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61802

Cumulative Model Updates: 234,906
Cumulative Timesteps: 1,959,165,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1959165612...
Checkpoint 1959165612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.03898
Policy Entropy: 2.17285
Value Function Loss: 0.01740

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.57219
Value Function Update Magnitude: 0.68631

Collected Steps per Second: 22,682.13504
Overall Steps per Second: 10,816.26826

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.62507

Cumulative Model Updates: 234,912
Cumulative Timesteps: 1,959,215,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.13847
Policy Entropy: 2.15682
Value Function Loss: 0.01731

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.55952
Value Function Update Magnitude: 0.66405

Collected Steps per Second: 23,472.09532
Overall Steps per Second: 10,821.02593

Timestep Collection Time: 2.13096
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.62230

Cumulative Model Updates: 234,918
Cumulative Timesteps: 1,959,265,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1959265656...
Checkpoint 1959265656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.21801
Policy Entropy: 2.17567
Value Function Loss: 0.01765

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.64269

Collected Steps per Second: 22,674.95894
Overall Steps per Second: 10,601.08724

Timestep Collection Time: 2.20631
Timestep Consumption Time: 2.51283
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.71914

Cumulative Model Updates: 234,924
Cumulative Timesteps: 1,959,315,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.12029
Policy Entropy: 2.20055
Value Function Loss: 0.01813

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.54287
Value Function Update Magnitude: 0.61479

Collected Steps per Second: 23,037.44868
Overall Steps per Second: 10,887.01124

Timestep Collection Time: 2.17081
Timestep Consumption Time: 2.42273
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.59355

Cumulative Model Updates: 234,930
Cumulative Timesteps: 1,959,365,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1959365694...
Checkpoint 1959365694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.98459
Policy Entropy: 2.20796
Value Function Loss: 0.01848

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.61396

Collected Steps per Second: 23,767.99743
Overall Steps per Second: 11,037.41725

Timestep Collection Time: 2.10434
Timestep Consumption Time: 2.42715
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.53149

Cumulative Model Updates: 234,936
Cumulative Timesteps: 1,959,415,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.93565
Policy Entropy: 2.20307
Value Function Loss: 0.01736

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.61783

Collected Steps per Second: 22,789.20496
Overall Steps per Second: 10,673.11489

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.68635

Cumulative Model Updates: 234,942
Cumulative Timesteps: 1,959,465,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1959465728...
Checkpoint 1959465728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.49326
Policy Entropy: 2.19993
Value Function Loss: 0.01737

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.53837
Value Function Update Magnitude: 0.62068

Collected Steps per Second: 22,993.11783
Overall Steps per Second: 10,927.94496

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.40211
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.57780

Cumulative Model Updates: 234,948
Cumulative Timesteps: 1,959,515,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.43178
Policy Entropy: 2.21346
Value Function Loss: 0.01721

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.61752

Collected Steps per Second: 22,455.85301
Overall Steps per Second: 10,903.38000

Timestep Collection Time: 2.22730
Timestep Consumption Time: 2.35990
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.58720

Cumulative Model Updates: 234,954
Cumulative Timesteps: 1,959,565,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1959565770...
Checkpoint 1959565770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.11690
Policy Entropy: 2.20073
Value Function Loss: 0.01690

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.52751
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 22,448.92289
Overall Steps per Second: 10,741.35241

Timestep Collection Time: 2.22781
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.65602

Cumulative Model Updates: 234,960
Cumulative Timesteps: 1,959,615,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.39520
Policy Entropy: 2.18476
Value Function Loss: 0.01671

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.53424
Value Function Update Magnitude: 0.61196

Collected Steps per Second: 22,710.14374
Overall Steps per Second: 10,797.34718

Timestep Collection Time: 2.20254
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.63262

Cumulative Model Updates: 234,966
Cumulative Timesteps: 1,959,665,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1959665802...
Checkpoint 1959665802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.96873
Policy Entropy: 2.16660
Value Function Loss: 0.01701

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.61532

Collected Steps per Second: 22,544.42755
Overall Steps per Second: 10,779.89269

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.64012

Cumulative Model Updates: 234,972
Cumulative Timesteps: 1,959,715,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.86929
Policy Entropy: 2.16367
Value Function Loss: 0.01807

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.65977

Collected Steps per Second: 23,136.27805
Overall Steps per Second: 10,879.68205

Timestep Collection Time: 2.16249
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.59866

Cumulative Model Updates: 234,978
Cumulative Timesteps: 1,959,765,854

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1959765854...
Checkpoint 1959765854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.85557
Policy Entropy: 2.18303
Value Function Loss: 0.01824

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.67691

Collected Steps per Second: 22,999.37440
Overall Steps per Second: 10,726.34058

Timestep Collection Time: 2.17519
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.66403

Cumulative Model Updates: 234,984
Cumulative Timesteps: 1,959,815,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.71503
Policy Entropy: 2.17007
Value Function Loss: 0.01712

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.55191
Value Function Update Magnitude: 0.64860

Collected Steps per Second: 23,669.95892
Overall Steps per Second: 10,779.88346

Timestep Collection Time: 2.11247
Timestep Consumption Time: 2.52599
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.63845

Cumulative Model Updates: 234,990
Cumulative Timesteps: 1,959,865,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1959865884...
Checkpoint 1959865884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.36357
Policy Entropy: 2.19443
Value Function Loss: 0.01627

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.64723

Collected Steps per Second: 22,697.12082
Overall Steps per Second: 10,705.50553

Timestep Collection Time: 2.20354
Timestep Consumption Time: 2.46826
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.67180

Cumulative Model Updates: 234,996
Cumulative Timesteps: 1,959,915,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.55722
Policy Entropy: 2.20203
Value Function Loss: 0.01581

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.53319
Value Function Update Magnitude: 0.64964

Collected Steps per Second: 23,371.42718
Overall Steps per Second: 11,011.58122

Timestep Collection Time: 2.14048
Timestep Consumption Time: 2.40256
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.54304

Cumulative Model Updates: 235,002
Cumulative Timesteps: 1,959,965,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1959965924...
Checkpoint 1959965924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.13738
Policy Entropy: 2.20915
Value Function Loss: 0.01703

Mean KL Divergence: 0.02801
SB3 Clip Fraction: 0.16497
Policy Update Magnitude: 0.52100
Value Function Update Magnitude: 0.64387

Collected Steps per Second: 22,578.84308
Overall Steps per Second: 10,650.79070

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.48022
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69486

Cumulative Model Updates: 235,008
Cumulative Timesteps: 1,960,015,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.18764
Policy Entropy: 2.17782
Value Function Loss: 0.01821

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.15899
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.62453

Collected Steps per Second: 22,494.14569
Overall Steps per Second: 10,769.87413

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.41997
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.64295

Cumulative Model Updates: 235,014
Cumulative Timesteps: 1,960,065,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1960065932...
Checkpoint 1960065932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.84830
Policy Entropy: 2.17098
Value Function Loss: 0.01899

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.15758
Policy Update Magnitude: 0.55528
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 22,455.62854
Overall Steps per Second: 10,648.96061

Timestep Collection Time: 2.22724
Timestep Consumption Time: 2.46937
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.69661

Cumulative Model Updates: 235,020
Cumulative Timesteps: 1,960,115,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.49498
Policy Entropy: 2.16527
Value Function Loss: 0.01927

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.56027
Value Function Update Magnitude: 0.63867

Collected Steps per Second: 22,822.77027
Overall Steps per Second: 10,868.27606

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.41091
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.60275

Cumulative Model Updates: 235,026
Cumulative Timesteps: 1,960,165,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1960165970...
Checkpoint 1960165970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.97971
Policy Entropy: 2.18551
Value Function Loss: 0.01848

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.55732
Value Function Update Magnitude: 0.64676

Collected Steps per Second: 21,979.02513
Overall Steps per Second: 10,622.57680

Timestep Collection Time: 2.27635
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70997

Cumulative Model Updates: 235,032
Cumulative Timesteps: 1,960,216,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.31184
Policy Entropy: 2.19426
Value Function Loss: 0.01831

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.63677

Collected Steps per Second: 23,181.40317
Overall Steps per Second: 10,850.38005

Timestep Collection Time: 2.15820
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61090

Cumulative Model Updates: 235,038
Cumulative Timesteps: 1,960,266,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1960266032...
Checkpoint 1960266032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.08233
Policy Entropy: 2.19183
Value Function Loss: 0.01826

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.64410

Collected Steps per Second: 22,988.45821
Overall Steps per Second: 10,726.44857

Timestep Collection Time: 2.17631
Timestep Consumption Time: 2.48786
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.66417

Cumulative Model Updates: 235,044
Cumulative Timesteps: 1,960,316,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.18084
Policy Entropy: 2.17815
Value Function Loss: 0.01819

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.66156

Collected Steps per Second: 23,198.80475
Overall Steps per Second: 10,882.51814

Timestep Collection Time: 2.15640
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.59691

Cumulative Model Updates: 235,050
Cumulative Timesteps: 1,960,366,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1960366088...
Checkpoint 1960366088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.73591
Policy Entropy: 2.17361
Value Function Loss: 0.01865

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.66950

Collected Steps per Second: 22,862.28371
Overall Steps per Second: 10,677.90231

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.68556

Cumulative Model Updates: 235,056
Cumulative Timesteps: 1,960,416,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.61470
Policy Entropy: 2.17819
Value Function Loss: 0.01644

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.65562

Collected Steps per Second: 23,218.24889
Overall Steps per Second: 10,882.48844

Timestep Collection Time: 2.15434
Timestep Consumption Time: 2.44204
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.59638

Cumulative Model Updates: 235,062
Cumulative Timesteps: 1,960,466,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1960466140...
Checkpoint 1960466140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.57087
Policy Entropy: 2.18897
Value Function Loss: 0.01654

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.53989
Value Function Update Magnitude: 0.62838

Collected Steps per Second: 22,836.37659
Overall Steps per Second: 10,638.76986

Timestep Collection Time: 2.19037
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.70167

Cumulative Model Updates: 235,068
Cumulative Timesteps: 1,960,516,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.53293
Policy Entropy: 2.15858
Value Function Loss: 0.01792

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.63499

Collected Steps per Second: 22,352.09601
Overall Steps per Second: 10,869.29570

Timestep Collection Time: 2.23764
Timestep Consumption Time: 2.36394
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.60159

Cumulative Model Updates: 235,074
Cumulative Timesteps: 1,960,566,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1960566176...
Checkpoint 1960566176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.86757
Policy Entropy: 2.15033
Value Function Loss: 0.01833

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.55906
Value Function Update Magnitude: 0.63919

Collected Steps per Second: 22,470.35371
Overall Steps per Second: 10,701.56287

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.44843
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.67483

Cumulative Model Updates: 235,080
Cumulative Timesteps: 1,960,616,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.60115
Policy Entropy: 2.14760
Value Function Loss: 0.01891

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.65811

Collected Steps per Second: 22,798.41599
Overall Steps per Second: 10,825.07649

Timestep Collection Time: 2.19375
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62020

Cumulative Model Updates: 235,086
Cumulative Timesteps: 1,960,666,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1960666218...
Checkpoint 1960666218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.17792
Policy Entropy: 2.17150
Value Function Loss: 0.01765

Mean KL Divergence: 0.02730
SB3 Clip Fraction: 0.16720
Policy Update Magnitude: 0.52037
Value Function Update Magnitude: 0.67176

Collected Steps per Second: 22,392.64468
Overall Steps per Second: 10,724.31675

Timestep Collection Time: 2.23377
Timestep Consumption Time: 2.43040
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.66417

Cumulative Model Updates: 235,092
Cumulative Timesteps: 1,960,716,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.29778
Policy Entropy: 2.17592
Value Function Loss: 0.01774

Mean KL Divergence: 0.02948
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.64799

Collected Steps per Second: 23,134.84717
Overall Steps per Second: 10,856.97885

Timestep Collection Time: 2.16237
Timestep Consumption Time: 2.44536
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.60773

Cumulative Model Updates: 235,098
Cumulative Timesteps: 1,960,766,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1960766264...
Checkpoint 1960766264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.67025
Policy Entropy: 2.18896
Value Function Loss: 0.01721

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.63334

Collected Steps per Second: 22,190.41446
Overall Steps per Second: 10,674.17654

Timestep Collection Time: 2.25431
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.68645

Cumulative Model Updates: 235,104
Cumulative Timesteps: 1,960,816,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.59769
Policy Entropy: 2.17510
Value Function Loss: 0.01793

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.62322

Collected Steps per Second: 22,596.84791
Overall Steps per Second: 10,688.63250

Timestep Collection Time: 2.21279
Timestep Consumption Time: 2.46527
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.67805

Cumulative Model Updates: 235,110
Cumulative Timesteps: 1,960,866,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1960866290...
Checkpoint 1960866290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.31764
Policy Entropy: 2.18917
Value Function Loss: 0.01760

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.56037
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 22,487.16092
Overall Steps per Second: 10,603.84937

Timestep Collection Time: 2.22438
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.71715

Cumulative Model Updates: 235,116
Cumulative Timesteps: 1,960,916,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.40558
Policy Entropy: 2.18298
Value Function Loss: 0.01814

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.62578

Collected Steps per Second: 22,883.06279
Overall Steps per Second: 10,734.74478

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.65964

Cumulative Model Updates: 235,122
Cumulative Timesteps: 1,960,966,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1960966330...
Checkpoint 1960966330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.86159
Policy Entropy: 2.20383
Value Function Loss: 0.01781

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.55311
Value Function Update Magnitude: 0.62213

Collected Steps per Second: 23,710.76002
Overall Steps per Second: 10,971.45338

Timestep Collection Time: 2.10934
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.55856

Cumulative Model Updates: 235,128
Cumulative Timesteps: 1,961,016,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.72553
Policy Entropy: 2.19780
Value Function Loss: 0.01846

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 22,922.57832
Overall Steps per Second: 10,679.55308

Timestep Collection Time: 2.18178
Timestep Consumption Time: 2.50119
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.68297

Cumulative Model Updates: 235,134
Cumulative Timesteps: 1,961,066,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1961066356...
Checkpoint 1961066356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.94960
Policy Entropy: 2.17807
Value Function Loss: 0.01762

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.62298

Collected Steps per Second: 23,003.45742
Overall Steps per Second: 10,915.36644

Timestep Collection Time: 2.17498
Timestep Consumption Time: 2.40865
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.58363

Cumulative Model Updates: 235,140
Cumulative Timesteps: 1,961,116,388

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.69307
Policy Entropy: 2.16807
Value Function Loss: 0.01711

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.54574
Value Function Update Magnitude: 0.60993

Collected Steps per Second: 23,348.76928
Overall Steps per Second: 11,010.54839

Timestep Collection Time: 2.14264
Timestep Consumption Time: 2.40100
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.54364

Cumulative Model Updates: 235,146
Cumulative Timesteps: 1,961,166,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1961166416...
Checkpoint 1961166416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.23926
Policy Entropy: 2.18016
Value Function Loss: 0.01604

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.58811

Collected Steps per Second: 22,902.19297
Overall Steps per Second: 10,659.16935

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.69117

Cumulative Model Updates: 235,152
Cumulative Timesteps: 1,961,216,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.51437
Policy Entropy: 2.20600
Value Function Loss: 0.01752

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.59380

Collected Steps per Second: 23,383.71887
Overall Steps per Second: 10,921.39967

Timestep Collection Time: 2.13833
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.57835

Cumulative Model Updates: 235,158
Cumulative Timesteps: 1,961,266,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1961266422...
Checkpoint 1961266422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.94875
Policy Entropy: 2.19594
Value Function Loss: 0.01894

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.60165

Collected Steps per Second: 22,286.57297
Overall Steps per Second: 10,616.84890

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.46649
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.71044

Cumulative Model Updates: 235,164
Cumulative Timesteps: 1,961,316,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.29334
Policy Entropy: 2.18564
Value Function Loss: 0.01913

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.55574
Value Function Update Magnitude: 0.61815

Collected Steps per Second: 22,614.64001
Overall Steps per Second: 10,824.85321

Timestep Collection Time: 2.21246
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62214

Cumulative Model Updates: 235,170
Cumulative Timesteps: 1,961,366,466

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1961366466...
Checkpoint 1961366466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.05883
Policy Entropy: 2.17091
Value Function Loss: 0.01889

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.61157

Collected Steps per Second: 22,245.30678
Overall Steps per Second: 10,620.42125

Timestep Collection Time: 2.24883
Timestep Consumption Time: 2.46153
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.71036

Cumulative Model Updates: 235,176
Cumulative Timesteps: 1,961,416,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.53440
Policy Entropy: 2.18024
Value Function Loss: 0.01955

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.55049
Value Function Update Magnitude: 0.60850

Collected Steps per Second: 21,919.51992
Overall Steps per Second: 10,488.66046

Timestep Collection Time: 2.28244
Timestep Consumption Time: 2.48747
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.76991

Cumulative Model Updates: 235,182
Cumulative Timesteps: 1,961,466,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1961466522...
Checkpoint 1961466522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.85194
Policy Entropy: 2.18160
Value Function Loss: 0.01854

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.55638
Value Function Update Magnitude: 0.61752

Collected Steps per Second: 22,727.91286
Overall Steps per Second: 10,752.07579

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.45180
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.65305

Cumulative Model Updates: 235,188
Cumulative Timesteps: 1,961,516,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.38505
Policy Entropy: 2.16337
Value Function Loss: 0.01914

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.56858
Value Function Update Magnitude: 0.61127

Collected Steps per Second: 23,218.66869
Overall Steps per Second: 10,799.27454

Timestep Collection Time: 2.15465
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.63253

Cumulative Model Updates: 235,194
Cumulative Timesteps: 1,961,566,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1961566580...
Checkpoint 1961566580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.73074
Policy Entropy: 2.14372
Value Function Loss: 0.01812

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.57218
Value Function Update Magnitude: 0.61387

Collected Steps per Second: 22,604.19920
Overall Steps per Second: 10,794.73611

Timestep Collection Time: 2.21233
Timestep Consumption Time: 2.42030
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.63263

Cumulative Model Updates: 235,200
Cumulative Timesteps: 1,961,616,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.30989
Policy Entropy: 2.14911
Value Function Loss: 0.01875

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.63302

Collected Steps per Second: 23,307.24472
Overall Steps per Second: 10,854.45405

Timestep Collection Time: 2.14594
Timestep Consumption Time: 2.46194
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.60788

Cumulative Model Updates: 235,206
Cumulative Timesteps: 1,961,666,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1961666604...
Checkpoint 1961666604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.93045
Policy Entropy: 2.19081
Value Function Loss: 0.01734

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.63985

Collected Steps per Second: 22,874.15637
Overall Steps per Second: 10,645.98691

Timestep Collection Time: 2.18596
Timestep Consumption Time: 2.51083
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.69679

Cumulative Model Updates: 235,212
Cumulative Timesteps: 1,961,716,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.45183
Policy Entropy: 2.20976
Value Function Loss: 0.01798

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.62838

Collected Steps per Second: 22,750.59754
Overall Steps per Second: 10,820.23086

Timestep Collection Time: 2.19889
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.62338

Cumulative Model Updates: 235,218
Cumulative Timesteps: 1,961,766,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1961766632...
Checkpoint 1961766632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.81765
Policy Entropy: 2.19841
Value Function Loss: 0.01659

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.61896

Collected Steps per Second: 21,962.38483
Overall Steps per Second: 10,714.72929

Timestep Collection Time: 2.27789
Timestep Consumption Time: 2.39119
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.66909

Cumulative Model Updates: 235,224
Cumulative Timesteps: 1,961,816,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.79118
Policy Entropy: 2.16923
Value Function Loss: 0.01729

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.52561
Value Function Update Magnitude: 0.60093

Collected Steps per Second: 22,661.08908
Overall Steps per Second: 10,708.54884

Timestep Collection Time: 2.20784
Timestep Consumption Time: 2.46432
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.67215

Cumulative Model Updates: 235,230
Cumulative Timesteps: 1,961,866,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1961866692...
Checkpoint 1961866692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.17942
Policy Entropy: 2.20408
Value Function Loss: 0.01712

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.53584
Value Function Update Magnitude: 0.57923

Collected Steps per Second: 22,429.45152
Overall Steps per Second: 10,742.35327

Timestep Collection Time: 2.22975
Timestep Consumption Time: 2.42584
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.65559

Cumulative Model Updates: 235,236
Cumulative Timesteps: 1,961,916,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.24888
Policy Entropy: 2.19049
Value Function Loss: 0.01710

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.54209
Value Function Update Magnitude: 0.58506

Collected Steps per Second: 22,952.68073
Overall Steps per Second: 10,974.88404

Timestep Collection Time: 2.17892
Timestep Consumption Time: 2.37803
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.55695

Cumulative Model Updates: 235,242
Cumulative Timesteps: 1,961,966,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1961966716...
Checkpoint 1961966716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.47061
Policy Entropy: 2.16968
Value Function Loss: 0.01681

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.55224

Collected Steps per Second: 22,869.75077
Overall Steps per Second: 10,641.86389

Timestep Collection Time: 2.18638
Timestep Consumption Time: 2.51223
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.69861

Cumulative Model Updates: 235,248
Cumulative Timesteps: 1,962,016,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.43699
Policy Entropy: 2.12656
Value Function Loss: 0.01771

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.54915

Collected Steps per Second: 23,233.53475
Overall Steps per Second: 10,904.77420

Timestep Collection Time: 2.15249
Timestep Consumption Time: 2.43357
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.58606

Cumulative Model Updates: 235,254
Cumulative Timesteps: 1,962,066,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1962066728...
Checkpoint 1962066728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.77740
Policy Entropy: 2.12251
Value Function Loss: 0.01803

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.56437

Collected Steps per Second: 22,722.33628
Overall Steps per Second: 10,706.04420

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.47107
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.67269

Cumulative Model Updates: 235,260
Cumulative Timesteps: 1,962,116,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.42073
Policy Entropy: 2.12714
Value Function Loss: 0.01823

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.56447

Collected Steps per Second: 23,420.38500
Overall Steps per Second: 10,888.16277

Timestep Collection Time: 2.13523
Timestep Consumption Time: 2.45764
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.59288

Cumulative Model Updates: 235,266
Cumulative Timesteps: 1,962,166,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1962166762...
Checkpoint 1962166762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.46768
Policy Entropy: 2.12464
Value Function Loss: 0.01745

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.54727
Value Function Update Magnitude: 0.57359

Collected Steps per Second: 23,011.52448
Overall Steps per Second: 11,054.03107

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.35173
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.52577

Cumulative Model Updates: 235,272
Cumulative Timesteps: 1,962,216,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.78320
Policy Entropy: 2.15959
Value Function Loss: 0.01639

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.57696

Collected Steps per Second: 22,436.96640
Overall Steps per Second: 10,575.88638

Timestep Collection Time: 2.22927
Timestep Consumption Time: 2.50017
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.72944

Cumulative Model Updates: 235,278
Cumulative Timesteps: 1,962,266,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1962266808...
Checkpoint 1962266808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.50290
Policy Entropy: 2.17626
Value Function Loss: 0.01687

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.57686

Collected Steps per Second: 22,460.33446
Overall Steps per Second: 10,547.80751

Timestep Collection Time: 2.22668
Timestep Consumption Time: 2.51478
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.74146

Cumulative Model Updates: 235,284
Cumulative Timesteps: 1,962,316,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.02108
Policy Entropy: 2.19451
Value Function Loss: 0.01702

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.53644
Value Function Update Magnitude: 0.59460

Collected Steps per Second: 22,556.48459
Overall Steps per Second: 10,821.68825

Timestep Collection Time: 2.21683
Timestep Consumption Time: 2.40389
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62072

Cumulative Model Updates: 235,290
Cumulative Timesteps: 1,962,366,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1962366824...
Checkpoint 1962366824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.67753
Policy Entropy: 2.17957
Value Function Loss: 0.01633

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.52622
Value Function Update Magnitude: 0.60624

Collected Steps per Second: 22,172.51444
Overall Steps per Second: 10,735.97855

Timestep Collection Time: 2.25522
Timestep Consumption Time: 2.40239
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.65761

Cumulative Model Updates: 235,296
Cumulative Timesteps: 1,962,416,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.28963
Policy Entropy: 2.18069
Value Function Loss: 0.01605

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.60581

Collected Steps per Second: 23,178.66076
Overall Steps per Second: 10,877.34577

Timestep Collection Time: 2.15750
Timestep Consumption Time: 2.43994
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59745

Cumulative Model Updates: 235,302
Cumulative Timesteps: 1,962,466,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1962466836...
Checkpoint 1962466836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.59400
Policy Entropy: 2.19935
Value Function Loss: 0.01536

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.52717
Value Function Update Magnitude: 0.60753

Collected Steps per Second: 22,721.09266
Overall Steps per Second: 10,675.41262

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68684

Cumulative Model Updates: 235,308
Cumulative Timesteps: 1,962,516,870

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.95448
Policy Entropy: 2.21120
Value Function Loss: 0.01593

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.52310
Value Function Update Magnitude: 0.58440

Collected Steps per Second: 23,320.75529
Overall Steps per Second: 10,876.26665

Timestep Collection Time: 2.14530
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.59992

Cumulative Model Updates: 235,314
Cumulative Timesteps: 1,962,566,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1962566900...
Checkpoint 1962566900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.85962
Policy Entropy: 2.24039
Value Function Loss: 0.01605

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.53033
Value Function Update Magnitude: 0.57941

Collected Steps per Second: 23,304.03328
Overall Steps per Second: 10,777.58213

Timestep Collection Time: 2.14692
Timestep Consumption Time: 2.49530
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.64223

Cumulative Model Updates: 235,320
Cumulative Timesteps: 1,962,616,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.22587
Policy Entropy: 2.22206
Value Function Loss: 0.01521

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.58839

Collected Steps per Second: 23,136.12432
Overall Steps per Second: 10,820.67204

Timestep Collection Time: 2.16199
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.62263

Cumulative Model Updates: 235,326
Cumulative Timesteps: 1,962,666,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1962666952...
Checkpoint 1962666952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.32311
Policy Entropy: 2.19700
Value Function Loss: 0.01659

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.59606

Collected Steps per Second: 22,337.03396
Overall Steps per Second: 10,602.72175

Timestep Collection Time: 2.23852
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.71596

Cumulative Model Updates: 235,332
Cumulative Timesteps: 1,962,716,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.69270
Policy Entropy: 2.15124
Value Function Loss: 0.01672

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.54610
Value Function Update Magnitude: 0.60801

Collected Steps per Second: 22,764.00421
Overall Steps per Second: 10,837.53783

Timestep Collection Time: 2.19777
Timestep Consumption Time: 2.41859
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61636

Cumulative Model Updates: 235,338
Cumulative Timesteps: 1,962,766,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1962766984...
Checkpoint 1962766984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.56608
Policy Entropy: 2.16573
Value Function Loss: 0.01714

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.61481

Collected Steps per Second: 22,037.74041
Overall Steps per Second: 10,753.98762

Timestep Collection Time: 2.26893
Timestep Consumption Time: 2.38070
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.64962

Cumulative Model Updates: 235,344
Cumulative Timesteps: 1,962,816,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.99379
Policy Entropy: 2.17236
Value Function Loss: 0.01632

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.53793
Value Function Update Magnitude: 0.59437

Collected Steps per Second: 22,800.53901
Overall Steps per Second: 10,815.82508

Timestep Collection Time: 2.19337
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.62378

Cumulative Model Updates: 235,350
Cumulative Timesteps: 1,962,866,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1962866996...
Checkpoint 1962866996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.72298
Policy Entropy: 2.17440
Value Function Loss: 0.01787

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.57829

Collected Steps per Second: 22,555.72376
Overall Steps per Second: 10,691.78193

Timestep Collection Time: 2.21771
Timestep Consumption Time: 2.46084
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.67855

Cumulative Model Updates: 235,356
Cumulative Timesteps: 1,962,917,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.01944
Policy Entropy: 2.15476
Value Function Loss: 0.01774

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.58729

Collected Steps per Second: 23,572.42793
Overall Steps per Second: 10,916.89671

Timestep Collection Time: 2.12265
Timestep Consumption Time: 2.46070
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.58335

Cumulative Model Updates: 235,362
Cumulative Timesteps: 1,962,967,054

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1962967054...
Checkpoint 1962967054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.52973
Policy Entropy: 2.15552
Value Function Loss: 0.01814

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.54068
Value Function Update Magnitude: 0.60607

Collected Steps per Second: 22,798.08565
Overall Steps per Second: 10,885.04369

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.40173
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.59621

Cumulative Model Updates: 235,368
Cumulative Timesteps: 1,963,017,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.49774
Policy Entropy: 2.18015
Value Function Loss: 0.01785

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.60296

Collected Steps per Second: 23,688.59755
Overall Steps per Second: 10,940.60138

Timestep Collection Time: 2.11089
Timestep Consumption Time: 2.45961
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.57050

Cumulative Model Updates: 235,374
Cumulative Timesteps: 1,963,067,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1963067088...
Checkpoint 1963067088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.53915
Policy Entropy: 2.19306
Value Function Loss: 0.01885

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.55084
Value Function Update Magnitude: 0.59830

Collected Steps per Second: 22,910.30839
Overall Steps per Second: 10,864.83122

Timestep Collection Time: 2.18242
Timestep Consumption Time: 2.41958
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.60200

Cumulative Model Updates: 235,380
Cumulative Timesteps: 1,963,117,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.23266
Policy Entropy: 2.24010
Value Function Loss: 0.01906

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.61171

Collected Steps per Second: 23,199.78585
Overall Steps per Second: 10,898.03855

Timestep Collection Time: 2.15623
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.59018

Cumulative Model Updates: 235,386
Cumulative Timesteps: 1,963,167,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1963167112...
Checkpoint 1963167112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.80952
Policy Entropy: 2.25413
Value Function Loss: 0.01782

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.53768
Value Function Update Magnitude: 0.62130

Collected Steps per Second: 22,412.05797
Overall Steps per Second: 10,624.74765

Timestep Collection Time: 2.23157
Timestep Consumption Time: 2.47575
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.70731

Cumulative Model Updates: 235,392
Cumulative Timesteps: 1,963,217,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.62546
Policy Entropy: 2.26977
Value Function Loss: 0.01729

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.53270
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,927.01497
Overall Steps per Second: 10,832.30562

Timestep Collection Time: 2.18083
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61582

Cumulative Model Updates: 235,398
Cumulative Timesteps: 1,963,267,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1963267126...
Checkpoint 1963267126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.43092
Policy Entropy: 2.22888
Value Function Loss: 0.01660

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.53482
Value Function Update Magnitude: 0.63098

Collected Steps per Second: 22,293.62629
Overall Steps per Second: 10,749.78862

Timestep Collection Time: 2.24360
Timestep Consumption Time: 2.40933
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.65293

Cumulative Model Updates: 235,404
Cumulative Timesteps: 1,963,317,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.53891
Policy Entropy: 2.21613
Value Function Loss: 0.01725

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.62733

Collected Steps per Second: 22,858.61173
Overall Steps per Second: 10,820.95668

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.43389
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.62177

Cumulative Model Updates: 235,410
Cumulative Timesteps: 1,963,367,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1963367156...
Checkpoint 1963367156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.98234
Policy Entropy: 2.17600
Value Function Loss: 0.01811

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.55663
Value Function Update Magnitude: 0.62576

Collected Steps per Second: 22,350.74674
Overall Steps per Second: 10,698.20630

Timestep Collection Time: 2.23769
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.67499

Cumulative Model Updates: 235,416
Cumulative Timesteps: 1,963,417,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.96860
Policy Entropy: 2.18296
Value Function Loss: 0.01701

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.54610
Value Function Update Magnitude: 0.63434

Collected Steps per Second: 22,983.71562
Overall Steps per Second: 10,840.37257

Timestep Collection Time: 2.17545
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61239

Cumulative Model Updates: 235,422
Cumulative Timesteps: 1,963,467,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1963467170...
Checkpoint 1963467170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.11192
Policy Entropy: 2.15971
Value Function Loss: 0.01828

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.54310
Value Function Update Magnitude: 0.61670

Collected Steps per Second: 22,699.25757
Overall Steps per Second: 10,820.45786

Timestep Collection Time: 2.20360
Timestep Consumption Time: 2.41913
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.62272

Cumulative Model Updates: 235,428
Cumulative Timesteps: 1,963,517,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.99649
Policy Entropy: 2.17329
Value Function Loss: 0.01746

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.61099

Collected Steps per Second: 23,556.01013
Overall Steps per Second: 10,811.72834

Timestep Collection Time: 2.12370
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.62701

Cumulative Model Updates: 235,434
Cumulative Timesteps: 1,963,567,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1963567216...
Checkpoint 1963567216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.74478
Policy Entropy: 2.18947
Value Function Loss: 0.01734

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.63611

Collected Steps per Second: 22,792.60507
Overall Steps per Second: 10,618.24918

Timestep Collection Time: 2.19396
Timestep Consumption Time: 2.51548
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.70944

Cumulative Model Updates: 235,440
Cumulative Timesteps: 1,963,617,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.18282
Policy Entropy: 2.20433
Value Function Loss: 0.01688

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.53816
Value Function Update Magnitude: 0.63591

Collected Steps per Second: 23,326.53827
Overall Steps per Second: 10,950.06497

Timestep Collection Time: 2.14357
Timestep Consumption Time: 2.42280
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.56637

Cumulative Model Updates: 235,446
Cumulative Timesteps: 1,963,667,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1963667224...
Checkpoint 1963667224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.17776
Policy Entropy: 2.22944
Value Function Loss: 0.01710

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.53829
Value Function Update Magnitude: 0.63120

Collected Steps per Second: 22,763.45112
Overall Steps per Second: 11,025.12799

Timestep Collection Time: 2.19782
Timestep Consumption Time: 2.33999
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.53782

Cumulative Model Updates: 235,452
Cumulative Timesteps: 1,963,717,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.58671
Policy Entropy: 2.19640
Value Function Loss: 0.01716

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.63929

Collected Steps per Second: 22,943.03689
Overall Steps per Second: 10,703.19233

Timestep Collection Time: 2.18009
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.67319

Cumulative Model Updates: 235,458
Cumulative Timesteps: 1,963,767,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1963767272...
Checkpoint 1963767272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.95316
Policy Entropy: 2.20295
Value Function Loss: 0.01732

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.62151

Collected Steps per Second: 22,241.61912
Overall Steps per Second: 10,535.03778

Timestep Collection Time: 2.24939
Timestep Consumption Time: 2.49953
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.74892

Cumulative Model Updates: 235,464
Cumulative Timesteps: 1,963,817,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.66430
Policy Entropy: 2.20405
Value Function Loss: 0.01710

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.60503

Collected Steps per Second: 23,125.75080
Overall Steps per Second: 10,835.34960

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.45283
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.61526

Cumulative Model Updates: 235,470
Cumulative Timesteps: 1,963,867,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1963867310...
Checkpoint 1963867310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.86500
Policy Entropy: 2.22067
Value Function Loss: 0.01751

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.52942
Value Function Update Magnitude: 0.59323

Collected Steps per Second: 23,319.25819
Overall Steps per Second: 10,849.84831

Timestep Collection Time: 2.14475
Timestep Consumption Time: 2.46490
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.60965

Cumulative Model Updates: 235,476
Cumulative Timesteps: 1,963,917,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.86495
Policy Entropy: 2.23144
Value Function Loss: 0.01805

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.52288
Value Function Update Magnitude: 0.59615

Collected Steps per Second: 23,575.49926
Overall Steps per Second: 10,734.69303

Timestep Collection Time: 2.12195
Timestep Consumption Time: 2.53827
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.66022

Cumulative Model Updates: 235,482
Cumulative Timesteps: 1,963,967,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1963967350...
Checkpoint 1963967350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.30306
Policy Entropy: 2.21312
Value Function Loss: 0.01897

Mean KL Divergence: 0.02990
SB3 Clip Fraction: 0.16762
Policy Update Magnitude: 0.50642
Value Function Update Magnitude: 0.60844

Collected Steps per Second: 22,754.97040
Overall Steps per Second: 10,710.59444

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.66902

Cumulative Model Updates: 235,488
Cumulative Timesteps: 1,964,017,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.77683
Policy Entropy: 2.20871
Value Function Loss: 0.01906

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.54882
Value Function Update Magnitude: 0.63229

Collected Steps per Second: 23,371.71033
Overall Steps per Second: 10,967.31542

Timestep Collection Time: 2.14002
Timestep Consumption Time: 2.42044
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.56046

Cumulative Model Updates: 235,494
Cumulative Timesteps: 1,964,067,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1964067374...
Checkpoint 1964067374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.83087
Policy Entropy: 2.20843
Value Function Loss: 0.01755

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.63194

Collected Steps per Second: 22,727.87797
Overall Steps per Second: 10,684.55362

Timestep Collection Time: 2.20047
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.68078

Cumulative Model Updates: 235,500
Cumulative Timesteps: 1,964,117,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.45089
Policy Entropy: 2.22361
Value Function Loss: 0.01637

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.53359
Value Function Update Magnitude: 0.61413

Collected Steps per Second: 23,334.93295
Overall Steps per Second: 10,766.92071

Timestep Collection Time: 2.14322
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.64497

Cumulative Model Updates: 235,506
Cumulative Timesteps: 1,964,167,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1964167398...
Checkpoint 1964167398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.95397
Policy Entropy: 2.22102
Value Function Loss: 0.01690

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.53533
Value Function Update Magnitude: 0.60899

Collected Steps per Second: 22,061.28069
Overall Steps per Second: 10,553.71255

Timestep Collection Time: 2.26768
Timestep Consumption Time: 2.47264
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.74032

Cumulative Model Updates: 235,512
Cumulative Timesteps: 1,964,217,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.72593
Policy Entropy: 2.21398
Value Function Loss: 0.01825

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.60549

Collected Steps per Second: 23,308.92930
Overall Steps per Second: 10,957.23997

Timestep Collection Time: 2.14562
Timestep Consumption Time: 2.41867
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.56429

Cumulative Model Updates: 235,518
Cumulative Timesteps: 1,964,267,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1964267438...
Checkpoint 1964267438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.76677
Policy Entropy: 2.17672
Value Function Loss: 0.01890

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 22,603.72225
Overall Steps per Second: 10,618.01989

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.49725
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.70954

Cumulative Model Updates: 235,524
Cumulative Timesteps: 1,964,317,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.21688
Policy Entropy: 2.17802
Value Function Loss: 0.01822

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.60650

Collected Steps per Second: 22,794.67199
Overall Steps per Second: 10,803.53757

Timestep Collection Time: 2.19428
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.62978

Cumulative Model Updates: 235,530
Cumulative Timesteps: 1,964,367,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1964367462...
Checkpoint 1964367462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.20785
Policy Entropy: 2.20528
Value Function Loss: 0.01655

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.53097
Value Function Update Magnitude: 0.60163

Collected Steps per Second: 22,264.97897
Overall Steps per Second: 10,756.94074

Timestep Collection Time: 2.24703
Timestep Consumption Time: 2.40392
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65095

Cumulative Model Updates: 235,536
Cumulative Timesteps: 1,964,417,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.77261
Policy Entropy: 2.22556
Value Function Loss: 0.01625

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.52938
Value Function Update Magnitude: 0.58661

Collected Steps per Second: 23,845.91772
Overall Steps per Second: 10,933.24246

Timestep Collection Time: 2.09696
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.57357

Cumulative Model Updates: 235,542
Cumulative Timesteps: 1,964,467,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1964467496...
Checkpoint 1964467496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.38639
Policy Entropy: 2.21132
Value Function Loss: 0.01742

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.53569
Value Function Update Magnitude: 0.59268

Collected Steps per Second: 22,718.73736
Overall Steps per Second: 10,642.43836

Timestep Collection Time: 2.20100
Timestep Consumption Time: 2.49754
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.69855

Cumulative Model Updates: 235,548
Cumulative Timesteps: 1,964,517,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.17731
Policy Entropy: 2.19307
Value Function Loss: 0.01701

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.59043

Collected Steps per Second: 23,074.37425
Overall Steps per Second: 10,904.19029

Timestep Collection Time: 2.16691
Timestep Consumption Time: 2.41849
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.58539

Cumulative Model Updates: 235,554
Cumulative Timesteps: 1,964,567,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1964567500...
Checkpoint 1964567500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.22490
Policy Entropy: 2.17829
Value Function Loss: 0.01831

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.58208

Collected Steps per Second: 22,769.58097
Overall Steps per Second: 10,987.69825

Timestep Collection Time: 2.19670
Timestep Consumption Time: 2.35548
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.55218

Cumulative Model Updates: 235,560
Cumulative Timesteps: 1,964,617,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.45367
Policy Entropy: 2.18872
Value Function Loss: 0.01686

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.60766

Collected Steps per Second: 22,142.54174
Overall Steps per Second: 10,553.63446

Timestep Collection Time: 2.25855
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.73865

Cumulative Model Updates: 235,566
Cumulative Timesteps: 1,964,667,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1964667528...
Checkpoint 1964667528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.22012
Policy Entropy: 2.16012
Value Function Loss: 0.01697

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.54088
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 22,572.59007
Overall Steps per Second: 10,634.83939

Timestep Collection Time: 2.21543
Timestep Consumption Time: 2.48685
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.70228

Cumulative Model Updates: 235,572
Cumulative Timesteps: 1,964,717,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.28256
Policy Entropy: 2.16049
Value Function Loss: 0.01622

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.60793

Collected Steps per Second: 23,107.90672
Overall Steps per Second: 10,963.13618

Timestep Collection Time: 2.16419
Timestep Consumption Time: 2.39746
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.56165

Cumulative Model Updates: 235,578
Cumulative Timesteps: 1,964,767,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1964767546...
Checkpoint 1964767546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.15085
Policy Entropy: 2.15171
Value Function Loss: 0.01765

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.54129
Value Function Update Magnitude: 0.63098

Collected Steps per Second: 22,748.15553
Overall Steps per Second: 10,823.79117

Timestep Collection Time: 2.19798
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.61945

Cumulative Model Updates: 235,584
Cumulative Timesteps: 1,964,817,546

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.19332
Policy Entropy: 2.17041
Value Function Loss: 0.01800

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.64827

Collected Steps per Second: 23,349.66864
Overall Steps per Second: 10,799.85658

Timestep Collection Time: 2.14213
Timestep Consumption Time: 2.48923
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.63136

Cumulative Model Updates: 235,590
Cumulative Timesteps: 1,964,867,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1964867564...
Checkpoint 1964867564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.17173
Policy Entropy: 2.20693
Value Function Loss: 0.01735

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.54461
Value Function Update Magnitude: 0.64460

Collected Steps per Second: 22,638.54132
Overall Steps per Second: 10,665.49457

Timestep Collection Time: 2.20889
Timestep Consumption Time: 2.47969
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.68858

Cumulative Model Updates: 235,596
Cumulative Timesteps: 1,964,917,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.41078
Policy Entropy: 2.20614
Value Function Loss: 0.01713

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 22,965.60807
Overall Steps per Second: 10,753.29324

Timestep Collection Time: 2.17760
Timestep Consumption Time: 2.47306
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.65067

Cumulative Model Updates: 235,602
Cumulative Timesteps: 1,964,967,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1964967580...
Checkpoint 1964967580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.88801
Policy Entropy: 2.22216
Value Function Loss: 0.01720

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 22,903.99436
Overall Steps per Second: 11,004.50468

Timestep Collection Time: 2.18329
Timestep Consumption Time: 2.36085
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.54414

Cumulative Model Updates: 235,608
Cumulative Timesteps: 1,965,017,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.52462
Policy Entropy: 2.18570
Value Function Loss: 0.01876

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.62454

Collected Steps per Second: 23,298.01514
Overall Steps per Second: 10,926.07809

Timestep Collection Time: 2.14636
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.57676

Cumulative Model Updates: 235,614
Cumulative Timesteps: 1,965,067,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1965067592...
Checkpoint 1965067592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.14303
Policy Entropy: 2.20999
Value Function Loss: 0.01756

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.54391
Value Function Update Magnitude: 0.61230

Collected Steps per Second: 22,288.66201
Overall Steps per Second: 10,710.50075

Timestep Collection Time: 2.24464
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.67112

Cumulative Model Updates: 235,620
Cumulative Timesteps: 1,965,117,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.27773
Policy Entropy: 2.18025
Value Function Loss: 0.01938

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.60075

Collected Steps per Second: 22,952.93638
Overall Steps per Second: 10,905.04219

Timestep Collection Time: 2.17907
Timestep Consumption Time: 2.40743
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.58650

Cumulative Model Updates: 235,626
Cumulative Timesteps: 1,965,167,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1965167638...
Checkpoint 1965167638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.99017
Policy Entropy: 2.21378
Value Function Loss: 0.01739

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.61235

Collected Steps per Second: 22,325.44236
Overall Steps per Second: 10,668.59061

Timestep Collection Time: 2.24005
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.68759

Cumulative Model Updates: 235,632
Cumulative Timesteps: 1,965,217,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.02186
Policy Entropy: 2.18529
Value Function Loss: 0.01882

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.61665

Collected Steps per Second: 23,061.25954
Overall Steps per Second: 10,922.34256

Timestep Collection Time: 2.16849
Timestep Consumption Time: 2.41002
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.57850

Cumulative Model Updates: 235,638
Cumulative Timesteps: 1,965,267,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1965267656...
Checkpoint 1965267656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.44460
Policy Entropy: 2.21193
Value Function Loss: 0.01779

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.55529
Value Function Update Magnitude: 0.60638

Collected Steps per Second: 22,791.07450
Overall Steps per Second: 10,638.59885

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.50663
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.70100

Cumulative Model Updates: 235,644
Cumulative Timesteps: 1,965,317,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.78375
Policy Entropy: 2.19245
Value Function Loss: 0.01770

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.54991
Value Function Update Magnitude: 0.61555

Collected Steps per Second: 23,259.57617
Overall Steps per Second: 10,916.58741

Timestep Collection Time: 2.15051
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.58202

Cumulative Model Updates: 235,650
Cumulative Timesteps: 1,965,367,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1965367688...
Checkpoint 1965367688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.86563
Policy Entropy: 2.22743
Value Function Loss: 0.01625

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.52786
Value Function Update Magnitude: 0.60095

Collected Steps per Second: 22,358.28413
Overall Steps per Second: 10,750.75296

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.41588
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.65344

Cumulative Model Updates: 235,656
Cumulative Timesteps: 1,965,417,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.92376
Policy Entropy: 2.23504
Value Function Loss: 0.01620

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.57601

Collected Steps per Second: 23,355.30978
Overall Steps per Second: 10,784.33486

Timestep Collection Time: 2.14187
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.63858

Cumulative Model Updates: 235,662
Cumulative Timesteps: 1,965,467,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1965467740...
Checkpoint 1965467740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.63810
Policy Entropy: 2.25759
Value Function Loss: 0.01705

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.52147
Value Function Update Magnitude: 0.56242

Collected Steps per Second: 22,786.65647
Overall Steps per Second: 10,627.62121

Timestep Collection Time: 2.19497
Timestep Consumption Time: 2.51126
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.70623

Cumulative Model Updates: 235,668
Cumulative Timesteps: 1,965,517,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.17822
Policy Entropy: 2.26724
Value Function Loss: 0.01746

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.52619
Value Function Update Magnitude: 0.55863

Collected Steps per Second: 23,372.86829
Overall Steps per Second: 10,934.46682

Timestep Collection Time: 2.13957
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.57343

Cumulative Model Updates: 235,674
Cumulative Timesteps: 1,965,567,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1965567764...
Checkpoint 1965567764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.89472
Policy Entropy: 2.24739
Value Function Loss: 0.01780

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.57148

Collected Steps per Second: 22,445.29862
Overall Steps per Second: 10,768.37278

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.41569
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.64341

Cumulative Model Updates: 235,680
Cumulative Timesteps: 1,965,617,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.70908
Policy Entropy: 2.21836
Value Function Loss: 0.01733

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.53215
Value Function Update Magnitude: 0.59643

Collected Steps per Second: 23,145.30535
Overall Steps per Second: 10,791.86380

Timestep Collection Time: 2.16027
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.63312

Cumulative Model Updates: 235,686
Cumulative Timesteps: 1,965,667,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1965667766...
Checkpoint 1965667766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.77275
Policy Entropy: 2.19147
Value Function Loss: 0.01688

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.60983

Collected Steps per Second: 22,495.91654
Overall Steps per Second: 10,626.92593

Timestep Collection Time: 2.22263
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.70503

Cumulative Model Updates: 235,692
Cumulative Timesteps: 1,965,717,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.80428
Policy Entropy: 2.19382
Value Function Loss: 0.01743

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.60303

Collected Steps per Second: 23,067.85386
Overall Steps per Second: 10,939.74152

Timestep Collection Time: 2.16752
Timestep Consumption Time: 2.40297
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.57049

Cumulative Model Updates: 235,698
Cumulative Timesteps: 1,965,767,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1965767766...
Checkpoint 1965767766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.53169
Policy Entropy: 2.20573
Value Function Loss: 0.01742

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.61878

Collected Steps per Second: 22,453.10096
Overall Steps per Second: 10,751.70033

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.42395
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.65117

Cumulative Model Updates: 235,704
Cumulative Timesteps: 1,965,817,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.52398
Policy Entropy: 2.19106
Value Function Loss: 0.01809

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.63368

Collected Steps per Second: 23,686.33061
Overall Steps per Second: 10,873.74763

Timestep Collection Time: 2.11126
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.59897

Cumulative Model Updates: 235,710
Cumulative Timesteps: 1,965,867,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1965867782...
Checkpoint 1965867782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.32901
Policy Entropy: 2.21662
Value Function Loss: 0.01685

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.54559
Value Function Update Magnitude: 0.63190

Collected Steps per Second: 22,811.24170
Overall Steps per Second: 10,713.72610

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.66710

Cumulative Model Updates: 235,716
Cumulative Timesteps: 1,965,917,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.86658
Policy Entropy: 2.22246
Value Function Loss: 0.01720

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.53539
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 23,413.15761
Overall Steps per Second: 10,887.98500

Timestep Collection Time: 2.13658
Timestep Consumption Time: 2.45785
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.59442

Cumulative Model Updates: 235,722
Cumulative Timesteps: 1,965,967,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1965967808...
Checkpoint 1965967808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.40884
Policy Entropy: 2.22448
Value Function Loss: 0.01554

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.52377
Value Function Update Magnitude: 0.59466

Collected Steps per Second: 22,732.95737
Overall Steps per Second: 10,852.88385

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.40878
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60928

Cumulative Model Updates: 235,728
Cumulative Timesteps: 1,966,017,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.90003
Policy Entropy: 2.21697
Value Function Loss: 0.01699

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.52356
Value Function Update Magnitude: 0.59011

Collected Steps per Second: 23,955.08338
Overall Steps per Second: 10,988.03642

Timestep Collection Time: 2.08849
Timestep Consumption Time: 2.46464
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.55313

Cumulative Model Updates: 235,734
Cumulative Timesteps: 1,966,067,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1966067862...
Checkpoint 1966067862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.34600
Policy Entropy: 2.21996
Value Function Loss: 0.01599

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.59786

Collected Steps per Second: 22,227.46395
Overall Steps per Second: 10,666.36562

Timestep Collection Time: 2.24947
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.68763

Cumulative Model Updates: 235,740
Cumulative Timesteps: 1,966,117,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.90472
Policy Entropy: 2.23231
Value Function Loss: 0.01692

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.52991
Value Function Update Magnitude: 0.59542

Collected Steps per Second: 22,833.42873
Overall Steps per Second: 10,849.74624

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.60988

Cumulative Model Updates: 235,746
Cumulative Timesteps: 1,966,167,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1966167878...
Checkpoint 1966167878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.30280
Policy Entropy: 2.20980
Value Function Loss: 0.01775

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 22,285.25654
Overall Steps per Second: 10,707.47732

Timestep Collection Time: 2.24417
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.67075

Cumulative Model Updates: 235,752
Cumulative Timesteps: 1,966,217,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.98474
Policy Entropy: 2.19482
Value Function Loss: 0.01821

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.55160
Value Function Update Magnitude: 0.61177

Collected Steps per Second: 23,125.58420
Overall Steps per Second: 10,897.05451

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.42716
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.59005

Cumulative Model Updates: 235,758
Cumulative Timesteps: 1,966,267,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1966267908...
Checkpoint 1966267908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.60902
Policy Entropy: 2.20771
Value Function Loss: 0.01874

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.55286
Value Function Update Magnitude: 0.62334

Collected Steps per Second: 22,638.65771
Overall Steps per Second: 10,643.08456

Timestep Collection Time: 2.21038
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.70164

Cumulative Model Updates: 235,764
Cumulative Timesteps: 1,966,317,948

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.35359
Policy Entropy: 2.21914
Value Function Loss: 0.01771

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.62686

Collected Steps per Second: 23,025.28015
Overall Steps per Second: 10,850.85885

Timestep Collection Time: 2.17161
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.60811

Cumulative Model Updates: 235,770
Cumulative Timesteps: 1,966,367,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1966367950...
Checkpoint 1966367950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.16022
Policy Entropy: 2.22452
Value Function Loss: 0.01708

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.63724

Collected Steps per Second: 23,285.56088
Overall Steps per Second: 10,747.89711

Timestep Collection Time: 2.14734
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.65226

Cumulative Model Updates: 235,776
Cumulative Timesteps: 1,966,417,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.57432
Policy Entropy: 2.22189
Value Function Loss: 0.01587

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.53358
Value Function Update Magnitude: 0.64100

Collected Steps per Second: 23,402.50702
Overall Steps per Second: 10,841.68662

Timestep Collection Time: 2.13704
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.61294

Cumulative Model Updates: 235,782
Cumulative Timesteps: 1,966,467,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1966467964...
Checkpoint 1966467964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.58364
Policy Entropy: 2.19063
Value Function Loss: 0.01729

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.55125
Value Function Update Magnitude: 0.62696

Collected Steps per Second: 22,707.14093
Overall Steps per Second: 10,687.07995

Timestep Collection Time: 2.20310
Timestep Consumption Time: 2.47788
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.68098

Cumulative Model Updates: 235,788
Cumulative Timesteps: 1,966,517,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.74318
Policy Entropy: 2.18753
Value Function Loss: 0.01788

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.61694

Collected Steps per Second: 23,436.45163
Overall Steps per Second: 11,005.61114

Timestep Collection Time: 2.13351
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.54332

Cumulative Model Updates: 235,794
Cumulative Timesteps: 1,966,567,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1966567992...
Checkpoint 1966567992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.44617
Policy Entropy: 2.17640
Value Function Loss: 0.01863

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.60912

Collected Steps per Second: 22,704.05896
Overall Steps per Second: 10,695.36944

Timestep Collection Time: 2.20304
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.67660

Cumulative Model Updates: 235,800
Cumulative Timesteps: 1,966,618,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.94325
Policy Entropy: 2.20811
Value Function Loss: 0.01773

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.58930

Collected Steps per Second: 22,989.07300
Overall Steps per Second: 10,741.23080

Timestep Collection Time: 2.17625
Timestep Consumption Time: 2.48150
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.65775

Cumulative Model Updates: 235,806
Cumulative Timesteps: 1,966,668,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1966668040...
Checkpoint 1966668040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.04671
Policy Entropy: 2.22665
Value Function Loss: 0.01802

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.58857

Collected Steps per Second: 22,179.20122
Overall Steps per Second: 10,639.95696

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.44500
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.69946

Cumulative Model Updates: 235,812
Cumulative Timesteps: 1,966,718,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.61777
Policy Entropy: 2.22233
Value Function Loss: 0.01720

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.60249

Collected Steps per Second: 23,716.33207
Overall Steps per Second: 10,887.71001

Timestep Collection Time: 2.10850
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.59289

Cumulative Model Updates: 235,818
Cumulative Timesteps: 1,966,768,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1966768048...
Checkpoint 1966768048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.71154
Policy Entropy: 2.20605
Value Function Loss: 0.01772

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.53660
Value Function Update Magnitude: 0.63482

Collected Steps per Second: 22,290.31964
Overall Steps per Second: 10,621.69797

Timestep Collection Time: 2.24313
Timestep Consumption Time: 2.46422
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.70735

Cumulative Model Updates: 235,824
Cumulative Timesteps: 1,966,818,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.00149
Policy Entropy: 2.18576
Value Function Loss: 0.01731

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.66579

Collected Steps per Second: 22,934.40292
Overall Steps per Second: 10,696.98946

Timestep Collection Time: 2.18048
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.67496

Cumulative Model Updates: 235,830
Cumulative Timesteps: 1,966,868,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1966868056...
Checkpoint 1966868056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.75375
Policy Entropy: 2.17785
Value Function Loss: 0.01684

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.67475

Collected Steps per Second: 22,787.44309
Overall Steps per Second: 10,863.91043

Timestep Collection Time: 2.19524
Timestep Consumption Time: 2.40936
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.60460

Cumulative Model Updates: 235,836
Cumulative Timesteps: 1,966,918,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.04117
Policy Entropy: 2.16540
Value Function Loss: 0.01548

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.53833
Value Function Update Magnitude: 0.65580

Collected Steps per Second: 23,216.46986
Overall Steps per Second: 10,918.72852

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.42623
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.58039

Cumulative Model Updates: 235,842
Cumulative Timesteps: 1,966,968,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1966968092...
Checkpoint 1966968092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.01927
Policy Entropy: 2.13997
Value Function Loss: 0.01595

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.63816

Collected Steps per Second: 22,904.04707
Overall Steps per Second: 10,681.79918

Timestep Collection Time: 2.18381
Timestep Consumption Time: 2.49874
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.68254

Cumulative Model Updates: 235,848
Cumulative Timesteps: 1,967,018,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.56774
Policy Entropy: 2.12993
Value Function Loss: 0.01618

Mean KL Divergence: 0.02565
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.64995

Collected Steps per Second: 23,030.19546
Overall Steps per Second: 10,935.19155

Timestep Collection Time: 2.17132
Timestep Consumption Time: 2.40162
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.57294

Cumulative Model Updates: 235,854
Cumulative Timesteps: 1,967,068,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1967068116...
Checkpoint 1967068116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.77442
Policy Entropy: 2.17747
Value Function Loss: 0.01709

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.65615

Collected Steps per Second: 22,522.84512
Overall Steps per Second: 10,946.86220

Timestep Collection Time: 2.22015
Timestep Consumption Time: 2.34774
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.56788

Cumulative Model Updates: 235,860
Cumulative Timesteps: 1,967,118,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.99238
Policy Entropy: 2.20397
Value Function Loss: 0.01728

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.63152

Collected Steps per Second: 22,698.83006
Overall Steps per Second: 10,627.36864

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.50208
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.70483

Cumulative Model Updates: 235,866
Cumulative Timesteps: 1,967,168,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1967168120...
Checkpoint 1967168120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.44104
Policy Entropy: 2.20464
Value Function Loss: 0.01870

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.63360

Collected Steps per Second: 22,460.95711
Overall Steps per Second: 10,585.18319

Timestep Collection Time: 2.22626
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.72396

Cumulative Model Updates: 235,872
Cumulative Timesteps: 1,967,218,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.89051
Policy Entropy: 2.16949
Value Function Loss: 0.01944

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.56167
Value Function Update Magnitude: 0.66002

Collected Steps per Second: 22,898.35702
Overall Steps per Second: 10,866.08073

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.60332

Cumulative Model Updates: 235,878
Cumulative Timesteps: 1,967,268,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1967268144...
Checkpoint 1967268144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.10720
Policy Entropy: 2.15622
Value Function Loss: 0.01928

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.67574

Collected Steps per Second: 22,497.17571
Overall Steps per Second: 10,635.64699

Timestep Collection Time: 2.22259
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.70136

Cumulative Model Updates: 235,884
Cumulative Timesteps: 1,967,318,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.84354
Policy Entropy: 2.15461
Value Function Loss: 0.01856

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.55997
Value Function Update Magnitude: 0.67941

Collected Steps per Second: 23,226.34566
Overall Steps per Second: 10,817.73392

Timestep Collection Time: 2.15367
Timestep Consumption Time: 2.47040
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62407

Cumulative Model Updates: 235,890
Cumulative Timesteps: 1,967,368,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1967368168...
Checkpoint 1967368168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.98798
Policy Entropy: 2.15791
Value Function Loss: 0.01881

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.56568
Value Function Update Magnitude: 0.67851

Collected Steps per Second: 22,602.08018
Overall Steps per Second: 10,750.84623

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.43988
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65322

Cumulative Model Updates: 235,896
Cumulative Timesteps: 1,967,418,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.57166
Policy Entropy: 2.15783
Value Function Loss: 0.01868

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.65252

Collected Steps per Second: 23,095.23218
Overall Steps per Second: 10,910.56626

Timestep Collection Time: 2.16530
Timestep Consumption Time: 2.41815
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.58345

Cumulative Model Updates: 235,902
Cumulative Timesteps: 1,967,468,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1967468202...
Checkpoint 1967468202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.36112
Policy Entropy: 2.16755
Value Function Loss: 0.01902

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.64250

Collected Steps per Second: 23,478.30276
Overall Steps per Second: 10,997.14460

Timestep Collection Time: 2.12980
Timestep Consumption Time: 2.41720
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.54700

Cumulative Model Updates: 235,908
Cumulative Timesteps: 1,967,518,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.53344
Policy Entropy: 2.18371
Value Function Loss: 0.01841

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.55178
Value Function Update Magnitude: 0.64976

Collected Steps per Second: 23,264.51596
Overall Steps per Second: 10,919.08469

Timestep Collection Time: 2.14920
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.57914

Cumulative Model Updates: 235,914
Cumulative Timesteps: 1,967,568,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1967568206...
Checkpoint 1967568206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.15803
Policy Entropy: 2.19687
Value Function Loss: 0.01823

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.54445
Value Function Update Magnitude: 0.65450

Collected Steps per Second: 22,382.51640
Overall Steps per Second: 10,690.22454

Timestep Collection Time: 2.23478
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.67904

Cumulative Model Updates: 235,920
Cumulative Timesteps: 1,967,618,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.95427
Policy Entropy: 2.20708
Value Function Loss: 0.01882

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11790
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.64591

Collected Steps per Second: 22,858.91194
Overall Steps per Second: 10,858.38790

Timestep Collection Time: 2.18742
Timestep Consumption Time: 2.41750
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.60492

Cumulative Model Updates: 235,926
Cumulative Timesteps: 1,967,668,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1967668228...
Checkpoint 1967668228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.35111
Policy Entropy: 2.20259
Value Function Loss: 0.01804

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.64241

Collected Steps per Second: 23,072.49936
Overall Steps per Second: 10,718.64093

Timestep Collection Time: 2.16804
Timestep Consumption Time: 2.49879
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.66682

Cumulative Model Updates: 235,932
Cumulative Timesteps: 1,967,718,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.48054
Policy Entropy: 2.20492
Value Function Loss: 0.01831

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.64333

Collected Steps per Second: 23,287.71236
Overall Steps per Second: 10,914.42604

Timestep Collection Time: 2.14817
Timestep Consumption Time: 2.43530
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58348

Cumulative Model Updates: 235,938
Cumulative Timesteps: 1,967,768,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1967768276...
Checkpoint 1967768276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.16139
Policy Entropy: 2.18630
Value Function Loss: 0.01840

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 22,718.63449
Overall Steps per Second: 10,623.51661

Timestep Collection Time: 2.20163
Timestep Consumption Time: 2.50660
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.70823

Cumulative Model Updates: 235,944
Cumulative Timesteps: 1,967,818,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.29093
Policy Entropy: 2.18518
Value Function Loss: 0.01901

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.65229

Collected Steps per Second: 23,356.54075
Overall Steps per Second: 10,954.03044

Timestep Collection Time: 2.14141
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.56599

Cumulative Model Updates: 235,950
Cumulative Timesteps: 1,967,868,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1967868310...
Checkpoint 1967868310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.02576
Policy Entropy: 2.15721
Value Function Loss: 0.01973

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.64312

Collected Steps per Second: 23,009.45678
Overall Steps per Second: 10,744.47120

Timestep Collection Time: 2.17354
Timestep Consumption Time: 2.48113
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.65467

Cumulative Model Updates: 235,956
Cumulative Timesteps: 1,967,918,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.06618
Policy Entropy: 2.18447
Value Function Loss: 0.01943

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.64058

Collected Steps per Second: 23,281.98998
Overall Steps per Second: 10,767.89498

Timestep Collection Time: 2.14896
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.64640

Cumulative Model Updates: 235,962
Cumulative Timesteps: 1,967,968,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1967968354...
Checkpoint 1967968354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.48756
Policy Entropy: 2.18083
Value Function Loss: 0.01941

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.56315
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,554.41467
Overall Steps per Second: 10,651.34191

Timestep Collection Time: 2.21686
Timestep Consumption Time: 2.47738
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.69424

Cumulative Model Updates: 235,968
Cumulative Timesteps: 1,968,018,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.67446
Policy Entropy: 2.20680
Value Function Loss: 0.01820

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.55922
Value Function Update Magnitude: 0.65045

Collected Steps per Second: 23,226.51966
Overall Steps per Second: 10,901.74896

Timestep Collection Time: 2.15400
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.58917

Cumulative Model Updates: 235,974
Cumulative Timesteps: 1,968,068,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1968068384...
Checkpoint 1968068384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.68556
Policy Entropy: 2.19297
Value Function Loss: 0.01937

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.65311

Collected Steps per Second: 22,787.58285
Overall Steps per Second: 10,635.22750

Timestep Collection Time: 2.19453
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.70211

Cumulative Model Updates: 235,980
Cumulative Timesteps: 1,968,118,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.09112
Policy Entropy: 2.20969
Value Function Loss: 0.01792

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.64749

Collected Steps per Second: 23,220.71212
Overall Steps per Second: 10,921.55568

Timestep Collection Time: 2.15334
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.57829

Cumulative Model Updates: 235,986
Cumulative Timesteps: 1,968,168,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1968168394...
Checkpoint 1968168394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.00651
Policy Entropy: 2.18582
Value Function Loss: 0.01758

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.50348
Value Function Update Magnitude: 0.63385

Collected Steps per Second: 22,320.48255
Overall Steps per Second: 10,601.68414

Timestep Collection Time: 2.24153
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.71925

Cumulative Model Updates: 235,992
Cumulative Timesteps: 1,968,218,426

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.87643
Policy Entropy: 2.18121
Value Function Loss: 0.01657

Mean KL Divergence: 0.03648
SB3 Clip Fraction: 0.18606
Policy Update Magnitude: 0.48282
Value Function Update Magnitude: 0.59946

Collected Steps per Second: 22,922.49749
Overall Steps per Second: 10,871.37778

Timestep Collection Time: 2.18283
Timestep Consumption Time: 2.41971
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60254

Cumulative Model Updates: 235,998
Cumulative Timesteps: 1,968,268,462

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1968268462...
Checkpoint 1968268462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.69830
Policy Entropy: 2.15182
Value Function Loss: 0.01660

Mean KL Divergence: 0.02938
SB3 Clip Fraction: 0.16632
Policy Update Magnitude: 0.49040
Value Function Update Magnitude: 0.58575

Collected Steps per Second: 23,052.98256
Overall Steps per Second: 10,742.09451

Timestep Collection Time: 2.17022
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.65738

Cumulative Model Updates: 236,004
Cumulative Timesteps: 1,968,318,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.28248
Policy Entropy: 2.16563
Value Function Loss: 0.01708

Mean KL Divergence: 0.02885
SB3 Clip Fraction: 0.16653
Policy Update Magnitude: 0.52082
Value Function Update Magnitude: 0.59418

Collected Steps per Second: 23,477.00489
Overall Steps per Second: 10,935.88663

Timestep Collection Time: 2.13025
Timestep Consumption Time: 2.44295
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.57320

Cumulative Model Updates: 236,010
Cumulative Timesteps: 1,968,368,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1968368504...
Checkpoint 1968368504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.83241
Policy Entropy: 2.16878
Value Function Loss: 0.01780

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.16408
Policy Update Magnitude: 0.52994
Value Function Update Magnitude: 0.63499

Collected Steps per Second: 22,759.13918
Overall Steps per Second: 10,609.64307

Timestep Collection Time: 2.19710
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.71307

Cumulative Model Updates: 236,016
Cumulative Timesteps: 1,968,418,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.02495
Policy Entropy: 2.17882
Value Function Loss: 0.01765

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.64808

Collected Steps per Second: 23,036.62781
Overall Steps per Second: 10,923.39002

Timestep Collection Time: 2.17159
Timestep Consumption Time: 2.40813
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.57971

Cumulative Model Updates: 236,022
Cumulative Timesteps: 1,968,468,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1968468534...
Checkpoint 1968468534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.40974
Policy Entropy: 2.20743
Value Function Loss: 0.01640

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.54180
Value Function Update Magnitude: 0.62689

Collected Steps per Second: 22,474.16765
Overall Steps per Second: 10,666.34801

Timestep Collection Time: 2.22576
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.68970

Cumulative Model Updates: 236,028
Cumulative Timesteps: 1,968,518,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.69568
Policy Entropy: 2.23376
Value Function Loss: 0.01569

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.52883
Value Function Update Magnitude: 0.61973

Collected Steps per Second: 23,306.16503
Overall Steps per Second: 10,871.22237

Timestep Collection Time: 2.14536
Timestep Consumption Time: 2.45394
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.59930

Cumulative Model Updates: 236,034
Cumulative Timesteps: 1,968,568,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1968568556...
Checkpoint 1968568556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.72024
Policy Entropy: 2.25117
Value Function Loss: 0.01548

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.52056
Value Function Update Magnitude: 0.62481

Collected Steps per Second: 22,538.16428
Overall Steps per Second: 10,652.27757

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.69533

Cumulative Model Updates: 236,040
Cumulative Timesteps: 1,968,618,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.24523
Policy Entropy: 2.22927
Value Function Loss: 0.01681

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.52986
Value Function Update Magnitude: 0.62955

Collected Steps per Second: 22,361.95626
Overall Steps per Second: 10,647.64293

Timestep Collection Time: 2.23728
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.69869

Cumulative Model Updates: 236,046
Cumulative Timesteps: 1,968,668,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1968668602...
Checkpoint 1968668602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.29920
Policy Entropy: 2.22762
Value Function Loss: 0.01710

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.65002

Collected Steps per Second: 22,578.49847
Overall Steps per Second: 10,938.83287

Timestep Collection Time: 2.21512
Timestep Consumption Time: 2.35704
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.57215

Cumulative Model Updates: 236,052
Cumulative Timesteps: 1,968,718,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.28868
Policy Entropy: 2.20124
Value Function Loss: 0.01802

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.54096
Value Function Update Magnitude: 0.65909

Collected Steps per Second: 23,067.70176
Overall Steps per Second: 10,866.59533

Timestep Collection Time: 2.16805
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60236

Cumulative Model Updates: 236,058
Cumulative Timesteps: 1,968,768,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1968768628...
Checkpoint 1968768628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.28133
Policy Entropy: 2.17748
Value Function Loss: 0.01845

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.65891

Collected Steps per Second: 22,174.13462
Overall Steps per Second: 10,661.01490

Timestep Collection Time: 2.25542
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.69111

Cumulative Model Updates: 236,064
Cumulative Timesteps: 1,968,818,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.48595
Policy Entropy: 2.18002
Value Function Loss: 0.01828

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.65652

Collected Steps per Second: 23,045.77106
Overall Steps per Second: 10,924.00225

Timestep Collection Time: 2.16986
Timestep Consumption Time: 2.40777
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.57763

Cumulative Model Updates: 236,070
Cumulative Timesteps: 1,968,868,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1968868646...
Checkpoint 1968868646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.66086
Policy Entropy: 2.19795
Value Function Loss: 0.01851

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.64285

Collected Steps per Second: 23,016.23235
Overall Steps per Second: 10,734.68366

Timestep Collection Time: 2.17377
Timestep Consumption Time: 2.48701
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.66078

Cumulative Model Updates: 236,076
Cumulative Timesteps: 1,968,918,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.78430
Policy Entropy: 2.18592
Value Function Loss: 0.01739

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.55403
Value Function Update Magnitude: 0.62694

Collected Steps per Second: 22,960.58815
Overall Steps per Second: 10,759.61177

Timestep Collection Time: 2.17817
Timestep Consumption Time: 2.46996
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.64812

Cumulative Model Updates: 236,082
Cumulative Timesteps: 1,968,968,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1968968690...
Checkpoint 1968968690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.09244
Policy Entropy: 2.17405
Value Function Loss: 0.01773

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.55414
Value Function Update Magnitude: 0.61368

Collected Steps per Second: 22,132.11530
Overall Steps per Second: 10,631.11395

Timestep Collection Time: 2.26015
Timestep Consumption Time: 2.44509
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.70525

Cumulative Model Updates: 236,088
Cumulative Timesteps: 1,969,018,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.72220
Policy Entropy: 2.17734
Value Function Loss: 0.01788

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.60610

Collected Steps per Second: 23,198.44207
Overall Steps per Second: 10,973.07440

Timestep Collection Time: 2.15635
Timestep Consumption Time: 2.40244
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.55880

Cumulative Model Updates: 236,094
Cumulative Timesteps: 1,969,068,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1969068736...
Checkpoint 1969068736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.48191
Policy Entropy: 2.22658
Value Function Loss: 0.01775

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 22,734.49064
Overall Steps per Second: 10,617.43657

Timestep Collection Time: 2.19939
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70942

Cumulative Model Updates: 236,100
Cumulative Timesteps: 1,969,118,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.05386
Policy Entropy: 2.22344
Value Function Loss: 0.01795

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.59184

Collected Steps per Second: 22,846.15417
Overall Steps per Second: 10,804.36349

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.43931
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62795

Cumulative Model Updates: 236,106
Cumulative Timesteps: 1,969,168,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1969168740...
Checkpoint 1969168740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.56875
Policy Entropy: 2.22573
Value Function Loss: 0.01906

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.59054

Collected Steps per Second: 22,264.20460
Overall Steps per Second: 10,719.05592

Timestep Collection Time: 2.24576
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.66459

Cumulative Model Updates: 236,112
Cumulative Timesteps: 1,969,218,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.49921
Policy Entropy: 2.18904
Value Function Loss: 0.01953

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.62431

Collected Steps per Second: 23,601.38548
Overall Steps per Second: 10,963.02298

Timestep Collection Time: 2.11894
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.56170

Cumulative Model Updates: 236,118
Cumulative Timesteps: 1,969,268,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1969268750...
Checkpoint 1969268750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.50171
Policy Entropy: 2.19676
Value Function Loss: 0.01965

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.64257

Collected Steps per Second: 22,688.68235
Overall Steps per Second: 10,631.30742

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.70460

Cumulative Model Updates: 236,124
Cumulative Timesteps: 1,969,318,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.91936
Policy Entropy: 2.16592
Value Function Loss: 0.01963

Mean KL Divergence: 0.02704
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.51536
Value Function Update Magnitude: 0.64289

Collected Steps per Second: 23,201.32982
Overall Steps per Second: 10,854.49773

Timestep Collection Time: 2.15565
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.60768

Cumulative Model Updates: 236,130
Cumulative Timesteps: 1,969,368,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1969368780...
Checkpoint 1969368780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.67791
Policy Entropy: 2.19422
Value Function Loss: 0.01890

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.16375
Policy Update Magnitude: 0.51606
Value Function Update Magnitude: 0.64002

Collected Steps per Second: 22,643.08471
Overall Steps per Second: 10,642.41037

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.69818

Cumulative Model Updates: 236,136
Cumulative Timesteps: 1,969,418,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.51416
Policy Entropy: 2.18600
Value Function Loss: 0.01856

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.53517
Value Function Update Magnitude: 0.63577

Collected Steps per Second: 24,238.14574
Overall Steps per Second: 10,950.59121

Timestep Collection Time: 2.06303
Timestep Consumption Time: 2.50330
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.56633

Cumulative Model Updates: 236,142
Cumulative Timesteps: 1,969,468,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1969468784...
Checkpoint 1969468784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.76602
Policy Entropy: 2.19182
Value Function Loss: 0.01844

Mean KL Divergence: 0.02547
SB3 Clip Fraction: 0.15842
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.62757

Collected Steps per Second: 22,971.68511
Overall Steps per Second: 10,697.90600

Timestep Collection Time: 2.17781
Timestep Consumption Time: 2.49862
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.67643

Cumulative Model Updates: 236,148
Cumulative Timesteps: 1,969,518,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.04936
Policy Entropy: 2.16884
Value Function Loss: 0.01959

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.16150
Policy Update Magnitude: 0.51074
Value Function Update Magnitude: 0.62850

Collected Steps per Second: 23,457.26087
Overall Steps per Second: 10,846.20902

Timestep Collection Time: 2.13213
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.61120

Cumulative Model Updates: 236,154
Cumulative Timesteps: 1,969,568,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1969568826...
Checkpoint 1969568826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.74682
Policy Entropy: 2.15830
Value Function Loss: 0.01938

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.53689
Value Function Update Magnitude: 0.63222

Collected Steps per Second: 22,300.17069
Overall Steps per Second: 10,727.12556

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.42030
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.66369

Cumulative Model Updates: 236,160
Cumulative Timesteps: 1,969,618,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.25346
Policy Entropy: 2.18572
Value Function Loss: 0.01815

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.54605
Value Function Update Magnitude: 0.62990

Collected Steps per Second: 22,985.67606
Overall Steps per Second: 10,900.10123

Timestep Collection Time: 2.17562
Timestep Consumption Time: 2.41223
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.58785

Cumulative Model Updates: 236,166
Cumulative Timesteps: 1,969,668,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1969668862...
Checkpoint 1969668862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.93607
Policy Entropy: 2.22680
Value Function Loss: 0.01708

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.54054
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 22,403.48505
Overall Steps per Second: 10,559.70825

Timestep Collection Time: 2.23188
Timestep Consumption Time: 2.50328
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.73517

Cumulative Model Updates: 236,172
Cumulative Timesteps: 1,969,718,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.95719
Policy Entropy: 2.24100
Value Function Loss: 0.01691

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.54148
Value Function Update Magnitude: 0.60739

Collected Steps per Second: 22,608.84554
Overall Steps per Second: 10,827.07413

Timestep Collection Time: 2.21152
Timestep Consumption Time: 2.40653
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61805

Cumulative Model Updates: 236,178
Cumulative Timesteps: 1,969,768,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1969768864...
Checkpoint 1969768864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.22966
Policy Entropy: 2.22329
Value Function Loss: 0.01713

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.59973

Collected Steps per Second: 22,364.27141
Overall Steps per Second: 10,731.28162

Timestep Collection Time: 2.23580
Timestep Consumption Time: 2.42366
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.65946

Cumulative Model Updates: 236,184
Cumulative Timesteps: 1,969,818,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.92847
Policy Entropy: 2.20178
Value Function Loss: 0.01749

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.61024

Collected Steps per Second: 23,202.03370
Overall Steps per Second: 10,852.21681

Timestep Collection Time: 2.15619
Timestep Consumption Time: 2.45374
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.60993

Cumulative Model Updates: 236,190
Cumulative Timesteps: 1,969,868,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1969868894...
Checkpoint 1969868894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.91763
Policy Entropy: 2.20718
Value Function Loss: 0.01756

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.54148
Value Function Update Magnitude: 0.60930

Collected Steps per Second: 22,598.28093
Overall Steps per Second: 10,685.15747

Timestep Collection Time: 2.21335
Timestep Consumption Time: 2.46772
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.68107

Cumulative Model Updates: 236,196
Cumulative Timesteps: 1,969,918,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.08666
Policy Entropy: 2.20711
Value Function Loss: 0.01819

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.53920
Value Function Update Magnitude: 0.58715

Collected Steps per Second: 23,161.69285
Overall Steps per Second: 10,953.20159

Timestep Collection Time: 2.15969
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.56688

Cumulative Model Updates: 236,202
Cumulative Timesteps: 1,969,968,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1969968934...
Checkpoint 1969968934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.82725
Policy Entropy: 2.20093
Value Function Loss: 0.01878

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.60156

Collected Steps per Second: 22,853.64507
Overall Steps per Second: 11,057.68553

Timestep Collection Time: 2.18783
Timestep Consumption Time: 2.33391
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.52174

Cumulative Model Updates: 236,208
Cumulative Timesteps: 1,970,018,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.77457
Policy Entropy: 2.17877
Value Function Loss: 0.01843

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.61565

Collected Steps per Second: 23,445.16240
Overall Steps per Second: 10,942.37126

Timestep Collection Time: 2.13400
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.57232

Cumulative Model Updates: 236,214
Cumulative Timesteps: 1,970,068,966

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1970068966...
Checkpoint 1970068966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.25419
Policy Entropy: 2.14870
Value Function Loss: 0.01835

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 22,351.22560
Overall Steps per Second: 10,655.51188

Timestep Collection Time: 2.23791
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.69428

Cumulative Model Updates: 236,220
Cumulative Timesteps: 1,970,118,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.24667
Policy Entropy: 2.13905
Value Function Loss: 0.01817

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.60571

Collected Steps per Second: 22,798.31793
Overall Steps per Second: 10,877.13286

Timestep Collection Time: 2.19534
Timestep Consumption Time: 2.40606
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60140

Cumulative Model Updates: 236,226
Cumulative Timesteps: 1,970,169,036

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1970169036...
Checkpoint 1970169036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.88419
Policy Entropy: 2.15871
Value Function Loss: 0.01905

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.60648

Collected Steps per Second: 22,220.20626
Overall Steps per Second: 10,714.31257

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.41722
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.66815

Cumulative Model Updates: 236,232
Cumulative Timesteps: 1,970,219,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.09442
Policy Entropy: 2.20708
Value Function Loss: 0.01878

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.61943

Collected Steps per Second: 22,761.22051
Overall Steps per Second: 10,766.99476

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.64475

Cumulative Model Updates: 236,238
Cumulative Timesteps: 1,970,269,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1970269062...
Checkpoint 1970269062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.88841
Policy Entropy: 2.20991
Value Function Loss: 0.01884

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.56462
Value Function Update Magnitude: 0.62509

Collected Steps per Second: 22,486.69513
Overall Steps per Second: 10,692.78500

Timestep Collection Time: 2.22469
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.67848

Cumulative Model Updates: 236,244
Cumulative Timesteps: 1,970,319,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.52023
Policy Entropy: 2.20285
Value Function Loss: 0.01851

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.15993
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.62106

Collected Steps per Second: 23,126.01506
Overall Steps per Second: 10,922.03072

Timestep Collection Time: 2.16336
Timestep Consumption Time: 2.41729
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.58065

Cumulative Model Updates: 236,250
Cumulative Timesteps: 1,970,369,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1970369118...
Checkpoint 1970369118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.19220
Policy Entropy: 2.19265
Value Function Loss: 0.01951

Mean KL Divergence: 0.03053
SB3 Clip Fraction: 0.17228
Policy Update Magnitude: 0.52525
Value Function Update Magnitude: 0.61287

Collected Steps per Second: 22,636.64964
Overall Steps per Second: 10,866.57491

Timestep Collection Time: 2.20943
Timestep Consumption Time: 2.39313
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.60255

Cumulative Model Updates: 236,256
Cumulative Timesteps: 1,970,419,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.45523
Policy Entropy: 2.18524
Value Function Loss: 0.01984

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.55362
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 22,331.41689
Overall Steps per Second: 10,704.98833

Timestep Collection Time: 2.23989
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.67259

Cumulative Model Updates: 236,262
Cumulative Timesteps: 1,970,469,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1970469152...
Checkpoint 1970469152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.38802
Policy Entropy: 2.22314
Value Function Loss: 0.01942

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 22,561.35340
Overall Steps per Second: 10,654.10367

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.47705
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.69340

Cumulative Model Updates: 236,268
Cumulative Timesteps: 1,970,519,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.80310
Policy Entropy: 2.21618
Value Function Loss: 0.01752

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 22,843.54505
Overall Steps per Second: 10,880.85458

Timestep Collection Time: 2.18977
Timestep Consumption Time: 2.40748
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.59725

Cumulative Model Updates: 236,274
Cumulative Timesteps: 1,970,569,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1970569178...
Checkpoint 1970569178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.11229
Policy Entropy: 2.24875
Value Function Loss: 0.01663

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.56837

Collected Steps per Second: 22,697.19911
Overall Steps per Second: 10,764.11646

Timestep Collection Time: 2.20353
Timestep Consumption Time: 2.44283
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.64636

Cumulative Model Updates: 236,280
Cumulative Timesteps: 1,970,619,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.73549
Policy Entropy: 2.21891
Value Function Loss: 0.01821

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.56428

Collected Steps per Second: 23,551.64915
Overall Steps per Second: 10,785.38481

Timestep Collection Time: 2.12393
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.63794

Cumulative Model Updates: 236,286
Cumulative Timesteps: 1,970,669,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1970669214...
Checkpoint 1970669214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.41472
Policy Entropy: 2.24889
Value Function Loss: 0.01819

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.59138

Collected Steps per Second: 22,450.94781
Overall Steps per Second: 10,649.63906

Timestep Collection Time: 2.22743
Timestep Consumption Time: 2.46831
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.69575

Cumulative Model Updates: 236,292
Cumulative Timesteps: 1,970,719,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.95290
Policy Entropy: 2.23859
Value Function Loss: 0.01894

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.60949

Collected Steps per Second: 23,251.38013
Overall Steps per Second: 10,941.25939

Timestep Collection Time: 2.15101
Timestep Consumption Time: 2.42013
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.57114

Cumulative Model Updates: 236,298
Cumulative Timesteps: 1,970,769,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1970769236...
Checkpoint 1970769236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.41310
Policy Entropy: 2.24867
Value Function Loss: 0.01757

Mean KL Divergence: 0.02745
SB3 Clip Fraction: 0.15369
Policy Update Magnitude: 0.52850
Value Function Update Magnitude: 0.61352

Collected Steps per Second: 23,129.46401
Overall Steps per Second: 10,791.02316

Timestep Collection Time: 2.16278
Timestep Consumption Time: 2.47292
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.63570

Cumulative Model Updates: 236,304
Cumulative Timesteps: 1,970,819,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.41932
Policy Entropy: 2.22698
Value Function Loss: 0.01719

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.53907
Value Function Update Magnitude: 0.60846

Collected Steps per Second: 23,392.74598
Overall Steps per Second: 10,776.49352

Timestep Collection Time: 2.13836
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.64177

Cumulative Model Updates: 236,310
Cumulative Timesteps: 1,970,869,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1970869282...
Checkpoint 1970869282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.28989
Policy Entropy: 2.20637
Value Function Loss: 0.01598

Mean KL Divergence: 0.02779
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.52903
Value Function Update Magnitude: 0.60352

Collected Steps per Second: 22,475.38468
Overall Steps per Second: 10,610.67260

Timestep Collection Time: 2.22483
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.71261

Cumulative Model Updates: 236,316
Cumulative Timesteps: 1,970,919,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.12871
Policy Entropy: 2.20276
Value Function Loss: 0.01781

Mean KL Divergence: 0.02667
SB3 Clip Fraction: 0.15636
Policy Update Magnitude: 0.53957
Value Function Update Magnitude: 0.59495

Collected Steps per Second: 23,082.94175
Overall Steps per Second: 10,948.42427

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.40201
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.56924

Cumulative Model Updates: 236,322
Cumulative Timesteps: 1,970,969,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1970969312...
Checkpoint 1970969312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.36739
Policy Entropy: 2.19778
Value Function Loss: 0.01847

Mean KL Divergence: 0.02697
SB3 Clip Fraction: 0.16147
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.59842

Collected Steps per Second: 22,352.31168
Overall Steps per Second: 10,625.22252

Timestep Collection Time: 2.23691
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.70578

Cumulative Model Updates: 236,328
Cumulative Timesteps: 1,971,019,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.60100
Policy Entropy: 2.21811
Value Function Loss: 0.01940

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.62100

Collected Steps per Second: 23,076.54650
Overall Steps per Second: 10,844.97546

Timestep Collection Time: 2.16731
Timestep Consumption Time: 2.44441
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.61172

Cumulative Model Updates: 236,334
Cumulative Timesteps: 1,971,069,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1971069326...
Checkpoint 1971069326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.09786
Policy Entropy: 2.20736
Value Function Loss: 0.01855

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.56386
Value Function Update Magnitude: 0.61701

Collected Steps per Second: 22,589.01398
Overall Steps per Second: 10,742.76433

Timestep Collection Time: 2.21355
Timestep Consumption Time: 2.44093
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.65448

Cumulative Model Updates: 236,340
Cumulative Timesteps: 1,971,119,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.78047
Policy Entropy: 2.20802
Value Function Loss: 0.01825

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.55437
Value Function Update Magnitude: 0.59143

Collected Steps per Second: 23,496.22449
Overall Steps per Second: 10,879.84883

Timestep Collection Time: 2.12902
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.59786

Cumulative Model Updates: 236,346
Cumulative Timesteps: 1,971,169,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1971169352...
Checkpoint 1971169352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.26805
Policy Entropy: 2.20621
Value Function Loss: 0.01798

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.58075

Collected Steps per Second: 23,492.97369
Overall Steps per Second: 11,005.23798

Timestep Collection Time: 2.12932
Timestep Consumption Time: 2.41615
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.54547

Cumulative Model Updates: 236,352
Cumulative Timesteps: 1,971,219,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.81738
Policy Entropy: 2.22041
Value Function Loss: 0.01733

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.59176

Collected Steps per Second: 23,173.98237
Overall Steps per Second: 10,894.99522

Timestep Collection Time: 2.15889
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.59202

Cumulative Model Updates: 236,358
Cumulative Timesteps: 1,971,269,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1971269406...
Checkpoint 1971269406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.79987
Policy Entropy: 2.22773
Value Function Loss: 0.01662

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.53329
Value Function Update Magnitude: 0.59159

Collected Steps per Second: 21,998.60742
Overall Steps per Second: 10,701.41731

Timestep Collection Time: 2.27505
Timestep Consumption Time: 2.40171
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.67676

Cumulative Model Updates: 236,364
Cumulative Timesteps: 1,971,319,454

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.99719
Policy Entropy: 2.21502
Value Function Loss: 0.01652

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.53349
Value Function Update Magnitude: 0.58053

Collected Steps per Second: 23,278.94239
Overall Steps per Second: 10,991.69103

Timestep Collection Time: 2.14786
Timestep Consumption Time: 2.40103
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.54889

Cumulative Model Updates: 236,370
Cumulative Timesteps: 1,971,369,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1971369454...
Checkpoint 1971369454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.95689
Policy Entropy: 2.21337
Value Function Loss: 0.01688

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.53725
Value Function Update Magnitude: 0.59312

Collected Steps per Second: 22,469.74032
Overall Steps per Second: 10,656.15719

Timestep Collection Time: 2.22566
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.69306

Cumulative Model Updates: 236,376
Cumulative Timesteps: 1,971,419,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.73779
Policy Entropy: 2.21133
Value Function Loss: 0.01740

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.61471

Collected Steps per Second: 22,826.77045
Overall Steps per Second: 10,835.82373

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.61543

Cumulative Model Updates: 236,382
Cumulative Timesteps: 1,971,469,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1971469476...
Checkpoint 1971469476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.21581
Policy Entropy: 2.21857
Value Function Loss: 0.01885

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.62506

Collected Steps per Second: 22,527.67444
Overall Steps per Second: 10,682.12925

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.46171
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.68165

Cumulative Model Updates: 236,388
Cumulative Timesteps: 1,971,519,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.81362
Policy Entropy: 2.21051
Value Function Loss: 0.01854

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.61279

Collected Steps per Second: 22,403.75699
Overall Steps per Second: 10,892.83943

Timestep Collection Time: 2.23311
Timestep Consumption Time: 2.35982
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.59293

Cumulative Model Updates: 236,394
Cumulative Timesteps: 1,971,569,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1971569516...
Checkpoint 1971569516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.94058
Policy Entropy: 2.23277
Value Function Loss: 0.01757

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11510
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.60350

Collected Steps per Second: 22,588.57563
Overall Steps per Second: 10,677.46218

Timestep Collection Time: 2.21457
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.68501

Cumulative Model Updates: 236,400
Cumulative Timesteps: 1,971,619,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.58178
Policy Entropy: 2.23610
Value Function Loss: 0.01699

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.53394
Value Function Update Magnitude: 0.59508

Collected Steps per Second: 23,335.98159
Overall Steps per Second: 10,885.52041

Timestep Collection Time: 2.14330
Timestep Consumption Time: 2.45143
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.59473

Cumulative Model Updates: 236,406
Cumulative Timesteps: 1,971,669,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1971669556...
Checkpoint 1971669556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.59753
Policy Entropy: 2.23246
Value Function Loss: 0.01656

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11620
Policy Update Magnitude: 0.53911
Value Function Update Magnitude: 0.60719

Collected Steps per Second: 22,879.44874
Overall Steps per Second: 10,727.82854

Timestep Collection Time: 2.18633
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.66283

Cumulative Model Updates: 236,412
Cumulative Timesteps: 1,971,719,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.56362
Policy Entropy: 2.23175
Value Function Loss: 0.01600

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.61782

Collected Steps per Second: 23,386.52388
Overall Steps per Second: 11,034.81601

Timestep Collection Time: 2.13884
Timestep Consumption Time: 2.39409
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.53293

Cumulative Model Updates: 236,418
Cumulative Timesteps: 1,971,769,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1971769598...
Checkpoint 1971769598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.11809
Policy Entropy: 2.23655
Value Function Loss: 0.01639

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.53569
Value Function Update Magnitude: 0.60510

Collected Steps per Second: 22,852.31420
Overall Steps per Second: 10,858.82329

Timestep Collection Time: 2.18884
Timestep Consumption Time: 2.41755
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60639

Cumulative Model Updates: 236,424
Cumulative Timesteps: 1,971,819,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.01457
Policy Entropy: 2.24698
Value Function Loss: 0.01742

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.60569

Collected Steps per Second: 23,534.91861
Overall Steps per Second: 10,979.95651

Timestep Collection Time: 2.12484
Timestep Consumption Time: 2.42964
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.55448

Cumulative Model Updates: 236,430
Cumulative Timesteps: 1,971,869,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1971869626...
Checkpoint 1971869626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.95558
Policy Entropy: 2.22554
Value Function Loss: 0.01762

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.62800

Collected Steps per Second: 22,590.73930
Overall Steps per Second: 10,667.49292

Timestep Collection Time: 2.21409
Timestep Consumption Time: 2.47473
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.68882

Cumulative Model Updates: 236,436
Cumulative Timesteps: 1,971,919,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.65653
Policy Entropy: 2.22421
Value Function Loss: 0.01695

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.53710
Value Function Update Magnitude: 0.62590

Collected Steps per Second: 22,923.10357
Overall Steps per Second: 10,876.81786

Timestep Collection Time: 2.18208
Timestep Consumption Time: 2.41669
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.59877

Cumulative Model Updates: 236,442
Cumulative Timesteps: 1,971,969,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1971969664...
Checkpoint 1971969664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.79405
Policy Entropy: 2.23490
Value Function Loss: 0.01493

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.52420
Value Function Update Magnitude: 0.59666

Collected Steps per Second: 22,339.30101
Overall Steps per Second: 10,651.42519

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.45600
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.69421

Cumulative Model Updates: 236,448
Cumulative Timesteps: 1,972,019,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.87680
Policy Entropy: 2.22635
Value Function Loss: 0.01527

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.50810
Value Function Update Magnitude: 0.55792

Collected Steps per Second: 22,886.68520
Overall Steps per Second: 10,864.42904

Timestep Collection Time: 2.18573
Timestep Consumption Time: 2.41866
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60438

Cumulative Model Updates: 236,454
Cumulative Timesteps: 1,972,069,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1972069688...
Checkpoint 1972069688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.56050
Policy Entropy: 2.20342
Value Function Loss: 0.01584

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.52364
Value Function Update Magnitude: 0.55359

Collected Steps per Second: 22,419.41376
Overall Steps per Second: 10,734.07135

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.42824
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.65881

Cumulative Model Updates: 236,460
Cumulative Timesteps: 1,972,119,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.40633
Policy Entropy: 2.18466
Value Function Loss: 0.01818

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.53715
Value Function Update Magnitude: 0.59213

Collected Steps per Second: 23,502.63739
Overall Steps per Second: 10,842.82344

Timestep Collection Time: 2.12785
Timestep Consumption Time: 2.48442
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.61227

Cumulative Model Updates: 236,466
Cumulative Timesteps: 1,972,169,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1972169706...
Checkpoint 1972169706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.45543
Policy Entropy: 2.19865
Value Function Loss: 0.01790

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.63120

Collected Steps per Second: 22,326.03114
Overall Steps per Second: 10,645.22107

Timestep Collection Time: 2.23963
Timestep Consumption Time: 2.45750
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.69713

Cumulative Model Updates: 236,472
Cumulative Timesteps: 1,972,219,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.30058
Policy Entropy: 2.21311
Value Function Loss: 0.01822

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.64195

Collected Steps per Second: 23,579.51527
Overall Steps per Second: 10,915.32531

Timestep Collection Time: 2.12074
Timestep Consumption Time: 2.46053
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.58127

Cumulative Model Updates: 236,478
Cumulative Timesteps: 1,972,269,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1972269714...
Checkpoint 1972269714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.56944
Policy Entropy: 2.25429
Value Function Loss: 0.01668

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.52926
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 22,729.49195
Overall Steps per Second: 10,993.62251

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.34831
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.54809

Cumulative Model Updates: 236,484
Cumulative Timesteps: 1,972,319,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.05442
Policy Entropy: 2.26277
Value Function Loss: 0.01679

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.52736
Value Function Update Magnitude: 0.62678

Collected Steps per Second: 23,626.50176
Overall Steps per Second: 10,992.37911

Timestep Collection Time: 2.11711
Timestep Consumption Time: 2.43331
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.55043

Cumulative Model Updates: 236,490
Cumulative Timesteps: 1,972,369,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1972369734...
Checkpoint 1972369734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.89543
Policy Entropy: 2.25722
Value Function Loss: 0.01831

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.53602
Value Function Update Magnitude: 0.64128

Collected Steps per Second: 22,087.39827
Overall Steps per Second: 10,634.05268

Timestep Collection Time: 2.26401
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.70244

Cumulative Model Updates: 236,496
Cumulative Timesteps: 1,972,419,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.94888
Policy Entropy: 2.23146
Value Function Loss: 0.01878

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.66133

Collected Steps per Second: 22,654.06095
Overall Steps per Second: 10,866.10144

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.39560
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60386

Cumulative Model Updates: 236,502
Cumulative Timesteps: 1,972,469,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1972469766...
Checkpoint 1972469766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.14996
Policy Entropy: 2.19977
Value Function Loss: 0.01949

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.70642

Collected Steps per Second: 22,587.45369
Overall Steps per Second: 10,773.25847

Timestep Collection Time: 2.21468
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.64335

Cumulative Model Updates: 236,508
Cumulative Timesteps: 1,972,519,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.07063
Policy Entropy: 2.22927
Value Function Loss: 0.01744

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.71897

Collected Steps per Second: 23,242.02831
Overall Steps per Second: 10,842.21010

Timestep Collection Time: 2.15222
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61363

Cumulative Model Updates: 236,514
Cumulative Timesteps: 1,972,569,812

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1972569812...
Checkpoint 1972569812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.02733
Policy Entropy: 2.22644
Value Function Loss: 0.01804

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.70516

Collected Steps per Second: 22,525.11949
Overall Steps per Second: 10,600.99165

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.71748

Cumulative Model Updates: 236,520
Cumulative Timesteps: 1,972,619,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.73641
Policy Entropy: 2.22898
Value Function Loss: 0.01804

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.55077
Value Function Update Magnitude: 0.69058

Collected Steps per Second: 23,178.56629
Overall Steps per Second: 10,928.77359

Timestep Collection Time: 2.15811
Timestep Consumption Time: 2.41898
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.57709

Cumulative Model Updates: 236,526
Cumulative Timesteps: 1,972,669,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1972669844...
Checkpoint 1972669844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.16874
Policy Entropy: 2.20481
Value Function Loss: 0.01865

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.68697

Collected Steps per Second: 23,560.64858
Overall Steps per Second: 10,997.91298

Timestep Collection Time: 2.12329
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.54868

Cumulative Model Updates: 236,532
Cumulative Timesteps: 1,972,719,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.06222
Policy Entropy: 2.21796
Value Function Loss: 0.01800

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.65406

Collected Steps per Second: 23,434.51781
Overall Steps per Second: 10,935.07577

Timestep Collection Time: 2.13454
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.57445

Cumulative Model Updates: 236,538
Cumulative Timesteps: 1,972,769,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1972769892...
Checkpoint 1972769892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.73027
Policy Entropy: 2.20881
Value Function Loss: 0.01937

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 22,580.91751
Overall Steps per Second: 10,802.98580

Timestep Collection Time: 2.21488
Timestep Consumption Time: 2.41477
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.62965

Cumulative Model Updates: 236,544
Cumulative Timesteps: 1,972,819,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.64507
Policy Entropy: 2.18553
Value Function Loss: 0.01826

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.54852
Value Function Update Magnitude: 0.64174

Collected Steps per Second: 22,295.90976
Overall Steps per Second: 10,637.44604

Timestep Collection Time: 2.24274
Timestep Consumption Time: 2.45801
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.70075

Cumulative Model Updates: 236,550
Cumulative Timesteps: 1,972,869,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1972869910...
Checkpoint 1972869910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.54992
Policy Entropy: 2.16391
Value Function Loss: 0.01858

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.63439

Collected Steps per Second: 22,092.00737
Overall Steps per Second: 10,892.28221

Timestep Collection Time: 2.26426
Timestep Consumption Time: 2.32817
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.59243

Cumulative Model Updates: 236,556
Cumulative Timesteps: 1,972,919,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.22833
Policy Entropy: 2.17591
Value Function Loss: 0.01887

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.54977
Value Function Update Magnitude: 0.60858

Collected Steps per Second: 23,030.95701
Overall Steps per Second: 10,843.66775

Timestep Collection Time: 2.17169
Timestep Consumption Time: 2.44078
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.61246

Cumulative Model Updates: 236,562
Cumulative Timesteps: 1,972,969,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1972969948...
Checkpoint 1972969948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.67858
Policy Entropy: 2.19864
Value Function Loss: 0.01876

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.60303

Collected Steps per Second: 22,917.84026
Overall Steps per Second: 10,671.26516

Timestep Collection Time: 2.18240
Timestep Consumption Time: 2.50457
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.68698

Cumulative Model Updates: 236,568
Cumulative Timesteps: 1,973,019,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.57132
Policy Entropy: 2.20382
Value Function Loss: 0.01830

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.52955
Value Function Update Magnitude: 0.61458

Collected Steps per Second: 23,049.62161
Overall Steps per Second: 10,863.51996

Timestep Collection Time: 2.17010
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.60440

Cumulative Model Updates: 236,574
Cumulative Timesteps: 1,973,069,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1973069984...
Checkpoint 1973069984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.01257
Policy Entropy: 2.21739
Value Function Loss: 0.01772

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.53275
Value Function Update Magnitude: 0.60817

Collected Steps per Second: 22,808.09473
Overall Steps per Second: 10,863.70210

Timestep Collection Time: 2.19334
Timestep Consumption Time: 2.41153
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.60488

Cumulative Model Updates: 236,580
Cumulative Timesteps: 1,973,120,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.68196
Policy Entropy: 2.21058
Value Function Loss: 0.01821

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.53370
Value Function Update Magnitude: 0.60668

Collected Steps per Second: 23,611.66216
Overall Steps per Second: 10,868.13603

Timestep Collection Time: 2.11895
Timestep Consumption Time: 2.48460
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.60355

Cumulative Model Updates: 236,586
Cumulative Timesteps: 1,973,170,042

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1973170042...
Checkpoint 1973170042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.97023
Policy Entropy: 2.24077
Value Function Loss: 0.01665

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.51938
Value Function Update Magnitude: 0.59761

Collected Steps per Second: 22,893.24061
Overall Steps per Second: 10,849.39600

Timestep Collection Time: 2.18492
Timestep Consumption Time: 2.42547
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61039

Cumulative Model Updates: 236,592
Cumulative Timesteps: 1,973,220,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.39871
Policy Entropy: 2.24201
Value Function Loss: 0.01662

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.51237
Value Function Update Magnitude: 0.58107

Collected Steps per Second: 23,082.80495
Overall Steps per Second: 10,941.97825

Timestep Collection Time: 2.16715
Timestep Consumption Time: 2.40460
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.57175

Cumulative Model Updates: 236,598
Cumulative Timesteps: 1,973,270,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1973270086...
Checkpoint 1973270086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.41155
Policy Entropy: 2.25235
Value Function Loss: 0.01631

Mean KL Divergence: 0.02613
SB3 Clip Fraction: 0.15196
Policy Update Magnitude: 0.51792
Value Function Update Magnitude: 0.58389

Collected Steps per Second: 22,497.76153
Overall Steps per Second: 10,788.56183

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.41325
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.63676

Cumulative Model Updates: 236,604
Cumulative Timesteps: 1,973,320,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.80805
Policy Entropy: 2.24441
Value Function Loss: 0.01764

Mean KL Divergence: 0.02536
SB3 Clip Fraction: 0.15064
Policy Update Magnitude: 0.54569
Value Function Update Magnitude: 0.60754

Collected Steps per Second: 23,001.96574
Overall Steps per Second: 10,903.24062

Timestep Collection Time: 2.17486
Timestep Consumption Time: 2.41332
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.58818

Cumulative Model Updates: 236,610
Cumulative Timesteps: 1,973,370,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1973370136...
Checkpoint 1973370136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.48491
Policy Entropy: 2.23145
Value Function Loss: 0.01781

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.62776

Collected Steps per Second: 22,336.06539
Overall Steps per Second: 10,607.84176

Timestep Collection Time: 2.23934
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.71519

Cumulative Model Updates: 236,616
Cumulative Timesteps: 1,973,420,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.92370
Policy Entropy: 2.23504
Value Function Loss: 0.01773

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.63873

Collected Steps per Second: 22,921.61307
Overall Steps per Second: 10,902.27649

Timestep Collection Time: 2.18239
Timestep Consumption Time: 2.40601
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.58840

Cumulative Model Updates: 236,622
Cumulative Timesteps: 1,973,470,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1973470178...
Checkpoint 1973470178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.45006
Policy Entropy: 2.22207
Value Function Loss: 0.01869

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.62762

Collected Steps per Second: 22,569.15289
Overall Steps per Second: 10,747.04075

Timestep Collection Time: 2.21577
Timestep Consumption Time: 2.43742
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.65319

Cumulative Model Updates: 236,628
Cumulative Timesteps: 1,973,520,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.84965
Policy Entropy: 2.22481
Value Function Loss: 0.01931

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.55367
Value Function Update Magnitude: 0.62579

Collected Steps per Second: 23,515.51164
Overall Steps per Second: 10,775.51830

Timestep Collection Time: 2.12728
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.64238

Cumulative Model Updates: 236,634
Cumulative Timesteps: 1,973,570,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1973570210...
Checkpoint 1973570210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.20711
Policy Entropy: 2.21507
Value Function Loss: 0.01832

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.62027

Collected Steps per Second: 22,596.11946
Overall Steps per Second: 10,649.17511

Timestep Collection Time: 2.21339
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.69651

Cumulative Model Updates: 236,640
Cumulative Timesteps: 1,973,620,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.78976
Policy Entropy: 2.19412
Value Function Loss: 0.01821

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.54798
Value Function Update Magnitude: 0.59907

Collected Steps per Second: 22,804.15323
Overall Steps per Second: 10,853.34248

Timestep Collection Time: 2.19372
Timestep Consumption Time: 2.41555
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60927

Cumulative Model Updates: 236,646
Cumulative Timesteps: 1,973,670,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1973670250...
Checkpoint 1973670250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.65357
Policy Entropy: 2.21107
Value Function Loss: 0.01717

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.60103

Collected Steps per Second: 22,625.84279
Overall Steps per Second: 10,810.43271

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.41588
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.62627

Cumulative Model Updates: 236,652
Cumulative Timesteps: 1,973,720,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.23488
Policy Entropy: 2.20766
Value Function Loss: 0.01601

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.59356

Collected Steps per Second: 23,434.18716
Overall Steps per Second: 10,794.11796

Timestep Collection Time: 2.13398
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.63289

Cumulative Model Updates: 236,658
Cumulative Timesteps: 1,973,770,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1973770270...
Checkpoint 1973770270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.08512
Policy Entropy: 2.22636
Value Function Loss: 0.01509

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.50816
Value Function Update Magnitude: 0.56665

Collected Steps per Second: 22,067.72793
Overall Steps per Second: 10,623.10536

Timestep Collection Time: 2.26648
Timestep Consumption Time: 2.44175
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.70823

Cumulative Model Updates: 236,664
Cumulative Timesteps: 1,973,820,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.16953
Policy Entropy: 2.19240
Value Function Loss: 0.01619

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.50520
Value Function Update Magnitude: 0.56166

Collected Steps per Second: 22,705.00076
Overall Steps per Second: 10,841.70820

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.40995
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61237

Cumulative Model Updates: 236,670
Cumulative Timesteps: 1,973,870,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1973870292...
Checkpoint 1973870292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.76727
Policy Entropy: 2.19156
Value Function Loss: 0.01711

Mean KL Divergence: 0.02773
SB3 Clip Fraction: 0.16804
Policy Update Magnitude: 0.49495
Value Function Update Magnitude: 0.57364

Collected Steps per Second: 22,302.95730
Overall Steps per Second: 10,737.12201

Timestep Collection Time: 2.24347
Timestep Consumption Time: 2.41662
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.66009

Cumulative Model Updates: 236,676
Cumulative Timesteps: 1,973,920,328

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.13573
Policy Entropy: 2.18564
Value Function Loss: 0.01727

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.15910
Policy Update Magnitude: 0.52873
Value Function Update Magnitude: 0.57479

Collected Steps per Second: 23,307.52790
Overall Steps per Second: 10,864.94184

Timestep Collection Time: 2.14660
Timestep Consumption Time: 2.45830
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.60490

Cumulative Model Updates: 236,682
Cumulative Timesteps: 1,973,970,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1973970360...
Checkpoint 1973970360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.97593
Policy Entropy: 2.23876
Value Function Loss: 0.01707

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.53636
Value Function Update Magnitude: 0.57309

Collected Steps per Second: 22,761.28899
Overall Steps per Second: 10,687.57639

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.68039

Cumulative Model Updates: 236,688
Cumulative Timesteps: 1,974,020,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.11335
Policy Entropy: 2.23282
Value Function Loss: 0.01672

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.53194
Value Function Update Magnitude: 0.58113

Collected Steps per Second: 23,107.97986
Overall Steps per Second: 10,977.27750

Timestep Collection Time: 2.16445
Timestep Consumption Time: 2.39187
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.55632

Cumulative Model Updates: 236,694
Cumulative Timesteps: 1,974,070,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1974070398...
Checkpoint 1974070398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.87605
Policy Entropy: 2.24396
Value Function Loss: 0.01718

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.53331
Value Function Update Magnitude: 0.58725

Collected Steps per Second: 22,781.68272
Overall Steps per Second: 11,004.66100

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.34963
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.54517

Cumulative Model Updates: 236,700
Cumulative Timesteps: 1,974,120,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.01559
Policy Entropy: 2.23304
Value Function Loss: 0.01641

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.52734
Value Function Update Magnitude: 0.60172

Collected Steps per Second: 23,353.50679
Overall Steps per Second: 10,940.15404

Timestep Collection Time: 2.14126
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.57087

Cumulative Model Updates: 236,706
Cumulative Timesteps: 1,974,170,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1974170422...
Checkpoint 1974170422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.75131
Policy Entropy: 2.24430
Value Function Loss: 0.01602

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.52506
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 22,791.50802
Overall Steps per Second: 10,629.60569

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.51014
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.70403

Cumulative Model Updates: 236,712
Cumulative Timesteps: 1,974,220,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.02456
Policy Entropy: 2.22952
Value Function Loss: 0.01631

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.52925
Value Function Update Magnitude: 0.60495

Collected Steps per Second: 22,588.82797
Overall Steps per Second: 10,857.77885

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.39275
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60739

Cumulative Model Updates: 236,718
Cumulative Timesteps: 1,974,270,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1974270450...
Checkpoint 1974270450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.12612
Policy Entropy: 2.20669
Value Function Loss: 0.01687

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.52705
Value Function Update Magnitude: 0.63079

Collected Steps per Second: 21,952.04219
Overall Steps per Second: 10,762.73082

Timestep Collection Time: 2.27869
Timestep Consumption Time: 2.36901
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.64771

Cumulative Model Updates: 236,724
Cumulative Timesteps: 1,974,320,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.82037
Policy Entropy: 2.20724
Value Function Loss: 0.01687

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.51787
Value Function Update Magnitude: 0.62846

Collected Steps per Second: 23,158.22653
Overall Steps per Second: 10,892.90044

Timestep Collection Time: 2.15923
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.59051

Cumulative Model Updates: 236,730
Cumulative Timesteps: 1,974,370,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1974370476...
Checkpoint 1974370476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.93140
Policy Entropy: 2.22640
Value Function Loss: 0.01605

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.52275
Value Function Update Magnitude: 0.61024

Collected Steps per Second: 22,542.99236
Overall Steps per Second: 10,618.80015

Timestep Collection Time: 2.21816
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.70901

Cumulative Model Updates: 236,736
Cumulative Timesteps: 1,974,420,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.09267
Policy Entropy: 2.22186
Value Function Loss: 0.01768

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.53732
Value Function Update Magnitude: 0.60619

Collected Steps per Second: 22,944.74963
Overall Steps per Second: 10,873.25879

Timestep Collection Time: 2.17958
Timestep Consumption Time: 2.41977
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59936

Cumulative Model Updates: 236,742
Cumulative Timesteps: 1,974,470,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1974470490...
Checkpoint 1974470490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.33125
Policy Entropy: 2.21419
Value Function Loss: 0.01788

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.53444
Value Function Update Magnitude: 0.60830

Collected Steps per Second: 22,711.22312
Overall Steps per Second: 10,846.82650

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.40809
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.60964

Cumulative Model Updates: 236,748
Cumulative Timesteps: 1,974,520,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.56714
Policy Entropy: 2.18253
Value Function Loss: 0.01877

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.63520

Collected Steps per Second: 23,619.99550
Overall Steps per Second: 10,864.33485

Timestep Collection Time: 2.11727
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.60314

Cumulative Model Updates: 236,754
Cumulative Timesteps: 1,974,570,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1974570500...
Checkpoint 1974570500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.66829
Policy Entropy: 2.19753
Value Function Loss: 0.01744

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.63174

Collected Steps per Second: 22,913.81063
Overall Steps per Second: 10,858.85282

Timestep Collection Time: 2.18331
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60712

Cumulative Model Updates: 236,760
Cumulative Timesteps: 1,974,620,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.40314
Policy Entropy: 2.22371
Value Function Loss: 0.01595

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 22,763.19017
Overall Steps per Second: 10,766.15822

Timestep Collection Time: 2.19670
Timestep Consumption Time: 2.44785
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.64455

Cumulative Model Updates: 236,766
Cumulative Timesteps: 1,974,670,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1974670532...
Checkpoint 1974670532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.76002
Policy Entropy: 2.25017
Value Function Loss: 0.01458

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.51004
Value Function Update Magnitude: 0.58134

Collected Steps per Second: 22,679.13407
Overall Steps per Second: 10,894.22236

Timestep Collection Time: 2.20476
Timestep Consumption Time: 2.38501
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.58977

Cumulative Model Updates: 236,772
Cumulative Timesteps: 1,974,720,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.00596
Policy Entropy: 2.25348
Value Function Loss: 0.01483

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.51211
Value Function Update Magnitude: 0.55342

Collected Steps per Second: 22,826.18715
Overall Steps per Second: 10,824.26084

Timestep Collection Time: 2.19152
Timestep Consumption Time: 2.42995
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.62147

Cumulative Model Updates: 236,778
Cumulative Timesteps: 1,974,770,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1974770558...
Checkpoint 1974770558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.80684
Policy Entropy: 2.23301
Value Function Loss: 0.01556

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.51935
Value Function Update Magnitude: 0.56838

Collected Steps per Second: 22,274.12294
Overall Steps per Second: 10,675.73724

Timestep Collection Time: 2.24566
Timestep Consumption Time: 2.43974
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68539

Cumulative Model Updates: 236,784
Cumulative Timesteps: 1,974,820,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.47516
Policy Entropy: 2.23261
Value Function Loss: 0.01715

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.59253

Collected Steps per Second: 22,164.34221
Overall Steps per Second: 10,680.17333

Timestep Collection Time: 2.25651
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.68288

Cumulative Model Updates: 236,790
Cumulative Timesteps: 1,974,870,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1974870592...
Checkpoint 1974870592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.76828
Policy Entropy: 2.20833
Value Function Loss: 0.01840

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.54189
Value Function Update Magnitude: 0.60998

Collected Steps per Second: 23,257.93578
Overall Steps per Second: 10,932.21207

Timestep Collection Time: 2.15041
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.57492

Cumulative Model Updates: 236,796
Cumulative Timesteps: 1,974,920,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.35873
Policy Entropy: 2.21097
Value Function Loss: 0.01818

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.62145

Collected Steps per Second: 23,266.20276
Overall Steps per Second: 10,919.79041

Timestep Collection Time: 2.14990
Timestep Consumption Time: 2.43077
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.58067

Cumulative Model Updates: 236,802
Cumulative Timesteps: 1,974,970,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1974970626...
Checkpoint 1974970626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.23366
Policy Entropy: 2.20298
Value Function Loss: 0.01905

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.62606

Collected Steps per Second: 22,860.68352
Overall Steps per Second: 10,784.00771

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.44933
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.63650

Cumulative Model Updates: 236,808
Cumulative Timesteps: 1,975,020,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.79684
Policy Entropy: 2.21121
Value Function Loss: 0.01788

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.63187

Collected Steps per Second: 23,635.92659
Overall Steps per Second: 11,203.89980

Timestep Collection Time: 2.11627
Timestep Consumption Time: 2.34825
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.46452

Cumulative Model Updates: 236,814
Cumulative Timesteps: 1,975,070,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1975070646...
Checkpoint 1975070646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.07590
Policy Entropy: 2.22582
Value Function Loss: 0.01834

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11733
Policy Update Magnitude: 0.54360
Value Function Update Magnitude: 0.61710

Collected Steps per Second: 22,691.73713
Overall Steps per Second: 10,669.89813

Timestep Collection Time: 2.20477
Timestep Consumption Time: 2.48412
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68889

Cumulative Model Updates: 236,820
Cumulative Timesteps: 1,975,120,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.60124
Policy Entropy: 2.24041
Value Function Loss: 0.01805

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.54411
Value Function Update Magnitude: 0.59342

Collected Steps per Second: 22,630.49154
Overall Steps per Second: 10,778.01292

Timestep Collection Time: 2.21047
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.64130

Cumulative Model Updates: 236,826
Cumulative Timesteps: 1,975,170,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1975170700...
Checkpoint 1975170700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.04175
Policy Entropy: 2.22547
Value Function Loss: 0.01938

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.59154

Collected Steps per Second: 22,252.15957
Overall Steps per Second: 10,687.28415

Timestep Collection Time: 2.24706
Timestep Consumption Time: 2.43158
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.67864

Cumulative Model Updates: 236,832
Cumulative Timesteps: 1,975,220,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.29644
Policy Entropy: 2.20608
Value Function Loss: 0.01938

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.60962

Collected Steps per Second: 22,730.54449
Overall Steps per Second: 10,733.25614

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.66047

Cumulative Model Updates: 236,838
Cumulative Timesteps: 1,975,270,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1975270724...
Checkpoint 1975270724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.00536
Policy Entropy: 2.20163
Value Function Loss: 0.01855

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.53978
Value Function Update Magnitude: 0.61204

Collected Steps per Second: 22,523.77330
Overall Steps per Second: 10,893.16266

Timestep Collection Time: 2.22023
Timestep Consumption Time: 2.37054
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.59077

Cumulative Model Updates: 236,844
Cumulative Timesteps: 1,975,320,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.72413
Policy Entropy: 2.21910
Value Function Loss: 0.01683

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.53116
Value Function Update Magnitude: 0.58607

Collected Steps per Second: 23,288.36718
Overall Steps per Second: 10,918.32416

Timestep Collection Time: 2.14725
Timestep Consumption Time: 2.43275
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.58001

Cumulative Model Updates: 236,850
Cumulative Timesteps: 1,975,370,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975370738...
Checkpoint 1975370738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.96501
Policy Entropy: 2.19680
Value Function Loss: 0.01587

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.52598
Value Function Update Magnitude: 0.56728

Collected Steps per Second: 22,680.12605
Overall Steps per Second: 10,593.33343

Timestep Collection Time: 2.20501
Timestep Consumption Time: 2.51588
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.72089

Cumulative Model Updates: 236,856
Cumulative Timesteps: 1,975,420,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.95579
Policy Entropy: 2.18517
Value Function Loss: 0.01681

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.53834
Value Function Update Magnitude: 0.56045

Collected Steps per Second: 23,162.75394
Overall Steps per Second: 10,959.86918

Timestep Collection Time: 2.15890
Timestep Consumption Time: 2.40375
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.56265

Cumulative Model Updates: 236,862
Cumulative Timesteps: 1,975,470,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975470754...
Checkpoint 1975470754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.67108
Policy Entropy: 2.14464
Value Function Loss: 0.01859

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.55303
Value Function Update Magnitude: 0.57738

Collected Steps per Second: 23,803.41662
Overall Steps per Second: 11,037.64599

Timestep Collection Time: 2.10096
Timestep Consumption Time: 2.42990
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.53086

Cumulative Model Updates: 236,868
Cumulative Timesteps: 1,975,520,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.40389
Policy Entropy: 2.16020
Value Function Loss: 0.01917

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.55666
Value Function Update Magnitude: 0.58143

Collected Steps per Second: 23,277.72487
Overall Steps per Second: 10,907.20978

Timestep Collection Time: 2.14823
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.58467

Cumulative Model Updates: 236,874
Cumulative Timesteps: 1,975,570,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975570770...
Checkpoint 1975570770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.36517
Policy Entropy: 2.15776
Value Function Loss: 0.01807

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.58332

Collected Steps per Second: 22,150.75525
Overall Steps per Second: 10,668.77699

Timestep Collection Time: 2.25798
Timestep Consumption Time: 2.43009
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.68807

Cumulative Model Updates: 236,880
Cumulative Timesteps: 1,975,620,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.13407
Policy Entropy: 2.16520
Value Function Loss: 0.01817

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.59051

Collected Steps per Second: 22,525.33695
Overall Steps per Second: 10,960.57227

Timestep Collection Time: 2.22070
Timestep Consumption Time: 2.34311
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.56381

Cumulative Model Updates: 236,886
Cumulative Timesteps: 1,975,670,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1975670808...
Checkpoint 1975670808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.31040
Policy Entropy: 2.15577
Value Function Loss: 0.01798

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.60219

Collected Steps per Second: 22,855.91078
Overall Steps per Second: 10,713.79681

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.67005

Cumulative Model Updates: 236,892
Cumulative Timesteps: 1,975,720,842

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.75505
Policy Entropy: 2.15737
Value Function Loss: 0.01812

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.62475

Collected Steps per Second: 22,803.99378
Overall Steps per Second: 10,811.54801

Timestep Collection Time: 2.19286
Timestep Consumption Time: 2.43238
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.62524

Cumulative Model Updates: 236,898
Cumulative Timesteps: 1,975,770,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975770848...
Checkpoint 1975770848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.73022
Policy Entropy: 2.17353
Value Function Loss: 0.01740

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.62987

Collected Steps per Second: 22,399.94725
Overall Steps per Second: 10,663.90520

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.45666
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.68890

Cumulative Model Updates: 236,904
Cumulative Timesteps: 1,975,820,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.71649
Policy Entropy: 2.20333
Value Function Loss: 0.01726

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.54503
Value Function Update Magnitude: 0.59616

Collected Steps per Second: 23,178.04101
Overall Steps per Second: 10,812.92288

Timestep Collection Time: 2.15747
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.62465

Cumulative Model Updates: 236,910
Cumulative Timesteps: 1,975,870,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975870856...
Checkpoint 1975870856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.01803
Policy Entropy: 2.21702
Value Function Loss: 0.01765

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 22,644.35687
Overall Steps per Second: 10,838.30100

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.40589
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.61456

Cumulative Model Updates: 236,916
Cumulative Timesteps: 1,975,920,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.39778
Policy Entropy: 2.24568
Value Function Loss: 0.01721

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12274
Policy Update Magnitude: 0.53107
Value Function Update Magnitude: 0.57270

Collected Steps per Second: 23,479.73966
Overall Steps per Second: 10,778.23210

Timestep Collection Time: 2.13035
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.64084

Cumulative Model Updates: 236,922
Cumulative Timesteps: 1,975,970,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1975970890...
Checkpoint 1975970890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.88612
Policy Entropy: 2.22922
Value Function Loss: 0.01756

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.53219
Value Function Update Magnitude: 0.59834

Collected Steps per Second: 22,314.38116
Overall Steps per Second: 10,628.79576

Timestep Collection Time: 2.24151
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.70590

Cumulative Model Updates: 236,928
Cumulative Timesteps: 1,976,020,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.42082
Policy Entropy: 2.21976
Value Function Loss: 0.01751

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.54419
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 23,119.13169
Overall Steps per Second: 10,908.68391

Timestep Collection Time: 2.16392
Timestep Consumption Time: 2.42215
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.58607

Cumulative Model Updates: 236,934
Cumulative Timesteps: 1,976,070,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1976070936...
Checkpoint 1976070936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.81121
Policy Entropy: 2.18515
Value Function Loss: 0.01813

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.63680

Collected Steps per Second: 22,959.96587
Overall Steps per Second: 10,672.96355

Timestep Collection Time: 2.17892
Timestep Consumption Time: 2.50843
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.68736

Cumulative Model Updates: 236,940
Cumulative Timesteps: 1,976,120,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.23407
Policy Entropy: 2.18948
Value Function Loss: 0.01854

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.55644
Value Function Update Magnitude: 0.63115

Collected Steps per Second: 22,978.11327
Overall Steps per Second: 10,837.65236

Timestep Collection Time: 2.17642
Timestep Consumption Time: 2.43805
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61447

Cumulative Model Updates: 236,946
Cumulative Timesteps: 1,976,170,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1976170974...
Checkpoint 1976170974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.51694
Policy Entropy: 2.18921
Value Function Loss: 0.01927

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.62742

Collected Steps per Second: 22,218.45981
Overall Steps per Second: 10,666.36091

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.43784
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.68876

Cumulative Model Updates: 236,952
Cumulative Timesteps: 1,976,220,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.10313
Policy Entropy: 2.21318
Value Function Loss: 0.01872

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 21,897.50926
Overall Steps per Second: 10,637.05946

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.41854
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.70318

Cumulative Model Updates: 236,958
Cumulative Timesteps: 1,976,271,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1976271014...
Checkpoint 1976271014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.20767
Policy Entropy: 2.23438
Value Function Loss: 0.01806

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.63096

Collected Steps per Second: 22,810.09725
Overall Steps per Second: 10,715.15370

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.66722

Cumulative Model Updates: 236,964
Cumulative Timesteps: 1,976,321,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.57250
Policy Entropy: 2.25099
Value Function Loss: 0.01709

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.54814
Value Function Update Magnitude: 0.61592

Collected Steps per Second: 23,208.25492
Overall Steps per Second: 10,695.19128

Timestep Collection Time: 2.15492
Timestep Consumption Time: 2.52120
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.67612

Cumulative Model Updates: 236,970
Cumulative Timesteps: 1,976,371,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1976371036...
Checkpoint 1976371036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.54772
Policy Entropy: 2.22659
Value Function Loss: 0.01824

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.60913

Collected Steps per Second: 22,763.04263
Overall Steps per Second: 10,697.32477

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.67463

Cumulative Model Updates: 236,976
Cumulative Timesteps: 1,976,421,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.28461
Policy Entropy: 2.20752
Value Function Loss: 0.01791

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.59353

Collected Steps per Second: 23,167.09355
Overall Steps per Second: 10,908.47559

Timestep Collection Time: 2.15849
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.58414

Cumulative Model Updates: 236,982
Cumulative Timesteps: 1,976,471,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1976471048...
Checkpoint 1976471048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.51725
Policy Entropy: 2.20492
Value Function Loss: 0.01844

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.58257

Collected Steps per Second: 23,056.89597
Overall Steps per Second: 10,799.89249

Timestep Collection Time: 2.16933
Timestep Consumption Time: 2.46201
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.63134

Cumulative Model Updates: 236,988
Cumulative Timesteps: 1,976,521,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.71799
Policy Entropy: 2.23598
Value Function Loss: 0.01721

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.59132

Collected Steps per Second: 23,211.45409
Overall Steps per Second: 10,725.72739

Timestep Collection Time: 2.15437
Timestep Consumption Time: 2.50788
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.66225

Cumulative Model Updates: 236,994
Cumulative Timesteps: 1,976,571,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1976571072...
Checkpoint 1976571072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.31749
Policy Entropy: 2.26387
Value Function Loss: 0.01665

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.52420
Value Function Update Magnitude: 0.59453

Collected Steps per Second: 22,516.67677
Overall Steps per Second: 10,663.94947

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.69151

Cumulative Model Updates: 237,000
Cumulative Timesteps: 1,976,621,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.58378
Policy Entropy: 2.26358
Value Function Loss: 0.01609

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.51980
Value Function Update Magnitude: 0.57768

Collected Steps per Second: 22,915.81110
Overall Steps per Second: 10,844.78066

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.61236

Cumulative Model Updates: 237,006
Cumulative Timesteps: 1,976,671,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1976671122...
Checkpoint 1976671122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.22839
Policy Entropy: 2.25499
Value Function Loss: 0.01691

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.52099
Value Function Update Magnitude: 0.58690

Collected Steps per Second: 22,563.24450
Overall Steps per Second: 10,620.76911

Timestep Collection Time: 2.21608
Timestep Consumption Time: 2.49186
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.70795

Cumulative Model Updates: 237,012
Cumulative Timesteps: 1,976,721,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.31254
Policy Entropy: 2.22490
Value Function Loss: 0.01759

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.53086
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 22,678.56274
Overall Steps per Second: 10,687.94217

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.68079

Cumulative Model Updates: 237,018
Cumulative Timesteps: 1,976,771,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1976771152...
Checkpoint 1976771152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.79158
Policy Entropy: 2.21808
Value Function Loss: 0.01825

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.64217

Collected Steps per Second: 22,494.75401
Overall Steps per Second: 10,788.23720

Timestep Collection Time: 2.22399
Timestep Consumption Time: 2.41329
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.63727

Cumulative Model Updates: 237,024
Cumulative Timesteps: 1,976,821,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.47632
Policy Entropy: 2.21966
Value Function Loss: 0.01737

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.52384
Value Function Update Magnitude: 0.64314

Collected Steps per Second: 23,078.24777
Overall Steps per Second: 11,025.88494

Timestep Collection Time: 2.16654
Timestep Consumption Time: 2.36824
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.53478

Cumulative Model Updates: 237,030
Cumulative Timesteps: 1,976,871,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1976871180...
Checkpoint 1976871180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.94092
Policy Entropy: 2.23606
Value Function Loss: 0.01678

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.62821

Collected Steps per Second: 22,872.16268
Overall Steps per Second: 10,671.39076

Timestep Collection Time: 2.18606
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.68542

Cumulative Model Updates: 237,036
Cumulative Timesteps: 1,976,921,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.80978
Policy Entropy: 2.21558
Value Function Loss: 0.01669

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.52203
Value Function Update Magnitude: 0.61304

Collected Steps per Second: 23,157.42275
Overall Steps per Second: 10,819.41402

Timestep Collection Time: 2.16017
Timestep Consumption Time: 2.46337
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.62354

Cumulative Model Updates: 237,042
Cumulative Timesteps: 1,976,971,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1976971204...
Checkpoint 1976971204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.13376
Policy Entropy: 2.19424
Value Function Loss: 0.01747

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.53158
Value Function Update Magnitude: 0.60273

Collected Steps per Second: 22,757.22809
Overall Steps per Second: 10,692.13139

Timestep Collection Time: 2.19842
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.67914

Cumulative Model Updates: 237,048
Cumulative Timesteps: 1,977,021,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.63692
Policy Entropy: 2.22941
Value Function Loss: 0.01696

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.52945
Value Function Update Magnitude: 0.59477

Collected Steps per Second: 23,238.55149
Overall Steps per Second: 10,927.09805

Timestep Collection Time: 2.15160
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.57578

Cumulative Model Updates: 237,054
Cumulative Timesteps: 1,977,071,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1977071234...
Checkpoint 1977071234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.41635
Policy Entropy: 2.25681
Value Function Loss: 0.01696

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.52892
Value Function Update Magnitude: 0.58113

Collected Steps per Second: 22,924.50460
Overall Steps per Second: 10,740.53934

Timestep Collection Time: 2.18186
Timestep Consumption Time: 2.47508
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.65694

Cumulative Model Updates: 237,060
Cumulative Timesteps: 1,977,121,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.07594
Policy Entropy: 2.27468
Value Function Loss: 0.01659

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.52349
Value Function Update Magnitude: 0.57286

Collected Steps per Second: 22,257.04777
Overall Steps per Second: 10,682.26914

Timestep Collection Time: 2.24765
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.68309

Cumulative Model Updates: 237,066
Cumulative Timesteps: 1,977,171,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1977171278...
Checkpoint 1977171278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.61559
Policy Entropy: 2.26389
Value Function Loss: 0.01679

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.52723
Value Function Update Magnitude: 0.59814

Collected Steps per Second: 22,469.86720
Overall Steps per Second: 10,704.05114

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.67132

Cumulative Model Updates: 237,072
Cumulative Timesteps: 1,977,221,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.49108
Policy Entropy: 2.25398
Value Function Loss: 0.01635

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.53715
Value Function Update Magnitude: 0.60303

Collected Steps per Second: 22,857.43749
Overall Steps per Second: 10,936.52222

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.38465
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.57239

Cumulative Model Updates: 237,078
Cumulative Timesteps: 1,977,271,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1977271286...
Checkpoint 1977271286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.96420
Policy Entropy: 2.23255
Value Function Loss: 0.01602

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.53488
Value Function Update Magnitude: 0.58781

Collected Steps per Second: 22,933.86720
Overall Steps per Second: 10,635.10809

Timestep Collection Time: 2.18132
Timestep Consumption Time: 2.52254
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.70385

Cumulative Model Updates: 237,084
Cumulative Timesteps: 1,977,321,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.00204
Policy Entropy: 2.20643
Value Function Loss: 0.01666

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.58994

Collected Steps per Second: 22,983.45296
Overall Steps per Second: 10,795.73417

Timestep Collection Time: 2.17565
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.63183

Cumulative Model Updates: 237,090
Cumulative Timesteps: 1,977,371,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1977371316...
Checkpoint 1977371316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.01612
Policy Entropy: 2.19263
Value Function Loss: 0.01687

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.53166
Value Function Update Magnitude: 0.60219

Collected Steps per Second: 22,712.33247
Overall Steps per Second: 10,815.70668

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.42185
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.62365

Cumulative Model Updates: 237,096
Cumulative Timesteps: 1,977,421,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.23645
Policy Entropy: 2.20800
Value Function Loss: 0.01691

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.53416
Value Function Update Magnitude: 0.59869

Collected Steps per Second: 23,379.76460
Overall Steps per Second: 10,848.98290

Timestep Collection Time: 2.13954
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.61075

Cumulative Model Updates: 237,102
Cumulative Timesteps: 1,977,471,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1977471346...
Checkpoint 1977471346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.42881
Policy Entropy: 2.20178
Value Function Loss: 0.01760

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11355
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.59651

Collected Steps per Second: 23,142.12680
Overall Steps per Second: 10,800.80305

Timestep Collection Time: 2.16091
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.63003

Cumulative Model Updates: 237,108
Cumulative Timesteps: 1,977,521,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.16787
Policy Entropy: 2.22032
Value Function Loss: 0.01672

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.53191
Value Function Update Magnitude: 0.61348

Collected Steps per Second: 23,160.69236
Overall Steps per Second: 10,787.08643

Timestep Collection Time: 2.15995
Timestep Consumption Time: 2.47763
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.63758

Cumulative Model Updates: 237,114
Cumulative Timesteps: 1,977,571,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1977571380...
Checkpoint 1977571380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.48491
Policy Entropy: 2.20973
Value Function Loss: 0.01772

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.53193
Value Function Update Magnitude: 0.61043

Collected Steps per Second: 22,509.23821
Overall Steps per Second: 10,936.78448

Timestep Collection Time: 2.22202
Timestep Consumption Time: 2.35117
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.57319

Cumulative Model Updates: 237,120
Cumulative Timesteps: 1,977,621,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.40140
Policy Entropy: 2.20891
Value Function Loss: 0.01665

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.52799
Value Function Update Magnitude: 0.60164

Collected Steps per Second: 22,645.81417
Overall Steps per Second: 10,628.36157

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.70722

Cumulative Model Updates: 237,126
Cumulative Timesteps: 1,977,671,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1977671426...
Checkpoint 1977671426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.40712
Policy Entropy: 2.21087
Value Function Loss: 0.01696

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.60152

Collected Steps per Second: 22,465.37700
Overall Steps per Second: 10,561.04417

Timestep Collection Time: 2.22583
Timestep Consumption Time: 2.50893
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.73476

Cumulative Model Updates: 237,132
Cumulative Timesteps: 1,977,721,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.97851
Policy Entropy: 2.20383
Value Function Loss: 0.01742

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.60069

Collected Steps per Second: 22,732.05404
Overall Steps per Second: 10,843.81218

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.41226
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.61258

Cumulative Model Updates: 237,138
Cumulative Timesteps: 1,977,771,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1977771448...
Checkpoint 1977771448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.75410
Policy Entropy: 2.22064
Value Function Loss: 0.01813

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.61097

Collected Steps per Second: 22,528.79812
Overall Steps per Second: 10,765.73972

Timestep Collection Time: 2.21974
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.64511

Cumulative Model Updates: 237,144
Cumulative Timesteps: 1,977,821,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.79452
Policy Entropy: 2.21742
Value Function Loss: 0.01899

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.62596

Collected Steps per Second: 23,326.43923
Overall Steps per Second: 10,939.13808

Timestep Collection Time: 2.14400
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.57184

Cumulative Model Updates: 237,150
Cumulative Timesteps: 1,977,871,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1977871468...
Checkpoint 1977871468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.69294
Policy Entropy: 2.21157
Value Function Loss: 0.01892

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.53606
Value Function Update Magnitude: 0.62612

Collected Steps per Second: 22,919.42133
Overall Steps per Second: 10,713.34768

Timestep Collection Time: 2.18190
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.66782

Cumulative Model Updates: 237,156
Cumulative Timesteps: 1,977,921,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.07359
Policy Entropy: 2.18489
Value Function Loss: 0.01796

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.61468

Collected Steps per Second: 22,688.08434
Overall Steps per Second: 10,748.54508

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.44858
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.65291

Cumulative Model Updates: 237,162
Cumulative Timesteps: 1,977,971,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1977971488...
Checkpoint 1977971488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.16435
Policy Entropy: 2.17037
Value Function Loss: 0.01756

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.53803
Value Function Update Magnitude: 0.60418

Collected Steps per Second: 22,481.37616
Overall Steps per Second: 10,778.10494

Timestep Collection Time: 2.22415
Timestep Consumption Time: 2.41507
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.63922

Cumulative Model Updates: 237,168
Cumulative Timesteps: 1,978,021,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.93270
Policy Entropy: 2.18329
Value Function Loss: 0.01717

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.53627
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 23,425.40853
Overall Steps per Second: 10,775.01166

Timestep Collection Time: 2.13554
Timestep Consumption Time: 2.50723
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.64278

Cumulative Model Updates: 237,174
Cumulative Timesteps: 1,978,071,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1978071516...
Checkpoint 1978071516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.64907
Policy Entropy: 2.19419
Value Function Loss: 0.01775

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.60580

Collected Steps per Second: 22,777.80386
Overall Steps per Second: 10,665.04415

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69065

Cumulative Model Updates: 237,180
Cumulative Timesteps: 1,978,121,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.61862
Policy Entropy: 2.22661
Value Function Loss: 0.01806

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.60566

Collected Steps per Second: 22,545.54115
Overall Steps per Second: 10,794.61422

Timestep Collection Time: 2.21853
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.63361

Cumulative Model Updates: 237,186
Cumulative Timesteps: 1,978,171,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1978171560...
Checkpoint 1978171560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.15773
Policy Entropy: 2.20377
Value Function Loss: 0.01760

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.62270

Collected Steps per Second: 22,978.21176
Overall Steps per Second: 10,706.80423

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.67292

Cumulative Model Updates: 237,192
Cumulative Timesteps: 1,978,221,592

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.64457
Policy Entropy: 2.22064
Value Function Loss: 0.01751

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.54299
Value Function Update Magnitude: 0.62304

Collected Steps per Second: 22,510.07141
Overall Steps per Second: 10,627.16279

Timestep Collection Time: 2.22221
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.70699

Cumulative Model Updates: 237,198
Cumulative Timesteps: 1,978,271,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1978271614...
Checkpoint 1978271614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.15143
Policy Entropy: 2.21123
Value Function Loss: 0.01758

Mean KL Divergence: 0.03297
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.53732
Value Function Update Magnitude: 0.61025

Collected Steps per Second: 22,730.05303
Overall Steps per Second: 10,863.22888

Timestep Collection Time: 2.19973
Timestep Consumption Time: 2.40295
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.60268

Cumulative Model Updates: 237,204
Cumulative Timesteps: 1,978,321,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.69083
Policy Entropy: 2.22120
Value Function Loss: 0.01714

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.52472
Value Function Update Magnitude: 0.59989

Collected Steps per Second: 22,759.51160
Overall Steps per Second: 10,902.43954

Timestep Collection Time: 2.19759
Timestep Consumption Time: 2.39001
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.58760

Cumulative Model Updates: 237,210
Cumulative Timesteps: 1,978,371,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1978371630...
Checkpoint 1978371630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.97073
Policy Entropy: 2.19413
Value Function Loss: 0.01656

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.53580
Value Function Update Magnitude: 0.59886

Collected Steps per Second: 22,889.53456
Overall Steps per Second: 10,613.47206

Timestep Collection Time: 2.18440
Timestep Consumption Time: 2.52659
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.71099

Cumulative Model Updates: 237,216
Cumulative Timesteps: 1,978,421,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.80188
Policy Entropy: 2.18982
Value Function Loss: 0.01628

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.52798
Value Function Update Magnitude: 0.59296

Collected Steps per Second: 23,163.58176
Overall Steps per Second: 10,782.04930

Timestep Collection Time: 2.15934
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.63901

Cumulative Model Updates: 237,222
Cumulative Timesteps: 1,978,471,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1978471648...
Checkpoint 1978471648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.97612
Policy Entropy: 2.17112
Value Function Loss: 0.01617

Mean KL Divergence: 0.03281
SB3 Clip Fraction: 0.17404
Policy Update Magnitude: 0.49733
Value Function Update Magnitude: 0.59667

Collected Steps per Second: 23,120.15287
Overall Steps per Second: 10,886.56012

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.59447

Cumulative Model Updates: 237,228
Cumulative Timesteps: 1,978,521,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.74481
Policy Entropy: 2.18635
Value Function Loss: 0.01758

Mean KL Divergence: 0.04447
SB3 Clip Fraction: 0.20175
Policy Update Magnitude: 0.48143
Value Function Update Magnitude: 0.62286

Collected Steps per Second: 23,096.95931
Overall Steps per Second: 10,897.64148

Timestep Collection Time: 2.16600
Timestep Consumption Time: 2.42472
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.59072

Cumulative Model Updates: 237,234
Cumulative Timesteps: 1,978,571,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1978571694...
Checkpoint 1978571694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.89824
Policy Entropy: 2.16538
Value Function Loss: 0.01834

Mean KL Divergence: 0.03841
SB3 Clip Fraction: 0.18314
Policy Update Magnitude: 0.52862
Value Function Update Magnitude: 0.64611

Collected Steps per Second: 21,660.17511
Overall Steps per Second: 10,528.59328

Timestep Collection Time: 2.30885
Timestep Consumption Time: 2.44108
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.74992

Cumulative Model Updates: 237,240
Cumulative Timesteps: 1,978,621,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.50238
Policy Entropy: 2.15059
Value Function Loss: 0.01890

Mean KL Divergence: 0.02650
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.56313
Value Function Update Magnitude: 0.66869

Collected Steps per Second: 21,548.86624
Overall Steps per Second: 10,315.18435

Timestep Collection Time: 2.32040
Timestep Consumption Time: 2.52702
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.84742

Cumulative Model Updates: 237,246
Cumulative Timesteps: 1,978,671,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1978671706...
Checkpoint 1978671706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.53345
Policy Entropy: 2.15377
Value Function Loss: 0.01834

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.56722
Value Function Update Magnitude: 0.64217

Collected Steps per Second: 21,634.39925
Overall Steps per Second: 10,443.39938

Timestep Collection Time: 2.31113
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.78771

Cumulative Model Updates: 237,252
Cumulative Timesteps: 1,978,721,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.29537
Policy Entropy: 2.16214
Value Function Loss: 0.01725

Mean KL Divergence: 0.03321
SB3 Clip Fraction: 0.18027
Policy Update Magnitude: 0.55991
Value Function Update Magnitude: 0.62228

Collected Steps per Second: 22,188.49312
Overall Steps per Second: 10,497.70373

Timestep Collection Time: 2.25351
Timestep Consumption Time: 2.50963
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.76314

Cumulative Model Updates: 237,258
Cumulative Timesteps: 1,978,771,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1978771708...
Checkpoint 1978771708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.79412
Policy Entropy: 2.19225
Value Function Loss: 0.01726

Mean KL Divergence: 0.03239
SB3 Clip Fraction: 0.17808
Policy Update Magnitude: 0.53514
Value Function Update Magnitude: 0.61564

Collected Steps per Second: 22,615.54354
Overall Steps per Second: 10,843.26561

Timestep Collection Time: 2.21184
Timestep Consumption Time: 2.40134
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.61319

Cumulative Model Updates: 237,264
Cumulative Timesteps: 1,978,821,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.14845
Policy Entropy: 2.21372
Value Function Loss: 0.01800

Mean KL Divergence: 0.03014
SB3 Clip Fraction: 0.17493
Policy Update Magnitude: 0.52558
Value Function Update Magnitude: 0.61878

Collected Steps per Second: 23,442.07597
Overall Steps per Second: 10,778.57581

Timestep Collection Time: 2.13343
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.63995

Cumulative Model Updates: 237,270
Cumulative Timesteps: 1,978,871,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1978871742...
Checkpoint 1978871742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.56350
Policy Entropy: 2.21421
Value Function Loss: 0.01709

Mean KL Divergence: 0.02835
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.53527
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 22,689.33507
Overall Steps per Second: 10,608.95067

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.71338

Cumulative Model Updates: 237,276
Cumulative Timesteps: 1,978,921,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.50400
Policy Entropy: 2.23087
Value Function Loss: 0.01761

Mean KL Divergence: 0.02363
SB3 Clip Fraction: 0.15139
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.60200

Collected Steps per Second: 22,811.66494
Overall Steps per Second: 10,865.93603

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.41064
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60338

Cumulative Model Updates: 237,282
Cumulative Timesteps: 1,978,971,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1978971766...
Checkpoint 1978971766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.32842
Policy Entropy: 2.21997
Value Function Loss: 0.01719

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.61662

Collected Steps per Second: 22,927.26972
Overall Steps per Second: 11,028.67555

Timestep Collection Time: 2.18090
Timestep Consumption Time: 2.35292
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.53382

Cumulative Model Updates: 237,288
Cumulative Timesteps: 1,979,021,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.97049
Policy Entropy: 2.25824
Value Function Loss: 0.01821

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.64270

Collected Steps per Second: 23,639.89872
Overall Steps per Second: 10,977.96522

Timestep Collection Time: 2.11558
Timestep Consumption Time: 2.44010
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.55567

Cumulative Model Updates: 237,294
Cumulative Timesteps: 1,979,071,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1979071780...
Checkpoint 1979071780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.12300
Policy Entropy: 2.26377
Value Function Loss: 0.01764

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.64319

Collected Steps per Second: 22,783.66252
Overall Steps per Second: 10,637.23819

Timestep Collection Time: 2.19543
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.70235

Cumulative Model Updates: 237,300
Cumulative Timesteps: 1,979,121,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.82359
Policy Entropy: 2.25330
Value Function Loss: 0.01865

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.64152

Collected Steps per Second: 22,722.05926
Overall Steps per Second: 10,847.20695

Timestep Collection Time: 2.20059
Timestep Consumption Time: 2.40907
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60967

Cumulative Model Updates: 237,306
Cumulative Timesteps: 1,979,171,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1979171802...
Checkpoint 1979171802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.43461
Policy Entropy: 2.24984
Value Function Loss: 0.01790

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.64839

Collected Steps per Second: 23,367.43202
Overall Steps per Second: 10,841.46743

Timestep Collection Time: 2.13973
Timestep Consumption Time: 2.47219
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.61192

Cumulative Model Updates: 237,312
Cumulative Timesteps: 1,979,221,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.74156
Policy Entropy: 2.25152
Value Function Loss: 0.01740

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.63852

Collected Steps per Second: 22,743.91462
Overall Steps per Second: 10,781.21987

Timestep Collection Time: 2.19927
Timestep Consumption Time: 2.44028
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.63955

Cumulative Model Updates: 237,318
Cumulative Timesteps: 1,979,271,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1979271822...
Checkpoint 1979271822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.15850
Policy Entropy: 2.23859
Value Function Loss: 0.01689

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.61161

Collected Steps per Second: 22,237.12896
Overall Steps per Second: 10,610.46909

Timestep Collection Time: 2.24984
Timestep Consumption Time: 2.46531
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.71515

Cumulative Model Updates: 237,324
Cumulative Timesteps: 1,979,321,852

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.70891
Policy Entropy: 2.20788
Value Function Loss: 0.01719

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.55684
Value Function Update Magnitude: 0.61608

Collected Steps per Second: 23,232.88946
Overall Steps per Second: 10,898.89585

Timestep Collection Time: 2.15247
Timestep Consumption Time: 2.43589
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.58835

Cumulative Model Updates: 237,330
Cumulative Timesteps: 1,979,371,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1979371860...
Checkpoint 1979371860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.22386
Policy Entropy: 2.20815
Value Function Loss: 0.01742

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.55294
Value Function Update Magnitude: 0.62598

Collected Steps per Second: 23,139.51793
Overall Steps per Second: 10,758.98084

Timestep Collection Time: 2.16106
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.64784

Cumulative Model Updates: 237,336
Cumulative Timesteps: 1,979,421,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.05035
Policy Entropy: 2.24628
Value Function Loss: 0.01755

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.61580

Collected Steps per Second: 23,571.17987
Overall Steps per Second: 10,772.88097

Timestep Collection Time: 2.12157
Timestep Consumption Time: 2.52045
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.64203

Cumulative Model Updates: 237,342
Cumulative Timesteps: 1,979,471,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1979471874...
Checkpoint 1979471874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.00081
Policy Entropy: 2.29124
Value Function Loss: 0.01725

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.52567
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 23,056.49209
Overall Steps per Second: 10,779.14527

Timestep Collection Time: 2.16937
Timestep Consumption Time: 2.47089
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.64026

Cumulative Model Updates: 237,348
Cumulative Timesteps: 1,979,521,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.99691
Policy Entropy: 2.26835
Value Function Loss: 0.01771

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.54059
Value Function Update Magnitude: 0.62325

Collected Steps per Second: 23,145.41894
Overall Steps per Second: 10,928.93882

Timestep Collection Time: 2.16112
Timestep Consumption Time: 2.41572
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.57684

Cumulative Model Updates: 237,354
Cumulative Timesteps: 1,979,571,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1979571912...
Checkpoint 1979571912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.04877
Policy Entropy: 2.24417
Value Function Loss: 0.01866

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.61736

Collected Steps per Second: 22,998.40088
Overall Steps per Second: 10,853.65117

Timestep Collection Time: 2.17406
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.60674

Cumulative Model Updates: 237,360
Cumulative Timesteps: 1,979,621,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.30402
Policy Entropy: 2.23010
Value Function Loss: 0.01843

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.61290

Collected Steps per Second: 22,727.36981
Overall Steps per Second: 10,739.61952

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.65696

Cumulative Model Updates: 237,366
Cumulative Timesteps: 1,979,671,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1979671926...
Checkpoint 1979671926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.55640
Policy Entropy: 2.26129
Value Function Loss: 0.01741

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.60690

Collected Steps per Second: 22,766.94696
Overall Steps per Second: 10,940.10227

Timestep Collection Time: 2.19819
Timestep Consumption Time: 2.37636
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.57455

Cumulative Model Updates: 237,372
Cumulative Timesteps: 1,979,721,972

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.13640
Policy Entropy: 2.26425
Value Function Loss: 0.01635

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 22,694.85960
Overall Steps per Second: 10,788.90799

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63532

Cumulative Model Updates: 237,378
Cumulative Timesteps: 1,979,771,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1979771982...
Checkpoint 1979771982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.81862
Policy Entropy: 2.24382
Value Function Loss: 0.01660

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.53451
Value Function Update Magnitude: 0.57919

Collected Steps per Second: 22,574.63556
Overall Steps per Second: 10,726.50067

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.66434

Cumulative Model Updates: 237,384
Cumulative Timesteps: 1,979,822,014

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.67210
Policy Entropy: 2.22220
Value Function Loss: 0.01677

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.53220
Value Function Update Magnitude: 0.57678

Collected Steps per Second: 23,344.49407
Overall Steps per Second: 10,925.17706

Timestep Collection Time: 2.14269
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.57842

Cumulative Model Updates: 237,390
Cumulative Timesteps: 1,979,872,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1979872034...
Checkpoint 1979872034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.28148
Policy Entropy: 2.22349
Value Function Loss: 0.01667

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.60148

Collected Steps per Second: 23,144.35612
Overall Steps per Second: 10,785.57397

Timestep Collection Time: 2.16035
Timestep Consumption Time: 2.47547
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.63582

Cumulative Model Updates: 237,396
Cumulative Timesteps: 1,979,922,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.84821
Policy Entropy: 2.21181
Value Function Loss: 0.01704

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.61615

Collected Steps per Second: 23,097.05333
Overall Steps per Second: 10,779.02851

Timestep Collection Time: 2.16582
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.64086

Cumulative Model Updates: 237,402
Cumulative Timesteps: 1,979,972,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1979972058...
Checkpoint 1979972058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.61061
Policy Entropy: 2.21360
Value Function Loss: 0.01590

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.54152
Value Function Update Magnitude: 0.62308

Collected Steps per Second: 22,803.28478
Overall Steps per Second: 10,612.83566

Timestep Collection Time: 2.19319
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.71241

Cumulative Model Updates: 237,408
Cumulative Timesteps: 1,980,022,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.11743
Policy Entropy: 2.21054
Value Function Loss: 0.01546

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.53245
Value Function Update Magnitude: 0.60241

Collected Steps per Second: 23,128.41737
Overall Steps per Second: 10,953.40882

Timestep Collection Time: 2.16279
Timestep Consumption Time: 2.40400
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.56680

Cumulative Model Updates: 237,414
Cumulative Timesteps: 1,980,072,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1980072092...
Checkpoint 1980072092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.28213
Policy Entropy: 2.23131
Value Function Loss: 0.01534

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.53198
Value Function Update Magnitude: 0.59546

Collected Steps per Second: 21,866.80596
Overall Steps per Second: 10,646.19667

Timestep Collection Time: 2.28657
Timestep Consumption Time: 2.40994
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.69651

Cumulative Model Updates: 237,420
Cumulative Timesteps: 1,980,122,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.24633
Policy Entropy: 2.23935
Value Function Loss: 0.01657

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.54104
Value Function Update Magnitude: 0.59894

Collected Steps per Second: 22,768.06450
Overall Steps per Second: 10,804.36380

Timestep Collection Time: 2.19641
Timestep Consumption Time: 2.43209
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.62850

Cumulative Model Updates: 237,426
Cumulative Timesteps: 1,980,172,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1980172100...
Checkpoint 1980172100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.82960
Policy Entropy: 2.24299
Value Function Loss: 0.01669

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.59601

Collected Steps per Second: 22,209.75221
Overall Steps per Second: 10,659.77343

Timestep Collection Time: 2.25162
Timestep Consumption Time: 2.43966
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.69128

Cumulative Model Updates: 237,432
Cumulative Timesteps: 1,980,222,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.95917
Policy Entropy: 2.25444
Value Function Loss: 0.01614

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.59322

Collected Steps per Second: 22,689.32423
Overall Steps per Second: 10,678.40592

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.47896
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.68291

Cumulative Model Updates: 237,438
Cumulative Timesteps: 1,980,272,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1980272114...
Checkpoint 1980272114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.79667
Policy Entropy: 2.24472
Value Function Loss: 0.01682

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.59373

Collected Steps per Second: 22,793.85654
Overall Steps per Second: 10,933.18007

Timestep Collection Time: 2.19375
Timestep Consumption Time: 2.37985
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.57360

Cumulative Model Updates: 237,444
Cumulative Timesteps: 1,980,322,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.97629
Policy Entropy: 2.25727
Value Function Loss: 0.01689

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.55686
Value Function Update Magnitude: 0.59916

Collected Steps per Second: 22,895.21461
Overall Steps per Second: 10,648.72727

Timestep Collection Time: 2.18439
Timestep Consumption Time: 2.51214
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.69652

Cumulative Model Updates: 237,450
Cumulative Timesteps: 1,980,372,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1980372130...
Checkpoint 1980372130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.73272
Policy Entropy: 2.24334
Value Function Loss: 0.01804

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.55458
Value Function Update Magnitude: 0.60927

Collected Steps per Second: 23,019.31354
Overall Steps per Second: 10,881.85119

Timestep Collection Time: 2.17261
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.59591

Cumulative Model Updates: 237,456
Cumulative Timesteps: 1,980,422,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.67544
Policy Entropy: 2.24507
Value Function Loss: 0.01774

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 23,025.91320
Overall Steps per Second: 10,936.41041

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.40167
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.57426

Cumulative Model Updates: 237,462
Cumulative Timesteps: 1,980,472,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1980472168...
Checkpoint 1980472168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.88790
Policy Entropy: 2.19636
Value Function Loss: 0.01756

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.61149

Collected Steps per Second: 23,036.60293
Overall Steps per Second: 10,773.74095

Timestep Collection Time: 2.17185
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.64388

Cumulative Model Updates: 237,468
Cumulative Timesteps: 1,980,522,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.90143
Policy Entropy: 2.20212
Value Function Loss: 0.01650

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.62332

Collected Steps per Second: 23,500.06640
Overall Steps per Second: 10,804.33747

Timestep Collection Time: 2.12816
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.62888

Cumulative Model Updates: 237,474
Cumulative Timesteps: 1,980,572,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1980572212...
Checkpoint 1980572212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.35790
Policy Entropy: 2.20160
Value Function Loss: 0.01652

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.59930

Collected Steps per Second: 21,528.51603
Overall Steps per Second: 10,530.15325

Timestep Collection Time: 2.32287
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.74903

Cumulative Model Updates: 237,480
Cumulative Timesteps: 1,980,622,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.83402
Policy Entropy: 2.22062
Value Function Loss: 0.01688

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.51855
Value Function Update Magnitude: 0.58156

Collected Steps per Second: 23,135.93411
Overall Steps per Second: 11,016.54431

Timestep Collection Time: 2.16149
Timestep Consumption Time: 2.37787
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.53935

Cumulative Model Updates: 237,486
Cumulative Timesteps: 1,980,672,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1980672228...
Checkpoint 1980672228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.22652
Policy Entropy: 2.22639
Value Function Loss: 0.01706

Mean KL Divergence: 0.02437
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.50848
Value Function Update Magnitude: 0.58078

Collected Steps per Second: 22,526.85974
Overall Steps per Second: 10,624.51390

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.70798

Cumulative Model Updates: 237,492
Cumulative Timesteps: 1,980,722,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.67132
Policy Entropy: 2.23705
Value Function Loss: 0.01695

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.15712
Policy Update Magnitude: 0.50944
Value Function Update Magnitude: 0.57736

Collected Steps per Second: 22,606.58601
Overall Steps per Second: 10,641.14018

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.48780
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.70025

Cumulative Model Updates: 237,498
Cumulative Timesteps: 1,980,772,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1980772264...
Checkpoint 1980772264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.65774
Policy Entropy: 2.26992
Value Function Loss: 0.01619

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.52380
Value Function Update Magnitude: 0.55419

Collected Steps per Second: 22,725.72434
Overall Steps per Second: 10,874.97388

Timestep Collection Time: 2.20024
Timestep Consumption Time: 2.39766
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.59790

Cumulative Model Updates: 237,504
Cumulative Timesteps: 1,980,822,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.57488
Policy Entropy: 2.26356
Value Function Loss: 0.01651

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.52985
Value Function Update Magnitude: 0.56787

Collected Steps per Second: 23,100.85695
Overall Steps per Second: 10,857.52532

Timestep Collection Time: 2.16581
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.60805

Cumulative Model Updates: 237,510
Cumulative Timesteps: 1,980,872,298

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1980872298...
Checkpoint 1980872298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.24672
Policy Entropy: 2.25867
Value Function Loss: 0.01603

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.52397
Value Function Update Magnitude: 0.58389

Collected Steps per Second: 22,737.37792
Overall Steps per Second: 10,734.17573

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.65970

Cumulative Model Updates: 237,516
Cumulative Timesteps: 1,980,922,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.89120
Policy Entropy: 2.24495
Value Function Loss: 0.01617

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.51993
Value Function Update Magnitude: 0.57666

Collected Steps per Second: 23,250.46827
Overall Steps per Second: 10,905.76192

Timestep Collection Time: 2.15127
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.58638

Cumulative Model Updates: 237,522
Cumulative Timesteps: 1,980,972,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1980972334...
Checkpoint 1980972334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.79165
Policy Entropy: 2.25835
Value Function Loss: 0.01667

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.52470
Value Function Update Magnitude: 0.57411

Collected Steps per Second: 23,576.36675
Overall Steps per Second: 10,783.61116

Timestep Collection Time: 2.12153
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.63833

Cumulative Model Updates: 237,528
Cumulative Timesteps: 1,981,022,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.53006
Policy Entropy: 2.23081
Value Function Loss: 0.01683

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.58559

Collected Steps per Second: 23,515.78305
Overall Steps per Second: 10,810.02272

Timestep Collection Time: 2.12700
Timestep Consumption Time: 2.50001
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.62700

Cumulative Model Updates: 237,534
Cumulative Timesteps: 1,981,072,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1981072370...
Checkpoint 1981072370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.06234
Policy Entropy: 2.23404
Value Function Loss: 0.01583

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.53123
Value Function Update Magnitude: 0.59212

Collected Steps per Second: 23,007.75465
Overall Steps per Second: 10,944.25252

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.39600
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.56970

Cumulative Model Updates: 237,540
Cumulative Timesteps: 1,981,122,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.60150
Policy Entropy: 2.21145
Value Function Loss: 0.01665

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.53564
Value Function Update Magnitude: 0.58759

Collected Steps per Second: 22,658.95684
Overall Steps per Second: 10,965.86340

Timestep Collection Time: 2.20769
Timestep Consumption Time: 2.35410
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.56179

Cumulative Model Updates: 237,546
Cumulative Timesteps: 1,981,172,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1981172406...
Checkpoint 1981172406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.16335
Policy Entropy: 2.24365
Value Function Loss: 0.01685

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.52698
Value Function Update Magnitude: 0.57591

Collected Steps per Second: 22,603.31299
Overall Steps per Second: 10,680.93205

Timestep Collection Time: 2.21313
Timestep Consumption Time: 2.47036
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.68349

Cumulative Model Updates: 237,552
Cumulative Timesteps: 1,981,222,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.30172
Policy Entropy: 2.21911
Value Function Loss: 0.01841

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.53111
Value Function Update Magnitude: 0.56479

Collected Steps per Second: 22,847.77196
Overall Steps per Second: 10,822.20610

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.62068

Cumulative Model Updates: 237,558
Cumulative Timesteps: 1,981,272,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1981272436...
Checkpoint 1981272436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.92875
Policy Entropy: 2.21454
Value Function Loss: 0.01854

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.57483

Collected Steps per Second: 22,487.03879
Overall Steps per Second: 10,775.22167

Timestep Collection Time: 2.22377
Timestep Consumption Time: 2.41706
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.64083

Cumulative Model Updates: 237,564
Cumulative Timesteps: 1,981,322,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.13967
Policy Entropy: 2.21979
Value Function Loss: 0.01812

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.59782

Collected Steps per Second: 22,856.39476
Overall Steps per Second: 10,868.78411

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.60051

Cumulative Model Updates: 237,570
Cumulative Timesteps: 1,981,372,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1981372444...
Checkpoint 1981372444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.87940
Policy Entropy: 2.21063
Value Function Loss: 0.01743

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.60818

Collected Steps per Second: 22,853.58164
Overall Steps per Second: 10,612.55455

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.52376
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.71178

Cumulative Model Updates: 237,576
Cumulative Timesteps: 1,981,422,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.40380
Policy Entropy: 2.22791
Value Function Loss: 0.01667

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.53060
Value Function Update Magnitude: 0.59686

Collected Steps per Second: 23,270.36931
Overall Steps per Second: 10,901.47692

Timestep Collection Time: 2.14977
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.58892

Cumulative Model Updates: 237,582
Cumulative Timesteps: 1,981,472,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1981472474...
Checkpoint 1981472474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.28761
Policy Entropy: 2.20682
Value Function Loss: 0.01679

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.58706

Collected Steps per Second: 23,050.50718
Overall Steps per Second: 11,088.80272

Timestep Collection Time: 2.16932
Timestep Consumption Time: 2.34009
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.50941

Cumulative Model Updates: 237,588
Cumulative Timesteps: 1,981,522,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.44021
Policy Entropy: 2.25116
Value Function Loss: 0.01571

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.52582
Value Function Update Magnitude: 0.57490

Collected Steps per Second: 23,014.66740
Overall Steps per Second: 10,848.92220

Timestep Collection Time: 2.17296
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.60967

Cumulative Model Updates: 237,594
Cumulative Timesteps: 1,981,572,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1981572488...
Checkpoint 1981572488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.65200
Policy Entropy: 2.22686
Value Function Loss: 0.01599

Mean KL Divergence: 0.04630
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.52303
Value Function Update Magnitude: 0.56247

Collected Steps per Second: 22,997.65076
Overall Steps per Second: 10,772.01316

Timestep Collection Time: 2.17492
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.64333

Cumulative Model Updates: 237,600
Cumulative Timesteps: 1,981,622,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.26459
Policy Entropy: 2.21403
Value Function Loss: 0.01747

Mean KL Divergence: 0.05244
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.57580

Collected Steps per Second: 22,408.52391
Overall Steps per Second: 10,803.37465

Timestep Collection Time: 2.23236
Timestep Consumption Time: 2.39804
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.63040

Cumulative Model Updates: 237,606
Cumulative Timesteps: 1,981,672,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1981672530...
Checkpoint 1981672530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.15580
Policy Entropy: 2.20428
Value Function Loss: 0.01770

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.58797

Collected Steps per Second: 22,599.07222
Overall Steps per Second: 10,742.59625

Timestep Collection Time: 2.21337
Timestep Consumption Time: 2.44286
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.65623

Cumulative Model Updates: 237,612
Cumulative Timesteps: 1,981,722,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.97903
Policy Entropy: 2.21312
Value Function Loss: 0.01792

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.52973
Value Function Update Magnitude: 0.59298

Collected Steps per Second: 23,463.22339
Overall Steps per Second: 10,921.05657

Timestep Collection Time: 2.13099
Timestep Consumption Time: 2.44732
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.57831

Cumulative Model Updates: 237,618
Cumulative Timesteps: 1,981,772,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1981772550...
Checkpoint 1981772550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.71659
Policy Entropy: 2.19635
Value Function Loss: 0.01685

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.59263

Collected Steps per Second: 22,774.41543
Overall Steps per Second: 10,678.49670

Timestep Collection Time: 2.19676
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.68512

Cumulative Model Updates: 237,624
Cumulative Timesteps: 1,981,822,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.68130
Policy Entropy: 2.22022
Value Function Loss: 0.01714

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.15857
Policy Update Magnitude: 0.53807
Value Function Update Magnitude: 0.60446

Collected Steps per Second: 22,812.89250
Overall Steps per Second: 10,870.44689

Timestep Collection Time: 2.19236
Timestep Consumption Time: 2.40856
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.60091

Cumulative Model Updates: 237,630
Cumulative Timesteps: 1,981,872,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1981872594...
Checkpoint 1981872594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.75854
Policy Entropy: 2.22253
Value Function Loss: 0.01753

Mean KL Divergence: 0.02662
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.55207
Value Function Update Magnitude: 0.62286

Collected Steps per Second: 22,477.99079
Overall Steps per Second: 10,727.43602

Timestep Collection Time: 2.22440
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.66095

Cumulative Model Updates: 237,636
Cumulative Timesteps: 1,981,922,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.63791
Policy Entropy: 2.23580
Value Function Loss: 0.01850

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.14719
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.63107

Collected Steps per Second: 23,455.77278
Overall Steps per Second: 10,807.07378

Timestep Collection Time: 2.13167
Timestep Consumption Time: 2.49493
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.62660

Cumulative Model Updates: 237,642
Cumulative Timesteps: 1,981,972,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1981972594...
Checkpoint 1981972594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.17681
Policy Entropy: 2.19083
Value Function Loss: 0.01851

Mean KL Divergence: 0.02539
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.65016

Collected Steps per Second: 23,002.56851
Overall Steps per Second: 10,702.00371

Timestep Collection Time: 2.17367
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.67202

Cumulative Model Updates: 237,648
Cumulative Timesteps: 1,982,022,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.60517
Policy Entropy: 2.18464
Value Function Loss: 0.01784

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 22,157.25706
Overall Steps per Second: 10,717.33788

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.40903
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.66590

Cumulative Model Updates: 237,654
Cumulative Timesteps: 1,982,072,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1982072600...
Checkpoint 1982072600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.73206
Policy Entropy: 2.18660
Value Function Loss: 0.01700

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.62141

Collected Steps per Second: 22,119.96499
Overall Steps per Second: 10,752.38586

Timestep Collection Time: 2.26149
Timestep Consumption Time: 2.39088
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.65236

Cumulative Model Updates: 237,660
Cumulative Timesteps: 1,982,122,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.23281
Policy Entropy: 2.19888
Value Function Loss: 0.01761

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.62078

Collected Steps per Second: 23,138.29053
Overall Steps per Second: 10,888.83075

Timestep Collection Time: 2.16109
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.59223

Cumulative Model Updates: 237,666
Cumulative Timesteps: 1,982,172,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1982172628...
Checkpoint 1982172628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.92543
Policy Entropy: 2.22580
Value Function Loss: 0.01734

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.62588

Collected Steps per Second: 22,826.35400
Overall Steps per Second: 10,666.28556

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.49742
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.68804

Cumulative Model Updates: 237,672
Cumulative Timesteps: 1,982,222,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.09570
Policy Entropy: 2.21227
Value Function Loss: 0.01897

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.64036

Collected Steps per Second: 23,200.40430
Overall Steps per Second: 10,846.44940

Timestep Collection Time: 2.15582
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.61128

Cumulative Model Updates: 237,678
Cumulative Timesteps: 1,982,272,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1982272648...
Checkpoint 1982272648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.51472
Policy Entropy: 2.20394
Value Function Loss: 0.02013

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.57202
Value Function Update Magnitude: 0.66775

Collected Steps per Second: 23,016.33164
Overall Steps per Second: 11,049.82924

Timestep Collection Time: 2.17246
Timestep Consumption Time: 2.35268
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.52514

Cumulative Model Updates: 237,684
Cumulative Timesteps: 1,982,322,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.17184
Policy Entropy: 2.16858
Value Function Loss: 0.01996

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.69732

Collected Steps per Second: 23,103.49961
Overall Steps per Second: 10,800.94525

Timestep Collection Time: 2.16547
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.63200

Cumulative Model Updates: 237,690
Cumulative Timesteps: 1,982,372,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1982372680...
Checkpoint 1982372680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.92793
Policy Entropy: 2.18448
Value Function Loss: 0.01897

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.56632
Value Function Update Magnitude: 0.70286

Collected Steps per Second: 22,777.03250
Overall Steps per Second: 10,810.27025

Timestep Collection Time: 2.19546
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62579

Cumulative Model Updates: 237,696
Cumulative Timesteps: 1,982,422,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.99371
Policy Entropy: 2.20655
Value Function Loss: 0.01659

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.66838

Collected Steps per Second: 22,735.74942
Overall Steps per Second: 10,842.02515

Timestep Collection Time: 2.19988
Timestep Consumption Time: 2.41328
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61316

Cumulative Model Updates: 237,702
Cumulative Timesteps: 1,982,472,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1982472702...
Checkpoint 1982472702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.60955
Policy Entropy: 2.20041
Value Function Loss: 0.01655

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.62037

Collected Steps per Second: 22,003.76399
Overall Steps per Second: 10,730.04061

Timestep Collection Time: 2.27370
Timestep Consumption Time: 2.38891
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.66261

Cumulative Model Updates: 237,708
Cumulative Timesteps: 1,982,522,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.05930
Policy Entropy: 2.20094
Value Function Loss: 0.01716

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.54551
Value Function Update Magnitude: 0.59669

Collected Steps per Second: 22,824.03522
Overall Steps per Second: 10,748.92027

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.46096
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.65163

Cumulative Model Updates: 237,714
Cumulative Timesteps: 1,982,572,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1982572732...
Checkpoint 1982572732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.52220
Policy Entropy: 2.20767
Value Function Loss: 0.01739

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.59641

Collected Steps per Second: 22,456.32765
Overall Steps per Second: 10,740.12201

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.65656

Cumulative Model Updates: 237,720
Cumulative Timesteps: 1,982,622,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.53199
Policy Entropy: 2.21979
Value Function Loss: 0.01772

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.54134
Value Function Update Magnitude: 0.59243

Collected Steps per Second: 22,706.58543
Overall Steps per Second: 10,716.84716

Timestep Collection Time: 2.20447
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.67078

Cumulative Model Updates: 237,726
Cumulative Timesteps: 1,982,672,800

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1982672800...
Checkpoint 1982672800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.71598
Policy Entropy: 2.23004
Value Function Loss: 0.01802

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.61953

Collected Steps per Second: 22,957.48095
Overall Steps per Second: 10,914.57241

Timestep Collection Time: 2.17794
Timestep Consumption Time: 2.40309
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.58103

Cumulative Model Updates: 237,732
Cumulative Timesteps: 1,982,722,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.43008
Policy Entropy: 2.21595
Value Function Loss: 0.01757

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.53616
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 23,124.57594
Overall Steps per Second: 10,836.37825

Timestep Collection Time: 2.16229
Timestep Consumption Time: 2.45198
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.61427

Cumulative Model Updates: 237,738
Cumulative Timesteps: 1,982,772,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1982772802...
Checkpoint 1982772802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.47508
Policy Entropy: 2.21312
Value Function Loss: 0.01788

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.60888

Collected Steps per Second: 22,753.46594
Overall Steps per Second: 10,711.67225

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.47152
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.67005

Cumulative Model Updates: 237,744
Cumulative Timesteps: 1,982,822,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.88132
Policy Entropy: 2.18255
Value Function Loss: 0.01736

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.54813
Value Function Update Magnitude: 0.61023

Collected Steps per Second: 23,021.48207
Overall Steps per Second: 10,882.41276

Timestep Collection Time: 2.17258
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.59604

Cumulative Model Updates: 237,750
Cumulative Timesteps: 1,982,872,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1982872842...
Checkpoint 1982872842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.92885
Policy Entropy: 2.17596
Value Function Loss: 0.01799

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.55922
Value Function Update Magnitude: 0.62711

Collected Steps per Second: 22,702.45649
Overall Steps per Second: 10,875.35166

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.39611
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.59939

Cumulative Model Updates: 237,756
Cumulative Timesteps: 1,982,922,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.15194
Policy Entropy: 2.20123
Value Function Loss: 0.01688

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.64118

Collected Steps per Second: 23,265.74756
Overall Steps per Second: 10,758.01136

Timestep Collection Time: 2.14986
Timestep Consumption Time: 2.49952
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.64937

Cumulative Model Updates: 237,762
Cumulative Timesteps: 1,982,972,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1982972880...
Checkpoint 1982972880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.35295
Policy Entropy: 2.21919
Value Function Loss: 0.01654

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.62827

Collected Steps per Second: 22,290.07929
Overall Steps per Second: 10,620.75471

Timestep Collection Time: 2.24423
Timestep Consumption Time: 2.46580
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.71002

Cumulative Model Updates: 237,768
Cumulative Timesteps: 1,983,022,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.50472
Policy Entropy: 2.23168
Value Function Loss: 0.01633

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.61691

Collected Steps per Second: 22,534.14541
Overall Steps per Second: 10,823.38814

Timestep Collection Time: 2.21894
Timestep Consumption Time: 2.40087
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61981

Cumulative Model Updates: 237,774
Cumulative Timesteps: 1,983,072,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1983072906...
Checkpoint 1983072906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.04595
Policy Entropy: 2.23417
Value Function Loss: 0.01679

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.62398

Collected Steps per Second: 22,565.52870
Overall Steps per Second: 10,823.08888

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.40446
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.62068

Cumulative Model Updates: 237,780
Cumulative Timesteps: 1,983,122,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.09075
Policy Entropy: 2.23943
Value Function Loss: 0.01788

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.63316

Collected Steps per Second: 23,284.69087
Overall Steps per Second: 10,817.33128

Timestep Collection Time: 2.14914
Timestep Consumption Time: 2.47696
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.62609

Cumulative Model Updates: 237,786
Cumulative Timesteps: 1,983,172,958

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1983172958...
Checkpoint 1983172958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.17825
Policy Entropy: 2.26322
Value Function Loss: 0.01745

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.63554

Collected Steps per Second: 22,968.96036
Overall Steps per Second: 10,748.41189

Timestep Collection Time: 2.17790
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.65408

Cumulative Model Updates: 237,792
Cumulative Timesteps: 1,983,222,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.08668
Policy Entropy: 2.25796
Value Function Loss: 0.01784

Mean KL Divergence: 0.02760
SB3 Clip Fraction: 0.15981
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.62897

Collected Steps per Second: 23,167.26574
Overall Steps per Second: 10,785.63244

Timestep Collection Time: 2.15830
Timestep Consumption Time: 2.47768
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.63598

Cumulative Model Updates: 237,798
Cumulative Timesteps: 1,983,272,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1983272984...
Checkpoint 1983272984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.90340
Policy Entropy: 2.26795
Value Function Loss: 0.01681

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.51667
Value Function Update Magnitude: 0.61675

Collected Steps per Second: 23,062.24389
Overall Steps per Second: 11,055.54938

Timestep Collection Time: 2.16822
Timestep Consumption Time: 2.35476
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.52298

Cumulative Model Updates: 237,804
Cumulative Timesteps: 1,983,322,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.31961
Policy Entropy: 2.25748
Value Function Loss: 0.01771

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 23,294.25244
Overall Steps per Second: 10,906.27560

Timestep Collection Time: 2.14671
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.58507

Cumulative Model Updates: 237,810
Cumulative Timesteps: 1,983,372,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1983372994...
Checkpoint 1983372994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.08820
Policy Entropy: 2.25492
Value Function Loss: 0.01862

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.56467
Value Function Update Magnitude: 0.64148

Collected Steps per Second: 22,756.49292
Overall Steps per Second: 10,689.08869

Timestep Collection Time: 2.19797
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.67935

Cumulative Model Updates: 237,816
Cumulative Timesteps: 1,983,423,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.48897
Policy Entropy: 2.25816
Value Function Loss: 0.01984

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.56022
Value Function Update Magnitude: 0.65047

Collected Steps per Second: 22,563.72497
Overall Steps per Second: 10,669.07349

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.68757

Cumulative Model Updates: 237,822
Cumulative Timesteps: 1,983,473,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1983473024...
Checkpoint 1983473024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.69424
Policy Entropy: 2.25977
Value Function Loss: 0.01815

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.54339
Value Function Update Magnitude: 0.64815

Collected Steps per Second: 22,299.28105
Overall Steps per Second: 10,908.15292

Timestep Collection Time: 2.24267
Timestep Consumption Time: 2.34197
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.58464

Cumulative Model Updates: 237,828
Cumulative Timesteps: 1,983,523,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.08879
Policy Entropy: 2.24749
Value Function Loss: 0.01743

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.53046
Value Function Update Magnitude: 0.64018

Collected Steps per Second: 23,177.95209
Overall Steps per Second: 10,942.53583

Timestep Collection Time: 2.15809
Timestep Consumption Time: 2.41307
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.57115

Cumulative Model Updates: 237,834
Cumulative Timesteps: 1,983,573,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1983573054...
Checkpoint 1983573054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.93101
Policy Entropy: 2.25010
Value Function Loss: 0.01597

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.52604
Value Function Update Magnitude: 0.61114

Collected Steps per Second: 23,121.79248
Overall Steps per Second: 10,654.18199

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.53073
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.69337

Cumulative Model Updates: 237,840
Cumulative Timesteps: 1,983,623,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.27471
Policy Entropy: 2.24406
Value Function Loss: 0.01720

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.53225
Value Function Update Magnitude: 0.59471

Collected Steps per Second: 23,085.94219
Overall Steps per Second: 10,808.68627

Timestep Collection Time: 2.16634
Timestep Consumption Time: 2.46068
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.62702

Cumulative Model Updates: 237,846
Cumulative Timesteps: 1,983,673,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1983673070...
Checkpoint 1983673070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.23064
Policy Entropy: 2.25371
Value Function Loss: 0.01619

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 23,632.58554
Overall Steps per Second: 10,887.54831

Timestep Collection Time: 2.11632
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.59369

Cumulative Model Updates: 237,852
Cumulative Timesteps: 1,983,723,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.35129
Policy Entropy: 2.23293
Value Function Loss: 0.01708

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.61161

Collected Steps per Second: 23,523.40988
Overall Steps per Second: 10,852.40876

Timestep Collection Time: 2.12639
Timestep Consumption Time: 2.48272
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.60911

Cumulative Model Updates: 237,858
Cumulative Timesteps: 1,983,773,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1983773104...
Checkpoint 1983773104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.08910
Policy Entropy: 2.22537
Value Function Loss: 0.01799

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.64174

Collected Steps per Second: 23,203.69392
Overall Steps per Second: 10,892.30349

Timestep Collection Time: 2.15509
Timestep Consumption Time: 2.43586
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59095

Cumulative Model Updates: 237,864
Cumulative Timesteps: 1,983,823,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.99101
Policy Entropy: 2.25586
Value Function Loss: 0.01730

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.64569

Collected Steps per Second: 23,015.98288
Overall Steps per Second: 10,963.00335

Timestep Collection Time: 2.17292
Timestep Consumption Time: 2.38896
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.56189

Cumulative Model Updates: 237,870
Cumulative Timesteps: 1,983,873,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1983873122...
Checkpoint 1983873122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.08792
Policy Entropy: 2.25502
Value Function Loss: 0.01704

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.61149

Collected Steps per Second: 22,548.41436
Overall Steps per Second: 10,648.38407

Timestep Collection Time: 2.21852
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69780

Cumulative Model Updates: 237,876
Cumulative Timesteps: 1,983,923,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.59780
Policy Entropy: 2.26449
Value Function Loss: 0.01658

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.52140
Value Function Update Magnitude: 0.59337

Collected Steps per Second: 22,927.03213
Overall Steps per Second: 10,810.81642

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.44514
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62685

Cumulative Model Updates: 237,882
Cumulative Timesteps: 1,983,973,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1983973166...
Checkpoint 1983973166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.85635
Policy Entropy: 2.22377
Value Function Loss: 0.01748

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.59373

Collected Steps per Second: 22,198.31163
Overall Steps per Second: 10,679.20932

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.68537

Cumulative Model Updates: 237,888
Cumulative Timesteps: 1,984,023,202

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.86227
Policy Entropy: 2.22184
Value Function Loss: 0.01783

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.55669
Value Function Update Magnitude: 0.61255

Collected Steps per Second: 22,865.88919
Overall Steps per Second: 11,021.10294

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.35140
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.53929

Cumulative Model Updates: 237,894
Cumulative Timesteps: 1,984,073,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1984073230...
Checkpoint 1984073230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.49107
Policy Entropy: 2.22037
Value Function Loss: 0.01810

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.54694
Value Function Update Magnitude: 0.62281

Collected Steps per Second: 22,925.52125
Overall Steps per Second: 10,610.93859

Timestep Collection Time: 2.18211
Timestep Consumption Time: 2.53246
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.71457

Cumulative Model Updates: 237,900
Cumulative Timesteps: 1,984,123,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.82312
Policy Entropy: 2.24193
Value Function Loss: 0.01774

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.53465
Value Function Update Magnitude: 0.60843

Collected Steps per Second: 22,921.25633
Overall Steps per Second: 10,830.02655

Timestep Collection Time: 2.18217
Timestep Consumption Time: 2.43629
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.61846

Cumulative Model Updates: 237,906
Cumulative Timesteps: 1,984,173,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1984173274...
Checkpoint 1984173274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.64408
Policy Entropy: 2.26884
Value Function Loss: 0.01759

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.53660
Value Function Update Magnitude: 0.58824

Collected Steps per Second: 22,685.69348
Overall Steps per Second: 10,720.63946

Timestep Collection Time: 2.20483
Timestep Consumption Time: 2.46075
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.66558

Cumulative Model Updates: 237,912
Cumulative Timesteps: 1,984,223,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.82752
Policy Entropy: 2.26757
Value Function Loss: 0.01872

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.53060
Value Function Update Magnitude: 0.58539

Collected Steps per Second: 23,157.83471
Overall Steps per Second: 10,923.23879

Timestep Collection Time: 2.16031
Timestep Consumption Time: 2.41965
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.57996

Cumulative Model Updates: 237,918
Cumulative Timesteps: 1,984,273,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1984273320...
Checkpoint 1984273320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.40681
Policy Entropy: 2.27243
Value Function Loss: 0.01866

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.51056
Value Function Update Magnitude: 0.58907

Collected Steps per Second: 23,102.26525
Overall Steps per Second: 10,783.18505

Timestep Collection Time: 2.16438
Timestep Consumption Time: 2.47266
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.63703

Cumulative Model Updates: 237,924
Cumulative Timesteps: 1,984,323,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.64962
Policy Entropy: 2.24732
Value Function Loss: 0.01877

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.53116
Value Function Update Magnitude: 0.60751

Collected Steps per Second: 22,981.62187
Overall Steps per Second: 10,776.51994

Timestep Collection Time: 2.17600
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.64046

Cumulative Model Updates: 237,930
Cumulative Timesteps: 1,984,373,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1984373330...
Checkpoint 1984373330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.84368
Policy Entropy: 2.23646
Value Function Loss: 0.01695

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.61350

Collected Steps per Second: 22,326.96668
Overall Steps per Second: 10,621.46395

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.46879
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.70896

Cumulative Model Updates: 237,936
Cumulative Timesteps: 1,984,423,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.20576
Policy Entropy: 2.20510
Value Function Loss: 0.01715

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.58915

Collected Steps per Second: 22,882.87216
Overall Steps per Second: 10,893.57674

Timestep Collection Time: 2.18539
Timestep Consumption Time: 2.40521
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.59060

Cumulative Model Updates: 237,942
Cumulative Timesteps: 1,984,473,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1984473354...
Checkpoint 1984473354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.74262
Policy Entropy: 2.23110
Value Function Loss: 0.01734

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.58228

Collected Steps per Second: 22,562.50446
Overall Steps per Second: 10,625.73471

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.70669

Cumulative Model Updates: 237,948
Cumulative Timesteps: 1,984,523,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.65591
Policy Entropy: 2.23557
Value Function Loss: 0.01684

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.54030
Value Function Update Magnitude: 0.59776

Collected Steps per Second: 22,890.15376
Overall Steps per Second: 10,856.38836

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.42201
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.60706

Cumulative Model Updates: 237,954
Cumulative Timesteps: 1,984,573,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1984573382...
Checkpoint 1984573382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.98155
Policy Entropy: 2.24496
Value Function Loss: 0.01770

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.59804

Collected Steps per Second: 22,463.35020
Overall Steps per Second: 10,733.17130

Timestep Collection Time: 2.22674
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.66032

Cumulative Model Updates: 237,960
Cumulative Timesteps: 1,984,623,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.35901
Policy Entropy: 2.19794
Value Function Loss: 0.01957

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.62669

Collected Steps per Second: 23,027.48469
Overall Steps per Second: 10,878.34795

Timestep Collection Time: 2.17141
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.59647

Cumulative Model Updates: 237,966
Cumulative Timesteps: 1,984,673,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1984673404...
Checkpoint 1984673404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.40984
Policy Entropy: 2.21620
Value Function Loss: 0.01980

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.57287
Value Function Update Magnitude: 0.66688

Collected Steps per Second: 22,947.15710
Overall Steps per Second: 10,716.80380

Timestep Collection Time: 2.18023
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.66837

Cumulative Model Updates: 237,972
Cumulative Timesteps: 1,984,723,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.94398
Policy Entropy: 2.24177
Value Function Loss: 0.01849

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.67779

Collected Steps per Second: 22,974.13013
Overall Steps per Second: 10,831.93018

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.61746

Cumulative Model Updates: 237,978
Cumulative Timesteps: 1,984,773,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1984773450...
Checkpoint 1984773450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.48545
Policy Entropy: 2.26819
Value Function Loss: 0.01739

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.66055

Collected Steps per Second: 22,617.37296
Overall Steps per Second: 10,655.57187

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.69313

Cumulative Model Updates: 237,984
Cumulative Timesteps: 1,984,823,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.27246
Policy Entropy: 2.24615
Value Function Loss: 0.01708

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.54406
Value Function Update Magnitude: 0.62915

Collected Steps per Second: 23,140.86393
Overall Steps per Second: 10,905.13848

Timestep Collection Time: 2.16189
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.58756

Cumulative Model Updates: 237,990
Cumulative Timesteps: 1,984,873,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1984873486...
Checkpoint 1984873486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.38407
Policy Entropy: 2.24672
Value Function Loss: 0.01658

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.61036

Collected Steps per Second: 22,868.41988
Overall Steps per Second: 10,683.84537

Timestep Collection Time: 2.18660
Timestep Consumption Time: 2.49374
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.68034

Cumulative Model Updates: 237,996
Cumulative Timesteps: 1,984,923,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.14898
Policy Entropy: 2.27586
Value Function Loss: 0.01567

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.52656
Value Function Update Magnitude: 0.60068

Collected Steps per Second: 23,029.02767
Overall Steps per Second: 10,850.77520

Timestep Collection Time: 2.17161
Timestep Consumption Time: 2.43728
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60889

Cumulative Model Updates: 238,002
Cumulative Timesteps: 1,984,973,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1984973500...
Checkpoint 1984973500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.70539
Policy Entropy: 2.27640
Value Function Loss: 0.01595

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.52371
Value Function Update Magnitude: 0.59889

Collected Steps per Second: 22,295.32203
Overall Steps per Second: 10,703.20136

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.67486

Cumulative Model Updates: 238,008
Cumulative Timesteps: 1,985,023,536

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.26845
Policy Entropy: 2.27971
Value Function Loss: 0.01623

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.52159
Value Function Update Magnitude: 0.61130

Collected Steps per Second: 22,646.18509
Overall Steps per Second: 10,896.96237

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.38189
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.59100

Cumulative Model Updates: 238,014
Cumulative Timesteps: 1,985,073,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1985073564...
Checkpoint 1985073564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.40400
Policy Entropy: 2.24523
Value Function Loss: 0.01677

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.53507
Value Function Update Magnitude: 0.60608

Collected Steps per Second: 22,681.58592
Overall Steps per Second: 10,574.46688

Timestep Collection Time: 2.20478
Timestep Consumption Time: 2.52434
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.72913

Cumulative Model Updates: 238,020
Cumulative Timesteps: 1,985,123,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.88236
Policy Entropy: 2.22681
Value Function Loss: 0.01658

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.54279
Value Function Update Magnitude: 0.61031

Collected Steps per Second: 23,186.35150
Overall Steps per Second: 10,871.67069

Timestep Collection Time: 2.15653
Timestep Consumption Time: 2.44277
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.59929

Cumulative Model Updates: 238,026
Cumulative Timesteps: 1,985,173,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1985173574...
Checkpoint 1985173574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.79279
Policy Entropy: 2.20845
Value Function Loss: 0.01708

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.62793

Collected Steps per Second: 22,886.91014
Overall Steps per Second: 10,716.11903

Timestep Collection Time: 2.18518
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.66699

Cumulative Model Updates: 238,032
Cumulative Timesteps: 1,985,223,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.18136
Policy Entropy: 2.23213
Value Function Loss: 0.01697

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.54473
Value Function Update Magnitude: 0.61840

Collected Steps per Second: 23,416.81414
Overall Steps per Second: 10,952.23019

Timestep Collection Time: 2.13650
Timestep Consumption Time: 2.43152
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.56802

Cumulative Model Updates: 238,038
Cumulative Timesteps: 1,985,273,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1985273616...
Checkpoint 1985273616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.43881
Policy Entropy: 2.24187
Value Function Loss: 0.01729

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.60089

Collected Steps per Second: 23,137.60100
Overall Steps per Second: 10,800.34360

Timestep Collection Time: 2.16159
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.63078

Cumulative Model Updates: 238,044
Cumulative Timesteps: 1,985,323,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.22813
Policy Entropy: 2.26181
Value Function Loss: 0.01727

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.53740
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 23,427.47182
Overall Steps per Second: 10,772.36598

Timestep Collection Time: 2.13484
Timestep Consumption Time: 2.50796
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.64281

Cumulative Model Updates: 238,050
Cumulative Timesteps: 1,985,373,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1985373644...
Checkpoint 1985373644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.73721
Policy Entropy: 2.23695
Value Function Loss: 0.01694

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.53525
Value Function Update Magnitude: 0.58328

Collected Steps per Second: 22,753.88129
Overall Steps per Second: 10,731.35993

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.65943

Cumulative Model Updates: 238,056
Cumulative Timesteps: 1,985,423,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.83665
Policy Entropy: 2.20783
Value Function Loss: 0.01825

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.59738

Collected Steps per Second: 22,889.60061
Overall Steps per Second: 10,882.71937

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.41043
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.59517

Cumulative Model Updates: 238,062
Cumulative Timesteps: 1,985,473,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1985473654...
Checkpoint 1985473654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.12701
Policy Entropy: 2.18897
Value Function Loss: 0.01780

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.55308
Value Function Update Magnitude: 0.60962

Collected Steps per Second: 22,749.33328
Overall Steps per Second: 10,688.53744

Timestep Collection Time: 2.19901
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.68034

Cumulative Model Updates: 238,068
Cumulative Timesteps: 1,985,523,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.15774
Policy Entropy: 2.18554
Value Function Loss: 0.01807

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.61147

Collected Steps per Second: 22,928.77693
Overall Steps per Second: 10,776.67242

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.45967
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.64095

Cumulative Model Updates: 238,074
Cumulative Timesteps: 1,985,573,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1985573694...
Checkpoint 1985573694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.96459
Policy Entropy: 2.22712
Value Function Loss: 0.01770

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.59728

Collected Steps per Second: 22,233.65085
Overall Steps per Second: 10,601.82769

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.71636

Cumulative Model Updates: 238,080
Cumulative Timesteps: 1,985,623,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.08662
Policy Entropy: 2.22296
Value Function Loss: 0.01843

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.55746
Value Function Update Magnitude: 0.59984

Collected Steps per Second: 23,146.64351
Overall Steps per Second: 10,933.21330

Timestep Collection Time: 2.16152
Timestep Consumption Time: 2.41462
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.57615

Cumulative Model Updates: 238,086
Cumulative Timesteps: 1,985,673,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1985673728...
Checkpoint 1985673728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.59678
Policy Entropy: 2.21391
Value Function Loss: 0.01852

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.61153

Collected Steps per Second: 22,567.74577
Overall Steps per Second: 10,590.45178

Timestep Collection Time: 2.21608
Timestep Consumption Time: 2.50628
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.72237

Cumulative Model Updates: 238,092
Cumulative Timesteps: 1,985,723,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.83186
Policy Entropy: 2.16110
Value Function Loss: 0.01857

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.56082
Value Function Update Magnitude: 0.63290

Collected Steps per Second: 23,032.09057
Overall Steps per Second: 10,859.00781

Timestep Collection Time: 2.17227
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.60742

Cumulative Model Updates: 238,098
Cumulative Timesteps: 1,985,773,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1985773772...
Checkpoint 1985773772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.34378
Policy Entropy: 2.15429
Value Function Loss: 0.01787

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.61734

Collected Steps per Second: 22,920.55856
Overall Steps per Second: 10,712.96255

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.66818

Cumulative Model Updates: 238,104
Cumulative Timesteps: 1,985,823,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.42433
Policy Entropy: 2.16103
Value Function Loss: 0.01733

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.54802
Value Function Update Magnitude: 0.60721

Collected Steps per Second: 23,083.43720
Overall Steps per Second: 10,944.68144

Timestep Collection Time: 2.16701
Timestep Consumption Time: 2.40343
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.57044

Cumulative Model Updates: 238,110
Cumulative Timesteps: 1,985,873,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1985873804...
Checkpoint 1985873804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.02998
Policy Entropy: 2.21878
Value Function Loss: 0.01605

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.60484

Collected Steps per Second: 21,730.34711
Overall Steps per Second: 10,554.86424

Timestep Collection Time: 2.30130
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.73791

Cumulative Model Updates: 238,116
Cumulative Timesteps: 1,985,923,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.55993
Policy Entropy: 2.21158
Value Function Loss: 0.01662

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.54319
Value Function Update Magnitude: 0.59461

Collected Steps per Second: 22,492.98915
Overall Steps per Second: 10,600.15147

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.71956

Cumulative Model Updates: 238,122
Cumulative Timesteps: 1,985,973,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1985973840...
Checkpoint 1985973840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.81097
Policy Entropy: 2.19719
Value Function Loss: 0.01763

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.55327
Value Function Update Magnitude: 0.60236

Collected Steps per Second: 22,530.80760
Overall Steps per Second: 10,693.69523

Timestep Collection Time: 2.22043
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.67827

Cumulative Model Updates: 238,128
Cumulative Timesteps: 1,986,023,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.89657
Policy Entropy: 2.18304
Value Function Loss: 0.01841

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.56081
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 23,709.08350
Overall Steps per Second: 10,868.76183

Timestep Collection Time: 2.10940
Timestep Consumption Time: 2.49204
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.60144

Cumulative Model Updates: 238,134
Cumulative Timesteps: 1,986,073,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1986073880...
Checkpoint 1986073880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.03790
Policy Entropy: 2.19919
Value Function Loss: 0.01789

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.64064

Collected Steps per Second: 22,731.73157
Overall Steps per Second: 10,649.25171

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.69592

Cumulative Model Updates: 238,140
Cumulative Timesteps: 1,986,123,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.23826
Policy Entropy: 2.23366
Value Function Loss: 0.01669

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.62899

Collected Steps per Second: 22,466.05271
Overall Steps per Second: 10,809.15710

Timestep Collection Time: 2.22594
Timestep Consumption Time: 2.40051
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62645

Cumulative Model Updates: 238,146
Cumulative Timesteps: 1,986,173,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1986173896...
Checkpoint 1986173896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.33506
Policy Entropy: 2.22818
Value Function Loss: 0.01674

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.61225

Collected Steps per Second: 22,958.14680
Overall Steps per Second: 10,810.21085

Timestep Collection Time: 2.17883
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.62729

Cumulative Model Updates: 238,152
Cumulative Timesteps: 1,986,223,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.73343
Policy Entropy: 2.23470
Value Function Loss: 0.01629

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.52795
Value Function Update Magnitude: 0.61723

Collected Steps per Second: 23,360.02864
Overall Steps per Second: 10,768.34284

Timestep Collection Time: 2.14075
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.64398

Cumulative Model Updates: 238,158
Cumulative Timesteps: 1,986,273,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1986273926...
Checkpoint 1986273926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.60936
Policy Entropy: 2.23143
Value Function Loss: 0.01682

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.11510
Policy Update Magnitude: 0.53364
Value Function Update Magnitude: 0.61220

Collected Steps per Second: 23,050.69868
Overall Steps per Second: 10,726.37364

Timestep Collection Time: 2.17000
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.66327

Cumulative Model Updates: 238,164
Cumulative Timesteps: 1,986,323,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.41202
Policy Entropy: 2.20063
Value Function Loss: 0.01698

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 22,763.83995
Overall Steps per Second: 10,748.08456

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.65460

Cumulative Model Updates: 238,170
Cumulative Timesteps: 1,986,373,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1986373974...
Checkpoint 1986373974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.07562
Policy Entropy: 2.18485
Value Function Loss: 0.01756

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.53855
Value Function Update Magnitude: 0.64273

Collected Steps per Second: 22,384.16056
Overall Steps per Second: 10,757.75898

Timestep Collection Time: 2.23471
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.64985

Cumulative Model Updates: 238,176
Cumulative Timesteps: 1,986,423,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.22714
Policy Entropy: 2.17250
Value Function Loss: 0.01842

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.53901
Value Function Update Magnitude: 0.63004

Collected Steps per Second: 23,307.77918
Overall Steps per Second: 10,851.13624

Timestep Collection Time: 2.14598
Timestep Consumption Time: 2.46349
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.60947

Cumulative Model Updates: 238,182
Cumulative Timesteps: 1,986,474,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1986474014...
Checkpoint 1986474014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16560
Policy Entropy: 2.18988
Value Function Loss: 0.01834

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.54362
Value Function Update Magnitude: 0.63226

Collected Steps per Second: 22,572.70338
Overall Steps per Second: 10,590.03162

Timestep Collection Time: 2.21613
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.72369

Cumulative Model Updates: 238,188
Cumulative Timesteps: 1,986,524,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.44096
Policy Entropy: 2.19271
Value Function Loss: 0.01915

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.64044

Collected Steps per Second: 22,529.56673
Overall Steps per Second: 10,678.83030

Timestep Collection Time: 2.21957
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.68272

Cumulative Model Updates: 238,194
Cumulative Timesteps: 1,986,574,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1986574044...
Checkpoint 1986574044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.27813
Policy Entropy: 2.21286
Value Function Loss: 0.01842

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.64882

Collected Steps per Second: 22,416.13976
Overall Steps per Second: 10,943.08227

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.33856
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.56910

Cumulative Model Updates: 238,200
Cumulative Timesteps: 1,986,624,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.98735
Policy Entropy: 2.21096
Value Function Loss: 0.01894

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.54668
Value Function Update Magnitude: 0.65872

Collected Steps per Second: 23,051.94196
Overall Steps per Second: 10,889.44854

Timestep Collection Time: 2.16936
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.59234

Cumulative Model Updates: 238,206
Cumulative Timesteps: 1,986,674,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1986674052...
Checkpoint 1986674052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.83430
Policy Entropy: 2.18818
Value Function Loss: 0.01830

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.65377

Collected Steps per Second: 22,791.17919
Overall Steps per Second: 10,571.73620

Timestep Collection Time: 2.19383
Timestep Consumption Time: 2.53576
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.72959

Cumulative Model Updates: 238,212
Cumulative Timesteps: 1,986,724,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.39999
Policy Entropy: 2.15858
Value Function Loss: 0.01846

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.64254

Collected Steps per Second: 23,031.33026
Overall Steps per Second: 10,897.21192

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.41737
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.58833

Cumulative Model Updates: 238,218
Cumulative Timesteps: 1,986,774,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1986774052...
Checkpoint 1986774052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.48582
Policy Entropy: 2.18017
Value Function Loss: 0.01751

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.63034

Collected Steps per Second: 22,795.26946
Overall Steps per Second: 10,940.58188

Timestep Collection Time: 2.19449
Timestep Consumption Time: 2.37784
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.57233

Cumulative Model Updates: 238,224
Cumulative Timesteps: 1,986,824,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.30916
Policy Entropy: 2.21861
Value Function Loss: 0.01728

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.53577
Value Function Update Magnitude: 0.64984

Collected Steps per Second: 23,295.31631
Overall Steps per Second: 10,776.38115

Timestep Collection Time: 2.14635
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.63978

Cumulative Model Updates: 238,230
Cumulative Timesteps: 1,986,874,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1986874076...
Checkpoint 1986874076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.93303
Policy Entropy: 2.23433
Value Function Loss: 0.01724

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.15968
Policy Update Magnitude: 0.51517
Value Function Update Magnitude: 0.65425

Collected Steps per Second: 22,828.24711
Overall Steps per Second: 10,869.11571

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.41069
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60166

Cumulative Model Updates: 238,236
Cumulative Timesteps: 1,986,924,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.34279
Policy Entropy: 2.20292
Value Function Loss: 0.01820

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.51813
Value Function Update Magnitude: 0.64890

Collected Steps per Second: 22,973.38648
Overall Steps per Second: 11,017.09934

Timestep Collection Time: 2.17748
Timestep Consumption Time: 2.36310
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.54058

Cumulative Model Updates: 238,242
Cumulative Timesteps: 1,986,974,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1986974116...
Checkpoint 1986974116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.46769
Policy Entropy: 2.16862
Value Function Loss: 0.01863

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.64825

Collected Steps per Second: 22,497.74645
Overall Steps per Second: 10,610.61911

Timestep Collection Time: 2.22316
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.71377

Cumulative Model Updates: 238,248
Cumulative Timesteps: 1,987,024,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.12766
Policy Entropy: 2.15491
Value Function Loss: 0.01878

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.66181

Collected Steps per Second: 22,401.43088
Overall Steps per Second: 10,593.61641

Timestep Collection Time: 2.23236
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.72058

Cumulative Model Updates: 238,254
Cumulative Timesteps: 1,987,074,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1987074140...
Checkpoint 1987074140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.96040
Policy Entropy: 2.17570
Value Function Loss: 0.01919

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.56971
Value Function Update Magnitude: 0.64724

Collected Steps per Second: 22,477.84028
Overall Steps per Second: 10,585.09623

Timestep Collection Time: 2.22477
Timestep Consumption Time: 2.49961
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.72438

Cumulative Model Updates: 238,260
Cumulative Timesteps: 1,987,124,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.50204
Policy Entropy: 2.19231
Value Function Loss: 0.01918

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.56587
Value Function Update Magnitude: 0.64135

Collected Steps per Second: 22,893.11461
Overall Steps per Second: 10,832.49251

Timestep Collection Time: 2.18476
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.61722

Cumulative Model Updates: 238,266
Cumulative Timesteps: 1,987,174,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1987174164...
Checkpoint 1987174164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.82500
Policy Entropy: 2.21724
Value Function Loss: 0.01818

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.62234

Collected Steps per Second: 22,708.76262
Overall Steps per Second: 10,660.79201

Timestep Collection Time: 2.20285
Timestep Consumption Time: 2.48948
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.69233

Cumulative Model Updates: 238,272
Cumulative Timesteps: 1,987,224,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.88187
Policy Entropy: 2.20538
Value Function Loss: 0.01815

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.54486
Value Function Update Magnitude: 0.59914

Collected Steps per Second: 23,357.00639
Overall Steps per Second: 10,923.20525

Timestep Collection Time: 2.14103
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.57814

Cumulative Model Updates: 238,278
Cumulative Timesteps: 1,987,274,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1987274196...
Checkpoint 1987274196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.14495
Policy Entropy: 2.19073
Value Function Loss: 0.01723

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 22,595.29478
Overall Steps per Second: 10,576.76494

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.72753

Cumulative Model Updates: 238,284
Cumulative Timesteps: 1,987,324,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.85735
Policy Entropy: 2.17552
Value Function Loss: 0.01701

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.53244
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 23,276.28327
Overall Steps per Second: 10,960.39058

Timestep Collection Time: 2.14820
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.56206

Cumulative Model Updates: 238,290
Cumulative Timesteps: 1,987,374,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1987374200...
Checkpoint 1987374200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.35334
Policy Entropy: 2.15240
Value Function Loss: 0.01774

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.62469

Collected Steps per Second: 22,517.25501
Overall Steps per Second: 10,603.31969

Timestep Collection Time: 2.22167
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71796

Cumulative Model Updates: 238,296
Cumulative Timesteps: 1,987,424,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.67265
Policy Entropy: 2.17560
Value Function Loss: 0.01790

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.61269

Collected Steps per Second: 23,134.75035
Overall Steps per Second: 10,879.37126

Timestep Collection Time: 2.16246
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59843

Cumulative Model Updates: 238,302
Cumulative Timesteps: 1,987,474,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1987474254...
Checkpoint 1987474254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.24076
Policy Entropy: 2.17832
Value Function Loss: 0.01840

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.61153

Collected Steps per Second: 22,567.26657
Overall Steps per Second: 10,685.60101

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.46478
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.68144

Cumulative Model Updates: 238,308
Cumulative Timesteps: 1,987,524,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.95772
Policy Entropy: 2.19816
Value Function Loss: 0.01776

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.54306
Value Function Update Magnitude: 0.62301

Collected Steps per Second: 22,241.44311
Overall Steps per Second: 10,870.98354

Timestep Collection Time: 2.24860
Timestep Consumption Time: 2.35191
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60050

Cumulative Model Updates: 238,314
Cumulative Timesteps: 1,987,574,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1987574290...
Checkpoint 1987574290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.94492
Policy Entropy: 2.17845
Value Function Loss: 0.01806

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.61855

Collected Steps per Second: 22,681.38476
Overall Steps per Second: 10,691.22230

Timestep Collection Time: 2.20542
Timestep Consumption Time: 2.47337
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.67879

Cumulative Model Updates: 238,320
Cumulative Timesteps: 1,987,624,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.17166
Policy Entropy: 2.18601
Value Function Loss: 0.01776

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.61995

Collected Steps per Second: 22,812.77379
Overall Steps per Second: 10,818.43652

Timestep Collection Time: 2.19298
Timestep Consumption Time: 2.43135
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.62433

Cumulative Model Updates: 238,326
Cumulative Timesteps: 1,987,674,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1987674340...
Checkpoint 1987674340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.34178
Policy Entropy: 2.20774
Value Function Loss: 0.01767

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.54212
Value Function Update Magnitude: 0.61881

Collected Steps per Second: 22,376.30327
Overall Steps per Second: 10,697.25542

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.67522

Cumulative Model Updates: 238,332
Cumulative Timesteps: 1,987,724,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.45097
Policy Entropy: 2.22487
Value Function Loss: 0.01789

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.60358

Collected Steps per Second: 23,019.56451
Overall Steps per Second: 10,959.05111

Timestep Collection Time: 2.17215
Timestep Consumption Time: 2.39047
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.56262

Cumulative Model Updates: 238,338
Cumulative Timesteps: 1,987,774,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1987774354...
Checkpoint 1987774354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.37474
Policy Entropy: 2.24533
Value Function Loss: 0.01795

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.60151

Collected Steps per Second: 22,906.48921
Overall Steps per Second: 10,666.87752

Timestep Collection Time: 2.18375
Timestep Consumption Time: 2.50572
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.68947

Cumulative Model Updates: 238,344
Cumulative Timesteps: 1,987,824,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.77879
Policy Entropy: 2.24841
Value Function Loss: 0.01642

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.53049
Value Function Update Magnitude: 0.60335

Collected Steps per Second: 22,858.46123
Overall Steps per Second: 10,822.44876

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.43333
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.62132

Cumulative Model Updates: 238,350
Cumulative Timesteps: 1,987,874,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1987874390...
Checkpoint 1987874390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.36012
Policy Entropy: 2.23661
Value Function Loss: 0.01721

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.53774
Value Function Update Magnitude: 0.60055

Collected Steps per Second: 22,585.87300
Overall Steps per Second: 10,639.99805

Timestep Collection Time: 2.21519
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.70226

Cumulative Model Updates: 238,356
Cumulative Timesteps: 1,987,924,422

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.15307
Policy Entropy: 2.23677
Value Function Loss: 0.01783

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 23,044.31473
Overall Steps per Second: 10,957.45607

Timestep Collection Time: 2.17103
Timestep Consumption Time: 2.39481
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.56584

Cumulative Model Updates: 238,362
Cumulative Timesteps: 1,987,974,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1987974452...
Checkpoint 1987974452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.68768
Policy Entropy: 2.23160
Value Function Loss: 0.01860

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.54900
Value Function Update Magnitude: 0.61758

Collected Steps per Second: 22,757.88149
Overall Steps per Second: 10,614.77515

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.51478
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.71305

Cumulative Model Updates: 238,368
Cumulative Timesteps: 1,988,024,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.83470
Policy Entropy: 2.23965
Value Function Loss: 0.01820

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.53194
Value Function Update Magnitude: 0.60911

Collected Steps per Second: 22,903.18729
Overall Steps per Second: 10,804.70636

Timestep Collection Time: 2.18432
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.63020

Cumulative Model Updates: 238,374
Cumulative Timesteps: 1,988,074,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1988074508...
Checkpoint 1988074508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.57901
Policy Entropy: 2.24423
Value Function Loss: 0.01755

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.53393
Value Function Update Magnitude: 0.58676

Collected Steps per Second: 22,481.72057
Overall Steps per Second: 10,739.63919

Timestep Collection Time: 2.22510
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.65788

Cumulative Model Updates: 238,380
Cumulative Timesteps: 1,988,124,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.32000
Policy Entropy: 2.24007
Value Function Loss: 0.01695

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.52892
Value Function Update Magnitude: 0.57243

Collected Steps per Second: 23,703.75931
Overall Steps per Second: 10,971.14987

Timestep Collection Time: 2.11021
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.55923

Cumulative Model Updates: 238,386
Cumulative Timesteps: 1,988,174,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1988174552...
Checkpoint 1988174552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.22607
Policy Entropy: 2.22280
Value Function Loss: 0.01637

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.51989
Value Function Update Magnitude: 0.56772

Collected Steps per Second: 22,722.01449
Overall Steps per Second: 10,599.65333

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.51804
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.71978

Cumulative Model Updates: 238,392
Cumulative Timesteps: 1,988,224,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.90485
Policy Entropy: 2.21618
Value Function Loss: 0.01609

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.53093
Value Function Update Magnitude: 0.55505

Collected Steps per Second: 23,439.84232
Overall Steps per Second: 10,814.72796

Timestep Collection Time: 2.13363
Timestep Consumption Time: 2.49080
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.62443

Cumulative Model Updates: 238,398
Cumulative Timesteps: 1,988,274,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1988274592...
Checkpoint 1988274592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.97800
Policy Entropy: 2.20350
Value Function Loss: 0.01620

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.52911
Value Function Update Magnitude: 0.55318

Collected Steps per Second: 23,006.81470
Overall Steps per Second: 10,718.70184

Timestep Collection Time: 2.17405
Timestep Consumption Time: 2.49237
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.66642

Cumulative Model Updates: 238,404
Cumulative Timesteps: 1,988,324,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.13235
Policy Entropy: 2.21053
Value Function Loss: 0.01713

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.53186
Value Function Update Magnitude: 0.55976

Collected Steps per Second: 23,133.99085
Overall Steps per Second: 10,974.71033

Timestep Collection Time: 2.16271
Timestep Consumption Time: 2.39614
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.55884

Cumulative Model Updates: 238,410
Cumulative Timesteps: 1,988,374,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1988374642...
Checkpoint 1988374642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.93834
Policy Entropy: 2.20326
Value Function Loss: 0.01717

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.53623
Value Function Update Magnitude: 0.57416

Collected Steps per Second: 22,822.47559
Overall Steps per Second: 10,685.55947

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.48958
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.68146

Cumulative Model Updates: 238,416
Cumulative Timesteps: 1,988,424,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.91060
Policy Entropy: 2.21481
Value Function Loss: 0.01727

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.57009

Collected Steps per Second: 23,115.52480
Overall Steps per Second: 10,850.54200

Timestep Collection Time: 2.16365
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.60936

Cumulative Model Updates: 238,422
Cumulative Timesteps: 1,988,474,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1988474680...
Checkpoint 1988474680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.53928
Policy Entropy: 2.21514
Value Function Loss: 0.01732

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.53224
Value Function Update Magnitude: 0.57235

Collected Steps per Second: 21,900.91439
Overall Steps per Second: 10,635.59734

Timestep Collection Time: 2.28301
Timestep Consumption Time: 2.41818
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.70119

Cumulative Model Updates: 238,428
Cumulative Timesteps: 1,988,524,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.66342
Policy Entropy: 2.24397
Value Function Loss: 0.01751

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.53415
Value Function Update Magnitude: 0.57236

Collected Steps per Second: 22,791.06867
Overall Steps per Second: 10,848.17330

Timestep Collection Time: 2.19411
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.60962

Cumulative Model Updates: 238,434
Cumulative Timesteps: 1,988,574,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1988574686...
Checkpoint 1988574686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.62913
Policy Entropy: 2.23450
Value Function Loss: 0.01762

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.59077

Collected Steps per Second: 22,414.98892
Overall Steps per Second: 10,764.09049

Timestep Collection Time: 2.23092
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.64563

Cumulative Model Updates: 238,440
Cumulative Timesteps: 1,988,624,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.42413
Policy Entropy: 2.23955
Value Function Loss: 0.01711

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.53475
Value Function Update Magnitude: 0.60269

Collected Steps per Second: 22,464.91318
Overall Steps per Second: 10,787.91920

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.40912
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.63481

Cumulative Model Updates: 238,446
Cumulative Timesteps: 1,988,674,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1988674692...
Checkpoint 1988674692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.20548
Policy Entropy: 2.21290
Value Function Loss: 0.01682

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.53068
Value Function Update Magnitude: 0.60371

Collected Steps per Second: 22,184.26969
Overall Steps per Second: 10,712.46801

Timestep Collection Time: 2.25457
Timestep Consumption Time: 2.41438
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.66895

Cumulative Model Updates: 238,452
Cumulative Timesteps: 1,988,724,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.23487
Policy Entropy: 2.22217
Value Function Loss: 0.01716

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.53958
Value Function Update Magnitude: 0.60537

Collected Steps per Second: 23,982.08634
Overall Steps per Second: 10,885.79665

Timestep Collection Time: 2.08489
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.59314

Cumulative Model Updates: 238,458
Cumulative Timesteps: 1,988,774,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1988774708...
Checkpoint 1988774708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.53965
Policy Entropy: 2.20232
Value Function Loss: 0.01702

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.54094
Value Function Update Magnitude: 0.62602

Collected Steps per Second: 22,837.72652
Overall Steps per Second: 10,637.63715

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.51244
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.70311

Cumulative Model Updates: 238,464
Cumulative Timesteps: 1,988,824,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.52650
Policy Entropy: 2.19744
Value Function Loss: 0.01731

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 22,557.13416
Overall Steps per Second: 10,542.45531

Timestep Collection Time: 2.21766
Timestep Consumption Time: 2.52735
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.74500

Cumulative Model Updates: 238,470
Cumulative Timesteps: 1,988,874,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1988874762...
Checkpoint 1988874762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.36183
Policy Entropy: 2.18111
Value Function Loss: 0.01782

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.61899

Collected Steps per Second: 22,551.41987
Overall Steps per Second: 10,934.60434

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.35614
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.57392

Cumulative Model Updates: 238,476
Cumulative Timesteps: 1,988,924,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.59596
Policy Entropy: 2.19427
Value Function Loss: 0.01802

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.63090

Collected Steps per Second: 23,241.17377
Overall Steps per Second: 10,916.39854

Timestep Collection Time: 2.15161
Timestep Consumption Time: 2.42920
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.58081

Cumulative Model Updates: 238,482
Cumulative Timesteps: 1,988,974,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1988974782...
Checkpoint 1988974782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.24579
Policy Entropy: 2.21305
Value Function Loss: 0.01729

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.53588
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 22,874.35797
Overall Steps per Second: 10,733.53516

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.47244
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.65830

Cumulative Model Updates: 238,488
Cumulative Timesteps: 1,989,024,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.38563
Policy Entropy: 2.25183
Value Function Loss: 0.01668

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 23,066.99661
Overall Steps per Second: 10,941.33853

Timestep Collection Time: 2.16864
Timestep Consumption Time: 2.40338
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.57202

Cumulative Model Updates: 238,494
Cumulative Timesteps: 1,989,074,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1989074806...
Checkpoint 1989074806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.40984
Policy Entropy: 2.27059
Value Function Loss: 0.01645

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.53027
Value Function Update Magnitude: 0.59410

Collected Steps per Second: 22,439.41237
Overall Steps per Second: 10,838.03659

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.38535
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.61375

Cumulative Model Updates: 238,500
Cumulative Timesteps: 1,989,124,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.28505
Policy Entropy: 2.26832
Value Function Loss: 0.01726

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.53406
Value Function Update Magnitude: 0.59682

Collected Steps per Second: 22,336.71336
Overall Steps per Second: 10,692.70839

Timestep Collection Time: 2.23918
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.67758

Cumulative Model Updates: 238,506
Cumulative Timesteps: 1,989,174,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1989174826...
Checkpoint 1989174826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.75661
Policy Entropy: 2.24541
Value Function Loss: 0.01751

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.61535

Collected Steps per Second: 22,607.37043
Overall Steps per Second: 10,616.90706

Timestep Collection Time: 2.21167
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70947

Cumulative Model Updates: 238,512
Cumulative Timesteps: 1,989,224,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.12704
Policy Entropy: 2.22178
Value Function Loss: 0.01732

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.54068
Value Function Update Magnitude: 0.61076

Collected Steps per Second: 23,220.22956
Overall Steps per Second: 10,923.10500

Timestep Collection Time: 2.15433
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.57965

Cumulative Model Updates: 238,518
Cumulative Timesteps: 1,989,274,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1989274850...
Checkpoint 1989274850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.04839
Policy Entropy: 2.21067
Value Function Loss: 0.01775

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.54603
Value Function Update Magnitude: 0.58334

Collected Steps per Second: 22,792.43242
Overall Steps per Second: 10,641.94972

Timestep Collection Time: 2.19503
Timestep Consumption Time: 2.50618
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.70121

Cumulative Model Updates: 238,524
Cumulative Timesteps: 1,989,324,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.16108
Policy Entropy: 2.20067
Value Function Loss: 0.01890

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.60876

Collected Steps per Second: 23,374.85664
Overall Steps per Second: 10,888.37329

Timestep Collection Time: 2.13939
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.59279

Cumulative Model Updates: 238,530
Cumulative Timesteps: 1,989,374,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1989374888...
Checkpoint 1989374888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.69886
Policy Entropy: 2.19824
Value Function Loss: 0.01921

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.55367
Value Function Update Magnitude: 0.63332

Collected Steps per Second: 22,652.04859
Overall Steps per Second: 10,680.92795

Timestep Collection Time: 2.20819
Timestep Consumption Time: 2.47492
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.68311

Cumulative Model Updates: 238,536
Cumulative Timesteps: 1,989,424,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.56782
Policy Entropy: 2.19471
Value Function Loss: 0.01939

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.55274
Value Function Update Magnitude: 0.62955

Collected Steps per Second: 23,309.73328
Overall Steps per Second: 10,921.00942

Timestep Collection Time: 2.14588
Timestep Consumption Time: 2.43428
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.58016

Cumulative Model Updates: 238,542
Cumulative Timesteps: 1,989,474,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1989474928...
Checkpoint 1989474928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.12897
Policy Entropy: 2.15744
Value Function Loss: 0.01959

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.61407

Collected Steps per Second: 22,776.89175
Overall Steps per Second: 10,662.35064

Timestep Collection Time: 2.19688
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.69296

Cumulative Model Updates: 238,548
Cumulative Timesteps: 1,989,524,966

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.36541
Policy Entropy: 2.14496
Value Function Loss: 0.01926

Mean KL Divergence: 0.03177
SB3 Clip Fraction: 0.17319
Policy Update Magnitude: 0.54485
Value Function Update Magnitude: 0.60915

Collected Steps per Second: 22,923.68177
Overall Steps per Second: 10,848.78409

Timestep Collection Time: 2.18228
Timestep Consumption Time: 2.42892
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.61121

Cumulative Model Updates: 238,554
Cumulative Timesteps: 1,989,574,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1989574992...
Checkpoint 1989574992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.31716
Policy Entropy: 2.13543
Value Function Loss: 0.01854

Mean KL Divergence: 0.02961
SB3 Clip Fraction: 0.16456
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.60763

Collected Steps per Second: 22,617.49414
Overall Steps per Second: 10,683.68718

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.68041

Cumulative Model Updates: 238,560
Cumulative Timesteps: 1,989,624,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.55282
Policy Entropy: 2.17419
Value Function Loss: 0.01779

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.55767
Value Function Update Magnitude: 0.59710

Collected Steps per Second: 23,005.67528
Overall Steps per Second: 10,865.29489

Timestep Collection Time: 2.17372
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.60254

Cumulative Model Updates: 238,566
Cumulative Timesteps: 1,989,675,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1989675004...
Checkpoint 1989675004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.35640
Policy Entropy: 2.18985
Value Function Loss: 0.01797

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.59456

Collected Steps per Second: 22,726.08477
Overall Steps per Second: 10,605.25011

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.51453
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.71465

Cumulative Model Updates: 238,572
Cumulative Timesteps: 1,989,725,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.14535
Policy Entropy: 2.21628
Value Function Loss: 0.01752

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.59101

Collected Steps per Second: 22,794.81684
Overall Steps per Second: 10,530.86599

Timestep Collection Time: 2.19392
Timestep Consumption Time: 2.55498
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.74890

Cumulative Model Updates: 238,578
Cumulative Timesteps: 1,989,775,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1989775014...
Checkpoint 1989775014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.65356
Policy Entropy: 2.21544
Value Function Loss: 0.01787

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.53027
Value Function Update Magnitude: 0.58246

Collected Steps per Second: 22,876.07034
Overall Steps per Second: 10,785.94300

Timestep Collection Time: 2.18639
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.63715

Cumulative Model Updates: 238,584
Cumulative Timesteps: 1,989,825,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.33594
Policy Entropy: 2.21041
Value Function Loss: 0.01703

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.53750
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 23,529.95314
Overall Steps per Second: 11,189.85595

Timestep Collection Time: 2.12529
Timestep Consumption Time: 2.34376
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.46905

Cumulative Model Updates: 238,590
Cumulative Timesteps: 1,989,875,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1989875038...
Checkpoint 1989875038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.80967
Policy Entropy: 2.22761
Value Function Loss: 0.01628

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 22,535.48032
Overall Steps per Second: 10,615.68106

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.49229
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.71190

Cumulative Model Updates: 238,596
Cumulative Timesteps: 1,989,925,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.11166
Policy Entropy: 2.23498
Value Function Loss: 0.01661

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.59284

Collected Steps per Second: 23,114.26634
Overall Steps per Second: 10,898.01386

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.58928

Cumulative Model Updates: 238,602
Cumulative Timesteps: 1,989,975,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1989975072...
Checkpoint 1989975072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.39513
Policy Entropy: 2.25800
Value Function Loss: 0.01778

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.53402
Value Function Update Magnitude: 0.60293

Collected Steps per Second: 22,278.09886
Overall Steps per Second: 10,720.47352

Timestep Collection Time: 2.24499
Timestep Consumption Time: 2.42029
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.66528

Cumulative Model Updates: 238,608
Cumulative Timesteps: 1,990,025,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.99914
Policy Entropy: 2.23544
Value Function Loss: 0.01843

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 22,740.93493
Overall Steps per Second: 10,888.40292

Timestep Collection Time: 2.20000
Timestep Consumption Time: 2.39480
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.59480

Cumulative Model Updates: 238,614
Cumulative Timesteps: 1,990,075,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1990075116...
Checkpoint 1990075116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.64948
Policy Entropy: 2.20666
Value Function Loss: 0.01765

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.62889

Collected Steps per Second: 22,165.60329
Overall Steps per Second: 10,605.26238

Timestep Collection Time: 2.25602
Timestep Consumption Time: 2.45919
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.71521

Cumulative Model Updates: 238,620
Cumulative Timesteps: 1,990,125,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.57946
Policy Entropy: 2.17130
Value Function Loss: 0.01725

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.53872
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 22,984.18468
Overall Steps per Second: 10,863.54852

Timestep Collection Time: 2.17645
Timestep Consumption Time: 2.42830
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.60476

Cumulative Model Updates: 238,626
Cumulative Timesteps: 1,990,175,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1990175146...
Checkpoint 1990175146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.80262
Policy Entropy: 2.16217
Value Function Loss: 0.01701

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.61670

Collected Steps per Second: 22,101.91070
Overall Steps per Second: 10,703.79243

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.41044
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.67404

Cumulative Model Updates: 238,632
Cumulative Timesteps: 1,990,225,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.75255
Policy Entropy: 2.18066
Value Function Loss: 0.01767

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.61872

Collected Steps per Second: 23,025.00375
Overall Steps per Second: 10,936.80708

Timestep Collection Time: 2.17294
Timestep Consumption Time: 2.40170
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.57464

Cumulative Model Updates: 238,638
Cumulative Timesteps: 1,990,275,208

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1990275208...
Checkpoint 1990275208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.67261
Policy Entropy: 2.20125
Value Function Loss: 0.01762

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.60606

Collected Steps per Second: 22,672.14419
Overall Steps per Second: 10,595.52614

Timestep Collection Time: 2.20650
Timestep Consumption Time: 2.51493
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.72143

Cumulative Model Updates: 238,644
Cumulative Timesteps: 1,990,325,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.72748
Policy Entropy: 2.21178
Value Function Loss: 0.01779

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.53789
Value Function Update Magnitude: 0.58804

Collected Steps per Second: 23,228.48003
Overall Steps per Second: 10,913.04485

Timestep Collection Time: 2.15287
Timestep Consumption Time: 2.42953
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.58241

Cumulative Model Updates: 238,650
Cumulative Timesteps: 1,990,375,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1990375242...
Checkpoint 1990375242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.45727
Policy Entropy: 2.21402
Value Function Loss: 0.01964

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.58275

Collected Steps per Second: 22,696.51645
Overall Steps per Second: 10,654.79518

Timestep Collection Time: 2.20325
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.69329

Cumulative Model Updates: 238,656
Cumulative Timesteps: 1,990,425,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.25193
Policy Entropy: 2.22327
Value Function Loss: 0.01836

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.54215
Value Function Update Magnitude: 0.58398

Collected Steps per Second: 24,086.70211
Overall Steps per Second: 10,913.59259

Timestep Collection Time: 2.07658
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.58309

Cumulative Model Updates: 238,662
Cumulative Timesteps: 1,990,475,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1990475266...
Checkpoint 1990475266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.70159
Policy Entropy: 2.21986
Value Function Loss: 0.01820

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.57857

Collected Steps per Second: 22,678.48641
Overall Steps per Second: 10,621.13598

Timestep Collection Time: 2.20535
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.70891

Cumulative Model Updates: 238,668
Cumulative Timesteps: 1,990,525,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.28659
Policy Entropy: 2.20150
Value Function Loss: 0.01792

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.56629

Collected Steps per Second: 22,879.25732
Overall Steps per Second: 10,899.71063

Timestep Collection Time: 2.18582
Timestep Consumption Time: 2.40237
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.58820

Cumulative Model Updates: 238,674
Cumulative Timesteps: 1,990,575,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1990575290...
Checkpoint 1990575290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.82389
Policy Entropy: 2.17735
Value Function Loss: 0.01843

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.58265

Collected Steps per Second: 22,182.89969
Overall Steps per Second: 10,683.24086

Timestep Collection Time: 2.25480
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.68191

Cumulative Model Updates: 238,680
Cumulative Timesteps: 1,990,625,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.67186
Policy Entropy: 2.17664
Value Function Loss: 0.01833

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.60150

Collected Steps per Second: 22,726.64006
Overall Steps per Second: 10,699.53850

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.47531
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.67740

Cumulative Model Updates: 238,686
Cumulative Timesteps: 1,990,675,354

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1990675354...
Checkpoint 1990675354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.90963
Policy Entropy: 2.16157
Value Function Loss: 0.01818

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.54232
Value Function Update Magnitude: 0.59872

Collected Steps per Second: 22,474.61699
Overall Steps per Second: 10,756.88174

Timestep Collection Time: 2.22571
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.65023

Cumulative Model Updates: 238,692
Cumulative Timesteps: 1,990,725,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.46755
Policy Entropy: 2.16253
Value Function Loss: 0.01742

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.60193

Collected Steps per Second: 23,328.88176
Overall Steps per Second: 10,973.04155

Timestep Collection Time: 2.14344
Timestep Consumption Time: 2.41355
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.55699

Cumulative Model Updates: 238,698
Cumulative Timesteps: 1,990,775,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1990775380...
Checkpoint 1990775380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.79130
Policy Entropy: 2.15875
Value Function Loss: 0.01710

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.53526
Value Function Update Magnitude: 0.59013

Collected Steps per Second: 22,943.01392
Overall Steps per Second: 11,050.50754

Timestep Collection Time: 2.18036
Timestep Consumption Time: 2.34649
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.52685

Cumulative Model Updates: 238,704
Cumulative Timesteps: 1,990,825,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.55238
Policy Entropy: 2.17952
Value Function Loss: 0.01670

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.52988
Value Function Update Magnitude: 0.57111

Collected Steps per Second: 23,264.54310
Overall Steps per Second: 10,937.90119

Timestep Collection Time: 2.14971
Timestep Consumption Time: 2.42265
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.57236

Cumulative Model Updates: 238,710
Cumulative Timesteps: 1,990,875,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1990875416...
Checkpoint 1990875416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.76633
Policy Entropy: 2.21315
Value Function Loss: 0.01680

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.53354
Value Function Update Magnitude: 0.56167

Collected Steps per Second: 22,611.50547
Overall Steps per Second: 10,678.91516

Timestep Collection Time: 2.21206
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.68381

Cumulative Model Updates: 238,716
Cumulative Timesteps: 1,990,925,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.07518
Policy Entropy: 2.20193
Value Function Loss: 0.01731

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.55478

Collected Steps per Second: 23,138.87941
Overall Steps per Second: 10,969.80981

Timestep Collection Time: 2.16104
Timestep Consumption Time: 2.39729
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.55833

Cumulative Model Updates: 238,722
Cumulative Timesteps: 1,990,975,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1990975438...
Checkpoint 1990975438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.88920
Policy Entropy: 2.20959
Value Function Loss: 0.01757

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.53132
Value Function Update Magnitude: 0.54547

Collected Steps per Second: 22,316.04706
Overall Steps per Second: 10,594.29753

Timestep Collection Time: 2.24188
Timestep Consumption Time: 2.48047
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.72235

Cumulative Model Updates: 238,728
Cumulative Timesteps: 1,991,025,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.83274
Policy Entropy: 2.18066
Value Function Loss: 0.01890

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.55822

Collected Steps per Second: 23,999.72315
Overall Steps per Second: 10,906.58709

Timestep Collection Time: 2.08344
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.58457

Cumulative Model Updates: 238,734
Cumulative Timesteps: 1,991,075,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1991075470...
Checkpoint 1991075470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.43904
Policy Entropy: 2.19217
Value Function Loss: 0.01920

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.54141
Value Function Update Magnitude: 0.58947

Collected Steps per Second: 22,278.43562
Overall Steps per Second: 10,641.86171

Timestep Collection Time: 2.24450
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.69880

Cumulative Model Updates: 238,740
Cumulative Timesteps: 1,991,125,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.88056
Policy Entropy: 2.19275
Value Function Loss: 0.01863

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.54127
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 23,021.81692
Overall Steps per Second: 10,867.44651

Timestep Collection Time: 2.17255
Timestep Consumption Time: 2.42982
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.60237

Cumulative Model Updates: 238,746
Cumulative Timesteps: 1,991,175,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1991175490...
Checkpoint 1991175490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.44774
Policy Entropy: 2.21583
Value Function Loss: 0.01830

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.59283

Collected Steps per Second: 22,885.32212
Overall Steps per Second: 10,857.09116

Timestep Collection Time: 2.18568
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.60713

Cumulative Model Updates: 238,752
Cumulative Timesteps: 1,991,225,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.40971
Policy Entropy: 2.21743
Value Function Loss: 0.01683

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.51228
Value Function Update Magnitude: 0.56948

Collected Steps per Second: 23,391.38067
Overall Steps per Second: 10,721.45454

Timestep Collection Time: 2.13788
Timestep Consumption Time: 2.52641
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.66429

Cumulative Model Updates: 238,758
Cumulative Timesteps: 1,991,275,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1991275518...
Checkpoint 1991275518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.40166
Policy Entropy: 2.21006
Value Function Loss: 0.01716

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.15704
Policy Update Magnitude: 0.50058
Value Function Update Magnitude: 0.54276

Collected Steps per Second: 22,587.95184
Overall Steps per Second: 10,655.37160

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.69491

Cumulative Model Updates: 238,764
Cumulative Timesteps: 1,991,325,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.06282
Policy Entropy: 2.18869
Value Function Loss: 0.01603

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.52167
Value Function Update Magnitude: 0.54629

Collected Steps per Second: 23,140.58165
Overall Steps per Second: 10,952.99268

Timestep Collection Time: 2.16200
Timestep Consumption Time: 2.40570
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.56770

Cumulative Model Updates: 238,770
Cumulative Timesteps: 1,991,375,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1991375574...
Checkpoint 1991375574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.84047
Policy Entropy: 2.19183
Value Function Loss: 0.01614

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.52869
Value Function Update Magnitude: 0.54407

Collected Steps per Second: 22,632.95947
Overall Steps per Second: 10,984.22973

Timestep Collection Time: 2.20934
Timestep Consumption Time: 2.34300
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.55234

Cumulative Model Updates: 238,776
Cumulative Timesteps: 1,991,425,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.71262
Policy Entropy: 2.17495
Value Function Loss: 0.01575

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.52084
Value Function Update Magnitude: 0.54787

Collected Steps per Second: 23,170.65909
Overall Steps per Second: 10,915.53028

Timestep Collection Time: 2.15790
Timestep Consumption Time: 2.42273
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.58063

Cumulative Model Updates: 238,782
Cumulative Timesteps: 1,991,475,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1991475578...
Checkpoint 1991475578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.87321
Policy Entropy: 2.18043
Value Function Loss: 0.01647

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.52707
Value Function Update Magnitude: 0.57208

Collected Steps per Second: 22,082.81652
Overall Steps per Second: 10,632.19931

Timestep Collection Time: 2.26429
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.70288

Cumulative Model Updates: 238,788
Cumulative Timesteps: 1,991,525,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.43573
Policy Entropy: 2.17859
Value Function Loss: 0.01782

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.60507

Collected Steps per Second: 22,581.67124
Overall Steps per Second: 10,696.96847

Timestep Collection Time: 2.21419
Timestep Consumption Time: 2.46004
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.67422

Cumulative Model Updates: 238,794
Cumulative Timesteps: 1,991,575,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1991575580...
Checkpoint 1991575580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.85533
Policy Entropy: 2.20084
Value Function Loss: 0.01901

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.63466

Collected Steps per Second: 22,456.22330
Overall Steps per Second: 10,935.48571

Timestep Collection Time: 2.22673
Timestep Consumption Time: 2.34590
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.57264

Cumulative Model Updates: 238,800
Cumulative Timesteps: 1,991,625,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.86211
Policy Entropy: 2.19834
Value Function Loss: 0.01790

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.54213
Value Function Update Magnitude: 0.64361

Collected Steps per Second: 23,267.05636
Overall Steps per Second: 10,921.92401

Timestep Collection Time: 2.14905
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.57813

Cumulative Model Updates: 238,806
Cumulative Timesteps: 1,991,675,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1991675586...
Checkpoint 1991675586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.15992
Policy Entropy: 2.19925
Value Function Loss: 0.01775

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.53382
Value Function Update Magnitude: 0.63110

Collected Steps per Second: 21,622.92466
Overall Steps per Second: 10,530.98473

Timestep Collection Time: 2.31310
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.74941

Cumulative Model Updates: 238,812
Cumulative Timesteps: 1,991,725,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.05645
Policy Entropy: 2.17321
Value Function Loss: 0.01804

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.54238
Value Function Update Magnitude: 0.62120

Collected Steps per Second: 22,826.79650
Overall Steps per Second: 10,996.60480

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.35702
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.54795

Cumulative Model Updates: 238,818
Cumulative Timesteps: 1,991,775,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1991775614...
Checkpoint 1991775614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.78870
Policy Entropy: 2.16759
Value Function Loss: 0.01841

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.63706

Collected Steps per Second: 22,734.46038
Overall Steps per Second: 10,660.79307

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.69046

Cumulative Model Updates: 238,824
Cumulative Timesteps: 1,991,825,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.96141
Policy Entropy: 2.15172
Value Function Loss: 0.01819

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.54420
Value Function Update Magnitude: 0.65040

Collected Steps per Second: 23,300.25150
Overall Steps per Second: 10,832.90111

Timestep Collection Time: 2.14641
Timestep Consumption Time: 2.47026
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61668

Cumulative Model Updates: 238,830
Cumulative Timesteps: 1,991,875,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1991875630...
Checkpoint 1991875630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.42301
Policy Entropy: 2.17530
Value Function Loss: 0.01781

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.55339
Value Function Update Magnitude: 0.63926

Collected Steps per Second: 22,309.45760
Overall Steps per Second: 10,776.43194

Timestep Collection Time: 2.24147
Timestep Consumption Time: 2.39884
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.64031

Cumulative Model Updates: 238,836
Cumulative Timesteps: 1,991,925,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.86969
Policy Entropy: 2.18572
Value Function Loss: 0.01745

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.54388
Value Function Update Magnitude: 0.64329

Collected Steps per Second: 23,235.61595
Overall Steps per Second: 10,925.76115

Timestep Collection Time: 2.15299
Timestep Consumption Time: 2.42573
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.57872

Cumulative Model Updates: 238,842
Cumulative Timesteps: 1,991,975,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1991975662...
Checkpoint 1991975662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.84531
Policy Entropy: 2.17547
Value Function Loss: 0.01774

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.64351

Collected Steps per Second: 22,647.54358
Overall Steps per Second: 10,615.25969

Timestep Collection Time: 2.20819
Timestep Consumption Time: 2.50296
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71114

Cumulative Model Updates: 238,848
Cumulative Timesteps: 1,992,025,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.68061
Policy Entropy: 2.19460
Value Function Loss: 0.01744

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.63866

Collected Steps per Second: 23,525.52223
Overall Steps per Second: 10,895.99830

Timestep Collection Time: 2.12637
Timestep Consumption Time: 2.46467
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.59104

Cumulative Model Updates: 238,854
Cumulative Timesteps: 1,992,075,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1992075696...
Checkpoint 1992075696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.04390
Policy Entropy: 2.19470
Value Function Loss: 0.01752

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 22,344.97964
Overall Steps per Second: 10,602.01742

Timestep Collection Time: 2.23773
Timestep Consumption Time: 2.47854
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.71627

Cumulative Model Updates: 238,860
Cumulative Timesteps: 1,992,125,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.77877
Policy Entropy: 2.25394
Value Function Loss: 0.01654

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.59600

Collected Steps per Second: 23,310.99126
Overall Steps per Second: 10,926.69363

Timestep Collection Time: 2.14568
Timestep Consumption Time: 2.43191
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.57760

Cumulative Model Updates: 238,866
Cumulative Timesteps: 1,992,175,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1992175716...
Checkpoint 1992175716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.21529
Policy Entropy: 2.22927
Value Function Loss: 0.01644

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.52703
Value Function Update Magnitude: 0.59397

Collected Steps per Second: 22,438.39098
Overall Steps per Second: 10,655.77406

Timestep Collection Time: 2.22922
Timestep Consumption Time: 2.46495
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.69417

Cumulative Model Updates: 238,872
Cumulative Timesteps: 1,992,225,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.77659
Policy Entropy: 2.26829
Value Function Loss: 0.01545

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.51665
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 22,831.05648
Overall Steps per Second: 10,880.23422

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.40645
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59733

Cumulative Model Updates: 238,878
Cumulative Timesteps: 1,992,275,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1992275756...
Checkpoint 1992275756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.97931
Policy Entropy: 2.22678
Value Function Loss: 0.01675

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.52291
Value Function Update Magnitude: 0.61336

Collected Steps per Second: 22,443.87069
Overall Steps per Second: 10,792.16949

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.40588
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.63429

Cumulative Model Updates: 238,884
Cumulative Timesteps: 1,992,325,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.29506
Policy Entropy: 2.20665
Value Function Loss: 0.01766

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.53388
Value Function Update Magnitude: 0.62306

Collected Steps per Second: 22,881.05553
Overall Steps per Second: 10,752.34321

Timestep Collection Time: 2.18548
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.65071

Cumulative Model Updates: 238,890
Cumulative Timesteps: 1,992,375,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1992375776...
Checkpoint 1992375776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.55015
Policy Entropy: 2.18353
Value Function Loss: 0.01841

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.53978
Value Function Update Magnitude: 0.61517

Collected Steps per Second: 22,713.91659
Overall Steps per Second: 10,649.13479

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.69691

Cumulative Model Updates: 238,896
Cumulative Timesteps: 1,992,425,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.82312
Policy Entropy: 2.15620
Value Function Loss: 0.01915

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.62005

Collected Steps per Second: 23,455.62361
Overall Steps per Second: 10,930.95902

Timestep Collection Time: 2.13288
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.57673

Cumulative Model Updates: 238,902
Cumulative Timesteps: 1,992,475,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1992475822...
Checkpoint 1992475822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.35987
Policy Entropy: 2.16096
Value Function Loss: 0.01871

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.54197
Value Function Update Magnitude: 0.63641

Collected Steps per Second: 22,629.82437
Overall Steps per Second: 11,000.63057

Timestep Collection Time: 2.20956
Timestep Consumption Time: 2.33581
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.54538

Cumulative Model Updates: 238,908
Cumulative Timesteps: 1,992,525,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.88293
Policy Entropy: 2.14984
Value Function Loss: 0.01799

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.15194
Policy Update Magnitude: 0.52597
Value Function Update Magnitude: 0.65969

Collected Steps per Second: 23,286.72047
Overall Steps per Second: 10,927.56885

Timestep Collection Time: 2.14766
Timestep Consumption Time: 2.42902
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.57668

Cumulative Model Updates: 238,914
Cumulative Timesteps: 1,992,575,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1992575836...
Checkpoint 1992575836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.19665
Policy Entropy: 2.17922
Value Function Loss: 0.01693

Mean KL Divergence: 0.02881
SB3 Clip Fraction: 0.16118
Policy Update Magnitude: 0.53192
Value Function Update Magnitude: 0.66299

Collected Steps per Second: 22,911.71716
Overall Steps per Second: 10,700.38702

Timestep Collection Time: 2.18342
Timestep Consumption Time: 2.49173
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.67516

Cumulative Model Updates: 238,920
Cumulative Timesteps: 1,992,625,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.74196
Policy Entropy: 2.19022
Value Function Loss: 0.01708

Mean KL Divergence: 0.02875
SB3 Clip Fraction: 0.16886
Policy Update Magnitude: 0.54339
Value Function Update Magnitude: 0.63571

Collected Steps per Second: 22,998.79604
Overall Steps per Second: 10,917.52849

Timestep Collection Time: 2.17524
Timestep Consumption Time: 2.40711
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.58236

Cumulative Model Updates: 238,926
Cumulative Timesteps: 1,992,675,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1992675890...
Checkpoint 1992675890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.40744
Policy Entropy: 2.18452
Value Function Loss: 0.01747

Mean KL Divergence: 0.02745
SB3 Clip Fraction: 0.16052
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.60270

Collected Steps per Second: 22,344.30571
Overall Steps per Second: 10,738.86916

Timestep Collection Time: 2.23789
Timestep Consumption Time: 2.41847
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.65636

Cumulative Model Updates: 238,932
Cumulative Timesteps: 1,992,725,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.01501
Policy Entropy: 2.20411
Value Function Loss: 0.01797

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.58618

Collected Steps per Second: 22,939.94173
Overall Steps per Second: 10,874.96748

Timestep Collection Time: 2.18065
Timestep Consumption Time: 2.41927
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.59992

Cumulative Model Updates: 238,938
Cumulative Timesteps: 1,992,775,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1992775918...
Checkpoint 1992775918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.56271
Policy Entropy: 2.21596
Value Function Loss: 0.01812

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.59649

Collected Steps per Second: 22,454.55816
Overall Steps per Second: 10,627.05714

Timestep Collection Time: 2.22725
Timestep Consumption Time: 2.47885
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.70610

Cumulative Model Updates: 238,944
Cumulative Timesteps: 1,992,825,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.42859
Policy Entropy: 2.20160
Value Function Loss: 0.01836

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 22,708.09801
Overall Steps per Second: 10,815.97999

Timestep Collection Time: 2.20247
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.62408

Cumulative Model Updates: 238,950
Cumulative Timesteps: 1,992,875,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1992875944...
Checkpoint 1992875944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.76546
Policy Entropy: 2.18244
Value Function Loss: 0.01781

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.54968
Value Function Update Magnitude: 0.62760

Collected Steps per Second: 23,381.57063
Overall Steps per Second: 10,701.65637

Timestep Collection Time: 2.14066
Timestep Consumption Time: 2.53637
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.67703

Cumulative Model Updates: 238,956
Cumulative Timesteps: 1,992,925,996

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.45144
Policy Entropy: 2.16729
Value Function Loss: 0.01832

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.55104
Value Function Update Magnitude: 0.63140

Collected Steps per Second: 22,891.43307
Overall Steps per Second: 10,830.82433

Timestep Collection Time: 2.18545
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.61904

Cumulative Model Updates: 238,962
Cumulative Timesteps: 1,992,976,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1992976024...
Checkpoint 1992976024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.50686
Policy Entropy: 2.21644
Value Function Loss: 0.01748

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.62574

Collected Steps per Second: 22,585.53422
Overall Steps per Second: 10,764.04161

Timestep Collection Time: 2.21416
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.64584

Cumulative Model Updates: 238,968
Cumulative Timesteps: 1,993,026,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.93868
Policy Entropy: 2.18402
Value Function Loss: 0.01756

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.61119

Collected Steps per Second: 23,214.54046
Overall Steps per Second: 10,875.11429

Timestep Collection Time: 2.15477
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.59968

Cumulative Model Updates: 238,974
Cumulative Timesteps: 1,993,076,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1993076054...
Checkpoint 1993076054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.74997
Policy Entropy: 2.18989
Value Function Loss: 0.01725

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.16123
Policy Update Magnitude: 0.52532
Value Function Update Magnitude: 0.60582

Collected Steps per Second: 23,414.39423
Overall Steps per Second: 11,002.37255

Timestep Collection Time: 2.13569
Timestep Consumption Time: 2.40932
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.54502

Cumulative Model Updates: 238,980
Cumulative Timesteps: 1,993,126,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.36166
Policy Entropy: 2.16681
Value Function Loss: 0.01713

Mean KL Divergence: 0.03001
SB3 Clip Fraction: 0.17499
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.62158

Collected Steps per Second: 23,141.96048
Overall Steps per Second: 10,897.14243

Timestep Collection Time: 2.16118
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.58964

Cumulative Model Updates: 238,986
Cumulative Timesteps: 1,993,176,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1993176074...
Checkpoint 1993176074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.11442
Policy Entropy: 2.19345
Value Function Loss: 0.01656

Mean KL Divergence: 0.02739
SB3 Clip Fraction: 0.16455
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.65516

Collected Steps per Second: 22,334.57437
Overall Steps per Second: 10,815.90724

Timestep Collection Time: 2.23931
Timestep Consumption Time: 2.38481
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.62412

Cumulative Model Updates: 238,992
Cumulative Timesteps: 1,993,226,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.51906
Policy Entropy: 2.18924
Value Function Loss: 0.01757

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.63716

Collected Steps per Second: 22,987.71876
Overall Steps per Second: 10,867.14806

Timestep Collection Time: 2.17621
Timestep Consumption Time: 2.42721
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.60342

Cumulative Model Updates: 238,998
Cumulative Timesteps: 1,993,276,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1993276114...
Checkpoint 1993276114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.12696
Policy Entropy: 2.18559
Value Function Loss: 0.01871

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.56855
Value Function Update Magnitude: 0.61259

Collected Steps per Second: 22,378.50947
Overall Steps per Second: 10,649.85872

Timestep Collection Time: 2.23563
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.69771

Cumulative Model Updates: 239,004
Cumulative Timesteps: 1,993,326,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.77788
Policy Entropy: 2.19018
Value Function Loss: 0.01867

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.60436

Collected Steps per Second: 23,219.00951
Overall Steps per Second: 10,913.45634

Timestep Collection Time: 2.15444
Timestep Consumption Time: 2.42926
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.58370

Cumulative Model Updates: 239,010
Cumulative Timesteps: 1,993,376,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1993376168...
Checkpoint 1993376168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.27606
Policy Entropy: 2.18161
Value Function Loss: 0.01743

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.54843
Value Function Update Magnitude: 0.59835

Collected Steps per Second: 22,878.99492
Overall Steps per Second: 10,680.29755

Timestep Collection Time: 2.18655
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.68395

Cumulative Model Updates: 239,016
Cumulative Timesteps: 1,993,426,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.61687
Policy Entropy: 2.18585
Value Function Loss: 0.01804

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 23,599.13804
Overall Steps per Second: 11,063.45167

Timestep Collection Time: 2.11881
Timestep Consumption Time: 2.40076
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.51957

Cumulative Model Updates: 239,022
Cumulative Timesteps: 1,993,476,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1993476196...
Checkpoint 1993476196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.26344
Policy Entropy: 2.17070
Value Function Loss: 0.01758

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 22,883.45536
Overall Steps per Second: 10,846.12621

Timestep Collection Time: 2.18595
Timestep Consumption Time: 2.42602
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61197

Cumulative Model Updates: 239,028
Cumulative Timesteps: 1,993,526,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.66231
Policy Entropy: 2.16904
Value Function Loss: 0.01786

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.54728
Value Function Update Magnitude: 0.60176

Collected Steps per Second: 23,193.18355
Overall Steps per Second: 10,883.64091

Timestep Collection Time: 2.15710
Timestep Consumption Time: 2.43971
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.59681

Cumulative Model Updates: 239,034
Cumulative Timesteps: 1,993,576,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1993576248...
Checkpoint 1993576248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.55249
Policy Entropy: 2.16478
Value Function Loss: 0.01753

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.54210
Value Function Update Magnitude: 0.58652

Collected Steps per Second: 22,866.49748
Overall Steps per Second: 10,923.40931

Timestep Collection Time: 2.18661
Timestep Consumption Time: 2.39072
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.57733

Cumulative Model Updates: 239,040
Cumulative Timesteps: 1,993,626,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.23541
Policy Entropy: 2.17751
Value Function Loss: 0.01815

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.59634

Collected Steps per Second: 23,310.66641
Overall Steps per Second: 10,772.16271

Timestep Collection Time: 2.14580
Timestep Consumption Time: 2.49765
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.64345

Cumulative Model Updates: 239,046
Cumulative Timesteps: 1,993,676,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1993676268...
Checkpoint 1993676268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.52326
Policy Entropy: 2.19749
Value Function Loss: 0.01795

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.61088

Collected Steps per Second: 22,444.14787
Overall Steps per Second: 10,598.99628

Timestep Collection Time: 2.22855
Timestep Consumption Time: 2.49057
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.71913

Cumulative Model Updates: 239,052
Cumulative Timesteps: 1,993,726,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.92301
Policy Entropy: 2.20446
Value Function Loss: 0.01795

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.63584

Collected Steps per Second: 22,813.30590
Overall Steps per Second: 10,898.75593

Timestep Collection Time: 2.19197
Timestep Consumption Time: 2.39626
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.58823

Cumulative Model Updates: 239,058
Cumulative Timesteps: 1,993,776,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1993776292...
Checkpoint 1993776292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.66444
Policy Entropy: 2.22179
Value Function Loss: 0.01704

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.52521
Value Function Update Magnitude: 0.62804

Collected Steps per Second: 22,573.50095
Overall Steps per Second: 10,961.19576

Timestep Collection Time: 2.21596
Timestep Consumption Time: 2.34759
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.56355

Cumulative Model Updates: 239,064
Cumulative Timesteps: 1,993,826,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.11591
Policy Entropy: 2.20813
Value Function Loss: 0.01739

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.53262
Value Function Update Magnitude: 0.60714

Collected Steps per Second: 23,321.61130
Overall Steps per Second: 10,794.43182

Timestep Collection Time: 2.14513
Timestep Consumption Time: 2.48948
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.63461

Cumulative Model Updates: 239,070
Cumulative Timesteps: 1,993,876,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1993876342...
Checkpoint 1993876342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.25225
Policy Entropy: 2.20923
Value Function Loss: 0.01687

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.61096

Collected Steps per Second: 22,884.38539
Overall Steps per Second: 10,801.11787

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.63396

Cumulative Model Updates: 239,076
Cumulative Timesteps: 1,993,926,394

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.33804
Policy Entropy: 2.21026
Value Function Loss: 0.01739

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.62261

Collected Steps per Second: 23,107.96758
Overall Steps per Second: 10,932.72592

Timestep Collection Time: 2.16419
Timestep Consumption Time: 2.41015
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.57434

Cumulative Model Updates: 239,082
Cumulative Timesteps: 1,993,976,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1993976404...
Checkpoint 1993976404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.74021
Policy Entropy: 2.21770
Value Function Loss: 0.01757

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,698.30515
Overall Steps per Second: 10,881.78976

Timestep Collection Time: 2.20395
Timestep Consumption Time: 2.39327
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.59722

Cumulative Model Updates: 239,088
Cumulative Timesteps: 1,994,026,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.82931
Policy Entropy: 2.22461
Value Function Loss: 0.01908

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.63512

Collected Steps per Second: 23,409.10335
Overall Steps per Second: 10,779.31225

Timestep Collection Time: 2.13686
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.64056

Cumulative Model Updates: 239,094
Cumulative Timesteps: 1,994,076,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1994076452...
Checkpoint 1994076452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.72158
Policy Entropy: 2.18330
Value Function Loss: 0.02018

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.64126

Collected Steps per Second: 22,699.57508
Overall Steps per Second: 10,648.01899

Timestep Collection Time: 2.20383
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.69815

Cumulative Model Updates: 239,100
Cumulative Timesteps: 1,994,126,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.53628
Policy Entropy: 2.18685
Value Function Loss: 0.02006

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.55415
Value Function Update Magnitude: 0.65695

Collected Steps per Second: 23,130.57922
Overall Steps per Second: 10,900.96920

Timestep Collection Time: 2.16199
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.58748

Cumulative Model Updates: 239,106
Cumulative Timesteps: 1,994,176,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1994176486...
Checkpoint 1994176486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.33374
Policy Entropy: 2.17538
Value Function Loss: 0.01895

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.66331

Collected Steps per Second: 22,860.40341
Overall Steps per Second: 10,707.54487

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.67110

Cumulative Model Updates: 239,112
Cumulative Timesteps: 1,994,226,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.11447
Policy Entropy: 2.18304
Value Function Loss: 0.01800

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.65736

Collected Steps per Second: 23,252.46478
Overall Steps per Second: 10,797.58838

Timestep Collection Time: 2.15048
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.63103

Cumulative Model Updates: 239,118
Cumulative Timesteps: 1,994,276,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1994276506...
Checkpoint 1994276506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.29064
Policy Entropy: 2.16774
Value Function Loss: 0.01699

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.64391

Collected Steps per Second: 22,186.85137
Overall Steps per Second: 10,626.42429

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.45255
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.70695

Cumulative Model Updates: 239,124
Cumulative Timesteps: 1,994,326,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.15227
Policy Entropy: 2.17860
Value Function Loss: 0.01729

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.53135
Value Function Update Magnitude: 0.61385

Collected Steps per Second: 23,371.05726
Overall Steps per Second: 10,947.12985

Timestep Collection Time: 2.14008
Timestep Consumption Time: 2.42879
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.56887

Cumulative Model Updates: 239,130
Cumulative Timesteps: 1,994,376,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1994376540...
Checkpoint 1994376540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.54421
Policy Entropy: 2.19743
Value Function Loss: 0.01683

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.52727
Value Function Update Magnitude: 0.58785

Collected Steps per Second: 22,924.86622
Overall Steps per Second: 10,622.52896

Timestep Collection Time: 2.18165
Timestep Consumption Time: 2.52665
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.70830

Cumulative Model Updates: 239,136
Cumulative Timesteps: 1,994,426,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.99544
Policy Entropy: 2.22749
Value Function Loss: 0.01726

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.52778
Value Function Update Magnitude: 0.56952

Collected Steps per Second: 23,569.88938
Overall Steps per Second: 10,837.66169

Timestep Collection Time: 2.12254
Timestep Consumption Time: 2.49359
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.61612

Cumulative Model Updates: 239,142
Cumulative Timesteps: 1,994,476,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1994476582...
Checkpoint 1994476582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.62651
Policy Entropy: 2.21195
Value Function Loss: 0.01799

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.52577
Value Function Update Magnitude: 0.57872

Collected Steps per Second: 22,577.56518
Overall Steps per Second: 10,674.24426

Timestep Collection Time: 2.21503
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.68511

Cumulative Model Updates: 239,148
Cumulative Timesteps: 1,994,526,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.65793
Policy Entropy: 2.22186
Value Function Loss: 0.01682

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.51927
Value Function Update Magnitude: 0.58032

Collected Steps per Second: 23,267.79441
Overall Steps per Second: 10,911.84113

Timestep Collection Time: 2.14924
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.58291

Cumulative Model Updates: 239,154
Cumulative Timesteps: 1,994,576,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1994576600...
Checkpoint 1994576600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.33184
Policy Entropy: 2.21453
Value Function Loss: 0.01591

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.51283
Value Function Update Magnitude: 0.55063

Collected Steps per Second: 22,641.34573
Overall Steps per Second: 10,634.29101

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.70177

Cumulative Model Updates: 239,160
Cumulative Timesteps: 1,994,626,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.59040
Policy Entropy: 2.23832
Value Function Loss: 0.01480

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.50787
Value Function Update Magnitude: 0.54182

Collected Steps per Second: 23,172.00088
Overall Steps per Second: 10,900.14752

Timestep Collection Time: 2.15821
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58801

Cumulative Model Updates: 239,166
Cumulative Timesteps: 1,994,676,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1994676610...
Checkpoint 1994676610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.12213
Policy Entropy: 2.22638
Value Function Loss: 0.01607

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.50994
Value Function Update Magnitude: 0.54197

Collected Steps per Second: 22,305.89074
Overall Steps per Second: 10,698.74428

Timestep Collection Time: 2.24308
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.67662

Cumulative Model Updates: 239,172
Cumulative Timesteps: 1,994,726,644

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.68041
Policy Entropy: 2.22750
Value Function Loss: 0.01607

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.51550
Value Function Update Magnitude: 0.55634

Collected Steps per Second: 23,004.62315
Overall Steps per Second: 10,887.17618

Timestep Collection Time: 2.17356
Timestep Consumption Time: 2.41918
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.59274

Cumulative Model Updates: 239,178
Cumulative Timesteps: 1,994,776,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1994776646...
Checkpoint 1994776646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.73318
Policy Entropy: 2.22005
Value Function Loss: 0.01573

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.51288
Value Function Update Magnitude: 0.58171

Collected Steps per Second: 22,615.08129
Overall Steps per Second: 10,625.56145

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.49552
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.70714

Cumulative Model Updates: 239,184
Cumulative Timesteps: 1,994,826,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.20417
Policy Entropy: 2.21991
Value Function Loss: 0.01528

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.51031
Value Function Update Magnitude: 0.58655

Collected Steps per Second: 22,887.82623
Overall Steps per Second: 10,849.33922

Timestep Collection Time: 2.18579
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61116

Cumulative Model Updates: 239,190
Cumulative Timesteps: 1,994,876,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1994876690...
Checkpoint 1994876690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.69364
Policy Entropy: 2.20504
Value Function Loss: 0.01673

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.60927

Collected Steps per Second: 22,065.10008
Overall Steps per Second: 10,672.20711

Timestep Collection Time: 2.26602
Timestep Consumption Time: 2.41904
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.68507

Cumulative Model Updates: 239,196
Cumulative Timesteps: 1,994,926,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.09381
Policy Entropy: 2.18894
Value Function Loss: 0.01712

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.53433
Value Function Update Magnitude: 0.61369

Collected Steps per Second: 24,361.07224
Overall Steps per Second: 10,960.30682

Timestep Collection Time: 2.05311
Timestep Consumption Time: 2.51026
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.56338

Cumulative Model Updates: 239,202
Cumulative Timesteps: 1,994,976,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1994976706...
Checkpoint 1994976706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.85163
Policy Entropy: 2.19154
Value Function Loss: 0.01730

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 22,782.26330
Overall Steps per Second: 10,658.19227

Timestep Collection Time: 2.19583
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.69367

Cumulative Model Updates: 239,208
Cumulative Timesteps: 1,995,026,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.86565
Policy Entropy: 2.22214
Value Function Loss: 0.01702

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.59668

Collected Steps per Second: 23,189.43641
Overall Steps per Second: 10,904.86883

Timestep Collection Time: 2.15659
Timestep Consumption Time: 2.42944
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.58602

Cumulative Model Updates: 239,214
Cumulative Timesteps: 1,995,076,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1995076742...
Checkpoint 1995076742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.84039
Policy Entropy: 2.24182
Value Function Loss: 0.01877

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.59083

Collected Steps per Second: 22,744.59272
Overall Steps per Second: 10,723.82724

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.46449
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.66307

Cumulative Model Updates: 239,220
Cumulative Timesteps: 1,995,126,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.52661
Policy Entropy: 2.23159
Value Function Loss: 0.01947

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.57744

Collected Steps per Second: 24,059.95736
Overall Steps per Second: 10,967.94109

Timestep Collection Time: 2.07856
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.55965

Cumulative Model Updates: 239,226
Cumulative Timesteps: 1,995,176,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1995176758...
Checkpoint 1995176758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.29201
Policy Entropy: 2.19204
Value Function Loss: 0.01944

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.55017
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 22,403.29605
Overall Steps per Second: 10,558.37502

Timestep Collection Time: 2.23297
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.73804

Cumulative Model Updates: 239,232
Cumulative Timesteps: 1,995,226,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.85606
Policy Entropy: 2.18285
Value Function Loss: 0.01823

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.60356

Collected Steps per Second: 23,033.52894
Overall Steps per Second: 10,907.96303

Timestep Collection Time: 2.17084
Timestep Consumption Time: 2.41316
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.58399

Cumulative Model Updates: 239,238
Cumulative Timesteps: 1,995,276,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1995276786...
Checkpoint 1995276786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.08298
Policy Entropy: 2.19263
Value Function Loss: 0.01682

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.52869
Value Function Update Magnitude: 0.62222

Collected Steps per Second: 22,062.40471
Overall Steps per Second: 10,553.81375

Timestep Collection Time: 2.26675
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.73857

Cumulative Model Updates: 239,244
Cumulative Timesteps: 1,995,326,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.54153
Policy Entropy: 2.19375
Value Function Loss: 0.01553

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.52196
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 23,197.56269
Overall Steps per Second: 10,905.63697

Timestep Collection Time: 2.15566
Timestep Consumption Time: 2.42968
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.58534

Cumulative Model Updates: 239,250
Cumulative Timesteps: 1,995,376,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1995376802...
Checkpoint 1995376802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.80702
Policy Entropy: 2.20014
Value Function Loss: 0.01541

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.51705
Value Function Update Magnitude: 0.58936

Collected Steps per Second: 22,651.92807
Overall Steps per Second: 10,642.18044

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.69885

Cumulative Model Updates: 239,256
Cumulative Timesteps: 1,995,426,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.67255
Policy Entropy: 2.18405
Value Function Loss: 0.01585

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.51680
Value Function Update Magnitude: 0.58984

Collected Steps per Second: 23,093.25964
Overall Steps per Second: 10,818.88463

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.45769
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.62395

Cumulative Model Updates: 239,262
Cumulative Timesteps: 1,995,476,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1995476834...
Checkpoint 1995476834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.95656
Policy Entropy: 2.20358
Value Function Loss: 0.01567

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.51727
Value Function Update Magnitude: 0.55722

Collected Steps per Second: 22,599.66663
Overall Steps per Second: 10,716.59935

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.45373
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.66659

Cumulative Model Updates: 239,268
Cumulative Timesteps: 1,995,526,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.10624
Policy Entropy: 2.21136
Value Function Loss: 0.01588

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.51807
Value Function Update Magnitude: 0.55248

Collected Steps per Second: 22,784.88739
Overall Steps per Second: 10,878.24293

Timestep Collection Time: 2.19523
Timestep Consumption Time: 2.40276
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.59799

Cumulative Model Updates: 239,274
Cumulative Timesteps: 1,995,576,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1995576862...
Checkpoint 1995576862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.97869
Policy Entropy: 2.21897
Value Function Loss: 0.01674

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.51808
Value Function Update Magnitude: 0.57166

Collected Steps per Second: 22,961.28715
Overall Steps per Second: 10,705.35187

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.67224

Cumulative Model Updates: 239,280
Cumulative Timesteps: 1,995,626,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.89988
Policy Entropy: 2.19459
Value Function Loss: 0.01933

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.59072

Collected Steps per Second: 23,280.86754
Overall Steps per Second: 10,947.54276

Timestep Collection Time: 2.14897
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.56998

Cumulative Model Updates: 239,286
Cumulative Timesteps: 1,995,676,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1995676910...
Checkpoint 1995676910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.85454
Policy Entropy: 2.17151
Value Function Loss: 0.01949

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.62038

Collected Steps per Second: 22,543.77897
Overall Steps per Second: 10,588.11097

Timestep Collection Time: 2.21862
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.72379

Cumulative Model Updates: 239,292
Cumulative Timesteps: 1,995,726,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.53196
Policy Entropy: 2.18944
Value Function Loss: 0.01904

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.62503

Collected Steps per Second: 22,831.84534
Overall Steps per Second: 10,942.78136

Timestep Collection Time: 2.19089
Timestep Consumption Time: 2.38035
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.57123

Cumulative Model Updates: 239,298
Cumulative Timesteps: 1,995,776,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1995776948...
Checkpoint 1995776948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.00147
Policy Entropy: 2.20112
Value Function Loss: 0.01758

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.60241

Collected Steps per Second: 22,719.89805
Overall Steps per Second: 10,642.59016

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.49809
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.69942

Cumulative Model Updates: 239,304
Cumulative Timesteps: 1,995,826,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.43623
Policy Entropy: 2.21074
Value Function Loss: 0.01782

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.58820

Collected Steps per Second: 22,924.01839
Overall Steps per Second: 10,829.90993

Timestep Collection Time: 2.18234
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.61943

Cumulative Model Updates: 239,310
Cumulative Timesteps: 1,995,876,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1995876990...
Checkpoint 1995876990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.43376
Policy Entropy: 2.21536
Value Function Loss: 0.01743

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.54262
Value Function Update Magnitude: 0.58856

Collected Steps per Second: 22,052.93480
Overall Steps per Second: 10,675.71415

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.41761
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.68615

Cumulative Model Updates: 239,316
Cumulative Timesteps: 1,995,927,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.06705
Policy Entropy: 2.22122
Value Function Loss: 0.01806

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.53810
Value Function Update Magnitude: 0.58355

Collected Steps per Second: 23,272.95663
Overall Steps per Second: 10,952.76769

Timestep Collection Time: 2.14859
Timestep Consumption Time: 2.41683
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.56542

Cumulative Model Updates: 239,322
Cumulative Timesteps: 1,995,977,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1995977022...
Checkpoint 1995977022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.56224
Policy Entropy: 2.22632
Value Function Loss: 0.01766

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.58564

Collected Steps per Second: 23,058.47723
Overall Steps per Second: 10,703.27534

Timestep Collection Time: 2.16909
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.67296

Cumulative Model Updates: 239,328
Cumulative Timesteps: 1,996,027,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.65590
Policy Entropy: 2.18530
Value Function Loss: 0.01786

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.60206

Collected Steps per Second: 23,201.59025
Overall Steps per Second: 10,823.84677

Timestep Collection Time: 2.15528
Timestep Consumption Time: 2.46470
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.61998

Cumulative Model Updates: 239,334
Cumulative Timesteps: 1,996,077,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1996077044...
Checkpoint 1996077044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.72721
Policy Entropy: 2.16198
Value Function Loss: 0.01807

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.60215

Collected Steps per Second: 22,603.97462
Overall Steps per Second: 10,640.99968

Timestep Collection Time: 2.21227
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.69937

Cumulative Model Updates: 239,340
Cumulative Timesteps: 1,996,127,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.08064
Policy Entropy: 2.13240
Value Function Loss: 0.01883

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.55501
Value Function Update Magnitude: 0.59596

Collected Steps per Second: 23,274.93588
Overall Steps per Second: 10,916.08805

Timestep Collection Time: 2.14961
Timestep Consumption Time: 2.43372
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.58333

Cumulative Model Updates: 239,346
Cumulative Timesteps: 1,996,177,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1996177082...
Checkpoint 1996177082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.74643
Policy Entropy: 2.14640
Value Function Loss: 0.01837

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.55177
Value Function Update Magnitude: 0.60697

Collected Steps per Second: 22,596.37018
Overall Steps per Second: 10,648.79280

Timestep Collection Time: 2.21390
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.69781

Cumulative Model Updates: 239,352
Cumulative Timesteps: 1,996,227,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.51882
Policy Entropy: 2.15020
Value Function Loss: 0.01902

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.53792
Value Function Update Magnitude: 0.64062

Collected Steps per Second: 23,326.50606
Overall Steps per Second: 10,916.24147

Timestep Collection Time: 2.14366
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.58070

Cumulative Model Updates: 239,358
Cumulative Timesteps: 1,996,277,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1996277112...
Checkpoint 1996277112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.81417
Policy Entropy: 2.20091
Value Function Loss: 0.01816

Mean KL Divergence: 0.03270
SB3 Clip Fraction: 0.18021
Policy Update Magnitude: 0.50946
Value Function Update Magnitude: 0.67087

Collected Steps per Second: 22,423.70089
Overall Steps per Second: 10,645.09877

Timestep Collection Time: 2.23059
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69869

Cumulative Model Updates: 239,364
Cumulative Timesteps: 1,996,327,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.71455
Policy Entropy: 2.20349
Value Function Loss: 0.01764

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.15576
Policy Update Magnitude: 0.53330
Value Function Update Magnitude: 0.65997

Collected Steps per Second: 22,807.64624
Overall Steps per Second: 10,924.75404

Timestep Collection Time: 2.19277
Timestep Consumption Time: 2.38509
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.57786

Cumulative Model Updates: 239,370
Cumulative Timesteps: 1,996,377,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1996377142...
Checkpoint 1996377142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.87904
Policy Entropy: 2.23903
Value Function Loss: 0.01696

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.60422

Collected Steps per Second: 22,491.84164
Overall Steps per Second: 10,627.26653

Timestep Collection Time: 2.22312
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.70507

Cumulative Model Updates: 239,376
Cumulative Timesteps: 1,996,427,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.00762
Policy Entropy: 2.25026
Value Function Loss: 0.01722

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.58386

Collected Steps per Second: 23,073.72488
Overall Steps per Second: 10,849.78497

Timestep Collection Time: 2.16853
Timestep Consumption Time: 2.44318
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61170

Cumulative Model Updates: 239,382
Cumulative Timesteps: 1,996,477,180

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1996477180...
Checkpoint 1996477180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.53899
Policy Entropy: 2.25794
Value Function Loss: 0.01697

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.60228

Collected Steps per Second: 22,709.96773
Overall Steps per Second: 10,697.56099

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.47229
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.67396

Cumulative Model Updates: 239,388
Cumulative Timesteps: 1,996,527,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.38196
Policy Entropy: 2.27651
Value Function Loss: 0.01635

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.53382
Value Function Update Magnitude: 0.60048

Collected Steps per Second: 23,090.85230
Overall Steps per Second: 10,958.98887

Timestep Collection Time: 2.16623
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.56429

Cumulative Model Updates: 239,394
Cumulative Timesteps: 1,996,577,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1996577200...
Checkpoint 1996577200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.52853
Policy Entropy: 2.28103
Value Function Loss: 0.01580

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.51820
Value Function Update Magnitude: 0.58821

Collected Steps per Second: 23,681.40026
Overall Steps per Second: 11,007.73811

Timestep Collection Time: 2.11161
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.54280

Cumulative Model Updates: 239,400
Cumulative Timesteps: 1,996,627,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.96764
Policy Entropy: 2.29271
Value Function Loss: 0.01583

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.51552
Value Function Update Magnitude: 0.56621

Collected Steps per Second: 23,296.96398
Overall Steps per Second: 10,935.33579

Timestep Collection Time: 2.14620
Timestep Consumption Time: 2.42613
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.57233

Cumulative Model Updates: 239,406
Cumulative Timesteps: 1,996,677,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1996677206...
Checkpoint 1996677206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.04797
Policy Entropy: 2.25354
Value Function Loss: 0.01698

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.51608
Value Function Update Magnitude: 0.57719

Collected Steps per Second: 22,488.95485
Overall Steps per Second: 10,670.48201

Timestep Collection Time: 2.22376
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.68676

Cumulative Model Updates: 239,412
Cumulative Timesteps: 1,996,727,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.44246
Policy Entropy: 2.23414
Value Function Loss: 0.01728

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.52726
Value Function Update Magnitude: 0.59682

Collected Steps per Second: 22,959.18086
Overall Steps per Second: 10,955.27309

Timestep Collection Time: 2.17821
Timestep Consumption Time: 2.38671
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.56493

Cumulative Model Updates: 239,418
Cumulative Timesteps: 1,996,777,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1996777226...
Checkpoint 1996777226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.02809
Policy Entropy: 2.22910
Value Function Loss: 0.01567

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.61568

Collected Steps per Second: 22,473.42689
Overall Steps per Second: 10,933.99062

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.34852
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.57381

Cumulative Model Updates: 239,424
Cumulative Timesteps: 1,996,827,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.86457
Policy Entropy: 2.23846
Value Function Loss: 0.01539

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.61464

Collected Steps per Second: 22,772.81231
Overall Steps per Second: 10,699.62540

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.47835
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.67474

Cumulative Model Updates: 239,430
Cumulative Timesteps: 1,996,877,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1996877254...
Checkpoint 1996877254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.00106
Policy Entropy: 2.23197
Value Function Loss: 0.01579

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.52190
Value Function Update Magnitude: 0.61457

Collected Steps per Second: 22,199.94169
Overall Steps per Second: 10,527.96789

Timestep Collection Time: 2.25289
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.75058

Cumulative Model Updates: 239,436
Cumulative Timesteps: 1,996,927,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.92936
Policy Entropy: 2.24397
Value Function Loss: 0.01630

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.51293
Value Function Update Magnitude: 0.60898

Collected Steps per Second: 23,108.62588
Overall Steps per Second: 10,897.81613

Timestep Collection Time: 2.16404
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.58881

Cumulative Model Updates: 239,442
Cumulative Timesteps: 1,996,977,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1996977276...
Checkpoint 1996977276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.72705
Policy Entropy: 2.25899
Value Function Loss: 0.01692

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.51901
Value Function Update Magnitude: 0.59665

Collected Steps per Second: 22,880.69391
Overall Steps per Second: 10,998.34994

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.36174
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.54777

Cumulative Model Updates: 239,448
Cumulative Timesteps: 1,997,027,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.23034
Policy Entropy: 2.24906
Value Function Loss: 0.01609

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.52197
Value Function Update Magnitude: 0.59939

Collected Steps per Second: 22,703.71054
Overall Steps per Second: 10,652.99812

Timestep Collection Time: 2.20316
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69539

Cumulative Model Updates: 239,454
Cumulative Timesteps: 1,997,077,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1997077314...
Checkpoint 1997077314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.05534
Policy Entropy: 2.24220
Value Function Loss: 0.01640

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.52980
Value Function Update Magnitude: 0.59016

Collected Steps per Second: 22,943.00676
Overall Steps per Second: 10,852.11333

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.60813

Cumulative Model Updates: 239,460
Cumulative Timesteps: 1,997,127,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.10392
Policy Entropy: 2.26242
Value Function Loss: 0.01595

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.52040
Value Function Update Magnitude: 0.58657

Collected Steps per Second: 23,168.88005
Overall Steps per Second: 10,946.11597

Timestep Collection Time: 2.15884
Timestep Consumption Time: 2.41063
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.56947

Cumulative Model Updates: 239,466
Cumulative Timesteps: 1,997,177,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1997177340...
Checkpoint 1997177340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.20419
Policy Entropy: 2.27583
Value Function Loss: 0.01581

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.51338
Value Function Update Magnitude: 0.59470

Collected Steps per Second: 22,783.40187
Overall Steps per Second: 10,876.95617

Timestep Collection Time: 2.19555
Timestep Consumption Time: 2.40335
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.59890

Cumulative Model Updates: 239,472
Cumulative Timesteps: 1,997,227,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.95444
Policy Entropy: 2.27849
Value Function Loss: 0.01661

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.52160
Value Function Update Magnitude: 0.59182

Collected Steps per Second: 23,173.01861
Overall Steps per Second: 10,746.71395

Timestep Collection Time: 2.15794
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.65314

Cumulative Model Updates: 239,478
Cumulative Timesteps: 1,997,277,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1997277368...
Checkpoint 1997277368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.24019
Policy Entropy: 2.26476
Value Function Loss: 0.01740

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.52330
Value Function Update Magnitude: 0.59976

Collected Steps per Second: 22,170.82476
Overall Steps per Second: 10,637.51312

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.70129

Cumulative Model Updates: 239,484
Cumulative Timesteps: 1,997,327,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.70247
Policy Entropy: 2.24209
Value Function Loss: 0.01837

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.52709
Value Function Update Magnitude: 0.60673

Collected Steps per Second: 22,868.47663
Overall Steps per Second: 10,866.12998

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60256

Cumulative Model Updates: 239,490
Cumulative Timesteps: 1,997,377,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1997377390...
Checkpoint 1997377390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.39275
Policy Entropy: 2.23526
Value Function Loss: 0.01871

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.52900
Value Function Update Magnitude: 0.59795

Collected Steps per Second: 23,656.36267
Overall Steps per Second: 10,777.46050

Timestep Collection Time: 2.11461
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.64154

Cumulative Model Updates: 239,496
Cumulative Timesteps: 1,997,427,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.83992
Policy Entropy: 2.23208
Value Function Loss: 0.01745

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.52211
Value Function Update Magnitude: 0.58772

Collected Steps per Second: 23,491.49509
Overall Steps per Second: 10,855.00696

Timestep Collection Time: 2.12894
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.60727

Cumulative Model Updates: 239,502
Cumulative Timesteps: 1,997,477,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1997477426...
Checkpoint 1997477426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.95044
Policy Entropy: 2.24664
Value Function Loss: 0.01707

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.52537
Value Function Update Magnitude: 0.56605

Collected Steps per Second: 21,408.78794
Overall Steps per Second: 10,359.72868

Timestep Collection Time: 2.33680
Timestep Consumption Time: 2.49229
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.82908

Cumulative Model Updates: 239,508
Cumulative Timesteps: 1,997,527,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.89906
Policy Entropy: 2.27144
Value Function Loss: 0.01667

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.53094
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 22,874.55716
Overall Steps per Second: 10,770.98725

Timestep Collection Time: 2.18697
Timestep Consumption Time: 2.45754
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.64451

Cumulative Model Updates: 239,514
Cumulative Timesteps: 1,997,577,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1997577480...
Checkpoint 1997577480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.18310
Policy Entropy: 2.27105
Value Function Loss: 0.01771

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.59653

Collected Steps per Second: 22,059.05988
Overall Steps per Second: 10,646.54433

Timestep Collection Time: 2.26791
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.69899

Cumulative Model Updates: 239,520
Cumulative Timesteps: 1,997,627,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.46480
Policy Entropy: 2.27746
Value Function Loss: 0.01709

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.53635
Value Function Update Magnitude: 0.60356

Collected Steps per Second: 23,351.02086
Overall Steps per Second: 10,854.68305

Timestep Collection Time: 2.14243
Timestep Consumption Time: 2.46645
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.60889

Cumulative Model Updates: 239,526
Cumulative Timesteps: 1,997,677,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1997677536...
Checkpoint 1997677536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.22980
Policy Entropy: 2.23867
Value Function Loss: 0.01792

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.53225
Value Function Update Magnitude: 0.59991

Collected Steps per Second: 22,572.18762
Overall Steps per Second: 10,664.48293

Timestep Collection Time: 2.21547
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.68921

Cumulative Model Updates: 239,532
Cumulative Timesteps: 1,997,727,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.82030
Policy Entropy: 2.23626
Value Function Loss: 0.01719

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.60490

Collected Steps per Second: 23,018.76669
Overall Steps per Second: 10,957.35334

Timestep Collection Time: 2.17275
Timestep Consumption Time: 2.39167
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.56442

Cumulative Model Updates: 239,538
Cumulative Timesteps: 1,997,777,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1997777558...
Checkpoint 1997777558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.84281
Policy Entropy: 2.23609
Value Function Loss: 0.01700

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.53715
Value Function Update Magnitude: 0.60963

Collected Steps per Second: 23,046.45872
Overall Steps per Second: 10,785.09087

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.63714

Cumulative Model Updates: 239,544
Cumulative Timesteps: 1,997,827,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.98533
Policy Entropy: 2.26001
Value Function Loss: 0.01608

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.53280
Value Function Update Magnitude: 0.61736

Collected Steps per Second: 23,461.81699
Overall Steps per Second: 10,803.64042

Timestep Collection Time: 2.13180
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.62955

Cumulative Model Updates: 239,550
Cumulative Timesteps: 1,997,877,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1997877586...
Checkpoint 1997877586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.16969
Policy Entropy: 2.25337
Value Function Loss: 0.01574

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.53028
Value Function Update Magnitude: 0.61734

Collected Steps per Second: 22,734.28890
Overall Steps per Second: 10,725.97857

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.46314
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.66326

Cumulative Model Updates: 239,556
Cumulative Timesteps: 1,997,927,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.75730
Policy Entropy: 2.24380
Value Function Loss: 0.01653

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.53275
Value Function Update Magnitude: 0.61839

Collected Steps per Second: 23,344.75797
Overall Steps per Second: 11,147.97427

Timestep Collection Time: 2.14198
Timestep Consumption Time: 2.34350
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.48548

Cumulative Model Updates: 239,562
Cumulative Timesteps: 1,997,977,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1997977608...
Checkpoint 1997977608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.65776
Policy Entropy: 2.21710
Value Function Loss: 0.01710

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.62287

Collected Steps per Second: 22,508.01832
Overall Steps per Second: 10,735.50649

Timestep Collection Time: 2.22179
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.65819

Cumulative Model Updates: 239,568
Cumulative Timesteps: 1,998,027,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.94231
Policy Entropy: 2.19416
Value Function Loss: 0.01821

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.63053

Collected Steps per Second: 22,926.31192
Overall Steps per Second: 10,835.60523

Timestep Collection Time: 2.18169
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.61608

Cumulative Model Updates: 239,574
Cumulative Timesteps: 1,998,077,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1998077634...
Checkpoint 1998077634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.51710
Policy Entropy: 2.22133
Value Function Loss: 0.01694

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.62857

Collected Steps per Second: 22,044.86636
Overall Steps per Second: 10,664.30285

Timestep Collection Time: 2.26828
Timestep Consumption Time: 2.42063
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.68891

Cumulative Model Updates: 239,580
Cumulative Timesteps: 1,998,127,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.24713
Policy Entropy: 2.20525
Value Function Loss: 0.01716

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.62581

Collected Steps per Second: 22,973.85904
Overall Steps per Second: 10,970.17225

Timestep Collection Time: 2.17726
Timestep Consumption Time: 2.38238
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.55964

Cumulative Model Updates: 239,586
Cumulative Timesteps: 1,998,177,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1998177658...
Checkpoint 1998177658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.50237
Policy Entropy: 2.23460
Value Function Loss: 0.01632

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.54580
Value Function Update Magnitude: 0.60682

Collected Steps per Second: 23,063.13944
Overall Steps per Second: 10,746.28079

Timestep Collection Time: 2.16857
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.65408

Cumulative Model Updates: 239,592
Cumulative Timesteps: 1,998,227,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.94835
Policy Entropy: 2.20445
Value Function Loss: 0.01732

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.59647

Collected Steps per Second: 23,609.36792
Overall Steps per Second: 10,813.98163

Timestep Collection Time: 2.11840
Timestep Consumption Time: 2.50654
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.62494

Cumulative Model Updates: 239,598
Cumulative Timesteps: 1,998,277,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1998277686...
Checkpoint 1998277686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.19392
Policy Entropy: 2.22266
Value Function Loss: 0.01809

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.60161

Collected Steps per Second: 22,400.44048
Overall Steps per Second: 10,635.47494

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.70200

Cumulative Model Updates: 239,604
Cumulative Timesteps: 1,998,327,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.98301
Policy Entropy: 2.21772
Value Function Loss: 0.01803

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.61541

Collected Steps per Second: 23,518.36643
Overall Steps per Second: 11,019.26311

Timestep Collection Time: 2.12642
Timestep Consumption Time: 2.41199
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.53842

Cumulative Model Updates: 239,610
Cumulative Timesteps: 1,998,377,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1998377704...
Checkpoint 1998377704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.40994
Policy Entropy: 2.22752
Value Function Loss: 0.01853

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.61097

Collected Steps per Second: 22,925.30672
Overall Steps per Second: 10,869.00710

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.42021
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.60208

Cumulative Model Updates: 239,616
Cumulative Timesteps: 1,998,427,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.83555
Policy Entropy: 2.23211
Value Function Loss: 0.01891

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.60631

Collected Steps per Second: 22,933.60234
Overall Steps per Second: 10,752.23799

Timestep Collection Time: 2.18143
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.65280

Cumulative Model Updates: 239,622
Cumulative Timesteps: 1,998,477,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1998477752...
Checkpoint 1998477752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.97832
Policy Entropy: 2.22284
Value Function Loss: 0.01931

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.61381

Collected Steps per Second: 22,168.46848
Overall Steps per Second: 10,608.94374

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.71546

Cumulative Model Updates: 239,628
Cumulative Timesteps: 1,998,527,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.22144
Policy Entropy: 2.23569
Value Function Loss: 0.01882

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.62654

Collected Steps per Second: 23,162.80913
Overall Steps per Second: 11,005.63718

Timestep Collection Time: 2.15993
Timestep Consumption Time: 2.38592
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.54585

Cumulative Model Updates: 239,634
Cumulative Timesteps: 1,998,577,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1998577808...
Checkpoint 1998577808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.78349
Policy Entropy: 2.22677
Value Function Loss: 0.01697

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.64948

Collected Steps per Second: 22,390.61049
Overall Steps per Second: 10,742.35245

Timestep Collection Time: 2.23344
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.65522

Cumulative Model Updates: 239,640
Cumulative Timesteps: 1,998,627,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.70880
Policy Entropy: 2.22357
Value Function Loss: 0.01672

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.53973
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 22,953.81806
Overall Steps per Second: 10,702.70481

Timestep Collection Time: 2.17898
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.67321

Cumulative Model Updates: 239,646
Cumulative Timesteps: 1,998,677,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1998677832...
Checkpoint 1998677832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.59588
Policy Entropy: 2.23733
Value Function Loss: 0.01668

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.61378

Collected Steps per Second: 22,868.78395
Overall Steps per Second: 10,660.53832

Timestep Collection Time: 2.18674
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.69095

Cumulative Model Updates: 239,652
Cumulative Timesteps: 1,998,727,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.28922
Policy Entropy: 2.22858
Value Function Loss: 0.01815

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.64214

Collected Steps per Second: 23,343.87276
Overall Steps per Second: 11,106.09867

Timestep Collection Time: 2.14215
Timestep Consumption Time: 2.36042
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.50257

Cumulative Model Updates: 239,658
Cumulative Timesteps: 1,998,777,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1998777846...
Checkpoint 1998777846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.15243
Policy Entropy: 2.23391
Value Function Loss: 0.01841

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.54990
Value Function Update Magnitude: 0.65199

Collected Steps per Second: 22,938.82026
Overall Steps per Second: 10,735.93889

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.47883
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.65968

Cumulative Model Updates: 239,664
Cumulative Timesteps: 1,998,827,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.30893
Policy Entropy: 2.18936
Value Function Loss: 0.01887

Mean KL Divergence: 0.03181
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.65815

Collected Steps per Second: 23,232.38030
Overall Steps per Second: 10,905.33660

Timestep Collection Time: 2.15234
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58528

Cumulative Model Updates: 239,670
Cumulative Timesteps: 1,998,877,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1998877876...
Checkpoint 1998877876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.39728
Policy Entropy: 2.19631
Value Function Loss: 0.01838

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.56117
Value Function Update Magnitude: 0.66008

Collected Steps per Second: 22,498.41904
Overall Steps per Second: 10,607.23359

Timestep Collection Time: 2.22380
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.71678

Cumulative Model Updates: 239,676
Cumulative Timesteps: 1,998,927,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.90280
Policy Entropy: 2.20345
Value Function Loss: 0.01921

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 23,091.37689
Overall Steps per Second: 10,958.62177

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.39836
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.56463

Cumulative Model Updates: 239,682
Cumulative Timesteps: 1,998,977,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1998977930...
Checkpoint 1998977930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.09710
Policy Entropy: 2.19448
Value Function Loss: 0.01879

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.55803
Value Function Update Magnitude: 0.65062

Collected Steps per Second: 22,283.38648
Overall Steps per Second: 10,635.51192

Timestep Collection Time: 2.24481
Timestep Consumption Time: 2.45849
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.70330

Cumulative Model Updates: 239,688
Cumulative Timesteps: 1,999,027,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.00327
Policy Entropy: 2.18716
Value Function Loss: 0.01820

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.55191
Value Function Update Magnitude: 0.64686

Collected Steps per Second: 22,923.13198
Overall Steps per Second: 10,830.33007

Timestep Collection Time: 2.18190
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61814

Cumulative Model Updates: 239,694
Cumulative Timesteps: 1,999,077,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1999077968...
Checkpoint 1999077968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.84212
Policy Entropy: 2.18795
Value Function Loss: 0.01712

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.53172
Value Function Update Magnitude: 0.62891

Collected Steps per Second: 22,293.98442
Overall Steps per Second: 10,679.56292

Timestep Collection Time: 2.24392
Timestep Consumption Time: 2.44035
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.68427

Cumulative Model Updates: 239,700
Cumulative Timesteps: 1,999,127,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.05387
Policy Entropy: 2.21812
Value Function Loss: 0.01699

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.52555
Value Function Update Magnitude: 0.62301

Collected Steps per Second: 23,005.15286
Overall Steps per Second: 10,915.41074

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.40774
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.58160

Cumulative Model Updates: 239,706
Cumulative Timesteps: 1,999,178,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1999178004...
Checkpoint 1999178004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.90685
Policy Entropy: 2.21755
Value Function Loss: 0.01789

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.53350
Value Function Update Magnitude: 0.62849

Collected Steps per Second: 23,758.00127
Overall Steps per Second: 10,855.87161

Timestep Collection Time: 2.10523
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.60728

Cumulative Model Updates: 239,712
Cumulative Timesteps: 1,999,228,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.62738
Policy Entropy: 2.23647
Value Function Loss: 0.01715

Mean KL Divergence: 0.02959
SB3 Clip Fraction: 0.16785
Policy Update Magnitude: 0.51575
Value Function Update Magnitude: 0.62784

Collected Steps per Second: 23,460.59760
Overall Steps per Second: 10,820.81965

Timestep Collection Time: 2.13226
Timestep Consumption Time: 2.49068
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.62294

Cumulative Model Updates: 239,718
Cumulative Timesteps: 1,999,278,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1999278044...
Checkpoint 1999278044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.91124
Policy Entropy: 2.24663
Value Function Loss: 0.01701

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.53524
Value Function Update Magnitude: 0.61363

Collected Steps per Second: 22,944.07813
Overall Steps per Second: 10,911.54457

Timestep Collection Time: 2.18017
Timestep Consumption Time: 2.40415
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.58432

Cumulative Model Updates: 239,724
Cumulative Timesteps: 1,999,328,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.10931
Policy Entropy: 2.25282
Value Function Loss: 0.01626

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.54041
Value Function Update Magnitude: 0.58949

Collected Steps per Second: 23,144.78867
Overall Steps per Second: 10,995.10807

Timestep Collection Time: 2.16083
Timestep Consumption Time: 2.38774
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.54857

Cumulative Model Updates: 239,730
Cumulative Timesteps: 1,999,378,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1999378078...
Checkpoint 1999378078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.34034
Policy Entropy: 2.24792
Value Function Loss: 0.01573

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.53116
Value Function Update Magnitude: 0.59237

Collected Steps per Second: 22,874.45779
Overall Steps per Second: 10,682.12270

Timestep Collection Time: 2.18698
Timestep Consumption Time: 2.49617
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.68315

Cumulative Model Updates: 239,736
Cumulative Timesteps: 1,999,428,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.30518
Policy Entropy: 2.22504
Value Function Loss: 0.01647

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.52940
Value Function Update Magnitude: 0.59335

Collected Steps per Second: 22,677.63326
Overall Steps per Second: 10,777.80292

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.43591
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.64213

Cumulative Model Updates: 239,742
Cumulative Timesteps: 1,999,478,136

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1999478136...
Checkpoint 1999478136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.41326
Policy Entropy: 2.21363
Value Function Loss: 0.01667

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.60242

Collected Steps per Second: 22,357.43136
Overall Steps per Second: 10,721.54138

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.66463

Cumulative Model Updates: 239,748
Cumulative Timesteps: 1,999,528,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.14305
Policy Entropy: 2.20351
Value Function Loss: 0.01791

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.53526
Value Function Update Magnitude: 0.60459

Collected Steps per Second: 22,716.20522
Overall Steps per Second: 10,955.03837

Timestep Collection Time: 2.20178
Timestep Consumption Time: 2.36379
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.56557

Cumulative Model Updates: 239,754
Cumulative Timesteps: 1,999,578,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1999578164...
Checkpoint 1999578164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.96554
Policy Entropy: 2.20289
Value Function Loss: 0.01794

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.60846

Collected Steps per Second: 22,511.60022
Overall Steps per Second: 10,621.04240

Timestep Collection Time: 2.22188
Timestep Consumption Time: 2.48745
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.70933

Cumulative Model Updates: 239,760
Cumulative Timesteps: 1,999,628,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.70260
Policy Entropy: 2.22793
Value Function Loss: 0.01756

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.54189
Value Function Update Magnitude: 0.60586

Collected Steps per Second: 22,680.23950
Overall Steps per Second: 10,642.07603

Timestep Collection Time: 2.20536
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.70002

Cumulative Model Updates: 239,766
Cumulative Timesteps: 1,999,678,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1999678200...
Checkpoint 1999678200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.48065
Policy Entropy: 2.22384
Value Function Loss: 0.01764

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.59055

Collected Steps per Second: 22,763.83870
Overall Steps per Second: 10,877.56022

Timestep Collection Time: 2.19647
Timestep Consumption Time: 2.40015
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.59662

Cumulative Model Updates: 239,772
Cumulative Timesteps: 1,999,728,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.76598
Policy Entropy: 2.21806
Value Function Loss: 0.01929

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.61443

Collected Steps per Second: 23,377.26073
Overall Steps per Second: 10,869.50191

Timestep Collection Time: 2.13951
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.60150

Cumulative Model Updates: 239,778
Cumulative Timesteps: 1,999,778,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1999778216...
Checkpoint 1999778216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.83430
Policy Entropy: 2.19251
Value Function Loss: 0.01986

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.64724

Collected Steps per Second: 22,115.29370
Overall Steps per Second: 10,396.12115

Timestep Collection Time: 2.26124
Timestep Consumption Time: 2.54901
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.81026

Cumulative Model Updates: 239,784
Cumulative Timesteps: 1,999,828,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.78236
Policy Entropy: 2.18879
Value Function Loss: 0.01920

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.65107

Collected Steps per Second: 22,770.35737
Overall Steps per Second: 10,769.47030

Timestep Collection Time: 2.19689
Timestep Consumption Time: 2.44809
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.64498

Cumulative Model Updates: 239,790
Cumulative Timesteps: 1,999,878,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1999878248...
Checkpoint 1999878248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.14119
Policy Entropy: 2.20354
Value Function Loss: 0.01923

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.64719

Collected Steps per Second: 23,442.31701
Overall Steps per Second: 10,883.07050

Timestep Collection Time: 2.13307
Timestep Consumption Time: 2.46159
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.59466

Cumulative Model Updates: 239,796
Cumulative Timesteps: 1,999,928,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.37735
Policy Entropy: 2.19560
Value Function Loss: 0.01926

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.63524

Collected Steps per Second: 23,450.44714
Overall Steps per Second: 10,847.56329

Timestep Collection Time: 2.13343
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.61210

Cumulative Model Updates: 239,802
Cumulative Timesteps: 1,999,978,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1999978282...
Checkpoint 1999978282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.55643
Policy Entropy: 2.16264
Value Function Loss: 0.01965

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.63674

Collected Steps per Second: 22,741.54746
Overall Steps per Second: 10,724.53899

Timestep Collection Time: 2.19985
Timestep Consumption Time: 2.46497
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.66482

Cumulative Model Updates: 239,808
Cumulative Timesteps: 2,000,028,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.87885
Policy Entropy: 2.16765
Value Function Loss: 0.01867

Mean KL Divergence: 0.02889
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.65542

Collected Steps per Second: 23,138.19456
Overall Steps per Second: 11,047.42104

Timestep Collection Time: 2.16119
Timestep Consumption Time: 2.36530
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.52649

Cumulative Model Updates: 239,814
Cumulative Timesteps: 2,000,078,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2000078316...
Checkpoint 2000078316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.35413
Policy Entropy: 2.18935
Value Function Loss: 0.01730

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.63324

Collected Steps per Second: 22,565.47568
Overall Steps per Second: 10,738.86694

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.65747

Cumulative Model Updates: 239,820
Cumulative Timesteps: 2,000,128,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.26619
Policy Entropy: 2.22963
Value Function Loss: 0.01702

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.61350

Collected Steps per Second: 22,986.07112
Overall Steps per Second: 10,861.11740

Timestep Collection Time: 2.17645
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.60616

Cumulative Model Updates: 239,826
Cumulative Timesteps: 2,000,178,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2000178360...
Checkpoint 2000178360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.74484
Policy Entropy: 2.23775
Value Function Loss: 0.01743

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.53140
Value Function Update Magnitude: 0.59853

Collected Steps per Second: 22,315.23609
Overall Steps per Second: 10,666.22750

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.44707
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.68769

Cumulative Model Updates: 239,832
Cumulative Timesteps: 2,000,228,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.32728
Policy Entropy: 2.24018
Value Function Loss: 0.01780

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.52982
Value Function Update Magnitude: 0.58300

Collected Steps per Second: 22,903.92757
Overall Steps per Second: 10,938.11978

Timestep Collection Time: 2.18425
Timestep Consumption Time: 2.38948
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.57373

Cumulative Model Updates: 239,838
Cumulative Timesteps: 2,000,278,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2000278388...
Checkpoint 2000278388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.12087
Policy Entropy: 2.24890
Value Function Loss: 0.01676

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.52278
Value Function Update Magnitude: 0.56904

Collected Steps per Second: 22,594.82855
Overall Steps per Second: 10,628.07320

Timestep Collection Time: 2.21431
Timestep Consumption Time: 2.49322
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.70753

Cumulative Model Updates: 239,844
Cumulative Timesteps: 2,000,328,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.89652
Policy Entropy: 2.23310
Value Function Loss: 0.01612

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.51613
Value Function Update Magnitude: 0.57325

Collected Steps per Second: 23,132.41489
Overall Steps per Second: 10,907.35922

Timestep Collection Time: 2.16147
Timestep Consumption Time: 2.42259
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.58406

Cumulative Model Updates: 239,850
Cumulative Timesteps: 2,000,378,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2000378420...
Checkpoint 2000378420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.44194
Policy Entropy: 2.24072
Value Function Loss: 0.01544

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.51399
Value Function Update Magnitude: 0.57438

Collected Steps per Second: 22,524.84474
Overall Steps per Second: 10,648.99566

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.47580
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.69584

Cumulative Model Updates: 239,856
Cumulative Timesteps: 2,000,428,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.54473
Policy Entropy: 2.25501
Value Function Loss: 0.01539

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.51780
Value Function Update Magnitude: 0.54975

Collected Steps per Second: 23,384.42420
Overall Steps per Second: 10,958.46334

Timestep Collection Time: 2.13920
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.56487

Cumulative Model Updates: 239,862
Cumulative Timesteps: 2,000,478,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2000478450...
Checkpoint 2000478450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.56262
Policy Entropy: 2.27818
Value Function Loss: 0.01667

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.51524
Value Function Update Magnitude: 0.53445

Collected Steps per Second: 22,870.01283
Overall Steps per Second: 10,684.88379

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.49364
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.68026

Cumulative Model Updates: 239,868
Cumulative Timesteps: 2,000,528,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.70443
Policy Entropy: 2.27770
Value Function Loss: 0.01603

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.51757
Value Function Update Magnitude: 0.56682

Collected Steps per Second: 22,825.87553
Overall Steps per Second: 10,832.53568

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.61591

Cumulative Model Updates: 239,874
Cumulative Timesteps: 2,000,578,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2000578460...
Checkpoint 2000578460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.83969
Policy Entropy: 2.23490
Value Function Loss: 0.01683

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.51922
Value Function Update Magnitude: 0.58171

Collected Steps per Second: 22,388.24447
Overall Steps per Second: 10,622.59233

Timestep Collection Time: 2.23358
Timestep Consumption Time: 2.47393
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.70751

Cumulative Model Updates: 239,880
Cumulative Timesteps: 2,000,628,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.67007
Policy Entropy: 2.23519
Value Function Loss: 0.01606

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.59166

Collected Steps per Second: 22,640.45379
Overall Steps per Second: 10,821.16938

Timestep Collection Time: 2.20914
Timestep Consumption Time: 2.41291
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62205

Cumulative Model Updates: 239,886
Cumulative Timesteps: 2,000,678,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2000678482...
Checkpoint 2000678482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.39979
Policy Entropy: 2.18299
Value Function Loss: 0.01770

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.53846
Value Function Update Magnitude: 0.60538

Collected Steps per Second: 23,138.88798
Overall Steps per Second: 10,730.77192

Timestep Collection Time: 2.16104
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.65987

Cumulative Model Updates: 239,892
Cumulative Timesteps: 2,000,728,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.84065
Policy Entropy: 2.21569
Value Function Loss: 0.01803

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 23,520.30028
Overall Steps per Second: 10,954.71359

Timestep Collection Time: 2.12582
Timestep Consumption Time: 2.43842
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.56425

Cumulative Model Updates: 239,898
Cumulative Timesteps: 2,000,778,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2000778486...
Checkpoint 2000778486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.49191
Policy Entropy: 2.21372
Value Function Loss: 0.01707

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.60810

Collected Steps per Second: 22,748.87294
Overall Steps per Second: 10,764.47070

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.44768
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.64621

Cumulative Model Updates: 239,904
Cumulative Timesteps: 2,000,828,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.63384
Policy Entropy: 2.26026
Value Function Loss: 0.01647

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.52193
Value Function Update Magnitude: 0.61596

Collected Steps per Second: 23,208.37799
Overall Steps per Second: 11,116.32674

Timestep Collection Time: 2.15517
Timestep Consumption Time: 2.34434
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.49951

Cumulative Model Updates: 239,910
Cumulative Timesteps: 2,000,878,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2000878518...
Checkpoint 2000878518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.36520
Policy Entropy: 2.23704
Value Function Loss: 0.01683

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.52748
Value Function Update Magnitude: 0.60463

Collected Steps per Second: 22,810.07483
Overall Steps per Second: 10,756.61102

Timestep Collection Time: 2.19315
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.65072

Cumulative Model Updates: 239,916
Cumulative Timesteps: 2,000,928,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.83967
Policy Entropy: 2.21202
Value Function Loss: 0.01819

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.59131

Collected Steps per Second: 23,047.29974
Overall Steps per Second: 10,871.43874

Timestep Collection Time: 2.16963
Timestep Consumption Time: 2.42995
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.59958

Cumulative Model Updates: 239,922
Cumulative Timesteps: 2,000,978,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2000978548...
Checkpoint 2000978548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.37053
Policy Entropy: 2.21516
Value Function Loss: 0.01837

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.59584

Collected Steps per Second: 22,895.08590
Overall Steps per Second: 10,693.61840

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.67756

Cumulative Model Updates: 239,928
Cumulative Timesteps: 2,001,028,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.21156
Policy Entropy: 2.21892
Value Function Loss: 0.01666

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.52984
Value Function Update Magnitude: 0.59755

Collected Steps per Second: 22,359.79736
Overall Steps per Second: 10,639.91747

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.70041

Cumulative Model Updates: 239,934
Cumulative Timesteps: 2,001,078,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2001078580...
Checkpoint 2001078580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.82233
Policy Entropy: 2.24216
Value Function Loss: 0.01555

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.51720
Value Function Update Magnitude: 0.58616

Collected Steps per Second: 22,752.83879
Overall Steps per Second: 10,919.32506

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.38275
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.58142

Cumulative Model Updates: 239,940
Cumulative Timesteps: 2,001,128,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.01502
Policy Entropy: 2.24024
Value Function Loss: 0.01539

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.57646

Collected Steps per Second: 22,704.55154
Overall Steps per Second: 10,809.92174

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.42328
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.62557

Cumulative Model Updates: 239,946
Cumulative Timesteps: 2,001,178,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2001178608...
Checkpoint 2001178608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.52928
Policy Entropy: 2.24610
Value Function Loss: 0.01681

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.52732
Value Function Update Magnitude: 0.58498

Collected Steps per Second: 22,380.48270
Overall Steps per Second: 10,723.16130

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.66504

Cumulative Model Updates: 239,952
Cumulative Timesteps: 2,001,228,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.80376
Policy Entropy: 2.21848
Value Function Loss: 0.01751

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.58506

Collected Steps per Second: 23,046.45938
Overall Steps per Second: 10,813.88611

Timestep Collection Time: 2.17022
Timestep Consumption Time: 2.45494
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62516

Cumulative Model Updates: 239,958
Cumulative Timesteps: 2,001,278,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2001278648...
Checkpoint 2001278648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.42818
Policy Entropy: 2.21271
Value Function Loss: 0.01815

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.54137
Value Function Update Magnitude: 0.57714

Collected Steps per Second: 22,641.39467
Overall Steps per Second: 10,786.22057

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.63814

Cumulative Model Updates: 239,964
Cumulative Timesteps: 2,001,328,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.43336
Policy Entropy: 2.19691
Value Function Loss: 0.01795

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.56893

Collected Steps per Second: 22,743.57182
Overall Steps per Second: 10,566.44999

Timestep Collection Time: 2.19895
Timestep Consumption Time: 2.53414
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.73309

Cumulative Model Updates: 239,970
Cumulative Timesteps: 2,001,378,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2001378688...
Checkpoint 2001378688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.25725
Policy Entropy: 2.22152
Value Function Loss: 0.01790

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.57898

Collected Steps per Second: 23,138.55133
Overall Steps per Second: 10,902.30073

Timestep Collection Time: 2.16193
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.58839

Cumulative Model Updates: 239,976
Cumulative Timesteps: 2,001,428,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.23362
Policy Entropy: 2.24096
Value Function Loss: 0.01730

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.53780
Value Function Update Magnitude: 0.60065

Collected Steps per Second: 23,086.60047
Overall Steps per Second: 10,851.72195

Timestep Collection Time: 2.16619
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.60849

Cumulative Model Updates: 239,982
Cumulative Timesteps: 2,001,478,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2001478722...
Checkpoint 2001478722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.33227
Policy Entropy: 2.25648
Value Function Loss: 0.01756

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.60123

Collected Steps per Second: 22,884.04589
Overall Steps per Second: 10,719.01496

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.48047
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.66610

Cumulative Model Updates: 239,988
Cumulative Timesteps: 2,001,528,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.67732
Policy Entropy: 2.25395
Value Function Loss: 0.01796

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.54979
Value Function Update Magnitude: 0.60384

Collected Steps per Second: 23,017.06380
Overall Steps per Second: 10,947.17292

Timestep Collection Time: 2.17343
Timestep Consumption Time: 2.39633
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.56976

Cumulative Model Updates: 239,994
Cumulative Timesteps: 2,001,578,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2001578764...
Checkpoint 2001578764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.97998
Policy Entropy: 2.24548
Value Function Loss: 0.01742

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.60892

Collected Steps per Second: 22,330.17805
Overall Steps per Second: 10,621.57581

Timestep Collection Time: 2.23993
Timestep Consumption Time: 2.46917
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.70909

Cumulative Model Updates: 240,000
Cumulative Timesteps: 2,001,628,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.13452
Policy Entropy: 2.24106
Value Function Loss: 0.01732

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.53940
Value Function Update Magnitude: 0.60491

Collected Steps per Second: 22,660.49074
Overall Steps per Second: 10,770.11929

Timestep Collection Time: 2.20745
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.64452

Cumulative Model Updates: 240,006
Cumulative Timesteps: 2,001,678,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2001678804...
Checkpoint 2001678804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.98628
Policy Entropy: 2.25292
Value Function Loss: 0.01660

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.52690
Value Function Update Magnitude: 0.57490

Collected Steps per Second: 22,182.86702
Overall Steps per Second: 10,707.44159

Timestep Collection Time: 2.25507
Timestep Consumption Time: 2.41682
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.67189

Cumulative Model Updates: 240,012
Cumulative Timesteps: 2,001,728,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.45789
Policy Entropy: 2.25707
Value Function Loss: 0.01741

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.53063
Value Function Update Magnitude: 0.55913

Collected Steps per Second: 23,112.36076
Overall Steps per Second: 11,026.09214

Timestep Collection Time: 2.16395
Timestep Consumption Time: 2.37202
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.53597

Cumulative Model Updates: 240,018
Cumulative Timesteps: 2,001,778,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2001778842...
Checkpoint 2001778842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.46087
Policy Entropy: 2.27149
Value Function Loss: 0.01678

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.52910
Value Function Update Magnitude: 0.56593

Collected Steps per Second: 22,855.87771
Overall Steps per Second: 10,700.67372

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.67316

Cumulative Model Updates: 240,024
Cumulative Timesteps: 2,001,828,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.71082
Policy Entropy: 2.26323
Value Function Loss: 0.01726

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.53143
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 22,768.88918
Overall Steps per Second: 10,795.48056

Timestep Collection Time: 2.19712
Timestep Consumption Time: 2.43686
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.63398

Cumulative Model Updates: 240,030
Cumulative Timesteps: 2,001,878,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2001878874...
Checkpoint 2001878874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.63919
Policy Entropy: 2.26542
Value Function Loss: 0.01729

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.53992
Value Function Update Magnitude: 0.59833

Collected Steps per Second: 22,646.67060
Overall Steps per Second: 10,669.91367

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.47933
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.68814

Cumulative Model Updates: 240,036
Cumulative Timesteps: 2,001,928,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.52316
Policy Entropy: 2.25955
Value Function Loss: 0.01741

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.53480
Value Function Update Magnitude: 0.61346

Collected Steps per Second: 23,049.83768
Overall Steps per Second: 10,896.40995

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.59142

Cumulative Model Updates: 240,042
Cumulative Timesteps: 2,001,978,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2001978926...
Checkpoint 2001978926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.83503
Policy Entropy: 2.26299
Value Function Loss: 0.01708

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.52778
Value Function Update Magnitude: 0.63367

Collected Steps per Second: 23,065.95696
Overall Steps per Second: 10,729.15820

Timestep Collection Time: 2.16822
Timestep Consumption Time: 2.49310
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.66132

Cumulative Model Updates: 240,048
Cumulative Timesteps: 2,002,028,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.47629
Policy Entropy: 2.29026
Value Function Loss: 0.01623

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.52153
Value Function Update Magnitude: 0.62106

Collected Steps per Second: 22,823.39424
Overall Steps per Second: 10,855.96478

Timestep Collection Time: 2.19126
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.60687

Cumulative Model Updates: 240,054
Cumulative Timesteps: 2,002,078,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2002078950...
Checkpoint 2002078950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.79444
Policy Entropy: 2.27893
Value Function Loss: 0.01644

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.52112
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,416.32288
Overall Steps per Second: 10,634.34748

Timestep Collection Time: 2.23061
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.70193

Cumulative Model Updates: 240,060
Cumulative Timesteps: 2,002,128,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.84652
Policy Entropy: 2.26826
Value Function Loss: 0.01655

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.52428
Value Function Update Magnitude: 0.61217

Collected Steps per Second: 22,776.24302
Overall Steps per Second: 10,881.18019

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.40011
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.59564

Cumulative Model Updates: 240,066
Cumulative Timesteps: 2,002,178,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2002178958...
Checkpoint 2002178958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.80752
Policy Entropy: 2.22002
Value Function Loss: 0.01724

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.52088
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 23,098.04197
Overall Steps per Second: 10,656.17562

Timestep Collection Time: 2.16503
Timestep Consumption Time: 2.52783
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.69287

Cumulative Model Updates: 240,072
Cumulative Timesteps: 2,002,228,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.53663
Policy Entropy: 2.19431
Value Function Loss: 0.01889

Mean KL Divergence: 0.02973
SB3 Clip Fraction: 0.16903
Policy Update Magnitude: 0.51849
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 23,201.55378
Overall Steps per Second: 10,837.52975

Timestep Collection Time: 2.15623
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.61618

Cumulative Model Updates: 240,078
Cumulative Timesteps: 2,002,278,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2002278994...
Checkpoint 2002278994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.99281
Policy Entropy: 2.22896
Value Function Loss: 0.01943

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.52669
Value Function Update Magnitude: 0.64311

Collected Steps per Second: 22,852.00079
Overall Steps per Second: 10,670.11856

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.49889
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.68767

Cumulative Model Updates: 240,084
Cumulative Timesteps: 2,002,329,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.92461
Policy Entropy: 2.24910
Value Function Loss: 0.01939

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.15940
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.66966

Collected Steps per Second: 23,085.95501
Overall Steps per Second: 10,940.92790

Timestep Collection Time: 2.16582
Timestep Consumption Time: 2.40418
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.57000

Cumulative Model Updates: 240,090
Cumulative Timesteps: 2,002,379,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2002379012...
Checkpoint 2002379012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.68973
Policy Entropy: 2.29007
Value Function Loss: 0.01856

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.15828
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.66727

Collected Steps per Second: 23,035.17599
Overall Steps per Second: 11,041.65955

Timestep Collection Time: 2.17111
Timestep Consumption Time: 2.35828
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.52939

Cumulative Model Updates: 240,096
Cumulative Timesteps: 2,002,429,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.74994
Policy Entropy: 2.27926
Value Function Loss: 0.01775

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.15329
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.66272

Collected Steps per Second: 23,110.58534
Overall Steps per Second: 10,879.72894

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.43278
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59681

Cumulative Model Updates: 240,102
Cumulative Timesteps: 2,002,479,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2002479036...
Checkpoint 2002479036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.10328
Policy Entropy: 2.25693
Value Function Loss: 0.01754

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.16451
Policy Update Magnitude: 0.50940
Value Function Update Magnitude: 0.65716

Collected Steps per Second: 22,431.05844
Overall Steps per Second: 10,735.49492

Timestep Collection Time: 2.23021
Timestep Consumption Time: 2.42966
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.65987

Cumulative Model Updates: 240,108
Cumulative Timesteps: 2,002,529,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.84493
Policy Entropy: 2.23697
Value Function Loss: 0.01720

Mean KL Divergence: 0.02568
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.50541
Value Function Update Magnitude: 0.63057

Collected Steps per Second: 22,481.54761
Overall Steps per Second: 10,810.85545

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.40113
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62535

Cumulative Model Updates: 240,114
Cumulative Timesteps: 2,002,579,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2002579066...
Checkpoint 2002579066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.58652
Policy Entropy: 2.23164
Value Function Loss: 0.01740

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.62048

Collected Steps per Second: 22,517.54387
Overall Steps per Second: 10,724.04703

Timestep Collection Time: 2.22165
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.66484

Cumulative Model Updates: 240,120
Cumulative Timesteps: 2,002,629,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.74691
Policy Entropy: 2.22784
Value Function Loss: 0.01764

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.61860

Collected Steps per Second: 22,469.47477
Overall Steps per Second: 10,925.05495

Timestep Collection Time: 2.22658
Timestep Consumption Time: 2.35281
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.57938

Cumulative Model Updates: 240,126
Cumulative Timesteps: 2,002,679,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2002679122...
Checkpoint 2002679122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.62466
Policy Entropy: 2.23980
Value Function Loss: 0.01750

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.54668
Value Function Update Magnitude: 0.62193

Collected Steps per Second: 22,782.72441
Overall Steps per Second: 10,624.33968

Timestep Collection Time: 2.19552
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70806

Cumulative Model Updates: 240,132
Cumulative Timesteps: 2,002,729,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.83337
Policy Entropy: 2.25033
Value Function Loss: 0.01762

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.62163

Collected Steps per Second: 23,159.19121
Overall Steps per Second: 10,850.49741

Timestep Collection Time: 2.15906
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60827

Cumulative Model Updates: 240,138
Cumulative Timesteps: 2,002,779,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2002779144...
Checkpoint 2002779144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.82622
Policy Entropy: 2.27304
Value Function Loss: 0.01756

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.61396

Collected Steps per Second: 22,675.32686
Overall Steps per Second: 10,647.99791

Timestep Collection Time: 2.20619
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.69816

Cumulative Model Updates: 240,144
Cumulative Timesteps: 2,002,829,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.62258
Policy Entropy: 2.24847
Value Function Loss: 0.01880

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.61552

Collected Steps per Second: 23,170.33556
Overall Steps per Second: 10,938.77615

Timestep Collection Time: 2.15828
Timestep Consumption Time: 2.41335
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.57163

Cumulative Model Updates: 240,150
Cumulative Timesteps: 2,002,879,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2002879178...
Checkpoint 2002879178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.19930
Policy Entropy: 2.24534
Value Function Loss: 0.01966

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.62665

Collected Steps per Second: 22,690.46922
Overall Steps per Second: 10,850.93376

Timestep Collection Time: 2.20427
Timestep Consumption Time: 2.40510
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.60937

Cumulative Model Updates: 240,156
Cumulative Timesteps: 2,002,929,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.55470
Policy Entropy: 2.24982
Value Function Loss: 0.01923

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.56085
Value Function Update Magnitude: 0.62535

Collected Steps per Second: 23,523.78469
Overall Steps per Second: 10,857.22146

Timestep Collection Time: 2.12627
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.60689

Cumulative Model Updates: 240,162
Cumulative Timesteps: 2,002,979,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2002979212...
Checkpoint 2002979212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.83753
Policy Entropy: 2.27945
Value Function Loss: 0.01829

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.55646
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,722.74481
Overall Steps per Second: 10,683.01323

Timestep Collection Time: 2.20149
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.68257

Cumulative Model Updates: 240,168
Cumulative Timesteps: 2,003,029,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.82628
Policy Entropy: 2.29254
Value Function Loss: 0.01629

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.61440

Collected Steps per Second: 22,748.40948
Overall Steps per Second: 10,712.32529

Timestep Collection Time: 2.19813
Timestep Consumption Time: 2.46976
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.66789

Cumulative Model Updates: 240,174
Cumulative Timesteps: 2,003,079,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2003079240...
Checkpoint 2003079240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.22073
Policy Entropy: 2.28311
Value Function Loss: 0.01590

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.53316
Value Function Update Magnitude: 0.58646

Collected Steps per Second: 21,336.39121
Overall Steps per Second: 10,574.54596

Timestep Collection Time: 2.34341
Timestep Consumption Time: 2.38492
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.72834

Cumulative Model Updates: 240,180
Cumulative Timesteps: 2,003,129,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.17812
Policy Entropy: 2.26078
Value Function Loss: 0.01556

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.52505
Value Function Update Magnitude: 0.55270

Collected Steps per Second: 21,045.65706
Overall Steps per Second: 10,172.75539

Timestep Collection Time: 2.37617
Timestep Consumption Time: 2.53971
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.91588

Cumulative Model Updates: 240,186
Cumulative Timesteps: 2,003,179,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2003179248...
Checkpoint 2003179248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.43375
Policy Entropy: 2.26030
Value Function Loss: 0.01550

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.52241
Value Function Update Magnitude: 0.53624

Collected Steps per Second: 21,856.58939
Overall Steps per Second: 10,627.22328

Timestep Collection Time: 2.28883
Timestep Consumption Time: 2.41852
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.70734

Cumulative Model Updates: 240,192
Cumulative Timesteps: 2,003,229,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.06210
Policy Entropy: 2.27745
Value Function Loss: 0.01637

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.54383

Collected Steps per Second: 22,873.89828
Overall Steps per Second: 10,778.06164

Timestep Collection Time: 2.18607
Timestep Consumption Time: 2.45335
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.63942

Cumulative Model Updates: 240,198
Cumulative Timesteps: 2,003,279,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2003279278...
Checkpoint 2003279278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.37547
Policy Entropy: 2.31711
Value Function Loss: 0.01736

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.51473
Value Function Update Magnitude: 0.55791

Collected Steps per Second: 22,115.63700
Overall Steps per Second: 10,687.11134

Timestep Collection Time: 2.26148
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.67984

Cumulative Model Updates: 240,204
Cumulative Timesteps: 2,003,329,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.59230
Policy Entropy: 2.30225
Value Function Loss: 0.01743

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.57727

Collected Steps per Second: 22,643.02626
Overall Steps per Second: 10,962.52192

Timestep Collection Time: 2.20819
Timestep Consumption Time: 2.35281
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.56099

Cumulative Model Updates: 240,210
Cumulative Timesteps: 2,003,379,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2003379292...
Checkpoint 2003379292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.18209
Policy Entropy: 2.27391
Value Function Loss: 0.01703

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.15614
Policy Update Magnitude: 0.51694
Value Function Update Magnitude: 0.58612

Collected Steps per Second: 22,533.51766
Overall Steps per Second: 10,584.36479

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.72508

Cumulative Model Updates: 240,216
Cumulative Timesteps: 2,003,429,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.11972
Policy Entropy: 2.23902
Value Function Loss: 0.01675

Mean KL Divergence: 0.02739
SB3 Clip Fraction: 0.17049
Policy Update Magnitude: 0.52461
Value Function Update Magnitude: 0.59245

Collected Steps per Second: 22,860.98676
Overall Steps per Second: 10,664.80308

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.68944

Cumulative Model Updates: 240,222
Cumulative Timesteps: 2,003,479,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2003479316...
Checkpoint 2003479316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.78787
Policy Entropy: 2.23097
Value Function Loss: 0.01729

Mean KL Divergence: 0.02962
SB3 Clip Fraction: 0.17533
Policy Update Magnitude: 0.52302
Value Function Update Magnitude: 0.61372

Collected Steps per Second: 22,948.37300
Overall Steps per Second: 10,844.95589

Timestep Collection Time: 2.17880
Timestep Consumption Time: 2.43163
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61044

Cumulative Model Updates: 240,228
Cumulative Timesteps: 2,003,529,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.32980
Policy Entropy: 2.25409
Value Function Loss: 0.01769

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.15251
Policy Update Magnitude: 0.55856
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 23,166.09220
Overall Steps per Second: 10,971.73189

Timestep Collection Time: 2.15884
Timestep Consumption Time: 2.39941
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.55826

Cumulative Model Updates: 240,234
Cumulative Timesteps: 2,003,579,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2003579328...
Checkpoint 2003579328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.84214
Policy Entropy: 2.26552
Value Function Loss: 0.01812

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.55727
Value Function Update Magnitude: 0.60374

Collected Steps per Second: 23,094.44718
Overall Steps per Second: 10,768.98147

Timestep Collection Time: 2.16537
Timestep Consumption Time: 2.47834
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.64371

Cumulative Model Updates: 240,240
Cumulative Timesteps: 2,003,629,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.25036
Policy Entropy: 2.28740
Value Function Loss: 0.01797

Mean KL Divergence: 0.02574
SB3 Clip Fraction: 0.15434
Policy Update Magnitude: 0.51284
Value Function Update Magnitude: 0.59380

Collected Steps per Second: 23,282.61719
Overall Steps per Second: 10,777.88050

Timestep Collection Time: 2.14813
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.64043

Cumulative Model Updates: 240,246
Cumulative Timesteps: 2,003,679,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2003679350...
Checkpoint 2003679350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.16711
Policy Entropy: 2.28356
Value Function Loss: 0.01772

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.15194
Policy Update Magnitude: 0.49248
Value Function Update Magnitude: 0.59762

Collected Steps per Second: 22,767.78580
Overall Steps per Second: 10,707.78676

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.47361
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.66987

Cumulative Model Updates: 240,252
Cumulative Timesteps: 2,003,729,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.27596
Policy Entropy: 2.29321
Value Function Loss: 0.01666

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.53439
Value Function Update Magnitude: 0.59724

Collected Steps per Second: 23,349.92822
Overall Steps per Second: 11,004.79381

Timestep Collection Time: 2.14245
Timestep Consumption Time: 2.40339
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.54584

Cumulative Model Updates: 240,258
Cumulative Timesteps: 2,003,779,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2003779380...
Checkpoint 2003779380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.91588
Policy Entropy: 2.26305
Value Function Loss: 0.01717

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.59754

Collected Steps per Second: 22,804.33274
Overall Steps per Second: 10,831.22774

Timestep Collection Time: 2.19265
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61647

Cumulative Model Updates: 240,264
Cumulative Timesteps: 2,003,829,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.24416
Policy Entropy: 2.28015
Value Function Loss: 0.01764

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.55087
Value Function Update Magnitude: 0.60315

Collected Steps per Second: 22,170.41944
Overall Steps per Second: 10,545.57219

Timestep Collection Time: 2.25625
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.74341

Cumulative Model Updates: 240,270
Cumulative Timesteps: 2,003,879,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2003879404...
Checkpoint 2003879404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.63396
Policy Entropy: 2.29482
Value Function Loss: 0.01822

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.61088

Collected Steps per Second: 22,331.88780
Overall Steps per Second: 10,658.40129

Timestep Collection Time: 2.24020
Timestep Consumption Time: 2.45356
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.69376

Cumulative Model Updates: 240,276
Cumulative Timesteps: 2,003,929,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.06540
Policy Entropy: 2.31557
Value Function Loss: 0.01729

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.61686

Collected Steps per Second: 22,761.34868
Overall Steps per Second: 10,901.68020

Timestep Collection Time: 2.19750
Timestep Consumption Time: 2.39060
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.58810

Cumulative Model Updates: 240,282
Cumulative Timesteps: 2,003,979,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2003979450...
Checkpoint 2003979450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.07048
Policy Entropy: 2.29235
Value Function Loss: 0.01859

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.61554

Collected Steps per Second: 22,892.32030
Overall Steps per Second: 10,637.60636

Timestep Collection Time: 2.18536
Timestep Consumption Time: 2.51758
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.70294

Cumulative Model Updates: 240,288
Cumulative Timesteps: 2,004,029,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.24181
Policy Entropy: 2.28793
Value Function Loss: 0.01826

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.59867

Collected Steps per Second: 22,975.59662
Overall Steps per Second: 10,838.00715

Timestep Collection Time: 2.17631
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.61358

Cumulative Model Updates: 240,294
Cumulative Timesteps: 2,004,079,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2004079480...
Checkpoint 2004079480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.98778
Policy Entropy: 2.28460
Value Function Loss: 0.01907

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.58492

Collected Steps per Second: 22,944.86183
Overall Steps per Second: 10,729.83743

Timestep Collection Time: 2.18018
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.66214

Cumulative Model Updates: 240,300
Cumulative Timesteps: 2,004,129,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.11587
Policy Entropy: 2.29875
Value Function Loss: 0.01689

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.53135
Value Function Update Magnitude: 0.58473

Collected Steps per Second: 23,004.10759
Overall Steps per Second: 10,903.69994

Timestep Collection Time: 2.17422
Timestep Consumption Time: 2.41285
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.58707

Cumulative Model Updates: 240,306
Cumulative Timesteps: 2,004,179,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2004179520...
Checkpoint 2004179520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.89784
Policy Entropy: 2.31590
Value Function Loss: 0.01601

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.52288
Value Function Update Magnitude: 0.57582

Collected Steps per Second: 23,909.79406
Overall Steps per Second: 11,079.65599

Timestep Collection Time: 2.09128
Timestep Consumption Time: 2.42168
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.51296

Cumulative Model Updates: 240,312
Cumulative Timesteps: 2,004,229,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.09046
Policy Entropy: 2.32591
Value Function Loss: 0.01545

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.52090
Value Function Update Magnitude: 0.57613

Collected Steps per Second: 22,907.83791
Overall Steps per Second: 10,859.39217

Timestep Collection Time: 2.18318
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60541

Cumulative Model Updates: 240,318
Cumulative Timesteps: 2,004,279,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2004279534...
Checkpoint 2004279534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.82675
Policy Entropy: 2.31914
Value Function Loss: 0.01585

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.52006
Value Function Update Magnitude: 0.56533

Collected Steps per Second: 22,420.17956
Overall Steps per Second: 10,761.78798

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.41613
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.64644

Cumulative Model Updates: 240,324
Cumulative Timesteps: 2,004,329,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.35100
Policy Entropy: 2.29772
Value Function Loss: 0.01719

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.52611
Value Function Update Magnitude: 0.58605

Collected Steps per Second: 23,031.74238
Overall Steps per Second: 10,831.20722

Timestep Collection Time: 2.17126
Timestep Consumption Time: 2.44576
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.61703

Cumulative Model Updates: 240,330
Cumulative Timesteps: 2,004,379,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2004379546...
Checkpoint 2004379546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.14154
Policy Entropy: 2.28776
Value Function Loss: 0.01733

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.61196

Collected Steps per Second: 23,535.75479
Overall Steps per Second: 11,008.05880

Timestep Collection Time: 2.12443
Timestep Consumption Time: 2.41770
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.54213

Cumulative Model Updates: 240,336
Cumulative Timesteps: 2,004,429,546

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.62981
Policy Entropy: 2.26778
Value Function Loss: 0.01776

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.64931

Collected Steps per Second: 22,757.80393
Overall Steps per Second: 10,632.89764

Timestep Collection Time: 2.19775
Timestep Consumption Time: 2.50614
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.70389

Cumulative Model Updates: 240,342
Cumulative Timesteps: 2,004,479,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2004479562...
Checkpoint 2004479562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.22687
Policy Entropy: 2.26326
Value Function Loss: 0.01661

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.66721

Collected Steps per Second: 22,551.03804
Overall Steps per Second: 10,558.97110

Timestep Collection Time: 2.21746
Timestep Consumption Time: 2.51842
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.73588

Cumulative Model Updates: 240,348
Cumulative Timesteps: 2,004,529,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.55530
Policy Entropy: 2.26386
Value Function Loss: 0.01660

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.53141
Value Function Update Magnitude: 0.64651

Collected Steps per Second: 23,208.44285
Overall Steps per Second: 10,968.18513

Timestep Collection Time: 2.15473
Timestep Consumption Time: 2.40464
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.55937

Cumulative Model Updates: 240,354
Cumulative Timesteps: 2,004,579,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2004579576...
Checkpoint 2004579576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.91379
Policy Entropy: 2.26409
Value Function Loss: 0.01736

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.53497
Value Function Update Magnitude: 0.61233

Collected Steps per Second: 23,089.30679
Overall Steps per Second: 11,042.80888

Timestep Collection Time: 2.16680
Timestep Consumption Time: 2.36375
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.53055

Cumulative Model Updates: 240,360
Cumulative Timesteps: 2,004,629,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.04031
Policy Entropy: 2.26273
Value Function Loss: 0.01784

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.52605
Value Function Update Magnitude: 0.61145

Collected Steps per Second: 23,093.71591
Overall Steps per Second: 10,856.98544

Timestep Collection Time: 2.16622
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60772

Cumulative Model Updates: 240,366
Cumulative Timesteps: 2,004,679,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2004679632...
Checkpoint 2004679632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.86957
Policy Entropy: 2.28169
Value Function Loss: 0.01753

Mean KL Divergence: 0.03124
SB3 Clip Fraction: 0.17894
Policy Update Magnitude: 0.52359
Value Function Update Magnitude: 0.61879

Collected Steps per Second: 22,715.28956
Overall Steps per Second: 10,732.25439

Timestep Collection Time: 2.20195
Timestep Consumption Time: 2.45858
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.66053

Cumulative Model Updates: 240,372
Cumulative Timesteps: 2,004,729,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.97317
Policy Entropy: 2.27019
Value Function Loss: 0.01671

Mean KL Divergence: 0.02847
SB3 Clip Fraction: 0.16757
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.62419

Collected Steps per Second: 23,221.43945
Overall Steps per Second: 10,931.62012

Timestep Collection Time: 2.15404
Timestep Consumption Time: 2.42167
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.57572

Cumulative Model Updates: 240,378
Cumulative Timesteps: 2,004,779,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2004779670...
Checkpoint 2004779670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.62219
Policy Entropy: 2.28131
Value Function Loss: 0.01695

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.15536
Policy Update Magnitude: 0.52807
Value Function Update Magnitude: 0.63313

Collected Steps per Second: 22,165.49917
Overall Steps per Second: 10,573.02293

Timestep Collection Time: 2.25693
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.73148

Cumulative Model Updates: 240,384
Cumulative Timesteps: 2,004,829,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.77837
Policy Entropy: 2.27320
Value Function Loss: 0.01671

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.65945

Collected Steps per Second: 22,816.23218
Overall Steps per Second: 10,830.66594

Timestep Collection Time: 2.19142
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61652

Cumulative Model Updates: 240,390
Cumulative Timesteps: 2,004,879,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2004879696...
Checkpoint 2004879696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.83646
Policy Entropy: 2.28329
Value Function Loss: 0.01748

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,144.52189
Overall Steps per Second: 10,709.64648

Timestep Collection Time: 2.25925
Timestep Consumption Time: 2.41224
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.67149

Cumulative Model Updates: 240,396
Cumulative Timesteps: 2,004,929,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.34856
Policy Entropy: 2.29248
Value Function Loss: 0.01734

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.54154
Value Function Update Magnitude: 0.63399

Collected Steps per Second: 22,830.96268
Overall Steps per Second: 10,833.95713

Timestep Collection Time: 2.19053
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61623

Cumulative Model Updates: 240,402
Cumulative Timesteps: 2,004,979,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2004979738...
Checkpoint 2004979738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.83823
Policy Entropy: 2.28734
Value Function Loss: 0.01737

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.11896
Policy Update Magnitude: 0.53653
Value Function Update Magnitude: 0.61279

Collected Steps per Second: 23,619.61484
Overall Steps per Second: 10,812.61328

Timestep Collection Time: 2.11773
Timestep Consumption Time: 2.50835
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.62608

Cumulative Model Updates: 240,408
Cumulative Timesteps: 2,005,029,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.83737
Policy Entropy: 2.25790
Value Function Loss: 0.01605

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.59758

Collected Steps per Second: 23,056.95664
Overall Steps per Second: 10,904.72065

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.41682
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.58554

Cumulative Model Updates: 240,414
Cumulative Timesteps: 2,005,079,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2005079762...
Checkpoint 2005079762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.31580
Policy Entropy: 2.25966
Value Function Loss: 0.01601

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.52583
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 23,013.80893
Overall Steps per Second: 10,757.51621

Timestep Collection Time: 2.17391
Timestep Consumption Time: 2.47679
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.65070

Cumulative Model Updates: 240,420
Cumulative Timesteps: 2,005,129,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.68350
Policy Entropy: 2.24857
Value Function Loss: 0.01656

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.59945

Collected Steps per Second: 23,222.81331
Overall Steps per Second: 10,780.73783

Timestep Collection Time: 2.15366
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.63920

Cumulative Model Updates: 240,426
Cumulative Timesteps: 2,005,179,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2005179806...
Checkpoint 2005179806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.70944
Policy Entropy: 2.28092
Value Function Loss: 0.01790

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 23,167.05353
Overall Steps per Second: 11,016.94312

Timestep Collection Time: 2.15841
Timestep Consumption Time: 2.38042
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.53883

Cumulative Model Updates: 240,432
Cumulative Timesteps: 2,005,229,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.39188
Policy Entropy: 2.26251
Value Function Loss: 0.01839

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.64492

Collected Steps per Second: 22,900.92135
Overall Steps per Second: 10,856.03860

Timestep Collection Time: 2.18393
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.60702

Cumulative Model Updates: 240,438
Cumulative Timesteps: 2,005,279,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2005279824...
Checkpoint 2005279824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.15519
Policy Entropy: 2.28493
Value Function Loss: 0.01679

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.52983
Value Function Update Magnitude: 0.64617

Collected Steps per Second: 22,527.16318
Overall Steps per Second: 10,792.13215

Timestep Collection Time: 2.22087
Timestep Consumption Time: 2.41491
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.63578

Cumulative Model Updates: 240,444
Cumulative Timesteps: 2,005,329,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.34257
Policy Entropy: 2.28548
Value Function Loss: 0.01605

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.52803
Value Function Update Magnitude: 0.60680

Collected Steps per Second: 22,922.31874
Overall Steps per Second: 10,847.27689

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.60945

Cumulative Model Updates: 240,450
Cumulative Timesteps: 2,005,379,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2005379854...
Checkpoint 2005379854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.61584
Policy Entropy: 2.28925
Value Function Loss: 0.01615

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.52957
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 22,721.66353
Overall Steps per Second: 11,007.69775

Timestep Collection Time: 2.20134
Timestep Consumption Time: 2.34258
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.54391

Cumulative Model Updates: 240,456
Cumulative Timesteps: 2,005,429,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.81057
Policy Entropy: 2.26694
Value Function Loss: 0.01674

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.53263
Value Function Update Magnitude: 0.63197

Collected Steps per Second: 22,780.86806
Overall Steps per Second: 10,642.61778

Timestep Collection Time: 2.19579
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.70016

Cumulative Model Updates: 240,462
Cumulative Timesteps: 2,005,479,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2005479894...
Checkpoint 2005479894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.29375
Policy Entropy: 2.26844
Value Function Loss: 0.01714

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.62343

Collected Steps per Second: 23,136.02675
Overall Steps per Second: 10,749.89400

Timestep Collection Time: 2.16139
Timestep Consumption Time: 2.49038
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.65177

Cumulative Model Updates: 240,468
Cumulative Timesteps: 2,005,529,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.32469
Policy Entropy: 2.28237
Value Function Loss: 0.01670

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.52838
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 23,165.40116
Overall Steps per Second: 10,819.61973

Timestep Collection Time: 2.15891
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.62234

Cumulative Model Updates: 240,474
Cumulative Timesteps: 2,005,579,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2005579912...
Checkpoint 2005579912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.04155
Policy Entropy: 2.31574
Value Function Loss: 0.01680

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.52391
Value Function Update Magnitude: 0.61844

Collected Steps per Second: 23,056.59898
Overall Steps per Second: 10,988.66260

Timestep Collection Time: 2.16927
Timestep Consumption Time: 2.38233
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.55160

Cumulative Model Updates: 240,480
Cumulative Timesteps: 2,005,629,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.01176
Policy Entropy: 2.30275
Value Function Loss: 0.01629

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.52443
Value Function Update Magnitude: 0.61878

Collected Steps per Second: 22,788.76225
Overall Steps per Second: 10,835.47678

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.42138
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61632

Cumulative Model Updates: 240,486
Cumulative Timesteps: 2,005,679,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2005679948...
Checkpoint 2005679948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.42781
Policy Entropy: 2.27954
Value Function Loss: 0.01772

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.53089
Value Function Update Magnitude: 0.62034

Collected Steps per Second: 22,896.49132
Overall Steps per Second: 10,703.26995

Timestep Collection Time: 2.18392
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.67184

Cumulative Model Updates: 240,492
Cumulative Timesteps: 2,005,729,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.80653
Policy Entropy: 2.25361
Value Function Loss: 0.01764

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.61984

Collected Steps per Second: 23,208.27646
Overall Steps per Second: 10,916.51371

Timestep Collection Time: 2.15492
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.58132

Cumulative Model Updates: 240,498
Cumulative Timesteps: 2,005,779,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2005779964...
Checkpoint 2005779964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.02470
Policy Entropy: 2.29513
Value Function Loss: 0.01657

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.52638
Value Function Update Magnitude: 0.62046

Collected Steps per Second: 22,257.61210
Overall Steps per Second: 10,739.47473

Timestep Collection Time: 2.24678
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.65647

Cumulative Model Updates: 240,504
Cumulative Timesteps: 2,005,829,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.18674
Policy Entropy: 2.33539
Value Function Loss: 0.01539

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.50904
Value Function Update Magnitude: 0.61103

Collected Steps per Second: 22,885.36940
Overall Steps per Second: 10,819.70258

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.62268

Cumulative Model Updates: 240,510
Cumulative Timesteps: 2,005,879,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2005879988...
Checkpoint 2005879988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.38953
Policy Entropy: 2.33759
Value Function Loss: 0.01621

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.51360
Value Function Update Magnitude: 0.62878

Collected Steps per Second: 22,447.97980
Overall Steps per Second: 10,620.30277

Timestep Collection Time: 2.22782
Timestep Consumption Time: 2.48109
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.70891

Cumulative Model Updates: 240,516
Cumulative Timesteps: 2,005,929,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.07395
Policy Entropy: 2.30754
Value Function Loss: 0.01620

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.52027
Value Function Update Magnitude: 0.65815

Collected Steps per Second: 23,000.19668
Overall Steps per Second: 10,892.18436

Timestep Collection Time: 2.17459
Timestep Consumption Time: 2.41733
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59192

Cumulative Model Updates: 240,522
Cumulative Timesteps: 2,005,980,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2005980014...
Checkpoint 2005980014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.03015
Policy Entropy: 2.26654
Value Function Loss: 0.01704

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.52236
Value Function Update Magnitude: 0.64555

Collected Steps per Second: 23,536.99304
Overall Steps per Second: 10,815.90484

Timestep Collection Time: 2.12474
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.62375

Cumulative Model Updates: 240,528
Cumulative Timesteps: 2,006,030,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.67287
Policy Entropy: 2.27999
Value Function Loss: 0.01706

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.52267
Value Function Update Magnitude: 0.61095

Collected Steps per Second: 23,356.50457
Overall Steps per Second: 10,761.13512

Timestep Collection Time: 2.14107
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.64709

Cumulative Model Updates: 240,534
Cumulative Timesteps: 2,006,080,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2006080032...
Checkpoint 2006080032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.31921
Policy Entropy: 2.26741
Value Function Loss: 0.01783

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.52363
Value Function Update Magnitude: 0.60809

Collected Steps per Second: 22,688.08344
Overall Steps per Second: 10,591.23387

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.51829
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.72315

Cumulative Model Updates: 240,540
Cumulative Timesteps: 2,006,130,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.88412
Policy Entropy: 2.28681
Value Function Loss: 0.01720

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.52872
Value Function Update Magnitude: 0.62816

Collected Steps per Second: 22,847.16070
Overall Steps per Second: 10,874.01505

Timestep Collection Time: 2.18951
Timestep Consumption Time: 2.41082
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.60032

Cumulative Model Updates: 240,546
Cumulative Timesteps: 2,006,180,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2006180080...
Checkpoint 2006180080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.39951
Policy Entropy: 2.25964
Value Function Loss: 0.01641

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.52667
Value Function Update Magnitude: 0.62974

Collected Steps per Second: 22,903.54213
Overall Steps per Second: 10,924.88737

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.39431
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.57799

Cumulative Model Updates: 240,552
Cumulative Timesteps: 2,006,230,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.42150
Policy Entropy: 2.27391
Value Function Loss: 0.01609

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.62107

Collected Steps per Second: 23,403.09736
Overall Steps per Second: 10,822.81582

Timestep Collection Time: 2.13655
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.62005

Cumulative Model Updates: 240,558
Cumulative Timesteps: 2,006,280,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2006280096...
Checkpoint 2006280096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.96279
Policy Entropy: 2.27484
Value Function Loss: 0.01587

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.63224

Collected Steps per Second: 22,686.24152
Overall Steps per Second: 10,690.12072

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.67815

Cumulative Model Updates: 240,564
Cumulative Timesteps: 2,006,330,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.79544
Policy Entropy: 2.29070
Value Function Loss: 0.01710

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.53577
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 22,792.79042
Overall Steps per Second: 10,862.03019

Timestep Collection Time: 2.19420
Timestep Consumption Time: 2.41009
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.60430

Cumulative Model Updates: 240,570
Cumulative Timesteps: 2,006,380,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2006380118...
Checkpoint 2006380118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.68575
Policy Entropy: 2.26553
Value Function Loss: 0.01736

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.54146
Value Function Update Magnitude: 0.61579

Collected Steps per Second: 22,890.69881
Overall Steps per Second: 10,756.97473

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.64945

Cumulative Model Updates: 240,576
Cumulative Timesteps: 2,006,430,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.68988
Policy Entropy: 2.24933
Value Function Loss: 0.01750

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.61603

Collected Steps per Second: 22,519.49387
Overall Steps per Second: 10,718.86877

Timestep Collection Time: 2.22128
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.66672

Cumulative Model Updates: 240,582
Cumulative Timesteps: 2,006,480,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2006480154...
Checkpoint 2006480154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.16961
Policy Entropy: 2.23331
Value Function Loss: 0.01734

Mean KL Divergence: 0.02512
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.61579

Collected Steps per Second: 22,578.96746
Overall Steps per Second: 10,603.55551

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.71578

Cumulative Model Updates: 240,588
Cumulative Timesteps: 2,006,530,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.80371
Policy Entropy: 2.28388
Value Function Loss: 0.01708

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 23,251.73895
Overall Steps per Second: 10,887.84520

Timestep Collection Time: 2.15038
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.59228

Cumulative Model Updates: 240,594
Cumulative Timesteps: 2,006,580,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2006580158...
Checkpoint 2006580158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.65354
Policy Entropy: 2.27495
Value Function Loss: 0.01824

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 23,213.35082
Overall Steps per Second: 10,806.89355

Timestep Collection Time: 2.15514
Timestep Consumption Time: 2.47413
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.62927

Cumulative Model Updates: 240,600
Cumulative Timesteps: 2,006,630,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.29182
Policy Entropy: 2.26565
Value Function Loss: 0.01836

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.62097

Collected Steps per Second: 23,104.73662
Overall Steps per Second: 10,755.04325

Timestep Collection Time: 2.16527
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.65159

Cumulative Model Updates: 240,606
Cumulative Timesteps: 2,006,680,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2006680214...
Checkpoint 2006680214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.26979
Policy Entropy: 2.24553
Value Function Loss: 0.01907

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.54826
Value Function Update Magnitude: 0.64224

Collected Steps per Second: 23,039.68485
Overall Steps per Second: 10,807.66529

Timestep Collection Time: 2.17052
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.62709

Cumulative Model Updates: 240,612
Cumulative Timesteps: 2,006,730,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.07759
Policy Entropy: 2.28191
Value Function Loss: 0.01889

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.54589
Value Function Update Magnitude: 0.64690

Collected Steps per Second: 23,132.61578
Overall Steps per Second: 10,786.73760

Timestep Collection Time: 2.16275
Timestep Consumption Time: 2.47536
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.63810

Cumulative Model Updates: 240,618
Cumulative Timesteps: 2,006,780,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2006780252...
Checkpoint 2006780252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.86015
Policy Entropy: 2.29383
Value Function Loss: 0.01896

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.64375

Collected Steps per Second: 23,430.99512
Overall Steps per Second: 10,967.70257

Timestep Collection Time: 2.13410
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.55920

Cumulative Model Updates: 240,624
Cumulative Timesteps: 2,006,830,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.35382
Policy Entropy: 2.28590
Value Function Loss: 0.01749

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.62959

Collected Steps per Second: 22,393.68975
Overall Steps per Second: 10,563.35529

Timestep Collection Time: 2.23322
Timestep Consumption Time: 2.50107
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.73429

Cumulative Model Updates: 240,630
Cumulative Timesteps: 2,006,880,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2006880266...
Checkpoint 2006880266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.74568
Policy Entropy: 2.26279
Value Function Loss: 0.01698

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.53019
Value Function Update Magnitude: 0.59918

Collected Steps per Second: 22,513.70954
Overall Steps per Second: 10,651.60085

Timestep Collection Time: 2.22185
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.69620

Cumulative Model Updates: 240,636
Cumulative Timesteps: 2,006,930,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.17849
Policy Entropy: 2.24952
Value Function Loss: 0.01679

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.53337
Value Function Update Magnitude: 0.58974

Collected Steps per Second: 22,678.29781
Overall Steps per Second: 10,890.23384

Timestep Collection Time: 2.20572
Timestep Consumption Time: 2.38757
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.59329

Cumulative Model Updates: 240,642
Cumulative Timesteps: 2,006,980,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2006980310...
Checkpoint 2006980310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.87092
Policy Entropy: 2.24845
Value Function Loss: 0.01653

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.53105
Value Function Update Magnitude: 0.59494

Collected Steps per Second: 22,823.41782
Overall Steps per Second: 10,611.52750

Timestep Collection Time: 2.19205
Timestep Consumption Time: 2.52264
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71468

Cumulative Model Updates: 240,648
Cumulative Timesteps: 2,007,030,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.02069
Policy Entropy: 2.25054
Value Function Loss: 0.01730

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.59975

Collected Steps per Second: 22,887.32692
Overall Steps per Second: 10,694.49690

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.49198
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.67773

Cumulative Model Updates: 240,654
Cumulative Timesteps: 2,007,080,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2007080366...
Checkpoint 2007080366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.53234
Policy Entropy: 2.25522
Value Function Loss: 0.01693

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.62127

Collected Steps per Second: 23,164.55250
Overall Steps per Second: 10,847.63901

Timestep Collection Time: 2.15856
Timestep Consumption Time: 2.45093
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.60948

Cumulative Model Updates: 240,660
Cumulative Timesteps: 2,007,130,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.02667
Policy Entropy: 2.24860
Value Function Loss: 0.01753

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.53876
Value Function Update Magnitude: 0.63917

Collected Steps per Second: 21,868.17357
Overall Steps per Second: 10,633.63978

Timestep Collection Time: 2.28771
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.70469

Cumulative Model Updates: 240,666
Cumulative Timesteps: 2,007,180,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2007180396...
Checkpoint 2007180396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.09940
Policy Entropy: 2.22295
Value Function Loss: 0.01806

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.64954

Collected Steps per Second: 23,079.48743
Overall Steps per Second: 10,890.53052

Timestep Collection Time: 2.16669
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59170

Cumulative Model Updates: 240,672
Cumulative Timesteps: 2,007,230,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.42702
Policy Entropy: 2.22408
Value Function Loss: 0.01839

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.65234

Collected Steps per Second: 23,277.17642
Overall Steps per Second: 10,907.14070

Timestep Collection Time: 2.14863
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.58544

Cumulative Model Updates: 240,678
Cumulative Timesteps: 2,007,280,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2007280416...
Checkpoint 2007280416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.20813
Policy Entropy: 2.21793
Value Function Loss: 0.01797

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.64034

Collected Steps per Second: 22,896.34509
Overall Steps per Second: 10,741.95658

Timestep Collection Time: 2.18506
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.65744

Cumulative Model Updates: 240,684
Cumulative Timesteps: 2,007,330,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.96414
Policy Entropy: 2.23452
Value Function Loss: 0.01726

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.53425
Value Function Update Magnitude: 0.62351

Collected Steps per Second: 22,665.52871
Overall Steps per Second: 10,869.59781

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.39495
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.60183

Cumulative Model Updates: 240,690
Cumulative Timesteps: 2,007,380,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2007380466...
Checkpoint 2007380466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.11899
Policy Entropy: 2.26603
Value Function Loss: 0.01719

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.62343

Collected Steps per Second: 22,483.62040
Overall Steps per Second: 10,606.47572

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.49056
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.71467

Cumulative Model Updates: 240,696
Cumulative Timesteps: 2,007,430,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.37683
Policy Entropy: 2.26254
Value Function Loss: 0.01669

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 22,717.96143
Overall Steps per Second: 10,853.70903

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.40688
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60875

Cumulative Model Updates: 240,702
Cumulative Timesteps: 2,007,480,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2007480494...
Checkpoint 2007480494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.31947
Policy Entropy: 2.25375
Value Function Loss: 0.01717

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.60562

Collected Steps per Second: 22,734.72687
Overall Steps per Second: 10,879.30281

Timestep Collection Time: 2.20042
Timestep Consumption Time: 2.39785
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.59827

Cumulative Model Updates: 240,708
Cumulative Timesteps: 2,007,530,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.14259
Policy Entropy: 2.21145
Value Function Loss: 0.01653

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.53702
Value Function Update Magnitude: 0.62882

Collected Steps per Second: 23,288.63649
Overall Steps per Second: 10,774.94985

Timestep Collection Time: 2.14791
Timestep Consumption Time: 2.49452
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.64243

Cumulative Model Updates: 240,714
Cumulative Timesteps: 2,007,580,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2007580542...
Checkpoint 2007580542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.23895
Policy Entropy: 2.18805
Value Function Loss: 0.01835

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.55048
Value Function Update Magnitude: 0.66162

Collected Steps per Second: 23,063.94717
Overall Steps per Second: 10,697.78334

Timestep Collection Time: 2.16875
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.67574

Cumulative Model Updates: 240,720
Cumulative Timesteps: 2,007,630,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.65443
Policy Entropy: 2.19411
Value Function Loss: 0.01841

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.55513
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 23,107.48172
Overall Steps per Second: 10,804.58228

Timestep Collection Time: 2.16406
Timestep Consumption Time: 2.46416
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.62822

Cumulative Model Updates: 240,726
Cumulative Timesteps: 2,007,680,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2007680568...
Checkpoint 2007680568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.46799
Policy Entropy: 2.20320
Value Function Loss: 0.01930

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.64280

Collected Steps per Second: 22,404.75192
Overall Steps per Second: 10,732.47282

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.42806
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.66062

Cumulative Model Updates: 240,732
Cumulative Timesteps: 2,007,730,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.93178
Policy Entropy: 2.24536
Value Function Loss: 0.01807

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.63978

Collected Steps per Second: 23,008.85615
Overall Steps per Second: 10,852.79741

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.43403
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.60711

Cumulative Model Updates: 240,738
Cumulative Timesteps: 2,007,780,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2007780588...
Checkpoint 2007780588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.80214
Policy Entropy: 2.25778
Value Function Loss: 0.01689

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 22,517.15866
Overall Steps per Second: 10,612.09056

Timestep Collection Time: 2.22124
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.71311

Cumulative Model Updates: 240,744
Cumulative Timesteps: 2,007,830,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.00443
Policy Entropy: 2.27698
Value Function Loss: 0.01654

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.62544

Collected Steps per Second: 22,732.16704
Overall Steps per Second: 10,868.05947

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.40178
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.60193

Cumulative Model Updates: 240,750
Cumulative Timesteps: 2,007,880,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2007880618...
Checkpoint 2007880618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.53012
Policy Entropy: 2.25965
Value Function Loss: 0.01544

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.52457
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,384.36609
Overall Steps per Second: 10,734.50949

Timestep Collection Time: 2.23379
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.65806

Cumulative Model Updates: 240,756
Cumulative Timesteps: 2,007,930,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.93165
Policy Entropy: 2.26222
Value Function Loss: 0.01676

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.53008
Value Function Update Magnitude: 0.57290

Collected Steps per Second: 22,973.85998
Overall Steps per Second: 10,838.87205

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.43742
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.61450

Cumulative Model Updates: 240,762
Cumulative Timesteps: 2,007,980,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2007980636...
Checkpoint 2007980636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.21908
Policy Entropy: 2.25068
Value Function Loss: 0.01735

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.52939
Value Function Update Magnitude: 0.58147

Collected Steps per Second: 22,409.55233
Overall Steps per Second: 10,668.28513

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.45687
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.68923

Cumulative Model Updates: 240,768
Cumulative Timesteps: 2,008,030,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.03700
Policy Entropy: 2.26556
Value Function Loss: 0.01837

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.52613
Value Function Update Magnitude: 0.59474

Collected Steps per Second: 22,481.30292
Overall Steps per Second: 10,693.07092

Timestep Collection Time: 2.22523
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67836

Cumulative Model Updates: 240,774
Cumulative Timesteps: 2,008,080,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2008080688...
Checkpoint 2008080688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.34872
Policy Entropy: 2.26319
Value Function Loss: 0.01861

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.54379
Value Function Update Magnitude: 0.62697

Collected Steps per Second: 22,822.23368
Overall Steps per Second: 10,885.55735

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.40345
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.59526

Cumulative Model Updates: 240,780
Cumulative Timesteps: 2,008,130,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.59022
Policy Entropy: 2.28309
Value Function Loss: 0.01828

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.54178
Value Function Update Magnitude: 0.63210

Collected Steps per Second: 23,257.79494
Overall Steps per Second: 10,933.72097

Timestep Collection Time: 2.15068
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.57484

Cumulative Model Updates: 240,786
Cumulative Timesteps: 2,008,180,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2008180730...
Checkpoint 2008180730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.83752
Policy Entropy: 2.28150
Value Function Loss: 0.01776

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.53080
Value Function Update Magnitude: 0.62198

Collected Steps per Second: 22,911.77953
Overall Steps per Second: 10,727.44063

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.66244

Cumulative Model Updates: 240,792
Cumulative Timesteps: 2,008,230,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.27860
Policy Entropy: 2.25992
Value Function Loss: 0.01896

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.62100

Collected Steps per Second: 23,254.96920
Overall Steps per Second: 10,805.60706

Timestep Collection Time: 2.15008
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.62723

Cumulative Model Updates: 240,798
Cumulative Timesteps: 2,008,280,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2008280746...
Checkpoint 2008280746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.56355
Policy Entropy: 2.24627
Value Function Loss: 0.01890

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.64810

Collected Steps per Second: 22,808.93586
Overall Steps per Second: 10,977.12086

Timestep Collection Time: 2.19335
Timestep Consumption Time: 2.36413
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.55748

Cumulative Model Updates: 240,804
Cumulative Timesteps: 2,008,330,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.41893
Policy Entropy: 2.24349
Value Function Loss: 0.01812

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.65619

Collected Steps per Second: 22,736.77039
Overall Steps per Second: 10,669.79746

Timestep Collection Time: 2.19934
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.68669

Cumulative Model Updates: 240,810
Cumulative Timesteps: 2,008,380,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2008380780...
Checkpoint 2008380780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.74526
Policy Entropy: 2.24980
Value Function Loss: 0.01697

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.54187
Value Function Update Magnitude: 0.62824

Collected Steps per Second: 22,648.58142
Overall Steps per Second: 10,649.49309

Timestep Collection Time: 2.20941
Timestep Consumption Time: 2.48941
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.69882

Cumulative Model Updates: 240,816
Cumulative Timesteps: 2,008,430,820

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.22792
Policy Entropy: 2.26888
Value Function Loss: 0.01661

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.60801

Collected Steps per Second: 22,718.66029
Overall Steps per Second: 10,811.80081

Timestep Collection Time: 2.20189
Timestep Consumption Time: 2.42491
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.62680

Cumulative Model Updates: 240,822
Cumulative Timesteps: 2,008,480,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2008480844...
Checkpoint 2008480844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.79208
Policy Entropy: 2.28678
Value Function Loss: 0.01660

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.52137
Value Function Update Magnitude: 0.60049

Collected Steps per Second: 23,254.20945
Overall Steps per Second: 10,782.08904

Timestep Collection Time: 2.15092
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.63899

Cumulative Model Updates: 240,828
Cumulative Timesteps: 2,008,530,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.85329
Policy Entropy: 2.30070
Value Function Loss: 0.01669

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.52876
Value Function Update Magnitude: 0.60497

Collected Steps per Second: 23,101.37694
Overall Steps per Second: 10,759.50618

Timestep Collection Time: 2.16593
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.65040

Cumulative Model Updates: 240,834
Cumulative Timesteps: 2,008,580,898

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2008580898...
Checkpoint 2008580898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.99461
Policy Entropy: 2.25755
Value Function Loss: 0.01667

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.53118
Value Function Update Magnitude: 0.61873

Collected Steps per Second: 23,019.33421
Overall Steps per Second: 10,705.95611

Timestep Collection Time: 2.17287
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.67198

Cumulative Model Updates: 240,840
Cumulative Timesteps: 2,008,630,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.58062
Policy Entropy: 2.24246
Value Function Loss: 0.01633

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.52807
Value Function Update Magnitude: 0.62220

Collected Steps per Second: 23,190.73042
Overall Steps per Second: 10,916.88827

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.58024

Cumulative Model Updates: 240,846
Cumulative Timesteps: 2,008,680,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2008680918...
Checkpoint 2008680918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.92185
Policy Entropy: 2.23982
Value Function Loss: 0.01669

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.62327

Collected Steps per Second: 23,096.62419
Overall Steps per Second: 10,776.03762

Timestep Collection Time: 2.16516
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.64067

Cumulative Model Updates: 240,852
Cumulative Timesteps: 2,008,730,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.53623
Policy Entropy: 2.26367
Value Function Loss: 0.01666

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.63534

Collected Steps per Second: 23,391.35350
Overall Steps per Second: 10,806.99953

Timestep Collection Time: 2.13874
Timestep Consumption Time: 2.49048
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.62922

Cumulative Model Updates: 240,858
Cumulative Timesteps: 2,008,780,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2008780954...
Checkpoint 2008780954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.10602
Policy Entropy: 2.24791
Value Function Loss: 0.01750

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.62204

Collected Steps per Second: 23,119.58854
Overall Steps per Second: 10,947.57624

Timestep Collection Time: 2.16336
Timestep Consumption Time: 2.40532
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.56868

Cumulative Model Updates: 240,864
Cumulative Timesteps: 2,008,830,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.98302
Policy Entropy: 2.26204
Value Function Loss: 0.01732

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 23,205.78224
Overall Steps per Second: 10,981.49203

Timestep Collection Time: 2.15584
Timestep Consumption Time: 2.39982
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.55567

Cumulative Model Updates: 240,870
Cumulative Timesteps: 2,008,880,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2008880998...
Checkpoint 2008880998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.56070
Policy Entropy: 2.24990
Value Function Loss: 0.01758

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.52419
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 22,619.41060
Overall Steps per Second: 10,609.26734

Timestep Collection Time: 2.21120
Timestep Consumption Time: 2.50317
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.71437

Cumulative Model Updates: 240,876
Cumulative Timesteps: 2,008,931,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.05762
Policy Entropy: 2.26970
Value Function Loss: 0.01857

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.53513
Value Function Update Magnitude: 0.61068

Collected Steps per Second: 22,754.20578
Overall Steps per Second: 10,823.66414

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.42366
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.62246

Cumulative Model Updates: 240,882
Cumulative Timesteps: 2,008,981,046

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2008981046...
Checkpoint 2008981046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.71700
Policy Entropy: 2.26302
Value Function Loss: 0.01784

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.53091
Value Function Update Magnitude: 0.62886

Collected Steps per Second: 22,138.71870
Overall Steps per Second: 10,703.28438

Timestep Collection Time: 2.25867
Timestep Consumption Time: 2.41317
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.67184

Cumulative Model Updates: 240,888
Cumulative Timesteps: 2,009,031,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.96203
Policy Entropy: 2.29444
Value Function Loss: 0.01784

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.52834
Value Function Update Magnitude: 0.63113

Collected Steps per Second: 22,875.03709
Overall Steps per Second: 10,960.58697

Timestep Collection Time: 2.18605
Timestep Consumption Time: 2.37630
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.56235

Cumulative Model Updates: 240,894
Cumulative Timesteps: 2,009,081,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2009081056...
Checkpoint 2009081056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.47198
Policy Entropy: 2.29611
Value Function Loss: 0.01656

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.62940

Collected Steps per Second: 22,266.61935
Overall Steps per Second: 10,658.77807

Timestep Collection Time: 2.24659
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.69322

Cumulative Model Updates: 240,900
Cumulative Timesteps: 2,009,131,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.28496
Policy Entropy: 2.26441
Value Function Loss: 0.01790

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.54817
Value Function Update Magnitude: 0.62967

Collected Steps per Second: 22,700.83474
Overall Steps per Second: 10,777.80927

Timestep Collection Time: 2.20336
Timestep Consumption Time: 2.43748
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.64083

Cumulative Model Updates: 240,906
Cumulative Timesteps: 2,009,181,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2009181098...
Checkpoint 2009181098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.96249
Policy Entropy: 2.26289
Value Function Loss: 0.01750

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.54558
Value Function Update Magnitude: 0.63409

Collected Steps per Second: 22,377.68747
Overall Steps per Second: 10,715.19858

Timestep Collection Time: 2.23473
Timestep Consumption Time: 2.43229
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.66702

Cumulative Model Updates: 240,912
Cumulative Timesteps: 2,009,231,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.94990
Policy Entropy: 2.26155
Value Function Loss: 0.01803

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.63600

Collected Steps per Second: 23,667.59758
Overall Steps per Second: 10,982.91248

Timestep Collection Time: 2.11352
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.55453

Cumulative Model Updates: 240,918
Cumulative Timesteps: 2,009,281,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2009281128...
Checkpoint 2009281128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.58176
Policy Entropy: 2.29070
Value Function Loss: 0.01852

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.63223

Collected Steps per Second: 23,084.46731
Overall Steps per Second: 10,757.59541

Timestep Collection Time: 2.16691
Timestep Consumption Time: 2.48301
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.64992

Cumulative Model Updates: 240,924
Cumulative Timesteps: 2,009,331,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.45882
Policy Entropy: 2.30455
Value Function Loss: 0.01776

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.53335
Value Function Update Magnitude: 0.62481

Collected Steps per Second: 23,243.20201
Overall Steps per Second: 10,783.93962

Timestep Collection Time: 2.15134
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.63690

Cumulative Model Updates: 240,930
Cumulative Timesteps: 2,009,381,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2009381154...
Checkpoint 2009381154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.56824
Policy Entropy: 2.29648
Value Function Loss: 0.01726

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.53126
Value Function Update Magnitude: 0.60067

Collected Steps per Second: 22,856.92344
Overall Steps per Second: 10,993.59308

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.36068
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.54829

Cumulative Model Updates: 240,936
Cumulative Timesteps: 2,009,431,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.14292
Policy Entropy: 2.30299
Value Function Loss: 0.01595

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.52616
Value Function Update Magnitude: 0.58217

Collected Steps per Second: 23,316.26457
Overall Steps per Second: 10,935.93549

Timestep Collection Time: 2.14528
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.57391

Cumulative Model Updates: 240,942
Cumulative Timesteps: 2,009,481,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2009481176...
Checkpoint 2009481176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.56630
Policy Entropy: 2.28301
Value Function Loss: 0.01758

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.52972
Value Function Update Magnitude: 0.59035

Collected Steps per Second: 22,717.70108
Overall Steps per Second: 10,671.91717

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.68557

Cumulative Model Updates: 240,948
Cumulative Timesteps: 2,009,531,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.27557
Policy Entropy: 2.28374
Value Function Loss: 0.01760

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.53797
Value Function Update Magnitude: 0.61922

Collected Steps per Second: 22,580.36643
Overall Steps per Second: 10,819.62827

Timestep Collection Time: 2.21511
Timestep Consumption Time: 2.40778
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62289

Cumulative Model Updates: 240,954
Cumulative Timesteps: 2,009,581,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2009581198...
Checkpoint 2009581198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.88543
Policy Entropy: 2.29715
Value Function Loss: 0.01836

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.62134

Collected Steps per Second: 22,505.50012
Overall Steps per Second: 10,749.10274

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.65174

Cumulative Model Updates: 240,960
Cumulative Timesteps: 2,009,631,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.64073
Policy Entropy: 2.25979
Value Function Loss: 0.01871

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.60664

Collected Steps per Second: 22,319.77471
Overall Steps per Second: 10,577.42384

Timestep Collection Time: 2.24178
Timestep Consumption Time: 2.48867
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.73045

Cumulative Model Updates: 240,966
Cumulative Timesteps: 2,009,681,236

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2009681236...
Checkpoint 2009681236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.34493
Policy Entropy: 2.26447
Value Function Loss: 0.01838

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.60673

Collected Steps per Second: 22,614.73553
Overall Steps per Second: 10,605.75869

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.71536

Cumulative Model Updates: 240,972
Cumulative Timesteps: 2,009,731,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.81418
Policy Entropy: 2.25275
Value Function Loss: 0.01745

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.60591

Collected Steps per Second: 23,011.41249
Overall Steps per Second: 10,791.38018

Timestep Collection Time: 2.17353
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.63481

Cumulative Model Updates: 240,978
Cumulative Timesteps: 2,009,781,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2009781262...
Checkpoint 2009781262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.63994
Policy Entropy: 2.28795
Value Function Loss: 0.01680

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.53182
Value Function Update Magnitude: 0.60228

Collected Steps per Second: 23,204.82726
Overall Steps per Second: 11,101.63420

Timestep Collection Time: 2.15533
Timestep Consumption Time: 2.34978
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.50510

Cumulative Model Updates: 240,984
Cumulative Timesteps: 2,009,831,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.20636
Policy Entropy: 2.26728
Value Function Loss: 0.01701

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.53841
Value Function Update Magnitude: 0.58862

Collected Steps per Second: 22,491.07241
Overall Steps per Second: 10,642.83520

Timestep Collection Time: 2.22417
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.70025

Cumulative Model Updates: 240,990
Cumulative Timesteps: 2,009,881,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2009881300...
Checkpoint 2009881300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.19308
Policy Entropy: 2.24992
Value Function Loss: 0.01809

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.53824
Value Function Update Magnitude: 0.58096

Collected Steps per Second: 23,032.43828
Overall Steps per Second: 10,879.43767

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59711

Cumulative Model Updates: 240,996
Cumulative Timesteps: 2,009,931,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.45896
Policy Entropy: 2.22966
Value Function Loss: 0.01838

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.54033
Value Function Update Magnitude: 0.59281

Collected Steps per Second: 22,930.04809
Overall Steps per Second: 10,889.20732

Timestep Collection Time: 2.18124
Timestep Consumption Time: 2.41193
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.59317

Cumulative Model Updates: 241,002
Cumulative Timesteps: 2,009,981,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2009981330...
Checkpoint 2009981330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.18217
Policy Entropy: 2.25283
Value Function Loss: 0.01758

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.59970

Collected Steps per Second: 22,409.61166
Overall Steps per Second: 10,755.05829

Timestep Collection Time: 2.23199
Timestep Consumption Time: 2.41866
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.65065

Cumulative Model Updates: 241,008
Cumulative Timesteps: 2,010,031,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.54533
Policy Entropy: 2.27656
Value Function Loss: 0.01632

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.52787
Value Function Update Magnitude: 0.60109

Collected Steps per Second: 22,861.77121
Overall Steps per Second: 10,828.93675

Timestep Collection Time: 2.18776
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61874

Cumulative Model Updates: 241,014
Cumulative Timesteps: 2,010,081,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2010081364...
Checkpoint 2010081364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.96400
Policy Entropy: 2.29396
Value Function Loss: 0.01531

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.51544
Value Function Update Magnitude: 0.57867

Collected Steps per Second: 22,680.59328
Overall Steps per Second: 10,664.50315

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69014

Cumulative Model Updates: 241,020
Cumulative Timesteps: 2,010,131,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.16442
Policy Entropy: 2.29363
Value Function Loss: 0.01546

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.51390
Value Function Update Magnitude: 0.56883

Collected Steps per Second: 23,033.35508
Overall Steps per Second: 10,863.67899

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.43251
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.60397

Cumulative Model Updates: 241,026
Cumulative Timesteps: 2,010,181,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2010181398...
Checkpoint 2010181398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.06260
Policy Entropy: 2.31790
Value Function Loss: 0.01631

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.52204
Value Function Update Magnitude: 0.58079

Collected Steps per Second: 22,904.60335
Overall Steps per Second: 11,009.26251

Timestep Collection Time: 2.18393
Timestep Consumption Time: 2.35970
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.54363

Cumulative Model Updates: 241,032
Cumulative Timesteps: 2,010,231,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.03233
Policy Entropy: 2.30884
Value Function Loss: 0.01670

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.52539
Value Function Update Magnitude: 0.60181

Collected Steps per Second: 22,922.74428
Overall Steps per Second: 10,690.02267

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.68025

Cumulative Model Updates: 241,038
Cumulative Timesteps: 2,010,281,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2010281452...
Checkpoint 2010281452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.15001
Policy Entropy: 2.31016
Value Function Loss: 0.01675

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.51941
Value Function Update Magnitude: 0.59626

Collected Steps per Second: 22,828.38924
Overall Steps per Second: 10,729.15141

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.47113
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.66244

Cumulative Model Updates: 241,044
Cumulative Timesteps: 2,010,331,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.98654
Policy Entropy: 2.27625
Value Function Loss: 0.01633

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.51301
Value Function Update Magnitude: 0.59645

Collected Steps per Second: 23,093.02371
Overall Steps per Second: 10,759.07131

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.65170

Cumulative Model Updates: 241,050
Cumulative Timesteps: 2,010,381,524

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2010381524...
Checkpoint 2010381524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.92227
Policy Entropy: 2.29199
Value Function Loss: 0.01574

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.50541
Value Function Update Magnitude: 0.57306

Collected Steps per Second: 23,807.15689
Overall Steps per Second: 11,061.14528

Timestep Collection Time: 2.10038
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.52069

Cumulative Model Updates: 241,056
Cumulative Timesteps: 2,010,431,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.72834
Policy Entropy: 2.27054
Value Function Loss: 0.01703

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.52224
Value Function Update Magnitude: 0.57220

Collected Steps per Second: 22,372.43538
Overall Steps per Second: 10,580.55619

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.72716

Cumulative Model Updates: 241,062
Cumulative Timesteps: 2,010,481,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2010481544...
Checkpoint 2010481544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.73238
Policy Entropy: 2.31111
Value Function Loss: 0.01645

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.53081
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 22,658.72933
Overall Steps per Second: 10,664.60791

Timestep Collection Time: 2.20763
Timestep Consumption Time: 2.48284
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.69047

Cumulative Model Updates: 241,068
Cumulative Timesteps: 2,010,531,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.94377
Policy Entropy: 2.30360
Value Function Loss: 0.01623

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.52038
Value Function Update Magnitude: 0.59572

Collected Steps per Second: 22,848.94448
Overall Steps per Second: 10,844.94914

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.42342
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.61284

Cumulative Model Updates: 241,074
Cumulative Timesteps: 2,010,581,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2010581592...
Checkpoint 2010581592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.80098
Policy Entropy: 2.31866
Value Function Loss: 0.01596

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.52014
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 23,282.55767
Overall Steps per Second: 10,746.71473

Timestep Collection Time: 2.14873
Timestep Consumption Time: 2.50646
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.65519

Cumulative Model Updates: 241,080
Cumulative Timesteps: 2,010,631,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.95972
Policy Entropy: 2.28892
Value Function Loss: 0.01644

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.52418
Value Function Update Magnitude: 0.58095

Collected Steps per Second: 23,433.07094
Overall Steps per Second: 10,778.51621

Timestep Collection Time: 2.13416
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.63979

Cumulative Model Updates: 241,086
Cumulative Timesteps: 2,010,681,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2010681630...
Checkpoint 2010681630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.63651
Policy Entropy: 2.30160
Value Function Loss: 0.01705

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.53827
Value Function Update Magnitude: 0.57881

Collected Steps per Second: 22,931.84632
Overall Steps per Second: 10,800.57100

Timestep Collection Time: 2.18133
Timestep Consumption Time: 2.45009
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.63142

Cumulative Model Updates: 241,092
Cumulative Timesteps: 2,010,731,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.29105
Policy Entropy: 2.33023
Value Function Loss: 0.01636

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.53210
Value Function Update Magnitude: 0.56047

Collected Steps per Second: 23,192.13990
Overall Steps per Second: 11,066.23252

Timestep Collection Time: 2.15608
Timestep Consumption Time: 2.36254
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.51861

Cumulative Model Updates: 241,098
Cumulative Timesteps: 2,010,781,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2010781656...
Checkpoint 2010781656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.93782
Policy Entropy: 2.32191
Value Function Loss: 0.01659

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.52857
Value Function Update Magnitude: 0.56462

Collected Steps per Second: 22,904.01202
Overall Steps per Second: 10,707.78814

Timestep Collection Time: 2.18363
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.67081

Cumulative Model Updates: 241,104
Cumulative Timesteps: 2,010,831,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.89507
Policy Entropy: 2.27962
Value Function Loss: 0.01742

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.53449
Value Function Update Magnitude: 0.58900

Collected Steps per Second: 23,353.43860
Overall Steps per Second: 10,983.18781

Timestep Collection Time: 2.14264
Timestep Consumption Time: 2.41323
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.55587

Cumulative Model Updates: 241,110
Cumulative Timesteps: 2,010,881,708

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2010881708...
Checkpoint 2010881708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.73893
Policy Entropy: 2.24401
Value Function Loss: 0.01924

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.61635

Collected Steps per Second: 22,418.73544
Overall Steps per Second: 10,633.59525

Timestep Collection Time: 2.23153
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.70471

Cumulative Model Updates: 241,116
Cumulative Timesteps: 2,010,931,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.96460
Policy Entropy: 2.23341
Value Function Loss: 0.01951

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.16798
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.63023

Collected Steps per Second: 22,590.08772
Overall Steps per Second: 10,817.88308

Timestep Collection Time: 2.21451
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62438

Cumulative Model Updates: 241,122
Cumulative Timesteps: 2,010,981,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2010981762...
Checkpoint 2010981762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.85289
Policy Entropy: 2.27990
Value Function Loss: 0.01882

Mean KL Divergence: 0.03136
SB3 Clip Fraction: 0.17298
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 23,172.38720
Overall Steps per Second: 10,672.26931

Timestep Collection Time: 2.15800
Timestep Consumption Time: 2.52760
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68560

Cumulative Model Updates: 241,128
Cumulative Timesteps: 2,011,031,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.42038
Policy Entropy: 2.27828
Value Function Loss: 0.01860

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.60950

Collected Steps per Second: 22,413.03089
Overall Steps per Second: 10,548.74743

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.51026
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.74217

Cumulative Model Updates: 241,134
Cumulative Timesteps: 2,011,081,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2011081792...
Checkpoint 2011081792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.21606
Policy Entropy: 2.28207
Value Function Loss: 0.01944

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.55274
Value Function Update Magnitude: 0.59712

Collected Steps per Second: 22,545.47254
Overall Steps per Second: 10,664.34831

Timestep Collection Time: 2.21898
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.69114

Cumulative Model Updates: 241,140
Cumulative Timesteps: 2,011,131,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.04096
Policy Entropy: 2.24702
Value Function Loss: 0.01886

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.61632

Collected Steps per Second: 23,392.52393
Overall Steps per Second: 11,019.03736

Timestep Collection Time: 2.13829
Timestep Consumption Time: 2.40113
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.53942

Cumulative Model Updates: 241,146
Cumulative Timesteps: 2,011,181,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2011181840...
Checkpoint 2011181840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.75989
Policy Entropy: 2.24136
Value Function Loss: 0.01873

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.55308
Value Function Update Magnitude: 0.61447

Collected Steps per Second: 23,012.77805
Overall Steps per Second: 10,877.99563

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.42421
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.59735

Cumulative Model Updates: 241,152
Cumulative Timesteps: 2,011,231,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.52844
Policy Entropy: 2.23999
Value Function Loss: 0.01804

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.60136

Collected Steps per Second: 23,059.49469
Overall Steps per Second: 10,856.76847

Timestep Collection Time: 2.16848
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60579

Cumulative Model Updates: 241,158
Cumulative Timesteps: 2,011,281,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2011281854...
Checkpoint 2011281854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.21553
Policy Entropy: 2.25209
Value Function Loss: 0.01776

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.60307

Collected Steps per Second: 22,906.51160
Overall Steps per Second: 10,698.95200

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.49196
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.67597

Cumulative Model Updates: 241,164
Cumulative Timesteps: 2,011,331,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.97429
Policy Entropy: 2.26199
Value Function Loss: 0.01679

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 24,212.82297
Overall Steps per Second: 10,936.55447

Timestep Collection Time: 2.06502
Timestep Consumption Time: 2.50680
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.57182

Cumulative Model Updates: 241,170
Cumulative Timesteps: 2,011,381,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2011381882...
Checkpoint 2011381882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.06325
Policy Entropy: 2.27715
Value Function Loss: 0.01584

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.52412
Value Function Update Magnitude: 0.60397

Collected Steps per Second: 22,779.90141
Overall Steps per Second: 10,629.26964

Timestep Collection Time: 2.19527
Timestep Consumption Time: 2.50948
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.70474

Cumulative Model Updates: 241,176
Cumulative Timesteps: 2,011,431,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.46442
Policy Entropy: 2.29570
Value Function Loss: 0.01593

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.51900
Value Function Update Magnitude: 0.60040

Collected Steps per Second: 22,599.37332
Overall Steps per Second: 10,659.28475

Timestep Collection Time: 2.21378
Timestep Consumption Time: 2.47978
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.69356

Cumulative Model Updates: 241,182
Cumulative Timesteps: 2,011,481,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2011481920...
Checkpoint 2011481920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.87866
Policy Entropy: 2.31057
Value Function Loss: 0.01697

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.53333
Value Function Update Magnitude: 0.61377

Collected Steps per Second: 22,604.85788
Overall Steps per Second: 10,852.24341

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.39677
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.60992

Cumulative Model Updates: 241,188
Cumulative Timesteps: 2,011,531,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.02580
Policy Entropy: 2.28434
Value Function Loss: 0.01735

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.60451

Collected Steps per Second: 23,809.92393
Overall Steps per Second: 10,984.88062

Timestep Collection Time: 2.10055
Timestep Consumption Time: 2.45243
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.55299

Cumulative Model Updates: 241,194
Cumulative Timesteps: 2,011,581,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2011581962...
Checkpoint 2011581962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.28318
Policy Entropy: 2.26091
Value Function Loss: 0.01815

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.60864

Collected Steps per Second: 22,627.13795
Overall Steps per Second: 10,631.59584

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.70372

Cumulative Model Updates: 241,200
Cumulative Timesteps: 2,011,631,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.99872
Policy Entropy: 2.23629
Value Function Loss: 0.01827

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.54519
Value Function Update Magnitude: 0.60290

Collected Steps per Second: 23,198.19248
Overall Steps per Second: 10,914.78220

Timestep Collection Time: 2.15637
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.58314

Cumulative Model Updates: 241,206
Cumulative Timesteps: 2,011,681,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2011681994...
Checkpoint 2011681994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.29460
Policy Entropy: 2.25569
Value Function Loss: 0.01860

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.61447

Collected Steps per Second: 22,922.31725
Overall Steps per Second: 10,785.72615

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.45516
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.63705

Cumulative Model Updates: 241,212
Cumulative Timesteps: 2,011,732,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.66644
Policy Entropy: 2.26464
Value Function Loss: 0.01829

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.62970

Collected Steps per Second: 23,227.68850
Overall Steps per Second: 11,003.70817

Timestep Collection Time: 2.15372
Timestep Consumption Time: 2.39256
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.54629

Cumulative Model Updates: 241,218
Cumulative Timesteps: 2,011,782,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2011782034...
Checkpoint 2011782034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.14883
Policy Entropy: 2.27947
Value Function Loss: 0.01795

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.61772

Collected Steps per Second: 23,357.25779
Overall Steps per Second: 10,888.57629

Timestep Collection Time: 2.14212
Timestep Consumption Time: 2.45297
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.59509

Cumulative Model Updates: 241,224
Cumulative Timesteps: 2,011,832,068

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.30566
Policy Entropy: 2.26652
Value Function Loss: 0.01783

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.61074

Collected Steps per Second: 23,004.81006
Overall Steps per Second: 10,863.25954

Timestep Collection Time: 2.17459
Timestep Consumption Time: 2.43047
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.60506

Cumulative Model Updates: 241,230
Cumulative Timesteps: 2,011,882,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2011882094...
Checkpoint 2011882094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.00133
Policy Entropy: 2.27655
Value Function Loss: 0.01796

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.62579

Collected Steps per Second: 22,843.73069
Overall Steps per Second: 10,893.95801

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.40159
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.59099

Cumulative Model Updates: 241,236
Cumulative Timesteps: 2,011,932,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.36667
Policy Entropy: 2.27929
Value Function Loss: 0.01737

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.53659
Value Function Update Magnitude: 0.62174

Collected Steps per Second: 23,114.91511
Overall Steps per Second: 10,739.46200

Timestep Collection Time: 2.16311
Timestep Consumption Time: 2.49262
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.65573

Cumulative Model Updates: 241,242
Cumulative Timesteps: 2,011,982,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2011982108...
Checkpoint 2011982108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.08277
Policy Entropy: 2.27497
Value Function Loss: 0.01761

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.53497
Value Function Update Magnitude: 0.60956

Collected Steps per Second: 22,609.26633
Overall Steps per Second: 10,632.82784

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.70261

Cumulative Model Updates: 241,248
Cumulative Timesteps: 2,012,032,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.46886
Policy Entropy: 2.25667
Value Function Loss: 0.01833

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.51915
Value Function Update Magnitude: 0.60586

Collected Steps per Second: 22,560.79965
Overall Steps per Second: 10,801.61511

Timestep Collection Time: 2.21641
Timestep Consumption Time: 2.41290
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.62931

Cumulative Model Updates: 241,254
Cumulative Timesteps: 2,012,082,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2012082114...
Checkpoint 2012082114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.09270
Policy Entropy: 2.23520
Value Function Loss: 0.01840

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.16410
Policy Update Magnitude: 0.51306
Value Function Update Magnitude: 0.61197

Collected Steps per Second: 22,580.19694
Overall Steps per Second: 10,781.41181

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.63947

Cumulative Model Updates: 241,260
Cumulative Timesteps: 2,012,132,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.45516
Policy Entropy: 2.24167
Value Function Loss: 0.01862

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.54873
Value Function Update Magnitude: 0.60823

Collected Steps per Second: 23,590.84018
Overall Steps per Second: 10,843.93866

Timestep Collection Time: 2.12023
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.61253

Cumulative Model Updates: 241,266
Cumulative Timesteps: 2,012,182,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2012182152...
Checkpoint 2012182152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.66438
Policy Entropy: 2.26890
Value Function Loss: 0.01678

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.59860

Collected Steps per Second: 22,904.80014
Overall Steps per Second: 10,683.78647

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.68167

Cumulative Model Updates: 241,272
Cumulative Timesteps: 2,012,232,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.64387
Policy Entropy: 2.26917
Value Function Loss: 0.01826

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.58421

Collected Steps per Second: 22,716.42357
Overall Steps per Second: 10,877.84042

Timestep Collection Time: 2.20105
Timestep Consumption Time: 2.39545
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.59650

Cumulative Model Updates: 241,278
Cumulative Timesteps: 2,012,282,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2012282170...
Checkpoint 2012282170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.02199
Policy Entropy: 2.25884
Value Function Loss: 0.01735

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.59308

Collected Steps per Second: 22,889.08644
Overall Steps per Second: 11,034.79773

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.34780
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.53330

Cumulative Model Updates: 241,284
Cumulative Timesteps: 2,012,332,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.37354
Policy Entropy: 2.23596
Value Function Loss: 0.01850

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 23,343.75655
Overall Steps per Second: 10,930.90863

Timestep Collection Time: 2.14310
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.57675

Cumulative Model Updates: 241,290
Cumulative Timesteps: 2,012,382,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2012382222...
Checkpoint 2012382222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.99152
Policy Entropy: 2.24409
Value Function Loss: 0.01826

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.54560
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 22,643.50874
Overall Steps per Second: 10,710.76154

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.66858

Cumulative Model Updates: 241,296
Cumulative Timesteps: 2,012,432,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.40191
Policy Entropy: 2.22846
Value Function Loss: 0.01810

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.53235
Value Function Update Magnitude: 0.64916

Collected Steps per Second: 22,652.15409
Overall Steps per Second: 10,820.62444

Timestep Collection Time: 2.20836
Timestep Consumption Time: 2.41467
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62302

Cumulative Model Updates: 241,302
Cumulative Timesteps: 2,012,482,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2012482250...
Checkpoint 2012482250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.32524
Policy Entropy: 2.23498
Value Function Loss: 0.01753

Mean KL Divergence: 0.02862
SB3 Clip Fraction: 0.16939
Policy Update Magnitude: 0.51608
Value Function Update Magnitude: 0.62448

Collected Steps per Second: 23,426.95074
Overall Steps per Second: 10,841.78624

Timestep Collection Time: 2.13515
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.61363

Cumulative Model Updates: 241,308
Cumulative Timesteps: 2,012,532,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.98345
Policy Entropy: 2.25900
Value Function Loss: 0.01739

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.63511

Collected Steps per Second: 23,102.93155
Overall Steps per Second: 10,802.74386

Timestep Collection Time: 2.16509
Timestep Consumption Time: 2.46521
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.63031

Cumulative Model Updates: 241,314
Cumulative Timesteps: 2,012,582,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2012582290...
Checkpoint 2012582290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.62884
Policy Entropy: 2.28013
Value Function Loss: 0.01740

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.62720

Collected Steps per Second: 22,467.25468
Overall Steps per Second: 10,613.37919

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.48697
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.71367

Cumulative Model Updates: 241,320
Cumulative Timesteps: 2,012,632,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.68351
Policy Entropy: 2.27999
Value Function Loss: 0.01773

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.62057

Collected Steps per Second: 23,187.84234
Overall Steps per Second: 10,911.83476

Timestep Collection Time: 2.15647
Timestep Consumption Time: 2.42607
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.58255

Cumulative Model Updates: 241,326
Cumulative Timesteps: 2,012,682,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2012682322...
Checkpoint 2012682322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.01732
Policy Entropy: 2.25208
Value Function Loss: 0.01776

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 23,104.07801
Overall Steps per Second: 10,759.63570

Timestep Collection Time: 2.16490
Timestep Consumption Time: 2.48377
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.64867

Cumulative Model Updates: 241,332
Cumulative Timesteps: 2,012,732,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.82048
Policy Entropy: 2.23149
Value Function Loss: 0.01769

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.61413

Collected Steps per Second: 23,401.56552
Overall Steps per Second: 10,798.77518

Timestep Collection Time: 2.13755
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.63219

Cumulative Model Updates: 241,338
Cumulative Timesteps: 2,012,782,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2012782362...
Checkpoint 2012782362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.21194
Policy Entropy: 2.26152
Value Function Loss: 0.01639

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.52751
Value Function Update Magnitude: 0.60516

Collected Steps per Second: 23,020.02213
Overall Steps per Second: 10,829.48309

Timestep Collection Time: 2.17220
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.61739

Cumulative Model Updates: 241,344
Cumulative Timesteps: 2,012,832,366

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.45165
Policy Entropy: 2.27455
Value Function Loss: 0.01638

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.53353
Value Function Update Magnitude: 0.57109

Collected Steps per Second: 23,017.41811
Overall Steps per Second: 10,894.03157

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.41808
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.59095

Cumulative Model Updates: 241,350
Cumulative Timesteps: 2,012,882,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2012882380...
Checkpoint 2012882380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.48577
Policy Entropy: 2.28429
Value Function Loss: 0.01657

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.52749
Value Function Update Magnitude: 0.56091

Collected Steps per Second: 22,852.38054
Overall Steps per Second: 10,850.58906

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.42028
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.60841

Cumulative Model Updates: 241,356
Cumulative Timesteps: 2,012,932,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.30633
Policy Entropy: 2.24454
Value Function Loss: 0.01759

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.53241
Value Function Update Magnitude: 0.57749

Collected Steps per Second: 21,492.96204
Overall Steps per Second: 10,477.70571

Timestep Collection Time: 2.32718
Timestep Consumption Time: 2.44657
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.77376

Cumulative Model Updates: 241,362
Cumulative Timesteps: 2,012,982,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2012982402...
Checkpoint 2012982402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.77102
Policy Entropy: 2.22916
Value Function Loss: 0.01799

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.58911

Collected Steps per Second: 22,491.34022
Overall Steps per Second: 10,676.61733

Timestep Collection Time: 2.22370
Timestep Consumption Time: 2.46074
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.68444

Cumulative Model Updates: 241,368
Cumulative Timesteps: 2,013,032,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.64280
Policy Entropy: 2.22495
Value Function Loss: 0.01798

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.58432

Collected Steps per Second: 23,389.06549
Overall Steps per Second: 10,974.48172

Timestep Collection Time: 2.13878
Timestep Consumption Time: 2.41943
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.55821

Cumulative Model Updates: 241,374
Cumulative Timesteps: 2,013,082,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2013082440...
Checkpoint 2013082440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.34074
Policy Entropy: 2.23509
Value Function Loss: 0.01780

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.53907
Value Function Update Magnitude: 0.57992

Collected Steps per Second: 22,767.17004
Overall Steps per Second: 10,611.28371

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.51602
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.71234

Cumulative Model Updates: 241,380
Cumulative Timesteps: 2,013,132,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.95183
Policy Entropy: 2.25506
Value Function Loss: 0.01839

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.60036

Collected Steps per Second: 23,456.02319
Overall Steps per Second: 10,901.96893

Timestep Collection Time: 2.13276
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.58871

Cumulative Model Updates: 241,386
Cumulative Timesteps: 2,013,182,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2013182470...
Checkpoint 2013182470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.36741
Policy Entropy: 2.24535
Value Function Loss: 0.01785

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.53963
Value Function Update Magnitude: 0.62342

Collected Steps per Second: 22,655.22806
Overall Steps per Second: 10,981.57377

Timestep Collection Time: 2.20788
Timestep Consumption Time: 2.34702
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.55490

Cumulative Model Updates: 241,392
Cumulative Timesteps: 2,013,232,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.22407
Policy Entropy: 2.27580
Value Function Loss: 0.01700

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.62404

Collected Steps per Second: 23,412.55605
Overall Steps per Second: 10,946.85551

Timestep Collection Time: 2.13629
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.56898

Cumulative Model Updates: 241,398
Cumulative Timesteps: 2,013,282,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2013282506...
Checkpoint 2013282506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.69588
Policy Entropy: 2.27915
Value Function Loss: 0.01661

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.60167

Collected Steps per Second: 23,013.54093
Overall Steps per Second: 10,687.23168

Timestep Collection Time: 2.17368
Timestep Consumption Time: 2.50705
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.68073

Cumulative Model Updates: 241,404
Cumulative Timesteps: 2,013,332,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.57881
Policy Entropy: 2.31081
Value Function Loss: 0.01669

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.58364

Collected Steps per Second: 23,522.45410
Overall Steps per Second: 10,929.04607

Timestep Collection Time: 2.12580
Timestep Consumption Time: 2.44953
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.57533

Cumulative Model Updates: 241,410
Cumulative Timesteps: 2,013,382,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2013382534...
Checkpoint 2013382534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.13600
Policy Entropy: 2.27379
Value Function Loss: 0.01846

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.57811

Collected Steps per Second: 22,976.82411
Overall Steps per Second: 11,068.52594

Timestep Collection Time: 2.17672
Timestep Consumption Time: 2.34186
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.51858

Cumulative Model Updates: 241,416
Cumulative Timesteps: 2,013,432,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.41958
Policy Entropy: 2.26114
Value Function Loss: 0.01817

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.60058

Collected Steps per Second: 22,799.60326
Overall Steps per Second: 10,714.40562

Timestep Collection Time: 2.19337
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.66736

Cumulative Model Updates: 241,422
Cumulative Timesteps: 2,013,482,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2013482556...
Checkpoint 2013482556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.72562
Policy Entropy: 2.22894
Value Function Loss: 0.01785

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.52846
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 22,802.69698
Overall Steps per Second: 10,845.35890

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61064

Cumulative Model Updates: 241,428
Cumulative Timesteps: 2,013,532,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.71174
Policy Entropy: 2.23995
Value Function Loss: 0.01695

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.52602
Value Function Update Magnitude: 0.62349

Collected Steps per Second: 22,785.61734
Overall Steps per Second: 10,703.37818

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.67292

Cumulative Model Updates: 241,434
Cumulative Timesteps: 2,013,582,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2013582576...
Checkpoint 2013582576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.07327
Policy Entropy: 2.22640
Value Function Loss: 0.01736

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.54379
Value Function Update Magnitude: 0.60842

Collected Steps per Second: 22,610.20986
Overall Steps per Second: 10,827.20767

Timestep Collection Time: 2.21210
Timestep Consumption Time: 2.40738
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61947

Cumulative Model Updates: 241,440
Cumulative Timesteps: 2,013,632,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.60142
Policy Entropy: 2.24207
Value Function Loss: 0.01756

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.61184

Collected Steps per Second: 23,015.88229
Overall Steps per Second: 11,012.43738

Timestep Collection Time: 2.17285
Timestep Consumption Time: 2.36838
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.54123

Cumulative Model Updates: 241,446
Cumulative Timesteps: 2,013,682,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2013682602...
Checkpoint 2013682602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.82141
Policy Entropy: 2.25350
Value Function Loss: 0.01737

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.52831
Value Function Update Magnitude: 0.61881

Collected Steps per Second: 22,949.68946
Overall Steps per Second: 10,719.85847

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.66536

Cumulative Model Updates: 241,452
Cumulative Timesteps: 2,013,732,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.94185
Policy Entropy: 2.27185
Value Function Loss: 0.01676

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.52441
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 23,252.26993
Overall Steps per Second: 10,814.66802

Timestep Collection Time: 2.15102
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.62483

Cumulative Model Updates: 241,458
Cumulative Timesteps: 2,013,782,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2013782630...
Checkpoint 2013782630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.37670
Policy Entropy: 2.27349
Value Function Loss: 0.01639

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.51224
Value Function Update Magnitude: 0.59067

Collected Steps per Second: 23,007.98322
Overall Steps per Second: 11,056.54333

Timestep Collection Time: 2.17333
Timestep Consumption Time: 2.34924
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.52257

Cumulative Model Updates: 241,464
Cumulative Timesteps: 2,013,832,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.95660
Policy Entropy: 2.24473
Value Function Loss: 0.01725

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.52216
Value Function Update Magnitude: 0.58633

Collected Steps per Second: 23,165.74171
Overall Steps per Second: 10,891.42314

Timestep Collection Time: 2.15922
Timestep Consumption Time: 2.43338
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.59260

Cumulative Model Updates: 241,470
Cumulative Timesteps: 2,013,882,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2013882654...
Checkpoint 2013882654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.61847
Policy Entropy: 2.24401
Value Function Loss: 0.01744

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.52794
Value Function Update Magnitude: 0.58539

Collected Steps per Second: 22,697.22589
Overall Steps per Second: 10,704.89717

Timestep Collection Time: 2.20353
Timestep Consumption Time: 2.46854
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.67207

Cumulative Model Updates: 241,476
Cumulative Timesteps: 2,013,932,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.41365
Policy Entropy: 2.24435
Value Function Loss: 0.01800

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.53007
Value Function Update Magnitude: 0.59809

Collected Steps per Second: 22,648.11675
Overall Steps per Second: 10,667.27411

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.48113
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69023

Cumulative Model Updates: 241,482
Cumulative Timesteps: 2,013,982,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2013982700...
Checkpoint 2013982700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.35059
Policy Entropy: 2.27488
Value Function Loss: 0.01697

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.53176
Value Function Update Magnitude: 0.61086

Collected Steps per Second: 22,620.00357
Overall Steps per Second: 10,834.33336

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.40510
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61607

Cumulative Model Updates: 241,488
Cumulative Timesteps: 2,014,032,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.66651
Policy Entropy: 2.27720
Value Function Loss: 0.01733

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.52511
Value Function Update Magnitude: 0.62417

Collected Steps per Second: 23,939.26080
Overall Steps per Second: 10,931.30624

Timestep Collection Time: 2.08879
Timestep Consumption Time: 2.48560
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.57438

Cumulative Model Updates: 241,494
Cumulative Timesteps: 2,014,082,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2014082716...
Checkpoint 2014082716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.68433
Policy Entropy: 2.29709
Value Function Loss: 0.01576

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.51354
Value Function Update Magnitude: 0.61103

Collected Steps per Second: 22,723.33475
Overall Steps per Second: 10,672.67217

Timestep Collection Time: 2.20117
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.68655

Cumulative Model Updates: 241,500
Cumulative Timesteps: 2,014,132,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.54992
Policy Entropy: 2.29715
Value Function Loss: 0.01597

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.51118
Value Function Update Magnitude: 0.58314

Collected Steps per Second: 23,455.11437
Overall Steps per Second: 10,921.59798

Timestep Collection Time: 2.13267
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.58010

Cumulative Model Updates: 241,506
Cumulative Timesteps: 2,014,182,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2014182756...
Checkpoint 2014182756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.31257
Policy Entropy: 2.26655
Value Function Loss: 0.01751

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.52638
Value Function Update Magnitude: 0.58160

Collected Steps per Second: 22,919.09760
Overall Steps per Second: 10,770.82339

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.46157
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.64403

Cumulative Model Updates: 241,512
Cumulative Timesteps: 2,014,232,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.26066
Policy Entropy: 2.24062
Value Function Loss: 0.01751

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.53606
Value Function Update Magnitude: 0.62417

Collected Steps per Second: 23,169.51306
Overall Steps per Second: 10,961.23953

Timestep Collection Time: 2.15913
Timestep Consumption Time: 2.40477
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.56390

Cumulative Model Updates: 241,518
Cumulative Timesteps: 2,014,282,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2014282802...
Checkpoint 2014282802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.93395
Policy Entropy: 2.23135
Value Function Loss: 0.01751

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.53636
Value Function Update Magnitude: 0.64823

Collected Steps per Second: 23,072.40767
Overall Steps per Second: 10,880.04997

Timestep Collection Time: 2.16813
Timestep Consumption Time: 2.42964
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.59777

Cumulative Model Updates: 241,524
Cumulative Timesteps: 2,014,332,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.88083
Policy Entropy: 2.24561
Value Function Loss: 0.01552

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.53369
Value Function Update Magnitude: 0.62301

Collected Steps per Second: 22,473.51273
Overall Steps per Second: 10,629.71937

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.70473

Cumulative Model Updates: 241,530
Cumulative Timesteps: 2,014,382,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2014382836...
Checkpoint 2014382836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.56387
Policy Entropy: 2.25209
Value Function Loss: 0.01551

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.51824
Value Function Update Magnitude: 0.58686

Collected Steps per Second: 22,240.18762
Overall Steps per Second: 10,615.28414

Timestep Collection Time: 2.24926
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.71245

Cumulative Model Updates: 241,536
Cumulative Timesteps: 2,014,432,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.27966
Policy Entropy: 2.25412
Value Function Loss: 0.01575

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.51210
Value Function Update Magnitude: 0.57089

Collected Steps per Second: 22,764.83654
Overall Steps per Second: 10,805.90211

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.43229
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.63006

Cumulative Model Updates: 241,542
Cumulative Timesteps: 2,014,482,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2014482892...
Checkpoint 2014482892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.99618
Policy Entropy: 2.25931
Value Function Loss: 0.01707

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.51614
Value Function Update Magnitude: 0.56329

Collected Steps per Second: 22,612.18026
Overall Steps per Second: 10,595.51740

Timestep Collection Time: 2.21146
Timestep Consumption Time: 2.50808
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.71954

Cumulative Model Updates: 241,548
Cumulative Timesteps: 2,014,532,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.87660
Policy Entropy: 2.27741
Value Function Loss: 0.01680

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.52653
Value Function Update Magnitude: 0.56413

Collected Steps per Second: 23,337.31216
Overall Steps per Second: 10,926.17474

Timestep Collection Time: 2.14309
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.57745

Cumulative Model Updates: 241,554
Cumulative Timesteps: 2,014,582,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2014582912...
Checkpoint 2014582912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.57636
Policy Entropy: 2.26878
Value Function Loss: 0.01732

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.57569

Collected Steps per Second: 23,007.74609
Overall Steps per Second: 11,007.87674

Timestep Collection Time: 2.17336
Timestep Consumption Time: 2.36921
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.54257

Cumulative Model Updates: 241,560
Cumulative Timesteps: 2,014,632,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.43218
Policy Entropy: 2.26922
Value Function Loss: 0.01644

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.53651
Value Function Update Magnitude: 0.59625

Collected Steps per Second: 23,187.03447
Overall Steps per Second: 10,926.71738

Timestep Collection Time: 2.15681
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.57685

Cumulative Model Updates: 241,566
Cumulative Timesteps: 2,014,682,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2014682926...
Checkpoint 2014682926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.51021
Policy Entropy: 2.23888
Value Function Loss: 0.01691

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.53496
Value Function Update Magnitude: 0.60325

Collected Steps per Second: 23,002.91707
Overall Steps per Second: 10,705.84788

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.49811
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.67296

Cumulative Model Updates: 241,572
Cumulative Timesteps: 2,014,732,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.38937
Policy Entropy: 2.24764
Value Function Loss: 0.01631

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.52925
Value Function Update Magnitude: 0.59446

Collected Steps per Second: 23,491.15218
Overall Steps per Second: 10,954.40038

Timestep Collection Time: 2.12880
Timestep Consumption Time: 2.43630
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.56511

Cumulative Model Updates: 241,578
Cumulative Timesteps: 2,014,782,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2014782962...
Checkpoint 2014782962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.61170
Policy Entropy: 2.23443
Value Function Loss: 0.01732

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.60161

Collected Steps per Second: 22,389.42040
Overall Steps per Second: 10,808.99728

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.39325
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.62707

Cumulative Model Updates: 241,584
Cumulative Timesteps: 2,014,832,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.76589
Policy Entropy: 2.23870
Value Function Loss: 0.01817

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.53995
Value Function Update Magnitude: 0.60341

Collected Steps per Second: 23,262.50791
Overall Steps per Second: 10,769.40100

Timestep Collection Time: 2.15050
Timestep Consumption Time: 2.49470
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.64520

Cumulative Model Updates: 241,590
Cumulative Timesteps: 2,014,883,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2014883002...
Checkpoint 2014883002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.54280
Policy Entropy: 2.23390
Value Function Loss: 0.01843

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.59808

Collected Steps per Second: 21,568.20126
Overall Steps per Second: 10,513.17835

Timestep Collection Time: 2.31878
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.75708

Cumulative Model Updates: 241,596
Cumulative Timesteps: 2,014,933,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.29595
Policy Entropy: 2.22861
Value Function Loss: 0.01664

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.52690
Value Function Update Magnitude: 0.57581

Collected Steps per Second: 23,038.59123
Overall Steps per Second: 10,760.32700

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.47653
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.64688

Cumulative Model Updates: 241,602
Cumulative Timesteps: 2,014,983,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2014983016...
Checkpoint 2014983016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.99834
Policy Entropy: 2.24022
Value Function Loss: 0.01564

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.51627
Value Function Update Magnitude: 0.54655

Collected Steps per Second: 22,415.76693
Overall Steps per Second: 10,764.54839

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.41430
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.64488

Cumulative Model Updates: 241,608
Cumulative Timesteps: 2,015,033,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.27978
Policy Entropy: 2.23697
Value Function Loss: 0.01506

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.51089
Value Function Update Magnitude: 0.54101

Collected Steps per Second: 24,189.67842
Overall Steps per Second: 10,977.25176

Timestep Collection Time: 2.06741
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.55579

Cumulative Model Updates: 241,614
Cumulative Timesteps: 2,015,083,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2015083026...
Checkpoint 2015083026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.99794
Policy Entropy: 2.24396
Value Function Loss: 0.01641

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.52150
Value Function Update Magnitude: 0.55523

Collected Steps per Second: 22,945.07758
Overall Steps per Second: 10,653.67576

Timestep Collection Time: 2.18016
Timestep Consumption Time: 2.51531
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.69547

Cumulative Model Updates: 241,620
Cumulative Timesteps: 2,015,133,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.69161
Policy Entropy: 2.24527
Value Function Loss: 0.01701

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.52521
Value Function Update Magnitude: 0.58597

Collected Steps per Second: 23,502.05860
Overall Steps per Second: 10,940.09673

Timestep Collection Time: 2.12807
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.57162

Cumulative Model Updates: 241,626
Cumulative Timesteps: 2,015,183,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2015183064...
Checkpoint 2015183064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.99137
Policy Entropy: 2.25739
Value Function Loss: 0.01776

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.53136
Value Function Update Magnitude: 0.59693

Collected Steps per Second: 22,955.94957
Overall Steps per Second: 11,035.65854

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.35353
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.53240

Cumulative Model Updates: 241,632
Cumulative Timesteps: 2,015,233,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.07419
Policy Entropy: 2.26455
Value Function Loss: 0.01799

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.60414

Collected Steps per Second: 23,124.93030
Overall Steps per Second: 10,893.11403

Timestep Collection Time: 2.16269
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.59116

Cumulative Model Updates: 241,638
Cumulative Timesteps: 2,015,283,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2015283094...
Checkpoint 2015283094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.39053
Policy Entropy: 2.24585
Value Function Loss: 0.01826

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.62258

Collected Steps per Second: 22,415.80626
Overall Steps per Second: 10,731.31636

Timestep Collection Time: 2.23101
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.66019

Cumulative Model Updates: 241,644
Cumulative Timesteps: 2,015,333,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.97371
Policy Entropy: 2.23372
Value Function Loss: 0.01816

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.61789

Collected Steps per Second: 23,053.43195
Overall Steps per Second: 10,882.61081

Timestep Collection Time: 2.16940
Timestep Consumption Time: 2.42619
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.59559

Cumulative Model Updates: 241,650
Cumulative Timesteps: 2,015,383,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2015383116...
Checkpoint 2015383116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.95062
Policy Entropy: 2.21032
Value Function Loss: 0.01829

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.60938

Collected Steps per Second: 22,449.15436
Overall Steps per Second: 10,654.55087

Timestep Collection Time: 2.22806
Timestep Consumption Time: 2.46646
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.69452

Cumulative Model Updates: 241,656
Cumulative Timesteps: 2,015,433,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.11800
Policy Entropy: 2.21176
Value Function Loss: 0.01830

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.60343

Collected Steps per Second: 23,153.32366
Overall Steps per Second: 10,934.95983

Timestep Collection Time: 2.16073
Timestep Consumption Time: 2.41432
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.57505

Cumulative Model Updates: 241,662
Cumulative Timesteps: 2,015,483,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2015483162...
Checkpoint 2015483162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.63933
Policy Entropy: 2.23030
Value Function Loss: 0.01796

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.59601

Collected Steps per Second: 22,827.39799
Overall Steps per Second: 10,659.28857

Timestep Collection Time: 2.19044
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.69093

Cumulative Model Updates: 241,668
Cumulative Timesteps: 2,015,533,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.70512
Policy Entropy: 2.24712
Value Function Loss: 0.01739

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.53464
Value Function Update Magnitude: 0.60137

Collected Steps per Second: 23,125.20693
Overall Steps per Second: 10,896.77476

Timestep Collection Time: 2.16283
Timestep Consumption Time: 2.42715
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.58998

Cumulative Model Updates: 241,674
Cumulative Timesteps: 2,015,583,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2015583180...
Checkpoint 2015583180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.76953
Policy Entropy: 2.26972
Value Function Loss: 0.01626

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.52669
Value Function Update Magnitude: 0.60377

Collected Steps per Second: 22,680.67766
Overall Steps per Second: 10,575.04525

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.52501
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.73076

Cumulative Model Updates: 241,680
Cumulative Timesteps: 2,015,633,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.79571
Policy Entropy: 2.25530
Value Function Loss: 0.01646

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.51747
Value Function Update Magnitude: 0.57936

Collected Steps per Second: 22,774.91748
Overall Steps per Second: 10,814.21142

Timestep Collection Time: 2.19575
Timestep Consumption Time: 2.42854
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.62429

Cumulative Model Updates: 241,686
Cumulative Timesteps: 2,015,683,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2015683216...
Checkpoint 2015683216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.54115
Policy Entropy: 2.26168
Value Function Loss: 0.01598

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.51521
Value Function Update Magnitude: 0.57210

Collected Steps per Second: 22,792.17023
Overall Steps per Second: 10,868.09802

Timestep Collection Time: 2.19514
Timestep Consumption Time: 2.40843
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.60357

Cumulative Model Updates: 241,692
Cumulative Timesteps: 2,015,733,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.13163
Policy Entropy: 2.26474
Value Function Loss: 0.01656

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.51590
Value Function Update Magnitude: 0.56700

Collected Steps per Second: 23,339.65138
Overall Steps per Second: 10,803.39680

Timestep Collection Time: 2.14296
Timestep Consumption Time: 2.48669
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.62965

Cumulative Model Updates: 241,698
Cumulative Timesteps: 2,015,783,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2015783264...
Checkpoint 2015783264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.06463
Policy Entropy: 2.27116
Value Function Loss: 0.01620

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.51524
Value Function Update Magnitude: 0.57241

Collected Steps per Second: 22,629.99092
Overall Steps per Second: 10,655.02662

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.48436
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.69487

Cumulative Model Updates: 241,704
Cumulative Timesteps: 2,015,833,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.98419
Policy Entropy: 2.27997
Value Function Loss: 0.01622

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.51747
Value Function Update Magnitude: 0.57537

Collected Steps per Second: 22,380.28659
Overall Steps per Second: 10,789.90045

Timestep Collection Time: 2.23465
Timestep Consumption Time: 2.40043
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.63508

Cumulative Model Updates: 241,710
Cumulative Timesteps: 2,015,883,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2015883300...
Checkpoint 2015883300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.74495
Policy Entropy: 2.25801
Value Function Loss: 0.01652

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.51891
Value Function Update Magnitude: 0.57710

Collected Steps per Second: 22,553.29851
Overall Steps per Second: 10,769.23143

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.42686
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.64471

Cumulative Model Updates: 241,716
Cumulative Timesteps: 2,015,933,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.09643
Policy Entropy: 2.28173
Value Function Loss: 0.01724

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.52938
Value Function Update Magnitude: 0.59409

Collected Steps per Second: 23,196.21286
Overall Steps per Second: 10,950.73525

Timestep Collection Time: 2.15561
Timestep Consumption Time: 2.41048
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.56609

Cumulative Model Updates: 241,722
Cumulative Timesteps: 2,015,983,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2015983322...
Checkpoint 2015983322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.34959
Policy Entropy: 2.25013
Value Function Loss: 0.01731

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.53048
Value Function Update Magnitude: 0.60736

Collected Steps per Second: 22,765.88524
Overall Steps per Second: 10,631.76736

Timestep Collection Time: 2.19653
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.70345

Cumulative Model Updates: 241,728
Cumulative Timesteps: 2,016,033,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.33922
Policy Entropy: 2.22614
Value Function Loss: 0.01701

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.62382

Collected Steps per Second: 23,264.80032
Overall Steps per Second: 10,876.95309

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.60037

Cumulative Model Updates: 241,734
Cumulative Timesteps: 2,016,083,366

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2016083366...
Checkpoint 2016083366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.51727
Policy Entropy: 2.18314
Value Function Loss: 0.01834

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.61746

Collected Steps per Second: 22,683.29358
Overall Steps per Second: 10,982.13355

Timestep Collection Time: 2.20497
Timestep Consumption Time: 2.34934
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.55431

Cumulative Model Updates: 241,740
Cumulative Timesteps: 2,016,133,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.03192
Policy Entropy: 2.22084
Value Function Loss: 0.01779

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.62985

Collected Steps per Second: 23,484.27451
Overall Steps per Second: 10,996.80438

Timestep Collection Time: 2.12977
Timestep Consumption Time: 2.41846
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.54823

Cumulative Model Updates: 241,746
Cumulative Timesteps: 2,016,183,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2016183398...
Checkpoint 2016183398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.54589
Policy Entropy: 2.25530
Value Function Loss: 0.01721

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.62745

Collected Steps per Second: 22,851.25142
Overall Steps per Second: 10,669.24105

Timestep Collection Time: 2.18894
Timestep Consumption Time: 2.49930
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.68824

Cumulative Model Updates: 241,752
Cumulative Timesteps: 2,016,233,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.69496
Policy Entropy: 2.27087
Value Function Loss: 0.01662

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.52410
Value Function Update Magnitude: 0.59263

Collected Steps per Second: 23,377.31710
Overall Steps per Second: 10,919.44895

Timestep Collection Time: 2.13977
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.58100

Cumulative Model Updates: 241,758
Cumulative Timesteps: 2,016,283,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2016283440...
Checkpoint 2016283440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.60511
Policy Entropy: 2.25412
Value Function Loss: 0.01702

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.58866

Collected Steps per Second: 23,624.53711
Overall Steps per Second: 11,019.58948

Timestep Collection Time: 2.11661
Timestep Consumption Time: 2.42112
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.53774

Cumulative Model Updates: 241,764
Cumulative Timesteps: 2,016,333,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.03071
Policy Entropy: 2.27657
Value Function Loss: 0.01748

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.53881
Value Function Update Magnitude: 0.58612

Collected Steps per Second: 22,975.20657
Overall Steps per Second: 10,760.24740

Timestep Collection Time: 2.17713
Timestep Consumption Time: 2.47146
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.64859

Cumulative Model Updates: 241,770
Cumulative Timesteps: 2,016,383,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2016383464...
Checkpoint 2016383464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.72443
Policy Entropy: 2.29032
Value Function Loss: 0.01704

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.53550
Value Function Update Magnitude: 0.60841

Collected Steps per Second: 22,641.23744
Overall Steps per Second: 10,864.56643

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.39414
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.60285

Cumulative Model Updates: 241,776
Cumulative Timesteps: 2,016,433,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.50805
Policy Entropy: 2.28266
Value Function Loss: 0.01730

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.60777

Collected Steps per Second: 22,749.44619
Overall Steps per Second: 10,902.01419

Timestep Collection Time: 2.19909
Timestep Consumption Time: 2.38979
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.58888

Cumulative Model Updates: 241,782
Cumulative Timesteps: 2,016,483,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2016483500...
Checkpoint 2016483500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.07025
Policy Entropy: 2.26952
Value Function Loss: 0.01802

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.62818

Collected Steps per Second: 22,928.02117
Overall Steps per Second: 10,652.76572

Timestep Collection Time: 2.18135
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.69493

Cumulative Model Updates: 241,788
Cumulative Timesteps: 2,016,533,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.82310
Policy Entropy: 2.25757
Value Function Loss: 0.01779

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.55439
Value Function Update Magnitude: 0.63725

Collected Steps per Second: 23,491.34642
Overall Steps per Second: 10,894.66039

Timestep Collection Time: 2.12946
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.59161

Cumulative Model Updates: 241,794
Cumulative Timesteps: 2,016,583,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2016583538...
Checkpoint 2016583538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.85292
Policy Entropy: 2.27080
Value Function Loss: 0.01764

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.55001
Value Function Update Magnitude: 0.63991

Collected Steps per Second: 22,774.95869
Overall Steps per Second: 10,671.84296

Timestep Collection Time: 2.19671
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.68804

Cumulative Model Updates: 241,800
Cumulative Timesteps: 2,016,633,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.06131
Policy Entropy: 2.25100
Value Function Loss: 0.01651

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.53336
Value Function Update Magnitude: 0.63444

Collected Steps per Second: 23,034.24709
Overall Steps per Second: 10,903.43110

Timestep Collection Time: 2.17198
Timestep Consumption Time: 2.41648
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.58846

Cumulative Model Updates: 241,806
Cumulative Timesteps: 2,016,683,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2016683598...
Checkpoint 2016683598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.24374
Policy Entropy: 2.26020
Value Function Loss: 0.01738

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.53044
Value Function Update Magnitude: 0.62484

Collected Steps per Second: 23,073.16067
Overall Steps per Second: 10,732.26406

Timestep Collection Time: 2.16780
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.66053

Cumulative Model Updates: 241,812
Cumulative Timesteps: 2,016,733,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.41481
Policy Entropy: 2.23006
Value Function Loss: 0.01795

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 23,448.44999
Overall Steps per Second: 10,834.01834

Timestep Collection Time: 2.13242
Timestep Consumption Time: 2.48286
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.61528

Cumulative Model Updates: 241,818
Cumulative Timesteps: 2,016,783,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2016783618...
Checkpoint 2016783618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.01174
Policy Entropy: 2.23446
Value Function Loss: 0.01885

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.53248
Value Function Update Magnitude: 0.63564

Collected Steps per Second: 22,710.96930
Overall Steps per Second: 10,678.84875

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.68421

Cumulative Model Updates: 241,824
Cumulative Timesteps: 2,016,833,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.94715
Policy Entropy: 2.22838
Value Function Loss: 0.01881

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.64733

Collected Steps per Second: 22,797.06889
Overall Steps per Second: 10,871.27325

Timestep Collection Time: 2.19379
Timestep Consumption Time: 2.40659
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.60038

Cumulative Model Updates: 241,830
Cumulative Timesteps: 2,016,883,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2016883652...
Checkpoint 2016883652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.47689
Policy Entropy: 2.26938
Value Function Loss: 0.01842

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 22,539.68097
Overall Steps per Second: 10,614.35856

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.71343

Cumulative Model Updates: 241,836
Cumulative Timesteps: 2,016,933,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.83442
Policy Entropy: 2.28147
Value Function Loss: 0.01720

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.64350

Collected Steps per Second: 22,531.41309
Overall Steps per Second: 10,619.59783

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.71054

Cumulative Model Updates: 241,842
Cumulative Timesteps: 2,016,983,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2016983706...
Checkpoint 2016983706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.04837
Policy Entropy: 2.27397
Value Function Loss: 0.01642

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.61489

Collected Steps per Second: 22,388.59059
Overall Steps per Second: 10,634.66027

Timestep Collection Time: 2.23364
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.70236

Cumulative Model Updates: 241,848
Cumulative Timesteps: 2,017,033,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.58644
Policy Entropy: 2.26553
Value Function Loss: 0.01619

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.58821

Collected Steps per Second: 23,566.71111
Overall Steps per Second: 11,033.17441

Timestep Collection Time: 2.12172
Timestep Consumption Time: 2.41025
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.53197

Cumulative Model Updates: 241,854
Cumulative Timesteps: 2,017,083,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2017083716...
Checkpoint 2017083716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.51087
Policy Entropy: 2.25597
Value Function Loss: 0.01695

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.53596
Value Function Update Magnitude: 0.58785

Collected Steps per Second: 22,617.25002
Overall Steps per Second: 10,767.54369

Timestep Collection Time: 2.21194
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.64619

Cumulative Model Updates: 241,860
Cumulative Timesteps: 2,017,133,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.51577
Policy Entropy: 2.27042
Value Function Loss: 0.01606

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.53379
Value Function Update Magnitude: 0.60571

Collected Steps per Second: 23,213.18880
Overall Steps per Second: 10,887.19616

Timestep Collection Time: 2.15524
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59531

Cumulative Model Updates: 241,866
Cumulative Timesteps: 2,017,183,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2017183774...
Checkpoint 2017183774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.53037
Policy Entropy: 2.26786
Value Function Loss: 0.01608

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.52863
Value Function Update Magnitude: 0.59442

Collected Steps per Second: 22,634.81299
Overall Steps per Second: 10,830.11249

Timestep Collection Time: 2.20934
Timestep Consumption Time: 2.40816
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.61750

Cumulative Model Updates: 241,872
Cumulative Timesteps: 2,017,233,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.89330
Policy Entropy: 2.27729
Value Function Loss: 0.01556

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.52359
Value Function Update Magnitude: 0.58476

Collected Steps per Second: 23,562.04145
Overall Steps per Second: 10,822.32281

Timestep Collection Time: 2.12308
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.62230

Cumulative Model Updates: 241,878
Cumulative Timesteps: 2,017,283,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2017283806...
Checkpoint 2017283806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.97546
Policy Entropy: 2.23729
Value Function Loss: 0.01586

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.52085
Value Function Update Magnitude: 0.59275

Collected Steps per Second: 22,713.19683
Overall Steps per Second: 10,655.18345

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.69499

Cumulative Model Updates: 241,884
Cumulative Timesteps: 2,017,333,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.86644
Policy Entropy: 2.25172
Value Function Loss: 0.01599

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.62279

Collected Steps per Second: 22,885.73391
Overall Steps per Second: 10,842.17119

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.61291

Cumulative Model Updates: 241,890
Cumulative Timesteps: 2,017,383,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2017383846...
Checkpoint 2017383846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.63902
Policy Entropy: 2.22274
Value Function Loss: 0.01616

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.52449
Value Function Update Magnitude: 0.64327

Collected Steps per Second: 22,323.87105
Overall Steps per Second: 10,689.39044

Timestep Collection Time: 2.23993
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.67791

Cumulative Model Updates: 241,896
Cumulative Timesteps: 2,017,433,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.41261
Policy Entropy: 2.26588
Value Function Loss: 0.01573

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.62886

Collected Steps per Second: 22,591.31519
Overall Steps per Second: 10,903.55821

Timestep Collection Time: 2.21386
Timestep Consumption Time: 2.37308
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.58694

Cumulative Model Updates: 241,902
Cumulative Timesteps: 2,017,483,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2017483864...
Checkpoint 2017483864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.59226
Policy Entropy: 2.24269
Value Function Loss: 0.01624

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.52568
Value Function Update Magnitude: 0.60448

Collected Steps per Second: 22,537.77084
Overall Steps per Second: 10,613.79651

Timestep Collection Time: 2.21956
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.71311

Cumulative Model Updates: 241,908
Cumulative Timesteps: 2,017,533,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.09587
Policy Entropy: 2.21494
Value Function Loss: 0.01701

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.58518

Collected Steps per Second: 23,304.48353
Overall Steps per Second: 10,848.71635

Timestep Collection Time: 2.14680
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.61161

Cumulative Model Updates: 241,914
Cumulative Timesteps: 2,017,583,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2017583918...
Checkpoint 2017583918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.79538
Policy Entropy: 2.17269
Value Function Loss: 0.01832

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.54094
Value Function Update Magnitude: 0.59542

Collected Steps per Second: 22,215.48093
Overall Steps per Second: 10,711.62273

Timestep Collection Time: 2.25113
Timestep Consumption Time: 2.41763
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.66876

Cumulative Model Updates: 241,920
Cumulative Timesteps: 2,017,633,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.65514
Policy Entropy: 2.14934
Value Function Loss: 0.01913

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.55261
Value Function Update Magnitude: 0.60655

Collected Steps per Second: 23,302.20689
Overall Steps per Second: 10,909.44178

Timestep Collection Time: 2.14658
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.58502

Cumulative Model Updates: 241,926
Cumulative Timesteps: 2,017,683,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2017683948...
Checkpoint 2017683948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.87791
Policy Entropy: 2.18474
Value Function Loss: 0.01782

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 22,817.97367
Overall Steps per Second: 10,630.70380

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.51281
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.70467

Cumulative Model Updates: 241,932
Cumulative Timesteps: 2,017,733,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.24222
Policy Entropy: 2.18241
Value Function Loss: 0.01756

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.60475

Collected Steps per Second: 23,115.37026
Overall Steps per Second: 10,885.25265

Timestep Collection Time: 2.16419
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59576

Cumulative Model Updates: 241,938
Cumulative Timesteps: 2,017,783,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2017783988...
Checkpoint 2017783988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.00056
Policy Entropy: 2.20755
Value Function Loss: 0.01645

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.54075
Value Function Update Magnitude: 0.59146

Collected Steps per Second: 22,979.15301
Overall Steps per Second: 10,766.12332

Timestep Collection Time: 2.17676
Timestep Consumption Time: 2.46930
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.64605

Cumulative Model Updates: 241,944
Cumulative Timesteps: 2,017,834,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.37781
Policy Entropy: 2.20227
Value Function Loss: 0.01654

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.57846

Collected Steps per Second: 22,737.86001
Overall Steps per Second: 10,810.98139

Timestep Collection Time: 2.19968
Timestep Consumption Time: 2.42673
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.62641

Cumulative Model Updates: 241,950
Cumulative Timesteps: 2,017,884,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2017884024...
Checkpoint 2017884024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.91738
Policy Entropy: 2.24917
Value Function Loss: 0.01670

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.54149
Value Function Update Magnitude: 0.57984

Collected Steps per Second: 22,527.55269
Overall Steps per Second: 10,657.62374

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69429

Cumulative Model Updates: 241,956
Cumulative Timesteps: 2,017,934,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.28954
Policy Entropy: 2.23027
Value Function Loss: 0.01799

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.54551
Value Function Update Magnitude: 0.60077

Collected Steps per Second: 22,865.66936
Overall Steps per Second: 10,828.36002

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.61972

Cumulative Model Updates: 241,962
Cumulative Timesteps: 2,017,984,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2017984078...
Checkpoint 2017984078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.27865
Policy Entropy: 2.22639
Value Function Loss: 0.01843

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.61251

Collected Steps per Second: 22,688.04590
Overall Steps per Second: 10,744.05975

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.45120
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.65615

Cumulative Model Updates: 241,968
Cumulative Timesteps: 2,018,034,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.35371
Policy Entropy: 2.19454
Value Function Loss: 0.01825

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.55003
Value Function Update Magnitude: 0.61736

Collected Steps per Second: 23,576.88193
Overall Steps per Second: 10,820.44601

Timestep Collection Time: 2.12165
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.62291

Cumulative Model Updates: 241,974
Cumulative Timesteps: 2,018,084,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2018084126...
Checkpoint 2018084126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.57792
Policy Entropy: 2.23587
Value Function Loss: 0.01752

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.59779

Collected Steps per Second: 22,900.11806
Overall Steps per Second: 10,670.58394

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.68653

Cumulative Model Updates: 241,980
Cumulative Timesteps: 2,018,134,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.11727
Policy Entropy: 2.24373
Value Function Loss: 0.01827

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 23,312.08851
Overall Steps per Second: 10,961.50404

Timestep Collection Time: 2.14567
Timestep Consumption Time: 2.41757
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.56324

Cumulative Model Updates: 241,986
Cumulative Timesteps: 2,018,184,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2018184154...
Checkpoint 2018184154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.08957
Policy Entropy: 2.25986
Value Function Loss: 0.01883

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.61284

Collected Steps per Second: 22,743.20402
Overall Steps per Second: 10,718.68971

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.66606

Cumulative Model Updates: 241,992
Cumulative Timesteps: 2,018,234,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.72276
Policy Entropy: 2.22190
Value Function Loss: 0.01927

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.61461

Collected Steps per Second: 24,337.89806
Overall Steps per Second: 11,071.39639

Timestep Collection Time: 2.05556
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.51867

Cumulative Model Updates: 241,998
Cumulative Timesteps: 2,018,284,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2018284196...
Checkpoint 2018284196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.46705
Policy Entropy: 2.22414
Value Function Loss: 0.01870

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.60610

Collected Steps per Second: 22,378.27435
Overall Steps per Second: 10,729.58727

Timestep Collection Time: 2.23529
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.66206

Cumulative Model Updates: 242,004
Cumulative Timesteps: 2,018,334,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.92290
Policy Entropy: 2.21604
Value Function Loss: 0.01836

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.54197
Value Function Update Magnitude: 0.61165

Collected Steps per Second: 22,801.20802
Overall Steps per Second: 10,769.51042

Timestep Collection Time: 2.19304
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.64311

Cumulative Model Updates: 242,010
Cumulative Timesteps: 2,018,384,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2018384222...
Checkpoint 2018384222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.23018
Policy Entropy: 2.20905
Value Function Loss: 0.01875

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.55205
Value Function Update Magnitude: 0.62623

Collected Steps per Second: 22,309.05948
Overall Steps per Second: 10,641.06468

Timestep Collection Time: 2.24169
Timestep Consumption Time: 2.45803
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.69972

Cumulative Model Updates: 242,016
Cumulative Timesteps: 2,018,434,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.84957
Policy Entropy: 2.21820
Value Function Loss: 0.01698

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.63337

Collected Steps per Second: 23,196.84176
Overall Steps per Second: 11,061.66758

Timestep Collection Time: 2.15667
Timestep Consumption Time: 2.36597
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.52265

Cumulative Model Updates: 242,022
Cumulative Timesteps: 2,018,484,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2018484260...
Checkpoint 2018484260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.49636
Policy Entropy: 2.21719
Value Function Loss: 0.01625

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.53696
Value Function Update Magnitude: 0.61065

Collected Steps per Second: 22,742.57845
Overall Steps per Second: 10,744.64831

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.45712
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.65757

Cumulative Model Updates: 242,028
Cumulative Timesteps: 2,018,534,304

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.61746
Policy Entropy: 2.24297
Value Function Loss: 0.01579

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.59148

Collected Steps per Second: 23,236.76057
Overall Steps per Second: 10,936.24894

Timestep Collection Time: 2.15185
Timestep Consumption Time: 2.42029
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.57213

Cumulative Model Updates: 242,034
Cumulative Timesteps: 2,018,584,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2018584306...
Checkpoint 2018584306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.13211
Policy Entropy: 2.21591
Value Function Loss: 0.01621

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.52955
Value Function Update Magnitude: 0.59434

Collected Steps per Second: 22,778.04726
Overall Steps per Second: 11,015.98507

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.34423
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.53977

Cumulative Model Updates: 242,040
Cumulative Timesteps: 2,018,634,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.85268
Policy Entropy: 2.20991
Value Function Loss: 0.01648

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 23,438.18585
Overall Steps per Second: 10,956.16690

Timestep Collection Time: 2.13353
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.56419

Cumulative Model Updates: 242,046
Cumulative Timesteps: 2,018,684,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2018684322...
Checkpoint 2018684322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.98131
Policy Entropy: 2.18062
Value Function Loss: 0.01697

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.62441

Collected Steps per Second: 22,758.64783
Overall Steps per Second: 10,650.05304

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.69725

Cumulative Model Updates: 242,052
Cumulative Timesteps: 2,018,734,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.02819
Policy Entropy: 2.17332
Value Function Loss: 0.01756

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.55497
Value Function Update Magnitude: 0.64407

Collected Steps per Second: 21,979.74496
Overall Steps per Second: 10,456.11493

Timestep Collection Time: 2.27564
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.78361

Cumulative Model Updates: 242,058
Cumulative Timesteps: 2,018,784,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2018784366...
Checkpoint 2018784366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.64898
Policy Entropy: 2.17732
Value Function Loss: 0.01771

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.56006
Value Function Update Magnitude: 0.65930

Collected Steps per Second: 22,042.83133
Overall Steps per Second: 10,650.02491

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69745

Cumulative Model Updates: 242,064
Cumulative Timesteps: 2,018,834,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.90459
Policy Entropy: 2.19771
Value Function Loss: 0.01676

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.65057

Collected Steps per Second: 23,216.72670
Overall Steps per Second: 10,935.47953

Timestep Collection Time: 2.15362
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.57227

Cumulative Model Updates: 242,070
Cumulative Timesteps: 2,018,884,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2018884394...
Checkpoint 2018884394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.14996
Policy Entropy: 2.21930
Value Function Loss: 0.01742

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.54896
Value Function Update Magnitude: 0.63752

Collected Steps per Second: 22,875.77933
Overall Steps per Second: 10,613.85521

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.52622
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.71290

Cumulative Model Updates: 242,076
Cumulative Timesteps: 2,018,934,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.00671
Policy Entropy: 2.23797
Value Function Loss: 0.01773

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.54500
Value Function Update Magnitude: 0.63406

Collected Steps per Second: 23,540.28461
Overall Steps per Second: 10,899.57744

Timestep Collection Time: 2.12402
Timestep Consumption Time: 2.46332
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.58733

Cumulative Model Updates: 242,082
Cumulative Timesteps: 2,018,984,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2018984416...
Checkpoint 2018984416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.11622
Policy Entropy: 2.23950
Value Function Loss: 0.01836

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.64237

Collected Steps per Second: 22,811.02564
Overall Steps per Second: 11,026.89260

Timestep Collection Time: 2.19262
Timestep Consumption Time: 2.34320
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.53582

Cumulative Model Updates: 242,088
Cumulative Timesteps: 2,019,034,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.65424
Policy Entropy: 2.23120
Value Function Loss: 0.01793

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.64693

Collected Steps per Second: 23,436.44830
Overall Steps per Second: 10,928.27286

Timestep Collection Time: 2.13420
Timestep Consumption Time: 2.44274
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.57694

Cumulative Model Updates: 242,094
Cumulative Timesteps: 2,019,084,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2019084450...
Checkpoint 2019084450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.49103
Policy Entropy: 2.21984
Value Function Loss: 0.01829

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.54642
Value Function Update Magnitude: 0.64991

Collected Steps per Second: 22,745.62981
Overall Steps per Second: 10,699.47016

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.47570
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.67462

Cumulative Model Updates: 242,100
Cumulative Timesteps: 2,019,134,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.19208
Policy Entropy: 2.21309
Value Function Loss: 0.01879

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.64937

Collected Steps per Second: 23,230.75706
Overall Steps per Second: 11,006.15313

Timestep Collection Time: 2.15361
Timestep Consumption Time: 2.39203
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.54564

Cumulative Model Updates: 242,106
Cumulative Timesteps: 2,019,184,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2019184496...
Checkpoint 2019184496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.04172
Policy Entropy: 2.22670
Value Function Loss: 0.01898

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.56618
Value Function Update Magnitude: 0.63665

Collected Steps per Second: 22,473.47960
Overall Steps per Second: 10,930.33635

Timestep Collection Time: 2.22502
Timestep Consumption Time: 2.34977
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.57479

Cumulative Model Updates: 242,112
Cumulative Timesteps: 2,019,234,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.33072
Policy Entropy: 2.23189
Value Function Loss: 0.01827

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.64013

Collected Steps per Second: 22,895.39497
Overall Steps per Second: 10,677.73995

Timestep Collection Time: 2.18454
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68414

Cumulative Model Updates: 242,118
Cumulative Timesteps: 2,019,284,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2019284516...
Checkpoint 2019284516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.02839
Policy Entropy: 2.23033
Value Function Loss: 0.01735

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.65243

Collected Steps per Second: 22,246.15446
Overall Steps per Second: 10,530.17139

Timestep Collection Time: 2.24848
Timestep Consumption Time: 2.50168
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.75016

Cumulative Model Updates: 242,124
Cumulative Timesteps: 2,019,334,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.97643
Policy Entropy: 2.22333
Value Function Loss: 0.01706

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.54485
Value Function Update Magnitude: 0.64515

Collected Steps per Second: 23,047.26449
Overall Steps per Second: 10,888.45401

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.59422

Cumulative Model Updates: 242,130
Cumulative Timesteps: 2,019,384,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2019384560...
Checkpoint 2019384560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.03561
Policy Entropy: 2.21743
Value Function Loss: 0.01756

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.54464
Value Function Update Magnitude: 0.63908

Collected Steps per Second: 22,789.91304
Overall Steps per Second: 10,639.92407

Timestep Collection Time: 2.19413
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.69966

Cumulative Model Updates: 242,136
Cumulative Timesteps: 2,019,434,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.80700
Policy Entropy: 2.21714
Value Function Loss: 0.01858

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.16078
Policy Update Magnitude: 0.53254
Value Function Update Magnitude: 0.65880

Collected Steps per Second: 23,558.24568
Overall Steps per Second: 10,887.22669

Timestep Collection Time: 2.12291
Timestep Consumption Time: 2.47073
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.59364

Cumulative Model Updates: 242,142
Cumulative Timesteps: 2,019,484,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2019484576...
Checkpoint 2019484576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.51588
Policy Entropy: 2.20314
Value Function Loss: 0.01909

Mean KL Divergence: 0.03373
SB3 Clip Fraction: 0.18199
Policy Update Magnitude: 0.52498
Value Function Update Magnitude: 0.67421

Collected Steps per Second: 22,781.07692
Overall Steps per Second: 10,629.30709

Timestep Collection Time: 2.19542
Timestep Consumption Time: 2.50987
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70529

Cumulative Model Updates: 242,148
Cumulative Timesteps: 2,019,534,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.85255
Policy Entropy: 2.20425
Value Function Loss: 0.01865

Mean KL Divergence: 0.03092
SB3 Clip Fraction: 0.17805
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.69063

Collected Steps per Second: 23,004.08531
Overall Steps per Second: 10,925.64863

Timestep Collection Time: 2.17379
Timestep Consumption Time: 2.40315
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.57694

Cumulative Model Updates: 242,154
Cumulative Timesteps: 2,019,584,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2019584596...
Checkpoint 2019584596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.26914
Policy Entropy: 2.22229
Value Function Loss: 0.01720

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.70027

Collected Steps per Second: 22,641.00644
Overall Steps per Second: 10,870.50588

Timestep Collection Time: 2.20865
Timestep Consumption Time: 2.39151
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.60015

Cumulative Model Updates: 242,160
Cumulative Timesteps: 2,019,634,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.76493
Policy Entropy: 2.21602
Value Function Loss: 0.01727

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.68595

Collected Steps per Second: 23,464.48402
Overall Steps per Second: 10,826.45887

Timestep Collection Time: 2.13182
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.62035

Cumulative Model Updates: 242,166
Cumulative Timesteps: 2,019,684,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2019684624...
Checkpoint 2019684624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.84389
Policy Entropy: 2.20141
Value Function Loss: 0.01763

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.56715
Value Function Update Magnitude: 0.68111

Collected Steps per Second: 22,529.81556
Overall Steps per Second: 10,589.91672

Timestep Collection Time: 2.21981
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.72261

Cumulative Model Updates: 242,172
Cumulative Timesteps: 2,019,734,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.17843
Policy Entropy: 2.18547
Value Function Loss: 0.01784

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.68157

Collected Steps per Second: 22,943.37200
Overall Steps per Second: 10,850.23718

Timestep Collection Time: 2.18024
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.61022

Cumulative Model Updates: 242,178
Cumulative Timesteps: 2,019,784,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2019784658...
Checkpoint 2019784658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.43884
Policy Entropy: 2.19003
Value Function Loss: 0.01902

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.56954
Value Function Update Magnitude: 0.67828

Collected Steps per Second: 23,378.09499
Overall Steps per Second: 10,879.88651

Timestep Collection Time: 2.13918
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.59656

Cumulative Model Updates: 242,184
Cumulative Timesteps: 2,019,834,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.60612
Policy Entropy: 2.20617
Value Function Loss: 0.01830

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.56227
Value Function Update Magnitude: 0.68527

Collected Steps per Second: 23,050.92190
Overall Steps per Second: 10,668.61982

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.68739

Cumulative Model Updates: 242,190
Cumulative Timesteps: 2,019,884,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2019884676...
Checkpoint 2019884676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.96677
Policy Entropy: 2.22409
Value Function Loss: 0.01763

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.68325

Collected Steps per Second: 22,771.02678
Overall Steps per Second: 10,611.45963

Timestep Collection Time: 2.19621
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.71283

Cumulative Model Updates: 242,196
Cumulative Timesteps: 2,019,934,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.48772
Policy Entropy: 2.25648
Value Function Loss: 0.01701

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.64993

Collected Steps per Second: 23,327.46703
Overall Steps per Second: 10,930.10303

Timestep Collection Time: 2.14382
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.57544

Cumulative Model Updates: 242,202
Cumulative Timesteps: 2,019,984,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2019984696...
Checkpoint 2019984696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.14693
Policy Entropy: 2.26591
Value Function Loss: 0.01630

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.64552

Collected Steps per Second: 22,482.13704
Overall Steps per Second: 10,820.64355

Timestep Collection Time: 2.22523
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.62338

Cumulative Model Updates: 242,208
Cumulative Timesteps: 2,020,034,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.98079
Policy Entropy: 2.27506
Value Function Loss: 0.01667

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.65322

Collected Steps per Second: 23,425.77038
Overall Steps per Second: 10,825.69068

Timestep Collection Time: 2.13449
Timestep Consumption Time: 2.48434
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.61883

Cumulative Model Updates: 242,214
Cumulative Timesteps: 2,020,084,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2020084726...
Checkpoint 2020084726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.07755
Policy Entropy: 2.28266
Value Function Loss: 0.01591

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.53195
Value Function Update Magnitude: 0.64976

Collected Steps per Second: 22,824.73248
Overall Steps per Second: 10,701.66891

Timestep Collection Time: 2.19104
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67310

Cumulative Model Updates: 242,220
Cumulative Timesteps: 2,020,134,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.95221
Policy Entropy: 2.29281
Value Function Loss: 0.01709

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.52837
Value Function Update Magnitude: 0.63811

Collected Steps per Second: 23,172.30667
Overall Steps per Second: 10,790.68679

Timestep Collection Time: 2.15801
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.63418

Cumulative Model Updates: 242,226
Cumulative Timesteps: 2,020,184,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2020184742...
Checkpoint 2020184742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.75676
Policy Entropy: 2.25914
Value Function Loss: 0.01692

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.53326
Value Function Update Magnitude: 0.63866

Collected Steps per Second: 22,356.73758
Overall Steps per Second: 10,821.62860

Timestep Collection Time: 2.23682
Timestep Consumption Time: 2.38430
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.62112

Cumulative Model Updates: 242,232
Cumulative Timesteps: 2,020,234,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.78542
Policy Entropy: 2.21925
Value Function Loss: 0.01836

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.64280

Collected Steps per Second: 23,064.26302
Overall Steps per Second: 10,723.63183

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66446

Cumulative Model Updates: 242,238
Cumulative Timesteps: 2,020,284,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2020284770...
Checkpoint 2020284770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.32420
Policy Entropy: 2.18305
Value Function Loss: 0.01828

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.65163

Collected Steps per Second: 22,160.15685
Overall Steps per Second: 10,629.37884

Timestep Collection Time: 2.25766
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.70677

Cumulative Model Updates: 242,244
Cumulative Timesteps: 2,020,334,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.11082
Policy Entropy: 2.21937
Value Function Loss: 0.01735

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.55650
Value Function Update Magnitude: 0.65250

Collected Steps per Second: 23,022.60137
Overall Steps per Second: 10,927.43319

Timestep Collection Time: 2.17360
Timestep Consumption Time: 2.40588
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.57948

Cumulative Model Updates: 242,250
Cumulative Timesteps: 2,020,384,842

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2020384842...
Checkpoint 2020384842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.84114
Policy Entropy: 2.21842
Value Function Loss: 0.01851

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.56641
Value Function Update Magnitude: 0.66269

Collected Steps per Second: 22,850.17670
Overall Steps per Second: 10,967.09009

Timestep Collection Time: 2.18887
Timestep Consumption Time: 2.37169
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.56055

Cumulative Model Updates: 242,256
Cumulative Timesteps: 2,020,434,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.82245
Policy Entropy: 2.24068
Value Function Loss: 0.01821

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.67314

Collected Steps per Second: 23,544.36533
Overall Steps per Second: 10,977.98698

Timestep Collection Time: 2.12501
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.55748

Cumulative Model Updates: 242,262
Cumulative Timesteps: 2,020,484,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2020484890...
Checkpoint 2020484890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.19862
Policy Entropy: 2.20889
Value Function Loss: 0.01940

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.66477

Collected Steps per Second: 22,734.96038
Overall Steps per Second: 10,666.47858

Timestep Collection Time: 2.20040
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.69002

Cumulative Model Updates: 242,268
Cumulative Timesteps: 2,020,534,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.41510
Policy Entropy: 2.24140
Value Function Loss: 0.01750

Mean KL Divergence: 0.02821
SB3 Clip Fraction: 0.16777
Policy Update Magnitude: 0.52175
Value Function Update Magnitude: 0.64857

Collected Steps per Second: 23,448.92321
Overall Steps per Second: 10,901.92874

Timestep Collection Time: 2.13306
Timestep Consumption Time: 2.45493
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.58800

Cumulative Model Updates: 242,274
Cumulative Timesteps: 2,020,584,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2020584934...
Checkpoint 2020584934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.20940
Policy Entropy: 2.24645
Value Function Loss: 0.01649

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.15781
Policy Update Magnitude: 0.49832
Value Function Update Magnitude: 0.62681

Collected Steps per Second: 22,641.35674
Overall Steps per Second: 10,690.32138

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.46987
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.67919

Cumulative Model Updates: 242,280
Cumulative Timesteps: 2,020,634,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.44927
Policy Entropy: 2.26211
Value Function Loss: 0.01559

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.16032
Policy Update Magnitude: 0.49906
Value Function Update Magnitude: 0.58236

Collected Steps per Second: 22,959.42772
Overall Steps per Second: 10,858.65061

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.42755
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.60591

Cumulative Model Updates: 242,286
Cumulative Timesteps: 2,020,684,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2020684970...
Checkpoint 2020684970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.16117
Policy Entropy: 2.26796
Value Function Loss: 0.01552

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.15645
Policy Update Magnitude: 0.51349
Value Function Update Magnitude: 0.56847

Collected Steps per Second: 21,518.69238
Overall Steps per Second: 10,425.65418

Timestep Collection Time: 2.32430
Timestep Consumption Time: 2.47309
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.79740

Cumulative Model Updates: 242,292
Cumulative Timesteps: 2,020,734,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.99130
Policy Entropy: 2.29347
Value Function Loss: 0.01598

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.15675
Policy Update Magnitude: 0.51151
Value Function Update Magnitude: 0.57635

Collected Steps per Second: 23,163.90699
Overall Steps per Second: 10,708.42686

Timestep Collection Time: 2.15913
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.67053

Cumulative Model Updates: 242,298
Cumulative Timesteps: 2,020,785,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2020785000...
Checkpoint 2020785000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.91720
Policy Entropy: 2.28531
Value Function Loss: 0.01650

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.52665
Value Function Update Magnitude: 0.59100

Collected Steps per Second: 22,224.57695
Overall Steps per Second: 10,711.80481

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.41808
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.66793

Cumulative Model Updates: 242,304
Cumulative Timesteps: 2,020,835,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.83835
Policy Entropy: 2.23032
Value Function Loss: 0.01622

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.54250
Value Function Update Magnitude: 0.60305

Collected Steps per Second: 23,597.02608
Overall Steps per Second: 10,828.61294

Timestep Collection Time: 2.11984
Timestep Consumption Time: 2.49958
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.61943

Cumulative Model Updates: 242,310
Cumulative Timesteps: 2,020,885,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2020885024...
Checkpoint 2020885024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.17865
Policy Entropy: 2.22368
Value Function Loss: 0.01660

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.60356

Collected Steps per Second: 22,828.84570
Overall Steps per Second: 10,616.32857

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.51972
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.71010

Cumulative Model Updates: 242,316
Cumulative Timesteps: 2,020,935,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.34519
Policy Entropy: 2.21228
Value Function Loss: 0.01782

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.56225
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 23,281.59542
Overall Steps per Second: 10,937.33250

Timestep Collection Time: 2.14865
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.57369

Cumulative Model Updates: 242,322
Cumulative Timesteps: 2,020,985,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2020985052...
Checkpoint 2020985052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.89453
Policy Entropy: 2.22983
Value Function Loss: 0.01858

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.56547
Value Function Update Magnitude: 0.60913

Collected Steps per Second: 22,634.62388
Overall Steps per Second: 11,004.55436

Timestep Collection Time: 2.20971
Timestep Consumption Time: 2.33532
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.54503

Cumulative Model Updates: 242,328
Cumulative Timesteps: 2,021,035,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.89340
Policy Entropy: 2.21762
Value Function Loss: 0.01848

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.55044
Value Function Update Magnitude: 0.61504

Collected Steps per Second: 23,393.99928
Overall Steps per Second: 10,943.41120

Timestep Collection Time: 2.13867
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.57188

Cumulative Model Updates: 242,334
Cumulative Timesteps: 2,021,085,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2021085100...
Checkpoint 2021085100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.83058
Policy Entropy: 2.23872
Value Function Loss: 0.01714

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.53517
Value Function Update Magnitude: 0.61011

Collected Steps per Second: 22,494.22611
Overall Steps per Second: 10,697.28630

Timestep Collection Time: 2.22333
Timestep Consumption Time: 2.45188
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.67520

Cumulative Model Updates: 242,340
Cumulative Timesteps: 2,021,135,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.32711
Policy Entropy: 2.23660
Value Function Loss: 0.01778

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.61169

Collected Steps per Second: 22,699.25413
Overall Steps per Second: 10,867.51718

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.39873
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60197

Cumulative Model Updates: 242,346
Cumulative Timesteps: 2,021,185,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2021185124...
Checkpoint 2021185124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.81027
Policy Entropy: 2.26389
Value Function Loss: 0.01723

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.53617
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 22,357.11854
Overall Steps per Second: 10,705.64229

Timestep Collection Time: 2.23696
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.67156

Cumulative Model Updates: 242,352
Cumulative Timesteps: 2,021,235,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.17429
Policy Entropy: 2.25909
Value Function Loss: 0.01595

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.52004
Value Function Update Magnitude: 0.60262

Collected Steps per Second: 23,506.56646
Overall Steps per Second: 10,920.82604

Timestep Collection Time: 2.12766
Timestep Consumption Time: 2.45203
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.57969

Cumulative Model Updates: 242,358
Cumulative Timesteps: 2,021,285,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2021285150...
Checkpoint 2021285150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.78303
Policy Entropy: 2.27660
Value Function Loss: 0.01664

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.52613
Value Function Update Magnitude: 0.59488

Collected Steps per Second: 22,502.25124
Overall Steps per Second: 10,602.34844

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.49444
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.71688

Cumulative Model Updates: 242,364
Cumulative Timesteps: 2,021,335,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.31360
Policy Entropy: 2.22358
Value Function Loss: 0.01736

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.11563
Policy Update Magnitude: 0.53963
Value Function Update Magnitude: 0.60389

Collected Steps per Second: 23,271.41538
Overall Steps per Second: 10,808.83663

Timestep Collection Time: 2.14873
Timestep Consumption Time: 2.47748
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.62621

Cumulative Model Updates: 242,370
Cumulative Timesteps: 2,021,385,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2021385164...
Checkpoint 2021385164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.55589
Policy Entropy: 2.18969
Value Function Loss: 0.01814

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.61437

Collected Steps per Second: 23,622.52508
Overall Steps per Second: 10,861.75142

Timestep Collection Time: 2.11747
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.60515

Cumulative Model Updates: 242,376
Cumulative Timesteps: 2,021,435,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.09225
Policy Entropy: 2.15751
Value Function Loss: 0.01886

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.63967

Collected Steps per Second: 23,597.40651
Overall Steps per Second: 10,826.24981

Timestep Collection Time: 2.12023
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.62136

Cumulative Model Updates: 242,382
Cumulative Timesteps: 2,021,485,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2021485216...
Checkpoint 2021485216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.01175
Policy Entropy: 2.18493
Value Function Loss: 0.01730

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.67285

Collected Steps per Second: 22,825.62827
Overall Steps per Second: 10,650.44844

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.69727

Cumulative Model Updates: 242,388
Cumulative Timesteps: 2,021,535,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.57726
Policy Entropy: 2.20110
Value Function Loss: 0.01812

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.54831
Value Function Update Magnitude: 0.65154

Collected Steps per Second: 23,066.02193
Overall Steps per Second: 10,901.35818

Timestep Collection Time: 2.16830
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.58787

Cumulative Model Updates: 242,394
Cumulative Timesteps: 2,021,585,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2021585258...
Checkpoint 2021585258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.96553
Policy Entropy: 2.22243
Value Function Loss: 0.01736

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.63932

Collected Steps per Second: 22,179.87431
Overall Steps per Second: 10,672.84375

Timestep Collection Time: 2.25466
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68554

Cumulative Model Updates: 242,400
Cumulative Timesteps: 2,021,635,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.07319
Policy Entropy: 2.22892
Value Function Loss: 0.01790

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.63580

Collected Steps per Second: 23,042.48208
Overall Steps per Second: 10,903.82374

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.41632
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.58683

Cumulative Model Updates: 242,406
Cumulative Timesteps: 2,021,685,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2021685280...
Checkpoint 2021685280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.93075
Policy Entropy: 2.24323
Value Function Loss: 0.01745

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.62638

Collected Steps per Second: 22,513.22260
Overall Steps per Second: 10,597.43821

Timestep Collection Time: 2.22127
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.71888

Cumulative Model Updates: 242,412
Cumulative Timesteps: 2,021,735,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.41241
Policy Entropy: 2.23873
Value Function Loss: 0.01785

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.54719
Value Function Update Magnitude: 0.62776

Collected Steps per Second: 22,949.14184
Overall Steps per Second: 10,818.22120

Timestep Collection Time: 2.17943
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.62331

Cumulative Model Updates: 242,418
Cumulative Timesteps: 2,021,785,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2021785304...
Checkpoint 2021785304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.54841
Policy Entropy: 2.24481
Value Function Loss: 0.01812

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.54399
Value Function Update Magnitude: 0.63213

Collected Steps per Second: 23,356.00067
Overall Steps per Second: 10,761.94979

Timestep Collection Time: 2.14086
Timestep Consumption Time: 2.50532
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.64618

Cumulative Model Updates: 242,424
Cumulative Timesteps: 2,021,835,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.26650
Policy Entropy: 2.25672
Value Function Loss: 0.01793

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.62627

Collected Steps per Second: 23,637.81568
Overall Steps per Second: 10,863.54541

Timestep Collection Time: 2.11551
Timestep Consumption Time: 2.48759
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.60310

Cumulative Model Updates: 242,430
Cumulative Timesteps: 2,021,885,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2021885312...
Checkpoint 2021885312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.50069
Policy Entropy: 2.27201
Value Function Loss: 0.01780

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.54420
Value Function Update Magnitude: 0.61274

Collected Steps per Second: 23,149.06425
Overall Steps per Second: 10,721.97237

Timestep Collection Time: 2.16043
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.66444

Cumulative Model Updates: 242,436
Cumulative Timesteps: 2,021,935,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.49187
Policy Entropy: 2.30552
Value Function Loss: 0.01694

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.54094
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 23,151.70223
Overall Steps per Second: 10,843.48988

Timestep Collection Time: 2.16105
Timestep Consumption Time: 2.45296
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.61401

Cumulative Model Updates: 242,442
Cumulative Timesteps: 2,021,985,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2021985356...
Checkpoint 2021985356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.34278
Policy Entropy: 2.29355
Value Function Loss: 0.01611

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.60852

Collected Steps per Second: 23,608.71628
Overall Steps per Second: 11,051.15733

Timestep Collection Time: 2.11862
Timestep Consumption Time: 2.40742
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.52604

Cumulative Model Updates: 242,448
Cumulative Timesteps: 2,022,035,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.36662
Policy Entropy: 2.29775
Value Function Loss: 0.01598

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.52363
Value Function Update Magnitude: 0.58526

Collected Steps per Second: 22,926.27564
Overall Steps per Second: 10,763.27353

Timestep Collection Time: 2.18108
Timestep Consumption Time: 2.46472
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.64580

Cumulative Model Updates: 242,454
Cumulative Timesteps: 2,022,085,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2022085378...
Checkpoint 2022085378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.20224
Policy Entropy: 2.24681
Value Function Loss: 0.01667

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.52888
Value Function Update Magnitude: 0.56974

Collected Steps per Second: 22,230.24500
Overall Steps per Second: 10,751.96372

Timestep Collection Time: 2.25054
Timestep Consumption Time: 2.40257
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.65310

Cumulative Model Updates: 242,460
Cumulative Timesteps: 2,022,135,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.55840
Policy Entropy: 2.24853
Value Function Loss: 0.01666

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.53124
Value Function Update Magnitude: 0.58772

Collected Steps per Second: 23,001.65849
Overall Steps per Second: 11,044.61160

Timestep Collection Time: 2.17463
Timestep Consumption Time: 2.35428
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.52891

Cumulative Model Updates: 242,466
Cumulative Timesteps: 2,022,185,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2022185428...
Checkpoint 2022185428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.45664
Policy Entropy: 2.23317
Value Function Loss: 0.01729

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.53439
Value Function Update Magnitude: 0.60690

Collected Steps per Second: 23,030.02544
Overall Steps per Second: 10,660.40256

Timestep Collection Time: 2.17108
Timestep Consumption Time: 2.51918
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.69025

Cumulative Model Updates: 242,472
Cumulative Timesteps: 2,022,235,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.60726
Policy Entropy: 2.26660
Value Function Loss: 0.01802

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.61890

Collected Steps per Second: 23,737.03998
Overall Steps per Second: 10,810.36583

Timestep Collection Time: 2.10776
Timestep Consumption Time: 2.52039
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.62815

Cumulative Model Updates: 242,478
Cumulative Timesteps: 2,022,285,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2022285460...
Checkpoint 2022285460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.41517
Policy Entropy: 2.26619
Value Function Loss: 0.01812

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.63189

Collected Steps per Second: 22,476.92858
Overall Steps per Second: 10,672.61600

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.46048
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.68507

Cumulative Model Updates: 242,484
Cumulative Timesteps: 2,022,335,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.12281
Policy Entropy: 2.25289
Value Function Loss: 0.01674

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.63035

Collected Steps per Second: 23,432.66634
Overall Steps per Second: 10,946.94488

Timestep Collection Time: 2.13429
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.56858

Cumulative Model Updates: 242,490
Cumulative Timesteps: 2,022,385,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2022385474...
Checkpoint 2022385474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.70521
Policy Entropy: 2.22410
Value Function Loss: 0.01718

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.54551
Value Function Update Magnitude: 0.62573

Collected Steps per Second: 22,840.53156
Overall Steps per Second: 10,684.09098

Timestep Collection Time: 2.18935
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.68042

Cumulative Model Updates: 242,496
Cumulative Timesteps: 2,022,435,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.34574
Policy Entropy: 2.22763
Value Function Loss: 0.01738

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.63471

Collected Steps per Second: 23,349.29865
Overall Steps per Second: 10,859.04371

Timestep Collection Time: 2.14225
Timestep Consumption Time: 2.46405
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.60630

Cumulative Model Updates: 242,502
Cumulative Timesteps: 2,022,485,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2022485500...
Checkpoint 2022485500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.58612
Policy Entropy: 2.25181
Value Function Loss: 0.01698

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.63927

Collected Steps per Second: 22,414.62578
Overall Steps per Second: 10,618.97106

Timestep Collection Time: 2.23211
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.71157

Cumulative Model Updates: 242,508
Cumulative Timesteps: 2,022,535,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.67906
Policy Entropy: 2.27297
Value Function Loss: 0.01754

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.62780

Collected Steps per Second: 23,073.39865
Overall Steps per Second: 10,949.71439

Timestep Collection Time: 2.16838
Timestep Consumption Time: 2.40087
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.56925

Cumulative Model Updates: 242,514
Cumulative Timesteps: 2,022,585,564

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2022585564...
Checkpoint 2022585564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.85777
Policy Entropy: 2.27728
Value Function Loss: 0.01655

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.54630
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 22,921.30901
Overall Steps per Second: 10,588.66309

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.54086
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.72241

Cumulative Model Updates: 242,520
Cumulative Timesteps: 2,022,635,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.42067
Policy Entropy: 2.26369
Value Function Loss: 0.01754

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.53975
Value Function Update Magnitude: 0.61570

Collected Steps per Second: 22,957.92325
Overall Steps per Second: 10,665.49240

Timestep Collection Time: 2.17877
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.68989

Cumulative Model Updates: 242,526
Cumulative Timesteps: 2,022,685,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2022685588...
Checkpoint 2022685588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.93609
Policy Entropy: 2.24698
Value Function Loss: 0.01724

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.62062

Collected Steps per Second: 23,063.53931
Overall Steps per Second: 10,882.50542

Timestep Collection Time: 2.16801
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59471

Cumulative Model Updates: 242,532
Cumulative Timesteps: 2,022,735,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.63404
Policy Entropy: 2.25438
Value Function Loss: 0.01633

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.52831
Value Function Update Magnitude: 0.61680

Collected Steps per Second: 23,397.32443
Overall Steps per Second: 10,944.47412

Timestep Collection Time: 2.13819
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.57107

Cumulative Model Updates: 242,538
Cumulative Timesteps: 2,022,785,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2022785618...
Checkpoint 2022785618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.68133
Policy Entropy: 2.28710
Value Function Loss: 0.01522

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.51257
Value Function Update Magnitude: 0.58705

Collected Steps per Second: 22,644.31448
Overall Steps per Second: 10,635.62482

Timestep Collection Time: 2.20815
Timestep Consumption Time: 2.49322
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.70137

Cumulative Model Updates: 242,544
Cumulative Timesteps: 2,022,835,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.62091
Policy Entropy: 2.30087
Value Function Loss: 0.01488

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.50684
Value Function Update Magnitude: 0.56497

Collected Steps per Second: 23,287.27476
Overall Steps per Second: 10,921.14612

Timestep Collection Time: 2.14804
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58029

Cumulative Model Updates: 242,550
Cumulative Timesteps: 2,022,885,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2022885642...
Checkpoint 2022885642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.68003
Policy Entropy: 2.28082
Value Function Loss: 0.01599

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.52191
Value Function Update Magnitude: 0.57605

Collected Steps per Second: 22,416.72764
Overall Steps per Second: 10,623.68125

Timestep Collection Time: 2.23092
Timestep Consumption Time: 2.47648
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.70741

Cumulative Model Updates: 242,556
Cumulative Timesteps: 2,022,935,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.63141
Policy Entropy: 2.26176
Value Function Loss: 0.01615

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.59316

Collected Steps per Second: 23,397.69524
Overall Steps per Second: 10,963.74256

Timestep Collection Time: 2.13782
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.56231

Cumulative Model Updates: 242,562
Cumulative Timesteps: 2,022,985,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2022985672...
Checkpoint 2022985672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.05809
Policy Entropy: 2.25751
Value Function Loss: 0.01785

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.61716

Collected Steps per Second: 22,486.30483
Overall Steps per Second: 10,624.92830

Timestep Collection Time: 2.22429
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.70742

Cumulative Model Updates: 242,568
Cumulative Timesteps: 2,023,035,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.17860
Policy Entropy: 2.29641
Value Function Loss: 0.01694

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.53623
Value Function Update Magnitude: 0.63003

Collected Steps per Second: 22,540.94860
Overall Steps per Second: 10,614.59097

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.71144

Cumulative Model Updates: 242,574
Cumulative Timesteps: 2,023,085,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2023085698...
Checkpoint 2023085698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.31557
Policy Entropy: 2.27091
Value Function Loss: 0.01777

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.53454
Value Function Update Magnitude: 0.62536

Collected Steps per Second: 22,375.31992
Overall Steps per Second: 10,673.35884

Timestep Collection Time: 2.23586
Timestep Consumption Time: 2.45133
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.68718

Cumulative Model Updates: 242,580
Cumulative Timesteps: 2,023,135,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.52237
Policy Entropy: 2.26806
Value Function Loss: 0.01680

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 22,817.12117
Overall Steps per Second: 10,859.73079

Timestep Collection Time: 2.19213
Timestep Consumption Time: 2.41370
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.60582

Cumulative Model Updates: 242,586
Cumulative Timesteps: 2,023,185,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2023185744...
Checkpoint 2023185744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.99412
Policy Entropy: 2.22431
Value Function Loss: 0.01703

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.62297

Collected Steps per Second: 22,986.39387
Overall Steps per Second: 10,712.83350

Timestep Collection Time: 2.17598
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.66898

Cumulative Model Updates: 242,592
Cumulative Timesteps: 2,023,235,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.25611
Policy Entropy: 2.22547
Value Function Loss: 0.01762

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.64386

Collected Steps per Second: 23,492.69681
Overall Steps per Second: 10,815.71155

Timestep Collection Time: 2.12858
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.62346

Cumulative Model Updates: 242,598
Cumulative Timesteps: 2,023,285,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2023285768...
Checkpoint 2023285768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.55679
Policy Entropy: 2.21457
Value Function Loss: 0.01760

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.66263

Collected Steps per Second: 22,838.66411
Overall Steps per Second: 10,878.80181

Timestep Collection Time: 2.18988
Timestep Consumption Time: 2.40750
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.59738

Cumulative Model Updates: 242,604
Cumulative Timesteps: 2,023,335,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.47799
Policy Entropy: 2.20284
Value Function Loss: 0.01738

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.55780
Value Function Update Magnitude: 0.66593

Collected Steps per Second: 23,285.99114
Overall Steps per Second: 11,012.74096

Timestep Collection Time: 2.14747
Timestep Consumption Time: 2.39327
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.54074

Cumulative Model Updates: 242,610
Cumulative Timesteps: 2,023,385,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2023385788...
Checkpoint 2023385788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.73424
Policy Entropy: 2.22487
Value Function Loss: 0.01728

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.54948
Value Function Update Magnitude: 0.65892

Collected Steps per Second: 22,554.15047
Overall Steps per Second: 10,647.14714

Timestep Collection Time: 2.21822
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.69891

Cumulative Model Updates: 242,616
Cumulative Timesteps: 2,023,435,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.59442
Policy Entropy: 2.22032
Value Function Loss: 0.01773

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.65357

Collected Steps per Second: 23,088.09209
Overall Steps per Second: 10,906.30377

Timestep Collection Time: 2.16657
Timestep Consumption Time: 2.41995
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.58652

Cumulative Model Updates: 242,622
Cumulative Timesteps: 2,023,485,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2023485840...
Checkpoint 2023485840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.59077
Policy Entropy: 2.22542
Value Function Loss: 0.01812

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.55105
Value Function Update Magnitude: 0.65924

Collected Steps per Second: 22,615.75446
Overall Steps per Second: 10,673.12851

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.68522

Cumulative Model Updates: 242,628
Cumulative Timesteps: 2,023,535,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.54430
Policy Entropy: 2.26317
Value Function Loss: 0.01691

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.53647
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 23,799.82747
Overall Steps per Second: 10,855.47750

Timestep Collection Time: 2.10094
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.60615

Cumulative Model Updates: 242,634
Cumulative Timesteps: 2,023,585,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2023585848...
Checkpoint 2023585848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.39144
Policy Entropy: 2.25013
Value Function Loss: 0.01659

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.11410
Policy Update Magnitude: 0.52548
Value Function Update Magnitude: 0.60729

Collected Steps per Second: 22,449.40571
Overall Steps per Second: 10,664.47175

Timestep Collection Time: 2.22848
Timestep Consumption Time: 2.46261
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.69109

Cumulative Model Updates: 242,640
Cumulative Timesteps: 2,023,635,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.05456
Policy Entropy: 2.25488
Value Function Loss: 0.01728

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 22,813.37470
Overall Steps per Second: 10,810.10037

Timestep Collection Time: 2.19275
Timestep Consumption Time: 2.43478
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.62752

Cumulative Model Updates: 242,646
Cumulative Timesteps: 2,023,685,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2023685900...
Checkpoint 2023685900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.02161
Policy Entropy: 2.21043
Value Function Loss: 0.01758

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.54372
Value Function Update Magnitude: 0.61473

Collected Steps per Second: 22,810.38620
Overall Steps per Second: 10,790.77286

Timestep Collection Time: 2.19339
Timestep Consumption Time: 2.44317
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.63655

Cumulative Model Updates: 242,652
Cumulative Timesteps: 2,023,735,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.12665
Policy Entropy: 2.25704
Value Function Loss: 0.01685

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.53880
Value Function Update Magnitude: 0.61094

Collected Steps per Second: 23,259.16045
Overall Steps per Second: 10,829.20082

Timestep Collection Time: 2.15081
Timestep Consumption Time: 2.46874
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.61955

Cumulative Model Updates: 242,658
Cumulative Timesteps: 2,023,785,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2023785958...
Checkpoint 2023785958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.20573
Policy Entropy: 2.27751
Value Function Loss: 0.01666

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,577.81659
Overall Steps per Second: 10,660.14573

Timestep Collection Time: 2.21518
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.69168

Cumulative Model Updates: 242,664
Cumulative Timesteps: 2,023,835,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.13702
Policy Entropy: 2.27798
Value Function Loss: 0.01628

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.52926
Value Function Update Magnitude: 0.60091

Collected Steps per Second: 23,162.19702
Overall Steps per Second: 10,885.53953

Timestep Collection Time: 2.15929
Timestep Consumption Time: 2.43524
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.59454

Cumulative Model Updates: 242,670
Cumulative Timesteps: 2,023,885,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2023885986...
Checkpoint 2023885986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.26209
Policy Entropy: 2.23784
Value Function Loss: 0.01636

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.59802

Collected Steps per Second: 22,508.39349
Overall Steps per Second: 10,642.69857

Timestep Collection Time: 2.22148
Timestep Consumption Time: 2.47676
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.69824

Cumulative Model Updates: 242,676
Cumulative Timesteps: 2,023,935,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.54058
Policy Entropy: 2.22603
Value Function Loss: 0.01748

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.53774
Value Function Update Magnitude: 0.61414

Collected Steps per Second: 23,418.61822
Overall Steps per Second: 10,970.24296

Timestep Collection Time: 2.13582
Timestep Consumption Time: 2.42360
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.55942

Cumulative Model Updates: 242,682
Cumulative Timesteps: 2,023,986,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2023986006...
Checkpoint 2023986006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.50862
Policy Entropy: 2.23075
Value Function Loss: 0.01825

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.55651
Value Function Update Magnitude: 0.64104

Collected Steps per Second: 22,349.08602
Overall Steps per Second: 10,639.81793

Timestep Collection Time: 2.23768
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.70027

Cumulative Model Updates: 242,688
Cumulative Timesteps: 2,024,036,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.13806
Policy Entropy: 2.26259
Value Function Loss: 0.01751

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.64307

Collected Steps per Second: 22,676.66323
Overall Steps per Second: 10,872.24852

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.39482
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.60052

Cumulative Model Updates: 242,694
Cumulative Timesteps: 2,024,086,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2024086034...
Checkpoint 2024086034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.79476
Policy Entropy: 2.26170
Value Function Loss: 0.01783

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.53537
Value Function Update Magnitude: 0.63182

Collected Steps per Second: 22,272.31402
Overall Steps per Second: 10,711.63259

Timestep Collection Time: 2.24539
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.66876

Cumulative Model Updates: 242,700
Cumulative Timesteps: 2,024,136,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.55051
Policy Entropy: 2.26272
Value Function Loss: 0.01763

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.61746

Collected Steps per Second: 23,093.08161
Overall Steps per Second: 10,929.24731

Timestep Collection Time: 2.16628
Timestep Consumption Time: 2.41098
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.57726

Cumulative Model Updates: 242,706
Cumulative Timesteps: 2,024,186,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2024186070...
Checkpoint 2024186070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.37394
Policy Entropy: 2.25238
Value Function Loss: 0.01877

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.60821

Collected Steps per Second: 22,390.72956
Overall Steps per Second: 10,573.99567

Timestep Collection Time: 2.23334
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.72915

Cumulative Model Updates: 242,712
Cumulative Timesteps: 2,024,236,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.50514
Policy Entropy: 2.23500
Value Function Loss: 0.01851

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.55910
Value Function Update Magnitude: 0.61957

Collected Steps per Second: 23,147.08972
Overall Steps per Second: 10,865.77711

Timestep Collection Time: 2.16079
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60308

Cumulative Model Updates: 242,718
Cumulative Timesteps: 2,024,286,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2024286092...
Checkpoint 2024286092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.89669
Policy Entropy: 2.25226
Value Function Loss: 0.01746

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.61399

Collected Steps per Second: 22,835.24373
Overall Steps per Second: 10,929.60188

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.38647
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.57729

Cumulative Model Updates: 242,724
Cumulative Timesteps: 2,024,336,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.57044
Policy Entropy: 2.24362
Value Function Loss: 0.01768

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.59472

Collected Steps per Second: 23,630.89215
Overall Steps per Second: 10,908.84518

Timestep Collection Time: 2.11706
Timestep Consumption Time: 2.46894
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.58600

Cumulative Model Updates: 242,730
Cumulative Timesteps: 2,024,386,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2024386148...
Checkpoint 2024386148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.76714
Policy Entropy: 2.25198
Value Function Loss: 0.01733

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.59580

Collected Steps per Second: 22,655.50262
Overall Steps per Second: 10,814.09555

Timestep Collection Time: 2.20803
Timestep Consumption Time: 2.41779
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.62581

Cumulative Model Updates: 242,736
Cumulative Timesteps: 2,024,436,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.22522
Policy Entropy: 2.24995
Value Function Loss: 0.01732

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.53294
Value Function Update Magnitude: 0.58348

Collected Steps per Second: 23,299.49140
Overall Steps per Second: 10,998.09783

Timestep Collection Time: 2.14666
Timestep Consumption Time: 2.40104
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.54770

Cumulative Model Updates: 242,742
Cumulative Timesteps: 2,024,486,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2024486188...
Checkpoint 2024486188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.61948
Policy Entropy: 2.24181
Value Function Loss: 0.01675

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 22,709.79554
Overall Steps per Second: 10,808.91567

Timestep Collection Time: 2.20222
Timestep Consumption Time: 2.42470
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.62692

Cumulative Model Updates: 242,748
Cumulative Timesteps: 2,024,536,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.79314
Policy Entropy: 2.24307
Value Function Loss: 0.01724

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.53506
Value Function Update Magnitude: 0.60193

Collected Steps per Second: 21,431.05896
Overall Steps per Second: 10,407.80507

Timestep Collection Time: 2.33306
Timestep Consumption Time: 2.47102
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.80409

Cumulative Model Updates: 242,754
Cumulative Timesteps: 2,024,586,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2024586200...
Checkpoint 2024586200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.98941
Policy Entropy: 2.24698
Value Function Loss: 0.01608

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.61734

Collected Steps per Second: 22,404.62015
Overall Steps per Second: 10,646.12972

Timestep Collection Time: 2.23293
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.69917

Cumulative Model Updates: 242,760
Cumulative Timesteps: 2,024,636,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.59930
Policy Entropy: 2.25554
Value Function Loss: 0.01676

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.53558
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 22,654.21381
Overall Steps per Second: 10,836.33004

Timestep Collection Time: 2.20824
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61651

Cumulative Model Updates: 242,766
Cumulative Timesteps: 2,024,686,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2024686254...
Checkpoint 2024686254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.90131
Policy Entropy: 2.26556
Value Function Loss: 0.01690

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.62984

Collected Steps per Second: 23,319.17156
Overall Steps per Second: 10,779.34649

Timestep Collection Time: 2.14519
Timestep Consumption Time: 2.49554
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.64073

Cumulative Model Updates: 242,772
Cumulative Timesteps: 2,024,736,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.76027
Policy Entropy: 2.27950
Value Function Loss: 0.01776

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.55120
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 23,287.86858
Overall Steps per Second: 10,868.42506

Timestep Collection Time: 2.14764
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.60177

Cumulative Model Updates: 242,778
Cumulative Timesteps: 2,024,786,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2024786292...
Checkpoint 2024786292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.13956
Policy Entropy: 2.26459
Value Function Loss: 0.01800

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.62584

Collected Steps per Second: 22,569.74062
Overall Steps per Second: 10,584.73364

Timestep Collection Time: 2.21633
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.72586

Cumulative Model Updates: 242,784
Cumulative Timesteps: 2,024,836,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.43631
Policy Entropy: 2.25106
Value Function Loss: 0.01817

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.54700
Value Function Update Magnitude: 0.64656

Collected Steps per Second: 22,852.70239
Overall Steps per Second: 10,954.80816

Timestep Collection Time: 2.18819
Timestep Consumption Time: 2.37657
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.56475

Cumulative Model Updates: 242,790
Cumulative Timesteps: 2,024,886,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2024886320...
Checkpoint 2024886320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.54249
Policy Entropy: 2.22951
Value Function Loss: 0.01801

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.66687

Collected Steps per Second: 22,994.37328
Overall Steps per Second: 10,722.04338

Timestep Collection Time: 2.17523
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.66497

Cumulative Model Updates: 242,796
Cumulative Timesteps: 2,024,936,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.27666
Policy Entropy: 2.25467
Value Function Loss: 0.01631

Mean KL Divergence: 0.02775
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.52499
Value Function Update Magnitude: 0.66135

Collected Steps per Second: 23,627.65760
Overall Steps per Second: 10,818.02224

Timestep Collection Time: 2.11659
Timestep Consumption Time: 2.50625
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.62284

Cumulative Model Updates: 242,802
Cumulative Timesteps: 2,024,986,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2024986348...
Checkpoint 2024986348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.82690
Policy Entropy: 2.26277
Value Function Loss: 0.01681

Mean KL Divergence: 0.03121
SB3 Clip Fraction: 0.17047
Policy Update Magnitude: 0.50993
Value Function Update Magnitude: 0.63915

Collected Steps per Second: 22,606.82856
Overall Steps per Second: 10,681.97673

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.47005
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.68265

Cumulative Model Updates: 242,808
Cumulative Timesteps: 2,025,036,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.39380
Policy Entropy: 2.24665
Value Function Loss: 0.01698

Mean KL Divergence: 0.02768
SB3 Clip Fraction: 0.16432
Policy Update Magnitude: 0.52216
Value Function Update Magnitude: 0.64508

Collected Steps per Second: 22,720.32190
Overall Steps per Second: 10,870.17626

Timestep Collection Time: 2.20085
Timestep Consumption Time: 2.39926
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.60011

Cumulative Model Updates: 242,814
Cumulative Timesteps: 2,025,086,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2025086372...
Checkpoint 2025086372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.84876
Policy Entropy: 2.23233
Value Function Loss: 0.01770

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.16710
Policy Update Magnitude: 0.51896
Value Function Update Magnitude: 0.64020

Collected Steps per Second: 22,442.50371
Overall Steps per Second: 10,811.46778

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.39728
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.62564

Cumulative Model Updates: 242,820
Cumulative Timesteps: 2,025,136,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.46908
Policy Entropy: 2.19813
Value Function Loss: 0.01758

Mean KL Divergence: 0.02999
SB3 Clip Fraction: 0.17296
Policy Update Magnitude: 0.51737
Value Function Update Magnitude: 0.63537

Collected Steps per Second: 23,286.13102
Overall Steps per Second: 10,744.71032

Timestep Collection Time: 2.14746
Timestep Consumption Time: 2.50655
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.65401

Cumulative Model Updates: 242,826
Cumulative Timesteps: 2,025,186,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2025186388...
Checkpoint 2025186388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.92113
Policy Entropy: 2.17156
Value Function Loss: 0.01835

Mean KL Divergence: 0.02540
SB3 Clip Fraction: 0.16468
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.63953

Collected Steps per Second: 22,609.63367
Overall Steps per Second: 10,624.99171

Timestep Collection Time: 2.21189
Timestep Consumption Time: 2.49494
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.70683

Cumulative Model Updates: 242,832
Cumulative Timesteps: 2,025,236,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.72270
Policy Entropy: 2.14216
Value Function Loss: 0.01841

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.15762
Policy Update Magnitude: 0.57513
Value Function Update Magnitude: 0.62289

Collected Steps per Second: 23,120.89558
Overall Steps per Second: 10,970.18127

Timestep Collection Time: 2.16306
Timestep Consumption Time: 2.39584
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.55890

Cumulative Model Updates: 242,838
Cumulative Timesteps: 2,025,286,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2025286410...
Checkpoint 2025286410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.75284
Policy Entropy: 2.16220
Value Function Loss: 0.01928

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.58194
Value Function Update Magnitude: 0.63061

Collected Steps per Second: 23,214.24210
Overall Steps per Second: 10,794.47113

Timestep Collection Time: 2.15385
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.63200

Cumulative Model Updates: 242,844
Cumulative Timesteps: 2,025,336,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.93066
Policy Entropy: 2.19098
Value Function Loss: 0.01981

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.58455
Value Function Update Magnitude: 0.65009

Collected Steps per Second: 23,492.61882
Overall Steps per Second: 10,826.19814

Timestep Collection Time: 2.12841
Timestep Consumption Time: 2.49020
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.61861

Cumulative Model Updates: 242,850
Cumulative Timesteps: 2,025,386,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2025386412...
Checkpoint 2025386412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.32003
Policy Entropy: 2.22004
Value Function Loss: 0.01935

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.56851
Value Function Update Magnitude: 0.66221

Collected Steps per Second: 22,703.10411
Overall Steps per Second: 10,690.33974

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.47498
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.67749

Cumulative Model Updates: 242,856
Cumulative Timesteps: 2,025,436,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.87869
Policy Entropy: 2.22667
Value Function Loss: 0.01867

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.55367
Value Function Update Magnitude: 0.64779

Collected Steps per Second: 23,348.52598
Overall Steps per Second: 10,834.42443

Timestep Collection Time: 2.14189
Timestep Consumption Time: 2.47395
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.61584

Cumulative Model Updates: 242,862
Cumulative Timesteps: 2,025,486,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2025486426...
Checkpoint 2025486426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.68147
Policy Entropy: 2.21904
Value Function Loss: 0.01762

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.55635
Value Function Update Magnitude: 0.61716

Collected Steps per Second: 23,655.26041
Overall Steps per Second: 11,020.62028

Timestep Collection Time: 2.11412
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.53786

Cumulative Model Updates: 242,868
Cumulative Timesteps: 2,025,536,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.46616
Policy Entropy: 2.19802
Value Function Loss: 0.01848

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.60136

Collected Steps per Second: 22,967.68549
Overall Steps per Second: 10,842.75958

Timestep Collection Time: 2.17715
Timestep Consumption Time: 2.43460
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.61174

Cumulative Model Updates: 242,874
Cumulative Timesteps: 2,025,586,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2025586440...
Checkpoint 2025586440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.85847
Policy Entropy: 2.18791
Value Function Loss: 0.01898

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.55921
Value Function Update Magnitude: 0.59567

Collected Steps per Second: 22,342.95257
Overall Steps per Second: 10,667.80925

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.44984
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.68831

Cumulative Model Updates: 242,880
Cumulative Timesteps: 2,025,636,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.02410
Policy Entropy: 2.20161
Value Function Loss: 0.01812

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.58694

Collected Steps per Second: 22,787.53174
Overall Steps per Second: 10,957.44694

Timestep Collection Time: 2.19620
Timestep Consumption Time: 2.37110
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.56730

Cumulative Model Updates: 242,886
Cumulative Timesteps: 2,025,686,500

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2025686500...
Checkpoint 2025686500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.67411
Policy Entropy: 2.19737
Value Function Loss: 0.01794

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.59165

Collected Steps per Second: 22,685.27316
Overall Steps per Second: 10,605.32057

Timestep Collection Time: 2.20451
Timestep Consumption Time: 2.51104
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.71556

Cumulative Model Updates: 242,892
Cumulative Timesteps: 2,025,736,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.17167
Policy Entropy: 2.17887
Value Function Loss: 0.01664

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.53645
Value Function Update Magnitude: 0.59331

Collected Steps per Second: 23,103.11857
Overall Steps per Second: 10,841.10543

Timestep Collection Time: 2.16473
Timestep Consumption Time: 2.44845
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.61318

Cumulative Model Updates: 242,898
Cumulative Timesteps: 2,025,786,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2025786522...
Checkpoint 2025786522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.17812
Policy Entropy: 2.14554
Value Function Loss: 0.01783

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.59671

Collected Steps per Second: 22,206.80293
Overall Steps per Second: 10,663.49362

Timestep Collection Time: 2.25201
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.68983

Cumulative Model Updates: 242,904
Cumulative Timesteps: 2,025,836,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.67612
Policy Entropy: 2.17554
Value Function Loss: 0.01744

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.55014
Value Function Update Magnitude: 0.60606

Collected Steps per Second: 23,183.63022
Overall Steps per Second: 10,972.33919

Timestep Collection Time: 2.15687
Timestep Consumption Time: 2.40041
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.55728

Cumulative Model Updates: 242,910
Cumulative Timesteps: 2,025,886,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2025886536...
Checkpoint 2025886536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.77063
Policy Entropy: 2.16241
Value Function Loss: 0.01872

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.61838

Collected Steps per Second: 22,987.57397
Overall Steps per Second: 10,706.80197

Timestep Collection Time: 2.17605
Timestep Consumption Time: 2.49594
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67198

Cumulative Model Updates: 242,916
Cumulative Timesteps: 2,025,936,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.88780
Policy Entropy: 2.18331
Value Function Loss: 0.01811

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.56499
Value Function Update Magnitude: 0.63047

Collected Steps per Second: 23,333.04868
Overall Steps per Second: 10,828.27724

Timestep Collection Time: 2.14297
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.61772

Cumulative Model Updates: 242,922
Cumulative Timesteps: 2,025,986,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2025986560...
Checkpoint 2025986560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.57841
Policy Entropy: 2.18289
Value Function Loss: 0.01713

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.62517

Collected Steps per Second: 22,503.76173
Overall Steps per Second: 10,623.60195

Timestep Collection Time: 2.22238
Timestep Consumption Time: 2.48525
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70763

Cumulative Model Updates: 242,928
Cumulative Timesteps: 2,026,036,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.54191
Policy Entropy: 2.21155
Value Function Loss: 0.01657

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.53973
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 22,956.71894
Overall Steps per Second: 10,965.22302

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.38329
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.56261

Cumulative Model Updates: 242,934
Cumulative Timesteps: 2,026,086,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2026086602...
Checkpoint 2026086602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.99674
Policy Entropy: 2.22039
Value Function Loss: 0.01586

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.58064

Collected Steps per Second: 22,454.61897
Overall Steps per Second: 10,604.26296

Timestep Collection Time: 2.22716
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71603

Cumulative Model Updates: 242,940
Cumulative Timesteps: 2,026,136,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.82029
Policy Entropy: 2.20019
Value Function Loss: 0.01733

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.54711
Value Function Update Magnitude: 0.59664

Collected Steps per Second: 22,827.87944
Overall Steps per Second: 10,817.49233

Timestep Collection Time: 2.19109
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62381

Cumulative Model Updates: 242,946
Cumulative Timesteps: 2,026,186,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2026186630...
Checkpoint 2026186630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.42212
Policy Entropy: 2.20179
Value Function Loss: 0.01653

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.54544
Value Function Update Magnitude: 0.60563

Collected Steps per Second: 22,157.37023
Overall Steps per Second: 10,751.37145

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.39446
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.65150

Cumulative Model Updates: 242,952
Cumulative Timesteps: 2,026,236,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.09874
Policy Entropy: 2.18818
Value Function Loss: 0.01753

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.54991
Value Function Update Magnitude: 0.63439

Collected Steps per Second: 22,744.35965
Overall Steps per Second: 10,919.84975

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.38123
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.58028

Cumulative Model Updates: 242,958
Cumulative Timesteps: 2,026,286,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2026286656...
Checkpoint 2026286656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.48590
Policy Entropy: 2.20779
Value Function Loss: 0.01717

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.54305
Value Function Update Magnitude: 0.63810

Collected Steps per Second: 22,744.04171
Overall Steps per Second: 10,594.55253

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.52143
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.72016

Cumulative Model Updates: 242,964
Cumulative Timesteps: 2,026,336,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.85687
Policy Entropy: 2.21431
Value Function Loss: 0.01775

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.54623
Value Function Update Magnitude: 0.63748

Collected Steps per Second: 23,641.10435
Overall Steps per Second: 10,839.54234

Timestep Collection Time: 2.11606
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.61514

Cumulative Model Updates: 242,970
Cumulative Timesteps: 2,026,386,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2026386690...
Checkpoint 2026386690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.76428
Policy Entropy: 2.21121
Value Function Loss: 0.01808

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.55271
Value Function Update Magnitude: 0.64023

Collected Steps per Second: 22,614.16306
Overall Steps per Second: 10,723.91578

Timestep Collection Time: 2.21127
Timestep Consumption Time: 2.45177
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.66304

Cumulative Model Updates: 242,976
Cumulative Timesteps: 2,026,436,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.75189
Policy Entropy: 2.21712
Value Function Loss: 0.01822

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.56090
Value Function Update Magnitude: 0.63346

Collected Steps per Second: 23,147.53320
Overall Steps per Second: 10,935.53175

Timestep Collection Time: 2.16066
Timestep Consumption Time: 2.41287
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.57353

Cumulative Model Updates: 242,982
Cumulative Timesteps: 2,026,486,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2026486710...
Checkpoint 2026486710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.28419
Policy Entropy: 2.22437
Value Function Loss: 0.01743

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.62837

Collected Steps per Second: 22,160.79347
Overall Steps per Second: 10,658.13743

Timestep Collection Time: 2.25660
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.69200

Cumulative Model Updates: 242,988
Cumulative Timesteps: 2,026,536,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.48179
Policy Entropy: 2.22485
Value Function Loss: 0.01603

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.62170

Collected Steps per Second: 22,965.69916
Overall Steps per Second: 10,825.58044

Timestep Collection Time: 2.17864
Timestep Consumption Time: 2.44319
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.62183

Cumulative Model Updates: 242,994
Cumulative Timesteps: 2,026,586,752

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2026586752...
Checkpoint 2026586752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.18072
Policy Entropy: 2.21166
Value Function Loss: 0.01580

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.52521
Value Function Update Magnitude: 0.60215

Collected Steps per Second: 22,577.19620
Overall Steps per Second: 10,806.45102

Timestep Collection Time: 2.21507
Timestep Consumption Time: 2.41272
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.62779

Cumulative Model Updates: 243,000
Cumulative Timesteps: 2,026,636,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.53624
Policy Entropy: 2.18362
Value Function Loss: 0.01698

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.54059
Value Function Update Magnitude: 0.60130

Collected Steps per Second: 23,129.66532
Overall Steps per Second: 10,798.19508

Timestep Collection Time: 2.16242
Timestep Consumption Time: 2.46947
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.63189

Cumulative Model Updates: 243,006
Cumulative Timesteps: 2,026,686,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2026686778...
Checkpoint 2026686778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.57733
Policy Entropy: 2.16648
Value Function Loss: 0.01648

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.54355
Value Function Update Magnitude: 0.61713

Collected Steps per Second: 22,820.36204
Overall Steps per Second: 10,660.05735

Timestep Collection Time: 2.19164
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.69172

Cumulative Model Updates: 243,012
Cumulative Timesteps: 2,026,736,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.85099
Policy Entropy: 2.16457
Value Function Loss: 0.01595

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.61557

Collected Steps per Second: 23,241.72477
Overall Steps per Second: 10,859.07310

Timestep Collection Time: 2.15191
Timestep Consumption Time: 2.45383
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.60573

Cumulative Model Updates: 243,018
Cumulative Timesteps: 2,026,786,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2026786806...
Checkpoint 2026786806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.80994
Policy Entropy: 2.16070
Value Function Loss: 0.01535

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.58779

Collected Steps per Second: 22,700.55870
Overall Steps per Second: 10,831.52422

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.61819

Cumulative Model Updates: 243,024
Cumulative Timesteps: 2,026,836,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.78628
Policy Entropy: 2.17937
Value Function Loss: 0.01691

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.11720
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.59636

Collected Steps per Second: 23,520.41897
Overall Steps per Second: 10,746.52555

Timestep Collection Time: 2.12641
Timestep Consumption Time: 2.52756
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.65397

Cumulative Model Updates: 243,030
Cumulative Timesteps: 2,026,886,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2026886842...
Checkpoint 2026886842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.58493
Policy Entropy: 2.18997
Value Function Loss: 0.01730

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.63365

Collected Steps per Second: 22,705.91380
Overall Steps per Second: 10,630.88824

Timestep Collection Time: 2.20304
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.70535

Cumulative Model Updates: 243,036
Cumulative Timesteps: 2,026,936,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.09645
Policy Entropy: 2.20332
Value Function Loss: 0.01708

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.62602

Collected Steps per Second: 23,125.72693
Overall Steps per Second: 10,907.41554

Timestep Collection Time: 2.16261
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.58514

Cumulative Model Updates: 243,042
Cumulative Timesteps: 2,026,986,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2026986876...
Checkpoint 2026986876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.20055
Policy Entropy: 2.19123
Value Function Loss: 0.01637

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 22,448.55883
Overall Steps per Second: 10,783.12267

Timestep Collection Time: 2.22821
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.63873

Cumulative Model Updates: 243,048
Cumulative Timesteps: 2,027,036,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.26171
Policy Entropy: 2.18588
Value Function Loss: 0.01730

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.55292
Value Function Update Magnitude: 0.63624

Collected Steps per Second: 22,725.45638
Overall Steps per Second: 10,824.58619

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.41981
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.62078

Cumulative Model Updates: 243,054
Cumulative Timesteps: 2,027,086,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2027086914...
Checkpoint 2027086914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.48290
Policy Entropy: 2.18671
Value Function Loss: 0.01802

Mean KL Divergence: 0.02652
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.56721
Value Function Update Magnitude: 0.64484

Collected Steps per Second: 22,478.49088
Overall Steps per Second: 10,600.45931

Timestep Collection Time: 2.22542
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.71904

Cumulative Model Updates: 243,060
Cumulative Timesteps: 2,027,136,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.56457
Policy Entropy: 2.20156
Value Function Loss: 0.01758

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.57059
Value Function Update Magnitude: 0.65166

Collected Steps per Second: 22,783.44735
Overall Steps per Second: 10,865.66372

Timestep Collection Time: 2.19563
Timestep Consumption Time: 2.40823
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60386

Cumulative Model Updates: 243,066
Cumulative Timesteps: 2,027,186,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2027186962...
Checkpoint 2027186962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.29341
Policy Entropy: 2.21977
Value Function Loss: 0.01705

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.55817
Value Function Update Magnitude: 0.63238

Collected Steps per Second: 22,478.02650
Overall Steps per Second: 10,766.11954

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.42087
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.64624

Cumulative Model Updates: 243,072
Cumulative Timesteps: 2,027,236,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.40605
Policy Entropy: 2.19696
Value Function Loss: 0.01745

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.55023
Value Function Update Magnitude: 0.62080

Collected Steps per Second: 23,565.01215
Overall Steps per Second: 10,873.79299

Timestep Collection Time: 2.12298
Timestep Consumption Time: 2.47781
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.60079

Cumulative Model Updates: 243,078
Cumulative Timesteps: 2,027,287,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2027287012...
Checkpoint 2027287012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.44702
Policy Entropy: 2.19123
Value Function Loss: 0.01827

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.61773

Collected Steps per Second: 22,923.13081
Overall Steps per Second: 10,717.70604

Timestep Collection Time: 2.18242
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.66779

Cumulative Model Updates: 243,084
Cumulative Timesteps: 2,027,337,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.35879
Policy Entropy: 2.17189
Value Function Loss: 0.01839

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.56906
Value Function Update Magnitude: 0.63281

Collected Steps per Second: 23,144.57053
Overall Steps per Second: 10,785.84718

Timestep Collection Time: 2.16042
Timestep Consumption Time: 2.47547
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.63589

Cumulative Model Updates: 243,090
Cumulative Timesteps: 2,027,387,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2027387042...
Checkpoint 2027387042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.86877
Policy Entropy: 2.19293
Value Function Loss: 0.01855

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.64181

Collected Steps per Second: 22,457.05830
Overall Steps per Second: 10,628.72430

Timestep Collection Time: 2.22709
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.70555

Cumulative Model Updates: 243,096
Cumulative Timesteps: 2,027,437,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.81504
Policy Entropy: 2.19695
Value Function Loss: 0.01845

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.56865
Value Function Update Magnitude: 0.63890

Collected Steps per Second: 23,408.43645
Overall Steps per Second: 10,961.49742

Timestep Collection Time: 2.13675
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.56306

Cumulative Model Updates: 243,102
Cumulative Timesteps: 2,027,487,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2027487074...
Checkpoint 2027487074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.06932
Policy Entropy: 2.16274
Value Function Loss: 0.01946

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.63863

Collected Steps per Second: 23,042.47375
Overall Steps per Second: 10,772.26006

Timestep Collection Time: 2.17017
Timestep Consumption Time: 2.47194
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.64211

Cumulative Model Updates: 243,108
Cumulative Timesteps: 2,027,537,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.24370
Policy Entropy: 2.15444
Value Function Loss: 0.01922

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.57198
Value Function Update Magnitude: 0.63034

Collected Steps per Second: 22,499.90407
Overall Steps per Second: 10,754.77477

Timestep Collection Time: 2.22303
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.65077

Cumulative Model Updates: 243,114
Cumulative Timesteps: 2,027,587,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2027587098...
Checkpoint 2027587098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.42122
Policy Entropy: 2.15954
Value Function Loss: 0.01920

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 22,369.38289
Overall Steps per Second: 10,760.77246

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.64874

Cumulative Model Updates: 243,120
Cumulative Timesteps: 2,027,637,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.50757
Policy Entropy: 2.18319
Value Function Loss: 0.01821

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.56441
Value Function Update Magnitude: 0.63736

Collected Steps per Second: 22,802.24758
Overall Steps per Second: 10,822.06680

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.62370

Cumulative Model Updates: 243,126
Cumulative Timesteps: 2,027,687,160

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2027687160...
Checkpoint 2027687160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.50547
Policy Entropy: 2.20737
Value Function Loss: 0.01763

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.55178
Value Function Update Magnitude: 0.64036

Collected Steps per Second: 23,111.02321
Overall Steps per Second: 10,638.97113

Timestep Collection Time: 2.16399
Timestep Consumption Time: 2.53684
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.70083

Cumulative Model Updates: 243,132
Cumulative Timesteps: 2,027,737,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.89457
Policy Entropy: 2.17192
Value Function Loss: 0.01769

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.60716

Collected Steps per Second: 22,923.75167
Overall Steps per Second: 10,823.62404

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.43955
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.62174

Cumulative Model Updates: 243,138
Cumulative Timesteps: 2,027,787,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2027787196...
Checkpoint 2027787196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.51944
Policy Entropy: 2.16727
Value Function Loss: 0.01911

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.58975

Collected Steps per Second: 22,788.58887
Overall Steps per Second: 10,675.39388

Timestep Collection Time: 2.19496
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.68554

Cumulative Model Updates: 243,144
Cumulative Timesteps: 2,027,837,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.36796
Policy Entropy: 2.15765
Value Function Loss: 0.01896

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.58061
Value Function Update Magnitude: 0.61702

Collected Steps per Second: 23,295.13303
Overall Steps per Second: 10,931.90550

Timestep Collection Time: 2.14749
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.57615

Cumulative Model Updates: 243,150
Cumulative Timesteps: 2,027,887,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2027887242...
Checkpoint 2027887242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.74094
Policy Entropy: 2.14824
Value Function Loss: 0.01939

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.58347
Value Function Update Magnitude: 0.62429

Collected Steps per Second: 23,030.39638
Overall Steps per Second: 10,732.99615

Timestep Collection Time: 2.17243
Timestep Consumption Time: 2.48908
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.66151

Cumulative Model Updates: 243,156
Cumulative Timesteps: 2,027,937,274

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.09235
Policy Entropy: 2.18227
Value Function Loss: 0.01872

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.57247
Value Function Update Magnitude: 0.60993

Collected Steps per Second: 23,225.42080
Overall Steps per Second: 10,822.27982

Timestep Collection Time: 2.15471
Timestep Consumption Time: 2.46946
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.62416

Cumulative Model Updates: 243,162
Cumulative Timesteps: 2,027,987,318

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2027987318...
Checkpoint 2027987318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.54029
Policy Entropy: 2.15817
Value Function Loss: 0.01905

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.59855

Collected Steps per Second: 22,422.33466
Overall Steps per Second: 10,665.08098

Timestep Collection Time: 2.23108
Timestep Consumption Time: 2.45956
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69063

Cumulative Model Updates: 243,168
Cumulative Timesteps: 2,028,037,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.08584
Policy Entropy: 2.18630
Value Function Loss: 0.01893

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.58376

Collected Steps per Second: 23,702.54940
Overall Steps per Second: 10,906.14846

Timestep Collection Time: 2.10998
Timestep Consumption Time: 2.47569
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.58567

Cumulative Model Updates: 243,174
Cumulative Timesteps: 2,028,087,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2028087356...
Checkpoint 2028087356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.76680
Policy Entropy: 2.16635
Value Function Loss: 0.01868

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.57398

Collected Steps per Second: 22,789.11231
Overall Steps per Second: 10,670.51267

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.68712

Cumulative Model Updates: 243,180
Cumulative Timesteps: 2,028,137,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.86722
Policy Entropy: 2.18592
Value Function Loss: 0.01816

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11710
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.57963

Collected Steps per Second: 22,803.21853
Overall Steps per Second: 10,801.94695

Timestep Collection Time: 2.19355
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63065

Cumulative Model Updates: 243,186
Cumulative Timesteps: 2,028,187,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2028187390...
Checkpoint 2028187390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.74932
Policy Entropy: 2.16001
Value Function Loss: 0.01840

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.59590

Collected Steps per Second: 22,588.28341
Overall Steps per Second: 10,708.19284

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.45637
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.67044

Cumulative Model Updates: 243,192
Cumulative Timesteps: 2,028,237,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.07646
Policy Entropy: 2.13327
Value Function Loss: 0.01885

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.57129
Value Function Update Magnitude: 0.60603

Collected Steps per Second: 23,995.36325
Overall Steps per Second: 10,938.96987

Timestep Collection Time: 2.08474
Timestep Consumption Time: 2.48827
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.57301

Cumulative Model Updates: 243,198
Cumulative Timesteps: 2,028,287,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2028287426...
Checkpoint 2028287426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.09920
Policy Entropy: 2.10787
Value Function Loss: 0.01930

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.57753
Value Function Update Magnitude: 0.61120

Collected Steps per Second: 22,797.60303
Overall Steps per Second: 10,663.02266

Timestep Collection Time: 2.19374
Timestep Consumption Time: 2.49649
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69023

Cumulative Model Updates: 243,204
Cumulative Timesteps: 2,028,337,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.10018
Policy Entropy: 2.10164
Value Function Loss: 0.01841

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.62415

Collected Steps per Second: 23,147.72814
Overall Steps per Second: 10,892.43215

Timestep Collection Time: 2.16047
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.59126

Cumulative Model Updates: 243,210
Cumulative Timesteps: 2,028,387,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2028387448...
Checkpoint 2028387448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.67121
Policy Entropy: 2.11230
Value Function Loss: 0.01675

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.61664

Collected Steps per Second: 22,174.94689
Overall Steps per Second: 10,578.59531

Timestep Collection Time: 2.25516
Timestep Consumption Time: 2.47212
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.72728

Cumulative Model Updates: 243,216
Cumulative Timesteps: 2,028,437,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.81645
Policy Entropy: 2.15058
Value Function Loss: 0.01656

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.59559

Collected Steps per Second: 23,375.16067
Overall Steps per Second: 10,943.29056

Timestep Collection Time: 2.13996
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.57102

Cumulative Model Updates: 243,222
Cumulative Timesteps: 2,028,487,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2028487478...
Checkpoint 2028487478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.29697
Policy Entropy: 2.17923
Value Function Loss: 0.01619

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.58080

Collected Steps per Second: 22,994.11474
Overall Steps per Second: 10,717.68020

Timestep Collection Time: 2.17508
Timestep Consumption Time: 2.49142
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.66649

Cumulative Model Updates: 243,228
Cumulative Timesteps: 2,028,537,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.28548
Policy Entropy: 2.17308
Value Function Loss: 0.01712

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.57003

Collected Steps per Second: 22,463.83000
Overall Steps per Second: 10,729.72396

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.66275

Cumulative Model Updates: 243,234
Cumulative Timesteps: 2,028,587,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2028587522...
Checkpoint 2028587522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.69280
Policy Entropy: 2.15430
Value Function Loss: 0.01711

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.58337

Collected Steps per Second: 22,209.70535
Overall Steps per Second: 10,748.76523

Timestep Collection Time: 2.25154
Timestep Consumption Time: 2.40072
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.65226

Cumulative Model Updates: 243,240
Cumulative Timesteps: 2,028,637,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.80864
Policy Entropy: 2.15117
Value Function Loss: 0.01737

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.60091

Collected Steps per Second: 22,701.41790
Overall Steps per Second: 10,812.75033

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.62639

Cumulative Model Updates: 243,246
Cumulative Timesteps: 2,028,687,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2028687552...
Checkpoint 2028687552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.34320
Policy Entropy: 2.18553
Value Function Loss: 0.01692

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.60682

Collected Steps per Second: 22,710.40370
Overall Steps per Second: 10,744.92256

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.65355

Cumulative Model Updates: 243,252
Cumulative Timesteps: 2,028,737,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.81884
Policy Entropy: 2.19795
Value Function Loss: 0.01710

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.58863

Collected Steps per Second: 23,234.62412
Overall Steps per Second: 10,872.43343

Timestep Collection Time: 2.15231
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59952

Cumulative Model Updates: 243,258
Cumulative Timesteps: 2,028,787,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2028787562...
Checkpoint 2028787562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.78933
Policy Entropy: 2.18702
Value Function Loss: 0.01737

Mean KL Divergence: 0.02342
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.59358

Collected Steps per Second: 23,653.44403
Overall Steps per Second: 11,010.56159

Timestep Collection Time: 2.11436
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.54218

Cumulative Model Updates: 243,264
Cumulative Timesteps: 2,028,837,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.78648
Policy Entropy: 2.17275
Value Function Loss: 0.01803

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.61575

Collected Steps per Second: 22,840.22744
Overall Steps per Second: 10,697.87019

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.67626

Cumulative Model Updates: 243,270
Cumulative Timesteps: 2,028,887,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2028887600...
Checkpoint 2028887600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.57099
Policy Entropy: 2.17820
Value Function Loss: 0.01898

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.63133

Collected Steps per Second: 22,958.13974
Overall Steps per Second: 10,922.37403

Timestep Collection Time: 2.17901
Timestep Consumption Time: 2.40113
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.58014

Cumulative Model Updates: 243,276
Cumulative Timesteps: 2,028,937,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.89994
Policy Entropy: 2.18219
Value Function Loss: 0.01963

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.55369
Value Function Update Magnitude: 0.62835

Collected Steps per Second: 22,941.23538
Overall Steps per Second: 10,972.38675

Timestep Collection Time: 2.17983
Timestep Consumption Time: 2.37779
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.55762

Cumulative Model Updates: 243,282
Cumulative Timesteps: 2,028,987,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2028987634...
Checkpoint 2028987634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.56711
Policy Entropy: 2.17062
Value Function Loss: 0.01901

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.61193

Collected Steps per Second: 23,166.97271
Overall Steps per Second: 10,773.50221

Timestep Collection Time: 2.15833
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.64120

Cumulative Model Updates: 243,288
Cumulative Timesteps: 2,029,037,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.83855
Policy Entropy: 2.15228
Value Function Loss: 0.01823

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.15338
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.59750

Collected Steps per Second: 22,699.39928
Overall Steps per Second: 10,784.08794

Timestep Collection Time: 2.20420
Timestep Consumption Time: 2.43541
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.63961

Cumulative Model Updates: 243,294
Cumulative Timesteps: 2,029,087,670

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2029087670...
Checkpoint 2029087670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.74366
Policy Entropy: 2.12830
Value Function Loss: 0.01911

Mean KL Divergence: 0.02846
SB3 Clip Fraction: 0.16580
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.60220

Collected Steps per Second: 22,313.49013
Overall Steps per Second: 10,595.64511

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.72175

Cumulative Model Updates: 243,300
Cumulative Timesteps: 2,029,137,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.03041
Policy Entropy: 2.11560
Value Function Loss: 0.01916

Mean KL Divergence: 0.03030
SB3 Clip Fraction: 0.17451
Policy Update Magnitude: 0.57669
Value Function Update Magnitude: 0.62469

Collected Steps per Second: 22,556.07408
Overall Steps per Second: 10,813.86653

Timestep Collection Time: 2.21838
Timestep Consumption Time: 2.40882
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.62721

Cumulative Model Updates: 243,306
Cumulative Timesteps: 2,029,187,738

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2029187738...
Checkpoint 2029187738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.85678
Policy Entropy: 2.11838
Value Function Loss: 0.01874

Mean KL Divergence: 0.02811
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.58165
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 23,272.49837
Overall Steps per Second: 10,745.75506

Timestep Collection Time: 2.14906
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.65430

Cumulative Model Updates: 243,312
Cumulative Timesteps: 2,029,237,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.78571
Policy Entropy: 2.14800
Value Function Loss: 0.01686

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.56567
Value Function Update Magnitude: 0.62297

Collected Steps per Second: 23,341.22201
Overall Steps per Second: 10,862.82841

Timestep Collection Time: 2.14282
Timestep Consumption Time: 2.46151
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.60433

Cumulative Model Updates: 243,318
Cumulative Timesteps: 2,029,287,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2029287768...
Checkpoint 2029287768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.72030
Policy Entropy: 2.15261
Value Function Loss: 0.01718

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.61018

Collected Steps per Second: 22,946.05173
Overall Steps per Second: 10,667.21561

Timestep Collection Time: 2.17972
Timestep Consumption Time: 2.50904
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.68876

Cumulative Model Updates: 243,324
Cumulative Timesteps: 2,029,337,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.69904
Policy Entropy: 2.15223
Value Function Loss: 0.01785

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.58911

Collected Steps per Second: 22,967.09445
Overall Steps per Second: 10,928.70725

Timestep Collection Time: 2.17825
Timestep Consumption Time: 2.39942
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.57767

Cumulative Model Updates: 243,330
Cumulative Timesteps: 2,029,387,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2029387812...
Checkpoint 2029387812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.18377
Policy Entropy: 2.17950
Value Function Loss: 0.01829

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.58828

Collected Steps per Second: 22,866.69814
Overall Steps per Second: 10,677.08554

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.68555

Cumulative Model Updates: 243,336
Cumulative Timesteps: 2,029,437,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.31698
Policy Entropy: 2.18107
Value Function Loss: 0.01821

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.60273

Collected Steps per Second: 22,728.46278
Overall Steps per Second: 10,784.89300

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.63649

Cumulative Model Updates: 243,342
Cumulative Timesteps: 2,029,487,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2029487844...
Checkpoint 2029487844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.36536
Policy Entropy: 2.18217
Value Function Loss: 0.01734

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.60623

Collected Steps per Second: 22,820.84917
Overall Steps per Second: 10,715.04866

Timestep Collection Time: 2.19133
Timestep Consumption Time: 2.47575
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.66708

Cumulative Model Updates: 243,348
Cumulative Timesteps: 2,029,537,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.12737
Policy Entropy: 2.16376
Value Function Loss: 0.01727

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.54128
Value Function Update Magnitude: 0.60830

Collected Steps per Second: 22,434.71917
Overall Steps per Second: 10,905.54150

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.35698
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.58648

Cumulative Model Updates: 243,354
Cumulative Timesteps: 2,029,587,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2029587870...
Checkpoint 2029587870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.84338
Policy Entropy: 2.15834
Value Function Loss: 0.01623

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.61453

Collected Steps per Second: 22,343.61569
Overall Steps per Second: 10,643.89860

Timestep Collection Time: 2.23787
Timestep Consumption Time: 2.45985
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.69771

Cumulative Model Updates: 243,360
Cumulative Timesteps: 2,029,637,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.39221
Policy Entropy: 2.15487
Value Function Loss: 0.01655

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.53744
Value Function Update Magnitude: 0.61600

Collected Steps per Second: 22,794.52716
Overall Steps per Second: 10,819.49297

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.62184

Cumulative Model Updates: 243,366
Cumulative Timesteps: 2,029,687,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2029687878...
Checkpoint 2029687878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.31129
Policy Entropy: 2.15231
Value Function Loss: 0.01680

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.61189

Collected Steps per Second: 22,893.26306
Overall Steps per Second: 10,749.59819

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.46739
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.65152

Cumulative Model Updates: 243,372
Cumulative Timesteps: 2,029,737,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.56647
Policy Entropy: 2.14571
Value Function Loss: 0.01833

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.63357

Collected Steps per Second: 22,712.77139
Overall Steps per Second: 10,846.02978

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.40973
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.61219

Cumulative Model Updates: 243,378
Cumulative Timesteps: 2,029,787,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2029787904...
Checkpoint 2029787904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.00282
Policy Entropy: 2.14594
Value Function Loss: 0.01810

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.65295

Collected Steps per Second: 22,916.60711
Overall Steps per Second: 10,698.01340

Timestep Collection Time: 2.18296
Timestep Consumption Time: 2.49324
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.67620

Cumulative Model Updates: 243,384
Cumulative Timesteps: 2,029,837,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.56596
Policy Entropy: 2.14160
Value Function Loss: 0.01771

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.55452
Value Function Update Magnitude: 0.63293

Collected Steps per Second: 22,943.11102
Overall Steps per Second: 10,832.13218

Timestep Collection Time: 2.18026
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.61793

Cumulative Model Updates: 243,390
Cumulative Timesteps: 2,029,887,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2029887952...
Checkpoint 2029887952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.84049
Policy Entropy: 2.14848
Value Function Loss: 0.01641

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.59906

Collected Steps per Second: 22,838.31236
Overall Steps per Second: 10,726.33588

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.66292

Cumulative Model Updates: 243,396
Cumulative Timesteps: 2,029,937,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.80495
Policy Entropy: 2.14951
Value Function Loss: 0.01567

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.53410
Value Function Update Magnitude: 0.58362

Collected Steps per Second: 23,118.90751
Overall Steps per Second: 10,892.42289

Timestep Collection Time: 2.16316
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.59127

Cumulative Model Updates: 243,402
Cumulative Timesteps: 2,029,987,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2029987978...
Checkpoint 2029987978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.31919
Policy Entropy: 2.15920
Value Function Loss: 0.01557

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.57941

Collected Steps per Second: 22,637.99513
Overall Steps per Second: 10,645.54017

Timestep Collection Time: 2.20876
Timestep Consumption Time: 2.48823
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.69699

Cumulative Model Updates: 243,408
Cumulative Timesteps: 2,030,037,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.36398
Policy Entropy: 2.16198
Value Function Loss: 0.01599

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.57865

Collected Steps per Second: 22,457.95161
Overall Steps per Second: 10,584.43838

Timestep Collection Time: 2.22763
Timestep Consumption Time: 2.49893
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.72656

Cumulative Model Updates: 243,414
Cumulative Timesteps: 2,030,088,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2030088008...
Checkpoint 2030088008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.97850
Policy Entropy: 2.17668
Value Function Loss: 0.01570

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.58458

Collected Steps per Second: 22,675.28762
Overall Steps per Second: 10,736.79500

Timestep Collection Time: 2.20531
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.65744

Cumulative Model Updates: 243,420
Cumulative Timesteps: 2,030,138,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.19631
Policy Entropy: 2.17222
Value Function Loss: 0.01684

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.57800

Collected Steps per Second: 23,709.55127
Overall Steps per Second: 10,923.28630

Timestep Collection Time: 2.10970
Timestep Consumption Time: 2.46951
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.57921

Cumulative Model Updates: 243,426
Cumulative Timesteps: 2,030,188,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2030188034...
Checkpoint 2030188034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.45415
Policy Entropy: 2.20044
Value Function Loss: 0.01620

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.52656
Value Function Update Magnitude: 0.57162

Collected Steps per Second: 22,830.85222
Overall Steps per Second: 10,810.44466

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62664

Cumulative Model Updates: 243,432
Cumulative Timesteps: 2,030,238,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.23937
Policy Entropy: 2.17168
Value Function Loss: 0.01673

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.52695
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 23,005.64771
Overall Steps per Second: 10,894.89056

Timestep Collection Time: 2.17347
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.58949

Cumulative Model Updates: 243,438
Cumulative Timesteps: 2,030,288,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2030288052...
Checkpoint 2030288052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.78050
Policy Entropy: 2.16833
Value Function Loss: 0.01666

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.57443

Collected Steps per Second: 22,620.31954
Overall Steps per Second: 10,716.23882

Timestep Collection Time: 2.21084
Timestep Consumption Time: 2.45591
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.66675

Cumulative Model Updates: 243,444
Cumulative Timesteps: 2,030,338,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.79097
Policy Entropy: 2.14000
Value Function Loss: 0.01746

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.52545
Value Function Update Magnitude: 0.57512

Collected Steps per Second: 22,827.00585
Overall Steps per Second: 10,838.42910

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.42399
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61543

Cumulative Model Updates: 243,450
Cumulative Timesteps: 2,030,388,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2030388086...
Checkpoint 2030388086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.21656
Policy Entropy: 2.14549
Value Function Loss: 0.01810

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.53551
Value Function Update Magnitude: 0.57432

Collected Steps per Second: 22,380.51056
Overall Steps per Second: 10,731.40948

Timestep Collection Time: 2.23471
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.66052

Cumulative Model Updates: 243,456
Cumulative Timesteps: 2,030,438,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.91904
Policy Entropy: 2.15525
Value Function Loss: 0.01838

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 22,914.15061
Overall Steps per Second: 10,835.15947

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61516

Cumulative Model Updates: 243,462
Cumulative Timesteps: 2,030,488,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2030488106...
Checkpoint 2030488106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.51357
Policy Entropy: 2.15490
Value Function Loss: 0.01925

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.54436
Value Function Update Magnitude: 0.59312

Collected Steps per Second: 22,834.48689
Overall Steps per Second: 10,702.26519

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.67471

Cumulative Model Updates: 243,468
Cumulative Timesteps: 2,030,538,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.55992
Policy Entropy: 2.14427
Value Function Loss: 0.01988

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 23,128.06287
Overall Steps per Second: 10,826.23985

Timestep Collection Time: 2.16265
Timestep Consumption Time: 2.45742
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.62007

Cumulative Model Updates: 243,474
Cumulative Timesteps: 2,030,588,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2030588154...
Checkpoint 2030588154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.60192
Policy Entropy: 2.12732
Value Function Loss: 0.01894

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.56139
Value Function Update Magnitude: 0.63257

Collected Steps per Second: 22,954.71653
Overall Steps per Second: 10,702.93852

Timestep Collection Time: 2.17855
Timestep Consumption Time: 2.49381
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.67236

Cumulative Model Updates: 243,480
Cumulative Timesteps: 2,030,638,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.69131
Policy Entropy: 2.11279
Value Function Loss: 0.01768

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.62186

Collected Steps per Second: 22,644.28318
Overall Steps per Second: 10,669.31685

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.68859

Cumulative Model Updates: 243,486
Cumulative Timesteps: 2,030,688,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2030688186...
Checkpoint 2030688186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.97418
Policy Entropy: 2.11249
Value Function Loss: 0.01703

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.53927
Value Function Update Magnitude: 0.58192

Collected Steps per Second: 23,131.49480
Overall Steps per Second: 10,871.17804

Timestep Collection Time: 2.16173
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.59969

Cumulative Model Updates: 243,492
Cumulative Timesteps: 2,030,738,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.49853
Policy Entropy: 2.12780
Value Function Loss: 0.01632

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.55491

Collected Steps per Second: 23,152.09894
Overall Steps per Second: 10,891.52729

Timestep Collection Time: 2.16084
Timestep Consumption Time: 2.43245
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.59330

Cumulative Model Updates: 243,498
Cumulative Timesteps: 2,030,788,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2030788218...
Checkpoint 2030788218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.21221
Policy Entropy: 2.13052
Value Function Loss: 0.01668

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.53957
Value Function Update Magnitude: 0.55141

Collected Steps per Second: 22,652.52746
Overall Steps per Second: 10,654.35739

Timestep Collection Time: 2.20832
Timestep Consumption Time: 2.48685
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69517

Cumulative Model Updates: 243,504
Cumulative Timesteps: 2,030,838,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.05182
Policy Entropy: 2.13128
Value Function Loss: 0.01654

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.53784
Value Function Update Magnitude: 0.56747

Collected Steps per Second: 22,536.55340
Overall Steps per Second: 10,681.81765

Timestep Collection Time: 2.21888
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.68141

Cumulative Model Updates: 243,510
Cumulative Timesteps: 2,030,888,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2030888248...
Checkpoint 2030888248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.35765
Policy Entropy: 2.11871
Value Function Loss: 0.01778

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.55733
Value Function Update Magnitude: 0.57785

Collected Steps per Second: 22,821.61349
Overall Steps per Second: 10,926.27076

Timestep Collection Time: 2.19196
Timestep Consumption Time: 2.38637
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.57832

Cumulative Model Updates: 243,516
Cumulative Timesteps: 2,030,938,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.80419
Policy Entropy: 2.10733
Value Function Loss: 0.01784

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.56088
Value Function Update Magnitude: 0.57883

Collected Steps per Second: 22,700.61739
Overall Steps per Second: 10,789.26679

Timestep Collection Time: 2.20346
Timestep Consumption Time: 2.43262
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.63609

Cumulative Model Updates: 243,522
Cumulative Timesteps: 2,030,988,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2030988292...
Checkpoint 2030988292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.94697
Policy Entropy: 2.09701
Value Function Loss: 0.01845

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.58219

Collected Steps per Second: 22,604.46080
Overall Steps per Second: 10,772.57907

Timestep Collection Time: 2.21310
Timestep Consumption Time: 2.43072
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.64383

Cumulative Model Updates: 243,528
Cumulative Timesteps: 2,031,038,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.21941
Policy Entropy: 2.10121
Value Function Loss: 0.01790

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.58650

Collected Steps per Second: 23,162.96962
Overall Steps per Second: 10,817.89389

Timestep Collection Time: 2.15965
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.62419

Cumulative Model Updates: 243,534
Cumulative Timesteps: 2,031,088,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2031088342...
Checkpoint 2031088342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.51987
Policy Entropy: 2.14382
Value Function Loss: 0.01725

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.54572
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 22,694.42237
Overall Steps per Second: 10,838.81095

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.61361

Cumulative Model Updates: 243,540
Cumulative Timesteps: 2,031,138,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.12417
Policy Entropy: 2.16606
Value Function Loss: 0.01720

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.55989

Collected Steps per Second: 23,344.08443
Overall Steps per Second: 10,745.23535

Timestep Collection Time: 2.14273
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.65509

Cumulative Model Updates: 243,546
Cumulative Timesteps: 2,031,188,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2031188368...
Checkpoint 2031188368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.07232
Policy Entropy: 2.16118
Value Function Loss: 0.01718

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.57134

Collected Steps per Second: 22,762.63514
Overall Steps per Second: 10,633.73709

Timestep Collection Time: 2.19667
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.70220

Cumulative Model Updates: 243,552
Cumulative Timesteps: 2,031,238,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.12221
Policy Entropy: 2.13357
Value Function Loss: 0.01787

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.58921

Collected Steps per Second: 23,083.27772
Overall Steps per Second: 10,920.23141

Timestep Collection Time: 2.16728
Timestep Consumption Time: 2.41394
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.58122

Cumulative Model Updates: 243,558
Cumulative Timesteps: 2,031,288,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2031288398...
Checkpoint 2031288398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.50048
Policy Entropy: 2.12659
Value Function Loss: 0.01852

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.59450

Collected Steps per Second: 22,398.23036
Overall Steps per Second: 10,770.02258

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.41039
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.64289

Cumulative Model Updates: 243,564
Cumulative Timesteps: 2,031,338,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.92377
Policy Entropy: 2.14096
Value Function Loss: 0.01803

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.59687

Collected Steps per Second: 22,688.25314
Overall Steps per Second: 10,830.50543

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.41339
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.61770

Cumulative Model Updates: 243,570
Cumulative Timesteps: 2,031,388,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2031388414...
Checkpoint 2031388414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.23979
Policy Entropy: 2.13735
Value Function Loss: 0.01835

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.59198

Collected Steps per Second: 22,362.61782
Overall Steps per Second: 10,628.60759

Timestep Collection Time: 2.23641
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.70541

Cumulative Model Updates: 243,576
Cumulative Timesteps: 2,031,438,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.04910
Policy Entropy: 2.15221
Value Function Loss: 0.01823

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.55795
Value Function Update Magnitude: 0.60364

Collected Steps per Second: 22,775.61782
Overall Steps per Second: 10,931.58182

Timestep Collection Time: 2.19647
Timestep Consumption Time: 2.37981
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.57628

Cumulative Model Updates: 243,582
Cumulative Timesteps: 2,031,488,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2031488452...
Checkpoint 2031488452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.06401
Policy Entropy: 2.14527
Value Function Loss: 0.01843

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.55411
Value Function Update Magnitude: 0.62746

Collected Steps per Second: 22,828.86377
Overall Steps per Second: 10,692.86457

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.48640
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.67714

Cumulative Model Updates: 243,588
Cumulative Timesteps: 2,031,538,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.44141
Policy Entropy: 2.14763
Value Function Loss: 0.01726

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.54493
Value Function Update Magnitude: 0.63249

Collected Steps per Second: 23,267.33666
Overall Steps per Second: 10,853.96886

Timestep Collection Time: 2.15005
Timestep Consumption Time: 2.45895
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.60901

Cumulative Model Updates: 243,594
Cumulative Timesteps: 2,031,588,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2031588490...
Checkpoint 2031588490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.33747
Policy Entropy: 2.17024
Value Function Loss: 0.01637

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.52938
Value Function Update Magnitude: 0.62073

Collected Steps per Second: 22,600.59454
Overall Steps per Second: 10,602.99759

Timestep Collection Time: 2.21339
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.71791

Cumulative Model Updates: 243,600
Cumulative Timesteps: 2,031,638,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.76019
Policy Entropy: 2.18123
Value Function Loss: 0.01659

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.52987
Value Function Update Magnitude: 0.59395

Collected Steps per Second: 22,934.56844
Overall Steps per Second: 10,901.32520

Timestep Collection Time: 2.18116
Timestep Consumption Time: 2.40764
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.58880

Cumulative Model Updates: 243,606
Cumulative Timesteps: 2,031,688,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2031688538...
Checkpoint 2031688538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.34435
Policy Entropy: 2.21113
Value Function Loss: 0.01580

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.57729

Collected Steps per Second: 23,871.76449
Overall Steps per Second: 10,980.31738

Timestep Collection Time: 2.09578
Timestep Consumption Time: 2.46055
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.55633

Cumulative Model Updates: 243,612
Cumulative Timesteps: 2,031,738,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.06488
Policy Entropy: 2.18937
Value Function Loss: 0.01644

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.52322
Value Function Update Magnitude: 0.56080

Collected Steps per Second: 23,092.25227
Overall Steps per Second: 10,718.61930

Timestep Collection Time: 2.16635
Timestep Consumption Time: 2.50085
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.66721

Cumulative Model Updates: 243,618
Cumulative Timesteps: 2,031,788,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2031788594...
Checkpoint 2031788594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.58047
Policy Entropy: 2.18661
Value Function Loss: 0.01721

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.53067
Value Function Update Magnitude: 0.55691

Collected Steps per Second: 23,022.24310
Overall Steps per Second: 10,945.40348

Timestep Collection Time: 2.17277
Timestep Consumption Time: 2.39737
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.57014

Cumulative Model Updates: 243,624
Cumulative Timesteps: 2,031,838,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.73043
Policy Entropy: 2.16405
Value Function Loss: 0.01777

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.53201
Value Function Update Magnitude: 0.57933

Collected Steps per Second: 22,629.20823
Overall Steps per Second: 10,960.06416

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.35389
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.56475

Cumulative Model Updates: 243,630
Cumulative Timesteps: 2,031,888,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2031888646...
Checkpoint 2031888646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.41020
Policy Entropy: 2.18131
Value Function Loss: 0.01719

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.59162

Collected Steps per Second: 22,704.87233
Overall Steps per Second: 10,690.22325

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.67998

Cumulative Model Updates: 243,636
Cumulative Timesteps: 2,031,938,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.41776
Policy Entropy: 2.17294
Value Function Loss: 0.01643

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.58553

Collected Steps per Second: 22,657.42487
Overall Steps per Second: 10,663.24592

Timestep Collection Time: 2.20775
Timestep Consumption Time: 2.48331
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.69107

Cumulative Model Updates: 243,642
Cumulative Timesteps: 2,031,988,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2031988698...
Checkpoint 2031988698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.73293
Policy Entropy: 2.17899
Value Function Loss: 0.01689

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.53197
Value Function Update Magnitude: 0.58235

Collected Steps per Second: 22,670.55905
Overall Steps per Second: 10,840.64255

Timestep Collection Time: 2.20674
Timestep Consumption Time: 2.40812
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61486

Cumulative Model Updates: 243,648
Cumulative Timesteps: 2,032,038,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.55405
Policy Entropy: 2.17236
Value Function Loss: 0.01711

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.54118
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 22,760.38275
Overall Steps per Second: 10,908.82097

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.38703
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.58418

Cumulative Model Updates: 243,654
Cumulative Timesteps: 2,032,088,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2032088734...
Checkpoint 2032088734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.26281
Policy Entropy: 2.18649
Value Function Loss: 0.01770

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.57656

Collected Steps per Second: 23,063.07828
Overall Steps per Second: 10,710.11189

Timestep Collection Time: 2.16927
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.67129

Cumulative Model Updates: 243,660
Cumulative Timesteps: 2,032,138,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.43810
Policy Entropy: 2.18612
Value Function Loss: 0.01698

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.56652

Collected Steps per Second: 22,635.70709
Overall Steps per Second: 10,778.95992

Timestep Collection Time: 2.20952
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.63997

Cumulative Model Updates: 243,666
Cumulative Timesteps: 2,032,188,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2032188778...
Checkpoint 2032188778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.12424
Policy Entropy: 2.17683
Value Function Loss: 0.01668

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.52292
Value Function Update Magnitude: 0.56700

Collected Steps per Second: 22,806.64790
Overall Steps per Second: 10,696.48976

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.67518

Cumulative Model Updates: 243,672
Cumulative Timesteps: 2,032,238,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.02955
Policy Entropy: 2.18776
Value Function Loss: 0.01675

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.53136
Value Function Update Magnitude: 0.58402

Collected Steps per Second: 23,104.53423
Overall Steps per Second: 10,957.46966

Timestep Collection Time: 2.16451
Timestep Consumption Time: 2.39950
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.56401

Cumulative Model Updates: 243,678
Cumulative Timesteps: 2,032,288,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2032288796...
Checkpoint 2032288796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.03220
Policy Entropy: 2.18576
Value Function Loss: 0.01770

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.53972
Value Function Update Magnitude: 0.60566

Collected Steps per Second: 22,512.50457
Overall Steps per Second: 10,652.31620

Timestep Collection Time: 2.22259
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.69719

Cumulative Model Updates: 243,684
Cumulative Timesteps: 2,032,338,832

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.78525
Policy Entropy: 2.16831
Value Function Loss: 0.01759

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.63176

Collected Steps per Second: 22,669.55320
Overall Steps per Second: 10,647.10154

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.69630

Cumulative Model Updates: 243,690
Cumulative Timesteps: 2,032,388,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2032388834...
Checkpoint 2032388834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.69915
Policy Entropy: 2.14489
Value Function Loss: 0.01775

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.54802
Value Function Update Magnitude: 0.63494

Collected Steps per Second: 22,619.31894
Overall Steps per Second: 10,813.17964

Timestep Collection Time: 2.21183
Timestep Consumption Time: 2.41494
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.62676

Cumulative Model Updates: 243,696
Cumulative Timesteps: 2,032,438,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.98839
Policy Entropy: 2.15628
Value Function Loss: 0.01653

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.63318

Collected Steps per Second: 22,578.69146
Overall Steps per Second: 10,919.70048

Timestep Collection Time: 2.21581
Timestep Consumption Time: 2.36582
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.58163

Cumulative Model Updates: 243,702
Cumulative Timesteps: 2,032,488,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2032488894...
Checkpoint 2032488894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.86271
Policy Entropy: 2.17517
Value Function Loss: 0.01746

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.53931
Value Function Update Magnitude: 0.62429

Collected Steps per Second: 23,159.04593
Overall Steps per Second: 10,692.48998

Timestep Collection Time: 2.15959
Timestep Consumption Time: 2.51790
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.67749

Cumulative Model Updates: 243,708
Cumulative Timesteps: 2,032,538,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.62691
Policy Entropy: 2.16959
Value Function Loss: 0.01746

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.60760

Collected Steps per Second: 23,132.92703
Overall Steps per Second: 10,836.24843

Timestep Collection Time: 2.16272
Timestep Consumption Time: 2.45419
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.61691

Cumulative Model Updates: 243,714
Cumulative Timesteps: 2,032,588,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2032588938...
Checkpoint 2032588938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.33190
Policy Entropy: 2.16702
Value Function Loss: 0.01778

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.53720
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,379.61793
Overall Steps per Second: 10,706.87926

Timestep Collection Time: 2.23462
Timestep Consumption Time: 2.43621
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.67083

Cumulative Model Updates: 243,720
Cumulative Timesteps: 2,032,638,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.69006
Policy Entropy: 2.16457
Value Function Loss: 0.01744

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.61225

Collected Steps per Second: 23,305.53495
Overall Steps per Second: 10,946.82220

Timestep Collection Time: 2.14593
Timestep Consumption Time: 2.42270
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.56863

Cumulative Model Updates: 243,726
Cumulative Timesteps: 2,032,688,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2032688960...
Checkpoint 2032688960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.36863
Policy Entropy: 2.21333
Value Function Loss: 0.01587

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.53129
Value Function Update Magnitude: 0.61244

Collected Steps per Second: 23,874.61129
Overall Steps per Second: 11,082.37673

Timestep Collection Time: 2.09553
Timestep Consumption Time: 2.41884
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.51437

Cumulative Model Updates: 243,732
Cumulative Timesteps: 2,032,738,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.97679
Policy Entropy: 2.22141
Value Function Loss: 0.01564

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.52204
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 23,022.88808
Overall Steps per Second: 10,871.11872

Timestep Collection Time: 2.17193
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.59971

Cumulative Model Updates: 243,738
Cumulative Timesteps: 2,032,788,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2032788994...
Checkpoint 2032788994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.00002
Policy Entropy: 2.22104
Value Function Loss: 0.01437

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.51391
Value Function Update Magnitude: 0.57505

Collected Steps per Second: 21,864.77220
Overall Steps per Second: 10,619.35487

Timestep Collection Time: 2.28770
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71027

Cumulative Model Updates: 243,744
Cumulative Timesteps: 2,032,839,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.68582
Policy Entropy: 2.20065
Value Function Loss: 0.01619

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.57114

Collected Steps per Second: 22,493.78546
Overall Steps per Second: 10,904.31449

Timestep Collection Time: 2.22301
Timestep Consumption Time: 2.36269
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.58571

Cumulative Model Updates: 243,750
Cumulative Timesteps: 2,032,889,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2032889018...
Checkpoint 2032889018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.94377
Policy Entropy: 2.19051
Value Function Loss: 0.01639

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.54532
Value Function Update Magnitude: 0.59650

Collected Steps per Second: 22,502.69631
Overall Steps per Second: 10,689.86019

Timestep Collection Time: 2.22258
Timestep Consumption Time: 2.45606
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.67864

Cumulative Model Updates: 243,756
Cumulative Timesteps: 2,032,939,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.77889
Policy Entropy: 2.18153
Value Function Loss: 0.01646

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.60790

Collected Steps per Second: 22,736.28860
Overall Steps per Second: 10,658.41477

Timestep Collection Time: 2.19966
Timestep Consumption Time: 2.49260
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.69225

Cumulative Model Updates: 243,762
Cumulative Timesteps: 2,032,989,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2032989044...
Checkpoint 2032989044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.84562
Policy Entropy: 2.15805
Value Function Loss: 0.01594

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.53430
Value Function Update Magnitude: 0.59577

Collected Steps per Second: 22,922.90827
Overall Steps per Second: 10,820.64898

Timestep Collection Time: 2.18140
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.62116

Cumulative Model Updates: 243,768
Cumulative Timesteps: 2,033,039,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.34706
Policy Entropy: 2.15688
Value Function Loss: 0.01628

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.53307
Value Function Update Magnitude: 0.59133

Collected Steps per Second: 24,065.78642
Overall Steps per Second: 11,011.78519

Timestep Collection Time: 2.07888
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.54331

Cumulative Model Updates: 243,774
Cumulative Timesteps: 2,033,089,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2033089078...
Checkpoint 2033089078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.22571
Policy Entropy: 2.16728
Value Function Loss: 0.01726

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.59273

Collected Steps per Second: 22,873.56633
Overall Steps per Second: 10,649.13787

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.69597

Cumulative Model Updates: 243,780
Cumulative Timesteps: 2,033,139,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.58209
Policy Entropy: 2.18168
Value Function Loss: 0.01749

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.54214
Value Function Update Magnitude: 0.60994

Collected Steps per Second: 23,110.15081
Overall Steps per Second: 10,871.26204

Timestep Collection Time: 2.16450
Timestep Consumption Time: 2.43680
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60131

Cumulative Model Updates: 243,786
Cumulative Timesteps: 2,033,189,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2033189108...
Checkpoint 2033189108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.91004
Policy Entropy: 2.16721
Value Function Loss: 0.01759

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.61136

Collected Steps per Second: 23,075.02284
Overall Steps per Second: 10,804.10064

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.63065

Cumulative Model Updates: 243,792
Cumulative Timesteps: 2,033,239,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.60304
Policy Entropy: 2.14673
Value Function Loss: 0.01859

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.61865

Collected Steps per Second: 24,007.24614
Overall Steps per Second: 11,000.41712

Timestep Collection Time: 2.08354
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.54710

Cumulative Model Updates: 243,798
Cumulative Timesteps: 2,033,289,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2033289158...
Checkpoint 2033289158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.00247
Policy Entropy: 2.11917
Value Function Loss: 0.01844

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.65202

Collected Steps per Second: 22,795.15398
Overall Steps per Second: 10,829.37572

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.42372
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61726

Cumulative Model Updates: 243,804
Cumulative Timesteps: 2,033,339,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.61753
Policy Entropy: 2.12753
Value Function Loss: 0.01896

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.54520
Value Function Update Magnitude: 0.64767

Collected Steps per Second: 22,837.20750
Overall Steps per Second: 10,749.93153

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.46237
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.65231

Cumulative Model Updates: 243,810
Cumulative Timesteps: 2,033,389,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2033389172...
Checkpoint 2033389172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.47258
Policy Entropy: 2.14881
Value Function Loss: 0.01761

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.54908
Value Function Update Magnitude: 0.62423

Collected Steps per Second: 22,327.06101
Overall Steps per Second: 10,778.62464

Timestep Collection Time: 2.24069
Timestep Consumption Time: 2.40072
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.64141

Cumulative Model Updates: 243,816
Cumulative Timesteps: 2,033,439,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.07531
Policy Entropy: 2.17487
Value Function Loss: 0.01736

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.61973

Collected Steps per Second: 23,557.59198
Overall Steps per Second: 11,002.47548

Timestep Collection Time: 2.12339
Timestep Consumption Time: 2.42304
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.54643

Cumulative Model Updates: 243,822
Cumulative Timesteps: 2,033,489,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2033489222...
Checkpoint 2033489222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.58337
Policy Entropy: 2.17119
Value Function Loss: 0.01810

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.55029
Value Function Update Magnitude: 0.60908

Collected Steps per Second: 22,684.29012
Overall Steps per Second: 10,626.56637

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.50102
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.70519

Cumulative Model Updates: 243,828
Cumulative Timesteps: 2,033,539,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.90654
Policy Entropy: 2.18642
Value Function Loss: 0.01904

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.61245

Collected Steps per Second: 23,088.07183
Overall Steps per Second: 10,849.10758

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61144

Cumulative Model Updates: 243,834
Cumulative Timesteps: 2,033,589,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2033589252...
Checkpoint 2033589252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.79865
Policy Entropy: 2.17301
Value Function Loss: 0.01895

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 22,896.78682
Overall Steps per Second: 10,916.65867

Timestep Collection Time: 2.18476
Timestep Consumption Time: 2.39759
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.58235

Cumulative Model Updates: 243,840
Cumulative Timesteps: 2,033,639,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.58528
Policy Entropy: 2.15750
Value Function Loss: 0.01947

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.63238

Collected Steps per Second: 23,625.59082
Overall Steps per Second: 10,923.52879

Timestep Collection Time: 2.11762
Timestep Consumption Time: 2.46240
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.58002

Cumulative Model Updates: 243,846
Cumulative Timesteps: 2,033,689,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2033689306...
Checkpoint 2033689306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.65693
Policy Entropy: 2.14710
Value Function Loss: 0.01867

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.63766

Collected Steps per Second: 22,634.52474
Overall Steps per Second: 10,800.28865

Timestep Collection Time: 2.20990
Timestep Consumption Time: 2.42146
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.63136

Cumulative Model Updates: 243,852
Cumulative Timesteps: 2,033,739,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.61804
Policy Entropy: 2.15089
Value Function Loss: 0.01893

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.54781
Value Function Update Magnitude: 0.64312

Collected Steps per Second: 22,866.03936
Overall Steps per Second: 10,891.65520

Timestep Collection Time: 2.18770
Timestep Consumption Time: 2.40518
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59287

Cumulative Model Updates: 243,858
Cumulative Timesteps: 2,033,789,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2033789350...
Checkpoint 2033789350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.47988
Policy Entropy: 2.18347
Value Function Loss: 0.01802

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.65158

Collected Steps per Second: 22,492.59374
Overall Steps per Second: 10,769.37414

Timestep Collection Time: 2.22420
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.64540

Cumulative Model Updates: 243,864
Cumulative Timesteps: 2,033,839,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.82970
Policy Entropy: 2.18286
Value Function Loss: 0.01783

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.65038

Collected Steps per Second: 22,735.76765
Overall Steps per Second: 10,802.21608

Timestep Collection Time: 2.19944
Timestep Consumption Time: 2.42979
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62924

Cumulative Model Updates: 243,870
Cumulative Timesteps: 2,033,889,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2033889384...
Checkpoint 2033889384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.27849
Policy Entropy: 2.18389
Value Function Loss: 0.01739

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.15694
Policy Update Magnitude: 0.51137
Value Function Update Magnitude: 0.64114

Collected Steps per Second: 22,724.89932
Overall Steps per Second: 10,736.19563

Timestep Collection Time: 2.20243
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.66180

Cumulative Model Updates: 243,876
Cumulative Timesteps: 2,033,939,434

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.93603
Policy Entropy: 2.16703
Value Function Loss: 0.01882

Mean KL Divergence: 0.03024
SB3 Clip Fraction: 0.16694
Policy Update Magnitude: 0.51990
Value Function Update Magnitude: 0.64533

Collected Steps per Second: 22,751.68966
Overall Steps per Second: 10,838.90192

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.41576
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.61375

Cumulative Model Updates: 243,882
Cumulative Timesteps: 2,033,989,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2033989442...
Checkpoint 2033989442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.61901
Policy Entropy: 2.16865
Value Function Loss: 0.01930

Mean KL Divergence: 0.02784
SB3 Clip Fraction: 0.15913
Policy Update Magnitude: 0.55567
Value Function Update Magnitude: 0.67001

Collected Steps per Second: 22,634.48801
Overall Steps per Second: 10,722.08955

Timestep Collection Time: 2.20920
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.66364

Cumulative Model Updates: 243,888
Cumulative Timesteps: 2,034,039,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.06910
Policy Entropy: 2.17767
Value Function Loss: 0.01896

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.68019

Collected Steps per Second: 23,080.32194
Overall Steps per Second: 10,875.76032

Timestep Collection Time: 2.16860
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60216

Cumulative Model Updates: 243,894
Cumulative Timesteps: 2,034,089,498

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2034089498...
Checkpoint 2034089498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.50299
Policy Entropy: 2.17537
Value Function Loss: 0.01851

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.66188

Collected Steps per Second: 22,865.35766
Overall Steps per Second: 10,673.14410

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.68466

Cumulative Model Updates: 243,900
Cumulative Timesteps: 2,034,139,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.30381
Policy Entropy: 2.13767
Value Function Loss: 0.01817

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.65054

Collected Steps per Second: 23,228.68183
Overall Steps per Second: 10,843.70352

Timestep Collection Time: 2.15346
Timestep Consumption Time: 2.45954
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.61300

Cumulative Model Updates: 243,906
Cumulative Timesteps: 2,034,189,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2034189520...
Checkpoint 2034189520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.02392
Policy Entropy: 2.13080
Value Function Loss: 0.01866

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.64548

Collected Steps per Second: 21,657.86021
Overall Steps per Second: 10,209.60981

Timestep Collection Time: 2.30872
Timestep Consumption Time: 2.58882
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.89754

Cumulative Model Updates: 243,912
Cumulative Timesteps: 2,034,239,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.56432
Policy Entropy: 2.14131
Value Function Loss: 0.01964

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.56735
Value Function Update Magnitude: 0.64512

Collected Steps per Second: 23,402.24759
Overall Steps per Second: 10,985.85642

Timestep Collection Time: 2.13749
Timestep Consumption Time: 2.41582
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.55331

Cumulative Model Updates: 243,918
Cumulative Timesteps: 2,034,289,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2034289544...
Checkpoint 2034289544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.47802
Policy Entropy: 2.19371
Value Function Loss: 0.01914

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.56936
Value Function Update Magnitude: 0.65760

Collected Steps per Second: 22,735.42338
Overall Steps per Second: 10,665.56518

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.68798

Cumulative Model Updates: 243,924
Cumulative Timesteps: 2,034,339,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.96632
Policy Entropy: 2.20865
Value Function Loss: 0.01915

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.55834
Value Function Update Magnitude: 0.66135

Collected Steps per Second: 22,787.84654
Overall Steps per Second: 10,830.36602

Timestep Collection Time: 2.19529
Timestep Consumption Time: 2.42376
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.61905

Cumulative Model Updates: 243,930
Cumulative Timesteps: 2,034,389,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2034389570...
Checkpoint 2034389570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.10487
Policy Entropy: 2.23291
Value Function Loss: 0.01793

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.54214
Value Function Update Magnitude: 0.66242

Collected Steps per Second: 22,231.62161
Overall Steps per Second: 10,616.48519

Timestep Collection Time: 2.24932
Timestep Consumption Time: 2.46090
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.71022

Cumulative Model Updates: 243,936
Cumulative Timesteps: 2,034,439,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.59687
Policy Entropy: 2.21693
Value Function Loss: 0.01881

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.68907

Collected Steps per Second: 22,715.69819
Overall Steps per Second: 10,691.64448

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.67786

Cumulative Model Updates: 243,942
Cumulative Timesteps: 2,034,489,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2034489590...
Checkpoint 2034489590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.86252
Policy Entropy: 2.21284
Value Function Loss: 0.01783

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.70149

Collected Steps per Second: 22,667.60352
Overall Steps per Second: 10,851.29799

Timestep Collection Time: 2.20667
Timestep Consumption Time: 2.40291
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.60959

Cumulative Model Updates: 243,948
Cumulative Timesteps: 2,034,539,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.05281
Policy Entropy: 2.19425
Value Function Loss: 0.01724

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.66449

Collected Steps per Second: 22,922.54000
Overall Steps per Second: 10,970.20241

Timestep Collection Time: 2.18239
Timestep Consumption Time: 2.37778
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.56017

Cumulative Model Updates: 243,954
Cumulative Timesteps: 2,034,589,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2034589636...
Checkpoint 2034589636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.82839
Policy Entropy: 2.19023
Value Function Loss: 0.01742

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.63509

Collected Steps per Second: 23,003.03415
Overall Steps per Second: 10,697.30626

Timestep Collection Time: 2.17363
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.67407

Cumulative Model Updates: 243,960
Cumulative Timesteps: 2,034,639,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.91047
Policy Entropy: 2.19183
Value Function Loss: 0.01822

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.64249

Collected Steps per Second: 23,284.09646
Overall Steps per Second: 10,856.45390

Timestep Collection Time: 2.14851
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.60795

Cumulative Model Updates: 243,966
Cumulative Timesteps: 2,034,689,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2034689662...
Checkpoint 2034689662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.55001
Policy Entropy: 2.20218
Value Function Loss: 0.01821

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.64677

Collected Steps per Second: 22,804.53457
Overall Steps per Second: 11,024.52439

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.34317
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.53607

Cumulative Model Updates: 243,972
Cumulative Timesteps: 2,034,739,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.28061
Policy Entropy: 2.21508
Value Function Loss: 0.01766

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.64002

Collected Steps per Second: 23,110.20337
Overall Steps per Second: 10,866.06828

Timestep Collection Time: 2.16372
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.60185

Cumulative Model Updates: 243,978
Cumulative Timesteps: 2,034,789,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2034789674...
Checkpoint 2034789674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.68211
Policy Entropy: 2.21705
Value Function Loss: 0.01665

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.64244

Collected Steps per Second: 22,851.01125
Overall Steps per Second: 10,739.14065

Timestep Collection Time: 2.18931
Timestep Consumption Time: 2.46916
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.65847

Cumulative Model Updates: 243,984
Cumulative Timesteps: 2,034,839,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.81673
Policy Entropy: 2.20665
Value Function Loss: 0.01803

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.55600
Value Function Update Magnitude: 0.65099

Collected Steps per Second: 22,402.51947
Overall Steps per Second: 10,678.53221

Timestep Collection Time: 2.23234
Timestep Consumption Time: 2.45089
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.68323

Cumulative Model Updates: 243,990
Cumulative Timesteps: 2,034,889,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2034889712...
Checkpoint 2034889712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.73506
Policy Entropy: 2.20672
Value Function Loss: 0.01717

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.65532

Collected Steps per Second: 22,705.45389
Overall Steps per Second: 10,876.56261

Timestep Collection Time: 2.20264
Timestep Consumption Time: 2.39550
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.59814

Cumulative Model Updates: 243,996
Cumulative Timesteps: 2,034,939,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.24192
Policy Entropy: 2.23170
Value Function Loss: 0.01805

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.54245
Value Function Update Magnitude: 0.63005

Collected Steps per Second: 22,820.90507
Overall Steps per Second: 10,824.07603

Timestep Collection Time: 2.19238
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62229

Cumulative Model Updates: 244,002
Cumulative Timesteps: 2,034,989,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2034989756...
Checkpoint 2034989756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.78810
Policy Entropy: 2.23654
Value Function Loss: 0.01749

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.60966

Collected Steps per Second: 22,619.83198
Overall Steps per Second: 10,769.30075

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.64320

Cumulative Model Updates: 244,008
Cumulative Timesteps: 2,035,039,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.08192
Policy Entropy: 2.24711
Value Function Loss: 0.01786

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.61772

Collected Steps per Second: 23,138.40266
Overall Steps per Second: 10,935.31954

Timestep Collection Time: 2.16221
Timestep Consumption Time: 2.41288
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.57508

Cumulative Model Updates: 244,014
Cumulative Timesteps: 2,035,089,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2035089790...
Checkpoint 2035089790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.38227
Policy Entropy: 2.22312
Value Function Loss: 0.01761

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.55005
Value Function Update Magnitude: 0.62960

Collected Steps per Second: 23,180.26252
Overall Steps per Second: 10,848.73753

Timestep Collection Time: 2.15830
Timestep Consumption Time: 2.45329
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.61160

Cumulative Model Updates: 244,020
Cumulative Timesteps: 2,035,139,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.27813
Policy Entropy: 2.19176
Value Function Loss: 0.01801

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.64250

Collected Steps per Second: 22,890.98668
Overall Steps per Second: 10,667.85983

Timestep Collection Time: 2.18435
Timestep Consumption Time: 2.50281
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.68716

Cumulative Model Updates: 244,026
Cumulative Timesteps: 2,035,189,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2035189822...
Checkpoint 2035189822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.99898
Policy Entropy: 2.14650
Value Function Loss: 0.01769

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.66617

Collected Steps per Second: 22,886.53010
Overall Steps per Second: 10,666.30051

Timestep Collection Time: 2.18583
Timestep Consumption Time: 2.50427
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.69010

Cumulative Model Updates: 244,032
Cumulative Timesteps: 2,035,239,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.70100
Policy Entropy: 2.12936
Value Function Loss: 0.01776

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.56201
Value Function Update Magnitude: 0.66413

Collected Steps per Second: 23,008.83458
Overall Steps per Second: 10,897.02087

Timestep Collection Time: 2.17369
Timestep Consumption Time: 2.41601
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.58969

Cumulative Model Updates: 244,038
Cumulative Timesteps: 2,035,289,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2035289862...
Checkpoint 2035289862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.33451
Policy Entropy: 2.15484
Value Function Loss: 0.01716

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.55377
Value Function Update Magnitude: 0.65887

Collected Steps per Second: 23,111.31449
Overall Steps per Second: 10,790.38886

Timestep Collection Time: 2.16344
Timestep Consumption Time: 2.47031
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.63375

Cumulative Model Updates: 244,044
Cumulative Timesteps: 2,035,339,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.31516
Policy Entropy: 2.15966
Value Function Loss: 0.01785

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.54643
Value Function Update Magnitude: 0.65105

Collected Steps per Second: 22,561.48186
Overall Steps per Second: 10,773.84773

Timestep Collection Time: 2.21714
Timestep Consumption Time: 2.42577
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.64291

Cumulative Model Updates: 244,050
Cumulative Timesteps: 2,035,389,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2035389884...
Checkpoint 2035389884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.75691
Policy Entropy: 2.16474
Value Function Loss: 0.01743

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.64355

Collected Steps per Second: 22,632.13597
Overall Steps per Second: 10,691.12009

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.46802
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.67771

Cumulative Model Updates: 244,056
Cumulative Timesteps: 2,035,439,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.71419
Policy Entropy: 2.16228
Value Function Loss: 0.01801

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.54673
Value Function Update Magnitude: 0.62728

Collected Steps per Second: 22,995.10243
Overall Steps per Second: 10,893.48326

Timestep Collection Time: 2.17455
Timestep Consumption Time: 2.41572
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.59027

Cumulative Model Updates: 244,062
Cumulative Timesteps: 2,035,489,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2035489898...
Checkpoint 2035489898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.34185
Policy Entropy: 2.21352
Value Function Loss: 0.01698

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.53519
Value Function Update Magnitude: 0.61292

Collected Steps per Second: 22,753.82213
Overall Steps per Second: 10,680.80363

Timestep Collection Time: 2.19796
Timestep Consumption Time: 2.48446
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.68242

Cumulative Model Updates: 244,068
Cumulative Timesteps: 2,035,539,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.86772
Policy Entropy: 2.24349
Value Function Loss: 0.01734

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.62274

Collected Steps per Second: 23,445.80722
Overall Steps per Second: 10,836.40985

Timestep Collection Time: 2.13369
Timestep Consumption Time: 2.48279
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.61647

Cumulative Model Updates: 244,074
Cumulative Timesteps: 2,035,589,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2035589936...
Checkpoint 2035589936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.87340
Policy Entropy: 2.24490
Value Function Loss: 0.01747

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.64099

Collected Steps per Second: 22,778.14887
Overall Steps per Second: 10,598.13306

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.52303
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.71838

Cumulative Model Updates: 244,080
Cumulative Timesteps: 2,035,639,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.58954
Policy Entropy: 2.20671
Value Function Loss: 0.01709

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.63651

Collected Steps per Second: 23,075.83163
Overall Steps per Second: 10,916.24442

Timestep Collection Time: 2.16720
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.58125

Cumulative Model Updates: 244,086
Cumulative Timesteps: 2,035,689,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2035689952...
Checkpoint 2035689952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.56039
Policy Entropy: 2.19439
Value Function Loss: 0.01699

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.53971
Value Function Update Magnitude: 0.63499

Collected Steps per Second: 23,649.01939
Overall Steps per Second: 11,048.77964

Timestep Collection Time: 2.11501
Timestep Consumption Time: 2.41200
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.52702

Cumulative Model Updates: 244,092
Cumulative Timesteps: 2,035,739,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.42914
Policy Entropy: 2.20063
Value Function Loss: 0.01613

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.61642

Collected Steps per Second: 23,225.09198
Overall Steps per Second: 10,922.84691

Timestep Collection Time: 2.15345
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.57884

Cumulative Model Updates: 244,098
Cumulative Timesteps: 2,035,789,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2035789984...
Checkpoint 2035789984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.61816
Policy Entropy: 2.19758
Value Function Loss: 0.01720

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.55171
Value Function Update Magnitude: 0.59724

Collected Steps per Second: 22,646.05798
Overall Steps per Second: 10,705.04105

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.46419
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.67331

Cumulative Model Updates: 244,104
Cumulative Timesteps: 2,035,840,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.18971
Policy Entropy: 2.20587
Value Function Loss: 0.01758

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.54528
Value Function Update Magnitude: 0.60804

Collected Steps per Second: 23,063.09390
Overall Steps per Second: 10,945.52977

Timestep Collection Time: 2.16866
Timestep Consumption Time: 2.40088
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.56954

Cumulative Model Updates: 244,110
Cumulative Timesteps: 2,035,890,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2035890028...
Checkpoint 2035890028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.42307
Policy Entropy: 2.19209
Value Function Loss: 0.01797

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.54867
Value Function Update Magnitude: 0.62701

Collected Steps per Second: 22,860.09841
Overall Steps per Second: 10,688.37406

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.68097

Cumulative Model Updates: 244,116
Cumulative Timesteps: 2,035,940,060

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.01289
Policy Entropy: 2.20875
Value Function Loss: 0.01697

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.53343
Value Function Update Magnitude: 0.61758

Collected Steps per Second: 22,744.09343
Overall Steps per Second: 10,805.79912

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.62789

Cumulative Model Updates: 244,122
Cumulative Timesteps: 2,035,990,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2035990068...
Checkpoint 2035990068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.11152
Policy Entropy: 2.20350
Value Function Loss: 0.01661

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.52936
Value Function Update Magnitude: 0.61468

Collected Steps per Second: 22,408.61830
Overall Steps per Second: 10,676.69133

Timestep Collection Time: 2.23253
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.68572

Cumulative Model Updates: 244,128
Cumulative Timesteps: 2,036,040,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.51797
Policy Entropy: 2.21441
Value Function Loss: 0.01786

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.61296

Collected Steps per Second: 23,261.53059
Overall Steps per Second: 10,888.20680

Timestep Collection Time: 2.14999
Timestep Consumption Time: 2.44324
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.59323

Cumulative Model Updates: 244,134
Cumulative Timesteps: 2,036,090,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2036090108...
Checkpoint 2036090108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.01028
Policy Entropy: 2.20932
Value Function Loss: 0.01825

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.62903

Collected Steps per Second: 23,915.67139
Overall Steps per Second: 11,080.91179

Timestep Collection Time: 2.09118
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.51335

Cumulative Model Updates: 244,140
Cumulative Timesteps: 2,036,140,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.24145
Policy Entropy: 2.21484
Value Function Loss: 0.01880

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.64342

Collected Steps per Second: 21,627.44212
Overall Steps per Second: 10,544.19880

Timestep Collection Time: 2.31428
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.74688

Cumulative Model Updates: 244,146
Cumulative Timesteps: 2,036,190,172

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2036190172...
Checkpoint 2036190172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.35057
Policy Entropy: 2.21629
Value Function Loss: 0.01766

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.53335
Value Function Update Magnitude: 0.64711

Collected Steps per Second: 22,352.53879
Overall Steps per Second: 10,608.80890

Timestep Collection Time: 2.23751
Timestep Consumption Time: 2.47688
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.71438

Cumulative Model Updates: 244,152
Cumulative Timesteps: 2,036,240,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.21087
Policy Entropy: 2.21992
Value Function Loss: 0.01681

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.63183

Collected Steps per Second: 22,915.16351
Overall Steps per Second: 10,934.57432

Timestep Collection Time: 2.18318
Timestep Consumption Time: 2.39203
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.57521

Cumulative Model Updates: 244,158
Cumulative Timesteps: 2,036,290,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2036290214...
Checkpoint 2036290214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.66827
Policy Entropy: 2.21655
Value Function Loss: 0.01661

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.61270

Collected Steps per Second: 23,125.60930
Overall Steps per Second: 10,622.76795

Timestep Collection Time: 2.16262
Timestep Consumption Time: 2.54538
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.70800

Cumulative Model Updates: 244,164
Cumulative Timesteps: 2,036,340,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.67096
Policy Entropy: 2.23439
Value Function Loss: 0.01626

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.53725
Value Function Update Magnitude: 0.63449

Collected Steps per Second: 23,516.94530
Overall Steps per Second: 10,883.94855

Timestep Collection Time: 2.12655
Timestep Consumption Time: 2.46829
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.59484

Cumulative Model Updates: 244,170
Cumulative Timesteps: 2,036,390,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2036390236...
Checkpoint 2036390236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.79076
Policy Entropy: 2.22945
Value Function Loss: 0.01713

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.53203
Value Function Update Magnitude: 0.64330

Collected Steps per Second: 22,819.84650
Overall Steps per Second: 10,729.18254

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.66317

Cumulative Model Updates: 244,176
Cumulative Timesteps: 2,036,440,268

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.06907
Policy Entropy: 2.21811
Value Function Loss: 0.01649

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.53274
Value Function Update Magnitude: 0.63498

Collected Steps per Second: 23,258.57769
Overall Steps per Second: 10,955.56993

Timestep Collection Time: 2.15078
Timestep Consumption Time: 2.41530
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.56608

Cumulative Model Updates: 244,182
Cumulative Timesteps: 2,036,490,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2036490292...
Checkpoint 2036490292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.88927
Policy Entropy: 2.21587
Value Function Loss: 0.01681

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.53033
Value Function Update Magnitude: 0.62831

Collected Steps per Second: 23,186.97128
Overall Steps per Second: 10,926.70652

Timestep Collection Time: 2.15716
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.57759

Cumulative Model Updates: 244,188
Cumulative Timesteps: 2,036,540,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.37452
Policy Entropy: 2.25701
Value Function Loss: 0.01647

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.52145
Value Function Update Magnitude: 0.61822

Collected Steps per Second: 22,844.09431
Overall Steps per Second: 10,716.13602

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.66698

Cumulative Model Updates: 244,194
Cumulative Timesteps: 2,036,590,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2036590322...
Checkpoint 2036590322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.45036
Policy Entropy: 2.25459
Value Function Loss: 0.01790

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.62698

Collected Steps per Second: 22,673.57870
Overall Steps per Second: 10,864.75746

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.39807
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.60443

Cumulative Model Updates: 244,200
Cumulative Timesteps: 2,036,640,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.00191
Policy Entropy: 2.21002
Value Function Loss: 0.01779

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.63756

Collected Steps per Second: 22,636.11577
Overall Steps per Second: 10,947.42726

Timestep Collection Time: 2.20930
Timestep Consumption Time: 2.35890
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.56820

Cumulative Model Updates: 244,206
Cumulative Timesteps: 2,036,690,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2036690358...
Checkpoint 2036690358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.48918
Policy Entropy: 2.16916
Value Function Loss: 0.01843

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.63930

Collected Steps per Second: 22,733.63587
Overall Steps per Second: 10,660.44239

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69268

Cumulative Model Updates: 244,212
Cumulative Timesteps: 2,036,740,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.95982
Policy Entropy: 2.19278
Value Function Loss: 0.01676

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.64262

Collected Steps per Second: 22,946.15952
Overall Steps per Second: 10,667.04523

Timestep Collection Time: 2.17962
Timestep Consumption Time: 2.50902
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.68865

Cumulative Model Updates: 244,218
Cumulative Timesteps: 2,036,790,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2036790398...
Checkpoint 2036790398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.06088
Policy Entropy: 2.21185
Value Function Loss: 0.01610

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.53696
Value Function Update Magnitude: 0.62335

Collected Steps per Second: 22,659.91369
Overall Steps per Second: 10,824.32347

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.62181

Cumulative Model Updates: 244,224
Cumulative Timesteps: 2,036,840,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.92791
Policy Entropy: 2.21918
Value Function Loss: 0.01666

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.53627
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 23,268.19990
Overall Steps per Second: 11,001.61269

Timestep Collection Time: 2.14929
Timestep Consumption Time: 2.39641
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.54570

Cumulative Model Updates: 244,230
Cumulative Timesteps: 2,036,890,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2036890436...
Checkpoint 2036890436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.16859
Policy Entropy: 2.20800
Value Function Loss: 0.01685

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.53599
Value Function Update Magnitude: 0.61628

Collected Steps per Second: 23,256.96905
Overall Steps per Second: 10,807.01996

Timestep Collection Time: 2.15024
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.62736

Cumulative Model Updates: 244,236
Cumulative Timesteps: 2,036,940,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.26787
Policy Entropy: 2.21880
Value Function Loss: 0.01616

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.53072
Value Function Update Magnitude: 0.60346

Collected Steps per Second: 23,335.01534
Overall Steps per Second: 10,758.38179

Timestep Collection Time: 2.14287
Timestep Consumption Time: 2.50504
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.64791

Cumulative Model Updates: 244,242
Cumulative Timesteps: 2,036,990,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2036990448...
Checkpoint 2036990448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.50308
Policy Entropy: 2.20232
Value Function Loss: 0.01624

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 22,477.41317
Overall Steps per Second: 10,570.56072

Timestep Collection Time: 2.22552
Timestep Consumption Time: 2.50687
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.73239

Cumulative Model Updates: 244,248
Cumulative Timesteps: 2,037,040,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.45475
Policy Entropy: 2.22549
Value Function Loss: 0.01508

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.52269
Value Function Update Magnitude: 0.60465

Collected Steps per Second: 23,312.80560
Overall Steps per Second: 10,950.62239

Timestep Collection Time: 2.14560
Timestep Consumption Time: 2.42218
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.56778

Cumulative Model Updates: 244,254
Cumulative Timesteps: 2,037,090,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2037090492...
Checkpoint 2037090492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.96258
Policy Entropy: 2.20936
Value Function Loss: 0.01546

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 22,652.97802
Overall Steps per Second: 10,660.31373

Timestep Collection Time: 2.20810
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.69217

Cumulative Model Updates: 244,260
Cumulative Timesteps: 2,037,140,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.92802
Policy Entropy: 2.23470
Value Function Loss: 0.01573

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.52055
Value Function Update Magnitude: 0.59557

Collected Steps per Second: 22,823.83322
Overall Steps per Second: 10,820.34897

Timestep Collection Time: 2.19104
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.62166

Cumulative Model Updates: 244,266
Cumulative Timesteps: 2,037,190,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2037190520...
Checkpoint 2037190520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.10209
Policy Entropy: 2.19976
Value Function Loss: 0.01792

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.53185
Value Function Update Magnitude: 0.60855

Collected Steps per Second: 22,180.11082
Overall Steps per Second: 10,694.02174

Timestep Collection Time: 2.25481
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.67663

Cumulative Model Updates: 244,272
Cumulative Timesteps: 2,037,240,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.89090
Policy Entropy: 2.17373
Value Function Loss: 0.01961

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.61491

Collected Steps per Second: 22,773.35306
Overall Steps per Second: 10,952.75434

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.37103
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.56798

Cumulative Model Updates: 244,278
Cumulative Timesteps: 2,037,290,564

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2037290564...
Checkpoint 2037290564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.24224
Policy Entropy: 2.16885
Value Function Loss: 0.01899

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.55894
Value Function Update Magnitude: 0.62036

Collected Steps per Second: 22,884.82293
Overall Steps per Second: 10,641.14064

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.69987

Cumulative Model Updates: 244,284
Cumulative Timesteps: 2,037,340,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.79441
Policy Entropy: 2.16132
Value Function Loss: 0.01860

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.56221
Value Function Update Magnitude: 0.62253

Collected Steps per Second: 23,009.27530
Overall Steps per Second: 10,847.42586

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.61013

Cumulative Model Updates: 244,290
Cumulative Timesteps: 2,037,390,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2037390584...
Checkpoint 2037390584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.09907
Policy Entropy: 2.18401
Value Function Loss: 0.01821

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 22,678.83695
Overall Steps per Second: 10,641.50673

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.49468
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.70009

Cumulative Model Updates: 244,296
Cumulative Timesteps: 2,037,440,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.43501
Policy Entropy: 2.19013
Value Function Loss: 0.01804

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.65986

Collected Steps per Second: 22,833.54891
Overall Steps per Second: 10,945.28526

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.37889
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.56909

Cumulative Model Updates: 244,302
Cumulative Timesteps: 2,037,490,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2037490610...
Checkpoint 2037490610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.33279
Policy Entropy: 2.21490
Value Function Loss: 0.01716

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,926.72452
Overall Steps per Second: 10,690.34284

Timestep Collection Time: 2.18130
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.67805

Cumulative Model Updates: 244,308
Cumulative Timesteps: 2,037,540,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.70654
Policy Entropy: 2.20623
Value Function Loss: 0.01686

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.54176
Value Function Update Magnitude: 0.63108

Collected Steps per Second: 23,109.05106
Overall Steps per Second: 10,857.76354

Timestep Collection Time: 2.16365
Timestep Consumption Time: 2.44135
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.60500

Cumulative Model Updates: 244,314
Cumulative Timesteps: 2,037,590,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2037590620...
Checkpoint 2037590620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.04230
Policy Entropy: 2.20849
Value Function Loss: 0.01627

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.11231
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.64228

Collected Steps per Second: 22,500.53936
Overall Steps per Second: 10,797.21154

Timestep Collection Time: 2.22252
Timestep Consumption Time: 2.40904
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.63157

Cumulative Model Updates: 244,320
Cumulative Timesteps: 2,037,640,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.03268
Policy Entropy: 2.20159
Value Function Loss: 0.01636

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.53513
Value Function Update Magnitude: 0.63447

Collected Steps per Second: 23,282.61393
Overall Steps per Second: 10,723.23563

Timestep Collection Time: 2.14804
Timestep Consumption Time: 2.51585
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.66389

Cumulative Model Updates: 244,326
Cumulative Timesteps: 2,037,690,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2037690640...
Checkpoint 2037690640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.40565
Policy Entropy: 2.20360
Value Function Loss: 0.01674

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.51789
Value Function Update Magnitude: 0.61871

Collected Steps per Second: 22,729.68827
Overall Steps per Second: 10,636.46749

Timestep Collection Time: 2.19977
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.70081

Cumulative Model Updates: 244,332
Cumulative Timesteps: 2,037,740,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.84866
Policy Entropy: 2.19801
Value Function Loss: 0.01755

Mean KL Divergence: 0.03001
SB3 Clip Fraction: 0.17018
Policy Update Magnitude: 0.49538
Value Function Update Magnitude: 0.62517

Collected Steps per Second: 22,273.61633
Overall Steps per Second: 10,545.20907

Timestep Collection Time: 2.24544
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74282

Cumulative Model Updates: 244,338
Cumulative Timesteps: 2,037,790,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2037790654...
Checkpoint 2037790654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.83763
Policy Entropy: 2.18388
Value Function Loss: 0.01755

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.52594
Value Function Update Magnitude: 0.63673

Collected Steps per Second: 22,831.84974
Overall Steps per Second: 10,972.97107

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.36711
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.55738

Cumulative Model Updates: 244,344
Cumulative Timesteps: 2,037,840,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.76543
Policy Entropy: 2.17147
Value Function Loss: 0.01725

Mean KL Divergence: 0.02741
SB3 Clip Fraction: 0.16068
Policy Update Magnitude: 0.54925
Value Function Update Magnitude: 0.63135

Collected Steps per Second: 23,585.69651
Overall Steps per Second: 11,014.34667

Timestep Collection Time: 2.12035
Timestep Consumption Time: 2.42009
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.54044

Cumulative Model Updates: 244,350
Cumulative Timesteps: 2,037,890,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2037890672...
Checkpoint 2037890672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.59948
Policy Entropy: 2.17296
Value Function Loss: 0.01691

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.54727
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 22,934.94590
Overall Steps per Second: 10,802.04458

Timestep Collection Time: 2.18104
Timestep Consumption Time: 2.44975
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.63079

Cumulative Model Updates: 244,356
Cumulative Timesteps: 2,037,940,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.48150
Policy Entropy: 2.19024
Value Function Loss: 0.01669

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.58042

Collected Steps per Second: 22,766.05368
Overall Steps per Second: 10,871.69700

Timestep Collection Time: 2.19748
Timestep Consumption Time: 2.40419
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.60167

Cumulative Model Updates: 244,362
Cumulative Timesteps: 2,037,990,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2037990722...
Checkpoint 2037990722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.66641
Policy Entropy: 2.19642
Value Function Loss: 0.01828

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.57585

Collected Steps per Second: 23,223.25739
Overall Steps per Second: 10,972.62847

Timestep Collection Time: 2.15396
Timestep Consumption Time: 2.40484
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.55880

Cumulative Model Updates: 244,368
Cumulative Timesteps: 2,038,040,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.37950
Policy Entropy: 2.19650
Value Function Loss: 0.01892

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.55585
Value Function Update Magnitude: 0.59121

Collected Steps per Second: 23,336.41592
Overall Steps per Second: 10,719.78478

Timestep Collection Time: 2.14300
Timestep Consumption Time: 2.52220
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.66521

Cumulative Model Updates: 244,374
Cumulative Timesteps: 2,038,090,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2038090754...
Checkpoint 2038090754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.81182
Policy Entropy: 2.20590
Value Function Loss: 0.01840

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.60003

Collected Steps per Second: 21,962.47634
Overall Steps per Second: 10,674.00107

Timestep Collection Time: 2.27688
Timestep Consumption Time: 2.40796
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.68484

Cumulative Model Updates: 244,380
Cumulative Timesteps: 2,038,140,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.59693
Policy Entropy: 2.18811
Value Function Loss: 0.01797

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.62444

Collected Steps per Second: 20,940.87275
Overall Steps per Second: 10,163.76061

Timestep Collection Time: 2.38796
Timestep Consumption Time: 2.53207
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.92003

Cumulative Model Updates: 244,386
Cumulative Timesteps: 2,038,190,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2038190766...
Checkpoint 2038190766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.17895
Policy Entropy: 2.19636
Value Function Loss: 0.01758

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.62644

Collected Steps per Second: 22,212.92624
Overall Steps per Second: 10,616.23678

Timestep Collection Time: 2.25139
Timestep Consumption Time: 2.45932
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.71071

Cumulative Model Updates: 244,392
Cumulative Timesteps: 2,038,240,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.32660
Policy Entropy: 2.19590
Value Function Loss: 0.01943

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.55671
Value Function Update Magnitude: 0.62967

Collected Steps per Second: 22,784.89014
Overall Steps per Second: 10,793.53565

Timestep Collection Time: 2.19575
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.63518

Cumulative Model Updates: 244,398
Cumulative Timesteps: 2,038,290,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2038290806...
Checkpoint 2038290806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.37327
Policy Entropy: 2.21156
Value Function Loss: 0.01933

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.56100
Value Function Update Magnitude: 0.65054

Collected Steps per Second: 22,457.31352
Overall Steps per Second: 10,723.98708

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.66282

Cumulative Model Updates: 244,404
Cumulative Timesteps: 2,038,340,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.04222
Policy Entropy: 2.19121
Value Function Loss: 0.01850

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.65949

Collected Steps per Second: 22,940.58939
Overall Steps per Second: 10,931.02805

Timestep Collection Time: 2.18076
Timestep Consumption Time: 2.39593
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.57670

Cumulative Model Updates: 244,410
Cumulative Timesteps: 2,038,390,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2038390838...
Checkpoint 2038390838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.59706
Policy Entropy: 2.18069
Value Function Loss: 0.01827

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.55168
Value Function Update Magnitude: 0.64505

Collected Steps per Second: 22,698.48649
Overall Steps per Second: 10,606.96260

Timestep Collection Time: 2.20323
Timestep Consumption Time: 2.51160
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.71483

Cumulative Model Updates: 244,416
Cumulative Timesteps: 2,038,440,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.48346
Policy Entropy: 2.22048
Value Function Loss: 0.01719

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.54351
Value Function Update Magnitude: 0.63054

Collected Steps per Second: 23,293.19978
Overall Steps per Second: 10,891.98098

Timestep Collection Time: 2.14706
Timestep Consumption Time: 2.44457
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.59163

Cumulative Model Updates: 244,422
Cumulative Timesteps: 2,038,490,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2038490860...
Checkpoint 2038490860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.88027
Policy Entropy: 2.23519
Value Function Loss: 0.01728

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.62106

Collected Steps per Second: 23,080.95166
Overall Steps per Second: 10,728.12147

Timestep Collection Time: 2.16664
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.66139

Cumulative Model Updates: 244,428
Cumulative Timesteps: 2,038,540,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.55907
Policy Entropy: 2.23146
Value Function Loss: 0.01731

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.62830

Collected Steps per Second: 23,167.31695
Overall Steps per Second: 10,903.68277

Timestep Collection Time: 2.15882
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.58689

Cumulative Model Updates: 244,434
Cumulative Timesteps: 2,038,590,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2038590882...
Checkpoint 2038590882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.45004
Policy Entropy: 2.16307
Value Function Loss: 0.01999

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.55125
Value Function Update Magnitude: 0.65285

Collected Steps per Second: 22,274.93803
Overall Steps per Second: 10,611.26724

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.71423

Cumulative Model Updates: 244,440
Cumulative Timesteps: 2,038,640,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.52867
Policy Entropy: 2.14844
Value Function Loss: 0.01917

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.67963

Collected Steps per Second: 22,543.33614
Overall Steps per Second: 10,617.38193

Timestep Collection Time: 2.21875
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.71095

Cumulative Model Updates: 244,446
Cumulative Timesteps: 2,038,690,924

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2038690924...
Checkpoint 2038690924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.82672
Policy Entropy: 2.17674
Value Function Loss: 0.01916

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.65717

Collected Steps per Second: 22,227.72042
Overall Steps per Second: 10,499.94821

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.51359
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.76402

Cumulative Model Updates: 244,452
Cumulative Timesteps: 2,038,740,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.95001
Policy Entropy: 2.22515
Value Function Loss: 0.01791

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.62852

Collected Steps per Second: 21,936.70795
Overall Steps per Second: 10,562.80788

Timestep Collection Time: 2.28047
Timestep Consumption Time: 2.45558
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.73605

Cumulative Model Updates: 244,458
Cumulative Timesteps: 2,038,790,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2038790972...
Checkpoint 2038790972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.21594
Policy Entropy: 2.22303
Value Function Loss: 0.01719

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.54161
Value Function Update Magnitude: 0.61133

Collected Steps per Second: 22,770.18799
Overall Steps per Second: 10,726.64619

Timestep Collection Time: 2.19603
Timestep Consumption Time: 2.46563
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.66166

Cumulative Model Updates: 244,464
Cumulative Timesteps: 2,038,840,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.48493
Policy Entropy: 2.21345
Value Function Loss: 0.01702

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.60277

Collected Steps per Second: 23,335.24060
Overall Steps per Second: 10,707.53759

Timestep Collection Time: 2.14268
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.66961

Cumulative Model Updates: 244,470
Cumulative Timesteps: 2,038,890,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2038890976...
Checkpoint 2038890976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.55982
Policy Entropy: 2.20751
Value Function Loss: 0.01626

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.60890

Collected Steps per Second: 22,424.85454
Overall Steps per Second: 10,609.12388

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.48375
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.71387

Cumulative Model Updates: 244,476
Cumulative Timesteps: 2,038,940,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.14419
Policy Entropy: 2.21776
Value Function Loss: 0.01823

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.62603

Collected Steps per Second: 23,056.50318
Overall Steps per Second: 10,926.11469

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.40857
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.57802

Cumulative Model Updates: 244,482
Cumulative Timesteps: 2,038,991,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2038991006...
Checkpoint 2038991006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.47610
Policy Entropy: 2.22402
Value Function Loss: 0.01719

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.63665

Collected Steps per Second: 23,111.39553
Overall Steps per Second: 10,782.36947

Timestep Collection Time: 2.16456
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.63961

Cumulative Model Updates: 244,488
Cumulative Timesteps: 2,039,041,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.15063
Policy Entropy: 2.20317
Value Function Loss: 0.01721

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.63405

Collected Steps per Second: 23,574.90968
Overall Steps per Second: 10,817.80157

Timestep Collection Time: 2.12090
Timestep Consumption Time: 2.50111
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.62201

Cumulative Model Updates: 244,494
Cumulative Timesteps: 2,039,091,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2039091032...
Checkpoint 2039091032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.77045
Policy Entropy: 2.22849
Value Function Loss: 0.01615

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.52922
Value Function Update Magnitude: 0.61608

Collected Steps per Second: 22,804.38266
Overall Steps per Second: 10,757.18195

Timestep Collection Time: 2.19265
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.64824

Cumulative Model Updates: 244,500
Cumulative Timesteps: 2,039,141,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.57208
Policy Entropy: 2.22686
Value Function Loss: 0.01619

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.60878

Collected Steps per Second: 22,625.53896
Overall Steps per Second: 10,809.13594

Timestep Collection Time: 2.21007
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.62609

Cumulative Model Updates: 244,506
Cumulative Timesteps: 2,039,191,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2039191038...
Checkpoint 2039191038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.14626
Policy Entropy: 2.24812
Value Function Loss: 0.01666

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.53143
Value Function Update Magnitude: 0.59852

Collected Steps per Second: 22,568.06592
Overall Steps per Second: 10,640.23733

Timestep Collection Time: 2.21579
Timestep Consumption Time: 2.48392
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69971

Cumulative Model Updates: 244,512
Cumulative Timesteps: 2,039,241,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.57302
Policy Entropy: 2.19947
Value Function Loss: 0.01803

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.55087
Value Function Update Magnitude: 0.62554

Collected Steps per Second: 22,910.05614
Overall Steps per Second: 10,872.92732

Timestep Collection Time: 2.18367
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.60115

Cumulative Model Updates: 244,518
Cumulative Timesteps: 2,039,291,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2039291072...
Checkpoint 2039291072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.69592
Policy Entropy: 2.19219
Value Function Loss: 0.01812

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.66754

Collected Steps per Second: 22,504.69830
Overall Steps per Second: 10,659.83882

Timestep Collection Time: 2.22202
Timestep Consumption Time: 2.46904
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69107

Cumulative Model Updates: 244,524
Cumulative Timesteps: 2,039,341,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.88273
Policy Entropy: 2.20925
Value Function Loss: 0.01714

Mean KL Divergence: 0.02736
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.51414
Value Function Update Magnitude: 0.66271

Collected Steps per Second: 22,940.73674
Overall Steps per Second: 10,797.17532

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.45161
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.63140

Cumulative Model Updates: 244,530
Cumulative Timesteps: 2,039,391,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2039391084...
Checkpoint 2039391084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.57649
Policy Entropy: 2.23725
Value Function Loss: 0.01588

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.50661
Value Function Update Magnitude: 0.62617

Collected Steps per Second: 23,558.93631
Overall Steps per Second: 11,007.48686

Timestep Collection Time: 2.12242
Timestep Consumption Time: 2.42012
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.54254

Cumulative Model Updates: 244,536
Cumulative Timesteps: 2,039,441,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.18241
Policy Entropy: 2.24302
Value Function Loss: 0.01634

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.52751
Value Function Update Magnitude: 0.60521

Collected Steps per Second: 23,567.89675
Overall Steps per Second: 10,996.34156

Timestep Collection Time: 2.12153
Timestep Consumption Time: 2.42544
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.54697

Cumulative Model Updates: 244,542
Cumulative Timesteps: 2,039,491,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2039491086...
Checkpoint 2039491086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.48366
Policy Entropy: 2.21585
Value Function Loss: 0.01682

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.62019

Collected Steps per Second: 22,692.19274
Overall Steps per Second: 10,670.66629

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.68631

Cumulative Model Updates: 244,548
Cumulative Timesteps: 2,039,541,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.58534
Policy Entropy: 2.22402
Value Function Loss: 0.01709

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.63331

Collected Steps per Second: 22,956.03621
Overall Steps per Second: 10,902.88842

Timestep Collection Time: 2.17895
Timestep Consumption Time: 2.40883
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.58778

Cumulative Model Updates: 244,554
Cumulative Timesteps: 2,039,591,112

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2039591112...
Checkpoint 2039591112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.60269
Policy Entropy: 2.22765
Value Function Loss: 0.01642

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.53375
Value Function Update Magnitude: 0.63152

Collected Steps per Second: 22,539.87716
Overall Steps per Second: 10,831.73240

Timestep Collection Time: 2.21856
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.61662

Cumulative Model Updates: 244,560
Cumulative Timesteps: 2,039,641,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.46811
Policy Entropy: 2.22188
Value Function Loss: 0.01755

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.53224
Value Function Update Magnitude: 0.61369

Collected Steps per Second: 22,999.46938
Overall Steps per Second: 10,724.15693

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.48960
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.66461

Cumulative Model Updates: 244,566
Cumulative Timesteps: 2,039,691,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2039691142...
Checkpoint 2039691142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.62932
Policy Entropy: 2.24021
Value Function Loss: 0.01746

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.53095
Value Function Update Magnitude: 0.61577

Collected Steps per Second: 22,308.75801
Overall Steps per Second: 10,663.04573

Timestep Collection Time: 2.24244
Timestep Consumption Time: 2.44909
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.69153

Cumulative Model Updates: 244,572
Cumulative Timesteps: 2,039,741,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.31173
Policy Entropy: 2.23756
Value Function Loss: 0.01712

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.52544
Value Function Update Magnitude: 0.61569

Collected Steps per Second: 22,607.12965
Overall Steps per Second: 10,844.65093

Timestep Collection Time: 2.21266
Timestep Consumption Time: 2.39993
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.61260

Cumulative Model Updates: 244,578
Cumulative Timesteps: 2,039,791,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2039791190...
Checkpoint 2039791190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.62672
Policy Entropy: 2.23083
Value Function Loss: 0.01690

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.52576
Value Function Update Magnitude: 0.61051

Collected Steps per Second: 22,485.26444
Overall Steps per Second: 10,756.29633

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.65104

Cumulative Model Updates: 244,584
Cumulative Timesteps: 2,039,841,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.97810
Policy Entropy: 2.20058
Value Function Loss: 0.01660

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.53285
Value Function Update Magnitude: 0.61387

Collected Steps per Second: 23,565.08003
Overall Steps per Second: 10,862.69680

Timestep Collection Time: 2.12204
Timestep Consumption Time: 2.48142
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.60346

Cumulative Model Updates: 244,590
Cumulative Timesteps: 2,039,891,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2039891224...
Checkpoint 2039891224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.78968
Policy Entropy: 2.18788
Value Function Loss: 0.01672

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.53129
Value Function Update Magnitude: 0.62552

Collected Steps per Second: 22,632.82600
Overall Steps per Second: 10,591.90199

Timestep Collection Time: 2.20998
Timestep Consumption Time: 2.51231
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.72229

Cumulative Model Updates: 244,596
Cumulative Timesteps: 2,039,941,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.77725
Policy Entropy: 2.20509
Value Function Loss: 0.01696

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.62591

Collected Steps per Second: 23,209.11579
Overall Steps per Second: 10,953.88354

Timestep Collection Time: 2.15570
Timestep Consumption Time: 2.41181
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.56751

Cumulative Model Updates: 244,602
Cumulative Timesteps: 2,039,991,274

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2039991274...
Checkpoint 2039991274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.69829
Policy Entropy: 2.18713
Value Function Loss: 0.01735

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.53280
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 21,685.25644
Overall Steps per Second: 10,417.69249

Timestep Collection Time: 2.30691
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.80202

Cumulative Model Updates: 244,608
Cumulative Timesteps: 2,040,041,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.34996
Policy Entropy: 2.20136
Value Function Loss: 0.01845

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.59608

Collected Steps per Second: 22,983.78935
Overall Steps per Second: 10,689.41262

Timestep Collection Time: 2.17632
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.67940

Cumulative Model Updates: 244,614
Cumulative Timesteps: 2,040,091,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2040091320...
Checkpoint 2040091320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.50805
Policy Entropy: 2.17433
Value Function Loss: 0.01847

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.60227

Collected Steps per Second: 22,279.15805
Overall Steps per Second: 10,624.16164

Timestep Collection Time: 2.24479
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.70738

Cumulative Model Updates: 244,620
Cumulative Timesteps: 2,040,141,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.46291
Policy Entropy: 2.20234
Value Function Loss: 0.01812

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.60285

Collected Steps per Second: 23,010.52585
Overall Steps per Second: 10,922.52126

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.40526
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.57861

Cumulative Model Updates: 244,626
Cumulative Timesteps: 2,040,191,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2040191342...
Checkpoint 2040191342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.00597
Policy Entropy: 2.16711
Value Function Loss: 0.01838

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.53416
Value Function Update Magnitude: 0.60954

Collected Steps per Second: 22,913.77577
Overall Steps per Second: 10,662.68482

Timestep Collection Time: 2.18236
Timestep Consumption Time: 2.50746
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.68981

Cumulative Model Updates: 244,632
Cumulative Timesteps: 2,040,241,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.87838
Policy Entropy: 2.15959
Value Function Loss: 0.01777

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.53438
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 23,366.20275
Overall Steps per Second: 10,899.32956

Timestep Collection Time: 2.14078
Timestep Consumption Time: 2.44867
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.58946

Cumulative Model Updates: 244,638
Cumulative Timesteps: 2,040,291,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2040291370...
Checkpoint 2040291370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.68773
Policy Entropy: 2.16235
Value Function Loss: 0.01735

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.62639

Collected Steps per Second: 22,377.29981
Overall Steps per Second: 10,585.61947

Timestep Collection Time: 2.23557
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.72585

Cumulative Model Updates: 244,644
Cumulative Timesteps: 2,040,341,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.99280
Policy Entropy: 2.20411
Value Function Loss: 0.01655

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.53309
Value Function Update Magnitude: 0.62970

Collected Steps per Second: 24,346.06875
Overall Steps per Second: 10,978.99733

Timestep Collection Time: 2.05429
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.55543

Cumulative Model Updates: 244,650
Cumulative Timesteps: 2,040,391,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2040391410...
Checkpoint 2040391410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.26327
Policy Entropy: 2.21619
Value Function Loss: 0.01682

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.52957
Value Function Update Magnitude: 0.61756

Collected Steps per Second: 22,941.95446
Overall Steps per Second: 10,740.47437

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.65585

Cumulative Model Updates: 244,656
Cumulative Timesteps: 2,040,441,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.65127
Policy Entropy: 2.20793
Value Function Loss: 0.01795

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.62677

Collected Steps per Second: 23,139.78401
Overall Steps per Second: 10,788.90207

Timestep Collection Time: 2.16173
Timestep Consumption Time: 2.47470
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.63643

Cumulative Model Updates: 244,662
Cumulative Timesteps: 2,040,491,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2040491438...
Checkpoint 2040491438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.73994
Policy Entropy: 2.20568
Value Function Loss: 0.01675

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.64227

Collected Steps per Second: 22,355.65547
Overall Steps per Second: 10,784.55922

Timestep Collection Time: 2.23782
Timestep Consumption Time: 2.40103
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.63885

Cumulative Model Updates: 244,668
Cumulative Timesteps: 2,040,541,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.20611
Policy Entropy: 2.20413
Value Function Loss: 0.01670

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.52729
Value Function Update Magnitude: 0.60808

Collected Steps per Second: 23,140.32360
Overall Steps per Second: 10,739.03721

Timestep Collection Time: 2.16082
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.65610

Cumulative Model Updates: 244,674
Cumulative Timesteps: 2,040,591,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2040591468...
Checkpoint 2040591468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.66884
Policy Entropy: 2.18440
Value Function Loss: 0.01715

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.53232
Value Function Update Magnitude: 0.59956

Collected Steps per Second: 22,579.49490
Overall Steps per Second: 10,634.50543

Timestep Collection Time: 2.21520
Timestep Consumption Time: 2.48817
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.70337

Cumulative Model Updates: 244,680
Cumulative Timesteps: 2,040,641,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.23112
Policy Entropy: 2.17618
Value Function Loss: 0.01787

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.53759
Value Function Update Magnitude: 0.59127

Collected Steps per Second: 22,957.10921
Overall Steps per Second: 10,923.98109

Timestep Collection Time: 2.17858
Timestep Consumption Time: 2.39978
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.57837

Cumulative Model Updates: 244,686
Cumulative Timesteps: 2,040,691,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2040691500...
Checkpoint 2040691500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.81736
Policy Entropy: 2.18357
Value Function Loss: 0.01869

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.54884
Value Function Update Magnitude: 0.59074

Collected Steps per Second: 22,624.86744
Overall Steps per Second: 10,781.54585

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.63755

Cumulative Model Updates: 244,692
Cumulative Timesteps: 2,040,741,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.30315
Policy Entropy: 2.21508
Value Function Loss: 0.01658

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.59770

Collected Steps per Second: 23,560.85713
Overall Steps per Second: 10,824.56301

Timestep Collection Time: 2.12267
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.62023

Cumulative Model Updates: 244,698
Cumulative Timesteps: 2,040,791,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2040791512...
Checkpoint 2040791512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.32049
Policy Entropy: 2.22013
Value Function Loss: 0.01614

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.52553
Value Function Update Magnitude: 0.58111

Collected Steps per Second: 23,137.83064
Overall Steps per Second: 10,821.44765

Timestep Collection Time: 2.16191
Timestep Consumption Time: 2.46057
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.62249

Cumulative Model Updates: 244,704
Cumulative Timesteps: 2,040,841,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.14789
Policy Entropy: 2.24039
Value Function Loss: 0.01545

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.51483
Value Function Update Magnitude: 0.55276

Collected Steps per Second: 23,214.59167
Overall Steps per Second: 10,735.90136

Timestep Collection Time: 2.15485
Timestep Consumption Time: 2.50465
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.65951

Cumulative Model Updates: 244,710
Cumulative Timesteps: 2,040,891,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2040891558...
Checkpoint 2040891558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.70716
Policy Entropy: 2.25642
Value Function Loss: 0.01528

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.50843
Value Function Update Magnitude: 0.54395

Collected Steps per Second: 22,811.58561
Overall Steps per Second: 11,029.71795

Timestep Collection Time: 2.19283
Timestep Consumption Time: 2.34237
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.53520

Cumulative Model Updates: 244,716
Cumulative Timesteps: 2,040,941,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.96908
Policy Entropy: 2.25656
Value Function Loss: 0.01514

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.50776
Value Function Update Magnitude: 0.54166

Collected Steps per Second: 23,144.65376
Overall Steps per Second: 10,895.45395

Timestep Collection Time: 2.16154
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.59164

Cumulative Model Updates: 244,722
Cumulative Timesteps: 2,040,991,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2040991608...
Checkpoint 2040991608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.53044
Policy Entropy: 2.23021
Value Function Loss: 0.01572

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.51310
Value Function Update Magnitude: 0.56505

Collected Steps per Second: 22,392.06728
Overall Steps per Second: 10,638.16189

Timestep Collection Time: 2.23383
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.70194

Cumulative Model Updates: 244,728
Cumulative Timesteps: 2,041,041,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.07206
Policy Entropy: 2.19532
Value Function Loss: 0.01649

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.52908
Value Function Update Magnitude: 0.57693

Collected Steps per Second: 22,939.64192
Overall Steps per Second: 10,905.97607

Timestep Collection Time: 2.18068
Timestep Consumption Time: 2.40616
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.58684

Cumulative Model Updates: 244,734
Cumulative Timesteps: 2,041,091,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2041091652...
Checkpoint 2041091652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.74919
Policy Entropy: 2.19168
Value Function Loss: 0.01761

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.54418
Value Function Update Magnitude: 0.59307

Collected Steps per Second: 23,264.24962
Overall Steps per Second: 10,759.90189

Timestep Collection Time: 2.15034
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.64930

Cumulative Model Updates: 244,740
Cumulative Timesteps: 2,041,141,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.68000
Policy Entropy: 2.19671
Value Function Loss: 0.01826

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.54798
Value Function Update Magnitude: 0.59909

Collected Steps per Second: 22,814.60162
Overall Steps per Second: 10,815.85178

Timestep Collection Time: 2.19210
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62395

Cumulative Model Updates: 244,746
Cumulative Timesteps: 2,041,191,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2041191690...
Checkpoint 2041191690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.45259
Policy Entropy: 2.22795
Value Function Loss: 0.01796

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.53343
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 22,709.64677
Overall Steps per Second: 10,650.30911

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.49399
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.69658

Cumulative Model Updates: 244,752
Cumulative Timesteps: 2,041,241,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.12909
Policy Entropy: 2.22505
Value Function Loss: 0.01769

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.53583
Value Function Update Magnitude: 0.64258

Collected Steps per Second: 23,473.44680
Overall Steps per Second: 10,967.69430

Timestep Collection Time: 2.13049
Timestep Consumption Time: 2.42926
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.55976

Cumulative Model Updates: 244,758
Cumulative Timesteps: 2,041,291,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2041291720...
Checkpoint 2041291720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.98447
Policy Entropy: 2.21336
Value Function Loss: 0.01824

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.54585
Value Function Update Magnitude: 0.63834

Collected Steps per Second: 22,884.96430
Overall Steps per Second: 10,727.91586

Timestep Collection Time: 2.18536
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.66186

Cumulative Model Updates: 244,764
Cumulative Timesteps: 2,041,341,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.55904
Policy Entropy: 2.19771
Value Function Loss: 0.01847

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.54812
Value Function Update Magnitude: 0.63328

Collected Steps per Second: 23,603.76155
Overall Steps per Second: 10,841.90878

Timestep Collection Time: 2.11848
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.61210

Cumulative Model Updates: 244,770
Cumulative Timesteps: 2,041,391,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2041391736...
Checkpoint 2041391736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.84880
Policy Entropy: 2.18007
Value Function Loss: 0.01849

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.54855
Value Function Update Magnitude: 0.63687

Collected Steps per Second: 22,704.42411
Overall Steps per Second: 10,752.50237

Timestep Collection Time: 2.20354
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.65287

Cumulative Model Updates: 244,776
Cumulative Timesteps: 2,041,441,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.10878
Policy Entropy: 2.17599
Value Function Loss: 0.01817

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.53394
Value Function Update Magnitude: 0.64009

Collected Steps per Second: 23,432.69264
Overall Steps per Second: 11,155.08943

Timestep Collection Time: 2.13377
Timestep Consumption Time: 2.34849
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.48226

Cumulative Model Updates: 244,782
Cumulative Timesteps: 2,041,491,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2041491766...
Checkpoint 2041491766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.22389
Policy Entropy: 2.16388
Value Function Loss: 0.01916

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.54335
Value Function Update Magnitude: 0.65605

Collected Steps per Second: 22,373.97893
Overall Steps per Second: 10,610.20541

Timestep Collection Time: 2.23519
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.71339

Cumulative Model Updates: 244,788
Cumulative Timesteps: 2,041,541,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.47477
Policy Entropy: 2.18993
Value Function Loss: 0.01863

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.55809
Value Function Update Magnitude: 0.67536

Collected Steps per Second: 22,570.45854
Overall Steps per Second: 10,625.09013

Timestep Collection Time: 2.21546
Timestep Consumption Time: 2.49076
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.70622

Cumulative Model Updates: 244,794
Cumulative Timesteps: 2,041,591,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2041591780...
Checkpoint 2041591780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.43782
Policy Entropy: 2.19779
Value Function Loss: 0.01838

Mean KL Divergence: 0.02535
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.55330
Value Function Update Magnitude: 0.65988

Collected Steps per Second: 22,401.58760
Overall Steps per Second: 10,937.59550

Timestep Collection Time: 2.23270
Timestep Consumption Time: 2.34015
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.57285

Cumulative Model Updates: 244,800
Cumulative Timesteps: 2,041,641,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.44854
Policy Entropy: 2.21239
Value Function Loss: 0.01819

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.65036

Collected Steps per Second: 22,846.29639
Overall Steps per Second: 10,690.28642

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.67789

Cumulative Model Updates: 244,806
Cumulative Timesteps: 2,041,691,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2041691804...
Checkpoint 2041691804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.06287
Policy Entropy: 2.19009
Value Function Loss: 0.01826

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.64553

Collected Steps per Second: 23,178.18197
Overall Steps per Second: 10,835.92176

Timestep Collection Time: 2.15875
Timestep Consumption Time: 2.45885
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.61760

Cumulative Model Updates: 244,812
Cumulative Timesteps: 2,041,741,840

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.31563
Policy Entropy: 2.17571
Value Function Loss: 0.01853

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.64782

Collected Steps per Second: 23,196.73723
Overall Steps per Second: 10,936.97731

Timestep Collection Time: 2.15660
Timestep Consumption Time: 2.41743
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.57402

Cumulative Model Updates: 244,818
Cumulative Timesteps: 2,041,791,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2041791866...
Checkpoint 2041791866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.32094
Policy Entropy: 2.16454
Value Function Loss: 0.01726

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 22,693.31512
Overall Steps per Second: 10,886.41369

Timestep Collection Time: 2.20409
Timestep Consumption Time: 2.39045
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.59453

Cumulative Model Updates: 244,824
Cumulative Timesteps: 2,041,841,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.69936
Policy Entropy: 2.15387
Value Function Loss: 0.01719

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.64064

Collected Steps per Second: 23,452.81504
Overall Steps per Second: 10,787.58331

Timestep Collection Time: 2.13245
Timestep Consumption Time: 2.50362
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.63607

Cumulative Model Updates: 244,830
Cumulative Timesteps: 2,041,891,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2041891896...
Checkpoint 2041891896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.81870
Policy Entropy: 2.14873
Value Function Loss: 0.01729

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.54429
Value Function Update Magnitude: 0.63187

Collected Steps per Second: 22,666.42200
Overall Steps per Second: 10,614.88869

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.50456
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.71055

Cumulative Model Updates: 244,836
Cumulative Timesteps: 2,041,941,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.33233
Policy Entropy: 2.15392
Value Function Loss: 0.01770

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.64413

Collected Steps per Second: 22,757.89083
Overall Steps per Second: 10,902.31706

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.38943
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.58673

Cumulative Model Updates: 244,842
Cumulative Timesteps: 2,041,991,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2041991904...
Checkpoint 2041991904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.01028
Policy Entropy: 2.20155
Value Function Loss: 0.01772

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.62773

Collected Steps per Second: 22,220.65666
Overall Steps per Second: 10,755.83245

Timestep Collection Time: 2.25124
Timestep Consumption Time: 2.39963
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.65087

Cumulative Model Updates: 244,848
Cumulative Timesteps: 2,042,041,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.89739
Policy Entropy: 2.22670
Value Function Loss: 0.01702

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.53233
Value Function Update Magnitude: 0.60823

Collected Steps per Second: 23,282.12869
Overall Steps per Second: 10,785.33998

Timestep Collection Time: 2.14903
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.63907

Cumulative Model Updates: 244,854
Cumulative Timesteps: 2,042,091,962

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2042091962...
Checkpoint 2042091962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.44133
Policy Entropy: 2.24376
Value Function Loss: 0.01613

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.51606
Value Function Update Magnitude: 0.58531

Collected Steps per Second: 22,603.58284
Overall Steps per Second: 10,596.72893

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71844

Cumulative Model Updates: 244,860
Cumulative Timesteps: 2,042,141,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.29680
Policy Entropy: 2.22660
Value Function Loss: 0.01584

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.51557
Value Function Update Magnitude: 0.57079

Collected Steps per Second: 22,813.58169
Overall Steps per Second: 10,933.26742

Timestep Collection Time: 2.19168
Timestep Consumption Time: 2.38152
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.57320

Cumulative Model Updates: 244,866
Cumulative Timesteps: 2,042,191,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2042191962...
Checkpoint 2042191962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.92651
Policy Entropy: 2.22533
Value Function Loss: 0.01801

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.59092

Collected Steps per Second: 22,825.89676
Overall Steps per Second: 10,623.74909

Timestep Collection Time: 2.19163
Timestep Consumption Time: 2.51725
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.70888

Cumulative Model Updates: 244,872
Cumulative Timesteps: 2,042,241,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.77452
Policy Entropy: 2.19141
Value Function Loss: 0.01810

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.53585
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 23,166.42657
Overall Steps per Second: 10,868.33220

Timestep Collection Time: 2.15925
Timestep Consumption Time: 2.44330
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.60255

Cumulative Model Updates: 244,878
Cumulative Timesteps: 2,042,292,010

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2042292010...
Checkpoint 2042292010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.61879
Policy Entropy: 2.18360
Value Function Loss: 0.01826

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.54628
Value Function Update Magnitude: 0.61180

Collected Steps per Second: 22,601.71858
Overall Steps per Second: 10,649.37994

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.69774

Cumulative Model Updates: 244,884
Cumulative Timesteps: 2,042,342,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.73432
Policy Entropy: 2.18227
Value Function Loss: 0.01682

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.59300

Collected Steps per Second: 23,372.76365
Overall Steps per Second: 10,950.72869

Timestep Collection Time: 2.13924
Timestep Consumption Time: 2.42666
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.56591

Cumulative Model Updates: 244,890
Cumulative Timesteps: 2,042,392,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2042392038...
Checkpoint 2042392038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.29990
Policy Entropy: 2.19540
Value Function Loss: 0.01665

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.57899

Collected Steps per Second: 22,848.06181
Overall Steps per Second: 10,673.30806

Timestep Collection Time: 2.18854
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.68496

Cumulative Model Updates: 244,896
Cumulative Timesteps: 2,042,442,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.09205
Policy Entropy: 2.19112
Value Function Loss: 0.01693

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.58143

Collected Steps per Second: 23,024.30641
Overall Steps per Second: 10,886.22609

Timestep Collection Time: 2.17205
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.59388

Cumulative Model Updates: 244,902
Cumulative Timesteps: 2,042,492,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2042492052...
Checkpoint 2042492052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.94027
Policy Entropy: 2.17170
Value Function Loss: 0.01687

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.59195

Collected Steps per Second: 22,620.83377
Overall Steps per Second: 10,667.43147

Timestep Collection Time: 2.21053
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.68754

Cumulative Model Updates: 244,908
Cumulative Timesteps: 2,042,542,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.44473
Policy Entropy: 2.17365
Value Function Loss: 0.01743

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.61784

Collected Steps per Second: 22,872.89319
Overall Steps per Second: 10,891.22757

Timestep Collection Time: 2.18669
Timestep Consumption Time: 2.40563
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.59232

Cumulative Model Updates: 244,914
Cumulative Timesteps: 2,042,592,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2042592072...
Checkpoint 2042592072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.21311
Policy Entropy: 2.17620
Value Function Loss: 0.01820

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.62770

Collected Steps per Second: 22,481.96546
Overall Steps per Second: 10,630.71621

Timestep Collection Time: 2.22409
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.70354

Cumulative Model Updates: 244,920
Cumulative Timesteps: 2,042,642,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.74329
Policy Entropy: 2.17800
Value Function Loss: 0.01895

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.53145
Value Function Update Magnitude: 0.62476

Collected Steps per Second: 22,745.75735
Overall Steps per Second: 10,821.82432

Timestep Collection Time: 2.19839
Timestep Consumption Time: 2.42227
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62066

Cumulative Model Updates: 244,926
Cumulative Timesteps: 2,042,692,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2042692078...
Checkpoint 2042692078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.70833
Policy Entropy: 2.19293
Value Function Loss: 0.01855

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.62219

Collected Steps per Second: 22,328.95240
Overall Steps per Second: 10,744.47775

Timestep Collection Time: 2.24050
Timestep Consumption Time: 2.41566
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.65616

Cumulative Model Updates: 244,932
Cumulative Timesteps: 2,042,742,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.46011
Policy Entropy: 2.19729
Value Function Loss: 0.01849

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.53539
Value Function Update Magnitude: 0.60839

Collected Steps per Second: 22,860.47561
Overall Steps per Second: 10,893.16839

Timestep Collection Time: 2.18849
Timestep Consumption Time: 2.40429
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.59279

Cumulative Model Updates: 244,938
Cumulative Timesteps: 2,042,792,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2042792136...
Checkpoint 2042792136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.76824
Policy Entropy: 2.19844
Value Function Loss: 0.01782

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 22,472.46025
Overall Steps per Second: 10,647.04802

Timestep Collection Time: 2.22619
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.69877

Cumulative Model Updates: 244,944
Cumulative Timesteps: 2,042,842,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.87420
Policy Entropy: 2.20142
Value Function Loss: 0.01725

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 23,464.84907
Overall Steps per Second: 10,893.20942

Timestep Collection Time: 2.13170
Timestep Consumption Time: 2.46015
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.59185

Cumulative Model Updates: 244,950
Cumulative Timesteps: 2,042,892,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2042892184...
Checkpoint 2042892184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.83425
Policy Entropy: 2.20835
Value Function Loss: 0.01802

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.53442
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 22,512.66709
Overall Steps per Second: 10,629.09371

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.70670

Cumulative Model Updates: 244,956
Cumulative Timesteps: 2,042,942,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.44101
Policy Entropy: 2.22024
Value Function Loss: 0.01887

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.62730

Collected Steps per Second: 23,362.37976
Overall Steps per Second: 10,910.60944

Timestep Collection Time: 2.14096
Timestep Consumption Time: 2.44338
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.58435

Cumulative Model Updates: 244,962
Cumulative Timesteps: 2,042,992,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2042992230...
Checkpoint 2042992230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.86149
Policy Entropy: 2.23530
Value Function Loss: 0.01989

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.63556

Collected Steps per Second: 22,782.63148
Overall Steps per Second: 10,645.87893

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.69928

Cumulative Model Updates: 244,968
Cumulative Timesteps: 2,043,042,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.36488
Policy Entropy: 2.22478
Value Function Loss: 0.01911

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.63765

Collected Steps per Second: 23,137.39142
Overall Steps per Second: 10,882.57013

Timestep Collection Time: 2.16187
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.59634

Cumulative Model Updates: 244,974
Cumulative Timesteps: 2,043,092,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2043092278...
Checkpoint 2043092278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.05246
Policy Entropy: 2.20895
Value Function Loss: 0.01929

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.56064
Value Function Update Magnitude: 0.64388

Collected Steps per Second: 22,553.52685
Overall Steps per Second: 10,667.00797

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.68791

Cumulative Model Updates: 244,980
Cumulative Timesteps: 2,043,142,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.03609
Policy Entropy: 2.20451
Value Function Loss: 0.01920

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.65363

Collected Steps per Second: 22,731.39753
Overall Steps per Second: 10,833.48208

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61754

Cumulative Model Updates: 244,986
Cumulative Timesteps: 2,043,192,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2043192308...
Checkpoint 2043192308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.97106
Policy Entropy: 2.23616
Value Function Loss: 0.01887

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.55914
Value Function Update Magnitude: 0.65545

Collected Steps per Second: 22,515.48204
Overall Steps per Second: 10,762.79775

Timestep Collection Time: 2.22203
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.64842

Cumulative Model Updates: 244,992
Cumulative Timesteps: 2,043,242,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.16113
Policy Entropy: 2.29917
Value Function Loss: 0.01733

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.63408

Collected Steps per Second: 23,264.52380
Overall Steps per Second: 10,778.38567

Timestep Collection Time: 2.15100
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.64281

Cumulative Model Updates: 244,998
Cumulative Timesteps: 2,043,292,380

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2043292380...
Checkpoint 2043292380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.93132
Policy Entropy: 2.29482
Value Function Loss: 0.01604

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.51268
Value Function Update Magnitude: 0.58241

Collected Steps per Second: 22,601.91434
Overall Steps per Second: 10,661.94803

Timestep Collection Time: 2.21291
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69108

Cumulative Model Updates: 245,004
Cumulative Timesteps: 2,043,342,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.56088
Policy Entropy: 2.27825
Value Function Loss: 0.01760

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.50967
Value Function Update Magnitude: 0.55133

Collected Steps per Second: 23,370.77534
Overall Steps per Second: 10,981.89520

Timestep Collection Time: 2.13942
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.55295

Cumulative Model Updates: 245,010
Cumulative Timesteps: 2,043,392,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2043392396...
Checkpoint 2043392396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.69921
Policy Entropy: 2.24043
Value Function Loss: 0.01816

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.53238
Value Function Update Magnitude: 0.58003

Collected Steps per Second: 23,098.57253
Overall Steps per Second: 10,806.54158

Timestep Collection Time: 2.16481
Timestep Consumption Time: 2.46239
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.62720

Cumulative Model Updates: 245,016
Cumulative Timesteps: 2,043,442,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.42176
Policy Entropy: 2.25844
Value Function Loss: 0.01799

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.58044

Collected Steps per Second: 23,676.23809
Overall Steps per Second: 10,894.69990

Timestep Collection Time: 2.11300
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.59196

Cumulative Model Updates: 245,022
Cumulative Timesteps: 2,043,492,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2043492428...
Checkpoint 2043492428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.08029
Policy Entropy: 2.28347
Value Function Loss: 0.01680

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.56083

Collected Steps per Second: 22,888.52635
Overall Steps per Second: 10,827.02786

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.62103

Cumulative Model Updates: 245,028
Cumulative Timesteps: 2,043,542,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.54757
Policy Entropy: 2.27609
Value Function Loss: 0.01666

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.51765
Value Function Update Magnitude: 0.54615

Collected Steps per Second: 22,795.50838
Overall Steps per Second: 10,722.87008

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.66517

Cumulative Model Updates: 245,034
Cumulative Timesteps: 2,043,592,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2043592484...
Checkpoint 2043592484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.95699
Policy Entropy: 2.27165
Value Function Loss: 0.01630

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.52090
Value Function Update Magnitude: 0.54783

Collected Steps per Second: 23,243.42588
Overall Steps per Second: 10,909.77675

Timestep Collection Time: 2.15192
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.58470

Cumulative Model Updates: 245,040
Cumulative Timesteps: 2,043,642,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.14375
Policy Entropy: 2.28369
Value Function Loss: 0.01615

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.52380
Value Function Update Magnitude: 0.55896

Collected Steps per Second: 22,898.97088
Overall Steps per Second: 10,820.59223

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62156

Cumulative Model Updates: 245,046
Cumulative Timesteps: 2,043,692,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2043692510...
Checkpoint 2043692510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.93345
Policy Entropy: 2.27761
Value Function Loss: 0.01776

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.52646
Value Function Update Magnitude: 0.57616

Collected Steps per Second: 22,467.08141
Overall Steps per Second: 10,723.27584

Timestep Collection Time: 2.22592
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.66369

Cumulative Model Updates: 245,052
Cumulative Timesteps: 2,043,742,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.74753
Policy Entropy: 2.25954
Value Function Loss: 0.01851

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.62744

Collected Steps per Second: 23,109.31525
Overall Steps per Second: 10,887.71902

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.42899
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.59288

Cumulative Model Updates: 245,058
Cumulative Timesteps: 2,043,792,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2043792526...
Checkpoint 2043792526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.53834
Policy Entropy: 2.23773
Value Function Loss: 0.01888

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.55095
Value Function Update Magnitude: 0.65360

Collected Steps per Second: 22,935.48437
Overall Steps per Second: 11,077.67424

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.33505
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.51647

Cumulative Model Updates: 245,064
Cumulative Timesteps: 2,043,842,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.38518
Policy Entropy: 2.23497
Value Function Loss: 0.01821

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.65153

Collected Steps per Second: 22,714.66549
Overall Steps per Second: 10,516.30486

Timestep Collection Time: 2.20184
Timestep Consumption Time: 2.55402
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.75585

Cumulative Model Updates: 245,070
Cumulative Timesteps: 2,043,892,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2043892572...
Checkpoint 2043892572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.25008
Policy Entropy: 2.24218
Value Function Loss: 0.01761

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.53529
Value Function Update Magnitude: 0.64682

Collected Steps per Second: 22,479.11209
Overall Steps per Second: 10,634.44553

Timestep Collection Time: 2.22535
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.70396

Cumulative Model Updates: 245,076
Cumulative Timesteps: 2,043,942,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.49071
Policy Entropy: 2.23802
Value Function Loss: 0.01773

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.53546
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 23,435.82331
Overall Steps per Second: 10,985.90102

Timestep Collection Time: 2.13357
Timestep Consumption Time: 2.41790
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.55147

Cumulative Model Updates: 245,082
Cumulative Timesteps: 2,043,992,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2043992598...
Checkpoint 2043992598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.11698
Policy Entropy: 2.24338
Value Function Loss: 0.01758

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.52798
Value Function Update Magnitude: 0.64071

Collected Steps per Second: 22,851.29026
Overall Steps per Second: 10,708.42011

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.48136
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.66960

Cumulative Model Updates: 245,088
Cumulative Timesteps: 2,044,042,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.09335
Policy Entropy: 2.23952
Value Function Loss: 0.01793

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.52721
Value Function Update Magnitude: 0.62152

Collected Steps per Second: 22,652.28360
Overall Steps per Second: 10,818.73897

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.41520
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.62327

Cumulative Model Updates: 245,094
Cumulative Timesteps: 2,044,092,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2044092620...
Checkpoint 2044092620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.46531
Policy Entropy: 2.23780
Value Function Loss: 0.01740

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.52244
Value Function Update Magnitude: 0.60672

Collected Steps per Second: 22,134.58324
Overall Steps per Second: 10,579.39297

Timestep Collection Time: 2.25990
Timestep Consumption Time: 2.46835
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.72825

Cumulative Model Updates: 245,100
Cumulative Timesteps: 2,044,142,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.71677
Policy Entropy: 2.25108
Value Function Loss: 0.01712

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.52410
Value Function Update Magnitude: 0.60971

Collected Steps per Second: 22,714.34002
Overall Steps per Second: 10,947.45395

Timestep Collection Time: 2.20231
Timestep Consumption Time: 2.36716
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.56946

Cumulative Model Updates: 245,106
Cumulative Timesteps: 2,044,192,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2044192666...
Checkpoint 2044192666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.28980
Policy Entropy: 2.28341
Value Function Loss: 0.01726

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.52956
Value Function Update Magnitude: 0.61706

Collected Steps per Second: 22,811.78281
Overall Steps per Second: 10,670.02577

Timestep Collection Time: 2.19229
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.68696

Cumulative Model Updates: 245,112
Cumulative Timesteps: 2,044,242,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.63530
Policy Entropy: 2.29618
Value Function Loss: 0.01734

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.52872
Value Function Update Magnitude: 0.60317

Collected Steps per Second: 23,437.74789
Overall Steps per Second: 10,853.11688

Timestep Collection Time: 2.13365
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60771

Cumulative Model Updates: 245,118
Cumulative Timesteps: 2,044,292,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2044292684...
Checkpoint 2044292684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.70587
Policy Entropy: 2.28819
Value Function Loss: 0.01821

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.59216

Collected Steps per Second: 22,428.46459
Overall Steps per Second: 10,642.11703

Timestep Collection Time: 2.22958
Timestep Consumption Time: 2.46930
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.69888

Cumulative Model Updates: 245,124
Cumulative Timesteps: 2,044,342,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.74664
Policy Entropy: 2.28066
Value Function Loss: 0.01705

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.51932
Value Function Update Magnitude: 0.58247

Collected Steps per Second: 23,517.44642
Overall Steps per Second: 10,980.09116

Timestep Collection Time: 2.12634
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.55424

Cumulative Model Updates: 245,130
Cumulative Timesteps: 2,044,392,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2044392696...
Checkpoint 2044392696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.60374
Policy Entropy: 2.26109
Value Function Loss: 0.01775

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.52241
Value Function Update Magnitude: 0.56698

Collected Steps per Second: 22,985.80221
Overall Steps per Second: 10,754.89719

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.65053

Cumulative Model Updates: 245,136
Cumulative Timesteps: 2,044,442,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.61361
Policy Entropy: 2.28174
Value Function Loss: 0.01798

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.53707
Value Function Update Magnitude: 0.57434

Collected Steps per Second: 23,574.47271
Overall Steps per Second: 10,819.90650

Timestep Collection Time: 2.12204
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.62351

Cumulative Model Updates: 245,142
Cumulative Timesteps: 2,044,492,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2044492738...
Checkpoint 2044492738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.66474
Policy Entropy: 2.25992
Value Function Loss: 0.01844

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.53676
Value Function Update Magnitude: 0.57723

Collected Steps per Second: 22,569.92092
Overall Steps per Second: 10,670.60033

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.47083
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.68652

Cumulative Model Updates: 245,148
Cumulative Timesteps: 2,044,542,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.03392
Policy Entropy: 2.24638
Value Function Loss: 0.01845

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.52104
Value Function Update Magnitude: 0.57115

Collected Steps per Second: 23,023.20053
Overall Steps per Second: 10,891.52341

Timestep Collection Time: 2.17224
Timestep Consumption Time: 2.41958
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.59183

Cumulative Model Updates: 245,154
Cumulative Timesteps: 2,044,592,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2044592758...
Checkpoint 2044592758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.29723
Policy Entropy: 2.19776
Value Function Loss: 0.01827

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.15429
Policy Update Magnitude: 0.50328
Value Function Update Magnitude: 0.57796

Collected Steps per Second: 22,669.81963
Overall Steps per Second: 10,661.08259

Timestep Collection Time: 2.20690
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.69277

Cumulative Model Updates: 245,160
Cumulative Timesteps: 2,044,642,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.95254
Policy Entropy: 2.20180
Value Function Loss: 0.01799

Mean KL Divergence: 0.03151
SB3 Clip Fraction: 0.17420
Policy Update Magnitude: 0.52644
Value Function Update Magnitude: 0.56926

Collected Steps per Second: 22,956.54180
Overall Steps per Second: 10,804.68613

Timestep Collection Time: 2.17803
Timestep Consumption Time: 2.44959
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.62762

Cumulative Model Updates: 245,166
Cumulative Timesteps: 2,044,692,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2044692788...
Checkpoint 2044692788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.42729
Policy Entropy: 2.20184
Value Function Loss: 0.01900

Mean KL Divergence: 0.02779
SB3 Clip Fraction: 0.16244
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.57272

Collected Steps per Second: 22,339.10368
Overall Steps per Second: 10,617.33647

Timestep Collection Time: 2.23832
Timestep Consumption Time: 2.47115
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.70947

Cumulative Model Updates: 245,172
Cumulative Timesteps: 2,044,742,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.32543
Policy Entropy: 2.24404
Value Function Loss: 0.01800

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.55191
Value Function Update Magnitude: 0.59342

Collected Steps per Second: 22,725.47835
Overall Steps per Second: 11,009.76631

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.34247
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.54378

Cumulative Model Updates: 245,178
Cumulative Timesteps: 2,044,792,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2044792816...
Checkpoint 2044792816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.06156
Policy Entropy: 2.24666
Value Function Loss: 0.01735

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.60680

Collected Steps per Second: 22,807.29025
Overall Steps per Second: 10,598.86063

Timestep Collection Time: 2.19307
Timestep Consumption Time: 2.52612
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.71919

Cumulative Model Updates: 245,184
Cumulative Timesteps: 2,044,842,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.67981
Policy Entropy: 2.25064
Value Function Loss: 0.01766

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.54851
Value Function Update Magnitude: 0.59436

Collected Steps per Second: 23,374.59673
Overall Steps per Second: 10,843.38374

Timestep Collection Time: 2.13916
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.61129

Cumulative Model Updates: 245,190
Cumulative Timesteps: 2,044,892,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2044892836...
Checkpoint 2044892836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.75764
Policy Entropy: 2.24341
Value Function Loss: 0.01758

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.60508

Collected Steps per Second: 22,686.18328
Overall Steps per Second: 10,644.65624

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.49361
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.69794

Cumulative Model Updates: 245,196
Cumulative Timesteps: 2,044,942,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.76534
Policy Entropy: 2.25624
Value Function Loss: 0.01759

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.61797

Collected Steps per Second: 23,344.87122
Overall Steps per Second: 10,936.23612

Timestep Collection Time: 2.14291
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.57433

Cumulative Model Updates: 245,202
Cumulative Timesteps: 2,044,992,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2044992870...
Checkpoint 2044992870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.83918
Policy Entropy: 2.25545
Value Function Loss: 0.01713

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.60846

Collected Steps per Second: 22,688.54546
Overall Steps per Second: 10,684.01652

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.68139

Cumulative Model Updates: 245,208
Cumulative Timesteps: 2,045,042,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.62469
Policy Entropy: 2.23454
Value Function Loss: 0.01721

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.53744
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 23,357.91957
Overall Steps per Second: 10,868.90316

Timestep Collection Time: 2.14060
Timestep Consumption Time: 2.45968
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.60028

Cumulative Model Updates: 245,214
Cumulative Timesteps: 2,045,092,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2045092886...
Checkpoint 2045092886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.29195
Policy Entropy: 2.21342
Value Function Loss: 0.01800

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.54327
Value Function Update Magnitude: 0.59368

Collected Steps per Second: 22,360.65469
Overall Steps per Second: 10,661.47400

Timestep Collection Time: 2.23652
Timestep Consumption Time: 2.45420
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.69072

Cumulative Model Updates: 245,220
Cumulative Timesteps: 2,045,142,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.97734
Policy Entropy: 2.21328
Value Function Loss: 0.01851

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.60106

Collected Steps per Second: 22,911.57066
Overall Steps per Second: 10,914.30215

Timestep Collection Time: 2.18300
Timestep Consumption Time: 2.39961
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.58261

Cumulative Model Updates: 245,226
Cumulative Timesteps: 2,045,192,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2045192912...
Checkpoint 2045192912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.07705
Policy Entropy: 2.22058
Value Function Loss: 0.01870

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.54968
Value Function Update Magnitude: 0.63393

Collected Steps per Second: 22,538.36093
Overall Steps per Second: 10,634.79503

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.70286

Cumulative Model Updates: 245,232
Cumulative Timesteps: 2,045,242,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.71199
Policy Entropy: 2.21263
Value Function Loss: 0.01828

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.55184
Value Function Update Magnitude: 0.64360

Collected Steps per Second: 23,327.24596
Overall Steps per Second: 10,904.12553

Timestep Collection Time: 2.14427
Timestep Consumption Time: 2.44298
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.58725

Cumulative Model Updates: 245,238
Cumulative Timesteps: 2,045,292,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2045292946...
Checkpoint 2045292946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.88449
Policy Entropy: 2.25265
Value Function Loss: 0.01736

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.62483

Collected Steps per Second: 22,562.31327
Overall Steps per Second: 10,704.82666

Timestep Collection Time: 2.21706
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.67285

Cumulative Model Updates: 245,244
Cumulative Timesteps: 2,045,342,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.84340
Policy Entropy: 2.27901
Value Function Loss: 0.01691

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.52737
Value Function Update Magnitude: 0.60773

Collected Steps per Second: 23,324.95798
Overall Steps per Second: 10,815.54120

Timestep Collection Time: 2.14423
Timestep Consumption Time: 2.48004
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.62427

Cumulative Model Updates: 245,250
Cumulative Timesteps: 2,045,392,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2045392982...
Checkpoint 2045392982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.43779
Policy Entropy: 2.32080
Value Function Loss: 0.01748

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.52914
Value Function Update Magnitude: 0.59525

Collected Steps per Second: 22,939.91709
Overall Steps per Second: 10,680.31154

Timestep Collection Time: 2.17978
Timestep Consumption Time: 2.50210
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.68189

Cumulative Model Updates: 245,256
Cumulative Timesteps: 2,045,442,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.76323
Policy Entropy: 2.30667
Value Function Loss: 0.01699

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.60381

Collected Steps per Second: 23,540.53151
Overall Steps per Second: 10,877.92481

Timestep Collection Time: 2.12510
Timestep Consumption Time: 2.47375
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.59886

Cumulative Model Updates: 245,262
Cumulative Timesteps: 2,045,493,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2045493012...
Checkpoint 2045493012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.58945
Policy Entropy: 2.30524
Value Function Loss: 0.01721

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.52822
Value Function Update Magnitude: 0.62552

Collected Steps per Second: 22,021.18691
Overall Steps per Second: 10,636.61957

Timestep Collection Time: 2.27118
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.70206

Cumulative Model Updates: 245,268
Cumulative Timesteps: 2,045,543,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.26996
Policy Entropy: 2.27542
Value Function Loss: 0.01715

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.53971
Value Function Update Magnitude: 0.64011

Collected Steps per Second: 23,551.38738
Overall Steps per Second: 10,942.47295

Timestep Collection Time: 2.12310
Timestep Consumption Time: 2.44643
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.56953

Cumulative Model Updates: 245,274
Cumulative Timesteps: 2,045,593,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2045593028...
Checkpoint 2045593028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.73208
Policy Entropy: 2.27617
Value Function Loss: 0.01763

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.63541

Collected Steps per Second: 22,718.99456
Overall Steps per Second: 10,621.03977

Timestep Collection Time: 2.20212
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.71046

Cumulative Model Updates: 245,280
Cumulative Timesteps: 2,045,643,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.62112
Policy Entropy: 2.25242
Value Function Loss: 0.01728

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.61407

Collected Steps per Second: 22,749.36637
Overall Steps per Second: 10,820.54861

Timestep Collection Time: 2.19839
Timestep Consumption Time: 2.42356
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.62195

Cumulative Model Updates: 245,286
Cumulative Timesteps: 2,045,693,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2045693070...
Checkpoint 2045693070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.27448
Policy Entropy: 2.25053
Value Function Loss: 0.01763

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.60974

Collected Steps per Second: 22,249.94655
Overall Steps per Second: 10,711.55884

Timestep Collection Time: 2.24801
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.66954

Cumulative Model Updates: 245,292
Cumulative Timesteps: 2,045,743,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.76797
Policy Entropy: 2.23863
Value Function Loss: 0.01745

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.54692
Value Function Update Magnitude: 0.62365

Collected Steps per Second: 22,724.01817
Overall Steps per Second: 10,690.80334

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.47749
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.67860

Cumulative Model Updates: 245,298
Cumulative Timesteps: 2,045,793,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2045793106...
Checkpoint 2045793106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.55927
Policy Entropy: 2.21321
Value Function Loss: 0.01840

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.64546

Collected Steps per Second: 22,075.33000
Overall Steps per Second: 10,501.14723

Timestep Collection Time: 2.26524
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.76196

Cumulative Model Updates: 245,304
Cumulative Timesteps: 2,045,843,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.07977
Policy Entropy: 2.22665
Value Function Loss: 0.01692

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.53486
Value Function Update Magnitude: 0.64294

Collected Steps per Second: 23,346.61341
Overall Steps per Second: 10,861.74153

Timestep Collection Time: 2.14198
Timestep Consumption Time: 2.46207
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.60405

Cumulative Model Updates: 245,310
Cumulative Timesteps: 2,045,893,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2045893120...
Checkpoint 2045893120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.55366
Policy Entropy: 2.19471
Value Function Loss: 0.01706

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.53552
Value Function Update Magnitude: 0.63488

Collected Steps per Second: 23,381.43594
Overall Steps per Second: 10,857.02099

Timestep Collection Time: 2.13948
Timestep Consumption Time: 2.46805
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.60753

Cumulative Model Updates: 245,316
Cumulative Timesteps: 2,045,943,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.22310
Policy Entropy: 2.22256
Value Function Loss: 0.01629

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.63066

Collected Steps per Second: 23,497.49406
Overall Steps per Second: 10,697.67061

Timestep Collection Time: 2.12908
Timestep Consumption Time: 2.54745
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.67653

Cumulative Model Updates: 245,322
Cumulative Timesteps: 2,045,993,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2045993172...
Checkpoint 2045993172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.43483
Policy Entropy: 2.22573
Value Function Loss: 0.01598

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.62427

Collected Steps per Second: 22,876.41017
Overall Steps per Second: 10,695.67358

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.49022
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.67684

Cumulative Model Updates: 245,328
Cumulative Timesteps: 2,046,043,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.13432
Policy Entropy: 2.24618
Value Function Loss: 0.01648

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.52574
Value Function Update Magnitude: 0.60417

Collected Steps per Second: 23,023.44850
Overall Steps per Second: 10,820.90919

Timestep Collection Time: 2.17196
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.62124

Cumulative Model Updates: 245,334
Cumulative Timesteps: 2,046,093,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2046093200...
Checkpoint 2046093200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.22807
Policy Entropy: 2.21588
Value Function Loss: 0.01791

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.58400

Collected Steps per Second: 23,538.39479
Overall Steps per Second: 10,990.51367

Timestep Collection Time: 2.12453
Timestep Consumption Time: 2.42558
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.55011

Cumulative Model Updates: 245,340
Cumulative Timesteps: 2,046,143,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.54540
Policy Entropy: 2.18518
Value Function Loss: 0.01869

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.53969
Value Function Update Magnitude: 0.60384

Collected Steps per Second: 23,141.49442
Overall Steps per Second: 10,749.66930

Timestep Collection Time: 2.16149
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.65317

Cumulative Model Updates: 245,346
Cumulative Timesteps: 2,046,193,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2046193228...
Checkpoint 2046193228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.23501
Policy Entropy: 2.18065
Value Function Loss: 0.01842

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.53126
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 22,401.40399
Overall Steps per Second: 10,634.90868

Timestep Collection Time: 2.23227
Timestep Consumption Time: 2.46979
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.70206

Cumulative Model Updates: 245,352
Cumulative Timesteps: 2,046,243,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.81082
Policy Entropy: 2.19134
Value Function Loss: 0.01744

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.53733
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 23,269.81309
Overall Steps per Second: 11,124.63225

Timestep Collection Time: 2.14914
Timestep Consumption Time: 2.34629
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.49543

Cumulative Model Updates: 245,358
Cumulative Timesteps: 2,046,293,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2046293244...
Checkpoint 2046293244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.25974
Policy Entropy: 2.21242
Value Function Loss: 0.01718

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.65309

Collected Steps per Second: 22,307.24893
Overall Steps per Second: 10,727.82270

Timestep Collection Time: 2.24259
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.66320

Cumulative Model Updates: 245,364
Cumulative Timesteps: 2,046,343,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.04211
Policy Entropy: 2.23331
Value Function Loss: 0.01765

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.67908

Collected Steps per Second: 22,623.84916
Overall Steps per Second: 10,653.53409

Timestep Collection Time: 2.21129
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.69591

Cumulative Model Updates: 245,370
Cumulative Timesteps: 2,046,393,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2046393298...
Checkpoint 2046393298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.99197
Policy Entropy: 2.24239
Value Function Loss: 0.01794

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.66491

Collected Steps per Second: 22,285.31078
Overall Steps per Second: 10,804.74183

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.38530
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.63019

Cumulative Model Updates: 245,376
Cumulative Timesteps: 2,046,443,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.11031
Policy Entropy: 2.24003
Value Function Loss: 0.01767

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.55535
Value Function Update Magnitude: 0.64856

Collected Steps per Second: 22,547.05373
Overall Steps per Second: 10,605.80050

Timestep Collection Time: 2.21918
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.71780

Cumulative Model Updates: 245,382
Cumulative Timesteps: 2,046,493,362

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2046493362...
Checkpoint 2046493362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.93318
Policy Entropy: 2.19988
Value Function Loss: 0.01747

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.63679

Collected Steps per Second: 22,655.34836
Overall Steps per Second: 10,922.79631

Timestep Collection Time: 2.20734
Timestep Consumption Time: 2.37098
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.57831

Cumulative Model Updates: 245,388
Cumulative Timesteps: 2,046,543,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.11721
Policy Entropy: 2.21390
Value Function Loss: 0.01583

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.16204
Policy Update Magnitude: 0.53224
Value Function Update Magnitude: 0.62441

Collected Steps per Second: 23,271.42912
Overall Steps per Second: 10,927.92510

Timestep Collection Time: 2.14907
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.57653

Cumulative Model Updates: 245,394
Cumulative Timesteps: 2,046,593,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2046593382...
Checkpoint 2046593382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.62154
Policy Entropy: 2.20850
Value Function Loss: 0.01695

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.55487
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,615.79435
Overall Steps per Second: 10,713.20771

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.45659
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.66770

Cumulative Model Updates: 245,400
Cumulative Timesteps: 2,046,643,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.42171
Policy Entropy: 2.22205
Value Function Loss: 0.01673

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.59969

Collected Steps per Second: 23,399.74596
Overall Steps per Second: 10,956.21020

Timestep Collection Time: 2.13806
Timestep Consumption Time: 2.42830
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.56636

Cumulative Model Updates: 245,406
Cumulative Timesteps: 2,046,693,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2046693418...
Checkpoint 2046693418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.77997
Policy Entropy: 2.20638
Value Function Loss: 0.01705

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.53108
Value Function Update Magnitude: 0.58429

Collected Steps per Second: 22,544.55687
Overall Steps per Second: 10,858.91089

Timestep Collection Time: 2.21889
Timestep Consumption Time: 2.38783
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.60672

Cumulative Model Updates: 245,412
Cumulative Timesteps: 2,046,743,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.95145
Policy Entropy: 2.19760
Value Function Loss: 0.01738

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.53797
Value Function Update Magnitude: 0.59191

Collected Steps per Second: 23,099.84195
Overall Steps per Second: 10,760.00211

Timestep Collection Time: 2.16530
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.64851

Cumulative Model Updates: 245,418
Cumulative Timesteps: 2,046,793,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2046793460...
Checkpoint 2046793460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.90442
Policy Entropy: 2.21733
Value Function Loss: 0.01686

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.53826
Value Function Update Magnitude: 0.61510

Collected Steps per Second: 22,486.55304
Overall Steps per Second: 10,604.43207

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.71765

Cumulative Model Updates: 245,424
Cumulative Timesteps: 2,046,843,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.02180
Policy Entropy: 2.20890
Value Function Loss: 0.01794

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.63909

Collected Steps per Second: 22,893.45669
Overall Steps per Second: 10,931.08602

Timestep Collection Time: 2.18508
Timestep Consumption Time: 2.39123
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.57631

Cumulative Model Updates: 245,430
Cumulative Timesteps: 2,046,893,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2046893512...
Checkpoint 2046893512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.23147
Policy Entropy: 2.21906
Value Function Loss: 0.01766

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.53537
Value Function Update Magnitude: 0.65119

Collected Steps per Second: 22,739.19132
Overall Steps per Second: 10,816.06225

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.62349

Cumulative Model Updates: 245,436
Cumulative Timesteps: 2,046,943,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.46330
Policy Entropy: 2.20477
Value Function Loss: 0.01895

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.53919
Value Function Update Magnitude: 0.65604

Collected Steps per Second: 23,736.05124
Overall Steps per Second: 11,001.40388

Timestep Collection Time: 2.10658
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.54506

Cumulative Model Updates: 245,442
Cumulative Timesteps: 2,046,993,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2046993522...
Checkpoint 2046993522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.41314
Policy Entropy: 2.21074
Value Function Loss: 0.01878

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.65052

Collected Steps per Second: 22,804.01174
Overall Steps per Second: 10,747.12362

Timestep Collection Time: 2.19347
Timestep Consumption Time: 2.46079
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.65427

Cumulative Model Updates: 245,448
Cumulative Timesteps: 2,047,043,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.91689
Policy Entropy: 2.22510
Value Function Loss: 0.01834

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.55330
Value Function Update Magnitude: 0.66045

Collected Steps per Second: 22,898.70425
Overall Steps per Second: 10,928.48974

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.39291
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.57758

Cumulative Model Updates: 245,454
Cumulative Timesteps: 2,047,093,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2047093568...
Checkpoint 2047093568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.95159
Policy Entropy: 2.23347
Value Function Loss: 0.01820

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.55143
Value Function Update Magnitude: 0.66390

Collected Steps per Second: 22,702.32865
Overall Steps per Second: 10,873.54019

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.39705
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.60053

Cumulative Model Updates: 245,460
Cumulative Timesteps: 2,047,143,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.83259
Policy Entropy: 2.23251
Value Function Loss: 0.01783

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.67497

Collected Steps per Second: 23,718.29880
Overall Steps per Second: 10,991.37051

Timestep Collection Time: 2.10884
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.55066

Cumulative Model Updates: 245,466
Cumulative Timesteps: 2,047,193,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2047193610...
Checkpoint 2047193610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.44162
Policy Entropy: 2.24393
Value Function Loss: 0.01715

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.66267

Collected Steps per Second: 22,348.19650
Overall Steps per Second: 10,724.71050

Timestep Collection Time: 2.23857
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.66474

Cumulative Model Updates: 245,472
Cumulative Timesteps: 2,047,243,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.58796
Policy Entropy: 2.21066
Value Function Loss: 0.01786

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.65676

Collected Steps per Second: 22,564.82891
Overall Steps per Second: 10,681.31959

Timestep Collection Time: 2.21779
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.68519

Cumulative Model Updates: 245,478
Cumulative Timesteps: 2,047,293,682

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2047293682...
Checkpoint 2047293682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.43776
Policy Entropy: 2.21774
Value Function Loss: 0.01717

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.53125
Value Function Update Magnitude: 0.66113

Collected Steps per Second: 22,632.23999
Overall Steps per Second: 10,990.84249

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.34122
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.55161

Cumulative Model Updates: 245,484
Cumulative Timesteps: 2,047,343,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.94428
Policy Entropy: 2.20589
Value Function Loss: 0.01711

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.52517
Value Function Update Magnitude: 0.64768

Collected Steps per Second: 23,062.25814
Overall Steps per Second: 10,856.98568

Timestep Collection Time: 2.16917
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60772

Cumulative Model Updates: 245,490
Cumulative Timesteps: 2,047,393,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2047393734...
Checkpoint 2047393734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.55938
Policy Entropy: 2.22614
Value Function Loss: 0.01632

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.52490
Value Function Update Magnitude: 0.63801

Collected Steps per Second: 22,672.87957
Overall Steps per Second: 10,668.41161

Timestep Collection Time: 2.20616
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.68861

Cumulative Model Updates: 245,496
Cumulative Timesteps: 2,047,443,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.88566
Policy Entropy: 2.21361
Value Function Loss: 0.01716

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.63198

Collected Steps per Second: 23,338.06027
Overall Steps per Second: 10,934.09447

Timestep Collection Time: 2.14311
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.57432

Cumulative Model Updates: 245,502
Cumulative Timesteps: 2,047,493,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2047493770...
Checkpoint 2047493770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.26308
Policy Entropy: 2.22634
Value Function Loss: 0.01688

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.54015
Value Function Update Magnitude: 0.62899

Collected Steps per Second: 23,125.51619
Overall Steps per Second: 10,789.11431

Timestep Collection Time: 2.16211
Timestep Consumption Time: 2.47219
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.63430

Cumulative Model Updates: 245,508
Cumulative Timesteps: 2,047,543,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.29471
Policy Entropy: 2.24061
Value Function Loss: 0.01745

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.53012
Value Function Update Magnitude: 0.63727

Collected Steps per Second: 23,802.69775
Overall Steps per Second: 10,919.30868

Timestep Collection Time: 2.10119
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.58033

Cumulative Model Updates: 245,514
Cumulative Timesteps: 2,047,593,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2047593784...
Checkpoint 2047593784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.77375
Policy Entropy: 2.27617
Value Function Loss: 0.01628

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.14638
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.64173

Collected Steps per Second: 23,066.58758
Overall Steps per Second: 10,893.87582

Timestep Collection Time: 2.16937
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.59341

Cumulative Model Updates: 245,520
Cumulative Timesteps: 2,047,643,824

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.13732
Policy Entropy: 2.24002
Value Function Loss: 0.01804

Mean KL Divergence: 0.02553
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.62854

Collected Steps per Second: 23,265.84079
Overall Steps per Second: 10,926.66736

Timestep Collection Time: 2.15028
Timestep Consumption Time: 2.42825
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.57852

Cumulative Model Updates: 245,526
Cumulative Timesteps: 2,047,693,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2047693852...
Checkpoint 2047693852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.36757
Policy Entropy: 2.24317
Value Function Loss: 0.01818

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 22,186.99042
Overall Steps per Second: 10,539.45673

Timestep Collection Time: 2.25465
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.74635

Cumulative Model Updates: 245,532
Cumulative Timesteps: 2,047,743,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.06668
Policy Entropy: 2.21278
Value Function Loss: 0.01925

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.55635
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 22,338.60173
Overall Steps per Second: 10,547.47928

Timestep Collection Time: 2.23953
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.74312

Cumulative Model Updates: 245,538
Cumulative Timesteps: 2,047,793,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2047793904...
Checkpoint 2047793904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.19627
Policy Entropy: 2.24371
Value Function Loss: 0.01719

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.54170
Value Function Update Magnitude: 0.62060

Collected Steps per Second: 22,389.54743
Overall Steps per Second: 10,664.14084

Timestep Collection Time: 2.23470
Timestep Consumption Time: 2.45709
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69180

Cumulative Model Updates: 245,544
Cumulative Timesteps: 2,047,843,938

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.41198
Policy Entropy: 2.23501
Value Function Loss: 0.01630

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.52214
Value Function Update Magnitude: 0.60089

Collected Steps per Second: 22,769.62611
Overall Steps per Second: 10,927.56115

Timestep Collection Time: 2.19635
Timestep Consumption Time: 2.38015
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.57650

Cumulative Model Updates: 245,550
Cumulative Timesteps: 2,047,893,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2047893948...
Checkpoint 2047893948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.40100
Policy Entropy: 2.22659
Value Function Loss: 0.01658

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.59250

Collected Steps per Second: 22,610.65205
Overall Steps per Second: 10,635.39388

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.70335

Cumulative Model Updates: 245,556
Cumulative Timesteps: 2,047,943,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.25316
Policy Entropy: 2.21130
Value Function Loss: 0.01747

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.53477
Value Function Update Magnitude: 0.61659

Collected Steps per Second: 23,593.25934
Overall Steps per Second: 10,879.61129

Timestep Collection Time: 2.12001
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.59741

Cumulative Model Updates: 245,562
Cumulative Timesteps: 2,047,993,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2047993988...
Checkpoint 2047993988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.34982
Policy Entropy: 2.18923
Value Function Loss: 0.01798

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.54150
Value Function Update Magnitude: 0.64693

Collected Steps per Second: 22,699.52587
Overall Steps per Second: 10,677.53975

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.68572

Cumulative Model Updates: 245,568
Cumulative Timesteps: 2,048,044,020

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.95893
Policy Entropy: 2.22363
Value Function Loss: 0.01801

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.66539

Collected Steps per Second: 23,241.82957
Overall Steps per Second: 10,926.58288

Timestep Collection Time: 2.15207
Timestep Consumption Time: 2.42558
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.57764

Cumulative Model Updates: 245,574
Cumulative Timesteps: 2,048,094,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2048094038...
Checkpoint 2048094038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.14182
Policy Entropy: 2.22815
Value Function Loss: 0.01734

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.66734

Collected Steps per Second: 22,965.37581
Overall Steps per Second: 10,753.99960

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.65222

Cumulative Model Updates: 245,580
Cumulative Timesteps: 2,048,144,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.63865
Policy Entropy: 2.24509
Value Function Loss: 0.01625

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.52238
Value Function Update Magnitude: 0.63540

Collected Steps per Second: 23,362.85226
Overall Steps per Second: 10,742.63853

Timestep Collection Time: 2.14092
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.65603

Cumulative Model Updates: 245,586
Cumulative Timesteps: 2,048,194,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2048194086...
Checkpoint 2048194086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.64975
Policy Entropy: 2.21910
Value Function Loss: 0.01602

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.51944
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 22,679.78106
Overall Steps per Second: 10,649.54928

Timestep Collection Time: 2.20584
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.69766

Cumulative Model Updates: 245,592
Cumulative Timesteps: 2,048,244,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.80237
Policy Entropy: 2.18652
Value Function Loss: 0.01736

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.53227
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 22,948.60056
Overall Steps per Second: 10,926.44131

Timestep Collection Time: 2.17913
Timestep Consumption Time: 2.39766
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.57679

Cumulative Model Updates: 245,598
Cumulative Timesteps: 2,048,294,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2048294122...
Checkpoint 2048294122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.83855
Policy Entropy: 2.15322
Value Function Loss: 0.01847

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.62930

Collected Steps per Second: 22,654.18723
Overall Steps per Second: 10,630.65511

Timestep Collection Time: 2.20710
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.70338

Cumulative Model Updates: 245,604
Cumulative Timesteps: 2,048,344,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.90403
Policy Entropy: 2.16155
Value Function Loss: 0.01872

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.64712

Collected Steps per Second: 23,007.46192
Overall Steps per Second: 10,861.08077

Timestep Collection Time: 2.17356
Timestep Consumption Time: 2.43077
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60433

Cumulative Model Updates: 245,610
Cumulative Timesteps: 2,048,394,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2048394130...
Checkpoint 2048394130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.90957
Policy Entropy: 2.18559
Value Function Loss: 0.01832

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.53339
Value Function Update Magnitude: 0.63712

Collected Steps per Second: 22,451.95373
Overall Steps per Second: 10,682.68025

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.45438
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.68216

Cumulative Model Updates: 245,616
Cumulative Timesteps: 2,048,444,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.36747
Policy Entropy: 2.22433
Value Function Loss: 0.01792

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.53451
Value Function Update Magnitude: 0.64001

Collected Steps per Second: 23,261.52632
Overall Steps per Second: 10,922.60540

Timestep Collection Time: 2.14956
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.57785

Cumulative Model Updates: 245,622
Cumulative Timesteps: 2,048,494,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2048494150...
Checkpoint 2048494150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.33460
Policy Entropy: 2.21164
Value Function Loss: 0.01792

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.67070

Collected Steps per Second: 22,800.41445
Overall Steps per Second: 10,688.92759

Timestep Collection Time: 2.19347
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.67886

Cumulative Model Updates: 245,628
Cumulative Timesteps: 2,048,544,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.90568
Policy Entropy: 2.20657
Value Function Loss: 0.01782

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.66369

Collected Steps per Second: 23,448.30948
Overall Steps per Second: 10,863.40086

Timestep Collection Time: 2.13354
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.60519

Cumulative Model Updates: 245,634
Cumulative Timesteps: 2,048,594,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2048594190...
Checkpoint 2048594190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.99465
Policy Entropy: 2.16279
Value Function Loss: 0.01823

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.65536

Collected Steps per Second: 22,580.98888
Overall Steps per Second: 10,670.08947

Timestep Collection Time: 2.21487
Timestep Consumption Time: 2.47244
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.68731

Cumulative Model Updates: 245,640
Cumulative Timesteps: 2,048,644,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.97389
Policy Entropy: 2.16582
Value Function Loss: 0.01754

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 23,012.27812
Overall Steps per Second: 10,858.60167

Timestep Collection Time: 2.17310
Timestep Consumption Time: 2.43228
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.60538

Cumulative Model Updates: 245,646
Cumulative Timesteps: 2,048,694,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2048694212...
Checkpoint 2048694212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.50013
Policy Entropy: 2.20549
Value Function Loss: 0.01623

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.52453
Value Function Update Magnitude: 0.62924

Collected Steps per Second: 22,967.76778
Overall Steps per Second: 10,705.19475

Timestep Collection Time: 2.17714
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.67100

Cumulative Model Updates: 245,652
Cumulative Timesteps: 2,048,744,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.04478
Policy Entropy: 2.22083
Value Function Loss: 0.01703

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.15738
Policy Update Magnitude: 0.51205
Value Function Update Magnitude: 0.61092

Collected Steps per Second: 22,729.04834
Overall Steps per Second: 10,789.04625

Timestep Collection Time: 2.20027
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.63526

Cumulative Model Updates: 245,658
Cumulative Timesteps: 2,048,794,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2048794226...
Checkpoint 2048794226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.51389
Policy Entropy: 2.22978
Value Function Loss: 0.01713

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.51881
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 22,457.87746
Overall Steps per Second: 10,697.33984

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.67817

Cumulative Model Updates: 245,664
Cumulative Timesteps: 2,048,844,270

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.13224
Policy Entropy: 2.20836
Value Function Loss: 0.01772

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.15628
Policy Update Magnitude: 0.54486
Value Function Update Magnitude: 0.66085

Collected Steps per Second: 22,902.71038
Overall Steps per Second: 10,942.01263

Timestep Collection Time: 2.18341
Timestep Consumption Time: 2.38668
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.57009

Cumulative Model Updates: 245,670
Cumulative Timesteps: 2,048,894,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2048894276...
Checkpoint 2048894276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.09603
Policy Entropy: 2.22163
Value Function Loss: 0.01745

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.64174

Collected Steps per Second: 22,422.95376
Overall Steps per Second: 10,634.72465

Timestep Collection Time: 2.23102
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.70402

Cumulative Model Updates: 245,676
Cumulative Timesteps: 2,048,944,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.89341
Policy Entropy: 2.22842
Value Function Loss: 0.01735

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.62146

Collected Steps per Second: 23,304.85795
Overall Steps per Second: 10,827.51622

Timestep Collection Time: 2.14582
Timestep Consumption Time: 2.47278
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.61860

Cumulative Model Updates: 245,682
Cumulative Timesteps: 2,048,994,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2048994310...
Checkpoint 2048994310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.32998
Policy Entropy: 2.21705
Value Function Loss: 0.01731

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.61695

Collected Steps per Second: 22,779.90975
Overall Steps per Second: 10,641.49605

Timestep Collection Time: 2.19518
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.69915

Cumulative Model Updates: 245,688
Cumulative Timesteps: 2,049,044,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.40772
Policy Entropy: 2.22269
Value Function Loss: 0.01719

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.53664
Value Function Update Magnitude: 0.63104

Collected Steps per Second: 23,920.38589
Overall Steps per Second: 10,972.86026

Timestep Collection Time: 2.09119
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.55870

Cumulative Model Updates: 245,694
Cumulative Timesteps: 2,049,094,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2049094338...
Checkpoint 2049094338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.65013
Policy Entropy: 2.23297
Value Function Loss: 0.01774

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.63906

Collected Steps per Second: 22,951.31053
Overall Steps per Second: 10,701.39596

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.67304

Cumulative Model Updates: 245,700
Cumulative Timesteps: 2,049,144,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.31323
Policy Entropy: 2.23742
Value Function Loss: 0.01776

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.64613

Collected Steps per Second: 23,282.50995
Overall Steps per Second: 10,836.47904

Timestep Collection Time: 2.14848
Timestep Consumption Time: 2.46760
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.61607

Cumulative Model Updates: 245,706
Cumulative Timesteps: 2,049,194,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2049194368...
Checkpoint 2049194368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.78315
Policy Entropy: 2.23941
Value Function Loss: 0.01767

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.54420
Value Function Update Magnitude: 0.64639

Collected Steps per Second: 22,990.27506
Overall Steps per Second: 11,052.81805

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.34909
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.52410

Cumulative Model Updates: 245,712
Cumulative Timesteps: 2,049,244,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.44602
Policy Entropy: 2.19805
Value Function Loss: 0.01890

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.64224

Collected Steps per Second: 22,726.77709
Overall Steps per Second: 10,682.43030

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.68264

Cumulative Model Updates: 245,718
Cumulative Timesteps: 2,049,294,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2049294394...
Checkpoint 2049294394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.36185
Policy Entropy: 2.20770
Value Function Loss: 0.01954

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.55827
Value Function Update Magnitude: 0.65517

Collected Steps per Second: 22,354.91498
Overall Steps per Second: 10,597.39184

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.71927

Cumulative Model Updates: 245,724
Cumulative Timesteps: 2,049,344,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.29747
Policy Entropy: 2.18416
Value Function Loss: 0.01961

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.54918
Value Function Update Magnitude: 0.66867

Collected Steps per Second: 22,972.66844
Overall Steps per Second: 10,798.16754

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.45401
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.63060

Cumulative Model Updates: 245,730
Cumulative Timesteps: 2,049,394,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2049394408...
Checkpoint 2049394408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.61015
Policy Entropy: 2.19582
Value Function Loss: 0.01908

Mean KL Divergence: 0.02891
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.67304

Collected Steps per Second: 22,389.13720
Overall Steps per Second: 10,748.95049

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.65385

Cumulative Model Updates: 245,736
Cumulative Timesteps: 2,049,444,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.38748
Policy Entropy: 2.20769
Value Function Loss: 0.01788

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.53341
Value Function Update Magnitude: 0.66815

Collected Steps per Second: 23,249.81021
Overall Steps per Second: 10,787.00271

Timestep Collection Time: 2.15176
Timestep Consumption Time: 2.48604
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.63780

Cumulative Model Updates: 245,742
Cumulative Timesteps: 2,049,494,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2049494460...
Checkpoint 2049494460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.73256
Policy Entropy: 2.20179
Value Function Loss: 0.01750

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.54176
Value Function Update Magnitude: 0.65547

Collected Steps per Second: 22,706.18084
Overall Steps per Second: 10,667.38519

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.48564
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.68812

Cumulative Model Updates: 245,748
Cumulative Timesteps: 2,049,544,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.47169
Policy Entropy: 2.16792
Value Function Loss: 0.01775

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.65917

Collected Steps per Second: 22,733.50149
Overall Steps per Second: 10,799.14446

Timestep Collection Time: 2.19984
Timestep Consumption Time: 2.43109
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.63092

Cumulative Model Updates: 245,754
Cumulative Timesteps: 2,049,594,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2049594480...
Checkpoint 2049594480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.50437
Policy Entropy: 2.16310
Value Function Loss: 0.01839

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.68528

Collected Steps per Second: 22,773.49012
Overall Steps per Second: 10,878.78530

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.40085
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.59665

Cumulative Model Updates: 245,760
Cumulative Timesteps: 2,049,644,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.58687
Policy Entropy: 2.17103
Value Function Loss: 0.01900

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.69446

Collected Steps per Second: 21,902.37564
Overall Steps per Second: 10,474.19804

Timestep Collection Time: 2.28295
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.77383

Cumulative Model Updates: 245,766
Cumulative Timesteps: 2,049,694,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2049694488...
Checkpoint 2049694488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.52966
Policy Entropy: 2.21907
Value Function Loss: 0.01860

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.69349

Collected Steps per Second: 22,847.64128
Overall Steps per Second: 10,834.27702

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61646

Cumulative Model Updates: 245,772
Cumulative Timesteps: 2,049,744,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.35708
Policy Entropy: 2.20061
Value Function Loss: 0.01898

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.67231

Collected Steps per Second: 23,119.52405
Overall Steps per Second: 10,942.78795

Timestep Collection Time: 2.16293
Timestep Consumption Time: 2.40683
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.56977

Cumulative Model Updates: 245,778
Cumulative Timesteps: 2,049,794,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2049794510...
Checkpoint 2049794510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.45530
Policy Entropy: 2.20802
Value Function Loss: 0.01850

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.65487

Collected Steps per Second: 22,650.97450
Overall Steps per Second: 10,836.89225

Timestep Collection Time: 2.20856
Timestep Consumption Time: 2.40771
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.61627

Cumulative Model Updates: 245,784
Cumulative Timesteps: 2,049,844,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.10661
Policy Entropy: 2.18380
Value Function Loss: 0.01869

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.65731

Collected Steps per Second: 23,103.48071
Overall Steps per Second: 10,801.36942

Timestep Collection Time: 2.16435
Timestep Consumption Time: 2.46506
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.62941

Cumulative Model Updates: 245,790
Cumulative Timesteps: 2,049,894,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2049894540...
Checkpoint 2049894540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.97019
Policy Entropy: 2.20765
Value Function Loss: 0.01669

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.65882

Collected Steps per Second: 22,467.59252
Overall Steps per Second: 10,616.31974

Timestep Collection Time: 2.22658
Timestep Consumption Time: 2.48559
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.71218

Cumulative Model Updates: 245,796
Cumulative Timesteps: 2,049,944,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.81108
Policy Entropy: 2.22228
Value Function Loss: 0.01742

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.64771

Collected Steps per Second: 23,013.86477
Overall Steps per Second: 10,941.13491

Timestep Collection Time: 2.17339
Timestep Consumption Time: 2.39817
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.57156

Cumulative Model Updates: 245,802
Cumulative Timesteps: 2,049,994,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2049994584...
Checkpoint 2049994584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.15912
Policy Entropy: 2.24558
Value Function Loss: 0.01684

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.53000
Value Function Update Magnitude: 0.63886

Collected Steps per Second: 22,877.95005
Overall Steps per Second: 10,662.40097

Timestep Collection Time: 2.18595
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.69031

Cumulative Model Updates: 245,808
Cumulative Timesteps: 2,050,044,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.30331
Policy Entropy: 2.25437
Value Function Loss: 0.01701

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.53015
Value Function Update Magnitude: 0.62171

Collected Steps per Second: 23,737.30601
Overall Steps per Second: 10,831.04132

Timestep Collection Time: 2.10732
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.61839

Cumulative Model Updates: 245,814
Cumulative Timesteps: 2,050,094,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2050094616...
Checkpoint 2050094616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.28563
Policy Entropy: 2.24259
Value Function Loss: 0.01627

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.52774
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 22,662.44223
Overall Steps per Second: 10,634.72458

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.70214

Cumulative Model Updates: 245,820
Cumulative Timesteps: 2,050,144,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.01972
Policy Entropy: 2.22018
Value Function Loss: 0.01620

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.53366
Value Function Update Magnitude: 0.60552

Collected Steps per Second: 23,059.30714
Overall Steps per Second: 10,849.87420

Timestep Collection Time: 2.16919
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61019

Cumulative Model Updates: 245,826
Cumulative Timesteps: 2,050,194,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2050194642...
Checkpoint 2050194642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.16242
Policy Entropy: 2.21335
Value Function Loss: 0.01597

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.60286

Collected Steps per Second: 23,172.68124
Overall Steps per Second: 11,053.36670

Timestep Collection Time: 2.15780
Timestep Consumption Time: 2.36589
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.52369

Cumulative Model Updates: 245,832
Cumulative Timesteps: 2,050,244,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.05928
Policy Entropy: 2.21435
Value Function Loss: 0.01660

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.52955
Value Function Update Magnitude: 0.58028

Collected Steps per Second: 23,187.94557
Overall Steps per Second: 10,927.37854

Timestep Collection Time: 2.15647
Timestep Consumption Time: 2.41956
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.57603

Cumulative Model Updates: 245,838
Cumulative Timesteps: 2,050,294,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2050294648...
Checkpoint 2050294648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.52638
Policy Entropy: 2.23521
Value Function Loss: 0.01801

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.57664

Collected Steps per Second: 22,405.57403
Overall Steps per Second: 10,709.81934

Timestep Collection Time: 2.23293
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.67141

Cumulative Model Updates: 245,844
Cumulative Timesteps: 2,050,344,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.30461
Policy Entropy: 2.21366
Value Function Loss: 0.01875

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.52814
Value Function Update Magnitude: 0.60163

Collected Steps per Second: 22,682.09721
Overall Steps per Second: 10,843.18328

Timestep Collection Time: 2.20438
Timestep Consumption Time: 2.40681
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61119

Cumulative Model Updates: 245,850
Cumulative Timesteps: 2,050,394,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2050394678...
Checkpoint 2050394678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.04125
Policy Entropy: 2.20435
Value Function Loss: 0.01950

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.62865

Collected Steps per Second: 22,348.08655
Overall Steps per Second: 10,716.64432

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.42987
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.66863

Cumulative Model Updates: 245,856
Cumulative Timesteps: 2,050,444,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.04820
Policy Entropy: 2.22085
Value Function Loss: 0.01771

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.54393
Value Function Update Magnitude: 0.63064

Collected Steps per Second: 23,674.92622
Overall Steps per Second: 10,957.03331

Timestep Collection Time: 2.11194
Timestep Consumption Time: 2.45134
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.56328

Cumulative Model Updates: 245,862
Cumulative Timesteps: 2,050,494,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2050494710...
Checkpoint 2050494710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.19894
Policy Entropy: 2.22855
Value Function Loss: 0.01884

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.61409

Collected Steps per Second: 23,169.42566
Overall Steps per Second: 10,692.63595

Timestep Collection Time: 2.15853
Timestep Consumption Time: 2.51870
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.67724

Cumulative Model Updates: 245,868
Cumulative Timesteps: 2,050,544,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.16073
Policy Entropy: 2.24221
Value Function Loss: 0.01813

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.60506

Collected Steps per Second: 23,406.58820
Overall Steps per Second: 10,809.09851

Timestep Collection Time: 2.13743
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.62851

Cumulative Model Updates: 245,874
Cumulative Timesteps: 2,050,594,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2050594752...
Checkpoint 2050594752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.91281
Policy Entropy: 2.22873
Value Function Loss: 0.01904

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.61604

Collected Steps per Second: 23,040.45450
Overall Steps per Second: 11,063.39195

Timestep Collection Time: 2.17053
Timestep Consumption Time: 2.34978
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.52031

Cumulative Model Updates: 245,880
Cumulative Timesteps: 2,050,644,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.83829
Policy Entropy: 2.23875
Value Function Loss: 0.01777

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.60886

Collected Steps per Second: 23,342.69285
Overall Steps per Second: 10,941.37557

Timestep Collection Time: 2.14217
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.57017

Cumulative Model Updates: 245,886
Cumulative Timesteps: 2,050,694,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2050694766...
Checkpoint 2050694766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.13841
Policy Entropy: 2.24224
Value Function Loss: 0.01785

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.61214

Collected Steps per Second: 22,509.62469
Overall Steps per Second: 10,678.64932

Timestep Collection Time: 2.22207
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.68393

Cumulative Model Updates: 245,892
Cumulative Timesteps: 2,050,744,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.02523
Policy Entropy: 2.24217
Value Function Loss: 0.01633

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.53504
Value Function Update Magnitude: 0.62432

Collected Steps per Second: 23,125.73175
Overall Steps per Second: 10,871.64639

Timestep Collection Time: 2.16287
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.60078

Cumulative Model Updates: 245,898
Cumulative Timesteps: 2,050,794,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2050794802...
Checkpoint 2050794802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.28914
Policy Entropy: 2.25357
Value Function Loss: 0.01618

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.52029
Value Function Update Magnitude: 0.62524

Collected Steps per Second: 22,534.98786
Overall Steps per Second: 10,839.23952

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.39448
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.61361

Cumulative Model Updates: 245,904
Cumulative Timesteps: 2,050,844,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.61925
Policy Entropy: 2.23717
Value Function Loss: 0.01631

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.51305
Value Function Update Magnitude: 0.61568

Collected Steps per Second: 23,209.67986
Overall Steps per Second: 10,734.60643

Timestep Collection Time: 2.15479
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.65895

Cumulative Model Updates: 245,910
Cumulative Timesteps: 2,050,894,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2050894822...
Checkpoint 2050894822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.54822
Policy Entropy: 2.25645
Value Function Loss: 0.01615

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.59794

Collected Steps per Second: 22,553.98034
Overall Steps per Second: 10,633.75080

Timestep Collection Time: 2.21761
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.70351

Cumulative Model Updates: 245,916
Cumulative Timesteps: 2,050,944,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.99339
Policy Entropy: 2.25930
Value Function Loss: 0.01608

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.52245
Value Function Update Magnitude: 0.58358

Collected Steps per Second: 22,943.85236
Overall Steps per Second: 10,893.67762

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.59276

Cumulative Model Updates: 245,922
Cumulative Timesteps: 2,050,994,870

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2050994870...
Checkpoint 2050994870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.69325
Policy Entropy: 2.27804
Value Function Loss: 0.01635

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.52665
Value Function Update Magnitude: 0.56502

Collected Steps per Second: 22,539.93832
Overall Steps per Second: 10,697.55433

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.45666
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.67584

Cumulative Model Updates: 245,928
Cumulative Timesteps: 2,051,044,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.75370
Policy Entropy: 2.25357
Value Function Loss: 0.01757

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.52529
Value Function Update Magnitude: 0.57681

Collected Steps per Second: 23,432.91393
Overall Steps per Second: 10,860.20068

Timestep Collection Time: 2.13435
Timestep Consumption Time: 2.47091
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.60526

Cumulative Model Updates: 245,934
Cumulative Timesteps: 2,051,094,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2051094904...
Checkpoint 2051094904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.65527
Policy Entropy: 2.24652
Value Function Loss: 0.01836

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.60202

Collected Steps per Second: 22,834.47249
Overall Steps per Second: 10,659.31254

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69186

Cumulative Model Updates: 245,940
Cumulative Timesteps: 2,051,144,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.12263
Policy Entropy: 2.22530
Value Function Loss: 0.01756

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.53672
Value Function Update Magnitude: 0.60714

Collected Steps per Second: 23,120.97142
Overall Steps per Second: 10,898.32481

Timestep Collection Time: 2.16280
Timestep Consumption Time: 2.42561
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.58841

Cumulative Model Updates: 245,946
Cumulative Timesteps: 2,051,194,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2051194922...
Checkpoint 2051194922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.17417
Policy Entropy: 2.23256
Value Function Loss: 0.01784

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.52686
Value Function Update Magnitude: 0.61667

Collected Steps per Second: 22,646.35950
Overall Steps per Second: 10,840.36285

Timestep Collection Time: 2.20857
Timestep Consumption Time: 2.40530
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.61387

Cumulative Model Updates: 245,952
Cumulative Timesteps: 2,051,244,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.80885
Policy Entropy: 2.22807
Value Function Loss: 0.01771

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.64129

Collected Steps per Second: 23,489.13820
Overall Steps per Second: 10,841.24954

Timestep Collection Time: 2.12949
Timestep Consumption Time: 2.48436
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.61386

Cumulative Model Updates: 245,958
Cumulative Timesteps: 2,051,294,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2051294958...
Checkpoint 2051294958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.67474
Policy Entropy: 2.24246
Value Function Loss: 0.01799

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.64300

Collected Steps per Second: 22,666.27929
Overall Steps per Second: 10,659.28810

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.69150

Cumulative Model Updates: 245,964
Cumulative Timesteps: 2,051,344,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.26855
Policy Entropy: 2.24383
Value Function Loss: 0.01793

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.54742
Value Function Update Magnitude: 0.63994

Collected Steps per Second: 22,879.80281
Overall Steps per Second: 10,757.67692

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.46310
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.64896

Cumulative Model Updates: 245,970
Cumulative Timesteps: 2,051,394,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2051394978...
Checkpoint 2051394978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.28793
Policy Entropy: 2.24264
Value Function Loss: 0.01779

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.54872
Value Function Update Magnitude: 0.62958

Collected Steps per Second: 22,492.08124
Overall Steps per Second: 10,817.98099

Timestep Collection Time: 2.22434
Timestep Consumption Time: 2.40037
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.62471

Cumulative Model Updates: 245,976
Cumulative Timesteps: 2,051,445,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.37019
Policy Entropy: 2.22716
Value Function Loss: 0.01846

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.55204
Value Function Update Magnitude: 0.64829

Collected Steps per Second: 23,363.62288
Overall Steps per Second: 10,756.35276

Timestep Collection Time: 2.14128
Timestep Consumption Time: 2.50974
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.65102

Cumulative Model Updates: 245,982
Cumulative Timesteps: 2,051,495,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2051495036...
Checkpoint 2051495036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.51372
Policy Entropy: 2.21218
Value Function Loss: 0.01827

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.66990

Collected Steps per Second: 22,824.86542
Overall Steps per Second: 10,682.16737

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.68369

Cumulative Model Updates: 245,988
Cumulative Timesteps: 2,051,545,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.59355
Policy Entropy: 2.20491
Value Function Loss: 0.01830

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.66667

Collected Steps per Second: 23,131.93570
Overall Steps per Second: 10,881.18259

Timestep Collection Time: 2.16212
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.59638

Cumulative Model Updates: 245,994
Cumulative Timesteps: 2,051,595,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2051595082...
Checkpoint 2051595082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.34859
Policy Entropy: 2.21799
Value Function Loss: 0.01796

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.65900

Collected Steps per Second: 22,348.19572
Overall Steps per Second: 10,743.89476

Timestep Collection Time: 2.23830
Timestep Consumption Time: 2.41755
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.65585

Cumulative Model Updates: 246,000
Cumulative Timesteps: 2,051,645,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.81740
Policy Entropy: 2.21539
Value Function Loss: 0.01788

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.54479
Value Function Update Magnitude: 0.64862

Collected Steps per Second: 22,162.05589
Overall Steps per Second: 10,586.01534

Timestep Collection Time: 2.25737
Timestep Consumption Time: 2.46849
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.72586

Cumulative Model Updates: 246,006
Cumulative Timesteps: 2,051,695,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2051695132...
Checkpoint 2051695132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.24387
Policy Entropy: 2.22524
Value Function Loss: 0.01672

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.53704
Value Function Update Magnitude: 0.63377

Collected Steps per Second: 22,931.76674
Overall Steps per Second: 10,945.15407

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.38909
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.57061

Cumulative Model Updates: 246,012
Cumulative Timesteps: 2,051,745,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.05755
Policy Entropy: 2.20862
Value Function Loss: 0.01697

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.52999
Value Function Update Magnitude: 0.60916

Collected Steps per Second: 23,211.12174
Overall Steps per Second: 10,878.20597

Timestep Collection Time: 2.15552
Timestep Consumption Time: 2.44377
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.59929

Cumulative Model Updates: 246,018
Cumulative Timesteps: 2,051,795,190

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2051795190...
Checkpoint 2051795190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.86968
Policy Entropy: 2.22030
Value Function Loss: 0.01708

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.52968
Value Function Update Magnitude: 0.59634

Collected Steps per Second: 22,882.28082
Overall Steps per Second: 10,668.95795

Timestep Collection Time: 2.18597
Timestep Consumption Time: 2.50240
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.68837

Cumulative Model Updates: 246,024
Cumulative Timesteps: 2,051,845,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.69853
Policy Entropy: 2.23323
Value Function Loss: 0.01687

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.52743
Value Function Update Magnitude: 0.59260

Collected Steps per Second: 23,154.39576
Overall Steps per Second: 10,902.28338

Timestep Collection Time: 2.16045
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.58840

Cumulative Model Updates: 246,030
Cumulative Timesteps: 2,051,895,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2051895234...
Checkpoint 2051895234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.55234
Policy Entropy: 2.23437
Value Function Loss: 0.01694

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.52399
Value Function Update Magnitude: 0.59486

Collected Steps per Second: 22,585.65655
Overall Steps per Second: 10,669.19108

Timestep Collection Time: 2.21379
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.68639

Cumulative Model Updates: 246,036
Cumulative Timesteps: 2,051,945,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.54214
Policy Entropy: 2.23617
Value Function Loss: 0.01640

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.59781

Collected Steps per Second: 23,022.51253
Overall Steps per Second: 10,851.40027

Timestep Collection Time: 2.17205
Timestep Consumption Time: 2.43621
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.60825

Cumulative Model Updates: 246,042
Cumulative Timesteps: 2,051,995,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2051995240...
Checkpoint 2051995240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.76055
Policy Entropy: 2.20925
Value Function Loss: 0.01661

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.53043
Value Function Update Magnitude: 0.60402

Collected Steps per Second: 22,781.83166
Overall Steps per Second: 10,656.25555

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69283

Cumulative Model Updates: 246,048
Cumulative Timesteps: 2,052,045,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.21030
Policy Entropy: 2.22278
Value Function Loss: 0.01671

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.52778
Value Function Update Magnitude: 0.59976

Collected Steps per Second: 22,755.41256
Overall Steps per Second: 10,791.32904

Timestep Collection Time: 2.19860
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.63613

Cumulative Model Updates: 246,054
Cumulative Timesteps: 2,052,095,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2052095278...
Checkpoint 2052095278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.12323
Policy Entropy: 2.20310
Value Function Loss: 0.01803

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.62208

Collected Steps per Second: 22,315.62246
Overall Steps per Second: 10,794.54458

Timestep Collection Time: 2.24094
Timestep Consumption Time: 2.39177
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.63271

Cumulative Model Updates: 246,060
Cumulative Timesteps: 2,052,145,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.48028
Policy Entropy: 2.21022
Value Function Loss: 0.01757

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.62092

Collected Steps per Second: 22,833.77844
Overall Steps per Second: 10,845.80428

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.42160
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.61247

Cumulative Model Updates: 246,066
Cumulative Timesteps: 2,052,195,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2052195312...
Checkpoint 2052195312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.63434
Policy Entropy: 2.18875
Value Function Loss: 0.01766

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.53562
Value Function Update Magnitude: 0.60776

Collected Steps per Second: 23,114.71661
Overall Steps per Second: 10,651.37164

Timestep Collection Time: 2.16425
Timestep Consumption Time: 2.53242
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.69667

Cumulative Model Updates: 246,072
Cumulative Timesteps: 2,052,245,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.30184
Policy Entropy: 2.22270
Value Function Loss: 0.01677

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.52682
Value Function Update Magnitude: 0.60156

Collected Steps per Second: 23,267.63513
Overall Steps per Second: 10,909.55955

Timestep Collection Time: 2.14908
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.58350

Cumulative Model Updates: 246,078
Cumulative Timesteps: 2,052,295,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2052295342...
Checkpoint 2052295342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.22980
Policy Entropy: 2.21281
Value Function Loss: 0.01678

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.53501
Value Function Update Magnitude: 0.60053

Collected Steps per Second: 22,850.90776
Overall Steps per Second: 10,747.91543

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.65300

Cumulative Model Updates: 246,084
Cumulative Timesteps: 2,052,345,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.16369
Policy Entropy: 2.20508
Value Function Loss: 0.01700

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.61585

Collected Steps per Second: 23,346.22614
Overall Steps per Second: 11,014.35294

Timestep Collection Time: 2.14262
Timestep Consumption Time: 2.39891
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.54153

Cumulative Model Updates: 246,090
Cumulative Timesteps: 2,052,395,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2052395374...
Checkpoint 2052395374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.32109
Policy Entropy: 2.20235
Value Function Loss: 0.01735

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.52805
Value Function Update Magnitude: 0.60761

Collected Steps per Second: 22,839.23884
Overall Steps per Second: 10,739.30842

Timestep Collection Time: 2.19009
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.65766

Cumulative Model Updates: 246,096
Cumulative Timesteps: 2,052,445,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.53101
Policy Entropy: 2.23109
Value Function Loss: 0.01771

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.52334
Value Function Update Magnitude: 0.58782

Collected Steps per Second: 23,013.67962
Overall Steps per Second: 10,737.77075

Timestep Collection Time: 2.17366
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.65870

Cumulative Model Updates: 246,102
Cumulative Timesteps: 2,052,495,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2052495418...
Checkpoint 2052495418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.64116
Policy Entropy: 2.24938
Value Function Loss: 0.01737

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.51818
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 22,510.41041
Overall Steps per Second: 10,700.89744

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.45170
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.67325

Cumulative Model Updates: 246,108
Cumulative Timesteps: 2,052,545,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.25327
Policy Entropy: 2.22773
Value Function Loss: 0.01705

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.52204
Value Function Update Magnitude: 0.56353

Collected Steps per Second: 22,828.64911
Overall Steps per Second: 10,866.88953

Timestep Collection Time: 2.19076
Timestep Consumption Time: 2.41148
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.60224

Cumulative Model Updates: 246,114
Cumulative Timesteps: 2,052,595,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2052595438...
Checkpoint 2052595438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.15698
Policy Entropy: 2.20092
Value Function Loss: 0.01725

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.52473
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 22,598.97420
Overall Steps per Second: 10,676.43731

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.68527

Cumulative Model Updates: 246,120
Cumulative Timesteps: 2,052,645,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.93577
Policy Entropy: 2.16596
Value Function Loss: 0.01821

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.54292
Value Function Update Magnitude: 0.59547

Collected Steps per Second: 23,277.22197
Overall Steps per Second: 10,745.23802

Timestep Collection Time: 2.14905
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.65546

Cumulative Model Updates: 246,126
Cumulative Timesteps: 2,052,695,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2052695484...
Checkpoint 2052695484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.88727
Policy Entropy: 2.17190
Value Function Loss: 0.01866

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.61660

Collected Steps per Second: 22,901.37486
Overall Steps per Second: 10,749.08719

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.46976
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.65435

Cumulative Model Updates: 246,132
Cumulative Timesteps: 2,052,745,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.86063
Policy Entropy: 2.18256
Value Function Loss: 0.01799

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.61782

Collected Steps per Second: 23,354.97597
Overall Steps per Second: 10,798.05569

Timestep Collection Time: 2.14113
Timestep Consumption Time: 2.48989
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.63102

Cumulative Model Updates: 246,138
Cumulative Timesteps: 2,052,795,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2052795520...
Checkpoint 2052795520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.66330
Policy Entropy: 2.21278
Value Function Loss: 0.01736

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.52841
Value Function Update Magnitude: 0.62023

Collected Steps per Second: 23,099.48107
Overall Steps per Second: 10,754.93099

Timestep Collection Time: 2.16498
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.64996

Cumulative Model Updates: 246,144
Cumulative Timesteps: 2,052,845,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.79575
Policy Entropy: 2.21218
Value Function Loss: 0.01740

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.62669

Collected Steps per Second: 23,181.99115
Overall Steps per Second: 10,800.95949

Timestep Collection Time: 2.15702
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.62959

Cumulative Model Updates: 246,150
Cumulative Timesteps: 2,052,895,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2052895534...
Checkpoint 2052895534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.53891
Policy Entropy: 2.20869
Value Function Loss: 0.01751

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.52927
Value Function Update Magnitude: 0.61300

Collected Steps per Second: 22,834.30164
Overall Steps per Second: 11,018.28641

Timestep Collection Time: 2.19013
Timestep Consumption Time: 2.34869
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.53882

Cumulative Model Updates: 246,156
Cumulative Timesteps: 2,052,945,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.77017
Policy Entropy: 2.19507
Value Function Loss: 0.01950

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.53089
Value Function Update Magnitude: 0.60580

Collected Steps per Second: 23,137.59260
Overall Steps per Second: 10,901.19454

Timestep Collection Time: 2.16228
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58941

Cumulative Model Updates: 246,162
Cumulative Timesteps: 2,052,995,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2052995574...
Checkpoint 2052995574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.10758
Policy Entropy: 2.20265
Value Function Loss: 0.01904

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.53582
Value Function Update Magnitude: 0.60849

Collected Steps per Second: 22,377.86263
Overall Steps per Second: 10,753.83239

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.65174

Cumulative Model Updates: 246,168
Cumulative Timesteps: 2,053,045,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.24349
Policy Entropy: 2.18843
Value Function Loss: 0.01887

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 22,282.26637
Overall Steps per Second: 10,673.87564

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.68527

Cumulative Model Updates: 246,174
Cumulative Timesteps: 2,053,095,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2053095608...
Checkpoint 2053095608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.66749
Policy Entropy: 2.20366
Value Function Loss: 0.01739

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.52869
Value Function Update Magnitude: 0.60656

Collected Steps per Second: 22,648.62202
Overall Steps per Second: 10,873.69602

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.39186
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.60064

Cumulative Model Updates: 246,180
Cumulative Timesteps: 2,053,145,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.23392
Policy Entropy: 2.17624
Value Function Loss: 0.01663

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.52668
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 23,069.14741
Overall Steps per Second: 10,831.97210

Timestep Collection Time: 2.16870
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61873

Cumulative Model Updates: 246,186
Cumulative Timesteps: 2,053,195,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2053195664...
Checkpoint 2053195664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.37118
Policy Entropy: 2.17992
Value Function Loss: 0.01777

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.62108

Collected Steps per Second: 22,815.47130
Overall Steps per Second: 10,683.29659

Timestep Collection Time: 2.19255
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68245

Cumulative Model Updates: 246,192
Cumulative Timesteps: 2,053,245,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.38365
Policy Entropy: 2.17758
Value Function Loss: 0.01786

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.63158

Collected Steps per Second: 23,197.27162
Overall Steps per Second: 10,953.33359

Timestep Collection Time: 2.15594
Timestep Consumption Time: 2.40997
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.56592

Cumulative Model Updates: 246,198
Cumulative Timesteps: 2,053,295,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2053295700...
Checkpoint 2053295700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.60061
Policy Entropy: 2.19399
Value Function Loss: 0.01750

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.62586

Collected Steps per Second: 22,818.80689
Overall Steps per Second: 10,688.36498

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.68023

Cumulative Model Updates: 246,204
Cumulative Timesteps: 2,053,345,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.43134
Policy Entropy: 2.20575
Value Function Loss: 0.01578

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.51502
Value Function Update Magnitude: 0.61238

Collected Steps per Second: 23,288.53719
Overall Steps per Second: 10,827.95331

Timestep Collection Time: 2.14775
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.61934

Cumulative Model Updates: 246,210
Cumulative Timesteps: 2,053,395,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2053395742...
Checkpoint 2053395742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.31221
Policy Entropy: 2.22865
Value Function Loss: 0.01649

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.51758
Value Function Update Magnitude: 0.59192

Collected Steps per Second: 22,953.18606
Overall Steps per Second: 10,771.47144

Timestep Collection Time: 2.17957
Timestep Consumption Time: 2.46492
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.64449

Cumulative Model Updates: 246,216
Cumulative Timesteps: 2,053,445,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.42685
Policy Entropy: 2.21052
Value Function Loss: 0.01788

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.53089
Value Function Update Magnitude: 0.58728

Collected Steps per Second: 22,971.78007
Overall Steps per Second: 10,813.94917

Timestep Collection Time: 2.17684
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.62421

Cumulative Model Updates: 246,222
Cumulative Timesteps: 2,053,495,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2053495776...
Checkpoint 2053495776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.12127
Policy Entropy: 2.23616
Value Function Loss: 0.01782

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.53659
Value Function Update Magnitude: 0.59951

Collected Steps per Second: 21,988.23433
Overall Steps per Second: 10,539.70280

Timestep Collection Time: 2.27413
Timestep Consumption Time: 2.47022
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.74435

Cumulative Model Updates: 246,228
Cumulative Timesteps: 2,053,545,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.83544
Policy Entropy: 2.23497
Value Function Loss: 0.01714

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.52349
Value Function Update Magnitude: 0.60549

Collected Steps per Second: 22,658.33137
Overall Steps per Second: 10,600.34501

Timestep Collection Time: 2.20705
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.71758

Cumulative Model Updates: 246,234
Cumulative Timesteps: 2,053,595,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2053595788...
Checkpoint 2053595788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.39417
Policy Entropy: 2.26109
Value Function Loss: 0.01645

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.52078
Value Function Update Magnitude: 0.62249

Collected Steps per Second: 22,539.22402
Overall Steps per Second: 10,669.61688

Timestep Collection Time: 2.21969
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.68902

Cumulative Model Updates: 246,240
Cumulative Timesteps: 2,053,645,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.98904
Policy Entropy: 2.25021
Value Function Loss: 0.01744

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.53035
Value Function Update Magnitude: 0.63996

Collected Steps per Second: 22,887.87481
Overall Steps per Second: 10,842.82192

Timestep Collection Time: 2.18509
Timestep Consumption Time: 2.42737
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.61245

Cumulative Model Updates: 246,246
Cumulative Timesteps: 2,053,695,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2053695830...
Checkpoint 2053695830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.86119
Policy Entropy: 2.22733
Value Function Loss: 0.01746

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.53370
Value Function Update Magnitude: 0.65644

Collected Steps per Second: 22,712.69499
Overall Steps per Second: 10,622.42535

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.70759

Cumulative Model Updates: 246,252
Cumulative Timesteps: 2,053,745,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.48677
Policy Entropy: 2.17907
Value Function Loss: 0.01823

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.70023

Collected Steps per Second: 23,175.35755
Overall Steps per Second: 10,907.32437

Timestep Collection Time: 2.15850
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.58628

Cumulative Model Updates: 246,258
Cumulative Timesteps: 2,053,795,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2053795860...
Checkpoint 2053795860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.95081
Policy Entropy: 2.17707
Value Function Loss: 0.01780

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.72330

Collected Steps per Second: 22,919.96044
Overall Steps per Second: 10,775.50877

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.64219

Cumulative Model Updates: 246,264
Cumulative Timesteps: 2,053,845,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.92918
Policy Entropy: 2.18102
Value Function Loss: 0.01846

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.73123

Collected Steps per Second: 22,952.97751
Overall Steps per Second: 10,929.80590

Timestep Collection Time: 2.17933
Timestep Consumption Time: 2.39733
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.57666

Cumulative Model Updates: 246,270
Cumulative Timesteps: 2,053,895,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2053895904...
Checkpoint 2053895904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.82474
Policy Entropy: 2.20628
Value Function Loss: 0.01795

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.72024

Collected Steps per Second: 22,919.79949
Overall Steps per Second: 10,880.27466

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.41434
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59621

Cumulative Model Updates: 246,276
Cumulative Timesteps: 2,053,945,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.52903
Policy Entropy: 2.19930
Value Function Loss: 0.01791

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.54632
Value Function Update Magnitude: 0.69908

Collected Steps per Second: 23,084.46616
Overall Steps per Second: 10,875.63537

Timestep Collection Time: 2.16734
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60037

Cumulative Model Updates: 246,282
Cumulative Timesteps: 2,053,995,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2053995944...
Checkpoint 2053995944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.66034
Policy Entropy: 2.20587
Value Function Loss: 0.01765

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.67771

Collected Steps per Second: 22,573.07816
Overall Steps per Second: 10,748.62587

Timestep Collection Time: 2.21565
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.65306

Cumulative Model Updates: 246,288
Cumulative Timesteps: 2,054,045,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.10540
Policy Entropy: 2.24316
Value Function Loss: 0.01773

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.66408

Collected Steps per Second: 22,546.11288
Overall Steps per Second: 10,949.33008

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.34909
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.56704

Cumulative Model Updates: 246,294
Cumulative Timesteps: 2,054,095,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2054095964...
Checkpoint 2054095964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.82563
Policy Entropy: 2.24946
Value Function Loss: 0.01748

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.53097
Value Function Update Magnitude: 0.65366

Collected Steps per Second: 22,716.13328
Overall Steps per Second: 10,655.82163

Timestep Collection Time: 2.20143
Timestep Consumption Time: 2.49159
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.69302

Cumulative Model Updates: 246,300
Cumulative Timesteps: 2,054,145,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.15305
Policy Entropy: 2.25644
Value Function Loss: 0.01837

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.53745
Value Function Update Magnitude: 0.65591

Collected Steps per Second: 22,940.63548
Overall Steps per Second: 10,832.25729

Timestep Collection Time: 2.18085
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61861

Cumulative Model Updates: 246,306
Cumulative Timesteps: 2,054,196,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2054196002...
Checkpoint 2054196002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.52237
Policy Entropy: 2.23248
Value Function Loss: 0.01864

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.65669

Collected Steps per Second: 22,836.26461
Overall Steps per Second: 10,626.03483

Timestep Collection Time: 2.18968
Timestep Consumption Time: 2.51613
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.70580

Cumulative Model Updates: 246,312
Cumulative Timesteps: 2,054,246,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.77810
Policy Entropy: 2.23277
Value Function Loss: 0.01780

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.53157
Value Function Update Magnitude: 0.64901

Collected Steps per Second: 23,059.12713
Overall Steps per Second: 10,910.69131

Timestep Collection Time: 2.16912
Timestep Consumption Time: 2.41519
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.58431

Cumulative Model Updates: 246,318
Cumulative Timesteps: 2,054,296,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2054296024...
Checkpoint 2054296024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.11815
Policy Entropy: 2.21509
Value Function Loss: 0.01657

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.53577
Value Function Update Magnitude: 0.64447

Collected Steps per Second: 23,107.50107
Overall Steps per Second: 10,759.96461

Timestep Collection Time: 2.16458
Timestep Consumption Time: 2.48395
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.64853

Cumulative Model Updates: 246,324
Cumulative Timesteps: 2,054,346,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.53085
Policy Entropy: 2.21196
Value Function Loss: 0.01633

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.54027
Value Function Update Magnitude: 0.62832

Collected Steps per Second: 23,377.44924
Overall Steps per Second: 10,828.89007

Timestep Collection Time: 2.13958
Timestep Consumption Time: 2.47936
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.61894

Cumulative Model Updates: 246,330
Cumulative Timesteps: 2,054,396,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2054396060...
Checkpoint 2054396060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.71261
Policy Entropy: 2.19137
Value Function Loss: 0.01707

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.53107
Value Function Update Magnitude: 0.63064

Collected Steps per Second: 22,933.18194
Overall Steps per Second: 10,799.32986

Timestep Collection Time: 2.18068
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.63084

Cumulative Model Updates: 246,336
Cumulative Timesteps: 2,054,446,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.03965
Policy Entropy: 2.18855
Value Function Loss: 0.01894

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.54110
Value Function Update Magnitude: 0.61879

Collected Steps per Second: 22,784.51435
Overall Steps per Second: 10,838.07139

Timestep Collection Time: 2.19544
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.61540

Cumulative Model Updates: 246,342
Cumulative Timesteps: 2,054,496,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2054496092...
Checkpoint 2054496092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.92757
Policy Entropy: 2.21271
Value Function Loss: 0.01910

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.64753

Collected Steps per Second: 22,558.36259
Overall Steps per Second: 10,613.85026

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.71233

Cumulative Model Updates: 246,348
Cumulative Timesteps: 2,054,546,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.90121
Policy Entropy: 2.21125
Value Function Loss: 0.01905

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.65183

Collected Steps per Second: 22,653.95678
Overall Steps per Second: 10,851.54000

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.40148
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60948

Cumulative Model Updates: 246,354
Cumulative Timesteps: 2,054,596,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2054596128...
Checkpoint 2054596128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.59647
Policy Entropy: 2.26064
Value Function Loss: 0.01771

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.54217
Value Function Update Magnitude: 0.65026

Collected Steps per Second: 22,737.69979
Overall Steps per Second: 11,005.76390

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.34483
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.54453

Cumulative Model Updates: 246,360
Cumulative Timesteps: 2,054,646,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.50416
Policy Entropy: 2.22566
Value Function Loss: 0.01832

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.64600

Collected Steps per Second: 22,658.15662
Overall Steps per Second: 10,676.66223

Timestep Collection Time: 2.20768
Timestep Consumption Time: 2.47749
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.68517

Cumulative Model Updates: 246,366
Cumulative Timesteps: 2,054,696,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2054696166...
Checkpoint 2054696166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.79457
Policy Entropy: 2.24610
Value Function Loss: 0.01702

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.63088

Collected Steps per Second: 22,623.64227
Overall Steps per Second: 10,625.96458

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.70677

Cumulative Model Updates: 246,372
Cumulative Timesteps: 2,054,746,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.91643
Policy Entropy: 2.20809
Value Function Loss: 0.01598

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.51863
Value Function Update Magnitude: 0.60981

Collected Steps per Second: 23,460.04858
Overall Steps per Second: 10,787.27855

Timestep Collection Time: 2.13231
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.63731

Cumulative Model Updates: 246,378
Cumulative Timesteps: 2,054,796,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2054796204...
Checkpoint 2054796204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.40003
Policy Entropy: 2.22886
Value Function Loss: 0.01493

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.50615
Value Function Update Magnitude: 0.59041

Collected Steps per Second: 23,025.56388
Overall Steps per Second: 11,058.93688

Timestep Collection Time: 2.17211
Timestep Consumption Time: 2.35039
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.52250

Cumulative Model Updates: 246,384
Cumulative Timesteps: 2,054,846,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.88471
Policy Entropy: 2.22091
Value Function Loss: 0.01507

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.51349
Value Function Update Magnitude: 0.58223

Collected Steps per Second: 23,345.98674
Overall Steps per Second: 10,923.71196

Timestep Collection Time: 2.14230
Timestep Consumption Time: 2.43618
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.57848

Cumulative Model Updates: 246,390
Cumulative Timesteps: 2,054,896,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2054896232...
Checkpoint 2054896232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.99393
Policy Entropy: 2.24299
Value Function Loss: 0.01591

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.51271
Value Function Update Magnitude: 0.58132

Collected Steps per Second: 23,073.12823
Overall Steps per Second: 10,716.01575

Timestep Collection Time: 2.16711
Timestep Consumption Time: 2.49899
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.66610

Cumulative Model Updates: 246,396
Cumulative Timesteps: 2,054,946,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.20866
Policy Entropy: 2.23292
Value Function Loss: 0.01744

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 23,227.53967
Overall Steps per Second: 10,865.61738

Timestep Collection Time: 2.15374
Timestep Consumption Time: 2.45033
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.60406

Cumulative Model Updates: 246,402
Cumulative Timesteps: 2,054,996,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2054996260...
Checkpoint 2054996260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.91973
Policy Entropy: 2.23218
Value Function Loss: 0.01714

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.60279

Collected Steps per Second: 22,773.56262
Overall Steps per Second: 11,034.68333

Timestep Collection Time: 2.19658
Timestep Consumption Time: 2.33676
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.53334

Cumulative Model Updates: 246,408
Cumulative Timesteps: 2,055,046,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.38897
Policy Entropy: 2.21158
Value Function Loss: 0.01758

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.52385
Value Function Update Magnitude: 0.60675

Collected Steps per Second: 22,717.53738
Overall Steps per Second: 10,686.23387

Timestep Collection Time: 2.20191
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.68098

Cumulative Model Updates: 246,414
Cumulative Timesteps: 2,055,096,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2055096306...
Checkpoint 2055096306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.10184
Policy Entropy: 2.20710
Value Function Loss: 0.01757

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.61219

Collected Steps per Second: 22,664.13258
Overall Steps per Second: 10,689.15494

Timestep Collection Time: 2.20692
Timestep Consumption Time: 2.47240
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67932

Cumulative Model Updates: 246,420
Cumulative Timesteps: 2,055,146,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.60859
Policy Entropy: 2.24839
Value Function Loss: 0.01703

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.60338

Collected Steps per Second: 22,693.22423
Overall Steps per Second: 10,703.08389

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.46874
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.67249

Cumulative Model Updates: 246,426
Cumulative Timesteps: 2,055,196,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2055196334...
Checkpoint 2055196334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.13874
Policy Entropy: 2.22663
Value Function Loss: 0.01669

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.52785
Value Function Update Magnitude: 0.61133

Collected Steps per Second: 22,459.21738
Overall Steps per Second: 10,788.26762

Timestep Collection Time: 2.22635
Timestep Consumption Time: 2.40850
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.63485

Cumulative Model Updates: 246,432
Cumulative Timesteps: 2,055,246,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.22923
Policy Entropy: 2.20972
Value Function Loss: 0.01604

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.61964

Collected Steps per Second: 23,441.63965
Overall Steps per Second: 10,751.37512

Timestep Collection Time: 2.13296
Timestep Consumption Time: 2.51761
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.65057

Cumulative Model Updates: 246,438
Cumulative Timesteps: 2,055,296,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2055296336...
Checkpoint 2055296336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.71768
Policy Entropy: 2.16504
Value Function Loss: 0.01577

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.54017
Value Function Update Magnitude: 0.62287

Collected Steps per Second: 22,700.69956
Overall Steps per Second: 10,639.44458

Timestep Collection Time: 2.20275
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.69987

Cumulative Model Updates: 246,444
Cumulative Timesteps: 2,055,346,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.69177
Policy Entropy: 2.19501
Value Function Loss: 0.01600

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.52525
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 23,010.94096
Overall Steps per Second: 10,892.72458

Timestep Collection Time: 2.17392
Timestep Consumption Time: 2.41850
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.59242

Cumulative Model Updates: 246,450
Cumulative Timesteps: 2,055,396,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2055396364...
Checkpoint 2055396364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.07817
Policy Entropy: 2.21236
Value Function Loss: 0.01603

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.52040
Value Function Update Magnitude: 0.60743

Collected Steps per Second: 22,981.60167
Overall Steps per Second: 11,047.18089

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.35180
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.52876

Cumulative Model Updates: 246,456
Cumulative Timesteps: 2,055,446,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.04450
Policy Entropy: 2.20938
Value Function Loss: 0.01772

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.53192
Value Function Update Magnitude: 0.59138

Collected Steps per Second: 22,034.29166
Overall Steps per Second: 10,537.24152

Timestep Collection Time: 2.26992
Timestep Consumption Time: 2.47668
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.74659

Cumulative Model Updates: 246,462
Cumulative Timesteps: 2,055,496,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2055496410...
Checkpoint 2055496410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.53072
Policy Entropy: 2.19506
Value Function Loss: 0.01737

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.58606

Collected Steps per Second: 23,001.76322
Overall Steps per Second: 10,686.98248

Timestep Collection Time: 2.17409
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.67934

Cumulative Model Updates: 246,468
Cumulative Timesteps: 2,055,546,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.79875
Policy Entropy: 2.16127
Value Function Loss: 0.01849

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.59447

Collected Steps per Second: 22,957.70092
Overall Steps per Second: 10,877.91068

Timestep Collection Time: 2.17879
Timestep Consumption Time: 2.41952
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.59831

Cumulative Model Updates: 246,474
Cumulative Timesteps: 2,055,596,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2055596438...
Checkpoint 2055596438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.61527
Policy Entropy: 2.17169
Value Function Loss: 0.01800

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.60884

Collected Steps per Second: 23,641.29679
Overall Steps per Second: 10,992.54668

Timestep Collection Time: 2.11511
Timestep Consumption Time: 2.43379
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.54890

Cumulative Model Updates: 246,480
Cumulative Timesteps: 2,055,646,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.21856
Policy Entropy: 2.17262
Value Function Loss: 0.01801

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.54998
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 22,484.40032
Overall Steps per Second: 10,581.12983

Timestep Collection Time: 2.22376
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.72539

Cumulative Model Updates: 246,486
Cumulative Timesteps: 2,055,696,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2055696442...
Checkpoint 2055696442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.72367
Policy Entropy: 2.18598
Value Function Loss: 0.01815

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.61419

Collected Steps per Second: 22,424.50622
Overall Steps per Second: 10,627.72464

Timestep Collection Time: 2.22970
Timestep Consumption Time: 2.47497
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.70468

Cumulative Model Updates: 246,492
Cumulative Timesteps: 2,055,746,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.00352
Policy Entropy: 2.17525
Value Function Loss: 0.01818

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.64019

Collected Steps per Second: 23,302.20100
Overall Steps per Second: 10,865.51669

Timestep Collection Time: 2.14675
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.60392

Cumulative Model Updates: 246,498
Cumulative Timesteps: 2,055,796,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2055796466...
Checkpoint 2055796466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.20496
Policy Entropy: 2.19639
Value Function Loss: 0.01861

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.52929
Value Function Update Magnitude: 0.64631

Collected Steps per Second: 22,942.15550
Overall Steps per Second: 10,682.13482

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.68127

Cumulative Model Updates: 246,504
Cumulative Timesteps: 2,055,846,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.05625
Policy Entropy: 2.21501
Value Function Loss: 0.01731

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.53335
Value Function Update Magnitude: 0.65215

Collected Steps per Second: 23,357.00827
Overall Steps per Second: 10,909.43989

Timestep Collection Time: 2.14094
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.58374

Cumulative Model Updates: 246,510
Cumulative Timesteps: 2,055,896,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2055896478...
Checkpoint 2055896478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.43647
Policy Entropy: 2.19266
Value Function Loss: 0.01758

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.63194

Collected Steps per Second: 22,948.08630
Overall Steps per Second: 11,057.65773

Timestep Collection Time: 2.17962
Timestep Consumption Time: 2.34377
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.52338

Cumulative Model Updates: 246,516
Cumulative Timesteps: 2,055,946,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.47803
Policy Entropy: 2.18816
Value Function Loss: 0.01827

Mean KL Divergence: 0.02789
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.53149
Value Function Update Magnitude: 0.64429

Collected Steps per Second: 22,963.84867
Overall Steps per Second: 10,824.56214

Timestep Collection Time: 2.17829
Timestep Consumption Time: 2.44286
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.62116

Cumulative Model Updates: 246,522
Cumulative Timesteps: 2,055,996,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2055996518...
Checkpoint 2055996518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.70226
Policy Entropy: 2.16747
Value Function Loss: 0.01868

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.55451
Value Function Update Magnitude: 0.65660

Collected Steps per Second: 22,677.97985
Overall Steps per Second: 10,681.05040

Timestep Collection Time: 2.20602
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.68381

Cumulative Model Updates: 246,528
Cumulative Timesteps: 2,056,046,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.20849
Policy Entropy: 2.20327
Value Function Loss: 0.01903

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.14602
Policy Update Magnitude: 0.55273
Value Function Update Magnitude: 0.64883

Collected Steps per Second: 22,684.56476
Overall Steps per Second: 10,698.36067

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.67642

Cumulative Model Updates: 246,534
Cumulative Timesteps: 2,056,096,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2056096576...
Checkpoint 2056096576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.56719
Policy Entropy: 2.19290
Value Function Loss: 0.01938

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.55395
Value Function Update Magnitude: 0.63568

Collected Steps per Second: 22,518.88082
Overall Steps per Second: 10,838.43786

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.39410
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.61561

Cumulative Model Updates: 246,540
Cumulative Timesteps: 2,056,146,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.81173
Policy Entropy: 2.21689
Value Function Loss: 0.01873

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.53513
Value Function Update Magnitude: 0.62052

Collected Steps per Second: 23,135.38340
Overall Steps per Second: 10,702.95103

Timestep Collection Time: 2.16162
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.67254

Cumulative Model Updates: 246,546
Cumulative Timesteps: 2,056,196,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2056196612...
Checkpoint 2056196612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.47713
Policy Entropy: 2.21735
Value Function Loss: 0.01829

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.52239
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 22,931.08120
Overall Steps per Second: 10,641.21579

Timestep Collection Time: 2.18149
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.70097

Cumulative Model Updates: 246,552
Cumulative Timesteps: 2,056,246,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.86470
Policy Entropy: 2.18756
Value Function Loss: 0.01713

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.53035
Value Function Update Magnitude: 0.61478

Collected Steps per Second: 23,153.26203
Overall Steps per Second: 10,891.71049

Timestep Collection Time: 2.15961
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.59083

Cumulative Model Updates: 246,558
Cumulative Timesteps: 2,056,296,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2056296638...
Checkpoint 2056296638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.16916
Policy Entropy: 2.18409
Value Function Loss: 0.01668

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.62387

Collected Steps per Second: 22,803.64940
Overall Steps per Second: 10,712.23991

Timestep Collection Time: 2.19263
Timestep Consumption Time: 2.47493
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.66756

Cumulative Model Updates: 246,564
Cumulative Timesteps: 2,056,346,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.42364
Policy Entropy: 2.14317
Value Function Loss: 0.01701

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.53024
Value Function Update Magnitude: 0.60666

Collected Steps per Second: 23,930.83136
Overall Steps per Second: 10,890.07725

Timestep Collection Time: 2.09036
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.59354

Cumulative Model Updates: 246,570
Cumulative Timesteps: 2,056,396,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2056396662...
Checkpoint 2056396662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.93054
Policy Entropy: 2.20554
Value Function Loss: 0.01685

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.53817
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 23,024.78540
Overall Steps per Second: 10,732.21180

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.48730
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.65887

Cumulative Model Updates: 246,576
Cumulative Timesteps: 2,056,446,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.02824
Policy Entropy: 2.23009
Value Function Loss: 0.01705

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.58132

Collected Steps per Second: 23,293.28649
Overall Steps per Second: 10,828.15377

Timestep Collection Time: 2.14774
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.62018

Cumulative Model Updates: 246,582
Cumulative Timesteps: 2,056,496,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2056496690...
Checkpoint 2056496690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.90984
Policy Entropy: 2.26921
Value Function Loss: 0.01578

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.52942
Value Function Update Magnitude: 0.58502

Collected Steps per Second: 22,608.56743
Overall Steps per Second: 10,849.22495

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.39784
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.61010

Cumulative Model Updates: 246,588
Cumulative Timesteps: 2,056,546,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.70001
Policy Entropy: 2.23167
Value Function Loss: 0.01712

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.52915
Value Function Update Magnitude: 0.57132

Collected Steps per Second: 23,114.66400
Overall Steps per Second: 10,733.85087

Timestep Collection Time: 2.16382
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.65965

Cumulative Model Updates: 246,594
Cumulative Timesteps: 2,056,596,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2056596722...
Checkpoint 2056596722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.98839
Policy Entropy: 2.20207
Value Function Loss: 0.01823

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.53797
Value Function Update Magnitude: 0.57656

Collected Steps per Second: 22,645.26406
Overall Steps per Second: 10,618.10956

Timestep Collection Time: 2.20850
Timestep Consumption Time: 2.50157
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.71007

Cumulative Model Updates: 246,600
Cumulative Timesteps: 2,056,646,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.03941
Policy Entropy: 2.17582
Value Function Loss: 0.01836

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.57421

Collected Steps per Second: 22,602.04431
Overall Steps per Second: 10,828.30822

Timestep Collection Time: 2.21343
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62011

Cumulative Model Updates: 246,606
Cumulative Timesteps: 2,056,696,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2056696762...
Checkpoint 2056696762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.35061
Policy Entropy: 2.19151
Value Function Loss: 0.01801

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.54873
Value Function Update Magnitude: 0.57554

Collected Steps per Second: 22,522.81668
Overall Steps per Second: 10,671.06375

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.46609
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.68651

Cumulative Model Updates: 246,612
Cumulative Timesteps: 2,056,746,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.83706
Policy Entropy: 2.19071
Value Function Loss: 0.01652

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.53596
Value Function Update Magnitude: 0.58492

Collected Steps per Second: 24,071.91231
Overall Steps per Second: 10,913.95395

Timestep Collection Time: 2.07761
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.58239

Cumulative Model Updates: 246,618
Cumulative Timesteps: 2,056,796,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2056796784...
Checkpoint 2056796784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.35211
Policy Entropy: 2.23521
Value Function Loss: 0.01598

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.53259
Value Function Update Magnitude: 0.58038

Collected Steps per Second: 22,684.62183
Overall Steps per Second: 10,622.41231

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.70741

Cumulative Model Updates: 246,624
Cumulative Timesteps: 2,056,846,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.55360
Policy Entropy: 2.21184
Value Function Loss: 0.01733

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.57490

Collected Steps per Second: 22,906.31706
Overall Steps per Second: 10,840.64452

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61412

Cumulative Model Updates: 246,630
Cumulative Timesteps: 2,056,896,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2056896808...
Checkpoint 2056896808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.34305
Policy Entropy: 2.19424
Value Function Loss: 0.01872

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.61054

Collected Steps per Second: 22,971.16381
Overall Steps per Second: 10,905.77040

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.40838
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.58528

Cumulative Model Updates: 246,636
Cumulative Timesteps: 2,056,946,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.38286
Policy Entropy: 2.17560
Value Function Loss: 0.01844

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.63671

Collected Steps per Second: 23,472.97208
Overall Steps per Second: 10,825.19845

Timestep Collection Time: 2.13079
Timestep Consumption Time: 2.48954
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.62033

Cumulative Model Updates: 246,642
Cumulative Timesteps: 2,056,996,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2056996830...
Checkpoint 2056996830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.85416
Policy Entropy: 2.15429
Value Function Loss: 0.01832

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.63902

Collected Steps per Second: 22,965.68799
Overall Steps per Second: 10,732.26192

Timestep Collection Time: 2.17838
Timestep Consumption Time: 2.48308
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.66146

Cumulative Model Updates: 246,648
Cumulative Timesteps: 2,057,046,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.96239
Policy Entropy: 2.20452
Value Function Loss: 0.01685

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.62431

Collected Steps per Second: 22,851.78507
Overall Steps per Second: 10,734.06592

Timestep Collection Time: 2.18854
Timestep Consumption Time: 2.47065
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.65919

Cumulative Model Updates: 246,654
Cumulative Timesteps: 2,057,096,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2057096870...
Checkpoint 2057096870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.84197
Policy Entropy: 2.19369
Value Function Loss: 0.01749

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.54186
Value Function Update Magnitude: 0.61126

Collected Steps per Second: 22,660.27310
Overall Steps per Second: 10,708.68140

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.66930

Cumulative Model Updates: 246,660
Cumulative Timesteps: 2,057,146,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.31066
Policy Entropy: 2.19231
Value Function Loss: 0.01786

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.60408

Collected Steps per Second: 23,773.83854
Overall Steps per Second: 10,875.69974

Timestep Collection Time: 2.10391
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.59906

Cumulative Model Updates: 246,666
Cumulative Timesteps: 2,057,196,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2057196890...
Checkpoint 2057196890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.19216
Policy Entropy: 2.14288
Value Function Loss: 0.01947

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.55692
Value Function Update Magnitude: 0.60410

Collected Steps per Second: 22,861.88549
Overall Steps per Second: 10,670.89645

Timestep Collection Time: 2.18757
Timestep Consumption Time: 2.49920
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.68677

Cumulative Model Updates: 246,672
Cumulative Timesteps: 2,057,246,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.61315
Policy Entropy: 2.12508
Value Function Loss: 0.01987

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.55929
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 23,220.51337
Overall Steps per Second: 10,849.31301

Timestep Collection Time: 2.15439
Timestep Consumption Time: 2.45659
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.61098

Cumulative Model Updates: 246,678
Cumulative Timesteps: 2,057,296,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2057296928...
Checkpoint 2057296928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.94603
Policy Entropy: 2.14101
Value Function Loss: 0.01874

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.63260

Collected Steps per Second: 23,083.57008
Overall Steps per Second: 11,038.30904

Timestep Collection Time: 2.16674
Timestep Consumption Time: 2.36439
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.53113

Cumulative Model Updates: 246,684
Cumulative Timesteps: 2,057,346,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.66597
Policy Entropy: 2.17241
Value Function Loss: 0.01786

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.54650
Value Function Update Magnitude: 0.63082

Collected Steps per Second: 22,997.29337
Overall Steps per Second: 10,874.32575

Timestep Collection Time: 2.17495
Timestep Consumption Time: 2.42469
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59964

Cumulative Model Updates: 246,690
Cumulative Timesteps: 2,057,396,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2057396962...
Checkpoint 2057396962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.15073
Policy Entropy: 2.18517
Value Function Loss: 0.01611

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.52241
Value Function Update Magnitude: 0.61289

Collected Steps per Second: 22,679.11536
Overall Steps per Second: 10,718.60994

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.46110
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.66665

Cumulative Model Updates: 246,696
Cumulative Timesteps: 2,057,446,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.49390
Policy Entropy: 2.19758
Value Function Loss: 0.01657

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.52836
Value Function Update Magnitude: 0.59965

Collected Steps per Second: 22,394.63632
Overall Steps per Second: 10,834.30402

Timestep Collection Time: 2.23303
Timestep Consumption Time: 2.38267
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61571

Cumulative Model Updates: 246,702
Cumulative Timesteps: 2,057,496,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2057496990...
Checkpoint 2057496990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.19864
Policy Entropy: 2.19932
Value Function Loss: 0.01566

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.52229
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 21,963.89181
Overall Steps per Second: 10,728.53727

Timestep Collection Time: 2.27710
Timestep Consumption Time: 2.38467
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.66177

Cumulative Model Updates: 246,708
Cumulative Timesteps: 2,057,547,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.64038
Policy Entropy: 2.19476
Value Function Loss: 0.01607

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.52023
Value Function Update Magnitude: 0.61368

Collected Steps per Second: 22,814.22561
Overall Steps per Second: 10,800.55461

Timestep Collection Time: 2.19197
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.63013

Cumulative Model Updates: 246,714
Cumulative Timesteps: 2,057,597,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2057597012...
Checkpoint 2057597012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.57694
Policy Entropy: 2.19200
Value Function Loss: 0.01638

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.52428
Value Function Update Magnitude: 0.60781

Collected Steps per Second: 22,481.96729
Overall Steps per Second: 10,754.52887

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.42559
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.64995

Cumulative Model Updates: 246,720
Cumulative Timesteps: 2,057,647,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.73530
Policy Entropy: 2.17873
Value Function Loss: 0.01747

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.53330
Value Function Update Magnitude: 0.61360

Collected Steps per Second: 22,680.15018
Overall Steps per Second: 10,637.41139

Timestep Collection Time: 2.20581
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.70302

Cumulative Model Updates: 246,726
Cumulative Timesteps: 2,057,697,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2057697048...
Checkpoint 2057697048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.95421
Policy Entropy: 2.17572
Value Function Loss: 0.01695

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.53048
Value Function Update Magnitude: 0.60450

Collected Steps per Second: 23,199.54761
Overall Steps per Second: 10,912.02768

Timestep Collection Time: 2.15582
Timestep Consumption Time: 2.42756
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.58338

Cumulative Model Updates: 246,732
Cumulative Timesteps: 2,057,747,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.18764
Policy Entropy: 2.17588
Value Function Loss: 0.01738

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.53139
Value Function Update Magnitude: 0.58752

Collected Steps per Second: 23,378.05018
Overall Steps per Second: 10,866.52981

Timestep Collection Time: 2.13919
Timestep Consumption Time: 2.46302
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.60221

Cumulative Model Updates: 246,738
Cumulative Timesteps: 2,057,797,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2057797072...
Checkpoint 2057797072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.93343
Policy Entropy: 2.18781
Value Function Loss: 0.01722

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.50597
Value Function Update Magnitude: 0.58368

Collected Steps per Second: 22,910.24523
Overall Steps per Second: 10,670.47207

Timestep Collection Time: 2.18295
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.68695

Cumulative Model Updates: 246,744
Cumulative Timesteps: 2,057,847,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.73489
Policy Entropy: 2.16863
Value Function Loss: 0.01807

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.50897
Value Function Update Magnitude: 0.59022

Collected Steps per Second: 23,208.07200
Overall Steps per Second: 10,912.66890

Timestep Collection Time: 2.15563
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.58440

Cumulative Model Updates: 246,750
Cumulative Timesteps: 2,057,897,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2057897112...
Checkpoint 2057897112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.11211
Policy Entropy: 2.19130
Value Function Loss: 0.01725

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.52380
Value Function Update Magnitude: 0.58629

Collected Steps per Second: 23,608.13070
Overall Steps per Second: 11,060.66893

Timestep Collection Time: 2.11893
Timestep Consumption Time: 2.40376
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.52269

Cumulative Model Updates: 246,756
Cumulative Timesteps: 2,057,947,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.00229
Policy Entropy: 2.16227
Value Function Loss: 0.01745

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.52744
Value Function Update Magnitude: 0.59237

Collected Steps per Second: 22,776.85251
Overall Steps per Second: 10,706.65508

Timestep Collection Time: 2.19600
Timestep Consumption Time: 2.47567
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.67167

Cumulative Model Updates: 246,762
Cumulative Timesteps: 2,057,997,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2057997154...
Checkpoint 2057997154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.80730
Policy Entropy: 2.19665
Value Function Loss: 0.01664

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.61269

Collected Steps per Second: 22,740.12765
Overall Steps per Second: 10,911.19660

Timestep Collection Time: 2.19972
Timestep Consumption Time: 2.38474
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.58447

Cumulative Model Updates: 246,768
Cumulative Timesteps: 2,058,047,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.05965
Policy Entropy: 2.19820
Value Function Loss: 0.01708

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.52408
Value Function Update Magnitude: 0.62201

Collected Steps per Second: 22,607.74282
Overall Steps per Second: 10,923.70256

Timestep Collection Time: 2.21181
Timestep Consumption Time: 2.36576
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.57757

Cumulative Model Updates: 246,774
Cumulative Timesteps: 2,058,097,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2058097180...
Checkpoint 2058097180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.23491
Policy Entropy: 2.20867
Value Function Loss: 0.01708

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.53511
Value Function Update Magnitude: 0.61216

Collected Steps per Second: 22,505.85623
Overall Steps per Second: 10,608.38971

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.71589

Cumulative Model Updates: 246,780
Cumulative Timesteps: 2,058,147,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.33055
Policy Entropy: 2.20233
Value Function Loss: 0.01655

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.52498
Value Function Update Magnitude: 0.60571

Collected Steps per Second: 23,483.41261
Overall Steps per Second: 10,897.60054

Timestep Collection Time: 2.13053
Timestep Consumption Time: 2.46058
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59110

Cumulative Model Updates: 246,786
Cumulative Timesteps: 2,058,197,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2058197240...
Checkpoint 2058197240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.35432
Policy Entropy: 2.18179
Value Function Loss: 0.01753

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.59847

Collected Steps per Second: 22,481.46107
Overall Steps per Second: 10,597.94320

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.71809

Cumulative Model Updates: 246,792
Cumulative Timesteps: 2,058,247,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.10847
Policy Entropy: 2.16761
Value Function Loss: 0.01844

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.61546

Collected Steps per Second: 23,106.78079
Overall Steps per Second: 10,986.19221

Timestep Collection Time: 2.16421
Timestep Consumption Time: 2.38768
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.55190

Cumulative Model Updates: 246,798
Cumulative Timesteps: 2,058,297,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2058297250...
Checkpoint 2058297250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.11536
Policy Entropy: 2.18435
Value Function Loss: 0.01930

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.65406

Collected Steps per Second: 23,011.88892
Overall Steps per Second: 10,748.31766

Timestep Collection Time: 2.17349
Timestep Consumption Time: 2.47989
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.65338

Cumulative Model Updates: 246,804
Cumulative Timesteps: 2,058,347,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.12483
Policy Entropy: 2.16215
Value Function Loss: 0.01949

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.68356

Collected Steps per Second: 23,255.54904
Overall Steps per Second: 10,772.03241

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.64332

Cumulative Model Updates: 246,810
Cumulative Timesteps: 2,058,397,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2058397284...
Checkpoint 2058397284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.89150
Policy Entropy: 2.19997
Value Function Loss: 0.01822

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.69364

Collected Steps per Second: 23,060.56843
Overall Steps per Second: 11,061.98287

Timestep Collection Time: 2.16890
Timestep Consumption Time: 2.35253
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.52143

Cumulative Model Updates: 246,816
Cumulative Timesteps: 2,058,447,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.09924
Policy Entropy: 2.18135
Value Function Loss: 0.01720

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.54344
Value Function Update Magnitude: 0.69125

Collected Steps per Second: 23,029.01899
Overall Steps per Second: 10,893.96169

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.41959
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.59172

Cumulative Model Updates: 246,822
Cumulative Timesteps: 2,058,497,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2058497322...
Checkpoint 2058497322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.72022
Policy Entropy: 2.17069
Value Function Loss: 0.01719

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.66740

Collected Steps per Second: 22,537.62984
Overall Steps per Second: 10,683.12540

Timestep Collection Time: 2.21851
Timestep Consumption Time: 2.46177
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.68028

Cumulative Model Updates: 246,828
Cumulative Timesteps: 2,058,547,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.61770
Policy Entropy: 2.15327
Value Function Loss: 0.01800

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.64435

Collected Steps per Second: 22,626.21480
Overall Steps per Second: 10,833.83617

Timestep Collection Time: 2.20983
Timestep Consumption Time: 2.40534
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61517

Cumulative Model Updates: 246,834
Cumulative Timesteps: 2,058,597,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2058597322...
Checkpoint 2058597322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.34326
Policy Entropy: 2.16514
Value Function Loss: 0.01955

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.62901

Collected Steps per Second: 22,665.43279
Overall Steps per Second: 10,818.04416

Timestep Collection Time: 2.20768
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.62542

Cumulative Model Updates: 246,840
Cumulative Timesteps: 2,058,647,360

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.88202
Policy Entropy: 2.16918
Value Function Loss: 0.01960

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.62989

Collected Steps per Second: 23,369.29384
Overall Steps per Second: 10,853.18637

Timestep Collection Time: 2.14067
Timestep Consumption Time: 2.46867
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.60934

Cumulative Model Updates: 246,846
Cumulative Timesteps: 2,058,697,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2058697386...
Checkpoint 2058697386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.55206
Policy Entropy: 2.18891
Value Function Loss: 0.01818

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.53841
Value Function Update Magnitude: 0.63516

Collected Steps per Second: 23,163.74883
Overall Steps per Second: 10,789.76101

Timestep Collection Time: 2.15906
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.63514

Cumulative Model Updates: 246,852
Cumulative Timesteps: 2,058,747,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.55266
Policy Entropy: 2.15572
Value Function Loss: 0.01819

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.62028

Collected Steps per Second: 22,954.39263
Overall Steps per Second: 10,718.68789

Timestep Collection Time: 2.17876
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.66587

Cumulative Model Updates: 246,858
Cumulative Timesteps: 2,058,797,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2058797410...
Checkpoint 2058797410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.85751
Policy Entropy: 2.16683
Value Function Loss: 0.01924

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.63030

Collected Steps per Second: 22,875.83837
Overall Steps per Second: 11,023.42682

Timestep Collection Time: 2.18650
Timestep Consumption Time: 2.35093
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.53743

Cumulative Model Updates: 246,864
Cumulative Timesteps: 2,058,847,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.91248
Policy Entropy: 2.13489
Value Function Loss: 0.01877

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.15377
Policy Update Magnitude: 0.53295
Value Function Update Magnitude: 0.64670

Collected Steps per Second: 22,891.11967
Overall Steps per Second: 10,724.97678

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.47855
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.66351

Cumulative Model Updates: 246,870
Cumulative Timesteps: 2,058,897,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2058897444...
Checkpoint 2058897444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.57774
Policy Entropy: 2.13268
Value Function Loss: 0.01806

Mean KL Divergence: 0.02818
SB3 Clip Fraction: 0.16782
Policy Update Magnitude: 0.50409
Value Function Update Magnitude: 0.62513

Collected Steps per Second: 23,003.31963
Overall Steps per Second: 10,886.70904

Timestep Collection Time: 2.17395
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.59349

Cumulative Model Updates: 246,876
Cumulative Timesteps: 2,058,947,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.51899
Policy Entropy: 2.14900
Value Function Loss: 0.01720

Mean KL Divergence: 0.02533
SB3 Clip Fraction: 0.15607
Policy Update Magnitude: 0.54339
Value Function Update Magnitude: 0.61373

Collected Steps per Second: 22,366.17860
Overall Steps per Second: 10,497.73592

Timestep Collection Time: 2.23668
Timestep Consumption Time: 2.52873
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76541

Cumulative Model Updates: 246,882
Cumulative Timesteps: 2,058,997,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2058997478...
Checkpoint 2058997478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.00519
Policy Entropy: 2.13843
Value Function Loss: 0.01788

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.55678
Value Function Update Magnitude: 0.61102

Collected Steps per Second: 22,318.15185
Overall Steps per Second: 10,607.91405

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.47333
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.71384

Cumulative Model Updates: 246,888
Cumulative Timesteps: 2,059,047,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.74508
Policy Entropy: 2.17116
Value Function Loss: 0.01748

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.60302

Collected Steps per Second: 23,609.38704
Overall Steps per Second: 10,877.82527

Timestep Collection Time: 2.11780
Timestep Consumption Time: 2.47871
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.59651

Cumulative Model Updates: 246,894
Cumulative Timesteps: 2,059,097,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2059097482...
Checkpoint 2059097482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.33927
Policy Entropy: 2.17173
Value Function Loss: 0.01814

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.53578
Value Function Update Magnitude: 0.60521

Collected Steps per Second: 22,607.52748
Overall Steps per Second: 10,700.01342

Timestep Collection Time: 2.21201
Timestep Consumption Time: 2.46163
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.67364

Cumulative Model Updates: 246,900
Cumulative Timesteps: 2,059,147,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.65514
Policy Entropy: 2.21019
Value Function Loss: 0.01618

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.59992

Collected Steps per Second: 22,550.79441
Overall Steps per Second: 10,530.09145

Timestep Collection Time: 2.21793
Timestep Consumption Time: 2.53189
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.74982

Cumulative Model Updates: 246,906
Cumulative Timesteps: 2,059,197,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2059197506...
Checkpoint 2059197506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.64601
Policy Entropy: 2.19599
Value Function Loss: 0.01808

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.51851
Value Function Update Magnitude: 0.61824

Collected Steps per Second: 23,071.95681
Overall Steps per Second: 10,913.56795

Timestep Collection Time: 2.16739
Timestep Consumption Time: 2.41461
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58200

Cumulative Model Updates: 246,912
Cumulative Timesteps: 2,059,247,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.51163
Policy Entropy: 2.20482
Value Function Loss: 0.01749

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.16055
Policy Update Magnitude: 0.50900
Value Function Update Magnitude: 0.63972

Collected Steps per Second: 23,571.44992
Overall Steps per Second: 10,963.21154

Timestep Collection Time: 2.12121
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.56071

Cumulative Model Updates: 246,918
Cumulative Timesteps: 2,059,297,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2059297512...
Checkpoint 2059297512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.26868
Policy Entropy: 2.20992
Value Function Loss: 0.01841

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.52370
Value Function Update Magnitude: 0.61734

Collected Steps per Second: 22,299.64523
Overall Steps per Second: 10,616.33646

Timestep Collection Time: 2.24317
Timestep Consumption Time: 2.46862
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.71179

Cumulative Model Updates: 246,924
Cumulative Timesteps: 2,059,347,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.31226
Policy Entropy: 2.20971
Value Function Loss: 0.01839

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.54461
Value Function Update Magnitude: 0.58862

Collected Steps per Second: 23,379.36664
Overall Steps per Second: 10,923.77289

Timestep Collection Time: 2.13898
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.57791

Cumulative Model Updates: 246,930
Cumulative Timesteps: 2,059,397,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2059397542...
Checkpoint 2059397542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.14558
Policy Entropy: 2.17328
Value Function Loss: 0.01853

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.54682
Value Function Update Magnitude: 0.58698

Collected Steps per Second: 22,691.67498
Overall Steps per Second: 10,750.34660

Timestep Collection Time: 2.20469
Timestep Consumption Time: 2.44893
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.65362

Cumulative Model Updates: 246,936
Cumulative Timesteps: 2,059,447,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.06388
Policy Entropy: 2.19176
Value Function Loss: 0.01769

Mean KL Divergence: 0.02758
SB3 Clip Fraction: 0.15729
Policy Update Magnitude: 0.52837
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 23,692.20838
Overall Steps per Second: 10,948.93691

Timestep Collection Time: 2.11116
Timestep Consumption Time: 2.45714
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.56830

Cumulative Model Updates: 246,942
Cumulative Timesteps: 2,059,497,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2059497588...
Checkpoint 2059497588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.66848
Policy Entropy: 2.20864
Value Function Loss: 0.01701

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.49701
Value Function Update Magnitude: 0.60262

Collected Steps per Second: 22,535.68699
Overall Steps per Second: 10,612.66373

Timestep Collection Time: 2.21932
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.71267

Cumulative Model Updates: 246,948
Cumulative Timesteps: 2,059,547,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.45801
Policy Entropy: 2.23109
Value Function Loss: 0.01658

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.52187
Value Function Update Magnitude: 0.60292

Collected Steps per Second: 22,585.68019
Overall Steps per Second: 10,840.05413

Timestep Collection Time: 2.21468
Timestep Consumption Time: 2.39969
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61437

Cumulative Model Updates: 246,954
Cumulative Timesteps: 2,059,597,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2059597622...
Checkpoint 2059597622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.68861
Policy Entropy: 2.17254
Value Function Loss: 0.01805

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.54097
Value Function Update Magnitude: 0.61416

Collected Steps per Second: 22,357.57505
Overall Steps per Second: 10,680.54128

Timestep Collection Time: 2.23736
Timestep Consumption Time: 2.44611
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.68347

Cumulative Model Updates: 246,960
Cumulative Timesteps: 2,059,647,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.42651
Policy Entropy: 2.14774
Value Function Loss: 0.01780

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.61910

Collected Steps per Second: 22,531.33808
Overall Steps per Second: 10,944.94734

Timestep Collection Time: 2.21966
Timestep Consumption Time: 2.34975
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.56941

Cumulative Model Updates: 246,966
Cumulative Timesteps: 2,059,697,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2059697656...
Checkpoint 2059697656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.98789
Policy Entropy: 2.14222
Value Function Loss: 0.01751

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.54098
Value Function Update Magnitude: 0.60134

Collected Steps per Second: 22,936.98491
Overall Steps per Second: 10,633.20516

Timestep Collection Time: 2.18111
Timestep Consumption Time: 2.52378
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.70488

Cumulative Model Updates: 246,972
Cumulative Timesteps: 2,059,747,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.59182
Policy Entropy: 2.16465
Value Function Loss: 0.01610

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.53026
Value Function Update Magnitude: 0.59281

Collected Steps per Second: 23,114.52642
Overall Steps per Second: 10,855.46713

Timestep Collection Time: 2.16323
Timestep Consumption Time: 2.44293
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.60616

Cumulative Model Updates: 246,978
Cumulative Timesteps: 2,059,797,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2059797686...
Checkpoint 2059797686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.82628
Policy Entropy: 2.18330
Value Function Loss: 0.01589

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.51864
Value Function Update Magnitude: 0.59421

Collected Steps per Second: 22,690.81339
Overall Steps per Second: 10,853.08885

Timestep Collection Time: 2.20389
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.60772

Cumulative Model Updates: 246,984
Cumulative Timesteps: 2,059,847,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.30728
Policy Entropy: 2.18235
Value Function Loss: 0.01724

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.52665
Value Function Update Magnitude: 0.58847

Collected Steps per Second: 23,211.57554
Overall Steps per Second: 10,716.99004

Timestep Collection Time: 2.15418
Timestep Consumption Time: 2.51149
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.66568

Cumulative Model Updates: 246,990
Cumulative Timesteps: 2,059,897,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2059897696...
Checkpoint 2059897696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.97179
Policy Entropy: 2.19239
Value Function Loss: 0.01750

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.59275

Collected Steps per Second: 22,821.20511
Overall Steps per Second: 10,642.13414

Timestep Collection Time: 2.19217
Timestep Consumption Time: 2.50877
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.70094

Cumulative Model Updates: 246,996
Cumulative Timesteps: 2,059,947,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.49775
Policy Entropy: 2.17053
Value Function Loss: 0.01852

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.52790
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 23,071.41739
Overall Steps per Second: 10,942.47439

Timestep Collection Time: 2.16727
Timestep Consumption Time: 2.40226
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.56953

Cumulative Model Updates: 247,002
Cumulative Timesteps: 2,059,997,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2059997726...
Checkpoint 2059997726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.34930
Policy Entropy: 2.17681
Value Function Loss: 0.01724

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.52468
Value Function Update Magnitude: 0.61715

Collected Steps per Second: 22,593.98675
Overall Steps per Second: 10,952.67977

Timestep Collection Time: 2.21439
Timestep Consumption Time: 2.35362
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.56801

Cumulative Model Updates: 247,008
Cumulative Timesteps: 2,060,047,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.06330
Policy Entropy: 2.17328
Value Function Loss: 0.01806

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.62328

Collected Steps per Second: 22,605.16530
Overall Steps per Second: 10,615.21171

Timestep Collection Time: 2.21241
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71135

Cumulative Model Updates: 247,014
Cumulative Timesteps: 2,060,097,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2060097770...
Checkpoint 2060097770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.34117
Policy Entropy: 2.16519
Value Function Loss: 0.01883

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.55833
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 22,579.80297
Overall Steps per Second: 10,608.60870

Timestep Collection Time: 2.21543
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.71542

Cumulative Model Updates: 247,020
Cumulative Timesteps: 2,060,147,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.83268
Policy Entropy: 2.18371
Value Function Loss: 0.01921

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.66505

Collected Steps per Second: 23,012.65319
Overall Steps per Second: 10,900.09094

Timestep Collection Time: 2.17324
Timestep Consumption Time: 2.41498
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.58822

Cumulative Model Updates: 247,026
Cumulative Timesteps: 2,060,197,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2060197806...
Checkpoint 2060197806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.46981
Policy Entropy: 2.16280
Value Function Loss: 0.01959

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.66932

Collected Steps per Second: 22,689.35578
Overall Steps per Second: 10,642.84439

Timestep Collection Time: 2.20500
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70081

Cumulative Model Updates: 247,032
Cumulative Timesteps: 2,060,247,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.32579
Policy Entropy: 2.17277
Value Function Loss: 0.01903

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.65247

Collected Steps per Second: 24,297.54054
Overall Steps per Second: 10,975.42005

Timestep Collection Time: 2.05881
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.55782

Cumulative Model Updates: 247,038
Cumulative Timesteps: 2,060,297,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2060297860...
Checkpoint 2060297860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.82414
Policy Entropy: 2.16458
Value Function Loss: 0.01862

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.65891

Collected Steps per Second: 23,087.06804
Overall Steps per Second: 10,773.57723

Timestep Collection Time: 2.16606
Timestep Consumption Time: 2.47567
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.64173

Cumulative Model Updates: 247,044
Cumulative Timesteps: 2,060,347,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.30938
Policy Entropy: 2.20692
Value Function Loss: 0.01652

Mean KL Divergence: 0.03102
SB3 Clip Fraction: 0.17222
Policy Update Magnitude: 0.52467
Value Function Update Magnitude: 0.65392

Collected Steps per Second: 23,009.28309
Overall Steps per Second: 10,754.83859

Timestep Collection Time: 2.17312
Timestep Consumption Time: 2.47613
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.64926

Cumulative Model Updates: 247,050
Cumulative Timesteps: 2,060,397,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2060397870...
Checkpoint 2060397870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.74701
Policy Entropy: 2.19851
Value Function Loss: 0.01711

Mean KL Divergence: 0.02912
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.54709
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 22,627.72986
Overall Steps per Second: 10,963.05576

Timestep Collection Time: 2.20994
Timestep Consumption Time: 2.35138
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.56132

Cumulative Model Updates: 247,056
Cumulative Timesteps: 2,060,447,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.25183
Policy Entropy: 2.18520
Value Function Loss: 0.01675

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.15976
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 23,315.71413
Overall Steps per Second: 10,958.17374

Timestep Collection Time: 2.14593
Timestep Consumption Time: 2.41997
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.56591

Cumulative Model Updates: 247,062
Cumulative Timesteps: 2,060,497,910

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2060497910...
Checkpoint 2060497910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.69515
Policy Entropy: 2.17556
Value Function Loss: 0.01641

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.53599
Value Function Update Magnitude: 0.62501

Collected Steps per Second: 22,602.18985
Overall Steps per Second: 10,744.14318

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.65556

Cumulative Model Updates: 247,068
Cumulative Timesteps: 2,060,547,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.09948
Policy Entropy: 2.20733
Value Function Loss: 0.01531

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.62778

Collected Steps per Second: 22,792.87567
Overall Steps per Second: 10,846.40689

Timestep Collection Time: 2.19402
Timestep Consumption Time: 2.41654
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61056

Cumulative Model Updates: 247,074
Cumulative Timesteps: 2,060,597,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2060597938...
Checkpoint 2060597938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.59199
Policy Entropy: 2.21614
Value Function Loss: 0.01594

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.62215

Collected Steps per Second: 22,428.87473
Overall Steps per Second: 10,755.31251

Timestep Collection Time: 2.22963
Timestep Consumption Time: 2.41998
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.64961

Cumulative Model Updates: 247,080
Cumulative Timesteps: 2,060,647,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.26813
Policy Entropy: 2.21789
Value Function Loss: 0.01699

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.63624

Collected Steps per Second: 22,784.91056
Overall Steps per Second: 10,812.75898

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.62639

Cumulative Model Updates: 247,086
Cumulative Timesteps: 2,060,697,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2060697970...
Checkpoint 2060697970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.47807
Policy Entropy: 2.20307
Value Function Loss: 0.01785

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.53301
Value Function Update Magnitude: 0.65168

Collected Steps per Second: 22,665.64660
Overall Steps per Second: 10,694.96674

Timestep Collection Time: 2.20704
Timestep Consumption Time: 2.47030
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.67734

Cumulative Model Updates: 247,092
Cumulative Timesteps: 2,060,747,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.26321
Policy Entropy: 2.20429
Value Function Loss: 0.01747

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.52941
Value Function Update Magnitude: 0.66258

Collected Steps per Second: 23,194.84715
Overall Steps per Second: 10,818.82365

Timestep Collection Time: 2.15600
Timestep Consumption Time: 2.46632
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.62231

Cumulative Model Updates: 247,098
Cumulative Timesteps: 2,060,798,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2060798002...
Checkpoint 2060798002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.25222
Policy Entropy: 2.19406
Value Function Loss: 0.01728

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.53811
Value Function Update Magnitude: 0.65294

Collected Steps per Second: 23,459.73208
Overall Steps per Second: 10,839.06054

Timestep Collection Time: 2.13174
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.61387

Cumulative Model Updates: 247,104
Cumulative Timesteps: 2,060,848,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.94583
Policy Entropy: 2.17446
Value Function Loss: 0.01695

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.64879

Collected Steps per Second: 23,173.83687
Overall Steps per Second: 10,731.31679

Timestep Collection Time: 2.15778
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.65963

Cumulative Model Updates: 247,110
Cumulative Timesteps: 2,060,898,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2060898016...
Checkpoint 2060898016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.79121
Policy Entropy: 2.18970
Value Function Loss: 0.01742

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.63707

Collected Steps per Second: 22,937.28962
Overall Steps per Second: 10,685.93363

Timestep Collection Time: 2.17994
Timestep Consumption Time: 2.49929
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.67924

Cumulative Model Updates: 247,116
Cumulative Timesteps: 2,060,948,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.86798
Policy Entropy: 2.21083
Value Function Loss: 0.01747

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.53237
Value Function Update Magnitude: 0.61833

Collected Steps per Second: 23,298.20005
Overall Steps per Second: 10,938.06346

Timestep Collection Time: 2.14720
Timestep Consumption Time: 2.42637
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.57357

Cumulative Model Updates: 247,122
Cumulative Timesteps: 2,060,998,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2060998044...
Checkpoint 2060998044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.80381
Policy Entropy: 2.20669
Value Function Loss: 0.01770

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.52512
Value Function Update Magnitude: 0.61696

Collected Steps per Second: 22,842.21505
Overall Steps per Second: 10,686.35536

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.49033
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.67961

Cumulative Model Updates: 247,128
Cumulative Timesteps: 2,061,048,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.20678
Policy Entropy: 2.16189
Value Function Loss: 0.01772

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.53551
Value Function Update Magnitude: 0.61460

Collected Steps per Second: 23,082.59211
Overall Steps per Second: 10,836.31053

Timestep Collection Time: 2.16778
Timestep Consumption Time: 2.44984
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.61762

Cumulative Model Updates: 247,134
Cumulative Timesteps: 2,061,098,090

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2061098090...
Checkpoint 2061098090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.50166
Policy Entropy: 2.13885
Value Function Loss: 0.01781

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.62529

Collected Steps per Second: 22,151.79459
Overall Steps per Second: 10,617.42706

Timestep Collection Time: 2.25760
Timestep Consumption Time: 2.45258
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.71018

Cumulative Model Updates: 247,140
Cumulative Timesteps: 2,061,148,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.77433
Policy Entropy: 2.16058
Value Function Loss: 0.01790

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.62676

Collected Steps per Second: 23,019.36493
Overall Steps per Second: 10,918.15419

Timestep Collection Time: 2.17234
Timestep Consumption Time: 2.40773
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.58008

Cumulative Model Updates: 247,146
Cumulative Timesteps: 2,061,198,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2061198106...
Checkpoint 2061198106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.51767
Policy Entropy: 2.17263
Value Function Loss: 0.01789

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.62757

Collected Steps per Second: 23,051.81929
Overall Steps per Second: 10,751.56469

Timestep Collection Time: 2.16903
Timestep Consumption Time: 2.48146
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.65049

Cumulative Model Updates: 247,152
Cumulative Timesteps: 2,061,248,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.65300
Policy Entropy: 2.16501
Value Function Loss: 0.01739

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.54963
Value Function Update Magnitude: 0.63236

Collected Steps per Second: 21,682.35929
Overall Steps per Second: 10,415.98830

Timestep Collection Time: 2.30667
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.80166

Cumulative Model Updates: 247,158
Cumulative Timesteps: 2,061,298,120

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2061298120...
Checkpoint 2061298120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.40685
Policy Entropy: 2.18003
Value Function Loss: 0.01663

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.63470

Collected Steps per Second: 22,793.09392
Overall Steps per Second: 10,740.82778

Timestep Collection Time: 2.19382
Timestep Consumption Time: 2.46168
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.65551

Cumulative Model Updates: 247,164
Cumulative Timesteps: 2,061,348,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.46344
Policy Entropy: 2.22005
Value Function Loss: 0.01483

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.51402
Value Function Update Magnitude: 0.61162

Collected Steps per Second: 22,972.96360
Overall Steps per Second: 10,935.36258

Timestep Collection Time: 2.17769
Timestep Consumption Time: 2.39719
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.57488

Cumulative Model Updates: 247,170
Cumulative Timesteps: 2,061,398,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2061398152...
Checkpoint 2061398152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.22936
Policy Entropy: 2.23398
Value Function Loss: 0.01507

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.50992
Value Function Update Magnitude: 0.57406

Collected Steps per Second: 23,057.07585
Overall Steps per Second: 10,815.18436

Timestep Collection Time: 2.16957
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62535

Cumulative Model Updates: 247,176
Cumulative Timesteps: 2,061,448,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.43788
Policy Entropy: 2.22291
Value Function Loss: 0.01585

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.51446
Value Function Update Magnitude: 0.57116

Collected Steps per Second: 22,854.49102
Overall Steps per Second: 10,700.24476

Timestep Collection Time: 2.18845
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.67429

Cumulative Model Updates: 247,182
Cumulative Timesteps: 2,061,498,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2061498192...
Checkpoint 2061498192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.79280
Policy Entropy: 2.17370
Value Function Loss: 0.01767

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.11383
Policy Update Magnitude: 0.52311
Value Function Update Magnitude: 0.59565

Collected Steps per Second: 23,093.04623
Overall Steps per Second: 10,934.10577

Timestep Collection Time: 2.16602
Timestep Consumption Time: 2.40866
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.57468

Cumulative Model Updates: 247,188
Cumulative Timesteps: 2,061,548,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.03250
Policy Entropy: 2.15913
Value Function Loss: 0.01868

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.62913

Collected Steps per Second: 23,383.05313
Overall Steps per Second: 10,937.63082

Timestep Collection Time: 2.13924
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.57339

Cumulative Model Updates: 247,194
Cumulative Timesteps: 2,061,598,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2061598234...
Checkpoint 2061598234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.78070
Policy Entropy: 2.15833
Value Function Loss: 0.01794

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.63420

Collected Steps per Second: 23,007.77245
Overall Steps per Second: 10,728.09278

Timestep Collection Time: 2.17396
Timestep Consumption Time: 2.48838
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.66234

Cumulative Model Updates: 247,200
Cumulative Timesteps: 2,061,648,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.07438
Policy Entropy: 2.16855
Value Function Loss: 0.01874

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.62378

Collected Steps per Second: 23,073.23346
Overall Steps per Second: 10,787.38065

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.63634

Cumulative Model Updates: 247,206
Cumulative Timesteps: 2,061,698,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2061698266...
Checkpoint 2061698266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.33697
Policy Entropy: 2.20383
Value Function Loss: 0.01755

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.54839
Value Function Update Magnitude: 0.62474

Collected Steps per Second: 22,377.75733
Overall Steps per Second: 10,638.17248

Timestep Collection Time: 2.23445
Timestep Consumption Time: 2.46579
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.70024

Cumulative Model Updates: 247,212
Cumulative Timesteps: 2,061,748,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.88222
Policy Entropy: 2.20007
Value Function Loss: 0.01665

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.61691

Collected Steps per Second: 22,838.76473
Overall Steps per Second: 10,926.94777

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.38677
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.57621

Cumulative Model Updates: 247,218
Cumulative Timesteps: 2,061,798,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2061798272...
Checkpoint 2061798272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.60479
Policy Entropy: 2.18621
Value Function Loss: 0.01703

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.54286
Value Function Update Magnitude: 0.59967

Collected Steps per Second: 22,612.86183
Overall Steps per Second: 10,617.19664

Timestep Collection Time: 2.21131
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.70972

Cumulative Model Updates: 247,224
Cumulative Timesteps: 2,061,848,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.28648
Policy Entropy: 2.15047
Value Function Loss: 0.01812

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.60515

Collected Steps per Second: 23,139.20528
Overall Steps per Second: 10,852.96673

Timestep Collection Time: 2.16187
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.60925

Cumulative Model Updates: 247,230
Cumulative Timesteps: 2,061,898,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2061898300...
Checkpoint 2061898300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.44588
Policy Entropy: 2.17121
Value Function Loss: 0.01922

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.61668

Collected Steps per Second: 22,509.46356
Overall Steps per Second: 10,705.13076

Timestep Collection Time: 2.22173
Timestep Consumption Time: 2.44986
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.67159

Cumulative Model Updates: 247,236
Cumulative Timesteps: 2,061,948,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.17481
Policy Entropy: 2.17293
Value Function Loss: 0.01909

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.54374
Value Function Update Magnitude: 0.62154

Collected Steps per Second: 23,378.38452
Overall Steps per Second: 10,953.55124

Timestep Collection Time: 2.13984
Timestep Consumption Time: 2.42726
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.56710

Cumulative Model Updates: 247,242
Cumulative Timesteps: 2,061,998,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2061998336...
Checkpoint 2061998336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.80825
Policy Entropy: 2.19711
Value Function Loss: 0.01888

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.54499
Value Function Update Magnitude: 0.62240

Collected Steps per Second: 22,952.05763
Overall Steps per Second: 10,746.56335

Timestep Collection Time: 2.17863
Timestep Consumption Time: 2.47439
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.65302

Cumulative Model Updates: 247,248
Cumulative Timesteps: 2,062,048,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.54086
Policy Entropy: 2.15294
Value Function Loss: 0.02052

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.62634

Collected Steps per Second: 23,403.26977
Overall Steps per Second: 10,793.44718

Timestep Collection Time: 2.13748
Timestep Consumption Time: 2.49718
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.63466

Cumulative Model Updates: 247,254
Cumulative Timesteps: 2,062,098,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2062098364...
Checkpoint 2062098364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.41909
Policy Entropy: 2.16881
Value Function Loss: 0.01993

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.63643

Collected Steps per Second: 23,044.62950
Overall Steps per Second: 10,814.74028

Timestep Collection Time: 2.16988
Timestep Consumption Time: 2.45381
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.62369

Cumulative Model Updates: 247,260
Cumulative Timesteps: 2,062,148,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.43445
Policy Entropy: 2.15732
Value Function Loss: 0.01997

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.61891

Collected Steps per Second: 22,894.90483
Overall Steps per Second: 10,893.78507

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.40636
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.59069

Cumulative Model Updates: 247,266
Cumulative Timesteps: 2,062,198,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2062198378...
Checkpoint 2062198378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.36891
Policy Entropy: 2.19844
Value Function Loss: 0.01791

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.53877
Value Function Update Magnitude: 0.60483

Collected Steps per Second: 22,404.38605
Overall Steps per Second: 10,631.58410

Timestep Collection Time: 2.23304
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70579

Cumulative Model Updates: 247,272
Cumulative Timesteps: 2,062,248,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.73951
Policy Entropy: 2.19898
Value Function Loss: 0.01838

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.54459
Value Function Update Magnitude: 0.60589

Collected Steps per Second: 23,040.72006
Overall Steps per Second: 10,731.82937

Timestep Collection Time: 2.17103
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.66109

Cumulative Model Updates: 247,278
Cumulative Timesteps: 2,062,298,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2062298430...
Checkpoint 2062298430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.10147
Policy Entropy: 2.20240
Value Function Loss: 0.01804

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.53898
Value Function Update Magnitude: 0.61249

Collected Steps per Second: 22,559.48081
Overall Steps per Second: 10,663.34554

Timestep Collection Time: 2.21707
Timestep Consumption Time: 2.47339
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69046

Cumulative Model Updates: 247,284
Cumulative Timesteps: 2,062,348,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.77718
Policy Entropy: 2.16243
Value Function Loss: 0.01822

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.53707
Value Function Update Magnitude: 0.63157

Collected Steps per Second: 23,045.34150
Overall Steps per Second: 10,765.58442

Timestep Collection Time: 2.17076
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.64684

Cumulative Model Updates: 247,290
Cumulative Timesteps: 2,062,398,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2062398472...
Checkpoint 2062398472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.36722
Policy Entropy: 2.15335
Value Function Loss: 0.01850

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.63961

Collected Steps per Second: 22,629.27075
Overall Steps per Second: 10,806.14727

Timestep Collection Time: 2.20988
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.62774

Cumulative Model Updates: 247,296
Cumulative Timesteps: 2,062,448,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.70090
Policy Entropy: 2.14862
Value Function Loss: 0.01840

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.54975
Value Function Update Magnitude: 0.64465

Collected Steps per Second: 23,348.21550
Overall Steps per Second: 10,895.30083

Timestep Collection Time: 2.14252
Timestep Consumption Time: 2.44882
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.59134

Cumulative Model Updates: 247,302
Cumulative Timesteps: 2,062,498,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2062498504...
Checkpoint 2062498504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.54344
Policy Entropy: 2.16212
Value Function Loss: 0.01751

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.53761
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,848.45783
Overall Steps per Second: 11,020.54413

Timestep Collection Time: 2.18859
Timestep Consumption Time: 2.34893
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.53753

Cumulative Model Updates: 247,308
Cumulative Timesteps: 2,062,548,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.60103
Policy Entropy: 2.16311
Value Function Loss: 0.01677

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.62769

Collected Steps per Second: 23,433.32724
Overall Steps per Second: 10,948.67440

Timestep Collection Time: 2.13457
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.56859

Cumulative Model Updates: 247,314
Cumulative Timesteps: 2,062,598,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2062598530...
Checkpoint 2062598530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.63114
Policy Entropy: 2.17593
Value Function Loss: 0.01750

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.61400

Collected Steps per Second: 22,035.95465
Overall Steps per Second: 10,635.90649

Timestep Collection Time: 2.27020
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.70350

Cumulative Model Updates: 247,320
Cumulative Timesteps: 2,062,648,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.02939
Policy Entropy: 2.18420
Value Function Loss: 0.01797

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.53251
Value Function Update Magnitude: 0.60788

Collected Steps per Second: 22,517.18539
Overall Steps per Second: 10,679.63889

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.46177
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.68274

Cumulative Model Updates: 247,326
Cumulative Timesteps: 2,062,698,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2062698566...
Checkpoint 2062698566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.75065
Policy Entropy: 2.20769
Value Function Loss: 0.01713

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.51444
Value Function Update Magnitude: 0.59771

Collected Steps per Second: 23,322.39450
Overall Steps per Second: 10,977.06114

Timestep Collection Time: 2.14481
Timestep Consumption Time: 2.41215
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.55696

Cumulative Model Updates: 247,332
Cumulative Timesteps: 2,062,748,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.94501
Policy Entropy: 2.20178
Value Function Loss: 0.01711

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.15470
Policy Update Magnitude: 0.48861
Value Function Update Magnitude: 0.56947

Collected Steps per Second: 23,219.99396
Overall Steps per Second: 10,939.74109

Timestep Collection Time: 2.15340
Timestep Consumption Time: 2.41727
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.57067

Cumulative Model Updates: 247,338
Cumulative Timesteps: 2,062,798,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2062798590...
Checkpoint 2062798590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.89339
Policy Entropy: 2.18787
Value Function Loss: 0.01662

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.50835
Value Function Update Magnitude: 0.54747

Collected Steps per Second: 22,675.45519
Overall Steps per Second: 10,582.21461

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.51988
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.72491

Cumulative Model Updates: 247,344
Cumulative Timesteps: 2,062,848,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.34459
Policy Entropy: 2.17725
Value Function Loss: 0.01780

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.52130
Value Function Update Magnitude: 0.54094

Collected Steps per Second: 23,491.58999
Overall Steps per Second: 10,962.41004

Timestep Collection Time: 2.12893
Timestep Consumption Time: 2.43320
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.56214

Cumulative Model Updates: 247,350
Cumulative Timesteps: 2,062,898,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2062898602...
Checkpoint 2062898602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.44724
Policy Entropy: 2.17489
Value Function Loss: 0.01761

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.52898
Value Function Update Magnitude: 0.55947

Collected Steps per Second: 23,294.01859
Overall Steps per Second: 10,952.35437

Timestep Collection Time: 2.14768
Timestep Consumption Time: 2.42011
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.56778

Cumulative Model Updates: 247,356
Cumulative Timesteps: 2,062,948,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.43707
Policy Entropy: 2.22469
Value Function Loss: 0.01602

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.51938
Value Function Update Magnitude: 0.56032

Collected Steps per Second: 23,157.25161
Overall Steps per Second: 10,905.27734

Timestep Collection Time: 2.15984
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.58640

Cumulative Model Updates: 247,362
Cumulative Timesteps: 2,062,998,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2062998646...
Checkpoint 2062998646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.13553
Policy Entropy: 2.21965
Value Function Loss: 0.01803

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.52894
Value Function Update Magnitude: 0.55598

Collected Steps per Second: 22,645.12256
Overall Steps per Second: 10,708.42464

Timestep Collection Time: 2.20851
Timestep Consumption Time: 2.46183
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.67034

Cumulative Model Updates: 247,368
Cumulative Timesteps: 2,063,048,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.33392
Policy Entropy: 2.22928
Value Function Loss: 0.01799

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.53433
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 23,805.02473
Overall Steps per Second: 10,960.84014

Timestep Collection Time: 2.10149
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.56407

Cumulative Model Updates: 247,374
Cumulative Timesteps: 2,063,098,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2063098684...
Checkpoint 2063098684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.82592
Policy Entropy: 2.22203
Value Function Loss: 0.01765

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.51904
Value Function Update Magnitude: 0.60834

Collected Steps per Second: 22,512.16848
Overall Steps per Second: 10,610.26903

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.49299
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.71543

Cumulative Model Updates: 247,380
Cumulative Timesteps: 2,063,148,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.25270
Policy Entropy: 2.22002
Value Function Loss: 0.01650

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.51616
Value Function Update Magnitude: 0.57773

Collected Steps per Second: 22,894.02462
Overall Steps per Second: 10,894.71573

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.40608
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.59067

Cumulative Model Updates: 247,386
Cumulative Timesteps: 2,063,198,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2063198730...
Checkpoint 2063198730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.06409
Policy Entropy: 2.20669
Value Function Loss: 0.01633

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.51414
Value Function Update Magnitude: 0.56759

Collected Steps per Second: 22,131.10196
Overall Steps per Second: 10,634.39791

Timestep Collection Time: 2.26053
Timestep Consumption Time: 2.44383
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.70436

Cumulative Model Updates: 247,392
Cumulative Timesteps: 2,063,248,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.87652
Policy Entropy: 2.20313
Value Function Loss: 0.01685

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.51179
Value Function Update Magnitude: 0.57679

Collected Steps per Second: 23,148.87581
Overall Steps per Second: 10,880.53922

Timestep Collection Time: 2.16002
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.59554

Cumulative Model Updates: 247,398
Cumulative Timesteps: 2,063,298,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2063298760...
Checkpoint 2063298760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.35906
Policy Entropy: 2.20053
Value Function Loss: 0.01875

Mean KL Divergence: 0.03012
SB3 Clip Fraction: 0.16954
Policy Update Magnitude: 0.50158
Value Function Update Magnitude: 0.58899

Collected Steps per Second: 23,018.30279
Overall Steps per Second: 10,722.94117

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.66551

Cumulative Model Updates: 247,404
Cumulative Timesteps: 2,063,348,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.10194
Policy Entropy: 2.18131
Value Function Loss: 0.01957

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 23,149.07478
Overall Steps per Second: 10,809.59273

Timestep Collection Time: 2.16086
Timestep Consumption Time: 2.46669
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.62756

Cumulative Model Updates: 247,410
Cumulative Timesteps: 2,063,398,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2063398810...
Checkpoint 2063398810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.44624
Policy Entropy: 2.16383
Value Function Loss: 0.01934

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.55900
Value Function Update Magnitude: 0.64065

Collected Steps per Second: 22,731.06143
Overall Steps per Second: 10,841.72619

Timestep Collection Time: 2.19972
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.61200

Cumulative Model Updates: 247,416
Cumulative Timesteps: 2,063,448,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.71851
Policy Entropy: 2.16010
Value Function Loss: 0.01820

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.55573
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 23,424.20486
Overall Steps per Second: 10,786.00645

Timestep Collection Time: 2.13582
Timestep Consumption Time: 2.50259
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.63842

Cumulative Model Updates: 247,422
Cumulative Timesteps: 2,063,498,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2063498842...
Checkpoint 2063498842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.06937
Policy Entropy: 2.20517
Value Function Loss: 0.01702

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.60189

Collected Steps per Second: 22,809.27189
Overall Steps per Second: 10,662.05720

Timestep Collection Time: 2.19218
Timestep Consumption Time: 2.49754
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.68971

Cumulative Model Updates: 247,428
Cumulative Timesteps: 2,063,548,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.55014
Policy Entropy: 2.23547
Value Function Loss: 0.01710

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.58595

Collected Steps per Second: 23,280.88183
Overall Steps per Second: 10,854.79798

Timestep Collection Time: 2.14803
Timestep Consumption Time: 2.45897
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.60700

Cumulative Model Updates: 247,434
Cumulative Timesteps: 2,063,598,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2063598852...
Checkpoint 2063598852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.94639
Policy Entropy: 2.24419
Value Function Loss: 0.01685

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.52771
Value Function Update Magnitude: 0.59488

Collected Steps per Second: 23,170.64153
Overall Steps per Second: 10,825.67976

Timestep Collection Time: 2.15825
Timestep Consumption Time: 2.46114
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.61939

Cumulative Model Updates: 247,440
Cumulative Timesteps: 2,063,648,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.56987
Policy Entropy: 2.23236
Value Function Loss: 0.01742

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.60008

Collected Steps per Second: 22,815.01497
Overall Steps per Second: 10,771.51197

Timestep Collection Time: 2.19180
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.64243

Cumulative Model Updates: 247,446
Cumulative Timesteps: 2,063,698,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2063698866...
Checkpoint 2063698866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.04964
Policy Entropy: 2.22740
Value Function Loss: 0.01698

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.53922
Value Function Update Magnitude: 0.60133

Collected Steps per Second: 22,613.36189
Overall Steps per Second: 10,625.00118

Timestep Collection Time: 2.21126
Timestep Consumption Time: 2.49500
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.70626

Cumulative Model Updates: 247,452
Cumulative Timesteps: 2,063,748,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.68594
Policy Entropy: 2.21158
Value Function Loss: 0.01705

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.51548
Value Function Update Magnitude: 0.59810

Collected Steps per Second: 22,848.79157
Overall Steps per Second: 10,854.44218

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.60678

Cumulative Model Updates: 247,458
Cumulative Timesteps: 2,063,798,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2063798874...
Checkpoint 2063798874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.06707
Policy Entropy: 2.22188
Value Function Loss: 0.01513

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.47604
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 23,245.08442
Overall Steps per Second: 10,756.57078

Timestep Collection Time: 2.15185
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.65018

Cumulative Model Updates: 247,464
Cumulative Timesteps: 2,063,848,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.41256
Policy Entropy: 2.21251
Value Function Loss: 0.01511

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.49233
Value Function Update Magnitude: 0.60092

Collected Steps per Second: 23,350.18080
Overall Steps per Second: 10,873.30779

Timestep Collection Time: 2.14157
Timestep Consumption Time: 2.45740
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.59897

Cumulative Model Updates: 247,470
Cumulative Timesteps: 2,063,898,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2063898900...
Checkpoint 2063898900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.03039
Policy Entropy: 2.21348
Value Function Loss: 0.01560

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.51981
Value Function Update Magnitude: 0.59537

Collected Steps per Second: 22,866.07844
Overall Steps per Second: 10,691.92512

Timestep Collection Time: 2.18708
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.67736

Cumulative Model Updates: 247,476
Cumulative Timesteps: 2,063,948,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.23575
Policy Entropy: 2.19519
Value Function Loss: 0.01715

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.53917
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 23,187.31246
Overall Steps per Second: 10,926.90237

Timestep Collection Time: 2.15799
Timestep Consumption Time: 2.42135
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.57934

Cumulative Model Updates: 247,482
Cumulative Timesteps: 2,063,998,948

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2063998948...
Checkpoint 2063998948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.28420
Policy Entropy: 2.15820
Value Function Loss: 0.01759

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.62700

Collected Steps per Second: 22,622.07950
Overall Steps per Second: 10,602.31922

Timestep Collection Time: 2.21067
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.71689

Cumulative Model Updates: 247,488
Cumulative Timesteps: 2,064,048,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.03796
Policy Entropy: 2.17946
Value Function Loss: 0.01682

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.63255

Collected Steps per Second: 23,582.21549
Overall Steps per Second: 10,846.73102

Timestep Collection Time: 2.12075
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.61079

Cumulative Model Updates: 247,494
Cumulative Timesteps: 2,064,098,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2064098970...
Checkpoint 2064098970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.44005
Policy Entropy: 2.20011
Value Function Loss: 0.01560

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.51931
Value Function Update Magnitude: 0.60290

Collected Steps per Second: 22,578.10292
Overall Steps per Second: 10,622.92231

Timestep Collection Time: 2.21471
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.70718

Cumulative Model Updates: 247,500
Cumulative Timesteps: 2,064,148,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.63046
Policy Entropy: 2.20806
Value Function Loss: 0.01657

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.52494
Value Function Update Magnitude: 0.58788

Collected Steps per Second: 23,681.36264
Overall Steps per Second: 10,943.58913

Timestep Collection Time: 2.11246
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.57126

Cumulative Model Updates: 247,506
Cumulative Timesteps: 2,064,199,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2064199000...
Checkpoint 2064199000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.74765
Policy Entropy: 2.19178
Value Function Loss: 0.01706

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.53832
Value Function Update Magnitude: 0.59998

Collected Steps per Second: 22,269.73376
Overall Steps per Second: 10,635.60158

Timestep Collection Time: 2.24610
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.70307

Cumulative Model Updates: 247,512
Cumulative Timesteps: 2,064,249,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.64020
Policy Entropy: 2.16687
Value Function Loss: 0.01773

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.53541
Value Function Update Magnitude: 0.63087

Collected Steps per Second: 22,831.38054
Overall Steps per Second: 10,838.82321

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.61545

Cumulative Model Updates: 247,518
Cumulative Timesteps: 2,064,299,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2064299046...
Checkpoint 2064299046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.17411
Policy Entropy: 2.19562
Value Function Loss: 0.01748

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.53399
Value Function Update Magnitude: 0.64069

Collected Steps per Second: 22,860.62485
Overall Steps per Second: 10,693.32786

Timestep Collection Time: 2.18725
Timestep Consumption Time: 2.48875
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.67600

Cumulative Model Updates: 247,524
Cumulative Timesteps: 2,064,349,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.04457
Policy Entropy: 2.20389
Value Function Loss: 0.01753

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.63822

Collected Steps per Second: 24,081.54381
Overall Steps per Second: 10,918.14847

Timestep Collection Time: 2.07653
Timestep Consumption Time: 2.50355
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.58008

Cumulative Model Updates: 247,530
Cumulative Timesteps: 2,064,399,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2064399054...
Checkpoint 2064399054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.75181
Policy Entropy: 2.20924
Value Function Loss: 0.01798

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.53984
Value Function Update Magnitude: 0.64401

Collected Steps per Second: 22,747.05676
Overall Steps per Second: 10,591.00129

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.52432
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.72363

Cumulative Model Updates: 247,536
Cumulative Timesteps: 2,064,449,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.53628
Policy Entropy: 2.20799
Value Function Loss: 0.01739

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.53763
Value Function Update Magnitude: 0.64767

Collected Steps per Second: 23,425.73939
Overall Steps per Second: 10,956.12742

Timestep Collection Time: 2.13458
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.56402

Cumulative Model Updates: 247,542
Cumulative Timesteps: 2,064,499,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2064499086...
Checkpoint 2064499086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.76895
Policy Entropy: 2.19294
Value Function Loss: 0.01773

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.53302
Value Function Update Magnitude: 0.63450

Collected Steps per Second: 22,712.29616
Overall Steps per Second: 10,702.88802

Timestep Collection Time: 2.20268
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.67425

Cumulative Model Updates: 247,548
Cumulative Timesteps: 2,064,549,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.71772
Policy Entropy: 2.20251
Value Function Loss: 0.01706

Mean KL Divergence: 0.02342
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.51699
Value Function Update Magnitude: 0.64514

Collected Steps per Second: 22,885.39679
Overall Steps per Second: 10,803.66062

Timestep Collection Time: 2.18532
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.62917

Cumulative Model Updates: 247,554
Cumulative Timesteps: 2,064,599,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2064599126...
Checkpoint 2064599126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.45483
Policy Entropy: 2.19379
Value Function Loss: 0.01777

Mean KL Divergence: 0.02872
SB3 Clip Fraction: 0.16739
Policy Update Magnitude: 0.49736
Value Function Update Magnitude: 0.64871

Collected Steps per Second: 22,650.39824
Overall Steps per Second: 10,672.87106

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.47780
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.68571

Cumulative Model Updates: 247,560
Cumulative Timesteps: 2,064,649,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.66559
Policy Entropy: 2.22236
Value Function Loss: 0.01752

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.15087
Policy Update Magnitude: 0.51877
Value Function Update Magnitude: 0.63492

Collected Steps per Second: 23,022.05203
Overall Steps per Second: 10,884.78248

Timestep Collection Time: 2.17192
Timestep Consumption Time: 2.42184
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.59375

Cumulative Model Updates: 247,566
Cumulative Timesteps: 2,064,699,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2064699138...
Checkpoint 2064699138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.71587
Policy Entropy: 2.20593
Value Function Loss: 0.01714

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.53233
Value Function Update Magnitude: 0.60410

Collected Steps per Second: 22,452.66421
Overall Steps per Second: 10,684.54680

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.68059

Cumulative Model Updates: 247,572
Cumulative Timesteps: 2,064,749,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.35050
Policy Entropy: 2.20661
Value Function Loss: 0.01693

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.53167
Value Function Update Magnitude: 0.57887

Collected Steps per Second: 22,813.24542
Overall Steps per Second: 10,890.20907

Timestep Collection Time: 2.19311
Timestep Consumption Time: 2.40111
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.59422

Cumulative Model Updates: 247,578
Cumulative Timesteps: 2,064,799,180

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2064799180...
Checkpoint 2064799180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.45685
Policy Entropy: 2.18768
Value Function Loss: 0.01673

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.52905
Value Function Update Magnitude: 0.58777

Collected Steps per Second: 22,478.22675
Overall Steps per Second: 10,607.68926

Timestep Collection Time: 2.22562
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.71620

Cumulative Model Updates: 247,584
Cumulative Timesteps: 2,064,849,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.40174
Policy Entropy: 2.20130
Value Function Loss: 0.01738

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.53611
Value Function Update Magnitude: 0.61374

Collected Steps per Second: 23,290.82994
Overall Steps per Second: 10,872.83078

Timestep Collection Time: 2.14806
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60138

Cumulative Model Updates: 247,590
Cumulative Timesteps: 2,064,899,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2064899238...
Checkpoint 2064899238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.01627
Policy Entropy: 2.20530
Value Function Loss: 0.01694

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.54229
Value Function Update Magnitude: 0.64186

Collected Steps per Second: 22,884.87874
Overall Steps per Second: 10,895.26802

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.40440
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.58933

Cumulative Model Updates: 247,596
Cumulative Timesteps: 2,064,949,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.69041
Policy Entropy: 2.20473
Value Function Loss: 0.01632

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.52867
Value Function Update Magnitude: 0.63516

Collected Steps per Second: 23,485.81237
Overall Steps per Second: 10,812.40743

Timestep Collection Time: 2.12971
Timestep Consumption Time: 2.49627
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.62598

Cumulative Model Updates: 247,602
Cumulative Timesteps: 2,064,999,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2064999258...
Checkpoint 2064999258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.75507
Policy Entropy: 2.22413
Value Function Loss: 0.01673

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.53108
Value Function Update Magnitude: 0.60219

Collected Steps per Second: 22,932.60330
Overall Steps per Second: 10,734.93196

Timestep Collection Time: 2.18056
Timestep Consumption Time: 2.47769
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.65825

Cumulative Model Updates: 247,608
Cumulative Timesteps: 2,065,049,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.08952
Policy Entropy: 2.21988
Value Function Loss: 0.01706

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.58695

Collected Steps per Second: 23,212.87328
Overall Steps per Second: 10,791.35309

Timestep Collection Time: 2.15484
Timestep Consumption Time: 2.48035
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.63519

Cumulative Model Updates: 247,614
Cumulative Timesteps: 2,065,099,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2065099284...
Checkpoint 2065099284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.09870
Policy Entropy: 2.22536
Value Function Loss: 0.01808

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.57963

Collected Steps per Second: 21,843.52846
Overall Steps per Second: 10,574.07855

Timestep Collection Time: 2.28965
Timestep Consumption Time: 2.44022
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.72987

Cumulative Model Updates: 247,620
Cumulative Timesteps: 2,065,149,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.88346
Policy Entropy: 2.18964
Value Function Loss: 0.01850

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.54666
Value Function Update Magnitude: 0.58848

Collected Steps per Second: 22,820.32547
Overall Steps per Second: 10,711.57506

Timestep Collection Time: 2.19226
Timestep Consumption Time: 2.47821
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.67046

Cumulative Model Updates: 247,626
Cumulative Timesteps: 2,065,199,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2065199326...
Checkpoint 2065199326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.22869
Policy Entropy: 2.18579
Value Function Loss: 0.01814

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.59619

Collected Steps per Second: 21,577.76795
Overall Steps per Second: 10,443.32935

Timestep Collection Time: 2.31813
Timestep Consumption Time: 2.47153
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.78966

Cumulative Model Updates: 247,632
Cumulative Timesteps: 2,065,249,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.53722
Policy Entropy: 2.19496
Value Function Loss: 0.01767

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.53248
Value Function Update Magnitude: 0.60689

Collected Steps per Second: 22,745.79932
Overall Steps per Second: 10,862.79878

Timestep Collection Time: 2.19856
Timestep Consumption Time: 2.40504
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.60360

Cumulative Model Updates: 247,638
Cumulative Timesteps: 2,065,299,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2065299354...
Checkpoint 2065299354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.00056
Policy Entropy: 2.19819
Value Function Loss: 0.01850

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.54555
Value Function Update Magnitude: 0.62366

Collected Steps per Second: 22,485.96448
Overall Steps per Second: 10,634.58645

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.70371

Cumulative Model Updates: 247,644
Cumulative Timesteps: 2,065,349,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.41872
Policy Entropy: 2.19197
Value Function Loss: 0.01856

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.66119

Collected Steps per Second: 22,866.99971
Overall Steps per Second: 10,656.20635

Timestep Collection Time: 2.18673
Timestep Consumption Time: 2.50574
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.69248

Cumulative Model Updates: 247,650
Cumulative Timesteps: 2,065,399,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2065399380...
Checkpoint 2065399380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.56460
Policy Entropy: 2.17809
Value Function Loss: 0.01849

Mean KL Divergence: 0.03124
SB3 Clip Fraction: 0.17363
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.67670

Collected Steps per Second: 22,437.54340
Overall Steps per Second: 10,634.30434

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.47405
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.70308

Cumulative Model Updates: 247,656
Cumulative Timesteps: 2,065,449,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.48452
Policy Entropy: 2.17913
Value Function Loss: 0.01782

Mean KL Divergence: 0.02705
SB3 Clip Fraction: 0.15865
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.65602

Collected Steps per Second: 24,317.82985
Overall Steps per Second: 11,123.31644

Timestep Collection Time: 2.05717
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.49740

Cumulative Model Updates: 247,662
Cumulative Timesteps: 2,065,499,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2065499420...
Checkpoint 2065499420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.54816
Policy Entropy: 2.19558
Value Function Loss: 0.01708

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.63399

Collected Steps per Second: 22,694.13648
Overall Steps per Second: 10,691.22845

Timestep Collection Time: 2.20392
Timestep Consumption Time: 2.47431
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.67823

Cumulative Model Updates: 247,668
Cumulative Timesteps: 2,065,549,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.58560
Policy Entropy: 2.23216
Value Function Loss: 0.01575

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.52793
Value Function Update Magnitude: 0.60251

Collected Steps per Second: 23,212.84762
Overall Steps per Second: 10,919.47698

Timestep Collection Time: 2.15501
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.58117

Cumulative Model Updates: 247,674
Cumulative Timesteps: 2,065,599,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2065599460...
Checkpoint 2065599460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.50367
Policy Entropy: 2.25538
Value Function Loss: 0.01594

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.52444
Value Function Update Magnitude: 0.57571

Collected Steps per Second: 22,583.27288
Overall Steps per Second: 10,864.91679

Timestep Collection Time: 2.21509
Timestep Consumption Time: 2.38909
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.60418

Cumulative Model Updates: 247,680
Cumulative Timesteps: 2,065,649,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.64806
Policy Entropy: 2.24879
Value Function Loss: 0.01769

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.53054
Value Function Update Magnitude: 0.58102

Collected Steps per Second: 22,827.77344
Overall Steps per Second: 10,685.23291

Timestep Collection Time: 2.19128
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.68141

Cumulative Model Updates: 247,686
Cumulative Timesteps: 2,065,699,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2065699506...
Checkpoint 2065699506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.30420
Policy Entropy: 2.24684
Value Function Loss: 0.01743

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.60844

Collected Steps per Second: 22,438.29838
Overall Steps per Second: 10,639.21214

Timestep Collection Time: 2.22896
Timestep Consumption Time: 2.47196
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.70091

Cumulative Model Updates: 247,692
Cumulative Timesteps: 2,065,749,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.27341
Policy Entropy: 2.23724
Value Function Loss: 0.01761

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.52819
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 23,042.46722
Overall Steps per Second: 10,936.71736

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.40252
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.57304

Cumulative Model Updates: 247,698
Cumulative Timesteps: 2,065,799,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2065799534...
Checkpoint 2065799534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.09432
Policy Entropy: 2.23095
Value Function Loss: 0.01679

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.52692
Value Function Update Magnitude: 0.62073

Collected Steps per Second: 22,644.43159
Overall Steps per Second: 10,805.31175

Timestep Collection Time: 2.20902
Timestep Consumption Time: 2.42037
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.62939

Cumulative Model Updates: 247,704
Cumulative Timesteps: 2,065,849,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.48847
Policy Entropy: 2.21773
Value Function Loss: 0.01647

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.53282
Value Function Update Magnitude: 0.62655

Collected Steps per Second: 23,284.43599
Overall Steps per Second: 10,740.60043

Timestep Collection Time: 2.14804
Timestep Consumption Time: 2.50868
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.65672

Cumulative Model Updates: 247,710
Cumulative Timesteps: 2,065,899,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2065899572...
Checkpoint 2065899572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.34177
Policy Entropy: 2.23436
Value Function Loss: 0.01628

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.52964
Value Function Update Magnitude: 0.61564

Collected Steps per Second: 22,725.75290
Overall Steps per Second: 10,653.75676

Timestep Collection Time: 2.20120
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69543

Cumulative Model Updates: 247,716
Cumulative Timesteps: 2,065,949,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.70578
Policy Entropy: 2.22979
Value Function Loss: 0.01659

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.51959
Value Function Update Magnitude: 0.61485

Collected Steps per Second: 23,183.91148
Overall Steps per Second: 10,855.46421

Timestep Collection Time: 2.15667
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.60598

Cumulative Model Updates: 247,722
Cumulative Timesteps: 2,065,999,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2065999596...
Checkpoint 2065999596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.61456
Policy Entropy: 2.21038
Value Function Loss: 0.01699

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.50639
Value Function Update Magnitude: 0.61807

Collected Steps per Second: 22,559.12863
Overall Steps per Second: 10,825.37581

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.40296
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.61989

Cumulative Model Updates: 247,728
Cumulative Timesteps: 2,066,049,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.86707
Policy Entropy: 2.18467
Value Function Loss: 0.01730

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.49838
Value Function Update Magnitude: 0.61755

Collected Steps per Second: 23,545.81541
Overall Steps per Second: 10,836.39593

Timestep Collection Time: 2.12377
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.61463

Cumulative Model Updates: 247,734
Cumulative Timesteps: 2,066,099,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2066099614...
Checkpoint 2066099614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.82394
Policy Entropy: 2.16430
Value Function Loss: 0.01822

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.52210
Value Function Update Magnitude: 0.61075

Collected Steps per Second: 22,566.90361
Overall Steps per Second: 10,637.79598

Timestep Collection Time: 2.21617
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70135

Cumulative Model Updates: 247,740
Cumulative Timesteps: 2,066,149,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.99520
Policy Entropy: 2.20074
Value Function Loss: 0.01784

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.53511
Value Function Update Magnitude: 0.59909

Collected Steps per Second: 23,106.78361
Overall Steps per Second: 10,908.74867

Timestep Collection Time: 2.16447
Timestep Consumption Time: 2.42029
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.58476

Cumulative Model Updates: 247,746
Cumulative Timesteps: 2,066,199,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2066199640...
Checkpoint 2066199640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.55131
Policy Entropy: 2.18186
Value Function Loss: 0.01743

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.53731
Value Function Update Magnitude: 0.59404

Collected Steps per Second: 22,351.71315
Overall Steps per Second: 10,580.60443

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.72827

Cumulative Model Updates: 247,752
Cumulative Timesteps: 2,066,249,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.38678
Policy Entropy: 2.19974
Value Function Loss: 0.01718

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.52570
Value Function Update Magnitude: 0.59267

Collected Steps per Second: 23,339.02790
Overall Steps per Second: 10,896.79607

Timestep Collection Time: 2.14233
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.58850

Cumulative Model Updates: 247,758
Cumulative Timesteps: 2,066,299,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2066299668...
Checkpoint 2066299668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.36673
Policy Entropy: 2.14531
Value Function Loss: 0.01813

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.52655
Value Function Update Magnitude: 0.60564

Collected Steps per Second: 22,840.62034
Overall Steps per Second: 10,768.08723

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.45427
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.64335

Cumulative Model Updates: 247,764
Cumulative Timesteps: 2,066,349,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.11476
Policy Entropy: 2.16196
Value Function Loss: 0.01731

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.61802

Collected Steps per Second: 23,207.05356
Overall Steps per Second: 11,112.35130

Timestep Collection Time: 2.15572
Timestep Consumption Time: 2.34629
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.50202

Cumulative Model Updates: 247,770
Cumulative Timesteps: 2,066,399,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2066399696...
Checkpoint 2066399696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.18776
Policy Entropy: 2.15598
Value Function Loss: 0.01753

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.53199
Value Function Update Magnitude: 0.63022

Collected Steps per Second: 22,695.51543
Overall Steps per Second: 10,737.92024

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.45371
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.65714

Cumulative Model Updates: 247,776
Cumulative Timesteps: 2,066,449,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.53777
Policy Entropy: 2.16811
Value Function Loss: 0.01737

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.61265

Collected Steps per Second: 23,068.81364
Overall Steps per Second: 10,874.92056

Timestep Collection Time: 2.16804
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.59902

Cumulative Model Updates: 247,782
Cumulative Timesteps: 2,066,499,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2066499718...
Checkpoint 2066499718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.73865
Policy Entropy: 2.19592
Value Function Loss: 0.01649

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.52672
Value Function Update Magnitude: 0.61321

Collected Steps per Second: 22,482.50432
Overall Steps per Second: 10,681.04154

Timestep Collection Time: 2.22466
Timestep Consumption Time: 2.45803
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.68269

Cumulative Model Updates: 247,788
Cumulative Timesteps: 2,066,549,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.44867
Policy Entropy: 2.20350
Value Function Loss: 0.01652

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.52974
Value Function Update Magnitude: 0.61473

Collected Steps per Second: 22,915.63256
Overall Steps per Second: 10,917.93406

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.39828
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.58072

Cumulative Model Updates: 247,794
Cumulative Timesteps: 2,066,599,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2066599746...
Checkpoint 2066599746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.60103
Policy Entropy: 2.22482
Value Function Loss: 0.01624

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 22,596.69960
Overall Steps per Second: 10,644.52198

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.48553
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.69913

Cumulative Model Updates: 247,800
Cumulative Timesteps: 2,066,649,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.75997
Policy Entropy: 2.22044
Value Function Loss: 0.01697

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.52112
Value Function Update Magnitude: 0.60181

Collected Steps per Second: 22,891.52815
Overall Steps per Second: 10,818.76928

Timestep Collection Time: 2.18439
Timestep Consumption Time: 2.43758
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.62197

Cumulative Model Updates: 247,806
Cumulative Timesteps: 2,066,699,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2066699770...
Checkpoint 2066699770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.49839
Policy Entropy: 2.22719
Value Function Loss: 0.01756

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.52811
Value Function Update Magnitude: 0.60280

Collected Steps per Second: 22,628.20770
Overall Steps per Second: 10,746.60966

Timestep Collection Time: 2.21069
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.65486

Cumulative Model Updates: 247,812
Cumulative Timesteps: 2,066,749,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.27233
Policy Entropy: 2.22027
Value Function Loss: 0.01662

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.60412

Collected Steps per Second: 23,274.49394
Overall Steps per Second: 10,903.83834

Timestep Collection Time: 2.14905
Timestep Consumption Time: 2.43814
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.58719

Cumulative Model Updates: 247,818
Cumulative Timesteps: 2,066,799,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2066799812...
Checkpoint 2066799812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.43755
Policy Entropy: 2.19776
Value Function Loss: 0.01678

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.52845
Value Function Update Magnitude: 0.58625

Collected Steps per Second: 22,968.92188
Overall Steps per Second: 10,682.52082

Timestep Collection Time: 2.17773
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.68242

Cumulative Model Updates: 247,824
Cumulative Timesteps: 2,066,849,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.50496
Policy Entropy: 2.18698
Value Function Loss: 0.01655

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.52662
Value Function Update Magnitude: 0.58373

Collected Steps per Second: 23,198.14675
Overall Steps per Second: 10,878.88995

Timestep Collection Time: 2.15543
Timestep Consumption Time: 2.44081
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.59624

Cumulative Model Updates: 247,830
Cumulative Timesteps: 2,066,899,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2066899834...
Checkpoint 2066899834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.45551
Policy Entropy: 2.18437
Value Function Loss: 0.01692

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.52533
Value Function Update Magnitude: 0.59191

Collected Steps per Second: 22,682.35897
Overall Steps per Second: 11,007.16167

Timestep Collection Time: 2.20559
Timestep Consumption Time: 2.33945
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.54504

Cumulative Model Updates: 247,836
Cumulative Timesteps: 2,066,949,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.75330
Policy Entropy: 2.19971
Value Function Loss: 0.01667

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.52991
Value Function Update Magnitude: 0.58837

Collected Steps per Second: 23,508.50057
Overall Steps per Second: 10,995.85750

Timestep Collection Time: 2.12732
Timestep Consumption Time: 2.42076
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.54808

Cumulative Model Updates: 247,842
Cumulative Timesteps: 2,066,999,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2066999872...
Checkpoint 2066999872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.69167
Policy Entropy: 2.18891
Value Function Loss: 0.01652

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.52577
Value Function Update Magnitude: 0.58562

Collected Steps per Second: 22,348.05961
Overall Steps per Second: 10,615.88525

Timestep Collection Time: 2.23742
Timestep Consumption Time: 2.47269
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.71011

Cumulative Model Updates: 247,848
Cumulative Timesteps: 2,067,049,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.92880
Policy Entropy: 2.18326
Value Function Loss: 0.01786

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.57825

Collected Steps per Second: 21,504.57644
Overall Steps per Second: 10,490.21679

Timestep Collection Time: 2.32555
Timestep Consumption Time: 2.44175
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.76730

Cumulative Model Updates: 247,854
Cumulative Timesteps: 2,067,099,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2067099884...
Checkpoint 2067099884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.31186
Policy Entropy: 2.16660
Value Function Loss: 0.01736

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.59255

Collected Steps per Second: 22,445.69894
Overall Steps per Second: 10,842.28101

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.38484
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.61324

Cumulative Model Updates: 247,860
Cumulative Timesteps: 2,067,149,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.12791
Policy Entropy: 2.17436
Value Function Loss: 0.01888

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.53684
Value Function Update Magnitude: 0.60304

Collected Steps per Second: 22,826.90569
Overall Steps per Second: 10,687.59351

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.48902
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68038

Cumulative Model Updates: 247,866
Cumulative Timesteps: 2,067,199,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2067199924...
Checkpoint 2067199924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.39992
Policy Entropy: 2.18610
Value Function Loss: 0.01806

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.62688

Collected Steps per Second: 22,316.18521
Overall Steps per Second: 10,652.23089

Timestep Collection Time: 2.24178
Timestep Consumption Time: 2.45470
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.69648

Cumulative Model Updates: 247,872
Cumulative Timesteps: 2,067,249,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.84638
Policy Entropy: 2.17092
Value Function Loss: 0.01889

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.63635

Collected Steps per Second: 23,249.19086
Overall Steps per Second: 10,845.61023

Timestep Collection Time: 2.15139
Timestep Consumption Time: 2.46043
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.61182

Cumulative Model Updates: 247,878
Cumulative Timesteps: 2,067,299,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2067299970...
Checkpoint 2067299970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.17446
Policy Entropy: 2.16350
Value Function Loss: 0.01773

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.54440
Value Function Update Magnitude: 0.64566

Collected Steps per Second: 22,456.04610
Overall Steps per Second: 10,755.05962

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.65121

Cumulative Model Updates: 247,884
Cumulative Timesteps: 2,067,349,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.10366
Policy Entropy: 2.15595
Value Function Loss: 0.01860

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.64385

Collected Steps per Second: 23,055.58581
Overall Steps per Second: 10,809.11531

Timestep Collection Time: 2.16876
Timestep Consumption Time: 2.45715
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.62591

Cumulative Model Updates: 247,890
Cumulative Timesteps: 2,067,399,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2067399996...
Checkpoint 2067399996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.58836
Policy Entropy: 2.14799
Value Function Loss: 0.01860

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.55198
Value Function Update Magnitude: 0.63446

Collected Steps per Second: 22,758.55404
Overall Steps per Second: 10,696.97546

Timestep Collection Time: 2.19794
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.67628

Cumulative Model Updates: 247,896
Cumulative Timesteps: 2,067,450,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.19476
Policy Entropy: 2.15932
Value Function Loss: 0.01778

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.54448
Value Function Update Magnitude: 0.64319

Collected Steps per Second: 23,141.32310
Overall Steps per Second: 10,893.57149

Timestep Collection Time: 2.16116
Timestep Consumption Time: 2.42981
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.59096

Cumulative Model Updates: 247,902
Cumulative Timesteps: 2,067,500,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2067500030...
Checkpoint 2067500030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.77802
Policy Entropy: 2.14179
Value Function Loss: 0.01700

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.63323

Collected Steps per Second: 22,877.01079
Overall Steps per Second: 10,704.53826

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.67148

Cumulative Model Updates: 247,908
Cumulative Timesteps: 2,067,550,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.88297
Policy Entropy: 2.15552
Value Function Loss: 0.01581

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.53645
Value Function Update Magnitude: 0.61126

Collected Steps per Second: 22,980.10482
Overall Steps per Second: 10,865.99859

Timestep Collection Time: 2.17710
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.60427

Cumulative Model Updates: 247,914
Cumulative Timesteps: 2,067,600,066

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2067600066...
Checkpoint 2067600066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.35690
Policy Entropy: 2.13587
Value Function Loss: 0.01666

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.53311
Value Function Update Magnitude: 0.59708

Collected Steps per Second: 22,158.54525
Overall Steps per Second: 10,636.06383

Timestep Collection Time: 2.25782
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.70381

Cumulative Model Updates: 247,920
Cumulative Timesteps: 2,067,650,096

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.19732
Policy Entropy: 2.15234
Value Function Loss: 0.01683

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.53575
Value Function Update Magnitude: 0.59454

Collected Steps per Second: 22,806.43301
Overall Steps per Second: 10,918.49320

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.38845
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.58213

Cumulative Model Updates: 247,926
Cumulative Timesteps: 2,067,700,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2067700126...
Checkpoint 2067700126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.52791
Policy Entropy: 2.15902
Value Function Loss: 0.01817

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.55433
Value Function Update Magnitude: 0.61393

Collected Steps per Second: 22,623.28931
Overall Steps per Second: 10,621.01715

Timestep Collection Time: 2.21091
Timestep Consumption Time: 2.49843
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.70934

Cumulative Model Updates: 247,932
Cumulative Timesteps: 2,067,750,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.34678
Policy Entropy: 2.15460
Value Function Loss: 0.01764

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.63419

Collected Steps per Second: 23,485.62399
Overall Steps per Second: 10,951.69872

Timestep Collection Time: 2.12990
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.56751

Cumulative Model Updates: 247,938
Cumulative Timesteps: 2,067,800,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2067800166...
Checkpoint 2067800166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.50965
Policy Entropy: 2.13356
Value Function Loss: 0.01724

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.62886

Collected Steps per Second: 22,758.51612
Overall Steps per Second: 10,718.64775

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.46917
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.66738

Cumulative Model Updates: 247,944
Cumulative Timesteps: 2,067,850,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.22789
Policy Entropy: 2.12933
Value Function Loss: 0.01651

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 23,936.21337
Overall Steps per Second: 10,952.95625

Timestep Collection Time: 2.08930
Timestep Consumption Time: 2.47659
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.56589

Cumulative Model Updates: 247,950
Cumulative Timesteps: 2,067,900,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2067900204...
Checkpoint 2067900204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.91751
Policy Entropy: 2.15217
Value Function Loss: 0.01609

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.53756
Value Function Update Magnitude: 0.61033

Collected Steps per Second: 22,477.11874
Overall Steps per Second: 10,591.39916

Timestep Collection Time: 2.22448
Timestep Consumption Time: 2.49633
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.72081

Cumulative Model Updates: 247,956
Cumulative Timesteps: 2,067,950,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.20206
Policy Entropy: 2.14418
Value Function Loss: 0.01639

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 23,334.94120
Overall Steps per Second: 10,830.91382

Timestep Collection Time: 2.14280
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.61660

Cumulative Model Updates: 247,962
Cumulative Timesteps: 2,068,000,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2068000206...
Checkpoint 2068000206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.79268
Policy Entropy: 2.13366
Value Function Loss: 0.01813

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.61437

Collected Steps per Second: 22,688.59280
Overall Steps per Second: 10,694.03144

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.47255
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.67700

Cumulative Model Updates: 247,968
Cumulative Timesteps: 2,068,050,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.66279
Policy Entropy: 2.12206
Value Function Loss: 0.01818

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.56909
Value Function Update Magnitude: 0.64550

Collected Steps per Second: 23,578.97381
Overall Steps per Second: 10,867.22645

Timestep Collection Time: 2.12079
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.60154

Cumulative Model Updates: 247,974
Cumulative Timesteps: 2,068,100,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2068100228...
Checkpoint 2068100228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.70727
Policy Entropy: 2.14577
Value Function Loss: 0.01737

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.11847
Policy Update Magnitude: 0.55467
Value Function Update Magnitude: 0.65022

Collected Steps per Second: 22,036.92372
Overall Steps per Second: 10,688.00226

Timestep Collection Time: 2.26919
Timestep Consumption Time: 2.40951
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.67870

Cumulative Model Updates: 247,980
Cumulative Timesteps: 2,068,150,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.14096
Policy Entropy: 2.18440
Value Function Loss: 0.01597

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.53658
Value Function Update Magnitude: 0.62737

Collected Steps per Second: 22,753.45255
Overall Steps per Second: 10,784.89212

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.63741

Cumulative Model Updates: 247,986
Cumulative Timesteps: 2,068,200,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2068200248...
Checkpoint 2068200248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.61421
Policy Entropy: 2.20839
Value Function Loss: 0.01599

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.11382
Policy Update Magnitude: 0.51903
Value Function Update Magnitude: 0.59523

Collected Steps per Second: 22,333.61736
Overall Steps per Second: 10,734.69803

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.65817

Cumulative Model Updates: 247,992
Cumulative Timesteps: 2,068,250,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.19980
Policy Entropy: 2.22083
Value Function Loss: 0.01601

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.51637
Value Function Update Magnitude: 0.56755

Collected Steps per Second: 23,612.99175
Overall Steps per Second: 10,875.03632

Timestep Collection Time: 2.11756
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.59787

Cumulative Model Updates: 247,998
Cumulative Timesteps: 2,068,300,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2068300254...
Checkpoint 2068300254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.58333
Policy Entropy: 2.20710
Value Function Loss: 0.01728

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.58121

Collected Steps per Second: 23,310.49261
Overall Steps per Second: 10,825.25575

Timestep Collection Time: 2.14573
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.62049

Cumulative Model Updates: 248,004
Cumulative Timesteps: 2,068,350,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.83932
Policy Entropy: 2.19469
Value Function Loss: 0.01722

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.53037
Value Function Update Magnitude: 0.60511

Collected Steps per Second: 23,056.31792
Overall Steps per Second: 10,817.40653

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.45426
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.62347

Cumulative Model Updates: 248,010
Cumulative Timesteps: 2,068,400,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2068400286...
Checkpoint 2068400286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.72711
Policy Entropy: 2.17319
Value Function Loss: 0.01674

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.62734

Collected Steps per Second: 22,738.08810
Overall Steps per Second: 10,873.55657

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.40089
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.60125

Cumulative Model Updates: 248,016
Cumulative Timesteps: 2,068,450,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.52621
Policy Entropy: 2.15677
Value Function Loss: 0.01641

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.63474

Collected Steps per Second: 24,176.62364
Overall Steps per Second: 11,060.38323

Timestep Collection Time: 2.06869
Timestep Consumption Time: 2.45321
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.52190

Cumulative Model Updates: 248,022
Cumulative Timesteps: 2,068,500,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2068500332...
Checkpoint 2068500332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.55392
Policy Entropy: 2.14342
Value Function Loss: 0.01710

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.54708
Value Function Update Magnitude: 0.63406

Collected Steps per Second: 22,223.40239
Overall Steps per Second: 10,617.44207

Timestep Collection Time: 2.25015
Timestep Consumption Time: 2.45965
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.70980

Cumulative Model Updates: 248,028
Cumulative Timesteps: 2,068,550,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.60949
Policy Entropy: 2.14980
Value Function Loss: 0.01708

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.63687

Collected Steps per Second: 22,812.35126
Overall Steps per Second: 10,880.69581

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.40388
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.59603

Cumulative Model Updates: 248,034
Cumulative Timesteps: 2,068,600,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2068600346...
Checkpoint 2068600346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.86490
Policy Entropy: 2.15263
Value Function Loss: 0.01771

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.64448

Collected Steps per Second: 22,246.45904
Overall Steps per Second: 10,714.43104

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.41925
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66698

Cumulative Model Updates: 248,040
Cumulative Timesteps: 2,068,650,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.88697
Policy Entropy: 2.14437
Value Function Loss: 0.01837

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.63857

Collected Steps per Second: 22,904.67513
Overall Steps per Second: 10,842.61274

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.42925
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61291

Cumulative Model Updates: 248,046
Cumulative Timesteps: 2,068,700,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2068700366...
Checkpoint 2068700366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.66843
Policy Entropy: 2.15258
Value Function Loss: 0.01879

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.55342
Value Function Update Magnitude: 0.61620

Collected Steps per Second: 22,583.86452
Overall Steps per Second: 10,655.37593

Timestep Collection Time: 2.21432
Timestep Consumption Time: 2.47889
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69322

Cumulative Model Updates: 248,052
Cumulative Timesteps: 2,068,750,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.83768
Policy Entropy: 2.17524
Value Function Loss: 0.01784

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.60421

Collected Steps per Second: 22,985.84447
Overall Steps per Second: 10,812.06952

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.44999
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.62594

Cumulative Model Updates: 248,058
Cumulative Timesteps: 2,068,800,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2068800390...
Checkpoint 2068800390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.97560
Policy Entropy: 2.18972
Value Function Loss: 0.01715

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.53358
Value Function Update Magnitude: 0.61183

Collected Steps per Second: 23,445.84086
Overall Steps per Second: 10,806.61317

Timestep Collection Time: 2.13257
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.62680

Cumulative Model Updates: 248,064
Cumulative Timesteps: 2,068,850,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.82686
Policy Entropy: 2.16488
Value Function Loss: 0.01689

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.62599

Collected Steps per Second: 23,384.74138
Overall Steps per Second: 10,828.22213

Timestep Collection Time: 2.13823
Timestep Consumption Time: 2.47952
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.61775

Cumulative Model Updates: 248,070
Cumulative Timesteps: 2,068,900,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2068900392...
Checkpoint 2068900392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.09414
Policy Entropy: 2.14892
Value Function Loss: 0.01752

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.53996
Value Function Update Magnitude: 0.63974

Collected Steps per Second: 22,926.23713
Overall Steps per Second: 10,764.60930

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.46424
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.64541

Cumulative Model Updates: 248,076
Cumulative Timesteps: 2,068,950,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.12590
Policy Entropy: 2.14867
Value Function Loss: 0.01681

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.64461

Collected Steps per Second: 23,200.54748
Overall Steps per Second: 10,899.16855

Timestep Collection Time: 2.15590
Timestep Consumption Time: 2.43326
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.58916

Cumulative Model Updates: 248,082
Cumulative Timesteps: 2,069,000,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2069000416...
Checkpoint 2069000416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.65434
Policy Entropy: 2.16462
Value Function Loss: 0.01724

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.53091
Value Function Update Magnitude: 0.63079

Collected Steps per Second: 23,247.96608
Overall Steps per Second: 10,944.52268

Timestep Collection Time: 2.15167
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.57051

Cumulative Model Updates: 248,088
Cumulative Timesteps: 2,069,050,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.87010
Policy Entropy: 2.17912
Value Function Loss: 0.01793

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.53440
Value Function Update Magnitude: 0.63379

Collected Steps per Second: 22,878.94174
Overall Steps per Second: 10,789.42753

Timestep Collection Time: 2.18559
Timestep Consumption Time: 2.44895
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.63454

Cumulative Model Updates: 248,094
Cumulative Timesteps: 2,069,100,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2069100442...
Checkpoint 2069100442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.18119
Policy Entropy: 2.16559
Value Function Loss: 0.01913

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.64124

Collected Steps per Second: 22,247.93759
Overall Steps per Second: 10,762.07401

Timestep Collection Time: 2.24803
Timestep Consumption Time: 2.39922
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.64725

Cumulative Model Updates: 248,100
Cumulative Timesteps: 2,069,150,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.98000
Policy Entropy: 2.15002
Value Function Loss: 0.01841

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.54114
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 23,038.96513
Overall Steps per Second: 10,946.44689

Timestep Collection Time: 2.17145
Timestep Consumption Time: 2.39880
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.57025

Cumulative Model Updates: 248,106
Cumulative Timesteps: 2,069,200,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2069200484...
Checkpoint 2069200484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.36766
Policy Entropy: 2.13179
Value Function Loss: 0.01754

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.54228
Value Function Update Magnitude: 0.62818

Collected Steps per Second: 22,572.08732
Overall Steps per Second: 10,633.85378

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70479

Cumulative Model Updates: 248,112
Cumulative Timesteps: 2,069,250,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.59658
Policy Entropy: 2.14335
Value Function Loss: 0.01622

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.62459

Collected Steps per Second: 23,280.17270
Overall Steps per Second: 10,786.91543

Timestep Collection Time: 2.14784
Timestep Consumption Time: 2.48759
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.63543

Cumulative Model Updates: 248,118
Cumulative Timesteps: 2,069,300,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2069300516...
Checkpoint 2069300516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.17481
Policy Entropy: 2.15615
Value Function Loss: 0.01738

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.63656

Collected Steps per Second: 22,606.71280
Overall Steps per Second: 10,739.53606

Timestep Collection Time: 2.21271
Timestep Consumption Time: 2.44504
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.65774

Cumulative Model Updates: 248,124
Cumulative Timesteps: 2,069,350,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.58204
Policy Entropy: 2.16017
Value Function Loss: 0.01793

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.54666
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 23,517.11474
Overall Steps per Second: 10,996.88306

Timestep Collection Time: 2.12696
Timestep Consumption Time: 2.42160
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.54856

Cumulative Model Updates: 248,130
Cumulative Timesteps: 2,069,400,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2069400558...
Checkpoint 2069400558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.43853
Policy Entropy: 2.14208
Value Function Loss: 0.01909

Mean KL Divergence: 0.03629
SB3 Clip Fraction: 0.18379
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.63955

Collected Steps per Second: 22,860.02715
Overall Steps per Second: 10,723.63964

Timestep Collection Time: 2.18801
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.66427

Cumulative Model Updates: 248,136
Cumulative Timesteps: 2,069,450,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.75831
Policy Entropy: 2.16198
Value Function Loss: 0.01800

Mean KL Divergence: 0.02950
SB3 Clip Fraction: 0.17332
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.65460

Collected Steps per Second: 23,319.19184
Overall Steps per Second: 10,729.11806

Timestep Collection Time: 2.14527
Timestep Consumption Time: 2.51737
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.66264

Cumulative Model Updates: 248,142
Cumulative Timesteps: 2,069,500,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2069500602...
Checkpoint 2069500602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.52564
Policy Entropy: 2.16567
Value Function Loss: 0.01647

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.54215
Value Function Update Magnitude: 0.64987

Collected Steps per Second: 22,967.17982
Overall Steps per Second: 11,028.60324

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.35749
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.53530

Cumulative Model Updates: 248,148
Cumulative Timesteps: 2,069,550,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.51125
Policy Entropy: 2.17712
Value Function Loss: 0.01615

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.54151
Value Function Update Magnitude: 0.62156

Collected Steps per Second: 22,684.26648
Overall Steps per Second: 10,671.65206

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.68868

Cumulative Model Updates: 248,154
Cumulative Timesteps: 2,069,600,656

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2069600656...
Checkpoint 2069600656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.86733
Policy Entropy: 2.17897
Value Function Loss: 0.01652

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.61069

Collected Steps per Second: 22,351.06075
Overall Steps per Second: 10,551.30339

Timestep Collection Time: 2.23748
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.73970

Cumulative Model Updates: 248,160
Cumulative Timesteps: 2,069,650,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.95190
Policy Entropy: 2.18603
Value Function Loss: 0.01811

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.62894

Collected Steps per Second: 22,847.69848
Overall Steps per Second: 10,816.22546

Timestep Collection Time: 2.18954
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62509

Cumulative Model Updates: 248,166
Cumulative Timesteps: 2,069,700,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2069700692...
Checkpoint 2069700692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.97929
Policy Entropy: 2.21415
Value Function Loss: 0.01724

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.64340

Collected Steps per Second: 22,559.03533
Overall Steps per Second: 10,776.53901

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.42359
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.64027

Cumulative Model Updates: 248,172
Cumulative Timesteps: 2,069,750,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.52754
Policy Entropy: 2.19638
Value Function Loss: 0.01782

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.63945

Collected Steps per Second: 23,488.02199
Overall Steps per Second: 10,857.06230

Timestep Collection Time: 2.12926
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.60640

Cumulative Model Updates: 248,178
Cumulative Timesteps: 2,069,800,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2069800710...
Checkpoint 2069800710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.58287
Policy Entropy: 2.16735
Value Function Loss: 0.01701

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.53698
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 22,601.88568
Overall Steps per Second: 10,607.78649

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.71352

Cumulative Model Updates: 248,184
Cumulative Timesteps: 2,069,850,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.51389
Policy Entropy: 2.14786
Value Function Loss: 0.01708

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.52855
Value Function Update Magnitude: 0.62914

Collected Steps per Second: 23,249.35599
Overall Steps per Second: 10,894.72944

Timestep Collection Time: 2.15094
Timestep Consumption Time: 2.43917
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.59011

Cumulative Model Updates: 248,190
Cumulative Timesteps: 2,069,900,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2069900718...
Checkpoint 2069900718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.49038
Policy Entropy: 2.14293
Value Function Loss: 0.01715

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.52363
Value Function Update Magnitude: 0.61682

Collected Steps per Second: 22,801.82925
Overall Steps per Second: 11,002.16279

Timestep Collection Time: 2.19333
Timestep Consumption Time: 2.35232
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.54565

Cumulative Model Updates: 248,196
Cumulative Timesteps: 2,069,950,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.43388
Policy Entropy: 2.18282
Value Function Loss: 0.01732

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.51364
Value Function Update Magnitude: 0.60846

Collected Steps per Second: 23,436.22799
Overall Steps per Second: 10,934.83768

Timestep Collection Time: 2.13430
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.57437

Cumulative Model Updates: 248,202
Cumulative Timesteps: 2,070,000,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2070000750...
Checkpoint 2070000750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.95678
Policy Entropy: 2.17172
Value Function Loss: 0.01820

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.53539
Value Function Update Magnitude: 0.63223

Collected Steps per Second: 22,385.76549
Overall Steps per Second: 10,745.34285

Timestep Collection Time: 2.23437
Timestep Consumption Time: 2.42049
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.65485

Cumulative Model Updates: 248,208
Cumulative Timesteps: 2,070,050,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.79143
Policy Entropy: 2.17572
Value Function Loss: 0.01759

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.53852
Value Function Update Magnitude: 0.63211

Collected Steps per Second: 22,776.17513
Overall Steps per Second: 10,913.08001

Timestep Collection Time: 2.19598
Timestep Consumption Time: 2.38715
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.58312

Cumulative Model Updates: 248,214
Cumulative Timesteps: 2,070,100,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2070100784...
Checkpoint 2070100784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.81206
Policy Entropy: 2.16330
Value Function Loss: 0.01718

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.52147
Value Function Update Magnitude: 0.62069

Collected Steps per Second: 22,435.10823
Overall Steps per Second: 10,642.44494

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.47011
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.69930

Cumulative Model Updates: 248,220
Cumulative Timesteps: 2,070,150,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.36722
Policy Entropy: 2.19248
Value Function Loss: 0.01783

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.52020
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 22,905.24054
Overall Steps per Second: 10,838.10941

Timestep Collection Time: 2.18308
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61372

Cumulative Model Updates: 248,226
Cumulative Timesteps: 2,070,200,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2070200800...
Checkpoint 2070200800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.06643
Policy Entropy: 2.17541
Value Function Loss: 0.01771

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.53442
Value Function Update Magnitude: 0.64117

Collected Steps per Second: 22,505.42726
Overall Steps per Second: 10,712.65865

Timestep Collection Time: 2.22258
Timestep Consumption Time: 2.44667
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.66924

Cumulative Model Updates: 248,232
Cumulative Timesteps: 2,070,250,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.55666
Policy Entropy: 2.18248
Value Function Loss: 0.01711

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.62842

Collected Steps per Second: 23,368.14873
Overall Steps per Second: 10,945.00680

Timestep Collection Time: 2.14078
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.57067

Cumulative Model Updates: 248,238
Cumulative Timesteps: 2,070,300,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2070300846...
Checkpoint 2070300846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.17999
Policy Entropy: 2.18402
Value Function Loss: 0.01687

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.52324
Value Function Update Magnitude: 0.61304

Collected Steps per Second: 22,696.85394
Overall Steps per Second: 10,638.90332

Timestep Collection Time: 2.20401
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.70199

Cumulative Model Updates: 248,244
Cumulative Timesteps: 2,070,350,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.29823
Policy Entropy: 2.20887
Value Function Loss: 0.01645

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.52457
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 23,282.64654
Overall Steps per Second: 10,853.31458

Timestep Collection Time: 2.14881
Timestep Consumption Time: 2.46084
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.60965

Cumulative Model Updates: 248,250
Cumulative Timesteps: 2,070,400,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2070400900...
Checkpoint 2070400900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.25582
Policy Entropy: 2.18821
Value Function Loss: 0.01818

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.51928
Value Function Update Magnitude: 0.62483

Collected Steps per Second: 22,627.54714
Overall Steps per Second: 10,843.16405

Timestep Collection Time: 2.21102
Timestep Consumption Time: 2.40295
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.61397

Cumulative Model Updates: 248,256
Cumulative Timesteps: 2,070,450,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.32055
Policy Entropy: 2.17336
Value Function Loss: 0.01783

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.51518
Value Function Update Magnitude: 0.63113

Collected Steps per Second: 23,568.28734
Overall Steps per Second: 10,867.06852

Timestep Collection Time: 2.12200
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.60216

Cumulative Model Updates: 248,262
Cumulative Timesteps: 2,070,500,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2070500942...
Checkpoint 2070500942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.97146
Policy Entropy: 2.15687
Value Function Loss: 0.01860

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.52055
Value Function Update Magnitude: 0.62271

Collected Steps per Second: 22,355.93602
Overall Steps per Second: 10,559.04961

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.73603

Cumulative Model Updates: 248,268
Cumulative Timesteps: 2,070,550,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.85419
Policy Entropy: 2.16749
Value Function Loss: 0.01701

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.51732
Value Function Update Magnitude: 0.61400

Collected Steps per Second: 22,859.70671
Overall Steps per Second: 10,922.42466

Timestep Collection Time: 2.18778
Timestep Consumption Time: 2.39106
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.57884

Cumulative Model Updates: 248,274
Cumulative Timesteps: 2,070,600,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2070600962...
Checkpoint 2070600962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.82524
Policy Entropy: 2.15872
Value Function Loss: 0.01705

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.62006

Collected Steps per Second: 22,359.03456
Overall Steps per Second: 10,949.58115

Timestep Collection Time: 2.23766
Timestep Consumption Time: 2.33164
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.56931

Cumulative Model Updates: 248,280
Cumulative Timesteps: 2,070,650,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.74885
Policy Entropy: 2.17787
Value Function Loss: 0.01632

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.52326
Value Function Update Magnitude: 0.63918

Collected Steps per Second: 23,008.13990
Overall Steps per Second: 10,759.04823

Timestep Collection Time: 2.17332
Timestep Consumption Time: 2.47431
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.64762

Cumulative Model Updates: 248,286
Cumulative Timesteps: 2,070,700,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2070700998...
Checkpoint 2070700998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.20456
Policy Entropy: 2.19422
Value Function Loss: 0.01671

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.51759
Value Function Update Magnitude: 0.64454

Collected Steps per Second: 22,476.61802
Overall Steps per Second: 10,575.28349

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72857

Cumulative Model Updates: 248,292
Cumulative Timesteps: 2,070,751,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.10634
Policy Entropy: 2.16762
Value Function Loss: 0.01774

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.53591
Value Function Update Magnitude: 0.61693

Collected Steps per Second: 23,274.72127
Overall Steps per Second: 11,006.00409

Timestep Collection Time: 2.14928
Timestep Consumption Time: 2.39587
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.54516

Cumulative Model Updates: 248,298
Cumulative Timesteps: 2,070,801,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2070801028...
Checkpoint 2070801028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.59845
Policy Entropy: 2.15175
Value Function Loss: 0.01776

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.53890
Value Function Update Magnitude: 0.60406

Collected Steps per Second: 22,841.92030
Overall Steps per Second: 10,902.40411

Timestep Collection Time: 2.18983
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.58798

Cumulative Model Updates: 248,304
Cumulative Timesteps: 2,070,851,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.92403
Policy Entropy: 2.12146
Value Function Loss: 0.01852

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.62415

Collected Steps per Second: 23,260.05492
Overall Steps per Second: 10,863.82719

Timestep Collection Time: 2.15012
Timestep Consumption Time: 2.45341
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.60353

Cumulative Model Updates: 248,310
Cumulative Timesteps: 2,070,901,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2070901060...
Checkpoint 2070901060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.81515
Policy Entropy: 2.14090
Value Function Loss: 0.01741

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.53904
Value Function Update Magnitude: 0.63189

Collected Steps per Second: 21,626.78951
Overall Steps per Second: 10,585.97533

Timestep Collection Time: 2.31241
Timestep Consumption Time: 2.41177
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.72417

Cumulative Model Updates: 248,316
Cumulative Timesteps: 2,070,951,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.00414
Policy Entropy: 2.15210
Value Function Loss: 0.01833

Mean KL Divergence: 0.02727
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.50927
Value Function Update Magnitude: 0.62023

Collected Steps per Second: 23,025.74539
Overall Steps per Second: 10,924.66731

Timestep Collection Time: 2.17183
Timestep Consumption Time: 2.40570
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.57753

Cumulative Model Updates: 248,322
Cumulative Timesteps: 2,071,001,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2071001078...
Checkpoint 2071001078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.44230
Policy Entropy: 2.16518
Value Function Loss: 0.01793

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.50261
Value Function Update Magnitude: 0.60114

Collected Steps per Second: 23,619.68175
Overall Steps per Second: 10,889.71796

Timestep Collection Time: 2.11739
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.59259

Cumulative Model Updates: 248,328
Cumulative Timesteps: 2,071,051,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.14180
Policy Entropy: 2.19674
Value Function Loss: 0.01723

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.50890
Value Function Update Magnitude: 0.57811

Collected Steps per Second: 23,031.21294
Overall Steps per Second: 10,713.49435

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.66962

Cumulative Model Updates: 248,334
Cumulative Timesteps: 2,071,101,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2071101118...
Checkpoint 2071101118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.69495
Policy Entropy: 2.21096
Value Function Loss: 0.01584

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.51027
Value Function Update Magnitude: 0.55279

Collected Steps per Second: 22,182.21608
Overall Steps per Second: 10,670.82112

Timestep Collection Time: 2.25532
Timestep Consumption Time: 2.43298
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.68830

Cumulative Model Updates: 248,340
Cumulative Timesteps: 2,071,151,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.76145
Policy Entropy: 2.21994
Value Function Loss: 0.01559

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.51220
Value Function Update Magnitude: 0.55094

Collected Steps per Second: 22,903.83006
Overall Steps per Second: 10,918.87192

Timestep Collection Time: 2.18426
Timestep Consumption Time: 2.39753
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.58179

Cumulative Model Updates: 248,346
Cumulative Timesteps: 2,071,201,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2071201174...
Checkpoint 2071201174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.11873
Policy Entropy: 2.19801
Value Function Loss: 0.01716

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.50843
Value Function Update Magnitude: 0.56570

Collected Steps per Second: 22,780.16990
Overall Steps per Second: 10,641.94864

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.70027

Cumulative Model Updates: 248,352
Cumulative Timesteps: 2,071,251,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.72850
Policy Entropy: 2.20199
Value Function Loss: 0.01752

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.52594
Value Function Update Magnitude: 0.58077

Collected Steps per Second: 23,685.40217
Overall Steps per Second: 10,880.19470

Timestep Collection Time: 2.11185
Timestep Consumption Time: 2.48549
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.59734

Cumulative Model Updates: 248,358
Cumulative Timesteps: 2,071,301,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2071301214...
Checkpoint 2071301214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.58197
Policy Entropy: 2.20369
Value Function Loss: 0.01801

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.51829
Value Function Update Magnitude: 0.57449

Collected Steps per Second: 22,667.00257
Overall Steps per Second: 10,663.52464

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.48343
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.68963

Cumulative Model Updates: 248,364
Cumulative Timesteps: 2,071,351,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.60504
Policy Entropy: 2.19922
Value Function Loss: 0.01867

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.52707
Value Function Update Magnitude: 0.57102

Collected Steps per Second: 22,981.68007
Overall Steps per Second: 10,889.92108

Timestep Collection Time: 2.17704
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.59434

Cumulative Model Updates: 248,370
Cumulative Timesteps: 2,071,401,254

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2071401254...
Checkpoint 2071401254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.63391
Policy Entropy: 2.20930
Value Function Loss: 0.01919

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.58752

Collected Steps per Second: 22,719.24959
Overall Steps per Second: 10,642.41029

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.69931

Cumulative Model Updates: 248,376
Cumulative Timesteps: 2,071,451,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.05446
Policy Entropy: 2.20887
Value Function Loss: 0.01821

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.51205
Value Function Update Magnitude: 0.60492

Collected Steps per Second: 23,227.55806
Overall Steps per Second: 10,907.18247

Timestep Collection Time: 2.15382
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.58670

Cumulative Model Updates: 248,382
Cumulative Timesteps: 2,071,501,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2071501294...
Checkpoint 2071501294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.04753
Policy Entropy: 2.20998
Value Function Loss: 0.01754

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.51745
Value Function Update Magnitude: 0.58824

Collected Steps per Second: 22,629.21296
Overall Steps per Second: 10,862.15210

Timestep Collection Time: 2.20962
Timestep Consumption Time: 2.39370
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.60332

Cumulative Model Updates: 248,388
Cumulative Timesteps: 2,071,551,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.12168
Policy Entropy: 2.21080
Value Function Loss: 0.01638

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.58145

Collected Steps per Second: 22,703.05510
Overall Steps per Second: 10,724.43468

Timestep Collection Time: 2.20332
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.66430

Cumulative Model Updates: 248,394
Cumulative Timesteps: 2,071,601,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2071601318...
Checkpoint 2071601318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.00791
Policy Entropy: 2.22347
Value Function Loss: 0.01716

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.51518
Value Function Update Magnitude: 0.57562

Collected Steps per Second: 22,404.95404
Overall Steps per Second: 10,624.53526

Timestep Collection Time: 2.23165
Timestep Consumption Time: 2.47444
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.70609

Cumulative Model Updates: 248,400
Cumulative Timesteps: 2,071,651,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.58290
Policy Entropy: 2.25250
Value Function Loss: 0.01668

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.56097

Collected Steps per Second: 22,708.18171
Overall Steps per Second: 10,832.81029

Timestep Collection Time: 2.20308
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61819

Cumulative Model Updates: 248,406
Cumulative Timesteps: 2,071,701,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2071701346...
Checkpoint 2071701346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.33403
Policy Entropy: 2.21432
Value Function Loss: 0.01835

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.51718
Value Function Update Magnitude: 0.55730

Collected Steps per Second: 22,193.39547
Overall Steps per Second: 10,704.04187

Timestep Collection Time: 2.25292
Timestep Consumption Time: 2.41821
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67113

Cumulative Model Updates: 248,412
Cumulative Timesteps: 2,071,751,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.22524
Policy Entropy: 2.22444
Value Function Loss: 0.01845

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.57786

Collected Steps per Second: 23,184.32227
Overall Steps per Second: 10,813.86761

Timestep Collection Time: 2.15784
Timestep Consumption Time: 2.46844
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62628

Cumulative Model Updates: 248,418
Cumulative Timesteps: 2,071,801,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2071801374...
Checkpoint 2071801374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.58932
Policy Entropy: 2.21366
Value Function Loss: 0.01833

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.52821
Value Function Update Magnitude: 0.61255

Collected Steps per Second: 22,282.08692
Overall Steps per Second: 10,678.39704

Timestep Collection Time: 2.24413
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.68273

Cumulative Model Updates: 248,424
Cumulative Timesteps: 2,071,851,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.02250
Policy Entropy: 2.23326
Value Function Loss: 0.01719

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.52938
Value Function Update Magnitude: 0.61569

Collected Steps per Second: 23,270.16561
Overall Steps per Second: 10,999.47720

Timestep Collection Time: 2.15031
Timestep Consumption Time: 2.39882
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.54913

Cumulative Model Updates: 248,430
Cumulative Timesteps: 2,071,901,416

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2071901416...
Checkpoint 2071901416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.41833
Policy Entropy: 2.22744
Value Function Loss: 0.01646

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.52483
Value Function Update Magnitude: 0.60786

Collected Steps per Second: 22,813.72358
Overall Steps per Second: 11,011.68187

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.35028
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.54318

Cumulative Model Updates: 248,436
Cumulative Timesteps: 2,071,951,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.94474
Policy Entropy: 2.22720
Value Function Loss: 0.01659

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.51768
Value Function Update Magnitude: 0.59181

Collected Steps per Second: 23,258.14838
Overall Steps per Second: 10,906.85255

Timestep Collection Time: 2.15082
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58647

Cumulative Model Updates: 248,442
Cumulative Timesteps: 2,072,001,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2072001468...
Checkpoint 2072001468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.40131
Policy Entropy: 2.22750
Value Function Loss: 0.01583

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.51203
Value Function Update Magnitude: 0.59558

Collected Steps per Second: 22,680.46437
Overall Steps per Second: 10,725.49915

Timestep Collection Time: 2.20454
Timestep Consumption Time: 2.45725
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.66179

Cumulative Model Updates: 248,448
Cumulative Timesteps: 2,072,051,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.30658
Policy Entropy: 2.20667
Value Function Loss: 0.01709

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.52012
Value Function Update Magnitude: 0.60168

Collected Steps per Second: 22,635.05598
Overall Steps per Second: 10,761.03534

Timestep Collection Time: 2.20949
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.64751

Cumulative Model Updates: 248,454
Cumulative Timesteps: 2,072,101,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2072101480...
Checkpoint 2072101480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.40613
Policy Entropy: 2.16132
Value Function Loss: 0.01798

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.52814
Value Function Update Magnitude: 0.60393

Collected Steps per Second: 22,582.98846
Overall Steps per Second: 10,798.60322

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.41656
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.63097

Cumulative Model Updates: 248,460
Cumulative Timesteps: 2,072,151,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.19409
Policy Entropy: 2.16621
Value Function Loss: 0.01693

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.52018
Value Function Update Magnitude: 0.58995

Collected Steps per Second: 23,152.70827
Overall Steps per Second: 10,903.84386

Timestep Collection Time: 2.16044
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.58737

Cumulative Model Updates: 248,466
Cumulative Timesteps: 2,072,201,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2072201508...
Checkpoint 2072201508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.07176
Policy Entropy: 2.16933
Value Function Loss: 0.01624

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.51740
Value Function Update Magnitude: 0.60538

Collected Steps per Second: 22,688.03650
Overall Steps per Second: 10,639.09377

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.70096

Cumulative Model Updates: 248,472
Cumulative Timesteps: 2,072,251,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.82510
Policy Entropy: 2.20368
Value Function Loss: 0.01527

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.50830
Value Function Update Magnitude: 0.61534

Collected Steps per Second: 23,072.58876
Overall Steps per Second: 10,851.72269

Timestep Collection Time: 2.16803
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60959

Cumulative Model Updates: 248,478
Cumulative Timesteps: 2,072,301,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2072301544...
Checkpoint 2072301544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.10634
Policy Entropy: 2.19647
Value Function Loss: 0.01686

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.51806
Value Function Update Magnitude: 0.60736

Collected Steps per Second: 22,639.63477
Overall Steps per Second: 10,637.61960

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70218

Cumulative Model Updates: 248,484
Cumulative Timesteps: 2,072,351,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.21697
Policy Entropy: 2.20667
Value Function Loss: 0.01717

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.52319
Value Function Update Magnitude: 0.61116

Collected Steps per Second: 24,122.07809
Overall Steps per Second: 10,907.73672

Timestep Collection Time: 2.07345
Timestep Consumption Time: 2.51192
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.58537

Cumulative Model Updates: 248,490
Cumulative Timesteps: 2,072,401,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2072401580...
Checkpoint 2072401580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.27275
Policy Entropy: 2.20022
Value Function Loss: 0.01699

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.52698
Value Function Update Magnitude: 0.61856

Collected Steps per Second: 22,881.07684
Overall Steps per Second: 10,672.84072

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.68835

Cumulative Model Updates: 248,496
Cumulative Timesteps: 2,072,451,618

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.48643
Policy Entropy: 2.17894
Value Function Loss: 0.01738

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.52901
Value Function Update Magnitude: 0.61607

Collected Steps per Second: 23,255.42243
Overall Steps per Second: 10,950.20368

Timestep Collection Time: 2.15021
Timestep Consumption Time: 2.41628
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.56649

Cumulative Model Updates: 248,502
Cumulative Timesteps: 2,072,501,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2072501622...
Checkpoint 2072501622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.93343
Policy Entropy: 2.18841
Value Function Loss: 0.01616

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.52902
Value Function Update Magnitude: 0.61885

Collected Steps per Second: 22,801.54198
Overall Steps per Second: 10,712.44230

Timestep Collection Time: 2.19380
Timestep Consumption Time: 2.47572
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.66952

Cumulative Model Updates: 248,508
Cumulative Timesteps: 2,072,551,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.31112
Policy Entropy: 2.20581
Value Function Loss: 0.01627

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.60903

Collected Steps per Second: 23,408.84509
Overall Steps per Second: 10,829.26637

Timestep Collection Time: 2.13671
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.61878

Cumulative Model Updates: 248,514
Cumulative Timesteps: 2,072,601,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2072601662...
Checkpoint 2072601662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.57597
Policy Entropy: 2.20693
Value Function Loss: 0.01573

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.51902
Value Function Update Magnitude: 0.59069

Collected Steps per Second: 22,398.32498
Overall Steps per Second: 10,647.18957

Timestep Collection Time: 2.23329
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.69814

Cumulative Model Updates: 248,520
Cumulative Timesteps: 2,072,651,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.82480
Policy Entropy: 2.19123
Value Function Loss: 0.01653

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.51192
Value Function Update Magnitude: 0.58286

Collected Steps per Second: 22,710.20910
Overall Steps per Second: 10,823.10352

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.41809
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61975

Cumulative Model Updates: 248,526
Cumulative Timesteps: 2,072,701,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2072701684...
Checkpoint 2072701684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.78477
Policy Entropy: 2.17996
Value Function Loss: 0.01668

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.51158
Value Function Update Magnitude: 0.59492

Collected Steps per Second: 22,759.05234
Overall Steps per Second: 10,764.73662

Timestep Collection Time: 2.19781
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.64665

Cumulative Model Updates: 248,532
Cumulative Timesteps: 2,072,751,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.99412
Policy Entropy: 2.17354
Value Function Loss: 0.01731

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.53103
Value Function Update Magnitude: 0.60241

Collected Steps per Second: 23,456.59177
Overall Steps per Second: 10,808.15280

Timestep Collection Time: 2.13177
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.62651

Cumulative Model Updates: 248,538
Cumulative Timesteps: 2,072,801,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2072801708...
Checkpoint 2072801708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.61229
Policy Entropy: 2.17986
Value Function Loss: 0.01720

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.54676
Value Function Update Magnitude: 0.60261

Collected Steps per Second: 22,755.06401
Overall Steps per Second: 10,679.78962

Timestep Collection Time: 2.19837
Timestep Consumption Time: 2.48562
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.68399

Cumulative Model Updates: 248,544
Cumulative Timesteps: 2,072,851,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.05265
Policy Entropy: 2.15986
Value Function Loss: 0.01747

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.53852
Value Function Update Magnitude: 0.62046

Collected Steps per Second: 22,222.33876
Overall Steps per Second: 10,628.26135

Timestep Collection Time: 2.25008
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.70463

Cumulative Model Updates: 248,550
Cumulative Timesteps: 2,072,901,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2072901734...
Checkpoint 2072901734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.37135
Policy Entropy: 2.20141
Value Function Loss: 0.01801

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.53176
Value Function Update Magnitude: 0.61578

Collected Steps per Second: 22,365.38597
Overall Steps per Second: 10,943.20770

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.33401
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.57014

Cumulative Model Updates: 248,556
Cumulative Timesteps: 2,072,951,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.28674
Policy Entropy: 2.21246
Value Function Loss: 0.01775

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.61805

Collected Steps per Second: 23,212.77248
Overall Steps per Second: 10,921.54130

Timestep Collection Time: 2.15433
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.57884

Cumulative Model Updates: 248,562
Cumulative Timesteps: 2,073,001,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2073001754...
Checkpoint 2073001754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.88424
Policy Entropy: 2.22350
Value Function Loss: 0.01654

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.51179
Value Function Update Magnitude: 0.61927

Collected Steps per Second: 22,567.66305
Overall Steps per Second: 10,607.77345

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.71447

Cumulative Model Updates: 248,568
Cumulative Timesteps: 2,073,051,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.83564
Policy Entropy: 2.21299
Value Function Loss: 0.01634

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.51549
Value Function Update Magnitude: 0.60797

Collected Steps per Second: 23,485.56725
Overall Steps per Second: 10,982.56000

Timestep Collection Time: 2.12897
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.55267

Cumulative Model Updates: 248,574
Cumulative Timesteps: 2,073,101,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2073101764...
Checkpoint 2073101764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.30893
Policy Entropy: 2.19001
Value Function Loss: 0.01696

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.63409

Collected Steps per Second: 22,816.36200
Overall Steps per Second: 10,687.55385

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.67890

Cumulative Model Updates: 248,580
Cumulative Timesteps: 2,073,151,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.59978
Policy Entropy: 2.19866
Value Function Loss: 0.01705

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.53249
Value Function Update Magnitude: 0.64477

Collected Steps per Second: 23,272.78168
Overall Steps per Second: 10,790.86692

Timestep Collection Time: 2.14964
Timestep Consumption Time: 2.48651
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.63614

Cumulative Model Updates: 248,586
Cumulative Timesteps: 2,073,201,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2073201798...
Checkpoint 2073201798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.66889
Policy Entropy: 2.18481
Value Function Loss: 0.01723

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.52561
Value Function Update Magnitude: 0.64734

Collected Steps per Second: 22,707.51629
Overall Steps per Second: 10,715.34390

Timestep Collection Time: 2.20262
Timestep Consumption Time: 2.46508
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.66770

Cumulative Model Updates: 248,592
Cumulative Timesteps: 2,073,251,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.49829
Policy Entropy: 2.21419
Value Function Loss: 0.01621

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.65084

Collected Steps per Second: 23,451.37696
Overall Steps per Second: 11,043.03214

Timestep Collection Time: 2.13241
Timestep Consumption Time: 2.39605
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.52847

Cumulative Model Updates: 248,598
Cumulative Timesteps: 2,073,301,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2073301822...
Checkpoint 2073301822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.84786
Policy Entropy: 2.18200
Value Function Loss: 0.01675

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.51595
Value Function Update Magnitude: 0.63240

Collected Steps per Second: 22,774.77210
Overall Steps per Second: 10,821.97190

Timestep Collection Time: 2.19568
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62078

Cumulative Model Updates: 248,604
Cumulative Timesteps: 2,073,351,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.40753
Policy Entropy: 2.19208
Value Function Loss: 0.01709

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.16191
Policy Update Magnitude: 0.53199
Value Function Update Magnitude: 0.61596

Collected Steps per Second: 22,653.66571
Overall Steps per Second: 10,628.31280

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.70724

Cumulative Model Updates: 248,610
Cumulative Timesteps: 2,073,401,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2073401858...
Checkpoint 2073401858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.44459
Policy Entropy: 2.16704
Value Function Loss: 0.01796

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 22,464.03457
Overall Steps per Second: 10,681.98389

Timestep Collection Time: 2.22649
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.68228

Cumulative Model Updates: 248,616
Cumulative Timesteps: 2,073,451,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.79139
Policy Entropy: 2.17950
Value Function Loss: 0.01792

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.54348
Value Function Update Magnitude: 0.61171

Collected Steps per Second: 22,931.44037
Overall Steps per Second: 10,766.50042

Timestep Collection Time: 2.18076
Timestep Consumption Time: 2.46402
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.64478

Cumulative Model Updates: 248,622
Cumulative Timesteps: 2,073,501,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2073501882...
Checkpoint 2073501882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.33122
Policy Entropy: 2.18331
Value Function Loss: 0.01713

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.53190
Value Function Update Magnitude: 0.63958

Collected Steps per Second: 23,277.21235
Overall Steps per Second: 10,705.91332

Timestep Collection Time: 2.14828
Timestep Consumption Time: 2.52260
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.67088

Cumulative Model Updates: 248,628
Cumulative Timesteps: 2,073,551,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.47445
Policy Entropy: 2.17506
Value Function Loss: 0.01633

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.52517
Value Function Update Magnitude: 0.63151

Collected Steps per Second: 23,160.58621
Overall Steps per Second: 10,818.98571

Timestep Collection Time: 2.15996
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.62391

Cumulative Model Updates: 248,634
Cumulative Timesteps: 2,073,601,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2073601914...
Checkpoint 2073601914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.06260
Policy Entropy: 2.18968
Value Function Loss: 0.01559

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.52500
Value Function Update Magnitude: 0.62654

Collected Steps per Second: 22,480.65204
Overall Steps per Second: 10,685.20592

Timestep Collection Time: 2.22485
Timestep Consumption Time: 2.45602
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.68086

Cumulative Model Updates: 248,640
Cumulative Timesteps: 2,073,651,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.80107
Policy Entropy: 2.14435
Value Function Loss: 0.01628

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.52440
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 23,432.63569
Overall Steps per Second: 11,018.10793

Timestep Collection Time: 2.13497
Timestep Consumption Time: 2.40555
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.54053

Cumulative Model Updates: 248,646
Cumulative Timesteps: 2,073,701,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2073701958...
Checkpoint 2073701958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.79827
Policy Entropy: 2.15213
Value Function Loss: 0.01752

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.52852
Value Function Update Magnitude: 0.64091

Collected Steps per Second: 23,145.09159
Overall Steps per Second: 10,882.49092

Timestep Collection Time: 2.16141
Timestep Consumption Time: 2.43552
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59693

Cumulative Model Updates: 248,652
Cumulative Timesteps: 2,073,751,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.24567
Policy Entropy: 2.14612
Value Function Loss: 0.01779

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.64502

Collected Steps per Second: 22,691.82243
Overall Steps per Second: 10,665.74916

Timestep Collection Time: 2.20379
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.68865

Cumulative Model Updates: 248,658
Cumulative Timesteps: 2,073,801,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2073801992...
Checkpoint 2073801992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.99489
Policy Entropy: 2.13974
Value Function Loss: 0.01852

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.54495
Value Function Update Magnitude: 0.64632

Collected Steps per Second: 22,625.56601
Overall Steps per Second: 10,739.55154

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.65848

Cumulative Model Updates: 248,664
Cumulative Timesteps: 2,073,852,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.36426
Policy Entropy: 2.14891
Value Function Loss: 0.01717

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.53528
Value Function Update Magnitude: 0.62494

Collected Steps per Second: 23,048.45672
Overall Steps per Second: 10,965.53166

Timestep Collection Time: 2.17047
Timestep Consumption Time: 2.39164
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.56211

Cumulative Model Updates: 248,670
Cumulative Timesteps: 2,073,902,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2073902048...
Checkpoint 2073902048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.76091
Policy Entropy: 2.14632
Value Function Loss: 0.01722

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.52220
Value Function Update Magnitude: 0.61470

Collected Steps per Second: 22,450.19447
Overall Steps per Second: 10,749.59460

Timestep Collection Time: 2.22715
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.65134

Cumulative Model Updates: 248,676
Cumulative Timesteps: 2,073,952,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.66624
Policy Entropy: 2.16875
Value Function Loss: 0.01684

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.52532
Value Function Update Magnitude: 0.60705

Collected Steps per Second: 22,437.80542
Overall Steps per Second: 10,544.32478

Timestep Collection Time: 2.22883
Timestep Consumption Time: 2.51401
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.74284

Cumulative Model Updates: 248,682
Cumulative Timesteps: 2,074,002,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2074002058...
Checkpoint 2074002058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.86426
Policy Entropy: 2.15394
Value Function Loss: 0.01689

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.52918
Value Function Update Magnitude: 0.62170

Collected Steps per Second: 22,393.61889
Overall Steps per Second: 10,682.71580

Timestep Collection Time: 2.23349
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.68196

Cumulative Model Updates: 248,688
Cumulative Timesteps: 2,074,052,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.30295
Policy Entropy: 2.17386
Value Function Loss: 0.01709

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.52593
Value Function Update Magnitude: 0.64051

Collected Steps per Second: 23,382.54669
Overall Steps per Second: 10,923.80682

Timestep Collection Time: 2.13920
Timestep Consumption Time: 2.43979
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.57899

Cumulative Model Updates: 248,694
Cumulative Timesteps: 2,074,102,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2074102094...
Checkpoint 2074102094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.86953
Policy Entropy: 2.18816
Value Function Loss: 0.01760

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.64894

Collected Steps per Second: 23,097.32390
Overall Steps per Second: 10,763.14229

Timestep Collection Time: 2.16605
Timestep Consumption Time: 2.48222
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.64827

Cumulative Model Updates: 248,700
Cumulative Timesteps: 2,074,152,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.11461
Policy Entropy: 2.19247
Value Function Loss: 0.01756

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.52513
Value Function Update Magnitude: 0.64420

Collected Steps per Second: 23,125.31845
Overall Steps per Second: 10,780.06947

Timestep Collection Time: 2.16265
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.63930

Cumulative Model Updates: 248,706
Cumulative Timesteps: 2,074,202,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2074202136...
Checkpoint 2074202136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.90888
Policy Entropy: 2.20923
Value Function Loss: 0.01776

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.52385
Value Function Update Magnitude: 0.62856

Collected Steps per Second: 22,678.52904
Overall Steps per Second: 10,713.76061

Timestep Collection Time: 2.20579
Timestep Consumption Time: 2.46335
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.66914

Cumulative Model Updates: 248,712
Cumulative Timesteps: 2,074,252,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.36621
Policy Entropy: 2.19784
Value Function Loss: 0.01781

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.52280
Value Function Update Magnitude: 0.62742

Collected Steps per Second: 23,076.87588
Overall Steps per Second: 10,916.89667

Timestep Collection Time: 2.16771
Timestep Consumption Time: 2.41454
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.58225

Cumulative Model Updates: 248,718
Cumulative Timesteps: 2,074,302,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2074302184...
Checkpoint 2074302184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.53264
Policy Entropy: 2.21617
Value Function Loss: 0.01694

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.53016
Value Function Update Magnitude: 0.64830

Collected Steps per Second: 23,142.13406
Overall Steps per Second: 10,898.49892

Timestep Collection Time: 2.16082
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.58834

Cumulative Model Updates: 248,724
Cumulative Timesteps: 2,074,352,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.76206
Policy Entropy: 2.19754
Value Function Loss: 0.01729

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.52667
Value Function Update Magnitude: 0.65081

Collected Steps per Second: 22,413.92034
Overall Steps per Second: 10,527.99310

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.51959
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.75133

Cumulative Model Updates: 248,730
Cumulative Timesteps: 2,074,402,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2074402212...
Checkpoint 2074402212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.71591
Policy Entropy: 2.20919
Value Function Loss: 0.01815

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.52870
Value Function Update Magnitude: 0.63935

Collected Steps per Second: 22,447.99683
Overall Steps per Second: 10,650.63329

Timestep Collection Time: 2.22799
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.69587

Cumulative Model Updates: 248,736
Cumulative Timesteps: 2,074,452,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.73086
Policy Entropy: 2.17536
Value Function Loss: 0.01896

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.53717
Value Function Update Magnitude: 0.64347

Collected Steps per Second: 22,924.26623
Overall Steps per Second: 10,902.29398

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.40577
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.58747

Cumulative Model Updates: 248,742
Cumulative Timesteps: 2,074,502,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2074502240...
Checkpoint 2074502240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.58965
Policy Entropy: 2.18850
Value Function Loss: 0.01917

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.65544

Collected Steps per Second: 22,306.62347
Overall Steps per Second: 10,595.42722

Timestep Collection Time: 2.24283
Timestep Consumption Time: 2.47902
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.72185

Cumulative Model Updates: 248,748
Cumulative Timesteps: 2,074,552,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.47901
Policy Entropy: 2.18392
Value Function Loss: 0.01841

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.66308

Collected Steps per Second: 23,148.65490
Overall Steps per Second: 10,689.61754

Timestep Collection Time: 2.16064
Timestep Consumption Time: 2.51829
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.67893

Cumulative Model Updates: 248,754
Cumulative Timesteps: 2,074,602,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2074602286...
Checkpoint 2074602286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.65170
Policy Entropy: 2.20877
Value Function Loss: 0.01716

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.52654
Value Function Update Magnitude: 0.67496

Collected Steps per Second: 22,934.99940
Overall Steps per Second: 10,874.88509

Timestep Collection Time: 2.18068
Timestep Consumption Time: 2.41835
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.59904

Cumulative Model Updates: 248,760
Cumulative Timesteps: 2,074,652,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.23827
Policy Entropy: 2.20161
Value Function Loss: 0.01654

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.51976
Value Function Update Magnitude: 0.64821

Collected Steps per Second: 24,173.77558
Overall Steps per Second: 10,935.69242

Timestep Collection Time: 2.06960
Timestep Consumption Time: 2.50533
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.57493

Cumulative Model Updates: 248,766
Cumulative Timesteps: 2,074,702,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2074702330...
Checkpoint 2074702330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.01655
Policy Entropy: 2.17073
Value Function Loss: 0.01715

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.62743

Collected Steps per Second: 22,851.83790
Overall Steps per Second: 10,658.66718

Timestep Collection Time: 2.18836
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.69177

Cumulative Model Updates: 248,772
Cumulative Timesteps: 2,074,752,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.10086
Policy Entropy: 2.16369
Value Function Loss: 0.01669

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.62385

Collected Steps per Second: 22,875.73209
Overall Steps per Second: 10,622.87687

Timestep Collection Time: 2.18633
Timestep Consumption Time: 2.52181
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.70814

Cumulative Model Updates: 248,778
Cumulative Timesteps: 2,074,802,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2074802352...
Checkpoint 2074802352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.88479
Policy Entropy: 2.14676
Value Function Loss: 0.01806

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.62189

Collected Steps per Second: 23,072.84679
Overall Steps per Second: 10,910.01183

Timestep Collection Time: 2.16826
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.58551

Cumulative Model Updates: 248,784
Cumulative Timesteps: 2,074,852,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.31042
Policy Entropy: 2.16883
Value Function Loss: 0.01711

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.63969

Collected Steps per Second: 22,765.66104
Overall Steps per Second: 10,733.61057

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.46335
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.66087

Cumulative Model Updates: 248,790
Cumulative Timesteps: 2,074,902,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2074902408...
Checkpoint 2074902408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.39060
Policy Entropy: 2.18343
Value Function Loss: 0.01806

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.52746
Value Function Update Magnitude: 0.64693

Collected Steps per Second: 22,357.64890
Overall Steps per Second: 10,634.26419

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.46630
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.70348

Cumulative Model Updates: 248,796
Cumulative Timesteps: 2,074,952,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.76536
Policy Entropy: 2.18244
Value Function Loss: 0.01702

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.52613
Value Function Update Magnitude: 0.65100

Collected Steps per Second: 22,541.37405
Overall Steps per Second: 10,673.31733

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.46683
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68533

Cumulative Model Updates: 248,802
Cumulative Timesteps: 2,075,002,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2075002434...
Checkpoint 2075002434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.40507
Policy Entropy: 2.17811
Value Function Loss: 0.01780

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.54083
Value Function Update Magnitude: 0.63114

Collected Steps per Second: 22,730.44143
Overall Steps per Second: 10,784.37720

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.63652

Cumulative Model Updates: 248,808
Cumulative Timesteps: 2,075,052,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.92938
Policy Entropy: 2.14597
Value Function Loss: 0.01833

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.62497

Collected Steps per Second: 23,324.44601
Overall Steps per Second: 10,764.26682

Timestep Collection Time: 2.14470
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.64723

Cumulative Model Updates: 248,814
Cumulative Timesteps: 2,075,102,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2075102460...
Checkpoint 2075102460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.00353
Policy Entropy: 2.16090
Value Function Loss: 0.01855

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 23,034.34413
Overall Steps per Second: 10,735.24814

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.48708
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.65793

Cumulative Model Updates: 248,820
Cumulative Timesteps: 2,075,152,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.19453
Policy Entropy: 2.15430
Value Function Loss: 0.01804

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.53322
Value Function Update Magnitude: 0.62442

Collected Steps per Second: 22,591.74317
Overall Steps per Second: 10,835.35886

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.40248
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.61674

Cumulative Model Updates: 248,826
Cumulative Timesteps: 2,075,202,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2075202488...
Checkpoint 2075202488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.41854
Policy Entropy: 2.19670
Value Function Loss: 0.01732

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.52603
Value Function Update Magnitude: 0.61673

Collected Steps per Second: 22,889.97538
Overall Steps per Second: 11,016.25370

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.35561
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.54111

Cumulative Model Updates: 248,832
Cumulative Timesteps: 2,075,252,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.71108
Policy Entropy: 2.19942
Value Function Loss: 0.01618

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.51562
Value Function Update Magnitude: 0.61533

Collected Steps per Second: 23,255.98160
Overall Steps per Second: 10,935.77844

Timestep Collection Time: 2.15016
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.57251

Cumulative Model Updates: 248,838
Cumulative Timesteps: 2,075,302,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2075302518...
Checkpoint 2075302518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.80936
Policy Entropy: 2.19834
Value Function Loss: 0.01631

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.52924
Value Function Update Magnitude: 0.60237

Collected Steps per Second: 22,393.59260
Overall Steps per Second: 10,679.14922

Timestep Collection Time: 2.23332
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.68314

Cumulative Model Updates: 248,844
Cumulative Timesteps: 2,075,352,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.89270
Policy Entropy: 2.17660
Value Function Loss: 0.01699

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.52562
Value Function Update Magnitude: 0.59197

Collected Steps per Second: 22,490.86713
Overall Steps per Second: 10,863.49701

Timestep Collection Time: 2.22312
Timestep Consumption Time: 2.37944
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.60257

Cumulative Model Updates: 248,850
Cumulative Timesteps: 2,075,402,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2075402530...
Checkpoint 2075402530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.98156
Policy Entropy: 2.16000
Value Function Loss: 0.01747

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.52667
Value Function Update Magnitude: 0.59176

Collected Steps per Second: 22,619.81095
Overall Steps per Second: 10,658.30072

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.69306

Cumulative Model Updates: 248,856
Cumulative Timesteps: 2,075,452,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.17828
Policy Entropy: 2.19556
Value Function Loss: 0.01759

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.53254
Value Function Update Magnitude: 0.60144

Collected Steps per Second: 22,619.04886
Overall Steps per Second: 10,615.98798

Timestep Collection Time: 2.21097
Timestep Consumption Time: 2.49985
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.71082

Cumulative Model Updates: 248,862
Cumulative Timesteps: 2,075,502,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2075502560...
Checkpoint 2075502560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.49955
Policy Entropy: 2.19314
Value Function Loss: 0.01684

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.52758
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 22,951.98331
Overall Steps per Second: 10,918.39143

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.40202
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.58144

Cumulative Model Updates: 248,868
Cumulative Timesteps: 2,075,552,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.35279
Policy Entropy: 2.20744
Value Function Loss: 0.01644

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.52534
Value Function Update Magnitude: 0.61232

Collected Steps per Second: 23,071.17243
Overall Steps per Second: 10,926.23745

Timestep Collection Time: 2.16738
Timestep Consumption Time: 2.40913
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.57651

Cumulative Model Updates: 248,874
Cumulative Timesteps: 2,075,602,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2075602586...
Checkpoint 2075602586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.09146
Policy Entropy: 2.14901
Value Function Loss: 0.01780

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.53827
Value Function Update Magnitude: 0.63053

Collected Steps per Second: 23,170.85319
Overall Steps per Second: 10,809.92609

Timestep Collection Time: 2.15831
Timestep Consumption Time: 2.46799
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.62630

Cumulative Model Updates: 248,880
Cumulative Timesteps: 2,075,652,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.58008
Policy Entropy: 2.17052
Value Function Loss: 0.01823

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 23,267.87224
Overall Steps per Second: 10,754.27667

Timestep Collection Time: 2.14906
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.64969

Cumulative Model Updates: 248,886
Cumulative Timesteps: 2,075,702,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2075702600...
Checkpoint 2075702600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.29883
Policy Entropy: 2.15015
Value Function Loss: 0.01855

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.54372
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 22,711.24902
Overall Steps per Second: 10,750.81675

Timestep Collection Time: 2.20199
Timestep Consumption Time: 2.44975
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.65174

Cumulative Model Updates: 248,892
Cumulative Timesteps: 2,075,752,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.39727
Policy Entropy: 2.17945
Value Function Loss: 0.01851

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.59597

Collected Steps per Second: 23,237.33450
Overall Steps per Second: 11,015.65638

Timestep Collection Time: 2.15248
Timestep Consumption Time: 2.38814
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.54063

Cumulative Model Updates: 248,898
Cumulative Timesteps: 2,075,802,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2075802628...
Checkpoint 2075802628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.34736
Policy Entropy: 2.16403
Value Function Loss: 0.01845

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.60393

Collected Steps per Second: 22,849.10480
Overall Steps per Second: 10,866.86099

Timestep Collection Time: 2.18958
Timestep Consumption Time: 2.41432
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.60391

Cumulative Model Updates: 248,904
Cumulative Timesteps: 2,075,852,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.11893
Policy Entropy: 2.16814
Value Function Loss: 0.01930

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.61076

Collected Steps per Second: 22,502.64380
Overall Steps per Second: 10,599.96070

Timestep Collection Time: 2.22294
Timestep Consumption Time: 2.49614
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.71907

Cumulative Model Updates: 248,910
Cumulative Timesteps: 2,075,902,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2075902680...
Checkpoint 2075902680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.25102
Policy Entropy: 2.17873
Value Function Loss: 0.01901

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.53732
Value Function Update Magnitude: 0.61095

Collected Steps per Second: 22,583.35041
Overall Steps per Second: 10,742.69940

Timestep Collection Time: 2.21553
Timestep Consumption Time: 2.44196
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.65749

Cumulative Model Updates: 248,916
Cumulative Timesteps: 2,075,952,714

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.13343
Policy Entropy: 2.17461
Value Function Loss: 0.01841

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 22,527.34928
Overall Steps per Second: 10,735.26704

Timestep Collection Time: 2.21970
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.65792

Cumulative Model Updates: 248,922
Cumulative Timesteps: 2,076,002,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2076002718...
Checkpoint 2076002718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.02057
Policy Entropy: 2.20035
Value Function Loss: 0.01834

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.16092
Policy Update Magnitude: 0.50686
Value Function Update Magnitude: 0.63747

Collected Steps per Second: 22,827.65141
Overall Steps per Second: 10,638.21484

Timestep Collection Time: 2.19120
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70192

Cumulative Model Updates: 248,928
Cumulative Timesteps: 2,076,052,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.67453
Policy Entropy: 2.20119
Value Function Loss: 0.01778

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.64445

Collected Steps per Second: 23,267.47441
Overall Steps per Second: 10,892.57605

Timestep Collection Time: 2.14978
Timestep Consumption Time: 2.44234
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.59212

Cumulative Model Updates: 248,934
Cumulative Timesteps: 2,076,102,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2076102758...
Checkpoint 2076102758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.18617
Policy Entropy: 2.19352
Value Function Loss: 0.01724

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.53855
Value Function Update Magnitude: 0.65713

Collected Steps per Second: 22,986.10088
Overall Steps per Second: 10,815.07987

Timestep Collection Time: 2.17566
Timestep Consumption Time: 2.44844
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.62410

Cumulative Model Updates: 248,940
Cumulative Timesteps: 2,076,152,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.33062
Policy Entropy: 2.15771
Value Function Loss: 0.01634

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.52231
Value Function Update Magnitude: 0.61946

Collected Steps per Second: 23,472.89171
Overall Steps per Second: 11,117.22734

Timestep Collection Time: 2.13088
Timestep Consumption Time: 2.36826
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.49914

Cumulative Model Updates: 248,946
Cumulative Timesteps: 2,076,202,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2076202786...
Checkpoint 2076202786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.41963
Policy Entropy: 2.17434
Value Function Loss: 0.01642

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.51437
Value Function Update Magnitude: 0.59988

Collected Steps per Second: 22,794.33854
Overall Steps per Second: 10,671.96534

Timestep Collection Time: 2.19432
Timestep Consumption Time: 2.49254
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.68686

Cumulative Model Updates: 248,952
Cumulative Timesteps: 2,076,252,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.78133
Policy Entropy: 2.19479
Value Function Loss: 0.01648

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.50843
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 23,329.09553
Overall Steps per Second: 10,950.19292

Timestep Collection Time: 2.14325
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.56613

Cumulative Model Updates: 248,958
Cumulative Timesteps: 2,076,302,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2076302804...
Checkpoint 2076302804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.27023
Policy Entropy: 2.17522
Value Function Loss: 0.01739

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.51057
Value Function Update Magnitude: 0.61927

Collected Steps per Second: 22,904.13732
Overall Steps per Second: 11,051.95395

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.34285
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.52753

Cumulative Model Updates: 248,964
Cumulative Timesteps: 2,076,352,842

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.31743
Policy Entropy: 2.14341
Value Function Loss: 0.01814

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.53227
Value Function Update Magnitude: 0.64186

Collected Steps per Second: 22,411.98130
Overall Steps per Second: 10,563.43114

Timestep Collection Time: 2.23220
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.73596

Cumulative Model Updates: 248,970
Cumulative Timesteps: 2,076,402,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2076402870...
Checkpoint 2076402870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.77643
Policy Entropy: 2.12149
Value Function Loss: 0.01792

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.53402
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 22,434.31973
Overall Steps per Second: 10,602.65099

Timestep Collection Time: 2.22917
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.71674

Cumulative Model Updates: 248,976
Cumulative Timesteps: 2,076,452,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.90820
Policy Entropy: 2.13637
Value Function Loss: 0.01863

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.53404
Value Function Update Magnitude: 0.66572

Collected Steps per Second: 22,685.93731
Overall Steps per Second: 10,843.87124

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.40728
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.61164

Cumulative Model Updates: 248,982
Cumulative Timesteps: 2,076,502,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2076502888...
Checkpoint 2076502888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.09853
Policy Entropy: 2.14635
Value Function Loss: 0.01926

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.50343
Value Function Update Magnitude: 0.66109

Collected Steps per Second: 21,615.91915
Overall Steps per Second: 10,286.11850

Timestep Collection Time: 2.31441
Timestep Consumption Time: 2.54924
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.86364

Cumulative Model Updates: 248,988
Cumulative Timesteps: 2,076,552,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.99610
Policy Entropy: 2.16379
Value Function Loss: 0.02022

Mean KL Divergence: 0.02922
SB3 Clip Fraction: 0.16777
Policy Update Magnitude: 0.48817
Value Function Update Magnitude: 0.66794

Collected Steps per Second: 21,906.26561
Overall Steps per Second: 10,437.27534

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.79167

Cumulative Model Updates: 248,994
Cumulative Timesteps: 2,076,602,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2076602928...
Checkpoint 2076602928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.82584
Policy Entropy: 2.18437
Value Function Loss: 0.01924

Mean KL Divergence: 0.03522
SB3 Clip Fraction: 0.17837
Policy Update Magnitude: 0.51758
Value Function Update Magnitude: 0.66420

Collected Steps per Second: 22,693.62459
Overall Steps per Second: 10,623.57757

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.70670

Cumulative Model Updates: 249,000
Cumulative Timesteps: 2,076,652,930

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.31429
Policy Entropy: 2.18468
Value Function Loss: 0.01899

Mean KL Divergence: 0.03411
SB3 Clip Fraction: 0.17954
Policy Update Magnitude: 0.51302
Value Function Update Magnitude: 0.65292

Collected Steps per Second: 23,247.06116
Overall Steps per Second: 10,917.50636

Timestep Collection Time: 2.15081
Timestep Consumption Time: 2.42899
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.57980

Cumulative Model Updates: 249,006
Cumulative Timesteps: 2,076,702,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2076702930...
Checkpoint 2076702930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.83103
Policy Entropy: 2.17259
Value Function Loss: 0.01870

Mean KL Divergence: 0.03076
SB3 Clip Fraction: 0.16616
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.65660

Collected Steps per Second: 22,074.92076
Overall Steps per Second: 10,688.64614

Timestep Collection Time: 2.26619
Timestep Consumption Time: 2.41410
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.68029

Cumulative Model Updates: 249,012
Cumulative Timesteps: 2,076,752,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.89681
Policy Entropy: 2.17529
Value Function Loss: 0.01776

Mean KL Divergence: 0.02727
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.65881

Collected Steps per Second: 22,649.17143
Overall Steps per Second: 10,774.03726

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.64209

Cumulative Model Updates: 249,018
Cumulative Timesteps: 2,076,802,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2076802970...
Checkpoint 2076802970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.73397
Policy Entropy: 2.18539
Value Function Loss: 0.01816

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.53740
Value Function Update Magnitude: 0.64220

Collected Steps per Second: 22,543.83811
Overall Steps per Second: 10,712.77578

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.66788

Cumulative Model Updates: 249,024
Cumulative Timesteps: 2,076,852,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.64622
Policy Entropy: 2.18652
Value Function Loss: 0.01851

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.53037
Value Function Update Magnitude: 0.60879

Collected Steps per Second: 23,060.60310
Overall Steps per Second: 10,952.63359

Timestep Collection Time: 2.16846
Timestep Consumption Time: 2.39720
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.56566

Cumulative Model Updates: 249,030
Cumulative Timesteps: 2,076,902,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2076902982...
Checkpoint 2076902982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.91424
Policy Entropy: 2.17757
Value Function Loss: 0.02038

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.49144
Value Function Update Magnitude: 0.61228

Collected Steps per Second: 23,233.19277
Overall Steps per Second: 10,842.73327

Timestep Collection Time: 2.15244
Timestep Consumption Time: 2.45968
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.61212

Cumulative Model Updates: 249,036
Cumulative Timesteps: 2,076,952,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.60876
Policy Entropy: 2.18120
Value Function Loss: 0.02004

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.48125
Value Function Update Magnitude: 0.63169

Collected Steps per Second: 23,341.46064
Overall Steps per Second: 10,806.13070

Timestep Collection Time: 2.14331
Timestep Consumption Time: 2.48628
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.62959

Cumulative Model Updates: 249,042
Cumulative Timesteps: 2,077,003,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2077003018...
Checkpoint 2077003018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.71683
Policy Entropy: 2.16913
Value Function Loss: 0.01904

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.49838
Value Function Update Magnitude: 0.63447

Collected Steps per Second: 23,030.71496
Overall Steps per Second: 10,991.83287

Timestep Collection Time: 2.17101
Timestep Consumption Time: 2.37782
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.54883

Cumulative Model Updates: 249,048
Cumulative Timesteps: 2,077,053,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.08336
Policy Entropy: 2.16827
Value Function Loss: 0.01858

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.52455
Value Function Update Magnitude: 0.63182

Collected Steps per Second: 23,366.85638
Overall Steps per Second: 10,919.06051

Timestep Collection Time: 2.14090
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.58153

Cumulative Model Updates: 249,054
Cumulative Timesteps: 2,077,103,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2077103044...
Checkpoint 2077103044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.99888
Policy Entropy: 2.17502
Value Function Loss: 0.01782

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.52515
Value Function Update Magnitude: 0.62873

Collected Steps per Second: 23,121.29646
Overall Steps per Second: 10,789.53906

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.63708

Cumulative Model Updates: 249,060
Cumulative Timesteps: 2,077,153,076

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.78805
Policy Entropy: 2.18703
Value Function Loss: 0.01802

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.63094

Collected Steps per Second: 22,599.61253
Overall Steps per Second: 10,758.36745

Timestep Collection Time: 2.21278
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.64829

Cumulative Model Updates: 249,066
Cumulative Timesteps: 2,077,203,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2077203084...
Checkpoint 2077203084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.42218
Policy Entropy: 2.19345
Value Function Loss: 0.01761

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.64135

Collected Steps per Second: 22,499.27556
Overall Steps per Second: 10,817.25651

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.40081
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.62391

Cumulative Model Updates: 249,072
Cumulative Timesteps: 2,077,253,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.81361
Policy Entropy: 2.20265
Value Function Loss: 0.01691

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.52811
Value Function Update Magnitude: 0.64638

Collected Steps per Second: 22,841.60294
Overall Steps per Second: 10,746.20666

Timestep Collection Time: 2.19100
Timestep Consumption Time: 2.46608
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.65709

Cumulative Model Updates: 249,078
Cumulative Timesteps: 2,077,303,148

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2077303148...
Checkpoint 2077303148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.97984
Policy Entropy: 2.20479
Value Function Loss: 0.01704

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11741
Policy Update Magnitude: 0.52556
Value Function Update Magnitude: 0.62677

Collected Steps per Second: 22,640.50553
Overall Steps per Second: 10,599.92337

Timestep Collection Time: 2.20949
Timestep Consumption Time: 2.50979
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.71928

Cumulative Model Updates: 249,084
Cumulative Timesteps: 2,077,353,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.99588
Policy Entropy: 2.21403
Value Function Loss: 0.01767

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.53071
Value Function Update Magnitude: 0.62299

Collected Steps per Second: 23,166.28286
Overall Steps per Second: 10,844.10270

Timestep Collection Time: 2.15874
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61172

Cumulative Model Updates: 249,090
Cumulative Timesteps: 2,077,403,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2077403182...
Checkpoint 2077403182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.33184
Policy Entropy: 2.20667
Value Function Loss: 0.01769

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.52750
Value Function Update Magnitude: 0.62992

Collected Steps per Second: 22,984.33297
Overall Steps per Second: 10,908.33104

Timestep Collection Time: 2.17557
Timestep Consumption Time: 2.40845
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.58402

Cumulative Model Updates: 249,096
Cumulative Timesteps: 2,077,453,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.39045
Policy Entropy: 2.21579
Value Function Loss: 0.01695

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.52132
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 23,472.91905
Overall Steps per Second: 10,821.51390

Timestep Collection Time: 2.13054
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.62135

Cumulative Model Updates: 249,102
Cumulative Timesteps: 2,077,503,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2077503196...
Checkpoint 2077503196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.19186
Policy Entropy: 2.23136
Value Function Loss: 0.01637

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.61909

Collected Steps per Second: 22,954.44486
Overall Steps per Second: 10,766.46994

Timestep Collection Time: 2.17892
Timestep Consumption Time: 2.46661
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.64553

Cumulative Model Updates: 249,108
Cumulative Timesteps: 2,077,553,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.91006
Policy Entropy: 2.24308
Value Function Loss: 0.01701

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.63188

Collected Steps per Second: 23,224.10786
Overall Steps per Second: 10,860.70572

Timestep Collection Time: 2.15328
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.60449

Cumulative Model Updates: 249,114
Cumulative Timesteps: 2,077,603,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2077603220...
Checkpoint 2077603220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.06236
Policy Entropy: 2.26218
Value Function Loss: 0.01685

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.51698
Value Function Update Magnitude: 0.61378

Collected Steps per Second: 23,103.90233
Overall Steps per Second: 10,922.25408

Timestep Collection Time: 2.16457
Timestep Consumption Time: 2.41416
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.57873

Cumulative Model Updates: 249,120
Cumulative Timesteps: 2,077,653,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.42693
Policy Entropy: 2.24158
Value Function Loss: 0.01706

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.51833
Value Function Update Magnitude: 0.60691

Collected Steps per Second: 22,732.75304
Overall Steps per Second: 10,806.23659

Timestep Collection Time: 2.20044
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.62899

Cumulative Model Updates: 249,126
Cumulative Timesteps: 2,077,703,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2077703252...
Checkpoint 2077703252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.45102
Policy Entropy: 2.22509
Value Function Loss: 0.01653

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.52360
Value Function Update Magnitude: 0.60682

Collected Steps per Second: 21,986.82575
Overall Steps per Second: 10,645.99230

Timestep Collection Time: 2.27500
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.69848

Cumulative Model Updates: 249,132
Cumulative Timesteps: 2,077,753,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.09621
Policy Entropy: 2.18945
Value Function Loss: 0.01740

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.61488

Collected Steps per Second: 22,572.06680
Overall Steps per Second: 10,695.61661

Timestep Collection Time: 2.21619
Timestep Consumption Time: 2.46087
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.67706

Cumulative Model Updates: 249,138
Cumulative Timesteps: 2,077,803,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2077803296...
Checkpoint 2077803296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.99683
Policy Entropy: 2.17463
Value Function Loss: 0.01794

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.63023

Collected Steps per Second: 22,925.50293
Overall Steps per Second: 10,921.57281

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.39875
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.58121

Cumulative Model Updates: 249,144
Cumulative Timesteps: 2,077,853,330

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.10530
Policy Entropy: 2.18908
Value Function Loss: 0.01790

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.64751

Collected Steps per Second: 23,723.84233
Overall Steps per Second: 10,900.63653

Timestep Collection Time: 2.10758
Timestep Consumption Time: 2.47930
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.58689

Cumulative Model Updates: 249,150
Cumulative Timesteps: 2,077,903,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2077903330...
Checkpoint 2077903330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.81456
Policy Entropy: 2.21397
Value Function Loss: 0.01736

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.64177

Collected Steps per Second: 23,204.59137
Overall Steps per Second: 10,771.22937

Timestep Collection Time: 2.15544
Timestep Consumption Time: 2.48805
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.64348

Cumulative Model Updates: 249,156
Cumulative Timesteps: 2,077,953,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.01359
Policy Entropy: 2.21160
Value Function Loss: 0.01706

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.51591
Value Function Update Magnitude: 0.62457

Collected Steps per Second: 23,158.30734
Overall Steps per Second: 10,777.36386

Timestep Collection Time: 2.15983
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.64102

Cumulative Model Updates: 249,162
Cumulative Timesteps: 2,078,003,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2078003364...
Checkpoint 2078003364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.17350
Policy Entropy: 2.19255
Value Function Loss: 0.01652

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.51214
Value Function Update Magnitude: 0.61499

Collected Steps per Second: 23,117.56615
Overall Steps per Second: 11,064.95819

Timestep Collection Time: 2.16320
Timestep Consumption Time: 2.35629
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.51949

Cumulative Model Updates: 249,168
Cumulative Timesteps: 2,078,053,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.82050
Policy Entropy: 2.18347
Value Function Loss: 0.01717

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 0.53109
Value Function Update Magnitude: 0.63172

Collected Steps per Second: 23,124.28615
Overall Steps per Second: 10,905.68272

Timestep Collection Time: 2.16309
Timestep Consumption Time: 2.42351
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.58660

Cumulative Model Updates: 249,174
Cumulative Timesteps: 2,078,103,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2078103392...
Checkpoint 2078103392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.42416
Policy Entropy: 2.16680
Value Function Loss: 0.01862

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.54464
Value Function Update Magnitude: 0.66031

Collected Steps per Second: 22,405.35908
Overall Steps per Second: 10,735.84633

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.42666
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.65916

Cumulative Model Updates: 249,180
Cumulative Timesteps: 2,078,153,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.61618
Policy Entropy: 2.17024
Value Function Loss: 0.01849

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.54711
Value Function Update Magnitude: 0.67098

Collected Steps per Second: 22,455.76582
Overall Steps per Second: 10,930.23988

Timestep Collection Time: 2.22669
Timestep Consumption Time: 2.34796
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.57465

Cumulative Model Updates: 249,186
Cumulative Timesteps: 2,078,203,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2078203414...
Checkpoint 2078203414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.33403
Policy Entropy: 2.17488
Value Function Loss: 0.01831

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.53694
Value Function Update Magnitude: 0.66562

Collected Steps per Second: 22,657.12793
Overall Steps per Second: 10,642.92911

Timestep Collection Time: 2.20725
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.69889

Cumulative Model Updates: 249,192
Cumulative Timesteps: 2,078,253,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.06637
Policy Entropy: 2.22582
Value Function Loss: 0.01679

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.52689
Value Function Update Magnitude: 0.63804

Collected Steps per Second: 22,737.01010
Overall Steps per Second: 10,800.85050

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.63038

Cumulative Model Updates: 249,198
Cumulative Timesteps: 2,078,303,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2078303436...
Checkpoint 2078303436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.97627
Policy Entropy: 2.23045
Value Function Loss: 0.01662

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.52332
Value Function Update Magnitude: 0.61855

Collected Steps per Second: 22,992.31181
Overall Steps per Second: 10,679.91076

Timestep Collection Time: 2.17560
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.68375

Cumulative Model Updates: 249,204
Cumulative Timesteps: 2,078,353,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.93571
Policy Entropy: 2.20723
Value Function Loss: 0.01714

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.52081
Value Function Update Magnitude: 0.60962

Collected Steps per Second: 22,992.82650
Overall Steps per Second: 10,896.80757

Timestep Collection Time: 2.17555
Timestep Consumption Time: 2.41497
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.59052

Cumulative Model Updates: 249,210
Cumulative Timesteps: 2,078,403,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2078403480...
Checkpoint 2078403480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.30608
Policy Entropy: 2.19072
Value Function Loss: 0.01798

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.52894
Value Function Update Magnitude: 0.61451

Collected Steps per Second: 22,698.04521
Overall Steps per Second: 10,659.76122

Timestep Collection Time: 2.20371
Timestep Consumption Time: 2.48870
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.69241

Cumulative Model Updates: 249,216
Cumulative Timesteps: 2,078,453,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.27415
Policy Entropy: 2.19060
Value Function Loss: 0.01789

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.62452

Collected Steps per Second: 22,818.55558
Overall Steps per Second: 10,825.70911

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.62030

Cumulative Model Updates: 249,222
Cumulative Timesteps: 2,078,503,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2078503518...
Checkpoint 2078503518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.40851
Policy Entropy: 2.20752
Value Function Loss: 0.01702

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.63345

Collected Steps per Second: 22,870.03687
Overall Steps per Second: 10,702.93341

Timestep Collection Time: 2.18644
Timestep Consumption Time: 2.48555
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.67199

Cumulative Model Updates: 249,228
Cumulative Timesteps: 2,078,553,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.85967
Policy Entropy: 2.19396
Value Function Loss: 0.01645

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.52643
Value Function Update Magnitude: 0.62867

Collected Steps per Second: 22,758.88367
Overall Steps per Second: 10,940.49084

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.37371
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.57109

Cumulative Model Updates: 249,234
Cumulative Timesteps: 2,078,603,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2078603532...
Checkpoint 2078603532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.78155
Policy Entropy: 2.19922
Value Function Loss: 0.01606

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.53196
Value Function Update Magnitude: 0.61617

Collected Steps per Second: 22,636.28341
Overall Steps per Second: 10,625.71833

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.49752
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.70707

Cumulative Model Updates: 249,240
Cumulative Timesteps: 2,078,653,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.59236
Policy Entropy: 2.20228
Value Function Loss: 0.01631

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.52545
Value Function Update Magnitude: 0.61319

Collected Steps per Second: 22,560.38036
Overall Steps per Second: 10,664.37113

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.69038

Cumulative Model Updates: 249,246
Cumulative Timesteps: 2,078,703,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2078703568...
Checkpoint 2078703568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.99945
Policy Entropy: 2.20089
Value Function Loss: 0.01621

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.51515
Value Function Update Magnitude: 0.61148

Collected Steps per Second: 22,501.81054
Overall Steps per Second: 10,845.26549

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.38836
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.61049

Cumulative Model Updates: 249,252
Cumulative Timesteps: 2,078,753,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.69273
Policy Entropy: 2.18256
Value Function Loss: 0.01706

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.11259
Policy Update Magnitude: 0.52329
Value Function Update Magnitude: 0.61305

Collected Steps per Second: 22,616.60682
Overall Steps per Second: 10,889.63966

Timestep Collection Time: 2.21112
Timestep Consumption Time: 2.38114
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.59225

Cumulative Model Updates: 249,258
Cumulative Timesteps: 2,078,803,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2078803578...
Checkpoint 2078803578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.91252
Policy Entropy: 2.18212
Value Function Loss: 0.01729

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.62169

Collected Steps per Second: 23,086.06546
Overall Steps per Second: 10,689.69228

Timestep Collection Time: 2.16624
Timestep Consumption Time: 2.51210
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67834

Cumulative Model Updates: 249,264
Cumulative Timesteps: 2,078,853,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.36286
Policy Entropy: 2.21975
Value Function Loss: 0.01727

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.52604
Value Function Update Magnitude: 0.62961

Collected Steps per Second: 23,220.10631
Overall Steps per Second: 10,904.89270

Timestep Collection Time: 2.15451
Timestep Consumption Time: 2.43315
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.58767

Cumulative Model Updates: 249,270
Cumulative Timesteps: 2,078,903,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2078903616...
Checkpoint 2078903616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.21351
Policy Entropy: 2.23483
Value Function Loss: 0.01642

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.64028

Collected Steps per Second: 23,132.18393
Overall Steps per Second: 10,854.34746

Timestep Collection Time: 2.16166
Timestep Consumption Time: 2.44515
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.60682

Cumulative Model Updates: 249,276
Cumulative Timesteps: 2,078,953,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.64882
Policy Entropy: 2.21449
Value Function Loss: 0.01713

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.52621
Value Function Update Magnitude: 0.62418

Collected Steps per Second: 23,090.08749
Overall Steps per Second: 10,981.17287

Timestep Collection Time: 2.16604
Timestep Consumption Time: 2.38848
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.55452

Cumulative Model Updates: 249,282
Cumulative Timesteps: 2,079,003,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2079003634...
Checkpoint 2079003634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.27025
Policy Entropy: 2.19903
Value Function Loss: 0.01799

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.52641
Value Function Update Magnitude: 0.62786

Collected Steps per Second: 22,923.40773
Overall Steps per Second: 10,902.43750

Timestep Collection Time: 2.18196
Timestep Consumption Time: 2.40582
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.58778

Cumulative Model Updates: 249,288
Cumulative Timesteps: 2,079,053,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.92079
Policy Entropy: 2.20417
Value Function Loss: 0.01783

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.53162
Value Function Update Magnitude: 0.63784

Collected Steps per Second: 22,791.02272
Overall Steps per Second: 10,797.42199

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.63259

Cumulative Model Updates: 249,294
Cumulative Timesteps: 2,079,103,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2079103672...
Checkpoint 2079103672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.22419
Policy Entropy: 2.19904
Value Function Loss: 0.01735

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.63674

Collected Steps per Second: 22,088.57088
Overall Steps per Second: 10,726.23956

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.39833
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.66240

Cumulative Model Updates: 249,300
Cumulative Timesteps: 2,079,153,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.96596
Policy Entropy: 2.18562
Value Function Loss: 0.01686

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.52583
Value Function Update Magnitude: 0.62933

Collected Steps per Second: 23,089.37670
Overall Steps per Second: 10,894.95418

Timestep Collection Time: 2.16619
Timestep Consumption Time: 2.42456
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59075

Cumulative Model Updates: 249,306
Cumulative Timesteps: 2,079,203,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2079203698...
Checkpoint 2079203698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.29420
Policy Entropy: 2.17913
Value Function Loss: 0.01727

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.52416
Value Function Update Magnitude: 0.62364

Collected Steps per Second: 22,936.97253
Overall Steps per Second: 10,622.12462

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.52818
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.70885

Cumulative Model Updates: 249,312
Cumulative Timesteps: 2,079,253,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.61008
Policy Entropy: 2.21986
Value Function Loss: 0.01730

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.52194
Value Function Update Magnitude: 0.62297

Collected Steps per Second: 23,422.04825
Overall Steps per Second: 10,899.43572

Timestep Collection Time: 2.13568
Timestep Consumption Time: 2.45373
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.58941

Cumulative Model Updates: 249,318
Cumulative Timesteps: 2,079,303,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2079303738...
Checkpoint 2079303738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.86276
Policy Entropy: 2.21022
Value Function Loss: 0.01829

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.52632
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 23,973.99153
Overall Steps per Second: 11,092.73140

Timestep Collection Time: 2.08643
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.50926

Cumulative Model Updates: 249,324
Cumulative Timesteps: 2,079,353,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.40891
Policy Entropy: 2.21422
Value Function Loss: 0.01778

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.63835

Collected Steps per Second: 23,396.59888
Overall Steps per Second: 10,962.75244

Timestep Collection Time: 2.13732
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.56145

Cumulative Model Updates: 249,330
Cumulative Timesteps: 2,079,403,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2079403764...
Checkpoint 2079403764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.04521
Policy Entropy: 2.20043
Value Function Loss: 0.01845

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.63533

Collected Steps per Second: 22,967.31145
Overall Steps per Second: 10,683.11073

Timestep Collection Time: 2.17831
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.68309

Cumulative Model Updates: 249,336
Cumulative Timesteps: 2,079,453,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.61586
Policy Entropy: 2.20969
Value Function Loss: 0.01741

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.61833

Collected Steps per Second: 23,073.16955
Overall Steps per Second: 10,862.56957

Timestep Collection Time: 2.16719
Timestep Consumption Time: 2.43614
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.60333

Cumulative Model Updates: 249,342
Cumulative Timesteps: 2,079,503,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2079503798...
Checkpoint 2079503798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.90994
Policy Entropy: 2.19473
Value Function Loss: 0.01794

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.53076
Value Function Update Magnitude: 0.60118

Collected Steps per Second: 23,376.30580
Overall Steps per Second: 10,994.44582

Timestep Collection Time: 2.13960
Timestep Consumption Time: 2.40960
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.54921

Cumulative Model Updates: 249,348
Cumulative Timesteps: 2,079,553,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.77310
Policy Entropy: 2.17481
Value Function Loss: 0.01842

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.53253
Value Function Update Magnitude: 0.59930

Collected Steps per Second: 22,599.37332
Overall Steps per Second: 10,619.17089

Timestep Collection Time: 2.21378
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.71129

Cumulative Model Updates: 249,354
Cumulative Timesteps: 2,079,603,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2079603844...
Checkpoint 2079603844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.60093
Policy Entropy: 2.14667
Value Function Loss: 0.01866

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.53314
Value Function Update Magnitude: 0.61118

Collected Steps per Second: 22,572.29690
Overall Steps per Second: 10,740.90699

Timestep Collection Time: 2.21599
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.65696

Cumulative Model Updates: 249,360
Cumulative Timesteps: 2,079,653,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.21654
Policy Entropy: 2.17696
Value Function Loss: 0.01766

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.53387
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 22,948.13881
Overall Steps per Second: 10,920.98518

Timestep Collection Time: 2.17926
Timestep Consumption Time: 2.40000
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.57926

Cumulative Model Updates: 249,366
Cumulative Timesteps: 2,079,703,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2079703874...
Checkpoint 2079703874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.98985
Policy Entropy: 2.18970
Value Function Loss: 0.01769

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.52712
Value Function Update Magnitude: 0.60813

Collected Steps per Second: 23,100.03483
Overall Steps per Second: 10,836.65427

Timestep Collection Time: 2.16536
Timestep Consumption Time: 2.45045
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61582

Cumulative Model Updates: 249,372
Cumulative Timesteps: 2,079,753,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.57144
Policy Entropy: 2.22979
Value Function Loss: 0.01661

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.52252
Value Function Update Magnitude: 0.58957

Collected Steps per Second: 22,620.65033
Overall Steps per Second: 10,610.90660

Timestep Collection Time: 2.21099
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.71345

Cumulative Model Updates: 249,378
Cumulative Timesteps: 2,079,803,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2079803908...
Checkpoint 2079803908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.45401
Policy Entropy: 2.21259
Value Function Loss: 0.01705

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.52135
Value Function Update Magnitude: 0.59128

Collected Steps per Second: 22,674.97206
Overall Steps per Second: 10,754.65037

Timestep Collection Time: 2.20560
Timestep Consumption Time: 2.44466
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.65027

Cumulative Model Updates: 249,384
Cumulative Timesteps: 2,079,853,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.54146
Policy Entropy: 2.22683
Value Function Loss: 0.01650

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.51937
Value Function Update Magnitude: 0.60113

Collected Steps per Second: 23,530.77756
Overall Steps per Second: 11,200.87690

Timestep Collection Time: 2.12590
Timestep Consumption Time: 2.34018
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.46608

Cumulative Model Updates: 249,390
Cumulative Timesteps: 2,079,903,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2079903944...
Checkpoint 2079903944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.07951
Policy Entropy: 2.22823
Value Function Loss: 0.01752

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.52223
Value Function Update Magnitude: 0.59775

Collected Steps per Second: 23,186.12637
Overall Steps per Second: 10,818.33873

Timestep Collection Time: 2.15767
Timestep Consumption Time: 2.46670
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.62437

Cumulative Model Updates: 249,396
Cumulative Timesteps: 2,079,953,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.39891
Policy Entropy: 2.21451
Value Function Loss: 0.01772

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.52321
Value Function Update Magnitude: 0.59034

Collected Steps per Second: 23,121.56797
Overall Steps per Second: 10,719.07473

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.66477

Cumulative Model Updates: 249,402
Cumulative Timesteps: 2,080,003,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2080003974...
Checkpoint 2080003974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.88734
Policy Entropy: 2.20954
Value Function Loss: 0.01840

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.52824
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 22,386.07035
Overall Steps per Second: 10,582.25448

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.72489

Cumulative Model Updates: 249,408
Cumulative Timesteps: 2,080,053,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.67847
Policy Entropy: 2.22102
Value Function Loss: 0.01773

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.53407
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 23,532.44214
Overall Steps per Second: 11,000.02162

Timestep Collection Time: 2.12515
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.54635

Cumulative Model Updates: 249,414
Cumulative Timesteps: 2,080,103,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2080103984...
Checkpoint 2080103984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.22773
Policy Entropy: 2.24370
Value Function Loss: 0.01829

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 22,946.09846
Overall Steps per Second: 10,730.59763

Timestep Collection Time: 2.17963
Timestep Consumption Time: 2.48125
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.66088

Cumulative Model Updates: 249,420
Cumulative Timesteps: 2,080,153,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.78684
Policy Entropy: 2.22665
Value Function Loss: 0.01741

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.62623

Collected Steps per Second: 22,977.58011
Overall Steps per Second: 10,746.03667

Timestep Collection Time: 2.17647
Timestep Consumption Time: 2.47734
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.65381

Cumulative Model Updates: 249,426
Cumulative Timesteps: 2,080,204,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2080204008...
Checkpoint 2080204008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.28534
Policy Entropy: 2.21376
Value Function Loss: 0.01865

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.52662
Value Function Update Magnitude: 0.61450

Collected Steps per Second: 22,914.55846
Overall Steps per Second: 10,678.84572

Timestep Collection Time: 2.18254
Timestep Consumption Time: 2.50074
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.68328

Cumulative Model Updates: 249,432
Cumulative Timesteps: 2,080,254,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.27248
Policy Entropy: 2.21470
Value Function Loss: 0.01775

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.52834
Value Function Update Magnitude: 0.62877

Collected Steps per Second: 23,867.48306
Overall Steps per Second: 10,851.98075

Timestep Collection Time: 2.09507
Timestep Consumption Time: 2.51275
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.60782

Cumulative Model Updates: 249,438
Cumulative Timesteps: 2,080,304,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2080304024...
Checkpoint 2080304024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.73783
Policy Entropy: 2.21019
Value Function Loss: 0.01807

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.53012
Value Function Update Magnitude: 0.63212

Collected Steps per Second: 23,082.40907
Overall Steps per Second: 10,722.25866

Timestep Collection Time: 2.16650
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.66394

Cumulative Model Updates: 249,444
Cumulative Timesteps: 2,080,354,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.80673
Policy Entropy: 2.21158
Value Function Loss: 0.01820

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.52893
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 23,053.36855
Overall Steps per Second: 10,851.61597

Timestep Collection Time: 2.16914
Timestep Consumption Time: 2.43902
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.60816

Cumulative Model Updates: 249,450
Cumulative Timesteps: 2,080,404,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2080404038...
Checkpoint 2080404038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.98332
Policy Entropy: 2.18442
Value Function Loss: 0.01798

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.52213
Value Function Update Magnitude: 0.60586

Collected Steps per Second: 23,165.19290
Overall Steps per Second: 11,075.63396

Timestep Collection Time: 2.15867
Timestep Consumption Time: 2.35629
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.51496

Cumulative Model Updates: 249,456
Cumulative Timesteps: 2,080,454,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.64712
Policy Entropy: 2.19067
Value Function Loss: 0.01813

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.52513
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 23,393.33934
Overall Steps per Second: 10,966.84031

Timestep Collection Time: 2.13770
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.55993

Cumulative Model Updates: 249,462
Cumulative Timesteps: 2,080,504,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2080504052...
Checkpoint 2080504052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.67266
Policy Entropy: 2.16978
Value Function Loss: 0.01789

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.52675
Value Function Update Magnitude: 0.57969

Collected Steps per Second: 22,572.01957
Overall Steps per Second: 10,617.03913

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.71035

Cumulative Model Updates: 249,468
Cumulative Timesteps: 2,080,554,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.90760
Policy Entropy: 2.17331
Value Function Loss: 0.01917

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.53579
Value Function Update Magnitude: 0.60290

Collected Steps per Second: 22,487.58866
Overall Steps per Second: 10,580.75883

Timestep Collection Time: 2.22389
Timestep Consumption Time: 2.50261
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.72650

Cumulative Model Updates: 249,474
Cumulative Timesteps: 2,080,604,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2080604072...
Checkpoint 2080604072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.66501
Policy Entropy: 2.17599
Value Function Loss: 0.01804

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.53692
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 22,706.36842
Overall Steps per Second: 10,953.25379

Timestep Collection Time: 2.20203
Timestep Consumption Time: 2.36283
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.56485

Cumulative Model Updates: 249,480
Cumulative Timesteps: 2,080,654,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.53462
Policy Entropy: 2.20013
Value Function Loss: 0.01809

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.59225

Collected Steps per Second: 23,270.76273
Overall Steps per Second: 10,911.15684

Timestep Collection Time: 2.14982
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.58503

Cumulative Model Updates: 249,486
Cumulative Timesteps: 2,080,704,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2080704100...
Checkpoint 2080704100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.33145
Policy Entropy: 2.21168
Value Function Loss: 0.01739

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.52722
Value Function Update Magnitude: 0.57360

Collected Steps per Second: 22,856.59132
Overall Steps per Second: 10,654.43028

Timestep Collection Time: 2.18817
Timestep Consumption Time: 2.50603
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69420

Cumulative Model Updates: 249,492
Cumulative Timesteps: 2,080,754,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.26298
Policy Entropy: 2.22474
Value Function Loss: 0.01750

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.52426
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 23,122.43716
Overall Steps per Second: 10,878.11676

Timestep Collection Time: 2.16266
Timestep Consumption Time: 2.43427
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.59694

Cumulative Model Updates: 249,498
Cumulative Timesteps: 2,080,804,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2080804120...
Checkpoint 2080804120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.37982
Policy Entropy: 2.21500
Value Function Loss: 0.01647

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.51933
Value Function Update Magnitude: 0.59233

Collected Steps per Second: 23,130.36308
Overall Steps per Second: 10,746.04041

Timestep Collection Time: 2.16278
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.65530

Cumulative Model Updates: 249,504
Cumulative Timesteps: 2,080,854,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.52361
Policy Entropy: 2.19820
Value Function Loss: 0.01660

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.51635
Value Function Update Magnitude: 0.59240

Collected Steps per Second: 23,311.80429
Overall Steps per Second: 10,871.10229

Timestep Collection Time: 2.14518
Timestep Consumption Time: 2.45491
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.60009

Cumulative Model Updates: 249,510
Cumulative Timesteps: 2,080,904,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2080904154...
Checkpoint 2080904154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.38794
Policy Entropy: 2.19046
Value Function Loss: 0.01603

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.51730
Value Function Update Magnitude: 0.61141

Collected Steps per Second: 22,783.31123
Overall Steps per Second: 10,772.58501

Timestep Collection Time: 2.19520
Timestep Consumption Time: 2.44751
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.64271

Cumulative Model Updates: 249,516
Cumulative Timesteps: 2,080,954,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.57035
Policy Entropy: 2.20458
Value Function Loss: 0.01596

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.50860
Value Function Update Magnitude: 0.61354

Collected Steps per Second: 23,190.37807
Overall Steps per Second: 10,999.81314

Timestep Collection Time: 2.15745
Timestep Consumption Time: 2.39099
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.54844

Cumulative Model Updates: 249,522
Cumulative Timesteps: 2,081,004,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2081004200...
Checkpoint 2081004200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.48709
Policy Entropy: 2.21266
Value Function Loss: 0.01650

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.51838
Value Function Update Magnitude: 0.60504

Collected Steps per Second: 22,475.06281
Overall Steps per Second: 10,766.46261

Timestep Collection Time: 2.22531
Timestep Consumption Time: 2.42004
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.64535

Cumulative Model Updates: 249,528
Cumulative Timesteps: 2,081,054,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.33208
Policy Entropy: 2.21953
Value Function Loss: 0.01791

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.52572
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 22,529.68320
Overall Steps per Second: 10,589.03121

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.72394

Cumulative Model Updates: 249,534
Cumulative Timesteps: 2,081,104,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2081104236...
Checkpoint 2081104236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.59725
Policy Entropy: 2.19456
Value Function Loss: 0.01904

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.53434
Value Function Update Magnitude: 0.62794

Collected Steps per Second: 22,409.41283
Overall Steps per Second: 10,629.31892

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.70604

Cumulative Model Updates: 249,540
Cumulative Timesteps: 2,081,154,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.78375
Policy Entropy: 2.20669
Value Function Loss: 0.01738

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.53132
Value Function Update Magnitude: 0.64563

Collected Steps per Second: 22,939.63941
Overall Steps per Second: 10,900.97203

Timestep Collection Time: 2.17972
Timestep Consumption Time: 2.40721
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.58693

Cumulative Model Updates: 249,546
Cumulative Timesteps: 2,081,204,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2081204260...
Checkpoint 2081204260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.25382
Policy Entropy: 2.19965
Value Function Loss: 0.01646

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.52150
Value Function Update Magnitude: 0.63114

Collected Steps per Second: 23,151.91710
Overall Steps per Second: 10,771.24611

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.48353
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.64422

Cumulative Model Updates: 249,552
Cumulative Timesteps: 2,081,254,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.74911
Policy Entropy: 2.21918
Value Function Loss: 0.01575

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.51396
Value Function Update Magnitude: 0.60467

Collected Steps per Second: 23,449.14027
Overall Steps per Second: 10,754.80711

Timestep Collection Time: 2.13262
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.64983

Cumulative Model Updates: 249,558
Cumulative Timesteps: 2,081,304,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2081304292...
Checkpoint 2081304292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.06710
Policy Entropy: 2.21831
Value Function Loss: 0.01829

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.52124
Value Function Update Magnitude: 0.61846

Collected Steps per Second: 22,996.55493
Overall Steps per Second: 10,810.11168

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.45175
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.62659

Cumulative Model Updates: 249,564
Cumulative Timesteps: 2,081,354,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.40032
Policy Entropy: 2.20164
Value Function Loss: 0.01809

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.52730
Value Function Update Magnitude: 0.64478

Collected Steps per Second: 22,704.52691
Overall Steps per Second: 10,823.93056

Timestep Collection Time: 2.20370
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.62254

Cumulative Model Updates: 249,570
Cumulative Timesteps: 2,081,404,340

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2081404340...
Checkpoint 2081404340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.47213
Policy Entropy: 2.16789
Value Function Loss: 0.01802

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.52980
Value Function Update Magnitude: 0.64053

Collected Steps per Second: 23,039.13502
Overall Steps per Second: 10,762.85108

Timestep Collection Time: 2.17057
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.64635

Cumulative Model Updates: 249,576
Cumulative Timesteps: 2,081,454,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.24250
Policy Entropy: 2.16221
Value Function Loss: 0.01789

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.53658
Value Function Update Magnitude: 0.61416

Collected Steps per Second: 23,233.44475
Overall Steps per Second: 10,774.12495

Timestep Collection Time: 2.15319
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.64316

Cumulative Model Updates: 249,582
Cumulative Timesteps: 2,081,504,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2081504374...
Checkpoint 2081504374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.23238
Policy Entropy: 2.16358
Value Function Loss: 0.01856

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 22,406.51632
Overall Steps per Second: 10,577.01801

Timestep Collection Time: 2.23149
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.72723

Cumulative Model Updates: 249,588
Cumulative Timesteps: 2,081,554,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.90174
Policy Entropy: 2.17786
Value Function Loss: 0.01987

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.54414
Value Function Update Magnitude: 0.63729

Collected Steps per Second: 22,101.90563
Overall Steps per Second: 10,801.39603

Timestep Collection Time: 2.26288
Timestep Consumption Time: 2.36745
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.63033

Cumulative Model Updates: 249,594
Cumulative Timesteps: 2,081,604,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2081604388...
Checkpoint 2081604388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.48931
Policy Entropy: 2.19249
Value Function Loss: 0.01913

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.65088

Collected Steps per Second: 22,594.23766
Overall Steps per Second: 10,723.09492

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.45194
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.66675

Cumulative Model Updates: 249,600
Cumulative Timesteps: 2,081,654,430

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.49094
Policy Entropy: 2.19840
Value Function Loss: 0.01851

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.53082
Value Function Update Magnitude: 0.65202

Collected Steps per Second: 22,549.94545
Overall Steps per Second: 10,631.77589

Timestep Collection Time: 2.21801
Timestep Consumption Time: 2.48638
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.70439

Cumulative Model Updates: 249,606
Cumulative Timesteps: 2,081,704,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2081704446...
Checkpoint 2081704446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.29574
Policy Entropy: 2.22130
Value Function Loss: 0.01740

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.51853
Value Function Update Magnitude: 0.61659

Collected Steps per Second: 22,897.55503
Overall Steps per Second: 10,958.47155

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.37914
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.56286

Cumulative Model Updates: 249,612
Cumulative Timesteps: 2,081,754,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.76356
Policy Entropy: 2.18921
Value Function Loss: 0.01775

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.48146
Value Function Update Magnitude: 0.60195

Collected Steps per Second: 23,337.43631
Overall Steps per Second: 10,839.71533

Timestep Collection Time: 2.14299
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.61377

Cumulative Model Updates: 249,618
Cumulative Timesteps: 2,081,804,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2081804460...
Checkpoint 2081804460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.03682
Policy Entropy: 2.19115
Value Function Loss: 0.01731

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.48528
Value Function Update Magnitude: 0.59315

Collected Steps per Second: 23,008.62186
Overall Steps per Second: 10,707.98597

Timestep Collection Time: 2.17336
Timestep Consumption Time: 2.49661
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.66997

Cumulative Model Updates: 249,624
Cumulative Timesteps: 2,081,854,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.76278
Policy Entropy: 2.16262
Value Function Loss: 0.01797

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.51271
Value Function Update Magnitude: 0.59220

Collected Steps per Second: 23,350.39286
Overall Steps per Second: 10,892.58343

Timestep Collection Time: 2.14146
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.59065

Cumulative Model Updates: 249,630
Cumulative Timesteps: 2,081,904,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2081904470...
Checkpoint 2081904470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.29573
Policy Entropy: 2.17374
Value Function Loss: 0.01869

Mean KL Divergence: 0.03174
SB3 Clip Fraction: 0.17134
Policy Update Magnitude: 0.50402
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 22,945.35141
Overall Steps per Second: 11,045.67847

Timestep Collection Time: 2.17961
Timestep Consumption Time: 2.34813
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.52774

Cumulative Model Updates: 249,636
Cumulative Timesteps: 2,081,954,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.02005
Policy Entropy: 2.17291
Value Function Loss: 0.01917

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.63166

Collected Steps per Second: 22,690.43054
Overall Steps per Second: 10,645.53310

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.69850

Cumulative Model Updates: 249,642
Cumulative Timesteps: 2,082,004,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2082004500...
Checkpoint 2082004500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.37686
Policy Entropy: 2.18255
Value Function Loss: 0.01938

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.64791

Collected Steps per Second: 22,539.52664
Overall Steps per Second: 10,495.44004

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.54656
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.76569

Cumulative Model Updates: 249,648
Cumulative Timesteps: 2,082,054,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.73747
Policy Entropy: 2.17755
Value Function Loss: 0.01905

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.63654

Collected Steps per Second: 22,737.73865
Overall Steps per Second: 10,855.67919

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.40776
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.60754

Cumulative Model Updates: 249,654
Cumulative Timesteps: 2,082,104,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2082104536...
Checkpoint 2082104536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.33808
Policy Entropy: 2.20899
Value Function Loss: 0.01939

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.62003

Collected Steps per Second: 22,948.23514
Overall Steps per Second: 10,704.88458

Timestep Collection Time: 2.17917
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.67151

Cumulative Model Updates: 249,660
Cumulative Timesteps: 2,082,154,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.77874
Policy Entropy: 2.21996
Value Function Loss: 0.01898

Mean KL Divergence: 0.04412
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.61499

Collected Steps per Second: 22,650.21972
Overall Steps per Second: 10,794.89291

Timestep Collection Time: 2.20819
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.63330

Cumulative Model Updates: 249,666
Cumulative Timesteps: 2,082,204,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2082204560...
Checkpoint 2082204560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.70770
Policy Entropy: 2.22327
Value Function Loss: 0.01793

Mean KL Divergence: 0.05891
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.61860

Collected Steps per Second: 22,683.31567
Overall Steps per Second: 10,741.93667

Timestep Collection Time: 2.20453
Timestep Consumption Time: 2.45068
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.65521

Cumulative Model Updates: 249,672
Cumulative Timesteps: 2,082,254,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.49733
Policy Entropy: 2.20022
Value Function Loss: 0.01759

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.52855
Value Function Update Magnitude: 0.59869

Collected Steps per Second: 22,881.83909
Overall Steps per Second: 10,866.81111

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.41699
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.60301

Cumulative Model Updates: 249,678
Cumulative Timesteps: 2,082,304,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2082304586...
Checkpoint 2082304586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.38063
Policy Entropy: 2.19434
Value Function Loss: 0.01803

Mean KL Divergence: 0.02659
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.49408
Value Function Update Magnitude: 0.57768

Collected Steps per Second: 23,100.72837
Overall Steps per Second: 11,054.03303

Timestep Collection Time: 2.16565
Timestep Consumption Time: 2.36012
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.52577

Cumulative Model Updates: 249,684
Cumulative Timesteps: 2,082,354,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.22951
Policy Entropy: 2.21450
Value Function Loss: 0.01721

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.49397
Value Function Update Magnitude: 0.57778

Collected Steps per Second: 23,053.55580
Overall Steps per Second: 10,874.85506

Timestep Collection Time: 2.16947
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.59905

Cumulative Model Updates: 249,690
Cumulative Timesteps: 2,082,404,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2082404628...
Checkpoint 2082404628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.47295
Policy Entropy: 2.20018
Value Function Loss: 0.01769

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.51291
Value Function Update Magnitude: 0.57453

Collected Steps per Second: 22,922.82785
Overall Steps per Second: 10,768.52469

Timestep Collection Time: 2.18167
Timestep Consumption Time: 2.46242
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.64409

Cumulative Model Updates: 249,696
Cumulative Timesteps: 2,082,454,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.72439
Policy Entropy: 2.21092
Value Function Loss: 0.01743

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.53271
Value Function Update Magnitude: 0.58389

Collected Steps per Second: 23,172.09621
Overall Steps per Second: 10,948.47833

Timestep Collection Time: 2.15803
Timestep Consumption Time: 2.40937
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.56739

Cumulative Model Updates: 249,702
Cumulative Timesteps: 2,082,504,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2082504644...
Checkpoint 2082504644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.33349
Policy Entropy: 2.20458
Value Function Loss: 0.01861

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.58831

Collected Steps per Second: 22,084.99894
Overall Steps per Second: 10,633.98553

Timestep Collection Time: 2.26461
Timestep Consumption Time: 2.43861
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.70322

Cumulative Model Updates: 249,708
Cumulative Timesteps: 2,082,554,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.79897
Policy Entropy: 2.20001
Value Function Loss: 0.01789

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.59046

Collected Steps per Second: 22,611.59134
Overall Steps per Second: 10,788.26212

Timestep Collection Time: 2.21241
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.63708

Cumulative Model Updates: 249,714
Cumulative Timesteps: 2,082,604,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2082604684...
Checkpoint 2082604684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.33635
Policy Entropy: 2.21893
Value Function Loss: 0.01677

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.52217
Value Function Update Magnitude: 0.58982

Collected Steps per Second: 22,874.59203
Overall Steps per Second: 10,716.34238

Timestep Collection Time: 2.18627
Timestep Consumption Time: 2.48044
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.66670

Cumulative Model Updates: 249,720
Cumulative Timesteps: 2,082,654,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.27609
Policy Entropy: 2.19732
Value Function Loss: 0.01635

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.52352
Value Function Update Magnitude: 0.58563

Collected Steps per Second: 22,969.42412
Overall Steps per Second: 10,955.36781

Timestep Collection Time: 2.17794
Timestep Consumption Time: 2.38841
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.56635

Cumulative Model Updates: 249,726
Cumulative Timesteps: 2,082,704,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2082704720...
Checkpoint 2082704720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.39711
Policy Entropy: 2.22212
Value Function Loss: 0.01671

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.52606
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 23,192.77175
Overall Steps per Second: 10,833.15727

Timestep Collection Time: 2.15714
Timestep Consumption Time: 2.46109
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.61823

Cumulative Model Updates: 249,732
Cumulative Timesteps: 2,082,754,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.74386
Policy Entropy: 2.19541
Value Function Loss: 0.01752

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.52997
Value Function Update Magnitude: 0.60788

Collected Steps per Second: 23,053.03452
Overall Steps per Second: 10,723.06733

Timestep Collection Time: 2.16943
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.66396

Cumulative Model Updates: 249,738
Cumulative Timesteps: 2,082,804,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2082804762...
Checkpoint 2082804762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.25370
Policy Entropy: 2.20576
Value Function Loss: 0.01829

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.53262
Value Function Update Magnitude: 0.58339

Collected Steps per Second: 22,798.55602
Overall Steps per Second: 10,763.36755

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.64799

Cumulative Model Updates: 249,744
Cumulative Timesteps: 2,082,854,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.16988
Policy Entropy: 2.20617
Value Function Loss: 0.01874

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.57624

Collected Steps per Second: 23,199.89274
Overall Steps per Second: 11,021.83370

Timestep Collection Time: 2.15544
Timestep Consumption Time: 2.38155
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.53699

Cumulative Model Updates: 249,750
Cumulative Timesteps: 2,082,904,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2082904796...
Checkpoint 2082904796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.63472
Policy Entropy: 2.20122
Value Function Loss: 0.01786

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.52794
Value Function Update Magnitude: 0.59989

Collected Steps per Second: 22,401.99898
Overall Steps per Second: 10,742.45654

Timestep Collection Time: 2.23266
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.65592

Cumulative Model Updates: 249,756
Cumulative Timesteps: 2,082,954,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.77371
Policy Entropy: 2.20307
Value Function Loss: 0.01837

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.61399

Collected Steps per Second: 22,472.49866
Overall Steps per Second: 10,573.75627

Timestep Collection Time: 2.22601
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.73096

Cumulative Model Updates: 249,762
Cumulative Timesteps: 2,083,004,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2083004836...
Checkpoint 2083004836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.33753
Policy Entropy: 2.18202
Value Function Loss: 0.01838

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.52573
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,291.86312
Overall Steps per Second: 10,578.59177

Timestep Collection Time: 2.24351
Timestep Consumption Time: 2.48415
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.72766

Cumulative Model Updates: 249,768
Cumulative Timesteps: 2,083,054,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.87679
Policy Entropy: 2.16514
Value Function Loss: 0.01866

Mean KL Divergence: 0.02598
SB3 Clip Fraction: 0.15875
Policy Update Magnitude: 0.50859
Value Function Update Magnitude: 0.60439

Collected Steps per Second: 22,937.43837
Overall Steps per Second: 10,935.83910

Timestep Collection Time: 2.18080
Timestep Consumption Time: 2.39333
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.57413

Cumulative Model Updates: 249,774
Cumulative Timesteps: 2,083,104,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2083104870...
Checkpoint 2083104870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.36305
Policy Entropy: 2.17828
Value Function Loss: 0.01704

Mean KL Divergence: 0.02608
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.51977
Value Function Update Magnitude: 0.60018

Collected Steps per Second: 22,867.14426
Overall Steps per Second: 10,611.76886

Timestep Collection Time: 2.18689
Timestep Consumption Time: 2.52561
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.71250

Cumulative Model Updates: 249,780
Cumulative Timesteps: 2,083,154,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.21012
Policy Entropy: 2.18423
Value Function Loss: 0.01727

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.53503
Value Function Update Magnitude: 0.60905

Collected Steps per Second: 22,845.60684
Overall Steps per Second: 10,806.46654

Timestep Collection Time: 2.18922
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.62815

Cumulative Model Updates: 249,786
Cumulative Timesteps: 2,083,204,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2083204892...
Checkpoint 2083204892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.94990
Policy Entropy: 2.21564
Value Function Loss: 0.01691

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.61355

Collected Steps per Second: 22,966.91262
Overall Steps per Second: 10,941.22727

Timestep Collection Time: 2.17800
Timestep Consumption Time: 2.39388
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.57188

Cumulative Model Updates: 249,792
Cumulative Timesteps: 2,083,254,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.98649
Policy Entropy: 2.20977
Value Function Loss: 0.01691

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.54310
Value Function Update Magnitude: 0.60431

Collected Steps per Second: 23,421.61067
Overall Steps per Second: 10,799.51307

Timestep Collection Time: 2.13572
Timestep Consumption Time: 2.49616
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.63188

Cumulative Model Updates: 249,798
Cumulative Timesteps: 2,083,304,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2083304936...
Checkpoint 2083304936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.85474
Policy Entropy: 2.21543
Value Function Loss: 0.01691

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 22,782.53701
Overall Steps per Second: 10,685.60960

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.68050

Cumulative Model Updates: 249,804
Cumulative Timesteps: 2,083,354,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.61448
Policy Entropy: 2.22458
Value Function Loss: 0.01673

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.52330
Value Function Update Magnitude: 0.61886

Collected Steps per Second: 23,127.19184
Overall Steps per Second: 10,819.14172

Timestep Collection Time: 2.16334
Timestep Consumption Time: 2.46106
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.62440

Cumulative Model Updates: 249,810
Cumulative Timesteps: 2,083,404,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2083404982...
Checkpoint 2083404982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.69993
Policy Entropy: 2.25777
Value Function Loss: 0.01619

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.51538
Value Function Update Magnitude: 0.62153

Collected Steps per Second: 22,410.48250
Overall Steps per Second: 10,829.74640

Timestep Collection Time: 2.23217
Timestep Consumption Time: 2.38696
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.61913

Cumulative Model Updates: 249,816
Cumulative Timesteps: 2,083,455,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.22010
Policy Entropy: 2.29704
Value Function Loss: 0.01544

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.50851
Value Function Update Magnitude: 0.57382

Collected Steps per Second: 23,182.48772
Overall Steps per Second: 10,717.67863

Timestep Collection Time: 2.15758
Timestep Consumption Time: 2.50929
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.66687

Cumulative Model Updates: 249,822
Cumulative Timesteps: 2,083,505,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2083505024...
Checkpoint 2083505024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.78876
Policy Entropy: 2.26978
Value Function Loss: 0.01559

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.49694
Value Function Update Magnitude: 0.53639

Collected Steps per Second: 22,496.45298
Overall Steps per Second: 10,615.02770

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.48773
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.71030

Cumulative Model Updates: 249,828
Cumulative Timesteps: 2,083,555,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.00641
Policy Entropy: 2.23355
Value Function Loss: 0.01592

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.50062
Value Function Update Magnitude: 0.54396

Collected Steps per Second: 22,624.20200
Overall Steps per Second: 10,836.73815

Timestep Collection Time: 2.21002
Timestep Consumption Time: 2.40391
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61393

Cumulative Model Updates: 249,834
Cumulative Timesteps: 2,083,605,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2083605024...
Checkpoint 2083605024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.65078
Policy Entropy: 2.18246
Value Function Loss: 0.01658

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.53649
Value Function Update Magnitude: 0.56491

Collected Steps per Second: 22,240.96064
Overall Steps per Second: 10,728.50707

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.41344
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.66253

Cumulative Model Updates: 249,840
Cumulative Timesteps: 2,083,655,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.86678
Policy Entropy: 2.19982
Value Function Loss: 0.01779

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.62405

Collected Steps per Second: 23,454.80623
Overall Steps per Second: 10,883.84785

Timestep Collection Time: 2.13304
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.59672

Cumulative Model Updates: 249,846
Cumulative Timesteps: 2,083,705,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2083705076...
Checkpoint 2083705076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.98528
Policy Entropy: 2.21661
Value Function Loss: 0.01777

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.66767

Collected Steps per Second: 22,986.18838
Overall Steps per Second: 10,690.41307

Timestep Collection Time: 2.17548
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.67765

Cumulative Model Updates: 249,852
Cumulative Timesteps: 2,083,755,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.47904
Policy Entropy: 2.24117
Value Function Loss: 0.01820

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.54081
Value Function Update Magnitude: 0.67470

Collected Steps per Second: 22,831.89365
Overall Steps per Second: 10,881.70897

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.40495
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59487

Cumulative Model Updates: 249,858
Cumulative Timesteps: 2,083,805,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2083805082...
Checkpoint 2083805082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.10137
Policy Entropy: 2.23777
Value Function Loss: 0.01826

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.52947
Value Function Update Magnitude: 0.67419

Collected Steps per Second: 23,523.38050
Overall Steps per Second: 11,013.00952

Timestep Collection Time: 2.12657
Timestep Consumption Time: 2.41570
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.54226

Cumulative Model Updates: 249,864
Cumulative Timesteps: 2,083,855,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.15955
Policy Entropy: 2.22527
Value Function Loss: 0.01860

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.11790
Policy Update Magnitude: 0.53040
Value Function Update Magnitude: 0.66270

Collected Steps per Second: 23,504.39745
Overall Steps per Second: 10,969.32245

Timestep Collection Time: 2.12735
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.55835

Cumulative Model Updates: 249,870
Cumulative Timesteps: 2,083,905,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2083905108...
Checkpoint 2083905108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.58684
Policy Entropy: 2.20025
Value Function Loss: 0.01854

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.52872
Value Function Update Magnitude: 0.65186

Collected Steps per Second: 22,851.25580
Overall Steps per Second: 10,754.98030

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.46114
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.64938

Cumulative Model Updates: 249,876
Cumulative Timesteps: 2,083,955,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.10385
Policy Entropy: 2.20126
Value Function Loss: 0.01835

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.64332

Collected Steps per Second: 22,634.64949
Overall Steps per Second: 10,838.66183

Timestep Collection Time: 2.20971
Timestep Consumption Time: 2.40488
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.61459

Cumulative Model Updates: 249,882
Cumulative Timesteps: 2,084,005,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2084005128...
Checkpoint 2084005128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.00921
Policy Entropy: 2.19736
Value Function Loss: 0.01855

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.53973
Value Function Update Magnitude: 0.63260

Collected Steps per Second: 22,730.25583
Overall Steps per Second: 10,627.04809

Timestep Collection Time: 2.20103
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.70780

Cumulative Model Updates: 249,888
Cumulative Timesteps: 2,084,055,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.36297
Policy Entropy: 2.22385
Value Function Loss: 0.01739

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.53286
Value Function Update Magnitude: 0.63626

Collected Steps per Second: 22,792.36562
Overall Steps per Second: 10,798.96092

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.63045

Cumulative Model Updates: 249,894
Cumulative Timesteps: 2,084,105,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2084105162...
Checkpoint 2084105162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.26546
Policy Entropy: 2.20713
Value Function Loss: 0.01723

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.52541
Value Function Update Magnitude: 0.64375

Collected Steps per Second: 22,642.31447
Overall Steps per Second: 10,794.07891

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.42547
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.63513

Cumulative Model Updates: 249,900
Cumulative Timesteps: 2,084,155,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.13258
Policy Entropy: 2.23087
Value Function Loss: 0.01602

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.52185
Value Function Update Magnitude: 0.63297

Collected Steps per Second: 23,886.89898
Overall Steps per Second: 10,903.40961

Timestep Collection Time: 2.09345
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.58627

Cumulative Model Updates: 249,906
Cumulative Timesteps: 2,084,205,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2084205200...
Checkpoint 2084205200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.18724
Policy Entropy: 2.21867
Value Function Loss: 0.01621

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.51858
Value Function Update Magnitude: 0.63345

Collected Steps per Second: 23,606.37331
Overall Steps per Second: 11,017.50490

Timestep Collection Time: 2.11892
Timestep Consumption Time: 2.42113
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.54005

Cumulative Model Updates: 249,912
Cumulative Timesteps: 2,084,255,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.54514
Policy Entropy: 2.23859
Value Function Loss: 0.01607

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.51449
Value Function Update Magnitude: 0.62970

Collected Steps per Second: 23,090.21844
Overall Steps per Second: 10,871.77704

Timestep Collection Time: 2.16646
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60127

Cumulative Model Updates: 249,918
Cumulative Timesteps: 2,084,305,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2084305244...
Checkpoint 2084305244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.94532
Policy Entropy: 2.25127
Value Function Loss: 0.01718

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.52297
Value Function Update Magnitude: 0.62738

Collected Steps per Second: 23,006.66019
Overall Steps per Second: 10,737.20469

Timestep Collection Time: 2.17407
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.65838

Cumulative Model Updates: 249,924
Cumulative Timesteps: 2,084,355,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.10478
Policy Entropy: 2.27150
Value Function Loss: 0.01720

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.11359
Policy Update Magnitude: 0.52868
Value Function Update Magnitude: 0.61832

Collected Steps per Second: 24,030.80594
Overall Steps per Second: 10,903.58787

Timestep Collection Time: 2.08149
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.58748

Cumulative Model Updates: 249,930
Cumulative Timesteps: 2,084,405,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2084405282...
Checkpoint 2084405282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.33743
Policy Entropy: 2.24385
Value Function Loss: 0.01708

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.52291
Value Function Update Magnitude: 0.60644

Collected Steps per Second: 22,816.75808
Overall Steps per Second: 10,634.96057

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.51030
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.70185

Cumulative Model Updates: 249,936
Cumulative Timesteps: 2,084,455,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.41889
Policy Entropy: 2.23181
Value Function Loss: 0.01626

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.51803
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 22,491.61657
Overall Steps per Second: 10,567.73227

Timestep Collection Time: 2.22376
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.73290

Cumulative Model Updates: 249,942
Cumulative Timesteps: 2,084,505,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2084505302...
Checkpoint 2084505302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.55680
Policy Entropy: 2.19956
Value Function Loss: 0.01606

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.50950
Value Function Update Magnitude: 0.58509

Collected Steps per Second: 22,481.14901
Overall Steps per Second: 10,686.44407

Timestep Collection Time: 2.22435
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67939

Cumulative Model Updates: 249,948
Cumulative Timesteps: 2,084,555,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.27776
Policy Entropy: 2.23112
Value Function Loss: 0.01573

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.51245
Value Function Update Magnitude: 0.59034

Collected Steps per Second: 23,961.69424
Overall Steps per Second: 10,862.89208

Timestep Collection Time: 2.08792
Timestep Consumption Time: 2.51767
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.60559

Cumulative Model Updates: 249,954
Cumulative Timesteps: 2,084,605,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2084605338...
Checkpoint 2084605338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.01284
Policy Entropy: 2.22266
Value Function Loss: 0.01626

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.50949
Value Function Update Magnitude: 0.60686

Collected Steps per Second: 23,331.66146
Overall Steps per Second: 10,954.75064

Timestep Collection Time: 2.14430
Timestep Consumption Time: 2.42267
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.56697

Cumulative Model Updates: 249,960
Cumulative Timesteps: 2,084,655,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.57729
Policy Entropy: 2.23852
Value Function Loss: 0.01597

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.51521
Value Function Update Magnitude: 0.63530

Collected Steps per Second: 23,307.09375
Overall Steps per Second: 11,003.84983

Timestep Collection Time: 2.14596
Timestep Consumption Time: 2.39936
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.54532

Cumulative Model Updates: 249,966
Cumulative Timesteps: 2,084,705,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2084705384...
Checkpoint 2084705384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.87821
Policy Entropy: 2.24861
Value Function Loss: 0.01663

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.51920
Value Function Update Magnitude: 0.64015

Collected Steps per Second: 23,315.97258
Overall Steps per Second: 11,093.91487

Timestep Collection Time: 2.14557
Timestep Consumption Time: 2.36375
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.50932

Cumulative Model Updates: 249,972
Cumulative Timesteps: 2,084,755,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.09828
Policy Entropy: 2.24261
Value Function Loss: 0.01734

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.51929
Value Function Update Magnitude: 0.62238

Collected Steps per Second: 23,292.43757
Overall Steps per Second: 10,944.55679

Timestep Collection Time: 2.14679
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.56885

Cumulative Model Updates: 249,978
Cumulative Timesteps: 2,084,805,414

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2084805414...
Checkpoint 2084805414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.66244
Policy Entropy: 2.21856
Value Function Loss: 0.01857

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.52327
Value Function Update Magnitude: 0.61381

Collected Steps per Second: 23,173.49422
Overall Steps per Second: 10,827.98577

Timestep Collection Time: 2.15772
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.61785

Cumulative Model Updates: 249,984
Cumulative Timesteps: 2,084,855,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.75961
Policy Entropy: 2.19937
Value Function Loss: 0.01758

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.63990

Collected Steps per Second: 22,878.23412
Overall Steps per Second: 10,716.47905

Timestep Collection Time: 2.18566
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.66608

Cumulative Model Updates: 249,990
Cumulative Timesteps: 2,084,905,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2084905420...
Checkpoint 2084905420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.30531
Policy Entropy: 2.21719
Value Function Loss: 0.01701

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.52478
Value Function Update Magnitude: 0.66912

Collected Steps per Second: 23,277.64056
Overall Steps per Second: 10,924.29239

Timestep Collection Time: 2.14833
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.57769

Cumulative Model Updates: 249,996
Cumulative Timesteps: 2,084,955,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.56706
Policy Entropy: 2.23581
Value Function Loss: 0.01740

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.69526

Collected Steps per Second: 22,582.81241
Overall Steps per Second: 10,625.13852

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.70639

Cumulative Model Updates: 250,002
Cumulative Timesteps: 2,085,005,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2085005434...
Checkpoint 2085005434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.18291
Policy Entropy: 2.23325
Value Function Loss: 0.01731

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.54232
Value Function Update Magnitude: 0.70853

Collected Steps per Second: 22,614.63192
Overall Steps per Second: 10,747.58563

Timestep Collection Time: 2.21202
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.65444

Cumulative Model Updates: 250,008
Cumulative Timesteps: 2,085,055,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.70356
Policy Entropy: 2.21819
Value Function Loss: 0.01814

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.69565

Collected Steps per Second: 22,759.00970
Overall Steps per Second: 10,703.55061

Timestep Collection Time: 2.19711
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.67172

Cumulative Model Updates: 250,014
Cumulative Timesteps: 2,085,105,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2085105462...
Checkpoint 2085105462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.97314
Policy Entropy: 2.20518
Value Function Loss: 0.01807

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.53545
Value Function Update Magnitude: 0.69618

Collected Steps per Second: 23,607.09814
Overall Steps per Second: 10,995.03289

Timestep Collection Time: 2.11868
Timestep Consumption Time: 2.43028
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.54896

Cumulative Model Updates: 250,020
Cumulative Timesteps: 2,085,155,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.81112
Policy Entropy: 2.21735
Value Function Loss: 0.01857

Mean KL Divergence: 0.03099
SB3 Clip Fraction: 0.16695
Policy Update Magnitude: 0.52237
Value Function Update Magnitude: 0.70490

Collected Steps per Second: 23,082.27539
Overall Steps per Second: 10,770.69554

Timestep Collection Time: 2.16642
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.64278

Cumulative Model Updates: 250,026
Cumulative Timesteps: 2,085,205,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2085205484...
Checkpoint 2085205484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.91002
Policy Entropy: 2.20609
Value Function Loss: 0.01852

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.53344
Value Function Update Magnitude: 0.71581

Collected Steps per Second: 23,404.58818
Overall Steps per Second: 10,921.23790

Timestep Collection Time: 2.13753
Timestep Consumption Time: 2.44327
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.58080

Cumulative Model Updates: 250,032
Cumulative Timesteps: 2,085,255,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.29987
Policy Entropy: 2.19705
Value Function Loss: 0.01901

Mean KL Divergence: 0.02698
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.51686
Value Function Update Magnitude: 0.70613

Collected Steps per Second: 23,312.06844
Overall Steps per Second: 10,963.47037

Timestep Collection Time: 2.14507
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.56115

Cumulative Model Updates: 250,038
Cumulative Timesteps: 2,085,305,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2085305518...
Checkpoint 2085305518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.09883
Policy Entropy: 2.17076
Value Function Loss: 0.01847

Mean KL Divergence: 0.02602
SB3 Clip Fraction: 0.15972
Policy Update Magnitude: 0.51239
Value Function Update Magnitude: 0.68170

Collected Steps per Second: 23,163.01717
Overall Steps per Second: 10,937.20702

Timestep Collection Time: 2.15913
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.57265

Cumulative Model Updates: 250,044
Cumulative Timesteps: 2,085,355,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.48274
Policy Entropy: 2.19256
Value Function Loss: 0.01867

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.52398
Value Function Update Magnitude: 0.66847

Collected Steps per Second: 22,965.48574
Overall Steps per Second: 10,702.13679

Timestep Collection Time: 2.17762
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67290

Cumulative Model Updates: 250,050
Cumulative Timesteps: 2,085,405,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2085405540...
Checkpoint 2085405540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.12651
Policy Entropy: 2.21369
Value Function Loss: 0.01740

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.67439

Collected Steps per Second: 22,617.82484
Overall Steps per Second: 10,849.18770

Timestep Collection Time: 2.21091
Timestep Consumption Time: 2.39828
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.60919

Cumulative Model Updates: 250,056
Cumulative Timesteps: 2,085,455,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.84270
Policy Entropy: 2.23572
Value Function Loss: 0.01751

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.52951
Value Function Update Magnitude: 0.67577

Collected Steps per Second: 22,843.88039
Overall Steps per Second: 11,034.58673

Timestep Collection Time: 2.18912
Timestep Consumption Time: 2.34281
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.53193

Cumulative Model Updates: 250,062
Cumulative Timesteps: 2,085,505,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2085505554...
Checkpoint 2085505554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.61867
Policy Entropy: 2.24540
Value Function Loss: 0.01659

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.51775
Value Function Update Magnitude: 0.67840

Collected Steps per Second: 22,552.05137
Overall Steps per Second: 10,614.84944

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.71283

Cumulative Model Updates: 250,068
Cumulative Timesteps: 2,085,555,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.57363
Policy Entropy: 2.23456
Value Function Loss: 0.01649

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.50621
Value Function Update Magnitude: 0.66556

Collected Steps per Second: 22,693.74818
Overall Steps per Second: 10,591.50535

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.51762
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.72095

Cumulative Model Updates: 250,074
Cumulative Timesteps: 2,085,605,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2085605582...
Checkpoint 2085605582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.89018
Policy Entropy: 2.23409
Value Function Loss: 0.01803

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.64653

Collected Steps per Second: 22,976.38281
Overall Steps per Second: 10,936.07230

Timestep Collection Time: 2.17693
Timestep Consumption Time: 2.39674
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.57367

Cumulative Model Updates: 250,080
Cumulative Timesteps: 2,085,655,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.97664
Policy Entropy: 2.22597
Value Function Loss: 0.01784

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.54435
Value Function Update Magnitude: 0.64635

Collected Steps per Second: 23,306.29599
Overall Steps per Second: 10,952.21359

Timestep Collection Time: 2.14569
Timestep Consumption Time: 2.42033
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.56602

Cumulative Model Updates: 250,086
Cumulative Timesteps: 2,085,705,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2085705608...
Checkpoint 2085705608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.59032
Policy Entropy: 2.23500
Value Function Loss: 0.01743

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.63325

Collected Steps per Second: 22,731.46260
Overall Steps per Second: 10,665.93934

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69007

Cumulative Model Updates: 250,092
Cumulative Timesteps: 2,085,755,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.43893
Policy Entropy: 2.21921
Value Function Loss: 0.01597

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.52507
Value Function Update Magnitude: 0.61775

Collected Steps per Second: 22,849.57538
Overall Steps per Second: 10,917.11995

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.39183
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.58015

Cumulative Model Updates: 250,098
Cumulative Timesteps: 2,085,805,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2085805634...
Checkpoint 2085805634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.29011
Policy Entropy: 2.21389
Value Function Loss: 0.01712

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.52539
Value Function Update Magnitude: 0.61011

Collected Steps per Second: 23,011.80659
Overall Steps per Second: 11,095.83062

Timestep Collection Time: 2.17367
Timestep Consumption Time: 2.33433
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.50800

Cumulative Model Updates: 250,104
Cumulative Timesteps: 2,085,855,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.76150
Policy Entropy: 2.18399
Value Function Loss: 0.01736

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.52299
Value Function Update Magnitude: 0.60991

Collected Steps per Second: 22,961.08283
Overall Steps per Second: 10,842.45691

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61390

Cumulative Model Updates: 250,110
Cumulative Timesteps: 2,085,905,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2085905680...
Checkpoint 2085905680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.84185
Policy Entropy: 2.21184
Value Function Loss: 0.01763

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.52146
Value Function Update Magnitude: 0.59995

Collected Steps per Second: 22,389.56837
Overall Steps per Second: 10,659.91831

Timestep Collection Time: 2.23336
Timestep Consumption Time: 2.45748
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69084

Cumulative Model Updates: 250,116
Cumulative Timesteps: 2,085,955,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.54797
Policy Entropy: 2.21929
Value Function Loss: 0.01720

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.52121
Value Function Update Magnitude: 0.59891

Collected Steps per Second: 23,007.04285
Overall Steps per Second: 10,916.64341

Timestep Collection Time: 2.17420
Timestep Consumption Time: 2.40797
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.58218

Cumulative Model Updates: 250,122
Cumulative Timesteps: 2,086,005,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2086005706...
Checkpoint 2086005706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.43725
Policy Entropy: 2.23609
Value Function Loss: 0.01794

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.52902
Value Function Update Magnitude: 0.59456

Collected Steps per Second: 22,875.13683
Overall Steps per Second: 10,684.37425

Timestep Collection Time: 2.18613
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.68048

Cumulative Model Updates: 250,128
Cumulative Timesteps: 2,086,055,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.94933
Policy Entropy: 2.21534
Value Function Loss: 0.01854

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.53625
Value Function Update Magnitude: 0.60413

Collected Steps per Second: 23,393.88955
Overall Steps per Second: 10,881.49722

Timestep Collection Time: 2.13791
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.59624

Cumulative Model Updates: 250,134
Cumulative Timesteps: 2,086,105,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2086105728...
Checkpoint 2086105728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.96020
Policy Entropy: 2.21557
Value Function Loss: 0.01821

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.62426

Collected Steps per Second: 22,804.26957
Overall Steps per Second: 10,737.18226

Timestep Collection Time: 2.19345
Timestep Consumption Time: 2.46513
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.65858

Cumulative Model Updates: 250,140
Cumulative Timesteps: 2,086,155,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.97922
Policy Entropy: 2.19389
Value Function Loss: 0.01780

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.61710

Collected Steps per Second: 22,982.86306
Overall Steps per Second: 10,920.86169

Timestep Collection Time: 2.17553
Timestep Consumption Time: 2.40286
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.57839

Cumulative Model Updates: 250,146
Cumulative Timesteps: 2,086,205,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2086205748...
Checkpoint 2086205748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.46064
Policy Entropy: 2.18342
Value Function Loss: 0.01851

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.53824
Value Function Update Magnitude: 0.61323

Collected Steps per Second: 23,130.33599
Overall Steps per Second: 10,918.95151

Timestep Collection Time: 2.16261
Timestep Consumption Time: 2.41859
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.58121

Cumulative Model Updates: 250,152
Cumulative Timesteps: 2,086,255,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.22346
Policy Entropy: 2.18842
Value Function Loss: 0.01819

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.54486
Value Function Update Magnitude: 0.60016

Collected Steps per Second: 23,490.05974
Overall Steps per Second: 10,991.48214

Timestep Collection Time: 2.12950
Timestep Consumption Time: 2.42148
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.55098

Cumulative Model Updates: 250,158
Cumulative Timesteps: 2,086,305,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2086305792...
Checkpoint 2086305792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.89414
Policy Entropy: 2.18808
Value Function Loss: 0.01886

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.60460

Collected Steps per Second: 22,697.93060
Overall Steps per Second: 10,690.09322

Timestep Collection Time: 2.20355
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.67872

Cumulative Model Updates: 250,164
Cumulative Timesteps: 2,086,355,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.43606
Policy Entropy: 2.18915
Value Function Loss: 0.01823

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.54133
Value Function Update Magnitude: 0.62810

Collected Steps per Second: 22,490.53557
Overall Steps per Second: 10,883.19872

Timestep Collection Time: 2.22325
Timestep Consumption Time: 2.37118
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.59442

Cumulative Model Updates: 250,170
Cumulative Timesteps: 2,086,405,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2086405810...
Checkpoint 2086405810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.09997
Policy Entropy: 2.17580
Value Function Loss: 0.01766

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.63998

Collected Steps per Second: 22,302.74182
Overall Steps per Second: 10,630.31075

Timestep Collection Time: 2.24304
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.70598

Cumulative Model Updates: 250,176
Cumulative Timesteps: 2,086,455,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.91097
Policy Entropy: 2.19270
Value Function Loss: 0.01875

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.63085

Collected Steps per Second: 22,987.94362
Overall Steps per Second: 10,862.12863

Timestep Collection Time: 2.17566
Timestep Consumption Time: 2.42878
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.60444

Cumulative Model Updates: 250,182
Cumulative Timesteps: 2,086,505,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2086505850...
Checkpoint 2086505850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.18633
Policy Entropy: 2.22388
Value Function Loss: 0.01759

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.53555
Value Function Update Magnitude: 0.63027

Collected Steps per Second: 22,627.01059
Overall Steps per Second: 10,759.46030

Timestep Collection Time: 2.21046
Timestep Consumption Time: 2.43810
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.64856

Cumulative Model Updates: 250,188
Cumulative Timesteps: 2,086,555,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.81050
Policy Entropy: 2.25451
Value Function Loss: 0.01727

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.61533

Collected Steps per Second: 23,500.78181
Overall Steps per Second: 10,835.88574

Timestep Collection Time: 2.12776
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.61467

Cumulative Model Updates: 250,194
Cumulative Timesteps: 2,086,605,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2086605870...
Checkpoint 2086605870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.95556
Policy Entropy: 2.25588
Value Function Loss: 0.01719

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.53664
Value Function Update Magnitude: 0.59879

Collected Steps per Second: 22,979.04677
Overall Steps per Second: 10,686.49367

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.68086

Cumulative Model Updates: 250,200
Cumulative Timesteps: 2,086,655,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.06161
Policy Entropy: 2.23546
Value Function Loss: 0.01729

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.53591
Value Function Update Magnitude: 0.59084

Collected Steps per Second: 23,269.29664
Overall Steps per Second: 10,857.45625

Timestep Collection Time: 2.14987
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.60752

Cumulative Model Updates: 250,206
Cumulative Timesteps: 2,086,705,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2086705918...
Checkpoint 2086705918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.47207
Policy Entropy: 2.22182
Value Function Loss: 0.01808

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.58941

Collected Steps per Second: 23,070.05380
Overall Steps per Second: 11,072.74632

Timestep Collection Time: 2.16740
Timestep Consumption Time: 2.34837
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.51577

Cumulative Model Updates: 250,212
Cumulative Timesteps: 2,086,755,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.68304
Policy Entropy: 2.22561
Value Function Loss: 0.01781

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.53082
Value Function Update Magnitude: 0.58140

Collected Steps per Second: 23,202.18336
Overall Steps per Second: 10,918.59354

Timestep Collection Time: 2.15557
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.58063

Cumulative Model Updates: 250,218
Cumulative Timesteps: 2,086,805,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2086805934...
Checkpoint 2086805934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.80899
Policy Entropy: 2.20669
Value Function Loss: 0.01838

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.52910
Value Function Update Magnitude: 0.56563

Collected Steps per Second: 22,920.35057
Overall Steps per Second: 10,665.68414

Timestep Collection Time: 2.18190
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.68887

Cumulative Model Updates: 250,224
Cumulative Timesteps: 2,086,855,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.33110
Policy Entropy: 2.18862
Value Function Loss: 0.01857

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.56915

Collected Steps per Second: 22,550.74583
Overall Steps per Second: 10,809.45954

Timestep Collection Time: 2.21775
Timestep Consumption Time: 2.40893
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62669

Cumulative Model Updates: 250,230
Cumulative Timesteps: 2,086,905,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2086905956...
Checkpoint 2086905956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.96580
Policy Entropy: 2.17547
Value Function Loss: 0.01898

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.53546
Value Function Update Magnitude: 0.59829

Collected Steps per Second: 22,657.88639
Overall Steps per Second: 10,825.48875

Timestep Collection Time: 2.20780
Timestep Consumption Time: 2.41315
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.62095

Cumulative Model Updates: 250,236
Cumulative Timesteps: 2,086,955,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.79060
Policy Entropy: 2.19313
Value Function Loss: 0.01863

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.52643
Value Function Update Magnitude: 0.63385

Collected Steps per Second: 22,676.64498
Overall Steps per Second: 10,794.03624

Timestep Collection Time: 2.20509
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.63256

Cumulative Model Updates: 250,242
Cumulative Timesteps: 2,087,005,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2087005984...
Checkpoint 2087005984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.96677
Policy Entropy: 2.21638
Value Function Loss: 0.01859

Mean KL Divergence: 0.02955
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.51829
Value Function Update Magnitude: 0.63928

Collected Steps per Second: 22,458.16480
Overall Steps per Second: 10,708.35246

Timestep Collection Time: 2.22654
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.66963

Cumulative Model Updates: 250,248
Cumulative Timesteps: 2,087,055,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.18412
Policy Entropy: 2.22940
Value Function Loss: 0.01787

Mean KL Divergence: 0.03286
SB3 Clip Fraction: 0.17704
Policy Update Magnitude: 0.51015
Value Function Update Magnitude: 0.62768

Collected Steps per Second: 23,391.31190
Overall Steps per Second: 10,888.85717

Timestep Collection Time: 2.13857
Timestep Consumption Time: 2.45548
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.59405

Cumulative Model Updates: 250,254
Cumulative Timesteps: 2,087,106,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2087106012...
Checkpoint 2087106012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.44477
Policy Entropy: 2.22436
Value Function Loss: 0.01701

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.16794
Policy Update Magnitude: 0.52398
Value Function Update Magnitude: 0.62821

Collected Steps per Second: 23,079.05266
Overall Steps per Second: 10,794.99450

Timestep Collection Time: 2.16655
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.63196

Cumulative Model Updates: 250,260
Cumulative Timesteps: 2,087,156,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.59781
Policy Entropy: 2.22288
Value Function Loss: 0.01698

Mean KL Divergence: 0.02850
SB3 Clip Fraction: 0.16804
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.63876

Collected Steps per Second: 22,997.90189
Overall Steps per Second: 10,737.45237

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.65697

Cumulative Model Updates: 250,266
Cumulative Timesteps: 2,087,206,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2087206018...
Checkpoint 2087206018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.47419
Policy Entropy: 2.22262
Value Function Loss: 0.01688

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.66218

Collected Steps per Second: 22,877.94003
Overall Steps per Second: 10,745.66780

Timestep Collection Time: 2.18656
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.65527

Cumulative Model Updates: 250,272
Cumulative Timesteps: 2,087,256,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.25140
Policy Entropy: 2.22055
Value Function Loss: 0.01651

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.65716

Collected Steps per Second: 23,182.20291
Overall Steps per Second: 10,942.85015

Timestep Collection Time: 2.15795
Timestep Consumption Time: 2.41362
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.57157

Cumulative Model Updates: 250,278
Cumulative Timesteps: 2,087,306,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2087306068...
Checkpoint 2087306068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.62371
Policy Entropy: 2.22532
Value Function Loss: 0.01622

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.62270

Collected Steps per Second: 22,977.55091
Overall Steps per Second: 10,759.20151

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.64737

Cumulative Model Updates: 250,284
Cumulative Timesteps: 2,087,356,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.10580
Policy Entropy: 2.20872
Value Function Loss: 0.01625

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.59910

Collected Steps per Second: 22,841.36374
Overall Steps per Second: 10,721.12556

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.66630

Cumulative Model Updates: 250,290
Cumulative Timesteps: 2,087,406,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2087406098...
Checkpoint 2087406098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.67152
Policy Entropy: 2.21376
Value Function Loss: 0.01657

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.52623
Value Function Update Magnitude: 0.58711

Collected Steps per Second: 22,193.33211
Overall Steps per Second: 10,751.20035

Timestep Collection Time: 2.25329
Timestep Consumption Time: 2.39810
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.65139

Cumulative Model Updates: 250,296
Cumulative Timesteps: 2,087,456,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.76490
Policy Entropy: 2.16652
Value Function Loss: 0.01662

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.53031
Value Function Update Magnitude: 0.59150

Collected Steps per Second: 22,864.67723
Overall Steps per Second: 10,787.06131

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.44968
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.63759

Cumulative Model Updates: 250,302
Cumulative Timesteps: 2,087,506,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2087506132...
Checkpoint 2087506132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.49030
Policy Entropy: 2.15444
Value Function Loss: 0.01786

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.54134
Value Function Update Magnitude: 0.60483

Collected Steps per Second: 22,579.34146
Overall Steps per Second: 10,605.09202

Timestep Collection Time: 2.21503
Timestep Consumption Time: 2.50100
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.71604

Cumulative Model Updates: 250,308
Cumulative Timesteps: 2,087,556,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.61944
Policy Entropy: 2.15053
Value Function Loss: 0.01913

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.62813

Collected Steps per Second: 23,033.81242
Overall Steps per Second: 10,863.65067

Timestep Collection Time: 2.17176
Timestep Consumption Time: 2.43295
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.60471

Cumulative Model Updates: 250,314
Cumulative Timesteps: 2,087,606,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2087606170...
Checkpoint 2087606170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.27430
Policy Entropy: 2.18490
Value Function Loss: 0.01893

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.65073

Collected Steps per Second: 22,902.44795
Overall Steps per Second: 10,895.80478

Timestep Collection Time: 2.18370
Timestep Consumption Time: 2.40633
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.59002

Cumulative Model Updates: 250,320
Cumulative Timesteps: 2,087,656,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.54419
Policy Entropy: 2.19247
Value Function Loss: 0.01860

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.65257

Collected Steps per Second: 23,216.50611
Overall Steps per Second: 10,718.55264

Timestep Collection Time: 2.15390
Timestep Consumption Time: 2.51147
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.66537

Cumulative Model Updates: 250,326
Cumulative Timesteps: 2,087,706,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2087706188...
Checkpoint 2087706188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.41824
Policy Entropy: 2.18368
Value Function Loss: 0.01754

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.54675
Value Function Update Magnitude: 0.63858

Collected Steps per Second: 23,017.49261
Overall Steps per Second: 10,681.94440

Timestep Collection Time: 2.17348
Timestep Consumption Time: 2.50994
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.68342

Cumulative Model Updates: 250,332
Cumulative Timesteps: 2,087,756,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.01780
Policy Entropy: 2.16972
Value Function Loss: 0.01760

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.63437

Collected Steps per Second: 23,113.01523
Overall Steps per Second: 10,933.25615

Timestep Collection Time: 2.16354
Timestep Consumption Time: 2.41021
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.57375

Cumulative Model Updates: 250,338
Cumulative Timesteps: 2,087,806,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2087806222...
Checkpoint 2087806222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.32812
Policy Entropy: 2.14305
Value Function Loss: 0.01791

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.65858

Collected Steps per Second: 23,012.65424
Overall Steps per Second: 11,107.48896

Timestep Collection Time: 2.17324
Timestep Consumption Time: 2.32931
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.50255

Cumulative Model Updates: 250,344
Cumulative Timesteps: 2,087,856,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.82238
Policy Entropy: 2.16361
Value Function Loss: 0.01910

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.66097

Collected Steps per Second: 22,942.62432
Overall Steps per Second: 10,833.76575

Timestep Collection Time: 2.18048
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.61760

Cumulative Model Updates: 250,350
Cumulative Timesteps: 2,087,906,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2087906260...
Checkpoint 2087906260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.83568
Policy Entropy: 2.17454
Value Function Loss: 0.01908

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.67133

Collected Steps per Second: 22,558.86055
Overall Steps per Second: 10,681.77312

Timestep Collection Time: 2.21767
Timestep Consumption Time: 2.46583
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.68349

Cumulative Model Updates: 250,356
Cumulative Timesteps: 2,087,956,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.04229
Policy Entropy: 2.18206
Value Function Loss: 0.01855

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.67880

Collected Steps per Second: 22,613.72708
Overall Steps per Second: 10,819.66525

Timestep Collection Time: 2.21167
Timestep Consumption Time: 2.41084
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.62251

Cumulative Model Updates: 250,362
Cumulative Timesteps: 2,088,006,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2088006302...
Checkpoint 2088006302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.14301
Policy Entropy: 2.17651
Value Function Loss: 0.01799

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.65611

Collected Steps per Second: 23,356.30167
Overall Steps per Second: 10,824.23750

Timestep Collection Time: 2.14109
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.62000

Cumulative Model Updates: 250,368
Cumulative Timesteps: 2,088,056,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.91329
Policy Entropy: 2.17540
Value Function Loss: 0.01688

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.54595
Value Function Update Magnitude: 0.63086

Collected Steps per Second: 23,140.93721
Overall Steps per Second: 10,834.17283

Timestep Collection Time: 2.16171
Timestep Consumption Time: 2.45553
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.61724

Cumulative Model Updates: 250,374
Cumulative Timesteps: 2,088,106,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2088106334...
Checkpoint 2088106334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.00624
Policy Entropy: 2.18485
Value Function Loss: 0.01722

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.61083

Collected Steps per Second: 22,958.95972
Overall Steps per Second: 10,772.41905

Timestep Collection Time: 2.17911
Timestep Consumption Time: 2.46516
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.64427

Cumulative Model Updates: 250,380
Cumulative Timesteps: 2,088,156,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.15753
Policy Entropy: 2.21880
Value Function Loss: 0.01762

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.61612

Collected Steps per Second: 23,257.24121
Overall Steps per Second: 11,113.99874

Timestep Collection Time: 2.15081
Timestep Consumption Time: 2.35000
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.50081

Cumulative Model Updates: 250,386
Cumulative Timesteps: 2,088,206,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2088206386...
Checkpoint 2088206386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.24529
Policy Entropy: 2.22653
Value Function Loss: 0.01835

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.62032

Collected Steps per Second: 23,115.50794
Overall Steps per Second: 10,734.40076

Timestep Collection Time: 2.16374
Timestep Consumption Time: 2.49567
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.65941

Cumulative Model Updates: 250,392
Cumulative Timesteps: 2,088,256,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.47383
Policy Entropy: 2.20839
Value Function Loss: 0.01841

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.62315

Collected Steps per Second: 23,298.18651
Overall Steps per Second: 10,917.87975

Timestep Collection Time: 2.14652
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.58056

Cumulative Model Updates: 250,398
Cumulative Timesteps: 2,088,306,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2088306412...
Checkpoint 2088306412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.56471
Policy Entropy: 2.19578
Value Function Loss: 0.01879

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.63128

Collected Steps per Second: 21,589.98119
Overall Steps per Second: 10,632.23027

Timestep Collection Time: 2.31719
Timestep Consumption Time: 2.38813
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.70532

Cumulative Model Updates: 250,404
Cumulative Timesteps: 2,088,356,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.30607
Policy Entropy: 2.15950
Value Function Loss: 0.01880

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.56489
Value Function Update Magnitude: 0.65318

Collected Steps per Second: 22,461.65731
Overall Steps per Second: 10,622.07880

Timestep Collection Time: 2.22619
Timestep Consumption Time: 2.48136
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.70755

Cumulative Model Updates: 250,410
Cumulative Timesteps: 2,088,406,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2088406444...
Checkpoint 2088406444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.05126
Policy Entropy: 2.18234
Value Function Loss: 0.01800

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.65589

Collected Steps per Second: 22,760.23387
Overall Steps per Second: 10,835.68680

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.61494

Cumulative Model Updates: 250,416
Cumulative Timesteps: 2,088,456,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.13688
Policy Entropy: 2.15250
Value Function Loss: 0.01859

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.56710
Value Function Update Magnitude: 0.63991

Collected Steps per Second: 22,970.97139
Overall Steps per Second: 10,909.21669

Timestep Collection Time: 2.17753
Timestep Consumption Time: 2.40758
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.58511

Cumulative Model Updates: 250,422
Cumulative Timesteps: 2,088,506,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2088506470...
Checkpoint 2088506470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.17499
Policy Entropy: 2.17173
Value Function Loss: 0.01851

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.64940

Collected Steps per Second: 22,974.24458
Overall Steps per Second: 10,711.95063

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.66899

Cumulative Model Updates: 250,428
Cumulative Timesteps: 2,088,556,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.37786
Policy Entropy: 2.17842
Value Function Loss: 0.01870

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.56583
Value Function Update Magnitude: 0.66229

Collected Steps per Second: 23,985.00542
Overall Steps per Second: 10,917.90457

Timestep Collection Time: 2.08555
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.58165

Cumulative Model Updates: 250,434
Cumulative Timesteps: 2,088,606,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2088606506...
Checkpoint 2088606506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.92858
Policy Entropy: 2.17333
Value Function Loss: 0.01837

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.56618
Value Function Update Magnitude: 0.64440

Collected Steps per Second: 23,046.71828
Overall Steps per Second: 10,744.27924

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.65531

Cumulative Model Updates: 250,440
Cumulative Timesteps: 2,088,656,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.04726
Policy Entropy: 2.14402
Value Function Loss: 0.01896

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.57776
Value Function Update Magnitude: 0.67175

Collected Steps per Second: 23,017.01566
Overall Steps per Second: 10,807.71249

Timestep Collection Time: 2.17283
Timestep Consumption Time: 2.45461
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.62744

Cumulative Model Updates: 250,446
Cumulative Timesteps: 2,088,706,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2088706536...
Checkpoint 2088706536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.71379
Policy Entropy: 2.11559
Value Function Loss: 0.02000

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.69556

Collected Steps per Second: 23,232.45061
Overall Steps per Second: 11,124.33668

Timestep Collection Time: 2.15225
Timestep Consumption Time: 2.34258
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.49483

Cumulative Model Updates: 250,452
Cumulative Timesteps: 2,088,756,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.10518
Policy Entropy: 2.10049
Value Function Loss: 0.01992

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.58459
Value Function Update Magnitude: 0.68838

Collected Steps per Second: 22,826.15837
Overall Steps per Second: 10,851.06790

Timestep Collection Time: 2.19170
Timestep Consumption Time: 2.41873
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61042

Cumulative Model Updates: 250,458
Cumulative Timesteps: 2,088,806,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2088806566...
Checkpoint 2088806566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.65572
Policy Entropy: 2.10260
Value Function Loss: 0.01938

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.57424
Value Function Update Magnitude: 0.67140

Collected Steps per Second: 22,401.94514
Overall Steps per Second: 10,704.07302

Timestep Collection Time: 2.23293
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.67317

Cumulative Model Updates: 250,464
Cumulative Timesteps: 2,088,856,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.90300
Policy Entropy: 2.13515
Value Function Loss: 0.01914

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.57351
Value Function Update Magnitude: 0.65943

Collected Steps per Second: 22,899.88624
Overall Steps per Second: 10,927.34003

Timestep Collection Time: 2.18447
Timestep Consumption Time: 2.39341
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.57788

Cumulative Model Updates: 250,470
Cumulative Timesteps: 2,088,906,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2088906612...
Checkpoint 2088906612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.35845
Policy Entropy: 2.15119
Value Function Loss: 0.02051

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.66944

Collected Steps per Second: 22,459.69484
Overall Steps per Second: 10,827.11000

Timestep Collection Time: 2.22746
Timestep Consumption Time: 2.39317
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.62062

Cumulative Model Updates: 250,476
Cumulative Timesteps: 2,088,956,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.90231
Policy Entropy: 2.13988
Value Function Loss: 0.02127

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.58552
Value Function Update Magnitude: 0.69392

Collected Steps per Second: 22,774.23980
Overall Steps per Second: 10,702.76320

Timestep Collection Time: 2.19564
Timestep Consumption Time: 2.47643
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.67206

Cumulative Model Updates: 250,482
Cumulative Timesteps: 2,089,006,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2089006644...
Checkpoint 2089006644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.38156
Policy Entropy: 2.12540
Value Function Loss: 0.02098

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.70592

Collected Steps per Second: 23,015.51041
Overall Steps per Second: 10,611.14020

Timestep Collection Time: 2.17323
Timestep Consumption Time: 2.54050
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.71373

Cumulative Model Updates: 250,488
Cumulative Timesteps: 2,089,056,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.61260
Policy Entropy: 2.11386
Value Function Loss: 0.01975

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.70505

Collected Steps per Second: 23,146.93634
Overall Steps per Second: 10,892.70686

Timestep Collection Time: 2.16046
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59096

Cumulative Model Updates: 250,494
Cumulative Timesteps: 2,089,106,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2089106670...
Checkpoint 2089106670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.27996
Policy Entropy: 2.14329
Value Function Loss: 0.01902

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.16704
Policy Update Magnitude: 0.53039
Value Function Update Magnitude: 0.68365

Collected Steps per Second: 23,094.92819
Overall Steps per Second: 10,801.49746

Timestep Collection Time: 2.16541
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.62991

Cumulative Model Updates: 250,500
Cumulative Timesteps: 2,089,156,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.16629
Policy Entropy: 2.13302
Value Function Loss: 0.02005

Mean KL Divergence: 0.02880
SB3 Clip Fraction: 0.17559
Policy Update Magnitude: 0.49384
Value Function Update Magnitude: 0.68438

Collected Steps per Second: 24,314.55142
Overall Steps per Second: 11,181.57198

Timestep Collection Time: 2.05704
Timestep Consumption Time: 2.41603
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.47307

Cumulative Model Updates: 250,506
Cumulative Timesteps: 2,089,206,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2089206696...
Checkpoint 2089206696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.18691
Policy Entropy: 2.13231
Value Function Loss: 0.02049

Mean KL Divergence: 0.02888
SB3 Clip Fraction: 0.17780
Policy Update Magnitude: 0.51910
Value Function Update Magnitude: 0.68427

Collected Steps per Second: 22,785.65832
Overall Steps per Second: 10,680.60460

Timestep Collection Time: 2.19559
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.68400

Cumulative Model Updates: 250,512
Cumulative Timesteps: 2,089,256,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.65133
Policy Entropy: 2.13652
Value Function Loss: 0.02002

Mean KL Divergence: 0.03106
SB3 Clip Fraction: 0.18380
Policy Update Magnitude: 0.52804
Value Function Update Magnitude: 0.68005

Collected Steps per Second: 23,230.85347
Overall Steps per Second: 10,913.89086

Timestep Collection Time: 2.15317
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.58315

Cumulative Model Updates: 250,518
Cumulative Timesteps: 2,089,306,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2089306744...
Checkpoint 2089306744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.50704
Policy Entropy: 2.12340
Value Function Loss: 0.01987

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.66956

Collected Steps per Second: 22,512.26220
Overall Steps per Second: 10,838.87189

Timestep Collection Time: 2.22101
Timestep Consumption Time: 2.39201
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.61303

Cumulative Model Updates: 250,524
Cumulative Timesteps: 2,089,356,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.56821
Policy Entropy: 2.13789
Value Function Loss: 0.01919

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.66523

Collected Steps per Second: 22,790.22449
Overall Steps per Second: 10,743.06993

Timestep Collection Time: 2.19454
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.65547

Cumulative Model Updates: 250,530
Cumulative Timesteps: 2,089,406,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2089406758...
Checkpoint 2089406758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.71195
Policy Entropy: 2.13042
Value Function Loss: 0.01909

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.16992
Policy Update Magnitude: 0.53524
Value Function Update Magnitude: 0.65774

Collected Steps per Second: 22,436.97415
Overall Steps per Second: 10,618.87528

Timestep Collection Time: 2.22989
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.71161

Cumulative Model Updates: 250,536
Cumulative Timesteps: 2,089,456,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.98604
Policy Entropy: 2.13797
Value Function Loss: 0.01917

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.68111

Collected Steps per Second: 22,633.60501
Overall Steps per Second: 10,832.16939

Timestep Collection Time: 2.20999
Timestep Consumption Time: 2.40774
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61773

Cumulative Model Updates: 250,542
Cumulative Timesteps: 2,089,506,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2089506810...
Checkpoint 2089506810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.77099
Policy Entropy: 2.13625
Value Function Loss: 0.01820

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.71200

Collected Steps per Second: 22,830.11156
Overall Steps per Second: 10,678.79412

Timestep Collection Time: 2.19149
Timestep Consumption Time: 2.49368
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.68517

Cumulative Model Updates: 250,548
Cumulative Timesteps: 2,089,556,842

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.71315
Policy Entropy: 2.12528
Value Function Loss: 0.01995

Mean KL Divergence: 0.02798
SB3 Clip Fraction: 0.17013
Policy Update Magnitude: 0.50763
Value Function Update Magnitude: 0.70428

Collected Steps per Second: 23,924.38001
Overall Steps per Second: 10,983.08638

Timestep Collection Time: 2.09034
Timestep Consumption Time: 2.46303
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.55336

Cumulative Model Updates: 250,554
Cumulative Timesteps: 2,089,606,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2089606852...
Checkpoint 2089606852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.49713
Policy Entropy: 2.12144
Value Function Loss: 0.02044

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.71221

Collected Steps per Second: 22,762.15532
Overall Steps per Second: 10,631.80966

Timestep Collection Time: 2.19698
Timestep Consumption Time: 2.50664
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.70362

Cumulative Model Updates: 250,560
Cumulative Timesteps: 2,089,656,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.27150
Policy Entropy: 2.10388
Value Function Loss: 0.02046

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.58704
Value Function Update Magnitude: 0.71131

Collected Steps per Second: 23,276.79690
Overall Steps per Second: 10,926.22830

Timestep Collection Time: 2.14892
Timestep Consumption Time: 2.42905
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.57798

Cumulative Model Updates: 250,566
Cumulative Timesteps: 2,089,706,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2089706880...
Checkpoint 2089706880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.99715
Policy Entropy: 2.09702
Value Function Loss: 0.02019

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.58678
Value Function Update Magnitude: 0.68344

Collected Steps per Second: 23,051.51092
Overall Steps per Second: 10,834.95499

Timestep Collection Time: 2.17001
Timestep Consumption Time: 2.44671
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.61672

Cumulative Model Updates: 250,572
Cumulative Timesteps: 2,089,756,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.73767
Policy Entropy: 2.09777
Value Function Loss: 0.01915

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.57489
Value Function Update Magnitude: 0.66928

Collected Steps per Second: 23,103.71056
Overall Steps per Second: 11,063.55331

Timestep Collection Time: 2.16450
Timestep Consumption Time: 2.35557
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.52007

Cumulative Model Updates: 250,578
Cumulative Timesteps: 2,089,806,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2089806910...
Checkpoint 2089806910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.21531
Policy Entropy: 2.08039
Value Function Loss: 0.01957

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.57107
Value Function Update Magnitude: 0.65674

Collected Steps per Second: 22,504.70731
Overall Steps per Second: 10,771.76694

Timestep Collection Time: 2.22176
Timestep Consumption Time: 2.42001
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.64176

Cumulative Model Updates: 250,584
Cumulative Timesteps: 2,089,856,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.16466
Policy Entropy: 2.07022
Value Function Loss: 0.01977

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,787.11934
Overall Steps per Second: 10,820.13854

Timestep Collection Time: 2.19440
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.62138

Cumulative Model Updates: 250,590
Cumulative Timesteps: 2,089,906,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2089906914...
Checkpoint 2089906914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.20626
Policy Entropy: 2.05194
Value Function Loss: 0.02026

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14954
Policy Update Magnitude: 0.58947
Value Function Update Magnitude: 0.67259

Collected Steps per Second: 22,371.95816
Overall Steps per Second: 10,681.08115

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.44653
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.68174

Cumulative Model Updates: 250,596
Cumulative Timesteps: 2,089,956,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.21914
Policy Entropy: 2.04252
Value Function Loss: 0.02092

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.57354
Value Function Update Magnitude: 0.69818

Collected Steps per Second: 23,684.25525
Overall Steps per Second: 10,917.72031

Timestep Collection Time: 2.11220
Timestep Consumption Time: 2.46989
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.58209

Cumulative Model Updates: 250,602
Cumulative Timesteps: 2,090,006,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2090006946...
Checkpoint 2090006946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.53096
Policy Entropy: 2.07153
Value Function Loss: 0.02057

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.71417

Collected Steps per Second: 23,033.45141
Overall Steps per Second: 10,663.40543

Timestep Collection Time: 2.17197
Timestep Consumption Time: 2.51959
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.69156

Cumulative Model Updates: 250,608
Cumulative Timesteps: 2,090,056,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.83090
Policy Entropy: 2.06919
Value Function Loss: 0.01997

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.57459
Value Function Update Magnitude: 0.69002

Collected Steps per Second: 23,306.96825
Overall Steps per Second: 10,856.27879

Timestep Collection Time: 2.14631
Timestep Consumption Time: 2.46153
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.60784

Cumulative Model Updates: 250,614
Cumulative Timesteps: 2,090,106,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2090106998...
Checkpoint 2090106998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.50249
Policy Entropy: 2.07343
Value Function Loss: 0.01929

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.58304
Value Function Update Magnitude: 0.67579

Collected Steps per Second: 22,532.46698
Overall Steps per Second: 10,645.06539

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.70002

Cumulative Model Updates: 250,620
Cumulative Timesteps: 2,090,157,030

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.89889
Policy Entropy: 2.06318
Value Function Loss: 0.02043

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.57554
Value Function Update Magnitude: 0.70101

Collected Steps per Second: 22,964.62701
Overall Steps per Second: 10,963.73790

Timestep Collection Time: 2.17796
Timestep Consumption Time: 2.38399
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.56195

Cumulative Model Updates: 250,626
Cumulative Timesteps: 2,090,207,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2090207046...
Checkpoint 2090207046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.83627
Policy Entropy: 2.05348
Value Function Loss: 0.02075

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.70614

Collected Steps per Second: 22,933.63899
Overall Steps per Second: 10,702.15352

Timestep Collection Time: 2.18020
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.67196

Cumulative Model Updates: 250,632
Cumulative Timesteps: 2,090,257,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.72586
Policy Entropy: 2.05981
Value Function Loss: 0.02111

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.16162
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.71172

Collected Steps per Second: 22,003.71071
Overall Steps per Second: 10,523.23943

Timestep Collection Time: 2.27380
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.75443

Cumulative Model Updates: 250,638
Cumulative Timesteps: 2,090,307,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2090307078...
Checkpoint 2090307078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.75781
Policy Entropy: 2.04587
Value Function Loss: 0.02092

Mean KL Divergence: 0.03222
SB3 Clip Fraction: 0.18623
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.72513

Collected Steps per Second: 22,324.93878
Overall Steps per Second: 10,660.20526

Timestep Collection Time: 2.24027
Timestep Consumption Time: 2.45138
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.69165

Cumulative Model Updates: 250,644
Cumulative Timesteps: 2,090,357,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.58686
Policy Entropy: 2.05372
Value Function Loss: 0.02086

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.16485
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.70646

Collected Steps per Second: 23,780.60905
Overall Steps per Second: 10,915.72467

Timestep Collection Time: 2.10323
Timestep Consumption Time: 2.47879
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.58201

Cumulative Model Updates: 250,650
Cumulative Timesteps: 2,090,407,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2090407108...
Checkpoint 2090407108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.68163
Policy Entropy: 2.04218
Value Function Loss: 0.02074

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.15487
Policy Update Magnitude: 0.57692
Value Function Update Magnitude: 0.68937

Collected Steps per Second: 23,262.51437
Overall Steps per Second: 10,856.60932

Timestep Collection Time: 2.14947
Timestep Consumption Time: 2.45621
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60567

Cumulative Model Updates: 250,656
Cumulative Timesteps: 2,090,457,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.16945
Policy Entropy: 2.02393
Value Function Loss: 0.02016

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.58240
Value Function Update Magnitude: 0.69540

Collected Steps per Second: 23,212.77892
Overall Steps per Second: 10,979.63823

Timestep Collection Time: 2.15476
Timestep Consumption Time: 2.40076
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.55552

Cumulative Model Updates: 250,662
Cumulative Timesteps: 2,090,507,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2090507128...
Checkpoint 2090507128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.30452
Policy Entropy: 2.01766
Value Function Loss: 0.01973

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.15942
Policy Update Magnitude: 0.55872
Value Function Update Magnitude: 0.67717

Collected Steps per Second: 22,820.03301
Overall Steps per Second: 10,999.03616

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.35545
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.54713

Cumulative Model Updates: 250,668
Cumulative Timesteps: 2,090,557,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.28464
Policy Entropy: 2.02859
Value Function Loss: 0.01908

Mean KL Divergence: 0.02834
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.51588
Value Function Update Magnitude: 0.65453

Collected Steps per Second: 22,396.62419
Overall Steps per Second: 10,899.93748

Timestep Collection Time: 2.23302
Timestep Consumption Time: 2.35527
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.58828

Cumulative Model Updates: 250,674
Cumulative Timesteps: 2,090,607,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2090607154...
Checkpoint 2090607154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.29864
Policy Entropy: 2.05482
Value Function Loss: 0.01912

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.16619
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.64395

Collected Steps per Second: 22,918.51833
Overall Steps per Second: 10,727.64732

Timestep Collection Time: 2.18217
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.66197

Cumulative Model Updates: 250,680
Cumulative Timesteps: 2,090,657,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.16401
Policy Entropy: 2.07116
Value Function Loss: 0.01880

Mean KL Divergence: 0.03081
SB3 Clip Fraction: 0.17906
Policy Update Magnitude: 0.57181
Value Function Update Magnitude: 0.65613

Collected Steps per Second: 23,135.32179
Overall Steps per Second: 10,887.76373

Timestep Collection Time: 2.16189
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.59378

Cumulative Model Updates: 250,686
Cumulative Timesteps: 2,090,707,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2090707182...
Checkpoint 2090707182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.56958
Policy Entropy: 2.05926
Value Function Loss: 0.01964

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.17353
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.68411

Collected Steps per Second: 22,578.97767
Overall Steps per Second: 10,843.96469

Timestep Collection Time: 2.21542
Timestep Consumption Time: 2.39746
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.61289

Cumulative Model Updates: 250,692
Cumulative Timesteps: 2,090,757,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.32213
Policy Entropy: 2.04813
Value Function Loss: 0.01978

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.15563
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.69565

Collected Steps per Second: 22,668.87489
Overall Steps per Second: 10,747.53257

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.44666
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.65242

Cumulative Model Updates: 250,698
Cumulative Timesteps: 2,090,807,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2090807206...
Checkpoint 2090807206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.32910
Policy Entropy: 2.02650
Value Function Loss: 0.01945

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.58125
Value Function Update Magnitude: 0.69709

Collected Steps per Second: 22,476.48734
Overall Steps per Second: 10,638.59466

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.47691
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.70288

Cumulative Model Updates: 250,704
Cumulative Timesteps: 2,090,857,238

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.82161
Policy Entropy: 2.02001
Value Function Loss: 0.02000

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.67311

Collected Steps per Second: 22,697.92047
Overall Steps per Second: 10,822.39254

Timestep Collection Time: 2.20302
Timestep Consumption Time: 2.41740
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62042

Cumulative Model Updates: 250,710
Cumulative Timesteps: 2,090,907,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2090907242...
Checkpoint 2090907242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.44539
Policy Entropy: 2.03416
Value Function Loss: 0.01853

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.66989

Collected Steps per Second: 22,607.96901
Overall Steps per Second: 10,746.96777

Timestep Collection Time: 2.21196
Timestep Consumption Time: 2.44126
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.65322

Cumulative Model Updates: 250,716
Cumulative Timesteps: 2,090,957,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.50033
Policy Entropy: 2.03945
Value Function Loss: 0.01881

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.57410
Value Function Update Magnitude: 0.66904

Collected Steps per Second: 23,362.32014
Overall Steps per Second: 10,897.86584

Timestep Collection Time: 2.14028
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.58824

Cumulative Model Updates: 250,722
Cumulative Timesteps: 2,091,007,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2091007252...
Checkpoint 2091007252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.81927
Policy Entropy: 2.06398
Value Function Loss: 0.01829

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.65889

Collected Steps per Second: 23,005.06343
Overall Steps per Second: 10,844.56477

Timestep Collection Time: 2.17422
Timestep Consumption Time: 2.43805
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.61226

Cumulative Model Updates: 250,728
Cumulative Timesteps: 2,091,057,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.21198
Policy Entropy: 2.05087
Value Function Loss: 0.01903

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.65597

Collected Steps per Second: 23,202.50323
Overall Steps per Second: 10,784.35056

Timestep Collection Time: 2.15494
Timestep Consumption Time: 2.48141
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.63635

Cumulative Model Updates: 250,734
Cumulative Timesteps: 2,091,107,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2091107270...
Checkpoint 2091107270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.90021
Policy Entropy: 2.04202
Value Function Loss: 0.01984

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.67116

Collected Steps per Second: 23,064.73669
Overall Steps per Second: 10,978.12142

Timestep Collection Time: 2.16825
Timestep Consumption Time: 2.38718
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.55542

Cumulative Model Updates: 250,740
Cumulative Timesteps: 2,091,157,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.04155
Policy Entropy: 2.05854
Value Function Loss: 0.01870

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.70788

Collected Steps per Second: 22,763.11427
Overall Steps per Second: 10,833.20434

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.42016
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.61784

Cumulative Model Updates: 250,746
Cumulative Timesteps: 2,091,207,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2091207306...
Checkpoint 2091207306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.68028
Policy Entropy: 2.05880
Value Function Loss: 0.01931

Mean KL Divergence: 0.02977
SB3 Clip Fraction: 0.17787
Policy Update Magnitude: 0.52856
Value Function Update Magnitude: 0.69208

Collected Steps per Second: 22,511.79444
Overall Steps per Second: 10,750.12843

Timestep Collection Time: 2.22221
Timestep Consumption Time: 2.43131
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.65353

Cumulative Model Updates: 250,752
Cumulative Timesteps: 2,091,257,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.60923
Policy Entropy: 2.07031
Value Function Loss: 0.01956

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.65570

Collected Steps per Second: 22,881.55592
Overall Steps per Second: 10,900.11936

Timestep Collection Time: 2.18534
Timestep Consumption Time: 2.40213
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.58747

Cumulative Model Updates: 250,758
Cumulative Timesteps: 2,091,307,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2091307336...
Checkpoint 2091307336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.91961
Policy Entropy: 2.03240
Value Function Loss: 0.01973

Mean KL Divergence: 0.02799
SB3 Clip Fraction: 0.16989
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.66033

Collected Steps per Second: 22,544.06186
Overall Steps per Second: 10,848.49139

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.39144
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.60967

Cumulative Model Updates: 250,764
Cumulative Timesteps: 2,091,357,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.84360
Policy Entropy: 2.03940
Value Function Loss: 0.01860

Mean KL Divergence: 0.02640
SB3 Clip Fraction: 0.16406
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.66871

Collected Steps per Second: 22,941.79709
Overall Steps per Second: 10,687.14100

Timestep Collection Time: 2.18065
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.68114

Cumulative Model Updates: 250,770
Cumulative Timesteps: 2,091,407,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2091407372...
Checkpoint 2091407372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.11625
Policy Entropy: 2.05180
Value Function Loss: 0.01696

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.65232

Collected Steps per Second: 23,013.66328
Overall Steps per Second: 10,646.73111

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.69684

Cumulative Model Updates: 250,776
Cumulative Timesteps: 2,091,457,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.76561
Policy Entropy: 2.04071
Value Function Loss: 0.01742

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.55679
Value Function Update Magnitude: 0.62338

Collected Steps per Second: 23,258.49496
Overall Steps per Second: 10,921.88515

Timestep Collection Time: 2.15035
Timestep Consumption Time: 2.42889
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.57925

Cumulative Model Updates: 250,782
Cumulative Timesteps: 2,091,507,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2091507392...
Checkpoint 2091507392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.52956
Policy Entropy: 2.04286
Value Function Loss: 0.01848

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.55855
Value Function Update Magnitude: 0.61294

Collected Steps per Second: 22,693.71791
Overall Steps per Second: 10,972.04738

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.35501
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.55940

Cumulative Model Updates: 250,788
Cumulative Timesteps: 2,091,557,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.24490
Policy Entropy: 2.03539
Value Function Loss: 0.01978

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.62249

Collected Steps per Second: 23,140.03586
Overall Steps per Second: 10,792.38053

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.63327

Cumulative Model Updates: 250,794
Cumulative Timesteps: 2,091,607,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2091607422...
Checkpoint 2091607422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.23936
Policy Entropy: 2.05110
Value Function Loss: 0.01971

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.62383

Collected Steps per Second: 23,111.02090
Overall Steps per Second: 10,878.99594

Timestep Collection Time: 2.16373
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.59656

Cumulative Model Updates: 250,800
Cumulative Timesteps: 2,091,657,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.94842
Policy Entropy: 2.03248
Value Function Loss: 0.01841

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.61676

Collected Steps per Second: 23,139.80682
Overall Steps per Second: 10,915.78205

Timestep Collection Time: 2.16182
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.58272

Cumulative Model Updates: 250,806
Cumulative Timesteps: 2,091,707,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2091707452...
Checkpoint 2091707452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.43482
Policy Entropy: 2.03947
Value Function Loss: 0.01874

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.56430
Value Function Update Magnitude: 0.62009

Collected Steps per Second: 22,167.70303
Overall Steps per Second: 10,700.36022

Timestep Collection Time: 2.25662
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.67498

Cumulative Model Updates: 250,812
Cumulative Timesteps: 2,091,757,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.23910
Policy Entropy: 2.04126
Value Function Loss: 0.01864

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.61158

Collected Steps per Second: 22,873.28600
Overall Steps per Second: 10,845.71844

Timestep Collection Time: 2.18701
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.61233

Cumulative Model Updates: 250,818
Cumulative Timesteps: 2,091,807,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2091807500...
Checkpoint 2091807500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.17309
Policy Entropy: 2.04836
Value Function Loss: 0.01997

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 22,449.13310
Overall Steps per Second: 10,601.44328

Timestep Collection Time: 2.22815
Timestep Consumption Time: 2.49008
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.71823

Cumulative Model Updates: 250,824
Cumulative Timesteps: 2,091,857,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.80252
Policy Entropy: 2.01633
Value Function Loss: 0.02156

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.62619

Collected Steps per Second: 22,908.29580
Overall Steps per Second: 10,892.92670

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.40887
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59271

Cumulative Model Updates: 250,830
Cumulative Timesteps: 2,091,907,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2091907548...
Checkpoint 2091907548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.98741
Policy Entropy: 2.04945
Value Function Loss: 0.01985

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.56552
Value Function Update Magnitude: 0.63957

Collected Steps per Second: 22,615.46685
Overall Steps per Second: 10,733.24071

Timestep Collection Time: 2.21185
Timestep Consumption Time: 2.44863
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.66048

Cumulative Model Updates: 250,836
Cumulative Timesteps: 2,091,957,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.28843
Policy Entropy: 2.06520
Value Function Loss: 0.01930

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 23,357.19694
Overall Steps per Second: 10,876.17920

Timestep Collection Time: 2.14187
Timestep Consumption Time: 2.45791
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.59978

Cumulative Model Updates: 250,842
Cumulative Timesteps: 2,092,007,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2092007598...
Checkpoint 2092007598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.58007
Policy Entropy: 2.08308
Value Function Loss: 0.01739

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.15024
Policy Update Magnitude: 0.51984
Value Function Update Magnitude: 0.61615

Collected Steps per Second: 22,983.89639
Overall Steps per Second: 10,707.90068

Timestep Collection Time: 2.17648
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.67169

Cumulative Model Updates: 250,848
Cumulative Timesteps: 2,092,057,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.31018
Policy Entropy: 2.05651
Value Function Loss: 0.01807

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.16902
Policy Update Magnitude: 0.48175
Value Function Update Magnitude: 0.60739

Collected Steps per Second: 23,412.31138
Overall Steps per Second: 10,820.38247

Timestep Collection Time: 2.13623
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.62220

Cumulative Model Updates: 250,854
Cumulative Timesteps: 2,092,107,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2092107636...
Checkpoint 2092107636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.14303
Policy Entropy: 2.04909
Value Function Loss: 0.01790

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.51419
Value Function Update Magnitude: 0.59871

Collected Steps per Second: 23,641.58931
Overall Steps per Second: 11,016.26146

Timestep Collection Time: 2.11585
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.54074

Cumulative Model Updates: 250,860
Cumulative Timesteps: 2,092,157,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.16054
Policy Entropy: 2.07339
Value Function Loss: 0.01753

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.58314

Collected Steps per Second: 23,225.38789
Overall Steps per Second: 10,925.48617

Timestep Collection Time: 2.15299
Timestep Consumption Time: 2.42383
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.57682

Cumulative Model Updates: 250,866
Cumulative Timesteps: 2,092,207,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2092207662...
Checkpoint 2092207662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.47649
Policy Entropy: 2.07495
Value Function Loss: 0.01744

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.56603

Collected Steps per Second: 22,113.14619
Overall Steps per Second: 10,641.79778

Timestep Collection Time: 2.26146
Timestep Consumption Time: 2.43775
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.69921

Cumulative Model Updates: 250,872
Cumulative Timesteps: 2,092,257,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.57695
Policy Entropy: 2.05940
Value Function Loss: 0.01737

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.55232
Value Function Update Magnitude: 0.56039

Collected Steps per Second: 22,668.46028
Overall Steps per Second: 10,948.71709

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.36132
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.56729

Cumulative Model Updates: 250,878
Cumulative Timesteps: 2,092,307,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2092307676...
Checkpoint 2092307676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.16043
Policy Entropy: 2.06288
Value Function Loss: 0.01768

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.55284
Value Function Update Magnitude: 0.56238

Collected Steps per Second: 22,324.15500
Overall Steps per Second: 10,661.23597

Timestep Collection Time: 2.24080
Timestep Consumption Time: 2.45134
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.69214

Cumulative Model Updates: 250,884
Cumulative Timesteps: 2,092,357,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.20879
Policy Entropy: 2.05709
Value Function Loss: 0.01804

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.57571

Collected Steps per Second: 22,959.62011
Overall Steps per Second: 10,851.98476

Timestep Collection Time: 2.17791
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.60782

Cumulative Model Updates: 250,890
Cumulative Timesteps: 2,092,407,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2092407704...
Checkpoint 2092407704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.24103
Policy Entropy: 2.05723
Value Function Loss: 0.01814

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.55132
Value Function Update Magnitude: 0.58924

Collected Steps per Second: 22,614.57144
Overall Steps per Second: 10,689.54397

Timestep Collection Time: 2.21176
Timestep Consumption Time: 2.46739
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.67915

Cumulative Model Updates: 250,896
Cumulative Timesteps: 2,092,457,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.51091
Policy Entropy: 2.04760
Value Function Loss: 0.01728

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.60502

Collected Steps per Second: 22,971.20340
Overall Steps per Second: 10,895.51119

Timestep Collection Time: 2.17803
Timestep Consumption Time: 2.41395
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.59198

Cumulative Model Updates: 250,902
Cumulative Timesteps: 2,092,507,754

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2092507754...
Checkpoint 2092507754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.20770
Policy Entropy: 2.04833
Value Function Loss: 0.01612

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.53565
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 22,761.41228
Overall Steps per Second: 10,883.34717

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.39882
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.59675

Cumulative Model Updates: 250,908
Cumulative Timesteps: 2,092,557,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.91198
Policy Entropy: 2.05407
Value Function Loss: 0.01652

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.58134

Collected Steps per Second: 23,270.43776
Overall Steps per Second: 10,751.85231

Timestep Collection Time: 2.14925
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.65166

Cumulative Model Updates: 250,914
Cumulative Timesteps: 2,092,607,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2092607796...
Checkpoint 2092607796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.93792
Policy Entropy: 2.03171
Value Function Loss: 0.01814

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.55176
Value Function Update Magnitude: 0.58222

Collected Steps per Second: 22,842.04295
Overall Steps per Second: 10,807.87727

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.43838
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.62829

Cumulative Model Updates: 250,920
Cumulative Timesteps: 2,092,657,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.16974
Policy Entropy: 2.04758
Value Function Loss: 0.01809

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.61141

Collected Steps per Second: 23,294.56713
Overall Steps per Second: 11,095.60575

Timestep Collection Time: 2.14668
Timestep Consumption Time: 2.36015
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.50683

Cumulative Model Updates: 250,926
Cumulative Timesteps: 2,092,707,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2092707824...
Checkpoint 2092707824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.90285
Policy Entropy: 2.05238
Value Function Loss: 0.01935

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 22,638.10650
Overall Steps per Second: 10,729.79740

Timestep Collection Time: 2.20964
Timestep Consumption Time: 2.45233
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.66197

Cumulative Model Updates: 250,932
Cumulative Timesteps: 2,092,757,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.97083
Policy Entropy: 2.06408
Value Function Loss: 0.01778

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.61552

Collected Steps per Second: 22,742.41141
Overall Steps per Second: 10,830.04058

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61790

Cumulative Model Updates: 250,938
Cumulative Timesteps: 2,092,807,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2092807858...
Checkpoint 2092807858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.52360
Policy Entropy: 2.05398
Value Function Loss: 0.01835

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.55011
Value Function Update Magnitude: 0.60154

Collected Steps per Second: 21,915.89234
Overall Steps per Second: 10,655.88455

Timestep Collection Time: 2.28172
Timestep Consumption Time: 2.41108
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.69281

Cumulative Model Updates: 250,944
Cumulative Timesteps: 2,092,857,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.25934
Policy Entropy: 2.06032
Value Function Loss: 0.01780

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.61615

Collected Steps per Second: 23,051.50243
Overall Steps per Second: 10,964.22636

Timestep Collection Time: 2.17001
Timestep Consumption Time: 2.39228
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.56229

Cumulative Model Updates: 250,950
Cumulative Timesteps: 2,092,907,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2092907886...
Checkpoint 2092907886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.06528
Policy Entropy: 2.06176
Value Function Loss: 0.01828

Mean KL Divergence: 0.02784
SB3 Clip Fraction: 0.16026
Policy Update Magnitude: 0.51126
Value Function Update Magnitude: 0.61822

Collected Steps per Second: 22,767.16442
Overall Steps per Second: 10,627.23526

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.70715

Cumulative Model Updates: 250,956
Cumulative Timesteps: 2,092,957,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.91080
Policy Entropy: 2.06764
Value Function Loss: 0.01871

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.16458
Policy Update Magnitude: 0.49568
Value Function Update Magnitude: 0.61120

Collected Steps per Second: 22,981.72281
Overall Steps per Second: 10,843.23538

Timestep Collection Time: 2.17686
Timestep Consumption Time: 2.43689
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61375

Cumulative Model Updates: 250,962
Cumulative Timesteps: 2,093,007,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2093007938...
Checkpoint 2093007938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.94887
Policy Entropy: 2.07803
Value Function Loss: 0.01789

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.62569

Collected Steps per Second: 22,502.23585
Overall Steps per Second: 10,773.52357

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.42007
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.64305

Cumulative Model Updates: 250,968
Cumulative Timesteps: 2,093,057,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.64882
Policy Entropy: 2.05288
Value Function Loss: 0.01879

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.56714
Value Function Update Magnitude: 0.64217

Collected Steps per Second: 23,226.18111
Overall Steps per Second: 10,849.91618

Timestep Collection Time: 2.15317
Timestep Consumption Time: 2.45608
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.60925

Cumulative Model Updates: 250,974
Cumulative Timesteps: 2,093,107,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2093107970...
Checkpoint 2093107970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.69302
Policy Entropy: 2.04226
Value Function Loss: 0.01870

Mean KL Divergence: 0.02761
SB3 Clip Fraction: 0.16783
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.64267

Collected Steps per Second: 22,975.09101
Overall Steps per Second: 10,710.00700

Timestep Collection Time: 2.17705
Timestep Consumption Time: 2.49316
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.67021

Cumulative Model Updates: 250,980
Cumulative Timesteps: 2,093,157,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.53982
Policy Entropy: 2.02757
Value Function Loss: 0.01974

Mean KL Divergence: 0.03209
SB3 Clip Fraction: 0.18414
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.63229

Collected Steps per Second: 23,182.38691
Overall Steps per Second: 10,840.95811

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.61435

Cumulative Model Updates: 250,986
Cumulative Timesteps: 2,093,208,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2093208012...
Checkpoint 2093208012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.37256
Policy Entropy: 2.06001
Value Function Loss: 0.01820

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.16837
Policy Update Magnitude: 0.56691
Value Function Update Magnitude: 0.62387

Collected Steps per Second: 22,207.22164
Overall Steps per Second: 10,640.46438

Timestep Collection Time: 2.25206
Timestep Consumption Time: 2.44811
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.70017

Cumulative Model Updates: 250,992
Cumulative Timesteps: 2,093,258,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.27108
Policy Entropy: 2.04895
Value Function Loss: 0.01763

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.57501
Value Function Update Magnitude: 0.60558

Collected Steps per Second: 22,757.73011
Overall Steps per Second: 10,918.17536

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.38285
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.58025

Cumulative Model Updates: 250,998
Cumulative Timesteps: 2,093,308,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2093308032...
Checkpoint 2093308032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.42809
Policy Entropy: 2.05591
Value Function Loss: 0.01785

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.56527
Value Function Update Magnitude: 0.60133

Collected Steps per Second: 22,341.24530
Overall Steps per Second: 10,584.87408

Timestep Collection Time: 2.23882
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.72542

Cumulative Model Updates: 251,004
Cumulative Timesteps: 2,093,358,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.78119
Policy Entropy: 2.05580
Value Function Loss: 0.01839

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.61634

Collected Steps per Second: 22,737.99843
Overall Steps per Second: 10,688.20753

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.67824

Cumulative Model Updates: 251,010
Cumulative Timesteps: 2,093,408,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2093408052...
Checkpoint 2093408052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.17640
Policy Entropy: 2.06444
Value Function Loss: 0.01779

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.61250

Collected Steps per Second: 22,244.81349
Overall Steps per Second: 10,645.11912

Timestep Collection Time: 2.24816
Timestep Consumption Time: 2.44976
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.69793

Cumulative Model Updates: 251,016
Cumulative Timesteps: 2,093,458,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.08385
Policy Entropy: 2.05522
Value Function Loss: 0.01715

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.60325

Collected Steps per Second: 23,508.44223
Overall Steps per Second: 10,930.51711

Timestep Collection Time: 2.12690
Timestep Consumption Time: 2.44745
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.57435

Cumulative Model Updates: 251,022
Cumulative Timesteps: 2,093,508,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2093508062...
Checkpoint 2093508062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.20750
Policy Entropy: 2.04707
Value Function Loss: 0.01724

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.54765
Value Function Update Magnitude: 0.57969

Collected Steps per Second: 23,320.12031
Overall Steps per Second: 10,856.33993

Timestep Collection Time: 2.14493
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.60745

Cumulative Model Updates: 251,028
Cumulative Timesteps: 2,093,558,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.21045
Policy Entropy: 2.04982
Value Function Loss: 0.01788

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.58684

Collected Steps per Second: 23,184.63480
Overall Steps per Second: 10,917.51983

Timestep Collection Time: 2.15712
Timestep Consumption Time: 2.42378
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.58089

Cumulative Model Updates: 251,034
Cumulative Timesteps: 2,093,608,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2093608094...
Checkpoint 2093608094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.83840
Policy Entropy: 2.04041
Value Function Loss: 0.01832

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.59807

Collected Steps per Second: 22,842.28196
Overall Steps per Second: 10,657.01115

Timestep Collection Time: 2.19006
Timestep Consumption Time: 2.50413
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.69419

Cumulative Model Updates: 251,040
Cumulative Timesteps: 2,093,658,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.26447
Policy Entropy: 2.01918
Value Function Loss: 0.01878

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.55384
Value Function Update Magnitude: 0.61357

Collected Steps per Second: 23,249.85080
Overall Steps per Second: 10,925.12630

Timestep Collection Time: 2.15158
Timestep Consumption Time: 2.42722
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.57880

Cumulative Model Updates: 251,046
Cumulative Timesteps: 2,093,708,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2093708144...
Checkpoint 2093708144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.20713
Policy Entropy: 2.00802
Value Function Loss: 0.01999

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.56919
Value Function Update Magnitude: 0.62485

Collected Steps per Second: 22,669.94446
Overall Steps per Second: 10,612.75840

Timestep Collection Time: 2.20592
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.71206

Cumulative Model Updates: 251,052
Cumulative Timesteps: 2,093,758,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.26183
Policy Entropy: 2.02296
Value Function Loss: 0.01972

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.57144
Value Function Update Magnitude: 0.64112

Collected Steps per Second: 22,787.54586
Overall Steps per Second: 10,833.43187

Timestep Collection Time: 2.19523
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61756

Cumulative Model Updates: 251,058
Cumulative Timesteps: 2,093,808,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2093808176...
Checkpoint 2093808176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.74453
Policy Entropy: 2.03579
Value Function Loss: 0.01848

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.64210

Collected Steps per Second: 22,175.60311
Overall Steps per Second: 10,680.08756

Timestep Collection Time: 2.25563
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.68348

Cumulative Model Updates: 251,064
Cumulative Timesteps: 2,093,858,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.91657
Policy Entropy: 2.01542
Value Function Loss: 0.01918

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.65015

Collected Steps per Second: 22,679.06789
Overall Steps per Second: 10,860.23982

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.40110
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60745

Cumulative Model Updates: 251,070
Cumulative Timesteps: 2,093,908,234

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2093908234...
Checkpoint 2093908234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.04130
Policy Entropy: 2.01239
Value Function Loss: 0.01841

Mean KL Divergence: 0.02441
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.55641
Value Function Update Magnitude: 0.66676

Collected Steps per Second: 22,421.32669
Overall Steps per Second: 10,714.40566

Timestep Collection Time: 2.23109
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.66885

Cumulative Model Updates: 251,076
Cumulative Timesteps: 2,093,958,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.08741
Policy Entropy: 2.02836
Value Function Loss: 0.01859

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.14930
Policy Update Magnitude: 0.55372
Value Function Update Magnitude: 0.66827

Collected Steps per Second: 23,510.61155
Overall Steps per Second: 10,970.92343

Timestep Collection Time: 2.12764
Timestep Consumption Time: 2.43187
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.55951

Cumulative Model Updates: 251,082
Cumulative Timesteps: 2,094,008,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2094008280...
Checkpoint 2094008280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.86565
Policy Entropy: 2.04432
Value Function Loss: 0.01824

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.64828

Collected Steps per Second: 22,632.66174
Overall Steps per Second: 10,618.61569

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.49991
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70947

Cumulative Model Updates: 251,088
Cumulative Timesteps: 2,094,058,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.48496
Policy Entropy: 2.03947
Value Function Loss: 0.01920

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.14678
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.66869

Collected Steps per Second: 23,200.91353
Overall Steps per Second: 10,889.31550

Timestep Collection Time: 2.15621
Timestep Consumption Time: 2.43784
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.59404

Cumulative Model Updates: 251,094
Cumulative Timesteps: 2,094,108,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2094108314...
Checkpoint 2094108314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.71522
Policy Entropy: 2.02378
Value Function Loss: 0.01868

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.68610

Collected Steps per Second: 22,138.65831
Overall Steps per Second: 10,627.19307

Timestep Collection Time: 2.25922
Timestep Consumption Time: 2.44720
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70642

Cumulative Model Updates: 251,100
Cumulative Timesteps: 2,094,158,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.54678
Policy Entropy: 2.01974
Value Function Loss: 0.01831

Mean KL Divergence: 0.02291
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.66714

Collected Steps per Second: 23,469.78961
Overall Steps per Second: 10,906.88246

Timestep Collection Time: 2.13091
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.58536

Cumulative Model Updates: 251,106
Cumulative Timesteps: 2,094,208,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2094208342...
Checkpoint 2094208342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.43765
Policy Entropy: 2.03713
Value Function Loss: 0.01795

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 22,632.85741
Overall Steps per Second: 10,673.03196

Timestep Collection Time: 2.21006
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.68658

Cumulative Model Updates: 251,112
Cumulative Timesteps: 2,094,258,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.97122
Policy Entropy: 2.01483
Value Function Loss: 0.01954

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.54500
Value Function Update Magnitude: 0.61409

Collected Steps per Second: 22,923.37213
Overall Steps per Second: 10,922.06015

Timestep Collection Time: 2.18162
Timestep Consumption Time: 2.39719
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.57881

Cumulative Model Updates: 251,118
Cumulative Timesteps: 2,094,308,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2094308372...
Checkpoint 2094308372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.30630
Policy Entropy: 2.01038
Value Function Loss: 0.01943

Mean KL Divergence: 0.03909
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 22,029.76547
Overall Steps per Second: 10,679.54487

Timestep Collection Time: 2.27020
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.68297

Cumulative Model Updates: 251,124
Cumulative Timesteps: 2,094,358,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.43723
Policy Entropy: 1.99636
Value Function Loss: 0.01898

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.63410

Collected Steps per Second: 22,849.14622
Overall Steps per Second: 10,835.05675

Timestep Collection Time: 2.18949
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61723

Cumulative Model Updates: 251,130
Cumulative Timesteps: 2,094,408,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2094408412...
Checkpoint 2094408412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.96962
Policy Entropy: 2.02167
Value Function Loss: 0.01841

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.62978

Collected Steps per Second: 22,551.25744
Overall Steps per Second: 10,653.47786

Timestep Collection Time: 2.21761
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.69424

Cumulative Model Updates: 251,136
Cumulative Timesteps: 2,094,458,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.07246
Policy Entropy: 2.03108
Value Function Loss: 0.01860

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.61797

Collected Steps per Second: 22,945.67514
Overall Steps per Second: 10,907.83871

Timestep Collection Time: 2.17923
Timestep Consumption Time: 2.40499
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.58423

Cumulative Model Updates: 251,142
Cumulative Timesteps: 2,094,508,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2094508426...
Checkpoint 2094508426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.28113
Policy Entropy: 2.02802
Value Function Loss: 0.01875

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.54989
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 22,837.95682
Overall Steps per Second: 10,624.35304

Timestep Collection Time: 2.18969
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.70692

Cumulative Model Updates: 251,148
Cumulative Timesteps: 2,094,558,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.60933
Policy Entropy: 2.00100
Value Function Loss: 0.01922

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 23,244.97294
Overall Steps per Second: 10,904.38336

Timestep Collection Time: 2.15160
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.58660

Cumulative Model Updates: 251,154
Cumulative Timesteps: 2,094,608,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2094608448...
Checkpoint 2094608448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.55417
Policy Entropy: 2.00159
Value Function Loss: 0.01847

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.61200

Collected Steps per Second: 22,962.06191
Overall Steps per Second: 10,777.10114

Timestep Collection Time: 2.17803
Timestep Consumption Time: 2.46255
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.64058

Cumulative Model Updates: 251,160
Cumulative Timesteps: 2,094,658,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.57748
Policy Entropy: 2.00470
Value Function Loss: 0.01841

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.54929
Value Function Update Magnitude: 0.61365

Collected Steps per Second: 23,457.04233
Overall Steps per Second: 11,170.80101

Timestep Collection Time: 2.13275
Timestep Consumption Time: 2.34571
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.47846

Cumulative Model Updates: 251,166
Cumulative Timesteps: 2,094,708,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2094708488...
Checkpoint 2094708488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.65300
Policy Entropy: 1.99783
Value Function Loss: 0.01768

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.62237

Collected Steps per Second: 22,736.67331
Overall Steps per Second: 10,740.41984

Timestep Collection Time: 2.19909
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.65531

Cumulative Model Updates: 251,172
Cumulative Timesteps: 2,094,758,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.89283
Policy Entropy: 1.99051
Value Function Loss: 0.01944

Mean KL Divergence: 0.02705
SB3 Clip Fraction: 0.16396
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.61083

Collected Steps per Second: 22,984.82134
Overall Steps per Second: 10,871.11839

Timestep Collection Time: 2.17631
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.60137

Cumulative Model Updates: 251,178
Cumulative Timesteps: 2,094,808,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2094808510...
Checkpoint 2094808510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.97382
Policy Entropy: 1.98564
Value Function Loss: 0.01946

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.16542
Policy Update Magnitude: 0.50265
Value Function Update Magnitude: 0.59493

Collected Steps per Second: 22,135.26195
Overall Steps per Second: 10,645.25940

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.69862

Cumulative Model Updates: 251,184
Cumulative Timesteps: 2,094,858,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.82683
Policy Entropy: 2.01911
Value Function Loss: 0.01940

Mean KL Divergence: 0.02856
SB3 Clip Fraction: 0.17322
Policy Update Magnitude: 0.48976
Value Function Update Magnitude: 0.62381

Collected Steps per Second: 22,788.54610
Overall Steps per Second: 10,866.20333

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.40888
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60437

Cumulative Model Updates: 251,190
Cumulative Timesteps: 2,094,908,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2094908560...
Checkpoint 2094908560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.31012
Policy Entropy: 2.03897
Value Function Loss: 0.01869

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.50552
Value Function Update Magnitude: 0.63160

Collected Steps per Second: 23,296.18687
Overall Steps per Second: 10,781.25376

Timestep Collection Time: 2.14696
Timestep Consumption Time: 2.49220
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.63916

Cumulative Model Updates: 251,196
Cumulative Timesteps: 2,094,958,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.34457
Policy Entropy: 2.03468
Value Function Loss: 0.01832

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.15712
Policy Update Magnitude: 0.51894
Value Function Update Magnitude: 0.61764

Collected Steps per Second: 23,299.58199
Overall Steps per Second: 10,892.88837

Timestep Collection Time: 2.14630
Timestep Consumption Time: 2.44458
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.59089

Cumulative Model Updates: 251,202
Cumulative Timesteps: 2,095,008,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2095008584...
Checkpoint 2095008584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.40798
Policy Entropy: 2.02686
Value Function Loss: 0.02040

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.17570
Policy Update Magnitude: 0.50341
Value Function Update Magnitude: 0.63583

Collected Steps per Second: 22,511.45824
Overall Steps per Second: 10,567.20043

Timestep Collection Time: 2.22207
Timestep Consumption Time: 2.51164
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.73370

Cumulative Model Updates: 251,208
Cumulative Timesteps: 2,095,058,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.22389
Policy Entropy: 2.00519
Value Function Loss: 0.01972

Mean KL Divergence: 0.03004
SB3 Clip Fraction: 0.18163
Policy Update Magnitude: 0.52361
Value Function Update Magnitude: 0.65788

Collected Steps per Second: 23,173.12407
Overall Steps per Second: 10,953.79996

Timestep Collection Time: 2.15819
Timestep Consumption Time: 2.40753
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.56572

Cumulative Model Updates: 251,214
Cumulative Timesteps: 2,095,108,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2095108618...
Checkpoint 2095108618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.94449
Policy Entropy: 2.00966
Value Function Loss: 0.01989

Mean KL Divergence: 0.02828
SB3 Clip Fraction: 0.17012
Policy Update Magnitude: 0.51206
Value Function Update Magnitude: 0.65128

Collected Steps per Second: 23,412.04349
Overall Steps per Second: 10,980.49624

Timestep Collection Time: 2.13676
Timestep Consumption Time: 2.41913
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.55590

Cumulative Model Updates: 251,220
Cumulative Timesteps: 2,095,158,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.46191
Policy Entropy: 1.99808
Value Function Loss: 0.01898

Mean KL Divergence: 0.02894
SB3 Clip Fraction: 0.16981
Policy Update Magnitude: 0.51613
Value Function Update Magnitude: 0.63033

Collected Steps per Second: 23,186.05456
Overall Steps per Second: 10,905.26018

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.58788

Cumulative Model Updates: 251,226
Cumulative Timesteps: 2,095,208,676

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2095208676...
Checkpoint 2095208676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.42378
Policy Entropy: 2.00082
Value Function Loss: 0.01898

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.16141
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.62680

Collected Steps per Second: 22,657.72341
Overall Steps per Second: 10,783.24321

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.63831

Cumulative Model Updates: 251,232
Cumulative Timesteps: 2,095,258,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.46828
Policy Entropy: 2.00800
Value Function Loss: 0.01943

Mean KL Divergence: 0.03351
SB3 Clip Fraction: 0.17322
Policy Update Magnitude: 0.53517
Value Function Update Magnitude: 0.63405

Collected Steps per Second: 22,878.70700
Overall Steps per Second: 10,870.64562

Timestep Collection Time: 2.18649
Timestep Consumption Time: 2.41526
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60175

Cumulative Model Updates: 251,238
Cumulative Timesteps: 2,095,308,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2095308716...
Checkpoint 2095308716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.26040
Policy Entropy: 2.02061
Value Function Loss: 0.01815

Mean KL Divergence: 0.02862
SB3 Clip Fraction: 0.16558
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.64122

Collected Steps per Second: 23,168.15486
Overall Steps per Second: 10,784.62130

Timestep Collection Time: 2.15900
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.63809

Cumulative Model Updates: 251,244
Cumulative Timesteps: 2,095,358,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.85070
Policy Entropy: 2.02497
Value Function Loss: 0.01786

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.63941

Collected Steps per Second: 23,015.82485
Overall Steps per Second: 10,800.79622

Timestep Collection Time: 2.17346
Timestep Consumption Time: 2.45805
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.63151

Cumulative Model Updates: 251,250
Cumulative Timesteps: 2,095,408,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2095408760...
Checkpoint 2095408760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.24663
Policy Entropy: 2.02845
Value Function Loss: 0.01790

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.55574
Value Function Update Magnitude: 0.63224

Collected Steps per Second: 22,683.47002
Overall Steps per Second: 10,638.24061

Timestep Collection Time: 2.20451
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.70059

Cumulative Model Updates: 251,256
Cumulative Timesteps: 2,095,458,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.86384
Policy Entropy: 2.02875
Value Function Loss: 0.01803

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.63531

Collected Steps per Second: 23,188.37785
Overall Steps per Second: 10,860.72953

Timestep Collection Time: 2.15729
Timestep Consumption Time: 2.44866
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60595

Cumulative Model Updates: 251,262
Cumulative Timesteps: 2,095,508,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2095508790...
Checkpoint 2095508790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.75176
Policy Entropy: 2.02272
Value Function Loss: 0.01899

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.61658

Collected Steps per Second: 22,697.15517
Overall Steps per Second: 10,840.28949

Timestep Collection Time: 2.20424
Timestep Consumption Time: 2.41095
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.61519

Cumulative Model Updates: 251,268
Cumulative Timesteps: 2,095,558,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.82743
Policy Entropy: 2.01471
Value Function Loss: 0.01874

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.56929
Value Function Update Magnitude: 0.62651

Collected Steps per Second: 23,485.97069
Overall Steps per Second: 10,823.67926

Timestep Collection Time: 2.12919
Timestep Consumption Time: 2.49087
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.62006

Cumulative Model Updates: 251,274
Cumulative Timesteps: 2,095,608,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2095608826...
Checkpoint 2095608826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.10944
Policy Entropy: 2.01579
Value Function Loss: 0.01864

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.63947

Collected Steps per Second: 22,362.68385
Overall Steps per Second: 10,533.68960

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.51171
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.74838

Cumulative Model Updates: 251,280
Cumulative Timesteps: 2,095,658,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.82288
Policy Entropy: 2.03084
Value Function Loss: 0.01824

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.62228

Collected Steps per Second: 23,323.61897
Overall Steps per Second: 10,928.82177

Timestep Collection Time: 2.14384
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.57524

Cumulative Model Updates: 251,286
Cumulative Timesteps: 2,095,708,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2095708846...
Checkpoint 2095708846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.50334
Policy Entropy: 2.03258
Value Function Loss: 0.01718

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.60751

Collected Steps per Second: 22,578.16683
Overall Steps per Second: 10,992.76554

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.33476
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.55008

Cumulative Model Updates: 251,292
Cumulative Timesteps: 2,095,758,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.55936
Policy Entropy: 2.02260
Value Function Loss: 0.01861

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.54740
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 22,746.05017
Overall Steps per Second: 10,693.02521

Timestep Collection Time: 2.19933
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.67838

Cumulative Model Updates: 251,298
Cumulative Timesteps: 2,095,808,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2095808890...
Checkpoint 2095808890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.57599
Policy Entropy: 2.01079
Value Function Loss: 0.01947

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.60689

Collected Steps per Second: 22,441.44644
Overall Steps per Second: 10,578.08420

Timestep Collection Time: 2.22811
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.72694

Cumulative Model Updates: 251,304
Cumulative Timesteps: 2,095,858,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.99850
Policy Entropy: 1.99678
Value Function Loss: 0.02036

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.56573
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 22,899.41911
Overall Steps per Second: 10,814.78153

Timestep Collection Time: 2.18346
Timestep Consumption Time: 2.43984
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.62330

Cumulative Model Updates: 251,310
Cumulative Timesteps: 2,095,908,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2095908892...
Checkpoint 2095908892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.77783
Policy Entropy: 2.01064
Value Function Loss: 0.01973

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.55748
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 23,353.17340
Overall Steps per Second: 10,811.15848

Timestep Collection Time: 2.14198
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.62689

Cumulative Model Updates: 251,316
Cumulative Timesteps: 2,095,958,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.22697
Policy Entropy: 2.03120
Value Function Loss: 0.01838

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.60797

Collected Steps per Second: 23,168.68012
Overall Steps per Second: 10,773.19652

Timestep Collection Time: 2.15912
Timestep Consumption Time: 2.48425
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.64338

Cumulative Model Updates: 251,322
Cumulative Timesteps: 2,096,008,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2096008938...
Checkpoint 2096008938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.57981
Policy Entropy: 2.05357
Value Function Loss: 0.01870

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.55920
Value Function Update Magnitude: 0.61192

Collected Steps per Second: 22,264.81658
Overall Steps per Second: 10,611.15765

Timestep Collection Time: 2.24579
Timestep Consumption Time: 2.46642
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.71221

Cumulative Model Updates: 251,328
Cumulative Timesteps: 2,096,058,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.90240
Policy Entropy: 2.04480
Value Function Loss: 0.01828

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.55380
Value Function Update Magnitude: 0.61121

Collected Steps per Second: 21,900.81718
Overall Steps per Second: 10,473.51530

Timestep Collection Time: 2.28375
Timestep Consumption Time: 2.49172
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.77547

Cumulative Model Updates: 251,334
Cumulative Timesteps: 2,096,108,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2096108956...
Checkpoint 2096108956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.20972
Policy Entropy: 2.04675
Value Function Loss: 0.01840

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.60551

Collected Steps per Second: 22,406.03335
Overall Steps per Second: 10,782.23288

Timestep Collection Time: 2.23154
Timestep Consumption Time: 2.40572
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.63726

Cumulative Model Updates: 251,340
Cumulative Timesteps: 2,096,158,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.08878
Policy Entropy: 2.04663
Value Function Loss: 0.01926

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.55044
Value Function Update Magnitude: 0.58966

Collected Steps per Second: 23,418.74208
Overall Steps per Second: 10,798.31022

Timestep Collection Time: 2.13564
Timestep Consumption Time: 2.49601
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.63165

Cumulative Model Updates: 251,346
Cumulative Timesteps: 2,096,208,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2096208970...
Checkpoint 2096208970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.89048
Policy Entropy: 2.04649
Value Function Loss: 0.01916

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.55525
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 22,932.75009
Overall Steps per Second: 10,622.25684

Timestep Collection Time: 2.18099
Timestep Consumption Time: 2.52762
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.70860

Cumulative Model Updates: 251,352
Cumulative Timesteps: 2,096,258,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.02980
Policy Entropy: 2.03300
Value Function Loss: 0.01957

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.54884
Value Function Update Magnitude: 0.58977

Collected Steps per Second: 23,099.05286
Overall Steps per Second: 10,807.27645

Timestep Collection Time: 2.16468
Timestep Consumption Time: 2.46202
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.62670

Cumulative Model Updates: 251,358
Cumulative Timesteps: 2,096,308,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2096308988...
Checkpoint 2096308988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.65303
Policy Entropy: 2.02858
Value Function Loss: 0.01848

Mean KL Divergence: 0.02831
SB3 Clip Fraction: 0.16610
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 22,657.69293
Overall Steps per Second: 10,856.17716

Timestep Collection Time: 2.20737
Timestep Consumption Time: 2.39959
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.60696

Cumulative Model Updates: 251,364
Cumulative Timesteps: 2,096,359,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.42072
Policy Entropy: 2.01806
Value Function Loss: 0.01833

Mean KL Divergence: 0.03015
SB3 Clip Fraction: 0.17143
Policy Update Magnitude: 0.52325
Value Function Update Magnitude: 0.59068

Collected Steps per Second: 23,576.27099
Overall Steps per Second: 10,877.28038

Timestep Collection Time: 2.12095
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.59711

Cumulative Model Updates: 251,370
Cumulative Timesteps: 2,096,409,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2096409006...
Checkpoint 2096409006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.45341
Policy Entropy: 2.01629
Value Function Loss: 0.01833

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.16529
Policy Update Magnitude: 0.54687
Value Function Update Magnitude: 0.59944

Collected Steps per Second: 22,975.46671
Overall Steps per Second: 10,886.23812

Timestep Collection Time: 2.17702
Timestep Consumption Time: 2.41759
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.59461

Cumulative Model Updates: 251,376
Cumulative Timesteps: 2,096,459,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.06807
Policy Entropy: 1.99975
Value Function Loss: 0.01927

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.55000
Value Function Update Magnitude: 0.60429

Collected Steps per Second: 23,268.05050
Overall Steps per Second: 10,928.88365

Timestep Collection Time: 2.14930
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.57595

Cumulative Model Updates: 251,382
Cumulative Timesteps: 2,096,509,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2096509034...
Checkpoint 2096509034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.57336
Policy Entropy: 2.02857
Value Function Loss: 0.01915

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.54763
Value Function Update Magnitude: 0.61373

Collected Steps per Second: 22,101.82075
Overall Steps per Second: 10,721.85674

Timestep Collection Time: 2.26280
Timestep Consumption Time: 2.40169
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.66449

Cumulative Model Updates: 251,388
Cumulative Timesteps: 2,096,559,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.39205
Policy Entropy: 2.02854
Value Function Loss: 0.01985

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.55756
Value Function Update Magnitude: 0.63233

Collected Steps per Second: 23,450.26904
Overall Steps per Second: 10,890.80465

Timestep Collection Time: 2.13217
Timestep Consumption Time: 2.45886
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.59103

Cumulative Model Updates: 251,394
Cumulative Timesteps: 2,096,609,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2096609046...
Checkpoint 2096609046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.42069
Policy Entropy: 2.03411
Value Function Loss: 0.01938

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.64280

Collected Steps per Second: 22,246.24460
Overall Steps per Second: 10,631.22122

Timestep Collection Time: 2.24883
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.70576

Cumulative Model Updates: 251,400
Cumulative Timesteps: 2,096,659,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.80796
Policy Entropy: 2.00686
Value Function Loss: 0.01869

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.64046

Collected Steps per Second: 22,911.45560
Overall Steps per Second: 10,833.21449

Timestep Collection Time: 2.18258
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61599

Cumulative Model Updates: 251,406
Cumulative Timesteps: 2,096,709,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2096709080...
Checkpoint 2096709080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.04884
Policy Entropy: 2.02743
Value Function Loss: 0.01839

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.62367

Collected Steps per Second: 22,453.27834
Overall Steps per Second: 10,762.85223

Timestep Collection Time: 2.22756
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.64710

Cumulative Model Updates: 251,412
Cumulative Timesteps: 2,096,759,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.31903
Policy Entropy: 2.03935
Value Function Loss: 0.01827

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.14741
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.63388

Collected Steps per Second: 23,275.79471
Overall Steps per Second: 10,930.09138

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.42725
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.57617

Cumulative Model Updates: 251,418
Cumulative Timesteps: 2,096,809,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2096809114...
Checkpoint 2096809114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.87542
Policy Entropy: 2.03455
Value Function Loss: 0.01925

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.65789

Collected Steps per Second: 23,092.49318
Overall Steps per Second: 10,755.10069

Timestep Collection Time: 2.16633
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.65137

Cumulative Model Updates: 251,424
Cumulative Timesteps: 2,096,859,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.57320
Policy Entropy: 2.00696
Value Function Loss: 0.01962

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.14826
Policy Update Magnitude: 0.55681
Value Function Update Magnitude: 0.64567

Collected Steps per Second: 23,372.98321
Overall Steps per Second: 10,753.96180

Timestep Collection Time: 2.14033
Timestep Consumption Time: 2.51153
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.65187

Cumulative Model Updates: 251,430
Cumulative Timesteps: 2,096,909,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2096909166...
Checkpoint 2096909166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.06082
Policy Entropy: 1.99948
Value Function Loss: 0.01912

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.64451

Collected Steps per Second: 22,564.44956
Overall Steps per Second: 10,652.23597

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69592

Cumulative Model Updates: 251,436
Cumulative Timesteps: 2,096,959,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.06082
Policy Entropy: 2.01140
Value Function Loss: 0.01910

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.62264

Collected Steps per Second: 23,363.25341
Overall Steps per Second: 10,981.46202

Timestep Collection Time: 2.14011
Timestep Consumption Time: 2.41301
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.55313

Cumulative Model Updates: 251,442
Cumulative Timesteps: 2,097,009,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2097009188...
Checkpoint 2097009188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.46120
Policy Entropy: 2.01511
Value Function Loss: 0.01934

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.62183

Collected Steps per Second: 22,553.73648
Overall Steps per Second: 10,567.30747

Timestep Collection Time: 2.21755
Timestep Consumption Time: 2.51535
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.73290

Cumulative Model Updates: 251,448
Cumulative Timesteps: 2,097,059,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.43886
Policy Entropy: 2.01663
Value Function Loss: 0.01904

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 23,027.59639
Overall Steps per Second: 10,858.13751

Timestep Collection Time: 2.17261
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.60760

Cumulative Model Updates: 251,454
Cumulative Timesteps: 2,097,109,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2097109232...
Checkpoint 2097109232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.16756
Policy Entropy: 2.00524
Value Function Loss: 0.01815

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.55612
Value Function Update Magnitude: 0.62917

Collected Steps per Second: 22,167.62283
Overall Steps per Second: 10,674.45855

Timestep Collection Time: 2.25635
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.68576

Cumulative Model Updates: 251,460
Cumulative Timesteps: 2,097,159,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.59203
Policy Entropy: 2.00003
Value Function Loss: 0.01815

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.55890
Value Function Update Magnitude: 0.62690

Collected Steps per Second: 23,221.61230
Overall Steps per Second: 10,942.61430

Timestep Collection Time: 2.15317
Timestep Consumption Time: 2.41613
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.56929

Cumulative Model Updates: 251,466
Cumulative Timesteps: 2,097,209,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2097209250...
Checkpoint 2097209250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.75124
Policy Entropy: 1.99692
Value Function Loss: 0.01749

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.54806
Value Function Update Magnitude: 0.62815

Collected Steps per Second: 22,688.67566
Overall Steps per Second: 10,661.73647

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.69098

Cumulative Model Updates: 251,472
Cumulative Timesteps: 2,097,259,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.80228
Policy Entropy: 2.01439
Value Function Loss: 0.01693

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.53837
Value Function Update Magnitude: 0.63300

Collected Steps per Second: 23,246.09410
Overall Steps per Second: 10,879.60395

Timestep Collection Time: 2.15167
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.59741

Cumulative Model Updates: 251,478
Cumulative Timesteps: 2,097,309,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2097309282...
Checkpoint 2097309282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.99443
Policy Entropy: 2.02832
Value Function Loss: 0.01666

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 22,935.60098
Overall Steps per Second: 10,811.34771

Timestep Collection Time: 2.18019
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.62514

Cumulative Model Updates: 251,484
Cumulative Timesteps: 2,097,359,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.15855
Policy Entropy: 2.01831
Value Function Loss: 0.01809

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.61191

Collected Steps per Second: 22,804.05301
Overall Steps per Second: 10,867.28067

Timestep Collection Time: 2.19277
Timestep Consumption Time: 2.40857
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.60134

Cumulative Model Updates: 251,490
Cumulative Timesteps: 2,097,409,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2097409290...
Checkpoint 2097409290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.22231
Policy Entropy: 2.02166
Value Function Loss: 0.01902

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.60074

Collected Steps per Second: 23,077.18361
Overall Steps per Second: 10,923.55380

Timestep Collection Time: 2.16716
Timestep Consumption Time: 2.41120
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.57836

Cumulative Model Updates: 251,496
Cumulative Timesteps: 2,097,459,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.22920
Policy Entropy: 2.02804
Value Function Loss: 0.02017

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.61174

Collected Steps per Second: 22,763.10878
Overall Steps per Second: 10,716.48253

Timestep Collection Time: 2.19706
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.66683

Cumulative Model Updates: 251,502
Cumulative Timesteps: 2,097,509,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2097509314...
Checkpoint 2097509314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.40486
Policy Entropy: 2.03342
Value Function Loss: 0.01823

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.61385

Collected Steps per Second: 22,335.57121
Overall Steps per Second: 10,809.76283

Timestep Collection Time: 2.23867
Timestep Consumption Time: 2.38696
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.62563

Cumulative Model Updates: 251,508
Cumulative Timesteps: 2,097,559,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.36598
Policy Entropy: 2.02491
Value Function Loss: 0.01870

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.62680

Collected Steps per Second: 22,745.02432
Overall Steps per Second: 11,028.80275

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.33623
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.53540

Cumulative Model Updates: 251,514
Cumulative Timesteps: 2,097,609,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2097609336...
Checkpoint 2097609336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.32627
Policy Entropy: 2.01644
Value Function Loss: 0.01894

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.56719
Value Function Update Magnitude: 0.63440

Collected Steps per Second: 23,080.59260
Overall Steps per Second: 10,732.82273

Timestep Collection Time: 2.16650
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.65898

Cumulative Model Updates: 251,520
Cumulative Timesteps: 2,097,659,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.99426
Policy Entropy: 2.02976
Value Function Loss: 0.01954

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.55943
Value Function Update Magnitude: 0.63762

Collected Steps per Second: 23,300.43585
Overall Steps per Second: 10,758.00266

Timestep Collection Time: 2.14708
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.65031

Cumulative Model Updates: 251,526
Cumulative Timesteps: 2,097,709,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2097709368...
Checkpoint 2097709368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.49807
Policy Entropy: 2.02481
Value Function Loss: 0.01949

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.63715

Collected Steps per Second: 22,595.11799
Overall Steps per Second: 10,668.90902

Timestep Collection Time: 2.21287
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.68651

Cumulative Model Updates: 251,532
Cumulative Timesteps: 2,097,759,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.93412
Policy Entropy: 2.00806
Value Function Loss: 0.01952

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.62937

Collected Steps per Second: 23,402.63538
Overall Steps per Second: 11,009.35315

Timestep Collection Time: 2.13720
Timestep Consumption Time: 2.40585
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.54305

Cumulative Model Updates: 251,538
Cumulative Timesteps: 2,097,809,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2097809384...
Checkpoint 2097809384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.45422
Policy Entropy: 1.99551
Value Function Loss: 0.02032

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.55198
Value Function Update Magnitude: 0.63419

Collected Steps per Second: 23,226.76969
Overall Steps per Second: 10,924.79433

Timestep Collection Time: 2.15269
Timestep Consumption Time: 2.42406
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.57675

Cumulative Model Updates: 251,544
Cumulative Timesteps: 2,097,859,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.96496
Policy Entropy: 1.98626
Value Function Loss: 0.01972

Mean KL Divergence: 0.03078
SB3 Clip Fraction: 0.17016
Policy Update Magnitude: 0.51289
Value Function Update Magnitude: 0.65647

Collected Steps per Second: 23,157.92992
Overall Steps per Second: 10,862.15470

Timestep Collection Time: 2.15986
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60480

Cumulative Model Updates: 251,550
Cumulative Timesteps: 2,097,909,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2097909402...
Checkpoint 2097909402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.89248
Policy Entropy: 1.99957
Value Function Loss: 0.01924

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.51552
Value Function Update Magnitude: 0.65551

Collected Steps per Second: 22,219.83006
Overall Steps per Second: 10,763.97422

Timestep Collection Time: 2.25087
Timestep Consumption Time: 2.39555
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.64643

Cumulative Model Updates: 251,556
Cumulative Timesteps: 2,097,959,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.93002
Policy Entropy: 2.00054
Value Function Loss: 0.01921

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.55999
Value Function Update Magnitude: 0.65922

Collected Steps per Second: 23,468.06935
Overall Steps per Second: 10,875.16730

Timestep Collection Time: 2.13183
Timestep Consumption Time: 2.46856
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.60039

Cumulative Model Updates: 251,562
Cumulative Timesteps: 2,098,009,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2098009446...
Checkpoint 2098009446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.86943
Policy Entropy: 2.02303
Value Function Loss: 0.01866

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.56738
Value Function Update Magnitude: 0.67294

Collected Steps per Second: 22,454.04157
Overall Steps per Second: 10,642.00726

Timestep Collection Time: 2.22713
Timestep Consumption Time: 2.47199
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.69911

Cumulative Model Updates: 251,568
Cumulative Timesteps: 2,098,059,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.89668
Policy Entropy: 2.04586
Value Function Loss: 0.01808

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.55196
Value Function Update Magnitude: 0.66413

Collected Steps per Second: 22,963.04701
Overall Steps per Second: 10,940.88866

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.39490
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.57440

Cumulative Model Updates: 251,574
Cumulative Timesteps: 2,098,109,502

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2098109502...
Checkpoint 2098109502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.70253
Policy Entropy: 2.05830
Value Function Loss: 0.01702

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 22,936.99381
Overall Steps per Second: 10,982.66716

Timestep Collection Time: 2.18023
Timestep Consumption Time: 2.37312
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.55336

Cumulative Model Updates: 251,580
Cumulative Timesteps: 2,098,159,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.97076
Policy Entropy: 2.05238
Value Function Loss: 0.01783

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.53516
Value Function Update Magnitude: 0.62668

Collected Steps per Second: 23,428.28246
Overall Steps per Second: 10,949.30947

Timestep Collection Time: 2.13486
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.56796

Cumulative Model Updates: 251,586
Cumulative Timesteps: 2,098,209,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2098209526...
Checkpoint 2098209526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.47629
Policy Entropy: 2.04535
Value Function Loss: 0.01690

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.54447
Value Function Update Magnitude: 0.63548

Collected Steps per Second: 23,049.44456
Overall Steps per Second: 10,690.21406

Timestep Collection Time: 2.17003
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.67886

Cumulative Model Updates: 251,592
Cumulative Timesteps: 2,098,259,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.79030
Policy Entropy: 2.04377
Value Function Loss: 0.01718

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.54382
Value Function Update Magnitude: 0.63158

Collected Steps per Second: 23,226.50473
Overall Steps per Second: 10,871.87503

Timestep Collection Time: 2.15314
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.59994

Cumulative Model Updates: 251,598
Cumulative Timesteps: 2,098,309,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2098309554...
Checkpoint 2098309554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.78011
Policy Entropy: 2.04789
Value Function Loss: 0.01763

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.65523

Collected Steps per Second: 22,679.97348
Overall Steps per Second: 10,662.39653

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.48548
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.69069

Cumulative Model Updates: 251,604
Cumulative Timesteps: 2,098,359,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.99679
Policy Entropy: 2.02611
Value Function Loss: 0.01788

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.55384
Value Function Update Magnitude: 0.64997

Collected Steps per Second: 24,058.56090
Overall Steps per Second: 10,936.52704

Timestep Collection Time: 2.07909
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.57366

Cumulative Model Updates: 251,610
Cumulative Timesteps: 2,098,409,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2098409588...
Checkpoint 2098409588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.64709
Policy Entropy: 2.01281
Value Function Loss: 0.01858

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.63517

Collected Steps per Second: 22,531.28627
Overall Steps per Second: 10,656.31007

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69374

Cumulative Model Updates: 251,616
Cumulative Timesteps: 2,098,459,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.33403
Policy Entropy: 2.00037
Value Function Loss: 0.01985

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.56691
Value Function Update Magnitude: 0.66466

Collected Steps per Second: 22,616.21664
Overall Steps per Second: 10,806.67685

Timestep Collection Time: 2.21213
Timestep Consumption Time: 2.41742
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62955

Cumulative Model Updates: 251,622
Cumulative Timesteps: 2,098,509,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2098509636...
Checkpoint 2098509636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.29006
Policy Entropy: 1.99143
Value Function Loss: 0.02005

Mean KL Divergence: 0.02933
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.68112

Collected Steps per Second: 22,134.21848
Overall Steps per Second: 10,731.88177

Timestep Collection Time: 2.26003
Timestep Consumption Time: 2.40122
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.66125

Cumulative Model Updates: 251,628
Cumulative Timesteps: 2,098,559,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.61680
Policy Entropy: 1.99914
Value Function Loss: 0.01967

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.56010
Value Function Update Magnitude: 0.66138

Collected Steps per Second: 23,019.93450
Overall Steps per Second: 10,907.84083

Timestep Collection Time: 2.17299
Timestep Consumption Time: 2.41289
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.58588

Cumulative Model Updates: 251,634
Cumulative Timesteps: 2,098,609,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2098609682...
Checkpoint 2098609682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.93894
Policy Entropy: 2.03476
Value Function Loss: 0.01813

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.55349
Value Function Update Magnitude: 0.64934

Collected Steps per Second: 22,578.49624
Overall Steps per Second: 10,646.69938

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.69685

Cumulative Model Updates: 251,640
Cumulative Timesteps: 2,098,659,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.03741
Policy Entropy: 2.03477
Value Function Loss: 0.01884

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.64552

Collected Steps per Second: 23,127.40319
Overall Steps per Second: 10,836.09411

Timestep Collection Time: 2.16228
Timestep Consumption Time: 2.45266
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61495

Cumulative Model Updates: 251,646
Cumulative Timesteps: 2,098,709,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2098709696...
Checkpoint 2098709696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.16801
Policy Entropy: 2.02361
Value Function Loss: 0.01835

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.64071

Collected Steps per Second: 22,776.51877
Overall Steps per Second: 10,661.27063

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.49473
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.69006

Cumulative Model Updates: 251,652
Cumulative Timesteps: 2,098,759,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.66800
Policy Entropy: 1.98853
Value Function Loss: 0.02171

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.64907

Collected Steps per Second: 23,158.33889
Overall Steps per Second: 10,937.15326

Timestep Collection Time: 2.15905
Timestep Consumption Time: 2.41252
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.57157

Cumulative Model Updates: 251,658
Cumulative Timesteps: 2,098,809,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2098809698...
Checkpoint 2098809698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.55434
Policy Entropy: 2.00132
Value Function Loss: 0.02069

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.67502

Collected Steps per Second: 22,768.34860
Overall Steps per Second: 10,654.25220

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.69465

Cumulative Model Updates: 251,664
Cumulative Timesteps: 2,098,859,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.44980
Policy Entropy: 2.01857
Value Function Loss: 0.02089

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.57459
Value Function Update Magnitude: 0.69586

Collected Steps per Second: 23,180.09360
Overall Steps per Second: 10,920.88438

Timestep Collection Time: 2.15754
Timestep Consumption Time: 2.42194
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.57948

Cumulative Model Updates: 251,670
Cumulative Timesteps: 2,098,909,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2098909728...
Checkpoint 2098909728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.57340
Policy Entropy: 2.01755
Value Function Loss: 0.01829

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.55466
Value Function Update Magnitude: 0.67883

Collected Steps per Second: 22,277.14330
Overall Steps per Second: 10,612.92258

Timestep Collection Time: 2.24589
Timestep Consumption Time: 2.46836
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71425

Cumulative Model Updates: 251,676
Cumulative Timesteps: 2,098,959,760

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.15850
Policy Entropy: 2.02522
Value Function Loss: 0.01831

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.66421

Collected Steps per Second: 23,626.06871
Overall Steps per Second: 10,946.57927

Timestep Collection Time: 2.11698
Timestep Consumption Time: 2.45212
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.56910

Cumulative Model Updates: 251,682
Cumulative Timesteps: 2,099,009,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2099009776...
Checkpoint 2099009776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.00394
Policy Entropy: 2.00487
Value Function Loss: 0.01959

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.65410

Collected Steps per Second: 22,304.77602
Overall Steps per Second: 10,619.11549

Timestep Collection Time: 2.24239
Timestep Consumption Time: 2.46761
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.71000

Cumulative Model Updates: 251,688
Cumulative Timesteps: 2,099,059,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.18175
Policy Entropy: 2.00709
Value Function Loss: 0.02054

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.56599
Value Function Update Magnitude: 0.64566

Collected Steps per Second: 22,896.18891
Overall Steps per Second: 10,894.81742

Timestep Collection Time: 2.18456
Timestep Consumption Time: 2.40643
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59099

Cumulative Model Updates: 251,694
Cumulative Timesteps: 2,099,109,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2099109810...
Checkpoint 2099109810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.51508
Policy Entropy: 1.98757
Value Function Loss: 0.02059

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.64108

Collected Steps per Second: 22,688.06878
Overall Steps per Second: 10,654.95837

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.48885
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.69265

Cumulative Model Updates: 251,700
Cumulative Timesteps: 2,099,159,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.38106
Policy Entropy: 1.97151
Value Function Loss: 0.02086

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.64478

Collected Steps per Second: 22,965.25397
Overall Steps per Second: 10,901.32740

Timestep Collection Time: 2.17746
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.58715

Cumulative Model Updates: 251,706
Cumulative Timesteps: 2,099,209,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2099209816...
Checkpoint 2099209816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.48994
Policy Entropy: 1.99459
Value Function Loss: 0.01860

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.54755
Value Function Update Magnitude: 0.64612

Collected Steps per Second: 22,861.75351
Overall Steps per Second: 10,682.41864

Timestep Collection Time: 2.18723
Timestep Consumption Time: 2.49373
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.68096

Cumulative Model Updates: 251,712
Cumulative Timesteps: 2,099,259,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.86439
Policy Entropy: 2.00310
Value Function Loss: 0.01814

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.62555

Collected Steps per Second: 23,258.45236
Overall Steps per Second: 10,884.59638

Timestep Collection Time: 2.15070
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.59567

Cumulative Model Updates: 251,718
Cumulative Timesteps: 2,099,309,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2099309842...
Checkpoint 2099309842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.82889
Policy Entropy: 2.02337
Value Function Loss: 0.01791

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.60587

Collected Steps per Second: 22,417.05970
Overall Steps per Second: 10,602.87245

Timestep Collection Time: 2.23062
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.71608

Cumulative Model Updates: 251,724
Cumulative Timesteps: 2,099,359,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.06408
Policy Entropy: 2.01529
Value Function Loss: 0.01888

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.55291
Value Function Update Magnitude: 0.60043

Collected Steps per Second: 23,366.90488
Overall Steps per Second: 10,907.06760

Timestep Collection Time: 2.14046
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.58565

Cumulative Model Updates: 251,730
Cumulative Timesteps: 2,099,409,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2099409862...
Checkpoint 2099409862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.66509
Policy Entropy: 2.01554
Value Function Loss: 0.01875

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.60021

Collected Steps per Second: 22,755.72949
Overall Steps per Second: 10,666.96952

Timestep Collection Time: 2.19751
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68793

Cumulative Model Updates: 251,736
Cumulative Timesteps: 2,099,459,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.47645
Policy Entropy: 2.01487
Value Function Loss: 0.01817

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 22,498.76163
Overall Steps per Second: 10,589.89631

Timestep Collection Time: 2.22288
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.72261

Cumulative Model Updates: 251,742
Cumulative Timesteps: 2,099,509,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2099509880...
Checkpoint 2099509880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.18790
Policy Entropy: 2.01645
Value Function Loss: 0.01766

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.53111
Value Function Update Magnitude: 0.60484

Collected Steps per Second: 21,994.96564
Overall Steps per Second: 10,542.05745

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.46976
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.74310

Cumulative Model Updates: 251,748
Cumulative Timesteps: 2,099,559,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.43688
Policy Entropy: 2.03214
Value Function Loss: 0.01756

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.52968
Value Function Update Magnitude: 0.58350

Collected Steps per Second: 23,028.60304
Overall Steps per Second: 10,862.51521

Timestep Collection Time: 2.17121
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.60299

Cumulative Model Updates: 251,754
Cumulative Timesteps: 2,099,609,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2099609882...
Checkpoint 2099609882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.59416
Policy Entropy: 2.02230
Value Function Loss: 0.01748

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.51637
Value Function Update Magnitude: 0.56644

Collected Steps per Second: 22,464.16209
Overall Steps per Second: 10,620.74058

Timestep Collection Time: 2.22630
Timestep Consumption Time: 2.48260
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.70890

Cumulative Model Updates: 251,760
Cumulative Timesteps: 2,099,659,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.13952
Policy Entropy: 2.01701
Value Function Loss: 0.01866

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.52199
Value Function Update Magnitude: 0.57682

Collected Steps per Second: 23,457.60500
Overall Steps per Second: 10,874.38115

Timestep Collection Time: 2.13150
Timestep Consumption Time: 2.46646
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.59796

Cumulative Model Updates: 251,766
Cumulative Timesteps: 2,099,709,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2099709894...
Checkpoint 2099709894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.67936
Policy Entropy: 2.01143
Value Function Loss: 0.01796

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.53203
Value Function Update Magnitude: 0.59322

Collected Steps per Second: 22,519.76434
Overall Steps per Second: 10,632.50389

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.48318
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.70425

Cumulative Model Updates: 251,772
Cumulative Timesteps: 2,099,759,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.97926
Policy Entropy: 2.00733
Value Function Loss: 0.01924

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.62252

Collected Steps per Second: 23,293.16614
Overall Steps per Second: 10,984.11614

Timestep Collection Time: 2.14707
Timestep Consumption Time: 2.40605
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.55312

Cumulative Model Updates: 251,778
Cumulative Timesteps: 2,099,809,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2099809924...
Checkpoint 2099809924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.70449
Policy Entropy: 2.03083
Value Function Loss: 0.01740

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.54599
Value Function Update Magnitude: 0.64331

Collected Steps per Second: 22,866.17427
Overall Steps per Second: 10,702.37354

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.67298

Cumulative Model Updates: 251,784
Cumulative Timesteps: 2,099,859,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.64878
Policy Entropy: 2.05246
Value Function Loss: 0.01805

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.64617

Collected Steps per Second: 23,277.78121
Overall Steps per Second: 10,855.85497

Timestep Collection Time: 2.14823
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.60636

Cumulative Model Updates: 251,790
Cumulative Timesteps: 2,099,909,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2099909942...
Checkpoint 2099909942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.06242
Policy Entropy: 2.06120
Value Function Loss: 0.01756

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.63704

Collected Steps per Second: 21,842.99805
Overall Steps per Second: 10,657.78902

Timestep Collection Time: 2.29044
Timestep Consumption Time: 2.40378
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.69422

Cumulative Model Updates: 251,796
Cumulative Timesteps: 2,099,959,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.99119
Policy Entropy: 2.04187
Value Function Loss: 0.01793

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.55434
Value Function Update Magnitude: 0.63511

Collected Steps per Second: 22,789.61026
Overall Steps per Second: 10,904.56049

Timestep Collection Time: 2.19556
Timestep Consumption Time: 2.39298
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.58854

Cumulative Model Updates: 251,802
Cumulative Timesteps: 2,100,010,008

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2100010008...
Checkpoint 2100010008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.52515
Policy Entropy: 2.03690
Value Function Loss: 0.01644

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.53405
Value Function Update Magnitude: 0.61598

Collected Steps per Second: 22,494.90142
Overall Steps per Second: 10,592.19164

Timestep Collection Time: 2.22273
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.72046

Cumulative Model Updates: 251,808
Cumulative Timesteps: 2,100,060,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.55968
Policy Entropy: 2.05225
Value Function Loss: 0.01654

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.61029

Collected Steps per Second: 22,988.04081
Overall Steps per Second: 10,836.15219

Timestep Collection Time: 2.17557
Timestep Consumption Time: 2.43973
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.61529

Cumulative Model Updates: 251,814
Cumulative Timesteps: 2,100,110,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2100110020...
Checkpoint 2100110020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.37580
Policy Entropy: 2.06948
Value Function Loss: 0.01689

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.52477
Value Function Update Magnitude: 0.62334

Collected Steps per Second: 21,944.55334
Overall Steps per Second: 10,617.76361

Timestep Collection Time: 2.27893
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.71003

Cumulative Model Updates: 251,820
Cumulative Timesteps: 2,100,160,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.56603
Policy Entropy: 2.06522
Value Function Loss: 0.01772

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.52867
Value Function Update Magnitude: 0.64570

Collected Steps per Second: 23,321.19562
Overall Steps per Second: 10,996.09568

Timestep Collection Time: 2.14483
Timestep Consumption Time: 2.40406
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.54889

Cumulative Model Updates: 251,826
Cumulative Timesteps: 2,100,210,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2100210050...
Checkpoint 2100210050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.48680
Policy Entropy: 2.05921
Value Function Loss: 0.01685

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.52435
Value Function Update Magnitude: 0.64962

Collected Steps per Second: 22,940.90621
Overall Steps per Second: 10,714.31165

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.66815

Cumulative Model Updates: 251,832
Cumulative Timesteps: 2,100,260,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.97378
Policy Entropy: 2.06610
Value Function Loss: 0.01681

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.52368
Value Function Update Magnitude: 0.63996

Collected Steps per Second: 23,341.78664
Overall Steps per Second: 10,857.11612

Timestep Collection Time: 2.14208
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.60527

Cumulative Model Updates: 251,838
Cumulative Timesteps: 2,100,310,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2100310066...
Checkpoint 2100310066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.74307
Policy Entropy: 2.06660
Value Function Loss: 0.01738

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.52760
Value Function Update Magnitude: 0.63654

Collected Steps per Second: 22,745.61012
Overall Steps per Second: 10,605.34680

Timestep Collection Time: 2.19831
Timestep Consumption Time: 2.51648
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71479

Cumulative Model Updates: 251,844
Cumulative Timesteps: 2,100,360,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.52357
Policy Entropy: 2.07752
Value Function Loss: 0.01738

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.53444
Value Function Update Magnitude: 0.63769

Collected Steps per Second: 23,114.25117
Overall Steps per Second: 10,916.14619

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.41817
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.58220

Cumulative Model Updates: 251,850
Cumulative Timesteps: 2,100,410,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2100410088...
Checkpoint 2100410088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.34820
Policy Entropy: 2.04958
Value Function Loss: 0.01751

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.65466

Collected Steps per Second: 23,203.19881
Overall Steps per Second: 10,794.51774

Timestep Collection Time: 2.15488
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.63198

Cumulative Model Updates: 251,856
Cumulative Timesteps: 2,100,460,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.19970
Policy Entropy: 2.01219
Value Function Loss: 0.01751

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.63503

Collected Steps per Second: 23,057.28817
Overall Steps per Second: 10,784.74280

Timestep Collection Time: 2.16929
Timestep Consumption Time: 2.46856
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.63785

Cumulative Model Updates: 251,862
Cumulative Timesteps: 2,100,510,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2100510106...
Checkpoint 2100510106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.05044
Policy Entropy: 1.99465
Value Function Loss: 0.01848

Mean KL Divergence: 0.02581
SB3 Clip Fraction: 0.15680
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.63157

Collected Steps per Second: 22,465.38742
Overall Steps per Second: 10,632.27700

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.70473

Cumulative Model Updates: 251,868
Cumulative Timesteps: 2,100,560,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.46380
Policy Entropy: 1.99903
Value Function Loss: 0.01896

Mean KL Divergence: 0.02633
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.50427
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 22,350.03330
Overall Steps per Second: 10,911.76527

Timestep Collection Time: 2.23794
Timestep Consumption Time: 2.34592
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.58386

Cumulative Model Updates: 251,874
Cumulative Timesteps: 2,100,610,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2100610146...
Checkpoint 2100610146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.85972
Policy Entropy: 2.03408
Value Function Loss: 0.01831

Mean KL Divergence: 0.03265
SB3 Clip Fraction: 0.18023
Policy Update Magnitude: 0.50353
Value Function Update Magnitude: 0.63995

Collected Steps per Second: 22,490.09857
Overall Steps per Second: 10,671.02733

Timestep Collection Time: 2.22329
Timestep Consumption Time: 2.46248
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.68577

Cumulative Model Updates: 251,880
Cumulative Timesteps: 2,100,660,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.49780
Policy Entropy: 2.04452
Value Function Loss: 0.01871

Mean KL Divergence: 0.04539
SB3 Clip Fraction: 0.21486
Policy Update Magnitude: 0.48817
Value Function Update Magnitude: 0.63820

Collected Steps per Second: 23,356.93244
Overall Steps per Second: 10,893.70403

Timestep Collection Time: 2.14172
Timestep Consumption Time: 2.45029
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.59201

Cumulative Model Updates: 251,886
Cumulative Timesteps: 2,100,710,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2100710172...
Checkpoint 2100710172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.44100
Policy Entropy: 2.04830
Value Function Loss: 0.02001

Mean KL Divergence: 0.03847
SB3 Clip Fraction: 0.18636
Policy Update Magnitude: 0.55002
Value Function Update Magnitude: 0.67708

Collected Steps per Second: 22,404.63011
Overall Steps per Second: 10,607.63726

Timestep Collection Time: 2.23186
Timestep Consumption Time: 2.48210
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.71396

Cumulative Model Updates: 251,892
Cumulative Timesteps: 2,100,760,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.06429
Policy Entropy: 2.03219
Value Function Loss: 0.01885

Mean KL Divergence: 0.02919
SB3 Clip Fraction: 0.17392
Policy Update Magnitude: 0.57501
Value Function Update Magnitude: 0.69448

Collected Steps per Second: 23,022.02758
Overall Steps per Second: 10,896.99125

Timestep Collection Time: 2.17227
Timestep Consumption Time: 2.41707
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.58934

Cumulative Model Updates: 251,898
Cumulative Timesteps: 2,100,810,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2100810186...
Checkpoint 2100810186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.09203
Policy Entropy: 2.03160
Value Function Loss: 0.01752

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.67698

Collected Steps per Second: 22,628.09218
Overall Steps per Second: 10,828.08366

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.40904
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.61965

Cumulative Model Updates: 251,904
Cumulative Timesteps: 2,100,860,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.42541
Policy Entropy: 2.02902
Value Function Loss: 0.01677

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.62562

Collected Steps per Second: 23,424.00479
Overall Steps per Second: 10,823.45355

Timestep Collection Time: 2.13507
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.62071

Cumulative Model Updates: 251,910
Cumulative Timesteps: 2,100,910,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2100910220...
Checkpoint 2100910220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.97358
Policy Entropy: 2.04059
Value Function Loss: 0.01644

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.60894

Collected Steps per Second: 22,354.50893
Overall Steps per Second: 10,586.93168

Timestep Collection Time: 2.23677
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.72299

Cumulative Model Updates: 251,916
Cumulative Timesteps: 2,100,960,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.18057
Policy Entropy: 2.01970
Value Function Loss: 0.01770

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.54560
Value Function Update Magnitude: 0.60866

Collected Steps per Second: 22,654.34804
Overall Steps per Second: 10,840.56173

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.40542
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61268

Cumulative Model Updates: 251,922
Cumulative Timesteps: 2,101,010,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2101010226...
Checkpoint 2101010226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.96594
Policy Entropy: 2.03990
Value Function Loss: 0.01737

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.53965
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 22,041.50301
Overall Steps per Second: 10,712.86511

Timestep Collection Time: 2.26954
Timestep Consumption Time: 2.39999
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.66953

Cumulative Model Updates: 251,928
Cumulative Timesteps: 2,101,060,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.40924
Policy Entropy: 2.03112
Value Function Loss: 0.01782

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.53959
Value Function Update Magnitude: 0.62348

Collected Steps per Second: 22,964.57498
Overall Steps per Second: 10,839.13979

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61310

Cumulative Model Updates: 251,934
Cumulative Timesteps: 2,101,110,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2101110252...
Checkpoint 2101110252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.19843
Policy Entropy: 2.02932
Value Function Loss: 0.01729

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.63004

Collected Steps per Second: 22,626.53341
Overall Steps per Second: 10,668.17178

Timestep Collection Time: 2.21068
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.68871

Cumulative Model Updates: 251,940
Cumulative Timesteps: 2,101,160,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.79519
Policy Entropy: 2.00029
Value Function Loss: 0.01874

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.61590

Collected Steps per Second: 23,116.06262
Overall Steps per Second: 10,873.57834

Timestep Collection Time: 2.16334
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.59904

Cumulative Model Updates: 251,946
Cumulative Timesteps: 2,101,210,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2101210280...
Checkpoint 2101210280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.28976
Policy Entropy: 1.98250
Value Function Loss: 0.02016

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.61860

Collected Steps per Second: 22,706.85514
Overall Steps per Second: 10,846.33943

Timestep Collection Time: 2.20198
Timestep Consumption Time: 2.40787
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.60985

Cumulative Model Updates: 251,952
Cumulative Timesteps: 2,101,260,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.25350
Policy Entropy: 1.99851
Value Function Loss: 0.01951

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.64175

Collected Steps per Second: 23,483.78412
Overall Steps per Second: 10,784.23618

Timestep Collection Time: 2.13024
Timestep Consumption Time: 2.50857
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.63881

Cumulative Model Updates: 251,958
Cumulative Timesteps: 2,101,310,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2101310306...
Checkpoint 2101310306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.26282
Policy Entropy: 2.01276
Value Function Loss: 0.01813

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.64900

Collected Steps per Second: 22,724.15779
Overall Steps per Second: 10,647.99642

Timestep Collection Time: 2.20127
Timestep Consumption Time: 2.49652
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.69779

Cumulative Model Updates: 251,964
Cumulative Timesteps: 2,101,360,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.50560
Policy Entropy: 2.01602
Value Function Loss: 0.01736

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.54319
Value Function Update Magnitude: 0.64668

Collected Steps per Second: 23,197.55873
Overall Steps per Second: 10,922.12169

Timestep Collection Time: 2.15583
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.57878

Cumulative Model Updates: 251,970
Cumulative Timesteps: 2,101,410,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2101410338...
Checkpoint 2101410338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.16424
Policy Entropy: 2.00749
Value Function Loss: 0.01715

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.53106
Value Function Update Magnitude: 0.63467

Collected Steps per Second: 22,712.03661
Overall Steps per Second: 11,023.42683

Timestep Collection Time: 2.20200
Timestep Consumption Time: 2.33488
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.53688

Cumulative Model Updates: 251,976
Cumulative Timesteps: 2,101,460,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.81468
Policy Entropy: 1.97739
Value Function Loss: 0.01733

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.53145
Value Function Update Magnitude: 0.61560

Collected Steps per Second: 22,878.40329
Overall Steps per Second: 10,735.89206

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.47339
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.66026

Cumulative Model Updates: 251,982
Cumulative Timesteps: 2,101,510,382

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2101510382...
Checkpoint 2101510382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.59500
Policy Entropy: 1.98409
Value Function Loss: 0.01689

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.53244
Value Function Update Magnitude: 0.59587

Collected Steps per Second: 22,407.74797
Overall Steps per Second: 10,648.83980

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.69553

Cumulative Model Updates: 251,988
Cumulative Timesteps: 2,101,560,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.55461
Policy Entropy: 1.98059
Value Function Loss: 0.01701

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.52156
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 22,703.28385
Overall Steps per Second: 10,679.85399

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68377

Cumulative Model Updates: 251,994
Cumulative Timesteps: 2,101,610,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2101610406...
Checkpoint 2101610406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.68679
Policy Entropy: 1.98726
Value Function Loss: 0.01824

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,179.07015
Overall Steps per Second: 10,615.55673

Timestep Collection Time: 2.25564
Timestep Consumption Time: 2.45707
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.71271

Cumulative Model Updates: 252,000
Cumulative Timesteps: 2,101,660,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.05780
Policy Entropy: 1.99987
Value Function Loss: 0.01761

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.15561
Policy Update Magnitude: 0.53545
Value Function Update Magnitude: 0.62308

Collected Steps per Second: 23,036.51450
Overall Steps per Second: 10,946.84881

Timestep Collection Time: 2.17168
Timestep Consumption Time: 2.39840
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.57008

Cumulative Model Updates: 252,006
Cumulative Timesteps: 2,101,710,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2101710462...
Checkpoint 2101710462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.72457
Policy Entropy: 2.01173
Value Function Loss: 0.01781

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.62955

Collected Steps per Second: 22,625.41674
Overall Steps per Second: 10,613.10745

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.71342

Cumulative Model Updates: 252,012
Cumulative Timesteps: 2,101,760,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.80882
Policy Entropy: 2.00733
Value Function Loss: 0.01695

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.54569
Value Function Update Magnitude: 0.63118

Collected Steps per Second: 23,057.43592
Overall Steps per Second: 10,887.78561

Timestep Collection Time: 2.16884
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59304

Cumulative Model Updates: 252,018
Cumulative Timesteps: 2,101,810,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2101810494...
Checkpoint 2101810494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.45399
Policy Entropy: 2.00197
Value Function Loss: 0.01817

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.54761
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 22,820.85832
Overall Steps per Second: 10,709.29806

Timestep Collection Time: 2.19150
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.66996

Cumulative Model Updates: 252,024
Cumulative Timesteps: 2,101,860,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.85975
Policy Entropy: 1.99330
Value Function Loss: 0.01853

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.61252

Collected Steps per Second: 21,886.51254
Overall Steps per Second: 10,787.46581

Timestep Collection Time: 2.28533
Timestep Consumption Time: 2.35134
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.63668

Cumulative Model Updates: 252,030
Cumulative Timesteps: 2,101,910,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2101910524...
Checkpoint 2101910524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.31544
Policy Entropy: 1.98860
Value Function Loss: 0.01834

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.17704
Policy Update Magnitude: 0.49164
Value Function Update Magnitude: 0.61473

Collected Steps per Second: 22,544.29967
Overall Steps per Second: 10,699.84544

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.45619
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.67502

Cumulative Model Updates: 252,036
Cumulative Timesteps: 2,101,960,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.70828
Policy Entropy: 2.02537
Value Function Loss: 0.01747

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.16678
Policy Update Magnitude: 0.51198
Value Function Update Magnitude: 0.62170

Collected Steps per Second: 22,484.00885
Overall Steps per Second: 10,596.50979

Timestep Collection Time: 2.22514
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.72137

Cumulative Model Updates: 252,042
Cumulative Timesteps: 2,102,010,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2102010576...
Checkpoint 2102010576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.69748
Policy Entropy: 2.02906
Value Function Loss: 0.01691

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.53700
Value Function Update Magnitude: 0.61126

Collected Steps per Second: 22,549.94452
Overall Steps per Second: 10,623.78104

Timestep Collection Time: 2.21792
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70774

Cumulative Model Updates: 252,048
Cumulative Timesteps: 2,102,060,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.35065
Policy Entropy: 2.05001
Value Function Loss: 0.01781

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.58750

Collected Steps per Second: 23,159.79312
Overall Steps per Second: 10,881.87800

Timestep Collection Time: 2.15917
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.59535

Cumulative Model Updates: 252,054
Cumulative Timesteps: 2,102,110,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2102110596...
Checkpoint 2102110596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.72581
Policy Entropy: 2.02550
Value Function Loss: 0.01836

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.53969
Value Function Update Magnitude: 0.57659

Collected Steps per Second: 22,850.41707
Overall Steps per Second: 10,686.46238

Timestep Collection Time: 2.18893
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68050

Cumulative Model Updates: 252,060
Cumulative Timesteps: 2,102,160,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.92627
Policy Entropy: 2.05206
Value Function Loss: 0.01796

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.58564

Collected Steps per Second: 23,558.62404
Overall Steps per Second: 10,800.78932

Timestep Collection Time: 2.12296
Timestep Consumption Time: 2.50763
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.63059

Cumulative Model Updates: 252,066
Cumulative Timesteps: 2,102,210,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2102210628...
Checkpoint 2102210628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.49353
Policy Entropy: 2.01370
Value Function Loss: 0.01809

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.54769
Value Function Update Magnitude: 0.58590

Collected Steps per Second: 22,955.22794
Overall Steps per Second: 10,801.25929

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.45221
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.63150

Cumulative Model Updates: 252,072
Cumulative Timesteps: 2,102,260,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.40147
Policy Entropy: 2.01055
Value Function Loss: 0.01729

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.58233

Collected Steps per Second: 23,412.54951
Overall Steps per Second: 11,162.58920

Timestep Collection Time: 2.13595
Timestep Consumption Time: 2.34402
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.47996

Cumulative Model Updates: 252,078
Cumulative Timesteps: 2,102,310,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2102310662...
Checkpoint 2102310662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.41479
Policy Entropy: 1.98682
Value Function Loss: 0.01853

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.60659

Collected Steps per Second: 22,759.42976
Overall Steps per Second: 10,702.19776

Timestep Collection Time: 2.19724
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.67269

Cumulative Model Updates: 252,084
Cumulative Timesteps: 2,102,360,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.86017
Policy Entropy: 1.98842
Value Function Loss: 0.01827

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.62746

Collected Steps per Second: 22,840.60459
Overall Steps per Second: 10,832.00058

Timestep Collection Time: 2.18935
Timestep Consumption Time: 2.42716
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61651

Cumulative Model Updates: 252,090
Cumulative Timesteps: 2,102,410,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2102410676...
Checkpoint 2102410676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.53248
Policy Entropy: 1.97152
Value Function Loss: 0.01850

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.63790

Collected Steps per Second: 22,335.20096
Overall Steps per Second: 10,689.12036

Timestep Collection Time: 2.23889
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.67821

Cumulative Model Updates: 252,096
Cumulative Timesteps: 2,102,460,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.62682
Policy Entropy: 1.93654
Value Function Loss: 0.01881

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.55891
Value Function Update Magnitude: 0.64701

Collected Steps per Second: 23,045.23289
Overall Steps per Second: 10,929.70948

Timestep Collection Time: 2.16973
Timestep Consumption Time: 2.40514
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.57487

Cumulative Model Updates: 252,102
Cumulative Timesteps: 2,102,510,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2102510684...
Checkpoint 2102510684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.29464
Policy Entropy: 1.96281
Value Function Loss: 0.01826

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.66190

Collected Steps per Second: 22,403.46561
Overall Steps per Second: 10,649.47673

Timestep Collection Time: 2.23296
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.69751

Cumulative Model Updates: 252,108
Cumulative Timesteps: 2,102,560,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.69061
Policy Entropy: 1.94472
Value Function Loss: 0.01998

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.15425
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.65810

Collected Steps per Second: 23,650.34851
Overall Steps per Second: 10,902.70263

Timestep Collection Time: 2.11523
Timestep Consumption Time: 2.47317
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.58840

Cumulative Model Updates: 252,114
Cumulative Timesteps: 2,102,610,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2102610736...
Checkpoint 2102610736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.53459
Policy Entropy: 1.95941
Value Function Loss: 0.01919

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.64894

Collected Steps per Second: 22,783.35535
Overall Steps per Second: 10,690.49298

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68005

Cumulative Model Updates: 252,120
Cumulative Timesteps: 2,102,660,768

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.46859
Policy Entropy: 1.92218
Value Function Loss: 0.02091

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.65118

Collected Steps per Second: 23,092.54490
Overall Steps per Second: 10,858.03745

Timestep Collection Time: 2.16581
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.60617

Cumulative Model Updates: 252,126
Cumulative Timesteps: 2,102,710,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2102710782...
Checkpoint 2102710782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.89817
Policy Entropy: 1.94646
Value Function Loss: 0.01991

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.65876

Collected Steps per Second: 22,606.12547
Overall Steps per Second: 10,687.28795

Timestep Collection Time: 2.21179
Timestep Consumption Time: 2.46667
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.67846

Cumulative Model Updates: 252,132
Cumulative Timesteps: 2,102,760,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.04360
Policy Entropy: 1.94149
Value Function Loss: 0.01978

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.63735

Collected Steps per Second: 23,365.58739
Overall Steps per Second: 10,938.39137

Timestep Collection Time: 2.14041
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.57215

Cumulative Model Updates: 252,138
Cumulative Timesteps: 2,102,810,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2102810794...
Checkpoint 2102810794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.03950
Policy Entropy: 1.97316
Value Function Loss: 0.01853

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.61909

Collected Steps per Second: 22,204.51332
Overall Steps per Second: 10,626.38010

Timestep Collection Time: 2.25197
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.70565

Cumulative Model Updates: 252,144
Cumulative Timesteps: 2,102,860,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.74391
Policy Entropy: 1.96400
Value Function Loss: 0.01708

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.61864

Collected Steps per Second: 22,726.16471
Overall Steps per Second: 10,908.82784

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.38419
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.58509

Cumulative Model Updates: 252,150
Cumulative Timesteps: 2,102,910,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2102910816...
Checkpoint 2102910816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.88155
Policy Entropy: 1.95586
Value Function Loss: 0.01804

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.60830

Collected Steps per Second: 22,427.16206
Overall Steps per Second: 10,625.11692

Timestep Collection Time: 2.23006
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.70715

Cumulative Model Updates: 252,156
Cumulative Timesteps: 2,102,960,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.08105
Policy Entropy: 1.95585
Value Function Loss: 0.01792

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.55048
Value Function Update Magnitude: 0.61331

Collected Steps per Second: 22,829.70403
Overall Steps per Second: 10,835.82053

Timestep Collection Time: 2.19118
Timestep Consumption Time: 2.42536
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61654

Cumulative Model Updates: 252,162
Cumulative Timesteps: 2,103,010,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2103010854...
Checkpoint 2103010854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.78425
Policy Entropy: 1.93801
Value Function Loss: 0.01904

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.54957
Value Function Update Magnitude: 0.62525

Collected Steps per Second: 22,462.16385
Overall Steps per Second: 10,734.24833

Timestep Collection Time: 2.22730
Timestep Consumption Time: 2.43348
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.66078

Cumulative Model Updates: 252,168
Cumulative Timesteps: 2,103,060,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.56255
Policy Entropy: 1.93634
Value Function Loss: 0.01902

Mean KL Divergence: 0.02750
SB3 Clip Fraction: 0.16473
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.63311

Collected Steps per Second: 23,284.46761
Overall Steps per Second: 10,909.29818

Timestep Collection Time: 2.14778
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.58416

Cumulative Model Updates: 252,174
Cumulative Timesteps: 2,103,110,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2103110894...
Checkpoint 2103110894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.97380
Policy Entropy: 1.94875
Value Function Loss: 0.01978

Mean KL Divergence: 0.02943
SB3 Clip Fraction: 0.17145
Policy Update Magnitude: 0.52167
Value Function Update Magnitude: 0.63914

Collected Steps per Second: 22,788.66739
Overall Steps per Second: 10,965.63843

Timestep Collection Time: 2.19504
Timestep Consumption Time: 2.36667
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.56170

Cumulative Model Updates: 252,180
Cumulative Timesteps: 2,103,160,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.10415
Policy Entropy: 1.97180
Value Function Loss: 0.01831

Mean KL Divergence: 0.03354
SB3 Clip Fraction: 0.17922
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.63028

Collected Steps per Second: 22,719.88286
Overall Steps per Second: 10,601.45096

Timestep Collection Time: 2.20080
Timestep Consumption Time: 2.51572
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.71652

Cumulative Model Updates: 252,186
Cumulative Timesteps: 2,103,210,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2103210918...
Checkpoint 2103210918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.02721
Policy Entropy: 1.97189
Value Function Loss: 0.01839

Mean KL Divergence: 0.03210
SB3 Clip Fraction: 0.17639
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.62421

Collected Steps per Second: 22,685.08522
Overall Steps per Second: 10,636.16762

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70376

Cumulative Model Updates: 252,192
Cumulative Timesteps: 2,103,260,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.72746
Policy Entropy: 1.96909
Value Function Loss: 0.01715

Mean KL Divergence: 0.03013
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.55487
Value Function Update Magnitude: 0.65002

Collected Steps per Second: 23,256.98522
Overall Steps per Second: 10,877.45145

Timestep Collection Time: 2.15032
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.59758

Cumulative Model Updates: 252,198
Cumulative Timesteps: 2,103,310,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2103310958...
Checkpoint 2103310958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.09439
Policy Entropy: 1.97010
Value Function Loss: 0.01842

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.16352
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.65939

Collected Steps per Second: 23,343.14356
Overall Steps per Second: 10,855.23432

Timestep Collection Time: 2.14307
Timestep Consumption Time: 2.46540
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.60847

Cumulative Model Updates: 252,204
Cumulative Timesteps: 2,103,360,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.09324
Policy Entropy: 1.97873
Value Function Loss: 0.01904

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.15944
Policy Update Magnitude: 0.57284
Value Function Update Magnitude: 0.65463

Collected Steps per Second: 22,863.90524
Overall Steps per Second: 10,726.06479

Timestep Collection Time: 2.18790
Timestep Consumption Time: 2.47588
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.66378

Cumulative Model Updates: 252,210
Cumulative Timesteps: 2,103,411,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2103411008...
Checkpoint 2103411008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.27082
Policy Entropy: 1.97668
Value Function Loss: 0.01887

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.65781

Collected Steps per Second: 22,586.15034
Overall Steps per Second: 10,664.43280

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.47553
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.68998

Cumulative Model Updates: 252,216
Cumulative Timesteps: 2,103,461,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.71406
Policy Entropy: 1.98876
Value Function Loss: 0.01833

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.55369
Value Function Update Magnitude: 0.66167

Collected Steps per Second: 22,734.93704
Overall Steps per Second: 10,885.38828

Timestep Collection Time: 2.20058
Timestep Consumption Time: 2.39549
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.59607

Cumulative Model Updates: 252,222
Cumulative Timesteps: 2,103,511,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2103511054...
Checkpoint 2103511054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.19955
Policy Entropy: 1.98901
Value Function Loss: 0.01780

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.65830

Collected Steps per Second: 22,283.14084
Overall Steps per Second: 10,632.79770

Timestep Collection Time: 2.24493
Timestep Consumption Time: 2.45976
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.70469

Cumulative Model Updates: 252,228
Cumulative Timesteps: 2,103,561,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.57121
Policy Entropy: 1.97831
Value Function Loss: 0.01818

Mean KL Divergence: 0.03123
SB3 Clip Fraction: 0.17433
Policy Update Magnitude: 0.54569
Value Function Update Magnitude: 0.65327

Collected Steps per Second: 23,442.53983
Overall Steps per Second: 10,862.57026

Timestep Collection Time: 2.13347
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60425

Cumulative Model Updates: 252,234
Cumulative Timesteps: 2,103,611,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2103611092...
Checkpoint 2103611092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.00160
Policy Entropy: 1.96965
Value Function Loss: 0.01785

Mean KL Divergence: 0.02560
SB3 Clip Fraction: 0.15718
Policy Update Magnitude: 0.49645
Value Function Update Magnitude: 0.63938

Collected Steps per Second: 22,783.16140
Overall Steps per Second: 10,684.69617

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.48529
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.68015

Cumulative Model Updates: 252,240
Cumulative Timesteps: 2,103,661,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.53078
Policy Entropy: 2.00015
Value Function Loss: 0.01909

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.14622
Policy Update Magnitude: 0.52954
Value Function Update Magnitude: 0.62483

Collected Steps per Second: 23,244.87589
Overall Steps per Second: 10,925.35578

Timestep Collection Time: 2.15101
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.57651

Cumulative Model Updates: 252,246
Cumulative Timesteps: 2,103,711,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2103711098...
Checkpoint 2103711098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.86341
Policy Entropy: 2.01973
Value Function Loss: 0.01809

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.53304
Value Function Update Magnitude: 0.63685

Collected Steps per Second: 22,946.49391
Overall Steps per Second: 10,719.78170

Timestep Collection Time: 2.17924
Timestep Consumption Time: 2.48559
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.66483

Cumulative Model Updates: 252,252
Cumulative Timesteps: 2,103,761,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.81073
Policy Entropy: 2.00586
Value Function Loss: 0.01933

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.54574
Value Function Update Magnitude: 0.63063

Collected Steps per Second: 23,171.18107
Overall Steps per Second: 10,713.04581

Timestep Collection Time: 2.15915
Timestep Consumption Time: 2.51086
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.67001

Cumulative Model Updates: 252,258
Cumulative Timesteps: 2,103,811,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2103811134...
Checkpoint 2103811134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.91886
Policy Entropy: 1.98232
Value Function Loss: 0.01907

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.61846

Collected Steps per Second: 22,640.59834
Overall Steps per Second: 10,706.79814

Timestep Collection Time: 2.20842
Timestep Consumption Time: 2.46151
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.66993

Cumulative Model Updates: 252,264
Cumulative Timesteps: 2,103,861,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.90046
Policy Entropy: 1.98800
Value Function Loss: 0.01950

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.63682

Collected Steps per Second: 23,108.76521
Overall Steps per Second: 10,943.91041

Timestep Collection Time: 2.16411
Timestep Consumption Time: 2.40555
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.56966

Cumulative Model Updates: 252,270
Cumulative Timesteps: 2,103,911,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2103911144...
Checkpoint 2103911144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.43023
Policy Entropy: 1.97993
Value Function Loss: 0.02057

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.64658

Collected Steps per Second: 22,312.80539
Overall Steps per Second: 10,631.88825

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.70453

Cumulative Model Updates: 252,276
Cumulative Timesteps: 2,103,961,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.89567
Policy Entropy: 1.96707
Value Function Loss: 0.01994

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.65900

Collected Steps per Second: 22,862.79825
Overall Steps per Second: 10,805.50996

Timestep Collection Time: 2.18775
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.62893

Cumulative Model Updates: 252,282
Cumulative Timesteps: 2,104,011,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2104011180...
Checkpoint 2104011180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.94479
Policy Entropy: 1.95189
Value Function Loss: 0.01952

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.54268
Value Function Update Magnitude: 0.65192

Collected Steps per Second: 22,280.14696
Overall Steps per Second: 10,758.68595

Timestep Collection Time: 2.24433
Timestep Consumption Time: 2.40345
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.64778

Cumulative Model Updates: 252,288
Cumulative Timesteps: 2,104,061,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.86361
Policy Entropy: 1.97563
Value Function Loss: 0.01856

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.53825
Value Function Update Magnitude: 0.64220

Collected Steps per Second: 22,983.19817
Overall Steps per Second: 10,862.33927

Timestep Collection Time: 2.17646
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.60509

Cumulative Model Updates: 252,294
Cumulative Timesteps: 2,104,111,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2104111206...
Checkpoint 2104111206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.28499
Policy Entropy: 1.99206
Value Function Loss: 0.01749

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.64023

Collected Steps per Second: 22,696.87130
Overall Steps per Second: 10,653.89949

Timestep Collection Time: 2.20295
Timestep Consumption Time: 2.49017
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.69312

Cumulative Model Updates: 252,300
Cumulative Timesteps: 2,104,161,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.59183
Policy Entropy: 1.99780
Value Function Loss: 0.01809

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.53416
Value Function Update Magnitude: 0.63356

Collected Steps per Second: 23,389.79250
Overall Steps per Second: 10,912.07974

Timestep Collection Time: 2.13845
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.58373

Cumulative Model Updates: 252,306
Cumulative Timesteps: 2,104,211,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2104211224...
Checkpoint 2104211224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.94834
Policy Entropy: 1.98762
Value Function Loss: 0.01767

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.52012
Value Function Update Magnitude: 0.61810

Collected Steps per Second: 22,817.47598
Overall Steps per Second: 10,768.87451

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.64357

Cumulative Model Updates: 252,312
Cumulative Timesteps: 2,104,261,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.65496
Policy Entropy: 1.98424
Value Function Loss: 0.01851

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.52844
Value Function Update Magnitude: 0.60354

Collected Steps per Second: 23,334.15971
Overall Steps per Second: 11,058.47434

Timestep Collection Time: 2.14390
Timestep Consumption Time: 2.37987
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.52377

Cumulative Model Updates: 252,318
Cumulative Timesteps: 2,104,311,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2104311256...
Checkpoint 2104311256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.88554
Policy Entropy: 1.97850
Value Function Loss: 0.01891

Mean KL Divergence: 0.02574
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.52138
Value Function Update Magnitude: 0.60008

Collected Steps per Second: 22,419.28895
Overall Steps per Second: 10,740.98190

Timestep Collection Time: 2.23040
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.65544

Cumulative Model Updates: 252,324
Cumulative Timesteps: 2,104,361,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.13530
Policy Entropy: 1.97434
Value Function Loss: 0.01916

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.49518
Value Function Update Magnitude: 0.60941

Collected Steps per Second: 23,241.81013
Overall Steps per Second: 10,914.71572

Timestep Collection Time: 2.15207
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58262

Cumulative Model Updates: 252,330
Cumulative Timesteps: 2,104,411,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2104411278...
Checkpoint 2104411278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.54413
Policy Entropy: 1.99156
Value Function Loss: 0.01919

Mean KL Divergence: 0.02938
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.51555
Value Function Update Magnitude: 0.61585

Collected Steps per Second: 22,384.58833
Overall Steps per Second: 10,684.08223

Timestep Collection Time: 2.23448
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.68154

Cumulative Model Updates: 252,336
Cumulative Timesteps: 2,104,461,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.13771
Policy Entropy: 1.97789
Value Function Loss: 0.01889

Mean KL Divergence: 0.02672
SB3 Clip Fraction: 0.16723
Policy Update Magnitude: 0.54819
Value Function Update Magnitude: 0.60828

Collected Steps per Second: 23,039.84089
Overall Steps per Second: 10,953.76069

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.39487
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.56537

Cumulative Model Updates: 252,342
Cumulative Timesteps: 2,104,511,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2104511304...
Checkpoint 2104511304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.65990
Policy Entropy: 1.99844
Value Function Loss: 0.01860

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.59690

Collected Steps per Second: 22,415.37521
Overall Steps per Second: 10,624.33935

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.47645
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.70787

Cumulative Model Updates: 252,348
Cumulative Timesteps: 2,104,561,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.84067
Policy Entropy: 2.00160
Value Function Loss: 0.01881

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.55362
Value Function Update Magnitude: 0.61381

Collected Steps per Second: 23,132.79929
Overall Steps per Second: 10,871.04179

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.60232

Cumulative Model Updates: 252,354
Cumulative Timesteps: 2,104,611,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2104611354...
Checkpoint 2104611354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.70349
Policy Entropy: 2.00803
Value Function Loss: 0.01935

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.55786
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 22,546.75271
Overall Steps per Second: 10,649.30420

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.47872
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.69740

Cumulative Model Updates: 252,360
Cumulative Timesteps: 2,104,661,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.75493
Policy Entropy: 2.00254
Value Function Loss: 0.01865

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.55198
Value Function Update Magnitude: 0.62551

Collected Steps per Second: 23,298.35212
Overall Steps per Second: 10,975.98955

Timestep Collection Time: 2.14702
Timestep Consumption Time: 2.41038
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.55740

Cumulative Model Updates: 252,366
Cumulative Timesteps: 2,104,711,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2104711400...
Checkpoint 2104711400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.39258
Policy Entropy: 1.99233
Value Function Loss: 0.01840

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.53337
Value Function Update Magnitude: 0.60830

Collected Steps per Second: 23,482.17337
Overall Steps per Second: 11,004.49564

Timestep Collection Time: 2.12927
Timestep Consumption Time: 2.41432
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.54360

Cumulative Model Updates: 252,372
Cumulative Timesteps: 2,104,761,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.19634
Policy Entropy: 1.99185
Value Function Loss: 0.01884

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.58722

Collected Steps per Second: 22,999.75850
Overall Steps per Second: 10,745.36262

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.47963
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.65391

Cumulative Model Updates: 252,378
Cumulative Timesteps: 2,104,811,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2104811408...
Checkpoint 2104811408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.46404
Policy Entropy: 1.98398
Value Function Loss: 0.02005

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.60189

Collected Steps per Second: 22,937.59153
Overall Steps per Second: 10,894.30041

Timestep Collection Time: 2.18000
Timestep Consumption Time: 2.40992
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.58992

Cumulative Model Updates: 252,384
Cumulative Timesteps: 2,104,861,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.03880
Policy Entropy: 1.96732
Value Function Loss: 0.01977

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.55549
Value Function Update Magnitude: 0.63354

Collected Steps per Second: 23,406.11524
Overall Steps per Second: 10,998.85510

Timestep Collection Time: 2.13713
Timestep Consumption Time: 2.41079
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.54793

Cumulative Model Updates: 252,390
Cumulative Timesteps: 2,104,911,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2104911434...
Checkpoint 2104911434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.62826
Policy Entropy: 1.97152
Value Function Loss: 0.01840

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.64879

Collected Steps per Second: 22,274.75132
Overall Steps per Second: 10,576.83229

Timestep Collection Time: 2.24595
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.72996

Cumulative Model Updates: 252,396
Cumulative Timesteps: 2,104,961,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.54706
Policy Entropy: 1.97770
Value Function Loss: 0.01881

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.64421

Collected Steps per Second: 22,799.02572
Overall Steps per Second: 10,786.98961

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.63707

Cumulative Model Updates: 252,402
Cumulative Timesteps: 2,105,011,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2105011482...
Checkpoint 2105011482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.95154
Policy Entropy: 2.00314
Value Function Loss: 0.01921

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.66565

Collected Steps per Second: 22,292.71308
Overall Steps per Second: 10,710.80399

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.66856

Cumulative Model Updates: 252,408
Cumulative Timesteps: 2,105,061,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.50508
Policy Entropy: 2.00586
Value Function Loss: 0.01927

Mean KL Divergence: 0.03121
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.67577

Collected Steps per Second: 22,794.59118
Overall Steps per Second: 10,868.40120

Timestep Collection Time: 2.19456
Timestep Consumption Time: 2.40815
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60270

Cumulative Model Updates: 252,414
Cumulative Timesteps: 2,105,111,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2105111510...
Checkpoint 2105111510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.44111
Policy Entropy: 2.02527
Value Function Loss: 0.01795

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.64886

Collected Steps per Second: 23,254.59321
Overall Steps per Second: 10,726.62758

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.66279

Cumulative Model Updates: 252,420
Cumulative Timesteps: 2,105,161,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.92851
Policy Entropy: 2.01823
Value Function Loss: 0.01802

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.53792
Value Function Update Magnitude: 0.60530

Collected Steps per Second: 23,254.45054
Overall Steps per Second: 10,864.20401

Timestep Collection Time: 2.15090
Timestep Consumption Time: 2.45303
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.60393

Cumulative Model Updates: 252,426
Cumulative Timesteps: 2,105,211,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2105211544...
Checkpoint 2105211544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.51519
Policy Entropy: 2.01634
Value Function Loss: 0.01797

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.54547
Value Function Update Magnitude: 0.61087

Collected Steps per Second: 22,715.12062
Overall Steps per Second: 10,610.59697

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.71246

Cumulative Model Updates: 252,432
Cumulative Timesteps: 2,105,261,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.36459
Policy Entropy: 1.99887
Value Function Loss: 0.01884

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.62583

Collected Steps per Second: 23,328.60022
Overall Steps per Second: 10,927.77620

Timestep Collection Time: 2.14355
Timestep Consumption Time: 2.43250
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.57605

Cumulative Model Updates: 252,438
Cumulative Timesteps: 2,105,311,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2105311552...
Checkpoint 2105311552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.16969
Policy Entropy: 2.00200
Value Function Loss: 0.01835

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.53840
Value Function Update Magnitude: 0.61687

Collected Steps per Second: 23,116.25196
Overall Steps per Second: 10,772.30815

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.64246

Cumulative Model Updates: 252,444
Cumulative Timesteps: 2,105,361,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.29984
Policy Entropy: 2.00255
Value Function Loss: 0.01904

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.54388
Value Function Update Magnitude: 0.61198

Collected Steps per Second: 23,321.02103
Overall Steps per Second: 10,796.49054

Timestep Collection Time: 2.14433
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.63188

Cumulative Model Updates: 252,450
Cumulative Timesteps: 2,105,411,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2105411570...
Checkpoint 2105411570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.71353
Policy Entropy: 2.00512
Value Function Loss: 0.01921

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.53526
Value Function Update Magnitude: 0.62152

Collected Steps per Second: 22,281.93367
Overall Steps per Second: 10,634.92478

Timestep Collection Time: 2.24532
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.70431

Cumulative Model Updates: 252,456
Cumulative Timesteps: 2,105,461,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.68385
Policy Entropy: 2.00241
Value Function Loss: 0.01851

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.62231

Collected Steps per Second: 22,967.28592
Overall Steps per Second: 10,899.89529

Timestep Collection Time: 2.17797
Timestep Consumption Time: 2.41125
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58922

Cumulative Model Updates: 252,462
Cumulative Timesteps: 2,105,511,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2105511622...
Checkpoint 2105511622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.75472
Policy Entropy: 2.00438
Value Function Loss: 0.01872

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.59918

Collected Steps per Second: 22,984.71859
Overall Steps per Second: 10,768.07705

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.64503

Cumulative Model Updates: 252,468
Cumulative Timesteps: 2,105,561,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.12304
Policy Entropy: 1.99777
Value Function Loss: 0.01917

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.62132

Collected Steps per Second: 23,011.72719
Overall Steps per Second: 10,778.84829

Timestep Collection Time: 2.17367
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.64057

Cumulative Model Updates: 252,474
Cumulative Timesteps: 2,105,611,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2105611660...
Checkpoint 2105611660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.92402
Policy Entropy: 1.99459
Value Function Loss: 0.02006

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.55145
Value Function Update Magnitude: 0.62683

Collected Steps per Second: 22,710.66003
Overall Steps per Second: 10,631.79262

Timestep Collection Time: 2.20231
Timestep Consumption Time: 2.50207
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.70438

Cumulative Model Updates: 252,480
Cumulative Timesteps: 2,105,661,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.67971
Policy Entropy: 1.97338
Value Function Loss: 0.02144

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.61074

Collected Steps per Second: 23,260.90782
Overall Steps per Second: 10,945.51422

Timestep Collection Time: 2.14987
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.56881

Cumulative Model Updates: 252,486
Cumulative Timesteps: 2,105,711,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2105711684...
Checkpoint 2105711684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.21645
Policy Entropy: 1.97973
Value Function Loss: 0.02082

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 21,598.17047
Overall Steps per Second: 10,608.08728

Timestep Collection Time: 2.31566
Timestep Consumption Time: 2.39905
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.71470

Cumulative Model Updates: 252,492
Cumulative Timesteps: 2,105,761,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.73379
Policy Entropy: 1.98790
Value Function Loss: 0.01869

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.55519
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 23,545.90123
Overall Steps per Second: 10,914.12354

Timestep Collection Time: 2.12385
Timestep Consumption Time: 2.45810
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.58195

Cumulative Model Updates: 252,498
Cumulative Timesteps: 2,105,811,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2105811706...
Checkpoint 2105811706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.50392
Policy Entropy: 1.99403
Value Function Loss: 0.01854

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.56349
Value Function Update Magnitude: 0.63541

Collected Steps per Second: 22,715.58423
Overall Steps per Second: 10,627.39926

Timestep Collection Time: 2.20166
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.70595

Cumulative Model Updates: 252,504
Cumulative Timesteps: 2,105,861,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.32967
Policy Entropy: 1.99479
Value Function Loss: 0.01770

Mean KL Divergence: 0.02254
SB3 Clip Fraction: 0.14934
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.64623

Collected Steps per Second: 23,227.69781
Overall Steps per Second: 11,005.37082

Timestep Collection Time: 2.15295
Timestep Consumption Time: 2.39102
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.54396

Cumulative Model Updates: 252,510
Cumulative Timesteps: 2,105,911,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2105911726...
Checkpoint 2105911726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.18997
Policy Entropy: 2.01596
Value Function Loss: 0.01684

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.54351
Value Function Update Magnitude: 0.65607

Collected Steps per Second: 22,408.67495
Overall Steps per Second: 10,811.47399

Timestep Collection Time: 2.23208
Timestep Consumption Time: 2.39430
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.62638

Cumulative Model Updates: 252,516
Cumulative Timesteps: 2,105,961,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.30399
Policy Entropy: 2.02250
Value Function Loss: 0.01731

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.53165
Value Function Update Magnitude: 0.64388

Collected Steps per Second: 23,106.48944
Overall Steps per Second: 10,726.93264

Timestep Collection Time: 2.16441
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.66228

Cumulative Model Updates: 252,522
Cumulative Timesteps: 2,106,011,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2106011756...
Checkpoint 2106011756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.65367
Policy Entropy: 2.00548
Value Function Loss: 0.01815

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.53855
Value Function Update Magnitude: 0.64046

Collected Steps per Second: 22,378.75342
Overall Steps per Second: 10,594.31498

Timestep Collection Time: 2.23569
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.72253

Cumulative Model Updates: 252,528
Cumulative Timesteps: 2,106,061,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.27003
Policy Entropy: 1.99385
Value Function Loss: 0.01975

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.63522

Collected Steps per Second: 22,851.56640
Overall Steps per Second: 10,872.21596

Timestep Collection Time: 2.18838
Timestep Consumption Time: 2.41123
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59961

Cumulative Model Updates: 252,534
Cumulative Timesteps: 2,106,111,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2106111796...
Checkpoint 2106111796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.56948
Policy Entropy: 2.00109
Value Function Loss: 0.01880

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.54814
Value Function Update Magnitude: 0.62987

Collected Steps per Second: 22,698.57371
Overall Steps per Second: 10,827.80735

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.61811

Cumulative Model Updates: 252,540
Cumulative Timesteps: 2,106,161,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.86339
Policy Entropy: 2.01838
Value Function Loss: 0.01908

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.61297

Collected Steps per Second: 23,644.34124
Overall Steps per Second: 10,832.62170

Timestep Collection Time: 2.11586
Timestep Consumption Time: 2.50242
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.61827

Cumulative Model Updates: 252,546
Cumulative Timesteps: 2,106,211,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2106211828...
Checkpoint 2106211828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.11288
Policy Entropy: 2.00526
Value Function Loss: 0.01742

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.53756
Value Function Update Magnitude: 0.60278

Collected Steps per Second: 22,656.08700
Overall Steps per Second: 10,619.15367

Timestep Collection Time: 2.20815
Timestep Consumption Time: 2.50296
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.71111

Cumulative Model Updates: 252,552
Cumulative Timesteps: 2,106,261,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.12161
Policy Entropy: 1.99578
Value Function Loss: 0.01787

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.60797

Collected Steps per Second: 22,961.05602
Overall Steps per Second: 10,849.56494

Timestep Collection Time: 2.17777
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.60885

Cumulative Model Updates: 252,558
Cumulative Timesteps: 2,106,311,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2106311860...
Checkpoint 2106311860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.01030
Policy Entropy: 1.98455
Value Function Loss: 0.01748

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.54286
Value Function Update Magnitude: 0.61670

Collected Steps per Second: 22,895.17126
Overall Steps per Second: 10,766.57877

Timestep Collection Time: 2.18465
Timestep Consumption Time: 2.46102
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.64567

Cumulative Model Updates: 252,564
Cumulative Timesteps: 2,106,361,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.61648
Policy Entropy: 1.99355
Value Function Loss: 0.01771

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.60795

Collected Steps per Second: 23,873.65921
Overall Steps per Second: 10,924.94472

Timestep Collection Time: 2.09486
Timestep Consumption Time: 2.48292
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.57778

Cumulative Model Updates: 252,570
Cumulative Timesteps: 2,106,411,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2106411890...
Checkpoint 2106411890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.80298
Policy Entropy: 1.98804
Value Function Loss: 0.01892

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.54765
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 22,725.86842
Overall Steps per Second: 10,707.97298

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.67129

Cumulative Model Updates: 252,576
Cumulative Timesteps: 2,106,461,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.86697
Policy Entropy: 1.99297
Value Function Loss: 0.01812

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.60275

Collected Steps per Second: 22,740.60319
Overall Steps per Second: 10,713.14091

Timestep Collection Time: 2.19968
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.66922

Cumulative Model Updates: 252,582
Cumulative Timesteps: 2,106,511,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2106511932...
Checkpoint 2106511932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.82405
Policy Entropy: 2.00019
Value Function Loss: 0.01786

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.61021

Collected Steps per Second: 22,241.14876
Overall Steps per Second: 10,735.60298

Timestep Collection Time: 2.24916
Timestep Consumption Time: 2.41047
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.65964

Cumulative Model Updates: 252,588
Cumulative Timesteps: 2,106,561,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.79202
Policy Entropy: 2.02115
Value Function Loss: 0.01642

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 23,160.57648
Overall Steps per Second: 10,830.55987

Timestep Collection Time: 2.15979
Timestep Consumption Time: 2.45881
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.61860

Cumulative Model Updates: 252,594
Cumulative Timesteps: 2,106,611,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2106611978...
Checkpoint 2106611978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.71626
Policy Entropy: 2.01115
Value Function Loss: 0.01709

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.53750
Value Function Update Magnitude: 0.59162

Collected Steps per Second: 23,131.75448
Overall Steps per Second: 10,618.58321

Timestep Collection Time: 2.16222
Timestep Consumption Time: 2.54801
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.71023

Cumulative Model Updates: 252,600
Cumulative Timesteps: 2,106,661,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.86800
Policy Entropy: 2.00346
Value Function Loss: 0.01807

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.59006

Collected Steps per Second: 23,050.11555
Overall Steps per Second: 10,840.41518

Timestep Collection Time: 2.17031
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61477

Cumulative Model Updates: 252,606
Cumulative Timesteps: 2,106,712,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2106712020...
Checkpoint 2106712020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.17144
Policy Entropy: 1.99221
Value Function Loss: 0.01831

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,832.67237
Overall Steps per Second: 10,912.75683

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.39214
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.58216

Cumulative Model Updates: 252,612
Cumulative Timesteps: 2,106,762,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.69671
Policy Entropy: 1.99556
Value Function Loss: 0.01886

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.63017

Collected Steps per Second: 23,505.31186
Overall Steps per Second: 10,826.44746

Timestep Collection Time: 2.12820
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.62054

Cumulative Model Updates: 252,618
Cumulative Timesteps: 2,106,812,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2106812048...
Checkpoint 2106812048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.02163
Policy Entropy: 1.99595
Value Function Loss: 0.01891

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.63787

Collected Steps per Second: 22,894.06074
Overall Steps per Second: 10,740.20693

Timestep Collection Time: 2.18406
Timestep Consumption Time: 2.47153
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.65559

Cumulative Model Updates: 252,624
Cumulative Timesteps: 2,106,862,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.66837
Policy Entropy: 1.98743
Value Function Loss: 0.01951

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.66360

Collected Steps per Second: 23,279.25180
Overall Steps per Second: 10,855.33329

Timestep Collection Time: 2.14878
Timestep Consumption Time: 2.45928
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.60806

Cumulative Model Updates: 252,630
Cumulative Timesteps: 2,106,912,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2106912072...
Checkpoint 2106912072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.48828
Policy Entropy: 1.99418
Value Function Loss: 0.01857

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.56834
Value Function Update Magnitude: 0.68871

Collected Steps per Second: 22,573.63753
Overall Steps per Second: 10,861.03194

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.38902
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.60435

Cumulative Model Updates: 252,636
Cumulative Timesteps: 2,106,962,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.47430
Policy Entropy: 1.98215
Value Function Loss: 0.01893

Mean KL Divergence: 0.02534
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.69811

Collected Steps per Second: 23,762.83325
Overall Steps per Second: 11,002.35596

Timestep Collection Time: 2.10581
Timestep Consumption Time: 2.44231
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.54812

Cumulative Model Updates: 252,642
Cumulative Timesteps: 2,107,012,120

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2107012120...
Checkpoint 2107012120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.57386
Policy Entropy: 1.99370
Value Function Loss: 0.01822

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.14638
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.69818

Collected Steps per Second: 22,115.92745
Overall Steps per Second: 10,672.43306

Timestep Collection Time: 2.26145
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.68628

Cumulative Model Updates: 252,648
Cumulative Timesteps: 2,107,062,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.72086
Policy Entropy: 2.00220
Value Function Loss: 0.01899

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.15322
Policy Update Magnitude: 0.53484
Value Function Update Magnitude: 0.67401

Collected Steps per Second: 23,011.58097
Overall Steps per Second: 10,873.55603

Timestep Collection Time: 2.17360
Timestep Consumption Time: 2.42637
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.59997

Cumulative Model Updates: 252,654
Cumulative Timesteps: 2,107,112,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2107112152...
Checkpoint 2107112152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.07650
Policy Entropy: 2.03568
Value Function Loss: 0.01880

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.17294
Policy Update Magnitude: 0.49796
Value Function Update Magnitude: 0.65515

Collected Steps per Second: 22,588.73436
Overall Steps per Second: 10,755.21169

Timestep Collection Time: 2.21402
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.65002

Cumulative Model Updates: 252,660
Cumulative Timesteps: 2,107,162,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.92752
Policy Entropy: 2.03596
Value Function Loss: 0.01841

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.51692
Value Function Update Magnitude: 0.65861

Collected Steps per Second: 23,407.39950
Overall Steps per Second: 10,756.98513

Timestep Collection Time: 2.13633
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.64870

Cumulative Model Updates: 252,666
Cumulative Timesteps: 2,107,212,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2107212170...
Checkpoint 2107212170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.25148
Policy Entropy: 2.04052
Value Function Loss: 0.01797

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.52912
Value Function Update Magnitude: 0.63797

Collected Steps per Second: 22,604.54126
Overall Steps per Second: 10,640.61978

Timestep Collection Time: 2.21239
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.69991

Cumulative Model Updates: 252,672
Cumulative Timesteps: 2,107,262,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.03073
Policy Entropy: 2.03103
Value Function Loss: 0.01860

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.53676
Value Function Update Magnitude: 0.63827

Collected Steps per Second: 23,020.15377
Overall Steps per Second: 10,955.75633

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.39238
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.56491

Cumulative Model Updates: 252,678
Cumulative Timesteps: 2,107,312,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2107312192...
Checkpoint 2107312192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.04510
Policy Entropy: 2.02360
Value Function Loss: 0.01875

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.17460
Policy Update Magnitude: 0.51665
Value Function Update Magnitude: 0.65332

Collected Steps per Second: 22,604.22652
Overall Steps per Second: 10,838.26575

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.40227
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.61513

Cumulative Model Updates: 252,684
Cumulative Timesteps: 2,107,362,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.99117
Policy Entropy: 2.03419
Value Function Loss: 0.01909

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.16798
Policy Update Magnitude: 0.52733
Value Function Update Magnitude: 0.66319

Collected Steps per Second: 23,578.22969
Overall Steps per Second: 10,903.75021

Timestep Collection Time: 2.12145
Timestep Consumption Time: 2.46596
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.58741

Cumulative Model Updates: 252,690
Cumulative Timesteps: 2,107,412,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2107412232...
Checkpoint 2107412232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.60459
Policy Entropy: 2.04248
Value Function Loss: 0.01894

Mean KL Divergence: 0.02894
SB3 Clip Fraction: 0.17350
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.68950

Collected Steps per Second: 22,645.56726
Overall Steps per Second: 10,790.55134

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.42672
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.63554

Cumulative Model Updates: 252,696
Cumulative Timesteps: 2,107,462,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.57993
Policy Entropy: 2.05396
Value Function Loss: 0.01901

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.16627
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.69199

Collected Steps per Second: 22,507.72268
Overall Steps per Second: 10,662.35272

Timestep Collection Time: 2.22199
Timestep Consumption Time: 2.46853
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69052

Cumulative Model Updates: 252,702
Cumulative Timesteps: 2,107,512,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2107512264...
Checkpoint 2107512264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.82855
Policy Entropy: 2.04722
Value Function Loss: 0.01889

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.68202

Collected Steps per Second: 22,469.21705
Overall Steps per Second: 10,904.90685

Timestep Collection Time: 2.22544
Timestep Consumption Time: 2.36001
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58546

Cumulative Model Updates: 252,708
Cumulative Timesteps: 2,107,562,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.12087
Policy Entropy: 2.04607
Value Function Loss: 0.01884

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.65808

Collected Steps per Second: 22,942.29052
Overall Steps per Second: 10,736.70520

Timestep Collection Time: 2.18060
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.65953

Cumulative Model Updates: 252,714
Cumulative Timesteps: 2,107,612,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2107612296...
Checkpoint 2107612296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.82402
Policy Entropy: 2.05011
Value Function Loss: 0.01737

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.53901
Value Function Update Magnitude: 0.66251

Collected Steps per Second: 23,041.26243
Overall Steps per Second: 10,788.86247

Timestep Collection Time: 2.17141
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.63737

Cumulative Model Updates: 252,720
Cumulative Timesteps: 2,107,662,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.60360
Policy Entropy: 2.05805
Value Function Loss: 0.01656

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.68143

Collected Steps per Second: 22,832.78038
Overall Steps per Second: 10,973.85215

Timestep Collection Time: 2.19053
Timestep Consumption Time: 2.36721
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.55774

Cumulative Model Updates: 252,726
Cumulative Timesteps: 2,107,712,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2107712344...
Checkpoint 2107712344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.79791
Policy Entropy: 2.05276
Value Function Loss: 0.01682

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.67566

Collected Steps per Second: 23,016.47936
Overall Steps per Second: 10,687.12336

Timestep Collection Time: 2.17331
Timestep Consumption Time: 2.50727
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.68059

Cumulative Model Updates: 252,732
Cumulative Timesteps: 2,107,762,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.87979
Policy Entropy: 2.02936
Value Function Loss: 0.01808

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.53398
Value Function Update Magnitude: 0.65596

Collected Steps per Second: 23,410.20004
Overall Steps per Second: 10,878.14621

Timestep Collection Time: 2.13599
Timestep Consumption Time: 2.46075
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.59674

Cumulative Model Updates: 252,738
Cumulative Timesteps: 2,107,812,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2107812370...
Checkpoint 2107812370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.03746
Policy Entropy: 2.01300
Value Function Loss: 0.01906

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.64854

Collected Steps per Second: 23,010.91035
Overall Steps per Second: 10,756.50686

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.64946

Cumulative Model Updates: 252,744
Cumulative Timesteps: 2,107,862,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.55210
Policy Entropy: 1.99314
Value Function Loss: 0.01917

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.54727
Value Function Update Magnitude: 0.63615

Collected Steps per Second: 22,944.72851
Overall Steps per Second: 10,864.53374

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.60471

Cumulative Model Updates: 252,750
Cumulative Timesteps: 2,107,912,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2107912410...
Checkpoint 2107912410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.28660
Policy Entropy: 2.02122
Value Function Loss: 0.01826

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.64408

Collected Steps per Second: 22,384.98121
Overall Steps per Second: 10,582.39886

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.72577

Cumulative Model Updates: 252,756
Cumulative Timesteps: 2,107,962,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.00978
Policy Entropy: 2.02806
Value Function Loss: 0.01816

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.54739
Value Function Update Magnitude: 0.66208

Collected Steps per Second: 22,746.25370
Overall Steps per Second: 10,709.37219

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.67180

Cumulative Model Updates: 252,762
Cumulative Timesteps: 2,108,012,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2108012452...
Checkpoint 2108012452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.93719
Policy Entropy: 2.02984
Value Function Loss: 0.01833

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.65668

Collected Steps per Second: 22,377.42593
Overall Steps per Second: 10,827.27539

Timestep Collection Time: 2.23556
Timestep Consumption Time: 2.38481
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62037

Cumulative Model Updates: 252,768
Cumulative Timesteps: 2,108,062,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.29189
Policy Entropy: 2.03013
Value Function Loss: 0.01750

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.61900

Collected Steps per Second: 22,564.60319
Overall Steps per Second: 10,695.00396

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.67602

Cumulative Model Updates: 252,774
Cumulative Timesteps: 2,108,112,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2108112488...
Checkpoint 2108112488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.82354
Policy Entropy: 2.00427
Value Function Loss: 0.01830

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.54171
Value Function Update Magnitude: 0.59501

Collected Steps per Second: 22,384.66525
Overall Steps per Second: 10,909.65464

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.34942
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.58310

Cumulative Model Updates: 252,780
Cumulative Timesteps: 2,108,162,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.57860
Policy Entropy: 2.00862
Value Function Loss: 0.01715

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.54215
Value Function Update Magnitude: 0.61424

Collected Steps per Second: 23,025.76109
Overall Steps per Second: 10,830.20927

Timestep Collection Time: 2.17165
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.61709

Cumulative Model Updates: 252,786
Cumulative Timesteps: 2,108,212,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2108212492...
Checkpoint 2108212492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.27437
Policy Entropy: 2.00145
Value Function Loss: 0.02018

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.65076

Collected Steps per Second: 22,828.16896
Overall Steps per Second: 10,631.22585

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.51365
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.70463

Cumulative Model Updates: 252,792
Cumulative Timesteps: 2,108,262,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.89924
Policy Entropy: 2.02553
Value Function Loss: 0.01943

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.65605

Collected Steps per Second: 23,225.57369
Overall Steps per Second: 10,936.25835

Timestep Collection Time: 2.15314
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.57268

Cumulative Model Updates: 252,798
Cumulative Timesteps: 2,108,312,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2108312516...
Checkpoint 2108312516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.89952
Policy Entropy: 2.04085
Value Function Loss: 0.02001

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.55193
Value Function Update Magnitude: 0.64123

Collected Steps per Second: 23,788.30294
Overall Steps per Second: 11,078.06799

Timestep Collection Time: 2.10238
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.51451

Cumulative Model Updates: 252,804
Cumulative Timesteps: 2,108,362,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.63434
Policy Entropy: 2.04340
Value Function Loss: 0.01842

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.54652
Value Function Update Magnitude: 0.63306

Collected Steps per Second: 23,274.92200
Overall Steps per Second: 10,925.86324

Timestep Collection Time: 2.14849
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.57685

Cumulative Model Updates: 252,810
Cumulative Timesteps: 2,108,412,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2108412534...
Checkpoint 2108412534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.63773
Policy Entropy: 2.05262
Value Function Loss: 0.01852

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.63626

Collected Steps per Second: 22,091.72273
Overall Steps per Second: 10,675.69966

Timestep Collection Time: 2.26465
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.68634

Cumulative Model Updates: 252,816
Cumulative Timesteps: 2,108,462,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.31632
Policy Entropy: 2.04443
Value Function Loss: 0.01799

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.66972

Collected Steps per Second: 22,599.97120
Overall Steps per Second: 10,840.44260

Timestep Collection Time: 2.21239
Timestep Consumption Time: 2.39997
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61236

Cumulative Model Updates: 252,822
Cumulative Timesteps: 2,108,512,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2108512564...
Checkpoint 2108512564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.09396
Policy Entropy: 2.04378
Value Function Loss: 0.01714

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.68562

Collected Steps per Second: 22,168.00560
Overall Steps per Second: 10,709.09590

Timestep Collection Time: 2.25659
Timestep Consumption Time: 2.41458
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.67117

Cumulative Model Updates: 252,828
Cumulative Timesteps: 2,108,562,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.21641
Policy Entropy: 2.03155
Value Function Loss: 0.01667

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.52408
Value Function Update Magnitude: 0.66391

Collected Steps per Second: 22,947.41577
Overall Steps per Second: 10,842.95864

Timestep Collection Time: 2.17985
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61332

Cumulative Model Updates: 252,834
Cumulative Timesteps: 2,108,612,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2108612610...
Checkpoint 2108612610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.68941
Policy Entropy: 2.02775
Value Function Loss: 0.01628

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.51036
Value Function Update Magnitude: 0.63831

Collected Steps per Second: 22,334.03933
Overall Steps per Second: 10,666.39292

Timestep Collection Time: 2.23874
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.68762

Cumulative Model Updates: 252,840
Cumulative Timesteps: 2,108,662,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.44433
Policy Entropy: 2.03186
Value Function Loss: 0.01739

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.62821

Collected Steps per Second: 23,112.45297
Overall Steps per Second: 10,926.33955

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.41353
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.57756

Cumulative Model Updates: 252,846
Cumulative Timesteps: 2,108,712,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2108712626...
Checkpoint 2108712626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.84304
Policy Entropy: 2.03831
Value Function Loss: 0.01860

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.54151
Value Function Update Magnitude: 0.63235

Collected Steps per Second: 22,882.85955
Overall Steps per Second: 10,703.28448

Timestep Collection Time: 2.18513
Timestep Consumption Time: 2.48652
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.67165

Cumulative Model Updates: 252,852
Cumulative Timesteps: 2,108,762,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.66172
Policy Entropy: 2.04912
Value Function Loss: 0.01858

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.64676

Collected Steps per Second: 23,118.62529
Overall Steps per Second: 10,847.38695

Timestep Collection Time: 2.16397
Timestep Consumption Time: 2.44802
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.61199

Cumulative Model Updates: 252,858
Cumulative Timesteps: 2,108,812,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2108812656...
Checkpoint 2108812656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.67886
Policy Entropy: 2.04982
Value Function Loss: 0.01724

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.54957
Value Function Update Magnitude: 0.67172

Collected Steps per Second: 22,887.19472
Overall Steps per Second: 10,748.36917

Timestep Collection Time: 2.18533
Timestep Consumption Time: 2.46803
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.65336

Cumulative Model Updates: 252,864
Cumulative Timesteps: 2,108,862,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.85879
Policy Entropy: 2.04414
Value Function Loss: 0.01712

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.67105

Collected Steps per Second: 23,092.04100
Overall Steps per Second: 10,956.85053

Timestep Collection Time: 2.16620
Timestep Consumption Time: 2.39916
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.56536

Cumulative Model Updates: 252,870
Cumulative Timesteps: 2,108,912,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2108912694...
Checkpoint 2108912694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.38123
Policy Entropy: 2.05543
Value Function Loss: 0.01756

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.66406

Collected Steps per Second: 22,745.21511
Overall Steps per Second: 10,746.33801

Timestep Collection Time: 2.19870
Timestep Consumption Time: 2.45497
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.65368

Cumulative Model Updates: 252,876
Cumulative Timesteps: 2,108,962,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.17592
Policy Entropy: 2.04743
Value Function Loss: 0.01843

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.54459
Value Function Update Magnitude: 0.67189

Collected Steps per Second: 22,458.70674
Overall Steps per Second: 10,686.54014

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.45385
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.68140

Cumulative Model Updates: 252,882
Cumulative Timesteps: 2,109,012,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2109012732...
Checkpoint 2109012732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.45863
Policy Entropy: 2.05027
Value Function Loss: 0.01759

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.53802
Value Function Update Magnitude: 0.65891

Collected Steps per Second: 22,587.27984
Overall Steps per Second: 10,650.24151

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.48219
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.69679

Cumulative Model Updates: 252,888
Cumulative Timesteps: 2,109,062,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.97288
Policy Entropy: 2.04033
Value Function Loss: 0.01794

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.64446

Collected Steps per Second: 22,827.11854
Overall Steps per Second: 10,878.89292

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.40568
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.59606

Cumulative Model Updates: 252,894
Cumulative Timesteps: 2,109,112,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2109112754...
Checkpoint 2109112754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.41221
Policy Entropy: 2.04025
Value Function Loss: 0.01810

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.65074

Collected Steps per Second: 23,238.99634
Overall Steps per Second: 10,771.84888

Timestep Collection Time: 2.15181
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.64229

Cumulative Model Updates: 252,900
Cumulative Timesteps: 2,109,162,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.96091
Policy Entropy: 2.05309
Value Function Loss: 0.01809

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.64385

Collected Steps per Second: 23,134.87182
Overall Steps per Second: 10,768.33280

Timestep Collection Time: 2.16150
Timestep Consumption Time: 2.48230
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.64380

Cumulative Model Updates: 252,906
Cumulative Timesteps: 2,109,212,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2109212766...
Checkpoint 2109212766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.99365
Policy Entropy: 2.06053
Value Function Loss: 0.01839

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.53852
Value Function Update Magnitude: 0.64194

Collected Steps per Second: 22,828.95606
Overall Steps per Second: 10,734.49424

Timestep Collection Time: 2.19134
Timestep Consumption Time: 2.46896
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.66030

Cumulative Model Updates: 252,912
Cumulative Timesteps: 2,109,262,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.75862
Policy Entropy: 2.05284
Value Function Loss: 0.01966

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.62621

Collected Steps per Second: 23,870.92122
Overall Steps per Second: 10,871.58881

Timestep Collection Time: 2.09552
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.60117

Cumulative Model Updates: 252,918
Cumulative Timesteps: 2,109,312,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2109312814...
Checkpoint 2109312814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.55018
Policy Entropy: 2.06145
Value Function Loss: 0.01974

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.61999

Collected Steps per Second: 22,987.00423
Overall Steps per Second: 10,795.07835

Timestep Collection Time: 2.17558
Timestep Consumption Time: 2.45709
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.63267

Cumulative Model Updates: 252,924
Cumulative Timesteps: 2,109,362,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.26492
Policy Entropy: 2.04872
Value Function Loss: 0.01923

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.53550
Value Function Update Magnitude: 0.61593

Collected Steps per Second: 23,053.10465
Overall Steps per Second: 10,671.48572

Timestep Collection Time: 2.16943
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.68651

Cumulative Model Updates: 252,930
Cumulative Timesteps: 2,109,412,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2109412836...
Checkpoint 2109412836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.11919
Policy Entropy: 2.04798
Value Function Loss: 0.01864

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.63212

Collected Steps per Second: 22,403.01893
Overall Steps per Second: 10,758.31055

Timestep Collection Time: 2.23273
Timestep Consumption Time: 2.41669
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64943

Cumulative Model Updates: 252,936
Cumulative Timesteps: 2,109,462,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.79850
Policy Entropy: 2.02850
Value Function Loss: 0.01848

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.55053
Value Function Update Magnitude: 0.65462

Collected Steps per Second: 23,084.78064
Overall Steps per Second: 10,820.03952

Timestep Collection Time: 2.16714
Timestep Consumption Time: 2.45650
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.62364

Cumulative Model Updates: 252,942
Cumulative Timesteps: 2,109,512,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2109512884...
Checkpoint 2109512884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.20784
Policy Entropy: 2.03026
Value Function Loss: 0.01938

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.66374

Collected Steps per Second: 22,639.83130
Overall Steps per Second: 10,638.05309

Timestep Collection Time: 2.20956
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.70236

Cumulative Model Updates: 252,948
Cumulative Timesteps: 2,109,562,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.47644
Policy Entropy: 2.04936
Value Function Loss: 0.01965

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.55492
Value Function Update Magnitude: 0.65932

Collected Steps per Second: 23,041.19972
Overall Steps per Second: 10,819.03799

Timestep Collection Time: 2.17063
Timestep Consumption Time: 2.45214
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62278

Cumulative Model Updates: 252,954
Cumulative Timesteps: 2,109,612,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2109612922...
Checkpoint 2109612922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.55077
Policy Entropy: 2.04981
Value Function Loss: 0.01998

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.55529
Value Function Update Magnitude: 0.64794

Collected Steps per Second: 23,054.42890
Overall Steps per Second: 10,750.87994

Timestep Collection Time: 2.17017
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.65376

Cumulative Model Updates: 252,960
Cumulative Timesteps: 2,109,662,954

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.93036
Policy Entropy: 2.05573
Value Function Loss: 0.01896

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.64879

Collected Steps per Second: 23,702.63886
Overall Steps per Second: 10,904.97154

Timestep Collection Time: 2.10972
Timestep Consumption Time: 2.47589
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.58561

Cumulative Model Updates: 252,966
Cumulative Timesteps: 2,109,712,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2109712960...
Checkpoint 2109712960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.61125
Policy Entropy: 2.06693
Value Function Loss: 0.01820

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.52644
Value Function Update Magnitude: 0.64501

Collected Steps per Second: 22,853.22584
Overall Steps per Second: 10,695.34495

Timestep Collection Time: 2.18884
Timestep Consumption Time: 2.48815
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.67699

Cumulative Model Updates: 252,972
Cumulative Timesteps: 2,109,762,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.74503
Policy Entropy: 2.04720
Value Function Loss: 0.01864

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.63249

Collected Steps per Second: 23,050.98641
Overall Steps per Second: 10,901.44251

Timestep Collection Time: 2.16928
Timestep Consumption Time: 2.41764
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.58692

Cumulative Model Updates: 252,978
Cumulative Timesteps: 2,109,812,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2109812986...
Checkpoint 2109812986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.74314
Policy Entropy: 2.04147
Value Function Loss: 0.01740

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 22,453.90114
Overall Steps per Second: 10,623.48695

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.70749

Cumulative Model Updates: 252,984
Cumulative Timesteps: 2,109,862,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.07644
Policy Entropy: 2.02112
Value Function Loss: 0.01840

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.60803

Collected Steps per Second: 22,671.22822
Overall Steps per Second: 10,911.49736

Timestep Collection Time: 2.20685
Timestep Consumption Time: 2.37841
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.58526

Cumulative Model Updates: 252,990
Cumulative Timesteps: 2,109,913,028

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2109913028...
Checkpoint 2109913028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.36458
Policy Entropy: 2.04154
Value Function Loss: 0.01757

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.61555

Collected Steps per Second: 22,600.02075
Overall Steps per Second: 10,597.14943

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.72033

Cumulative Model Updates: 252,996
Cumulative Timesteps: 2,109,963,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.22643
Policy Entropy: 2.01040
Value Function Loss: 0.01720

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.52293
Value Function Update Magnitude: 0.60064

Collected Steps per Second: 22,719.67773
Overall Steps per Second: 10,671.95498

Timestep Collection Time: 2.20091
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.68555

Cumulative Model Updates: 253,002
Cumulative Timesteps: 2,110,013,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2110013054...
Checkpoint 2110013054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.35924
Policy Entropy: 2.02465
Value Function Loss: 0.01780

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.52841
Value Function Update Magnitude: 0.59777

Collected Steps per Second: 22,447.77530
Overall Steps per Second: 10,945.71618

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.34098
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.56873

Cumulative Model Updates: 253,008
Cumulative Timesteps: 2,110,063,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.52935
Policy Entropy: 2.01974
Value Function Loss: 0.01749

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.53674
Value Function Update Magnitude: 0.62437

Collected Steps per Second: 23,399.14053
Overall Steps per Second: 10,882.31009

Timestep Collection Time: 2.13786
Timestep Consumption Time: 2.45896
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.59682

Cumulative Model Updates: 253,014
Cumulative Timesteps: 2,110,113,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2110113086...
Checkpoint 2110113086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.78716
Policy Entropy: 2.04721
Value Function Loss: 0.01770

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.53327
Value Function Update Magnitude: 0.63603

Collected Steps per Second: 23,018.63773
Overall Steps per Second: 10,764.04602

Timestep Collection Time: 2.17259
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.64602

Cumulative Model Updates: 253,020
Cumulative Timesteps: 2,110,163,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.39679
Policy Entropy: 2.03615
Value Function Loss: 0.01774

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.53561
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 23,191.04065
Overall Steps per Second: 10,746.92065

Timestep Collection Time: 2.15704
Timestep Consumption Time: 2.49769
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.65473

Cumulative Model Updates: 253,026
Cumulative Timesteps: 2,110,213,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2110213120...
Checkpoint 2110213120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.39033
Policy Entropy: 2.03793
Value Function Loss: 0.01816

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.64089

Collected Steps per Second: 22,933.88424
Overall Steps per Second: 10,727.64079

Timestep Collection Time: 2.18035
Timestep Consumption Time: 2.48088
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.66123

Cumulative Model Updates: 253,032
Cumulative Timesteps: 2,110,263,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.00264
Policy Entropy: 2.04575
Value Function Loss: 0.01831

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.63343

Collected Steps per Second: 22,999.79961
Overall Steps per Second: 10,871.57763

Timestep Collection Time: 2.17471
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.60080

Cumulative Model Updates: 253,038
Cumulative Timesteps: 2,110,313,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2110313142...
Checkpoint 2110313142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.49888
Policy Entropy: 2.05704
Value Function Loss: 0.01767

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.50982
Value Function Update Magnitude: 0.60735

Collected Steps per Second: 22,822.56311
Overall Steps per Second: 10,670.77077

Timestep Collection Time: 2.19134
Timestep Consumption Time: 2.49548
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.68682

Cumulative Model Updates: 253,044
Cumulative Timesteps: 2,110,363,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.15428
Policy Entropy: 2.03123
Value Function Loss: 0.01848

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.53154
Value Function Update Magnitude: 0.61078

Collected Steps per Second: 22,731.22693
Overall Steps per Second: 10,793.28159

Timestep Collection Time: 2.19962
Timestep Consumption Time: 2.43289
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63251

Cumulative Model Updates: 253,050
Cumulative Timesteps: 2,110,413,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2110413154...
Checkpoint 2110413154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.83940
Policy Entropy: 2.02543
Value Function Loss: 0.01828

Mean KL Divergence: 0.03050
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.51657
Value Function Update Magnitude: 0.63429

Collected Steps per Second: 22,550.50119
Overall Steps per Second: 10,676.03144

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.68376

Cumulative Model Updates: 253,056
Cumulative Timesteps: 2,110,463,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.62637
Policy Entropy: 2.03828
Value Function Loss: 0.01963

Mean KL Divergence: 0.03054
SB3 Clip Fraction: 0.17556
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.63906

Collected Steps per Second: 22,348.33474
Overall Steps per Second: 10,915.44786

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.34411
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.58213

Cumulative Model Updates: 253,062
Cumulative Timesteps: 2,110,513,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2110513174...
Checkpoint 2110513174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.67280
Policy Entropy: 2.06310
Value Function Loss: 0.01916

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.64523

Collected Steps per Second: 22,684.86215
Overall Steps per Second: 10,670.13335

Timestep Collection Time: 2.20491
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.68766

Cumulative Model Updates: 253,068
Cumulative Timesteps: 2,110,563,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.63164
Policy Entropy: 2.06282
Value Function Loss: 0.01945

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.14506
Policy Update Magnitude: 0.56670
Value Function Update Magnitude: 0.64479

Collected Steps per Second: 23,308.52549
Overall Steps per Second: 10,865.53942

Timestep Collection Time: 2.14608
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60373

Cumulative Model Updates: 253,074
Cumulative Timesteps: 2,110,613,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2110613214...
Checkpoint 2110613214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.97405
Policy Entropy: 2.07538
Value Function Loss: 0.01783

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.65371

Collected Steps per Second: 22,891.42469
Overall Steps per Second: 10,754.11570

Timestep Collection Time: 2.18545
Timestep Consumption Time: 2.46654
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.65199

Cumulative Model Updates: 253,080
Cumulative Timesteps: 2,110,663,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.30302
Policy Entropy: 2.07753
Value Function Loss: 0.01821

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.53973
Value Function Update Magnitude: 0.66662

Collected Steps per Second: 22,729.22728
Overall Steps per Second: 10,811.47838

Timestep Collection Time: 2.19999
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.62508

Cumulative Model Updates: 253,086
Cumulative Timesteps: 2,110,713,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2110713246...
Checkpoint 2110713246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.31388
Policy Entropy: 2.09801
Value Function Loss: 0.01685

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 22,986.97501
Overall Steps per Second: 10,716.59168

Timestep Collection Time: 2.17610
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.66772

Cumulative Model Updates: 253,092
Cumulative Timesteps: 2,110,763,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.68492
Policy Entropy: 2.06521
Value Function Loss: 0.01755

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.53608
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 23,492.09510
Overall Steps per Second: 10,853.27666

Timestep Collection Time: 2.12931
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.60893

Cumulative Model Updates: 253,098
Cumulative Timesteps: 2,110,813,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2110813290...
Checkpoint 2110813290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.88278
Policy Entropy: 2.04047
Value Function Loss: 0.01800

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.53326
Value Function Update Magnitude: 0.63875

Collected Steps per Second: 22,728.96839
Overall Steps per Second: 10,668.97402

Timestep Collection Time: 2.20080
Timestep Consumption Time: 2.48774
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.68855

Cumulative Model Updates: 253,104
Cumulative Timesteps: 2,110,863,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.53245
Policy Entropy: 2.01937
Value Function Loss: 0.01812

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.52919
Value Function Update Magnitude: 0.64321

Collected Steps per Second: 23,065.08525
Overall Steps per Second: 10,891.19316

Timestep Collection Time: 2.16795
Timestep Consumption Time: 2.42328
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59123

Cumulative Model Updates: 253,110
Cumulative Timesteps: 2,110,913,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2110913316...
Checkpoint 2110913316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.04506
Policy Entropy: 2.03226
Value Function Loss: 0.01812

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.63469

Collected Steps per Second: 22,736.40620
Overall Steps per Second: 10,662.31957

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.49039
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.68960

Cumulative Model Updates: 253,116
Cumulative Timesteps: 2,110,963,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.72273
Policy Entropy: 2.04275
Value Function Loss: 0.01697

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.63032

Collected Steps per Second: 22,874.72420
Overall Steps per Second: 10,822.60193

Timestep Collection Time: 2.18634
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.62107

Cumulative Model Updates: 253,122
Cumulative Timesteps: 2,111,013,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2111013330...
Checkpoint 2111013330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.06007
Policy Entropy: 2.03576
Value Function Loss: 0.01807

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.63453

Collected Steps per Second: 22,298.00331
Overall Steps per Second: 10,694.98865

Timestep Collection Time: 2.24298
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.67640

Cumulative Model Updates: 253,128
Cumulative Timesteps: 2,111,063,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.38061
Policy Entropy: 2.00698
Value Function Loss: 0.01918

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.62220

Collected Steps per Second: 23,543.29676
Overall Steps per Second: 10,882.35574

Timestep Collection Time: 2.12434
Timestep Consumption Time: 2.47154
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59588

Cumulative Model Updates: 253,134
Cumulative Timesteps: 2,111,113,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2111113358...
Checkpoint 2111113358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.22396
Policy Entropy: 2.01162
Value Function Loss: 0.01969

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.55930
Value Function Update Magnitude: 0.63474

Collected Steps per Second: 22,941.05352
Overall Steps per Second: 10,673.03894

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.68714

Cumulative Model Updates: 253,140
Cumulative Timesteps: 2,111,163,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.89684
Policy Entropy: 2.00832
Value Function Loss: 0.01829

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.55311
Value Function Update Magnitude: 0.63952

Collected Steps per Second: 23,379.50196
Overall Steps per Second: 10,945.80237

Timestep Collection Time: 2.13931
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.56942

Cumulative Model Updates: 253,146
Cumulative Timesteps: 2,111,213,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2111213400...
Checkpoint 2111213400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.93946
Policy Entropy: 2.00654
Value Function Loss: 0.01887

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.62938

Collected Steps per Second: 22,730.05361
Overall Steps per Second: 10,705.27118

Timestep Collection Time: 2.20008
Timestep Consumption Time: 2.47126
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.67134

Cumulative Model Updates: 253,152
Cumulative Timesteps: 2,111,263,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.66607
Policy Entropy: 1.99672
Value Function Loss: 0.01823

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.62511

Collected Steps per Second: 24,228.33579
Overall Steps per Second: 11,017.13806

Timestep Collection Time: 2.06436
Timestep Consumption Time: 2.47548
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.53984

Cumulative Model Updates: 253,158
Cumulative Timesteps: 2,111,313,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2111313424...
Checkpoint 2111313424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.53191
Policy Entropy: 2.01719
Value Function Loss: 0.01956

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.55049
Value Function Update Magnitude: 0.63788

Collected Steps per Second: 23,141.56429
Overall Steps per Second: 10,925.60381

Timestep Collection Time: 2.16122
Timestep Consumption Time: 2.41647
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.57769

Cumulative Model Updates: 253,164
Cumulative Timesteps: 2,111,363,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.45441
Policy Entropy: 2.02912
Value Function Loss: 0.01901

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.64380

Collected Steps per Second: 22,675.53036
Overall Steps per Second: 10,664.09896

Timestep Collection Time: 2.20608
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.69088

Cumulative Model Updates: 253,170
Cumulative Timesteps: 2,111,413,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2111413462...
Checkpoint 2111413462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.32284
Policy Entropy: 2.03912
Value Function Loss: 0.01906

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.64794

Collected Steps per Second: 22,546.19563
Overall Steps per Second: 10,907.60936

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.36714
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.58561

Cumulative Model Updates: 253,176
Cumulative Timesteps: 2,111,463,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.48407
Policy Entropy: 2.04758
Value Function Loss: 0.01780

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.16020
Policy Update Magnitude: 0.51515
Value Function Update Magnitude: 0.63493

Collected Steps per Second: 22,828.58356
Overall Steps per Second: 10,825.09406

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62019

Cumulative Model Updates: 253,182
Cumulative Timesteps: 2,111,513,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2111513494...
Checkpoint 2111513494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.31941
Policy Entropy: 2.02109
Value Function Loss: 0.01911

Mean KL Divergence: 0.03439
SB3 Clip Fraction: 0.18821
Policy Update Magnitude: 0.52188
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 21,741.90917
Overall Steps per Second: 10,593.59061

Timestep Collection Time: 2.30007
Timestep Consumption Time: 2.42052
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.72059

Cumulative Model Updates: 253,188
Cumulative Timesteps: 2,111,563,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.02934
Policy Entropy: 2.02853
Value Function Loss: 0.01832

Mean KL Divergence: 0.03281
SB3 Clip Fraction: 0.18313
Policy Update Magnitude: 0.52360
Value Function Update Magnitude: 0.61778

Collected Steps per Second: 22,544.62366
Overall Steps per Second: 10,649.56378

Timestep Collection Time: 2.21871
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.69691

Cumulative Model Updates: 253,194
Cumulative Timesteps: 2,111,613,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2111613522...
Checkpoint 2111613522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.38875
Policy Entropy: 2.01148
Value Function Loss: 0.01854

Mean KL Divergence: 0.02866
SB3 Clip Fraction: 0.16476
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 22,637.75915
Overall Steps per Second: 10,951.52332

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.35810
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.56795

Cumulative Model Updates: 253,200
Cumulative Timesteps: 2,111,663,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.99799
Policy Entropy: 2.03515
Value Function Loss: 0.01754

Mean KL Divergence: 0.02543
SB3 Clip Fraction: 0.16093
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.63599

Collected Steps per Second: 23,491.29731
Overall Steps per Second: 10,884.78153

Timestep Collection Time: 2.12913
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.59504

Cumulative Model Updates: 253,206
Cumulative Timesteps: 2,111,713,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2111713564...
Checkpoint 2111713564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.54183
Policy Entropy: 2.03256
Value Function Loss: 0.01800

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.54466
Value Function Update Magnitude: 0.61698

Collected Steps per Second: 22,631.41652
Overall Steps per Second: 10,648.75566

Timestep Collection Time: 2.21056
Timestep Consumption Time: 2.48746
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.69801

Cumulative Model Updates: 253,212
Cumulative Timesteps: 2,111,763,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.91890
Policy Entropy: 2.05043
Value Function Loss: 0.01783

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.53201
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 22,882.18583
Overall Steps per Second: 10,900.15850

Timestep Collection Time: 2.18650
Timestep Consumption Time: 2.40352
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.59003

Cumulative Model Updates: 253,218
Cumulative Timesteps: 2,111,813,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2111813624...
Checkpoint 2111813624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.20643
Policy Entropy: 2.06120
Value Function Loss: 0.01906

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.61294

Collected Steps per Second: 22,905.93819
Overall Steps per Second: 10,707.54779

Timestep Collection Time: 2.18424
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.67259

Cumulative Model Updates: 253,224
Cumulative Timesteps: 2,111,863,656

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.60703
Policy Entropy: 2.06570
Value Function Loss: 0.01873

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.55296
Value Function Update Magnitude: 0.63287

Collected Steps per Second: 22,994.00687
Overall Steps per Second: 10,946.24804

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.39444
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.56997

Cumulative Model Updates: 253,230
Cumulative Timesteps: 2,111,913,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2111913680...
Checkpoint 2111913680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.36190
Policy Entropy: 2.07101
Value Function Loss: 0.01914

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.54963
Value Function Update Magnitude: 0.65303

Collected Steps per Second: 22,916.00192
Overall Steps per Second: 10,711.20913

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.48722
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.67006

Cumulative Model Updates: 253,236
Cumulative Timesteps: 2,111,963,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.15408
Policy Entropy: 2.06534
Value Function Loss: 0.01851

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.54167
Value Function Update Magnitude: 0.65286

Collected Steps per Second: 22,708.62087
Overall Steps per Second: 10,766.74113

Timestep Collection Time: 2.20207
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.64449

Cumulative Model Updates: 253,242
Cumulative Timesteps: 2,112,013,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2112013708...
Checkpoint 2112013708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.21089
Policy Entropy: 2.06919
Value Function Loss: 0.01828

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.54211
Value Function Update Magnitude: 0.64514

Collected Steps per Second: 22,266.46744
Overall Steps per Second: 10,656.86538

Timestep Collection Time: 2.24607
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.69294

Cumulative Model Updates: 253,248
Cumulative Timesteps: 2,112,063,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.26966
Policy Entropy: 2.05754
Value Function Loss: 0.01884

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.64964

Collected Steps per Second: 22,446.02914
Overall Steps per Second: 10,917.93373

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.35224
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.57999

Cumulative Model Updates: 253,254
Cumulative Timesteps: 2,112,113,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2112113724...
Checkpoint 2112113724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.50570
Policy Entropy: 2.06442
Value Function Loss: 0.01857

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.65507

Collected Steps per Second: 23,039.83539
Overall Steps per Second: 10,684.81291

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.67973

Cumulative Model Updates: 253,260
Cumulative Timesteps: 2,112,163,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.58900
Policy Entropy: 2.07459
Value Function Loss: 0.01869

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.66620

Collected Steps per Second: 22,937.18279
Overall Steps per Second: 10,811.52044

Timestep Collection Time: 2.18083
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.62673

Cumulative Model Updates: 253,266
Cumulative Timesteps: 2,112,213,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2112213748...
Checkpoint 2112213748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.87512
Policy Entropy: 2.07173
Value Function Loss: 0.01741

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.64819

Collected Steps per Second: 22,968.78979
Overall Steps per Second: 10,699.19704

Timestep Collection Time: 2.17748
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.67456

Cumulative Model Updates: 253,272
Cumulative Timesteps: 2,112,263,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.01273
Policy Entropy: 2.07056
Value Function Loss: 0.01695

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.63772

Collected Steps per Second: 23,855.15304
Overall Steps per Second: 10,946.96526

Timestep Collection Time: 2.09598
Timestep Consumption Time: 2.47149
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.56748

Cumulative Model Updates: 253,278
Cumulative Timesteps: 2,112,313,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2112313762...
Checkpoint 2112313762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.80229
Policy Entropy: 2.05574
Value Function Loss: 0.01746

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.52801
Value Function Update Magnitude: 0.65215

Collected Steps per Second: 23,265.77746
Overall Steps per Second: 10,837.89589

Timestep Collection Time: 2.14994
Timestep Consumption Time: 2.46535
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.61529

Cumulative Model Updates: 253,284
Cumulative Timesteps: 2,112,363,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.61303
Policy Entropy: 2.05415
Value Function Loss: 0.01757

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.65084

Collected Steps per Second: 23,415.39020
Overall Steps per Second: 10,815.12086

Timestep Collection Time: 2.13586
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.62427

Cumulative Model Updates: 253,290
Cumulative Timesteps: 2,112,413,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2112413794...
Checkpoint 2112413794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.72314
Policy Entropy: 2.04224
Value Function Loss: 0.01886

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.66087

Collected Steps per Second: 22,685.47126
Overall Steps per Second: 10,734.82291

Timestep Collection Time: 2.20414
Timestep Consumption Time: 2.45378
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.65793

Cumulative Model Updates: 253,296
Cumulative Timesteps: 2,112,463,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.37468
Policy Entropy: 2.04279
Value Function Loss: 0.01762

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.67820

Collected Steps per Second: 23,681.28804
Overall Steps per Second: 10,945.09629

Timestep Collection Time: 2.11239
Timestep Consumption Time: 2.45806
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.57045

Cumulative Model Updates: 253,302
Cumulative Timesteps: 2,112,513,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2112513820...
Checkpoint 2112513820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.09548
Policy Entropy: 2.05380
Value Function Loss: 0.01702

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.52616
Value Function Update Magnitude: 0.67059

Collected Steps per Second: 22,742.86005
Overall Steps per Second: 10,794.50268

Timestep Collection Time: 2.19876
Timestep Consumption Time: 2.43379
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.63254

Cumulative Model Updates: 253,308
Cumulative Timesteps: 2,112,563,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.41227
Policy Entropy: 2.04738
Value Function Loss: 0.01748

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.52750
Value Function Update Magnitude: 0.64744

Collected Steps per Second: 23,164.58867
Overall Steps per Second: 10,623.18569

Timestep Collection Time: 2.15916
Timestep Consumption Time: 2.54903
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.70819

Cumulative Model Updates: 253,314
Cumulative Timesteps: 2,112,613,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2112613842...
Checkpoint 2112613842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.43046
Policy Entropy: 2.02614
Value Function Loss: 0.01782

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.53332
Value Function Update Magnitude: 0.65165

Collected Steps per Second: 22,841.89962
Overall Steps per Second: 10,889.02261

Timestep Collection Time: 2.19001
Timestep Consumption Time: 2.40397
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59398

Cumulative Model Updates: 253,320
Cumulative Timesteps: 2,112,663,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.24762
Policy Entropy: 2.01652
Value Function Loss: 0.01718

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.51625
Value Function Update Magnitude: 0.64497

Collected Steps per Second: 23,894.84777
Overall Steps per Second: 11,076.93905

Timestep Collection Time: 2.09359
Timestep Consumption Time: 2.42264
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.51623

Cumulative Model Updates: 253,326
Cumulative Timesteps: 2,112,713,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2112713892...
Checkpoint 2112713892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.92294
Policy Entropy: 2.01515
Value Function Loss: 0.01756

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.49836
Value Function Update Magnitude: 0.62630

Collected Steps per Second: 22,985.50879
Overall Steps per Second: 10,762.98064

Timestep Collection Time: 2.17615
Timestep Consumption Time: 2.47126
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.64741

Cumulative Model Updates: 253,332
Cumulative Timesteps: 2,112,763,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.04106
Policy Entropy: 2.02829
Value Function Loss: 0.01773

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.50046
Value Function Update Magnitude: 0.61858

Collected Steps per Second: 23,654.67075
Overall Steps per Second: 10,863.96589

Timestep Collection Time: 2.11468
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.60440

Cumulative Model Updates: 253,338
Cumulative Timesteps: 2,112,813,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2112813934...
Checkpoint 2112813934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.62883
Policy Entropy: 2.02334
Value Function Loss: 0.01922

Mean KL Divergence: 0.02547
SB3 Clip Fraction: 0.15202
Policy Update Magnitude: 0.50950
Value Function Update Magnitude: 0.62115

Collected Steps per Second: 22,930.90947
Overall Steps per Second: 10,907.60402

Timestep Collection Time: 2.18134
Timestep Consumption Time: 2.40446
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.58579

Cumulative Model Updates: 253,344
Cumulative Timesteps: 2,112,863,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.94114
Policy Entropy: 2.05183
Value Function Loss: 0.02005

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.17074
Policy Update Magnitude: 0.47886
Value Function Update Magnitude: 0.65940

Collected Steps per Second: 23,062.78063
Overall Steps per Second: 10,888.23262

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.59211

Cumulative Model Updates: 253,350
Cumulative Timesteps: 2,112,913,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2112913954...
Checkpoint 2112913954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.97297
Policy Entropy: 2.06559
Value Function Loss: 0.02076

Mean KL Divergence: 0.02645
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.52061
Value Function Update Magnitude: 0.67720

Collected Steps per Second: 22,232.98354
Overall Steps per Second: 10,743.33976

Timestep Collection Time: 2.24900
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.65423

Cumulative Model Updates: 253,356
Cumulative Timesteps: 2,112,963,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.81064
Policy Entropy: 2.04231
Value Function Loss: 0.02086

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.56379
Value Function Update Magnitude: 0.67339

Collected Steps per Second: 22,917.47208
Overall Steps per Second: 10,824.72596

Timestep Collection Time: 2.18261
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62090

Cumulative Model Updates: 253,362
Cumulative Timesteps: 2,113,013,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2113013976...
Checkpoint 2113013976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.66665
Policy Entropy: 2.04157
Value Function Loss: 0.01911

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.66417

Collected Steps per Second: 22,222.51156
Overall Steps per Second: 10,734.95410

Timestep Collection Time: 2.25033
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.65843

Cumulative Model Updates: 253,368
Cumulative Timesteps: 2,113,063,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.11593
Policy Entropy: 2.02458
Value Function Loss: 0.01915

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.65291

Collected Steps per Second: 22,893.15300
Overall Steps per Second: 10,847.73785

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.42529
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.60944

Cumulative Model Updates: 253,374
Cumulative Timesteps: 2,113,113,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2113113986...
Checkpoint 2113113986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.43652
Policy Entropy: 2.05447
Value Function Loss: 0.01906

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.55060
Value Function Update Magnitude: 0.63686

Collected Steps per Second: 22,930.38573
Overall Steps per Second: 10,622.97679

Timestep Collection Time: 2.18086
Timestep Consumption Time: 2.52667
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.70753

Cumulative Model Updates: 253,380
Cumulative Timesteps: 2,113,163,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.35882
Policy Entropy: 2.04808
Value Function Loss: 0.01880

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.62285

Collected Steps per Second: 23,118.23334
Overall Steps per Second: 10,868.15250

Timestep Collection Time: 2.16409
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60336

Cumulative Model Updates: 253,386
Cumulative Timesteps: 2,113,214,024

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2113214024...
Checkpoint 2113214024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.38381
Policy Entropy: 2.04689
Value Function Loss: 0.01837

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.53992
Value Function Update Magnitude: 0.61568

Collected Steps per Second: 23,055.71994
Overall Steps per Second: 11,069.97138

Timestep Collection Time: 2.16953
Timestep Consumption Time: 2.34900
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.51853

Cumulative Model Updates: 253,392
Cumulative Timesteps: 2,113,264,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.97901
Policy Entropy: 2.04083
Value Function Loss: 0.01805

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.53316
Value Function Update Magnitude: 0.61707

Collected Steps per Second: 23,072.76818
Overall Steps per Second: 10,928.66103

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.40826
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.57549

Cumulative Model Updates: 253,398
Cumulative Timesteps: 2,113,314,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2113314048...
Checkpoint 2113314048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.15578
Policy Entropy: 2.01615
Value Function Loss: 0.01912

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.52373
Value Function Update Magnitude: 0.60973

Collected Steps per Second: 23,107.43052
Overall Steps per Second: 10,733.47010

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.49502
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.65926

Cumulative Model Updates: 253,404
Cumulative Timesteps: 2,113,364,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.15453
Policy Entropy: 2.01873
Value Function Loss: 0.01870

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.14708
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.59954

Collected Steps per Second: 22,660.92984
Overall Steps per Second: 10,804.27444

Timestep Collection Time: 2.20768
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.63039

Cumulative Model Updates: 253,410
Cumulative Timesteps: 2,113,414,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2113414086...
Checkpoint 2113414086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.66255
Policy Entropy: 2.01621
Value Function Loss: 0.01948

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.53500
Value Function Update Magnitude: 0.61807

Collected Steps per Second: 22,585.10769
Overall Steps per Second: 10,710.31219

Timestep Collection Time: 2.21385
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.66840

Cumulative Model Updates: 253,416
Cumulative Timesteps: 2,113,464,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.45653
Policy Entropy: 2.02189
Value Function Loss: 0.01835

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.64661

Collected Steps per Second: 23,258.15760
Overall Steps per Second: 10,923.92219

Timestep Collection Time: 2.15030
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.57821

Cumulative Model Updates: 253,422
Cumulative Timesteps: 2,113,514,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2113514098...
Checkpoint 2113514098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.64295
Policy Entropy: 2.02385
Value Function Loss: 0.01820

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.63879

Collected Steps per Second: 22,340.55767
Overall Steps per Second: 10,635.60819

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.70119

Cumulative Model Updates: 253,428
Cumulative Timesteps: 2,113,564,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.68709
Policy Entropy: 2.04772
Value Function Loss: 0.01753

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.61911

Collected Steps per Second: 22,919.74118
Overall Steps per Second: 10,824.84211

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.43875
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62141

Cumulative Model Updates: 253,434
Cumulative Timesteps: 2,113,614,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2113614124...
Checkpoint 2113614124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.12133
Policy Entropy: 2.06030
Value Function Loss: 0.01837

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.62176

Collected Steps per Second: 22,847.54899
Overall Steps per Second: 10,660.01381

Timestep Collection Time: 2.18973
Timestep Consumption Time: 2.50351
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.69324

Cumulative Model Updates: 253,440
Cumulative Timesteps: 2,113,664,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.12223
Policy Entropy: 2.06542
Value Function Loss: 0.01958

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.54213
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 23,537.49814
Overall Steps per Second: 11,027.69697

Timestep Collection Time: 2.12529
Timestep Consumption Time: 2.41093
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.53621

Cumulative Model Updates: 253,446
Cumulative Timesteps: 2,113,714,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2113714178...
Checkpoint 2113714178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.20822
Policy Entropy: 2.05063
Value Function Loss: 0.01995

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.61339

Collected Steps per Second: 22,803.71716
Overall Steps per Second: 10,689.86962

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.48500
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.67789

Cumulative Model Updates: 253,452
Cumulative Timesteps: 2,113,764,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.11687
Policy Entropy: 2.04919
Value Function Loss: 0.01902

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.60123

Collected Steps per Second: 22,942.10156
Overall Steps per Second: 10,833.61585

Timestep Collection Time: 2.17975
Timestep Consumption Time: 2.43625
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.61600

Cumulative Model Updates: 253,458
Cumulative Timesteps: 2,113,814,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2113814192...
Checkpoint 2113814192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.23525
Policy Entropy: 2.03769
Value Function Loss: 0.01819

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.58377

Collected Steps per Second: 22,945.54024
Overall Steps per Second: 11,030.28679

Timestep Collection Time: 2.17951
Timestep Consumption Time: 2.35437
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.53388

Cumulative Model Updates: 253,464
Cumulative Timesteps: 2,113,864,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.70302
Policy Entropy: 2.03161
Value Function Loss: 0.01861

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12250
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 22,503.13232
Overall Steps per Second: 10,572.09832

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.50752
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.72943

Cumulative Model Updates: 253,470
Cumulative Timesteps: 2,113,914,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2113914202...
Checkpoint 2113914202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.89938
Policy Entropy: 2.02156
Value Function Loss: 0.01908

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.52219
Value Function Update Magnitude: 0.59072

Collected Steps per Second: 22,616.95123
Overall Steps per Second: 10,630.54213

Timestep Collection Time: 2.21100
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.70399

Cumulative Model Updates: 253,476
Cumulative Timesteps: 2,113,964,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.57636
Policy Entropy: 2.05069
Value Function Loss: 0.01839

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.14699
Policy Update Magnitude: 0.51628
Value Function Update Magnitude: 0.59859

Collected Steps per Second: 22,647.33161
Overall Steps per Second: 10,865.37913

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.39477
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.60324

Cumulative Model Updates: 253,482
Cumulative Timesteps: 2,114,014,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2114014224...
Checkpoint 2114014224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.35309
Policy Entropy: 2.06142
Value Function Loss: 0.01763

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.51862
Value Function Update Magnitude: 0.61871

Collected Steps per Second: 22,251.86983
Overall Steps per Second: 10,567.82937

Timestep Collection Time: 2.24736
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.73210

Cumulative Model Updates: 253,488
Cumulative Timesteps: 2,114,064,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.47636
Policy Entropy: 2.07102
Value Function Loss: 0.01698

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.52397
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 22,693.21261
Overall Steps per Second: 10,989.39790

Timestep Collection Time: 2.20339
Timestep Consumption Time: 2.34663
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.55002

Cumulative Model Updates: 253,494
Cumulative Timesteps: 2,114,114,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2114114234...
Checkpoint 2114114234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.25788
Policy Entropy: 2.05259
Value Function Loss: 0.01695

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.63434

Collected Steps per Second: 22,889.39645
Overall Steps per Second: 10,715.86677

Timestep Collection Time: 2.18547
Timestep Consumption Time: 2.48275
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.66822

Cumulative Model Updates: 253,500
Cumulative Timesteps: 2,114,164,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.37732
Policy Entropy: 2.08058
Value Function Loss: 0.01715

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.52796
Value Function Update Magnitude: 0.64157

Collected Steps per Second: 23,329.95656
Overall Steps per Second: 10,779.25103

Timestep Collection Time: 2.14317
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.63854

Cumulative Model Updates: 253,506
Cumulative Timesteps: 2,114,214,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2114214258...
Checkpoint 2114214258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.10575
Policy Entropy: 2.09006
Value Function Loss: 0.01819

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.66326

Collected Steps per Second: 22,649.49778
Overall Steps per Second: 10,656.94473

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.69459

Cumulative Model Updates: 253,512
Cumulative Timesteps: 2,114,264,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.23036
Policy Entropy: 2.08877
Value Function Loss: 0.01880

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.66230

Collected Steps per Second: 23,820.28772
Overall Steps per Second: 10,896.38308

Timestep Collection Time: 2.09939
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.58941

Cumulative Model Updates: 253,518
Cumulative Timesteps: 2,114,314,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2114314296...
Checkpoint 2114314296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.38635
Policy Entropy: 2.08712
Value Function Loss: 0.01874

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.53059
Value Function Update Magnitude: 0.64477

Collected Steps per Second: 22,881.41195
Overall Steps per Second: 10,683.53134

Timestep Collection Time: 2.18597
Timestep Consumption Time: 2.49582
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.68179

Cumulative Model Updates: 253,524
Cumulative Timesteps: 2,114,364,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.94731
Policy Entropy: 2.07611
Value Function Loss: 0.01825

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.52707
Value Function Update Magnitude: 0.62915

Collected Steps per Second: 22,927.65073
Overall Steps per Second: 10,845.81400

Timestep Collection Time: 2.18295
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61468

Cumulative Model Updates: 253,530
Cumulative Timesteps: 2,114,414,364

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2114414364...
Checkpoint 2114414364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.52184
Policy Entropy: 2.08458
Value Function Loss: 0.01849

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.53371
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 22,583.81139
Overall Steps per Second: 10,853.83267

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.39403
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.60925

Cumulative Model Updates: 253,536
Cumulative Timesteps: 2,114,464,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.92168
Policy Entropy: 2.07972
Value Function Loss: 0.01783

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.63077

Collected Steps per Second: 22,845.32250
Overall Steps per Second: 10,739.56895

Timestep Collection Time: 2.19012
Timestep Consumption Time: 2.46873
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.65885

Cumulative Model Updates: 253,542
Cumulative Timesteps: 2,114,514,426

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2114514426...
Checkpoint 2114514426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.09959
Policy Entropy: 2.09237
Value Function Loss: 0.01695

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.51999
Value Function Update Magnitude: 0.61969

Collected Steps per Second: 22,475.03591
Overall Steps per Second: 10,638.23767

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.70078

Cumulative Model Updates: 253,548
Cumulative Timesteps: 2,114,564,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.33386
Policy Entropy: 2.09141
Value Function Loss: 0.01716

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.61952

Collected Steps per Second: 22,888.11105
Overall Steps per Second: 10,878.64664

Timestep Collection Time: 2.18576
Timestep Consumption Time: 2.41297
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.59873

Cumulative Model Updates: 253,554
Cumulative Timesteps: 2,114,614,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2114614462...
Checkpoint 2114614462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.85082
Policy Entropy: 2.06195
Value Function Loss: 0.01846

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.51838
Value Function Update Magnitude: 0.62953

Collected Steps per Second: 22,968.80429
Overall Steps per Second: 10,889.41500

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.59308

Cumulative Model Updates: 253,560
Cumulative Timesteps: 2,114,664,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.27536
Policy Entropy: 2.06426
Value Function Loss: 0.01864

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.15832
Policy Update Magnitude: 0.49027
Value Function Update Magnitude: 0.62502

Collected Steps per Second: 22,989.21061
Overall Steps per Second: 10,709.43072

Timestep Collection Time: 2.17537
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.66972

Cumulative Model Updates: 253,566
Cumulative Timesteps: 2,114,714,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2114714488...
Checkpoint 2114714488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.96909
Policy Entropy: 2.07194
Value Function Loss: 0.01907

Mean KL Divergence: 0.02753
SB3 Clip Fraction: 0.16854
Policy Update Magnitude: 0.47175
Value Function Update Magnitude: 0.62387

Collected Steps per Second: 22,959.48085
Overall Steps per Second: 10,731.75862

Timestep Collection Time: 2.17784
Timestep Consumption Time: 2.48142
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.65926

Cumulative Model Updates: 253,572
Cumulative Timesteps: 2,114,764,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.86256
Policy Entropy: 2.09632
Value Function Loss: 0.01926

Mean KL Divergence: 0.03090
SB3 Clip Fraction: 0.18005
Policy Update Magnitude: 0.47422
Value Function Update Magnitude: 0.64299

Collected Steps per Second: 23,168.66099
Overall Steps per Second: 10,764.59520

Timestep Collection Time: 2.15809
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.64486

Cumulative Model Updates: 253,578
Cumulative Timesteps: 2,114,814,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2114814490...
Checkpoint 2114814490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.60358
Policy Entropy: 2.10589
Value Function Loss: 0.01874

Mean KL Divergence: 0.02855
SB3 Clip Fraction: 0.17483
Policy Update Magnitude: 0.49751
Value Function Update Magnitude: 0.66763

Collected Steps per Second: 22,794.17934
Overall Steps per Second: 11,008.48940

Timestep Collection Time: 2.19407
Timestep Consumption Time: 2.34897
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.54304

Cumulative Model Updates: 253,584
Cumulative Timesteps: 2,114,864,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.21406
Policy Entropy: 2.11142
Value Function Loss: 0.01845

Mean KL Divergence: 0.02882
SB3 Clip Fraction: 0.17735
Policy Update Magnitude: 0.51824
Value Function Update Magnitude: 0.65360

Collected Steps per Second: 22,769.49276
Overall Steps per Second: 10,682.20940

Timestep Collection Time: 2.19645
Timestep Consumption Time: 2.48536
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.68180

Cumulative Model Updates: 253,590
Cumulative Timesteps: 2,114,914,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2114914514...
Checkpoint 2114914514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.00721
Policy Entropy: 2.11761
Value Function Loss: 0.01743

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.16311
Policy Update Magnitude: 0.52173
Value Function Update Magnitude: 0.62717

Collected Steps per Second: 20,568.99010
Overall Steps per Second: 9,995.73062

Timestep Collection Time: 2.43084
Timestep Consumption Time: 2.57129
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 5.00214

Cumulative Model Updates: 253,596
Cumulative Timesteps: 2,114,964,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.90531
Policy Entropy: 2.11818
Value Function Loss: 0.01820

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.52021
Value Function Update Magnitude: 0.62026

Collected Steps per Second: 21,648.92798
Overall Steps per Second: 10,529.12772

Timestep Collection Time: 2.31005
Timestep Consumption Time: 2.43964
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.74968

Cumulative Model Updates: 253,602
Cumulative Timesteps: 2,115,014,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2115014524...
Checkpoint 2115014524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.08482
Policy Entropy: 2.10560
Value Function Loss: 0.01747

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.51148
Value Function Update Magnitude: 0.62886

Collected Steps per Second: 22,549.22835
Overall Steps per Second: 10,649.18614

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.47931
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.69801

Cumulative Model Updates: 253,608
Cumulative Timesteps: 2,115,064,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.80765
Policy Entropy: 2.10452
Value Function Loss: 0.01760

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.51507
Value Function Update Magnitude: 0.62029

Collected Steps per Second: 22,458.44393
Overall Steps per Second: 10,920.38297

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.35311
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.58024

Cumulative Model Updates: 253,614
Cumulative Timesteps: 2,115,114,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2115114572...
Checkpoint 2115114572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.34841
Policy Entropy: 2.11202
Value Function Loss: 0.01895

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.61474

Collected Steps per Second: 22,910.35116
Overall Steps per Second: 10,639.54524

Timestep Collection Time: 2.18312
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.70095

Cumulative Model Updates: 253,620
Cumulative Timesteps: 2,115,164,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.95550
Policy Entropy: 2.11455
Value Function Loss: 0.01891

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.53324
Value Function Update Magnitude: 0.61585

Collected Steps per Second: 22,876.48096
Overall Steps per Second: 10,641.83679

Timestep Collection Time: 2.18583
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.69881

Cumulative Model Updates: 253,626
Cumulative Timesteps: 2,115,214,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2115214592...
Checkpoint 2115214592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.91227
Policy Entropy: 2.11371
Value Function Loss: 0.01843

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.53253
Value Function Update Magnitude: 0.61769

Collected Steps per Second: 22,690.61832
Overall Steps per Second: 10,797.59983

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.63251

Cumulative Model Updates: 253,632
Cumulative Timesteps: 2,115,264,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.02573
Policy Entropy: 2.11627
Value Function Loss: 0.01746

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.52391
Value Function Update Magnitude: 0.60123

Collected Steps per Second: 22,894.97029
Overall Steps per Second: 11,059.90090

Timestep Collection Time: 2.18424
Timestep Consumption Time: 2.33732
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.52156

Cumulative Model Updates: 253,638
Cumulative Timesteps: 2,115,314,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2115314620...
Checkpoint 2115314620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.26288
Policy Entropy: 2.11014
Value Function Loss: 0.01833

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.58963

Collected Steps per Second: 22,753.86955
Overall Steps per Second: 10,682.27051

Timestep Collection Time: 2.19857
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.68309

Cumulative Model Updates: 253,644
Cumulative Timesteps: 2,115,364,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.57791
Policy Entropy: 2.09465
Value Function Loss: 0.01862

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.59947

Collected Steps per Second: 21,864.97432
Overall Steps per Second: 10,381.70591

Timestep Collection Time: 2.28722
Timestep Consumption Time: 2.52991
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.81713

Cumulative Model Updates: 253,650
Cumulative Timesteps: 2,115,414,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2115414656...
Checkpoint 2115414656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.96031
Policy Entropy: 2.07875
Value Function Loss: 0.01899

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.52349
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 22,618.16526
Overall Steps per Second: 10,609.02157

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.50256
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.71335

Cumulative Model Updates: 253,656
Cumulative Timesteps: 2,115,464,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.42128
Policy Entropy: 2.10322
Value Function Loss: 0.01754

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.52372
Value Function Update Magnitude: 0.59497

Collected Steps per Second: 23,029.48002
Overall Steps per Second: 10,960.66786

Timestep Collection Time: 2.17148
Timestep Consumption Time: 2.39102
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.56250

Cumulative Model Updates: 253,662
Cumulative Timesteps: 2,115,514,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2115514668...
Checkpoint 2115514668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.00241
Policy Entropy: 2.09745
Value Function Loss: 0.01789

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.61485

Collected Steps per Second: 22,586.46865
Overall Steps per Second: 10,617.13059

Timestep Collection Time: 2.21389
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.70975

Cumulative Model Updates: 253,668
Cumulative Timesteps: 2,115,564,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.81971
Policy Entropy: 2.09054
Value Function Loss: 0.01808

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 22,831.52545
Overall Steps per Second: 10,833.53314

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.61696

Cumulative Model Updates: 253,674
Cumulative Timesteps: 2,115,614,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2115614690...
Checkpoint 2115614690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.97898
Policy Entropy: 2.08065
Value Function Loss: 0.01806

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.53731
Value Function Update Magnitude: 0.61893

Collected Steps per Second: 22,115.23082
Overall Steps per Second: 10,733.53445

Timestep Collection Time: 2.26143
Timestep Consumption Time: 2.39799
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.65942

Cumulative Model Updates: 253,680
Cumulative Timesteps: 2,115,664,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.38106
Policy Entropy: 2.10091
Value Function Loss: 0.01775

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.52650
Value Function Update Magnitude: 0.60133

Collected Steps per Second: 22,873.04877
Overall Steps per Second: 10,908.19999

Timestep Collection Time: 2.18729
Timestep Consumption Time: 2.39917
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.58646

Cumulative Model Updates: 253,686
Cumulative Timesteps: 2,115,714,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2115714732...
Checkpoint 2115714732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.65138
Policy Entropy: 2.11463
Value Function Loss: 0.01768

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.51751
Value Function Update Magnitude: 0.57675

Collected Steps per Second: 23,051.41080
Overall Steps per Second: 10,648.27466

Timestep Collection Time: 2.16985
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.69729

Cumulative Model Updates: 253,692
Cumulative Timesteps: 2,115,764,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.86081
Policy Entropy: 2.12063
Value Function Loss: 0.01804

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.52568
Value Function Update Magnitude: 0.57645

Collected Steps per Second: 23,307.44327
Overall Steps per Second: 10,851.30991

Timestep Collection Time: 2.14575
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.60884

Cumulative Model Updates: 253,698
Cumulative Timesteps: 2,115,814,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2115814762...
Checkpoint 2115814762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.74605
Policy Entropy: 2.11114
Value Function Loss: 0.01842

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.60374

Collected Steps per Second: 22,723.60197
Overall Steps per Second: 10,669.78322

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.68894

Cumulative Model Updates: 253,704
Cumulative Timesteps: 2,115,864,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.67157
Policy Entropy: 2.10559
Value Function Loss: 0.01887

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.53862
Value Function Update Magnitude: 0.61471

Collected Steps per Second: 22,869.05109
Overall Steps per Second: 10,957.20258

Timestep Collection Time: 2.18759
Timestep Consumption Time: 2.37818
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.56576

Cumulative Model Updates: 253,710
Cumulative Timesteps: 2,115,914,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2115914820...
Checkpoint 2115914820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.63557
Policy Entropy: 2.09297
Value Function Loss: 0.01981

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.60866

Collected Steps per Second: 23,254.44633
Overall Steps per Second: 10,815.54652

Timestep Collection Time: 2.15107
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.62501

Cumulative Model Updates: 253,716
Cumulative Timesteps: 2,115,964,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.89917
Policy Entropy: 2.10636
Value Function Loss: 0.01956

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.62011

Collected Steps per Second: 23,260.06962
Overall Steps per Second: 10,733.62077

Timestep Collection Time: 2.15090
Timestep Consumption Time: 2.51016
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.66106

Cumulative Model Updates: 253,722
Cumulative Timesteps: 2,116,014,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2116014872...
Checkpoint 2116014872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.43637
Policy Entropy: 2.12376
Value Function Loss: 0.01820

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.63018

Collected Steps per Second: 22,263.85580
Overall Steps per Second: 10,621.11165

Timestep Collection Time: 2.24669
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.70949

Cumulative Model Updates: 253,728
Cumulative Timesteps: 2,116,064,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.69227
Policy Entropy: 2.13201
Value Function Loss: 0.01823

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.61219

Collected Steps per Second: 22,544.67739
Overall Steps per Second: 10,984.21153

Timestep Collection Time: 2.21862
Timestep Consumption Time: 2.33501
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.55363

Cumulative Model Updates: 253,734
Cumulative Timesteps: 2,116,114,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2116114910...
Checkpoint 2116114910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.74207
Policy Entropy: 2.10763
Value Function Loss: 0.01923

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.54318
Value Function Update Magnitude: 0.62196

Collected Steps per Second: 22,400.11698
Overall Steps per Second: 10,562.32464

Timestep Collection Time: 2.23213
Timestep Consumption Time: 2.50168
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73381

Cumulative Model Updates: 253,740
Cumulative Timesteps: 2,116,164,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.06248
Policy Entropy: 2.10137
Value Function Loss: 0.01789

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.64397

Collected Steps per Second: 22,891.84261
Overall Steps per Second: 10,851.00519

Timestep Collection Time: 2.18515
Timestep Consumption Time: 2.42475
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.60990

Cumulative Model Updates: 253,746
Cumulative Timesteps: 2,116,214,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2116214932...
Checkpoint 2116214932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.80193
Policy Entropy: 2.10723
Value Function Loss: 0.01796

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.64899

Collected Steps per Second: 22,732.02642
Overall Steps per Second: 10,741.03086

Timestep Collection Time: 2.20068
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.65747

Cumulative Model Updates: 253,752
Cumulative Timesteps: 2,116,264,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.15363
Policy Entropy: 2.11732
Value Function Loss: 0.01635

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.52440
Value Function Update Magnitude: 0.62117

Collected Steps per Second: 23,062.20454
Overall Steps per Second: 10,888.54670

Timestep Collection Time: 2.16822
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.59235

Cumulative Model Updates: 253,758
Cumulative Timesteps: 2,116,314,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2116314962...
Checkpoint 2116314962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.80028
Policy Entropy: 2.10162
Value Function Loss: 0.01778

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.52581
Value Function Update Magnitude: 0.59818

Collected Steps per Second: 22,971.46002
Overall Steps per Second: 10,718.39988

Timestep Collection Time: 2.17670
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.66506

Cumulative Model Updates: 253,764
Cumulative Timesteps: 2,116,364,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.06099
Policy Entropy: 2.09685
Value Function Loss: 0.01689

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.52489
Value Function Update Magnitude: 0.58715

Collected Steps per Second: 23,316.87269
Overall Steps per Second: 10,814.88175

Timestep Collection Time: 2.14506
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.62474

Cumulative Model Updates: 253,770
Cumulative Timesteps: 2,116,414,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2116414980...
Checkpoint 2116414980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.96530
Policy Entropy: 2.06696
Value Function Loss: 0.01786

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.53721
Value Function Update Magnitude: 0.58903

Collected Steps per Second: 23,019.58690
Overall Steps per Second: 11,057.32131

Timestep Collection Time: 2.17258
Timestep Consumption Time: 2.35039
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.52298

Cumulative Model Updates: 253,776
Cumulative Timesteps: 2,116,464,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.23478
Policy Entropy: 2.06563
Value Function Loss: 0.01794

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.53531
Value Function Update Magnitude: 0.60372

Collected Steps per Second: 23,016.83763
Overall Steps per Second: 10,884.80038

Timestep Collection Time: 2.17293
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.59485

Cumulative Model Updates: 253,782
Cumulative Timesteps: 2,116,515,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2116515006...
Checkpoint 2116515006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.40825
Policy Entropy: 2.08543
Value Function Loss: 0.01759

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.52461
Value Function Update Magnitude: 0.61347

Collected Steps per Second: 22,196.00216
Overall Steps per Second: 10,694.42214

Timestep Collection Time: 2.25383
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.67777

Cumulative Model Updates: 253,788
Cumulative Timesteps: 2,116,565,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.66526
Policy Entropy: 2.10495
Value Function Loss: 0.01713

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.52373
Value Function Update Magnitude: 0.60700

Collected Steps per Second: 22,819.34661
Overall Steps per Second: 10,873.26325

Timestep Collection Time: 2.19130
Timestep Consumption Time: 2.40750
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.59880

Cumulative Model Updates: 253,794
Cumulative Timesteps: 2,116,615,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2116615036...
Checkpoint 2116615036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.47738
Policy Entropy: 2.11884
Value Function Loss: 0.01794

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.52096
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,516.19744
Overall Steps per Second: 10,673.74819

Timestep Collection Time: 2.22196
Timestep Consumption Time: 2.46524
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.68720

Cumulative Model Updates: 253,800
Cumulative Timesteps: 2,116,665,066

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.82744
Policy Entropy: 2.08927
Value Function Loss: 0.01910

Mean KL Divergence: 0.02907
SB3 Clip Fraction: 0.17204
Policy Update Magnitude: 0.49884
Value Function Update Magnitude: 0.60555

Collected Steps per Second: 23,416.81061
Overall Steps per Second: 10,932.39833

Timestep Collection Time: 2.13530
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.57374

Cumulative Model Updates: 253,806
Cumulative Timesteps: 2,116,715,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2116715068...
Checkpoint 2116715068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.28975
Policy Entropy: 2.08609
Value Function Loss: 0.01883

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.15504
Policy Update Magnitude: 0.51108
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 22,919.19184
Overall Steps per Second: 10,630.00257

Timestep Collection Time: 2.18228
Timestep Consumption Time: 2.52290
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.70517

Cumulative Model Updates: 253,812
Cumulative Timesteps: 2,116,765,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.32799
Policy Entropy: 2.08512
Value Function Loss: 0.01820

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.52536
Value Function Update Magnitude: 0.59318

Collected Steps per Second: 23,135.56698
Overall Steps per Second: 10,855.70541

Timestep Collection Time: 2.16152
Timestep Consumption Time: 2.44509
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60661

Cumulative Model Updates: 253,818
Cumulative Timesteps: 2,116,815,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2116815092...
Checkpoint 2116815092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.34440
Policy Entropy: 2.10385
Value Function Loss: 0.01767

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.52840
Value Function Update Magnitude: 0.58510

Collected Steps per Second: 22,661.23212
Overall Steps per Second: 10,675.73710

Timestep Collection Time: 2.20694
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.68464

Cumulative Model Updates: 253,824
Cumulative Timesteps: 2,116,865,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.56497
Policy Entropy: 2.08847
Value Function Loss: 0.01863

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.59563

Collected Steps per Second: 22,913.57474
Overall Steps per Second: 10,944.98567

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.38676
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.56940

Cumulative Model Updates: 253,830
Cumulative Timesteps: 2,116,915,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2116915116...
Checkpoint 2116915116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.67062
Policy Entropy: 2.10615
Value Function Loss: 0.01798

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.52788
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 22,802.70527
Overall Steps per Second: 10,672.70149

Timestep Collection Time: 2.19386
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.68729

Cumulative Model Updates: 253,836
Cumulative Timesteps: 2,116,965,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.96555
Policy Entropy: 2.09972
Value Function Loss: 0.01879

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.52548
Value Function Update Magnitude: 0.63262

Collected Steps per Second: 23,261.35357
Overall Steps per Second: 10,836.25525

Timestep Collection Time: 2.15026
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.61580

Cumulative Model Updates: 253,842
Cumulative Timesteps: 2,117,015,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2117015160...
Checkpoint 2117015160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.09439
Policy Entropy: 2.10300
Value Function Loss: 0.01830

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.52890
Value Function Update Magnitude: 0.62004

Collected Steps per Second: 22,627.72547
Overall Steps per Second: 10,659.44701

Timestep Collection Time: 2.21083
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.69311

Cumulative Model Updates: 253,848
Cumulative Timesteps: 2,117,065,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.29005
Policy Entropy: 2.09877
Value Function Loss: 0.01753

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.52110
Value Function Update Magnitude: 0.60313

Collected Steps per Second: 22,686.05051
Overall Steps per Second: 10,948.38180

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.36421
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.56944

Cumulative Model Updates: 253,854
Cumulative Timesteps: 2,117,115,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2117115214...
Checkpoint 2117115214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.78302
Policy Entropy: 2.09608
Value Function Loss: 0.01791

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.51545
Value Function Update Magnitude: 0.58206

Collected Steps per Second: 22,294.80873
Overall Steps per Second: 10,631.27172

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.46122
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.70461

Cumulative Model Updates: 253,860
Cumulative Timesteps: 2,117,165,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.89818
Policy Entropy: 2.09702
Value Function Loss: 0.01795

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.52036
Value Function Update Magnitude: 0.57778

Collected Steps per Second: 22,830.46451
Overall Steps per Second: 10,816.57601

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62383

Cumulative Model Updates: 253,866
Cumulative Timesteps: 2,117,215,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2117215244...
Checkpoint 2117215244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.21981
Policy Entropy: 2.08164
Value Function Loss: 0.01946

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.60637

Collected Steps per Second: 22,650.34788
Overall Steps per Second: 10,709.89893

Timestep Collection Time: 2.20862
Timestep Consumption Time: 2.46239
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.67101

Cumulative Model Updates: 253,872
Cumulative Timesteps: 2,117,265,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.80022
Policy Entropy: 2.07733
Value Function Loss: 0.01852

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.54052
Value Function Update Magnitude: 0.62885

Collected Steps per Second: 22,937.07566
Overall Steps per Second: 10,947.27385

Timestep Collection Time: 2.18057
Timestep Consumption Time: 2.38823
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.56881

Cumulative Model Updates: 253,878
Cumulative Timesteps: 2,117,315,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2117315286...
Checkpoint 2117315286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.58129
Policy Entropy: 2.08407
Value Function Loss: 0.01820

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.64552

Collected Steps per Second: 22,232.27019
Overall Steps per Second: 10,622.61141

Timestep Collection Time: 2.24943
Timestep Consumption Time: 2.45845
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.70788

Cumulative Model Updates: 253,884
Cumulative Timesteps: 2,117,365,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.06961
Policy Entropy: 2.09901
Value Function Loss: 0.01738

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.64258

Collected Steps per Second: 23,088.03987
Overall Steps per Second: 10,866.34575

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.43720
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.60412

Cumulative Model Updates: 253,890
Cumulative Timesteps: 2,117,415,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2117415326...
Checkpoint 2117415326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.29426
Policy Entropy: 2.11443
Value Function Loss: 0.01801

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.54419
Value Function Update Magnitude: 0.62858

Collected Steps per Second: 22,273.05423
Overall Steps per Second: 10,665.45557

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.44327
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.68822

Cumulative Model Updates: 253,896
Cumulative Timesteps: 2,117,465,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.44880
Policy Entropy: 2.11212
Value Function Loss: 0.01810

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 23,273.35358
Overall Steps per Second: 10,925.68236

Timestep Collection Time: 2.14915
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.57802

Cumulative Model Updates: 253,902
Cumulative Timesteps: 2,117,515,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2117515346...
Checkpoint 2117515346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.73198
Policy Entropy: 2.12232
Value Function Loss: 0.01849

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.53921
Value Function Update Magnitude: 0.63010

Collected Steps per Second: 22,630.52113
Overall Steps per Second: 10,631.14516

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70391

Cumulative Model Updates: 253,908
Cumulative Timesteps: 2,117,565,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.82342
Policy Entropy: 2.12444
Value Function Loss: 0.01758

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.61774

Collected Steps per Second: 22,919.62972
Overall Steps per Second: 10,827.88475

Timestep Collection Time: 2.18180
Timestep Consumption Time: 2.43646
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.61826

Cumulative Model Updates: 253,914
Cumulative Timesteps: 2,117,615,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2117615360...
Checkpoint 2117615360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.63517
Policy Entropy: 2.11454
Value Function Loss: 0.01797

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.52186
Value Function Update Magnitude: 0.58987

Collected Steps per Second: 22,747.92888
Overall Steps per Second: 10,686.50150

Timestep Collection Time: 2.19800
Timestep Consumption Time: 2.48080
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.67880

Cumulative Model Updates: 253,920
Cumulative Timesteps: 2,117,665,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.97201
Policy Entropy: 2.10868
Value Function Loss: 0.01827

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.53391
Value Function Update Magnitude: 0.57419

Collected Steps per Second: 23,165.34850
Overall Steps per Second: 10,915.93029

Timestep Collection Time: 2.15866
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.58101

Cumulative Model Updates: 253,926
Cumulative Timesteps: 2,117,715,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2117715366...
Checkpoint 2117715366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.61318
Policy Entropy: 2.08092
Value Function Loss: 0.01831

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.52937
Value Function Update Magnitude: 0.57538

Collected Steps per Second: 22,804.75198
Overall Steps per Second: 10,675.72813

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.49199
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.68539

Cumulative Model Updates: 253,932
Cumulative Timesteps: 2,117,765,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.73252
Policy Entropy: 2.08906
Value Function Loss: 0.01878

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.51161
Value Function Update Magnitude: 0.59869

Collected Steps per Second: 23,114.02260
Overall Steps per Second: 10,918.77687

Timestep Collection Time: 2.16405
Timestep Consumption Time: 2.41704
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.58110

Cumulative Model Updates: 253,938
Cumulative Timesteps: 2,117,815,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2117815406...
Checkpoint 2117815406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.73266
Policy Entropy: 2.07241
Value Function Loss: 0.01941

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.52706
Value Function Update Magnitude: 0.63584

Collected Steps per Second: 22,293.88428
Overall Steps per Second: 10,618.57001

Timestep Collection Time: 2.24411
Timestep Consumption Time: 2.46744
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.71156

Cumulative Model Updates: 253,944
Cumulative Timesteps: 2,117,865,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.95188
Policy Entropy: 2.09739
Value Function Loss: 0.01891

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.63631

Collected Steps per Second: 22,409.19754
Overall Steps per Second: 10,919.75938

Timestep Collection Time: 2.23176
Timestep Consumption Time: 2.34819
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.57995

Cumulative Model Updates: 253,950
Cumulative Timesteps: 2,117,915,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2117915448...
Checkpoint 2117915448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.52027
Policy Entropy: 2.10653
Value Function Loss: 0.01849

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.52860
Value Function Update Magnitude: 0.62345

Collected Steps per Second: 22,563.57274
Overall Steps per Second: 10,632.93598

Timestep Collection Time: 2.21729
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.70519

Cumulative Model Updates: 253,956
Cumulative Timesteps: 2,117,965,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.57383
Policy Entropy: 2.12927
Value Function Loss: 0.01722

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.52631
Value Function Update Magnitude: 0.61003

Collected Steps per Second: 23,237.27358
Overall Steps per Second: 10,892.54149

Timestep Collection Time: 2.15206
Timestep Consumption Time: 2.43897
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59103

Cumulative Model Updates: 253,962
Cumulative Timesteps: 2,118,015,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2118015486...
Checkpoint 2118015486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.31705
Policy Entropy: 2.11215
Value Function Loss: 0.01699

Mean KL Divergence: 0.02693
SB3 Clip Fraction: 0.16144
Policy Update Magnitude: 0.52203
Value Function Update Magnitude: 0.61171

Collected Steps per Second: 22,700.90700
Overall Steps per Second: 10,639.32565

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.49849
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70237

Cumulative Model Updates: 253,968
Cumulative Timesteps: 2,118,065,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.79064
Policy Entropy: 2.10044
Value Function Loss: 0.01777

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.17088
Policy Update Magnitude: 0.52577
Value Function Update Magnitude: 0.62079

Collected Steps per Second: 23,116.38172
Overall Steps per Second: 10,925.50383

Timestep Collection Time: 2.16314
Timestep Consumption Time: 2.41367
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.57681

Cumulative Model Updates: 253,974
Cumulative Timesteps: 2,118,115,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2118115520...
Checkpoint 2118115520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.03104
Policy Entropy: 2.08062
Value Function Loss: 0.01790

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.16152
Policy Update Magnitude: 0.54523
Value Function Update Magnitude: 0.63527

Collected Steps per Second: 23,018.03684
Overall Steps per Second: 10,731.78481

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.66185

Cumulative Model Updates: 253,980
Cumulative Timesteps: 2,118,165,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.98718
Policy Entropy: 2.09437
Value Function Loss: 0.01760

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.54817
Value Function Update Magnitude: 0.62265

Collected Steps per Second: 23,348.69093
Overall Steps per Second: 10,824.24957

Timestep Collection Time: 2.14222
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.62092

Cumulative Model Updates: 253,986
Cumulative Timesteps: 2,118,215,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2118215568...
Checkpoint 2118215568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.97401
Policy Entropy: 2.10323
Value Function Loss: 0.01729

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.53019
Value Function Update Magnitude: 0.60136

Collected Steps per Second: 22,949.36195
Overall Steps per Second: 10,723.40003

Timestep Collection Time: 2.17923
Timestep Consumption Time: 2.48459
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.66382

Cumulative Model Updates: 253,992
Cumulative Timesteps: 2,118,265,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.05304
Policy Entropy: 2.10934
Value Function Loss: 0.01724

Mean KL Divergence: 0.02787
SB3 Clip Fraction: 0.17125
Policy Update Magnitude: 0.51690
Value Function Update Magnitude: 0.60298

Collected Steps per Second: 22,789.64479
Overall Steps per Second: 10,832.49500

Timestep Collection Time: 2.19486
Timestep Consumption Time: 2.42273
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.61759

Cumulative Model Updates: 253,998
Cumulative Timesteps: 2,118,315,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2118315600...
Checkpoint 2118315600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.92182
Policy Entropy: 2.13277
Value Function Loss: 0.01702

Mean KL Divergence: 0.02940
SB3 Clip Fraction: 0.17819
Policy Update Magnitude: 0.50504
Value Function Update Magnitude: 0.61814

Collected Steps per Second: 22,477.38766
Overall Steps per Second: 10,814.22896

Timestep Collection Time: 2.22481
Timestep Consumption Time: 2.39946
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.62428

Cumulative Model Updates: 254,004
Cumulative Timesteps: 2,118,365,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.60451
Policy Entropy: 2.11879
Value Function Loss: 0.01715

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.17565
Policy Update Magnitude: 0.52432
Value Function Update Magnitude: 0.61328

Collected Steps per Second: 22,758.90116
Overall Steps per Second: 10,719.02339

Timestep Collection Time: 2.19782
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.66647

Cumulative Model Updates: 254,010
Cumulative Timesteps: 2,118,415,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2118415628...
Checkpoint 2118415628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.65698
Policy Entropy: 2.13341
Value Function Loss: 0.01694

Mean KL Divergence: 0.03274
SB3 Clip Fraction: 0.16205
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.59787

Collected Steps per Second: 22,367.91796
Overall Steps per Second: 10,635.17233

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.70420

Cumulative Model Updates: 254,016
Cumulative Timesteps: 2,118,465,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.13932
Policy Entropy: 2.10395
Value Function Loss: 0.01900

Mean KL Divergence: 0.04044
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.59588

Collected Steps per Second: 22,815.75392
Overall Steps per Second: 10,868.88485

Timestep Collection Time: 2.19261
Timestep Consumption Time: 2.41007
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.60268

Cumulative Model Updates: 254,022
Cumulative Timesteps: 2,118,515,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2118515684...
Checkpoint 2118515684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.53765
Policy Entropy: 2.10820
Value Function Loss: 0.01954

Mean KL Divergence: 0.02798
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.53784
Value Function Update Magnitude: 0.60553

Collected Steps per Second: 22,875.18417
Overall Steps per Second: 10,860.37226

Timestep Collection Time: 2.18647
Timestep Consumption Time: 2.41889
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.60537

Cumulative Model Updates: 254,028
Cumulative Timesteps: 2,118,565,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.27702
Policy Entropy: 2.10095
Value Function Loss: 0.02013

Mean KL Divergence: 0.03049
SB3 Clip Fraction: 0.17412
Policy Update Magnitude: 0.51997
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 23,489.45208
Overall Steps per Second: 10,814.83412

Timestep Collection Time: 2.12938
Timestep Consumption Time: 2.49556
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.62494

Cumulative Model Updates: 254,034
Cumulative Timesteps: 2,118,615,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2118615718...
Checkpoint 2118615718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.61294
Policy Entropy: 2.09572
Value Function Loss: 0.01876

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.61440

Collected Steps per Second: 22,880.06409
Overall Steps per Second: 10,727.30263

Timestep Collection Time: 2.18627
Timestep Consumption Time: 2.47678
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.66305

Cumulative Model Updates: 254,040
Cumulative Timesteps: 2,118,665,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.88276
Policy Entropy: 2.08585
Value Function Loss: 0.01801

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 22,937.34791
Overall Steps per Second: 10,710.19523

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.67050

Cumulative Model Updates: 254,046
Cumulative Timesteps: 2,118,715,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2118715762...
Checkpoint 2118715762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.11747
Policy Entropy: 2.07812
Value Function Loss: 0.01746

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.54229
Value Function Update Magnitude: 0.60149

Collected Steps per Second: 22,905.67246
Overall Steps per Second: 10,963.31111

Timestep Collection Time: 2.18522
Timestep Consumption Time: 2.38037
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.56559

Cumulative Model Updates: 254,052
Cumulative Timesteps: 2,118,765,816

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.53241
Policy Entropy: 2.06364
Value Function Loss: 0.01789

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.59452

Collected Steps per Second: 23,154.37228
Overall Steps per Second: 10,731.59101

Timestep Collection Time: 2.15968
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.65970

Cumulative Model Updates: 254,058
Cumulative Timesteps: 2,118,815,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2118815822...
Checkpoint 2118815822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.45348
Policy Entropy: 2.07431
Value Function Loss: 0.01865

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.59552

Collected Steps per Second: 22,827.09056
Overall Steps per Second: 10,763.50888

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.45504
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.64551

Cumulative Model Updates: 254,064
Cumulative Timesteps: 2,118,865,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.86642
Policy Entropy: 2.06696
Value Function Loss: 0.01830

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.61774

Collected Steps per Second: 22,949.15026
Overall Steps per Second: 10,758.28624

Timestep Collection Time: 2.17943
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.64907

Cumulative Model Updates: 254,070
Cumulative Timesteps: 2,118,915,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2118915840...
Checkpoint 2118915840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.72110
Policy Entropy: 2.07839
Value Function Loss: 0.01723

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.53330
Value Function Update Magnitude: 0.63114

Collected Steps per Second: 22,284.59311
Overall Steps per Second: 10,587.72588

Timestep Collection Time: 2.24478
Timestep Consumption Time: 2.47994
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.72472

Cumulative Model Updates: 254,076
Cumulative Timesteps: 2,118,965,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.24511
Policy Entropy: 2.07385
Value Function Loss: 0.01689

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.62544

Collected Steps per Second: 23,797.32534
Overall Steps per Second: 10,847.21284

Timestep Collection Time: 2.10116
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.60966

Cumulative Model Updates: 254,082
Cumulative Timesteps: 2,119,015,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2119015866...
Checkpoint 2119015866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.64454
Policy Entropy: 2.07536
Value Function Loss: 0.01747

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.53727
Value Function Update Magnitude: 0.62079

Collected Steps per Second: 22,656.93776
Overall Steps per Second: 10,627.90514

Timestep Collection Time: 2.20736
Timestep Consumption Time: 2.49837
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.70573

Cumulative Model Updates: 254,088
Cumulative Timesteps: 2,119,065,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.87040
Policy Entropy: 2.07474
Value Function Loss: 0.01773

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.62880

Collected Steps per Second: 22,980.49231
Overall Steps per Second: 10,849.10984

Timestep Collection Time: 2.17680
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61089

Cumulative Model Updates: 254,094
Cumulative Timesteps: 2,119,115,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2119115902...
Checkpoint 2119115902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.55427
Policy Entropy: 2.06410
Value Function Loss: 0.01846

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.63385

Collected Steps per Second: 22,543.41293
Overall Steps per Second: 10,722.39090

Timestep Collection Time: 2.21803
Timestep Consumption Time: 2.44529
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.66333

Cumulative Model Updates: 254,100
Cumulative Timesteps: 2,119,165,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.10755
Policy Entropy: 2.06868
Value Function Loss: 0.01787

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.52852
Value Function Update Magnitude: 0.63483

Collected Steps per Second: 22,813.42733
Overall Steps per Second: 10,941.01024

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.37865
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.57069

Cumulative Model Updates: 254,106
Cumulative Timesteps: 2,119,215,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2119215912...
Checkpoint 2119215912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.55005
Policy Entropy: 2.06631
Value Function Loss: 0.01838

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.53137
Value Function Update Magnitude: 0.63001

Collected Steps per Second: 22,878.39054
Overall Steps per Second: 10,550.93734

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.55498
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.74176

Cumulative Model Updates: 254,112
Cumulative Timesteps: 2,119,265,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.78227
Policy Entropy: 2.09981
Value Function Loss: 0.01764

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.53420
Value Function Update Magnitude: 0.62381

Collected Steps per Second: 22,789.64932
Overall Steps per Second: 10,674.81072

Timestep Collection Time: 2.19521
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68655

Cumulative Model Updates: 254,118
Cumulative Timesteps: 2,119,315,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2119315970...
Checkpoint 2119315970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.15839
Policy Entropy: 2.09237
Value Function Loss: 0.01805

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.53353
Value Function Update Magnitude: 0.61307

Collected Steps per Second: 22,520.38124
Overall Steps per Second: 10,719.37533

Timestep Collection Time: 2.22145
Timestep Consumption Time: 2.44561
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.66706

Cumulative Model Updates: 254,124
Cumulative Timesteps: 2,119,365,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.89996
Policy Entropy: 2.10694
Value Function Loss: 0.01818

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.60375

Collected Steps per Second: 23,179.55286
Overall Steps per Second: 11,074.48604

Timestep Collection Time: 2.15725
Timestep Consumption Time: 2.35800
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.51524

Cumulative Model Updates: 254,130
Cumulative Timesteps: 2,119,416,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2119416002...
Checkpoint 2119416002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.77121
Policy Entropy: 2.08186
Value Function Loss: 0.01782

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.52966
Value Function Update Magnitude: 0.59756

Collected Steps per Second: 22,434.73701
Overall Steps per Second: 10,703.67134

Timestep Collection Time: 2.22869
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.67129

Cumulative Model Updates: 254,136
Cumulative Timesteps: 2,119,466,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.57352
Policy Entropy: 2.07828
Value Function Loss: 0.01838

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.59255

Collected Steps per Second: 22,831.82895
Overall Steps per Second: 10,810.91926

Timestep Collection Time: 2.19010
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62532

Cumulative Model Updates: 254,142
Cumulative Timesteps: 2,119,516,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2119516006...
Checkpoint 2119516006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.18401
Policy Entropy: 2.05640
Value Function Loss: 0.01852

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.62374

Collected Steps per Second: 22,471.77789
Overall Steps per Second: 10,760.65345

Timestep Collection Time: 2.22635
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.64935

Cumulative Model Updates: 254,148
Cumulative Timesteps: 2,119,566,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.34123
Policy Entropy: 2.03865
Value Function Loss: 0.01845

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.54075
Value Function Update Magnitude: 0.64326

Collected Steps per Second: 23,159.75569
Overall Steps per Second: 10,865.78385

Timestep Collection Time: 2.15995
Timestep Consumption Time: 2.44386
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.60381

Cumulative Model Updates: 254,154
Cumulative Timesteps: 2,119,616,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2119616060...
Checkpoint 2119616060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.90382
Policy Entropy: 2.06884
Value Function Loss: 0.01752

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.53961
Value Function Update Magnitude: 0.62428

Collected Steps per Second: 22,732.84683
Overall Steps per Second: 10,652.14604

Timestep Collection Time: 2.20052
Timestep Consumption Time: 2.49563
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.69614

Cumulative Model Updates: 254,160
Cumulative Timesteps: 2,119,666,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.39382
Policy Entropy: 2.08715
Value Function Loss: 0.01799

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.63752

Collected Steps per Second: 23,298.69177
Overall Steps per Second: 10,908.65531

Timestep Collection Time: 2.14699
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.58553

Cumulative Model Updates: 254,166
Cumulative Timesteps: 2,119,716,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2119716106...
Checkpoint 2119716106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.78927
Policy Entropy: 2.11701
Value Function Loss: 0.01797

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.64085

Collected Steps per Second: 22,797.64251
Overall Steps per Second: 10,710.64599

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.67068

Cumulative Model Updates: 254,172
Cumulative Timesteps: 2,119,766,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.17995
Policy Entropy: 2.11318
Value Function Loss: 0.01816

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.53161
Value Function Update Magnitude: 0.64363

Collected Steps per Second: 23,855.11865
Overall Steps per Second: 10,872.10270

Timestep Collection Time: 2.09615
Timestep Consumption Time: 2.50314
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.59929

Cumulative Model Updates: 254,178
Cumulative Timesteps: 2,119,816,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2119816136...
Checkpoint 2119816136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.61144
Policy Entropy: 2.11504
Value Function Loss: 0.01982

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.53837
Value Function Update Magnitude: 0.62422

Collected Steps per Second: 21,932.55148
Overall Steps per Second: 10,601.19126

Timestep Collection Time: 2.27990
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.71683

Cumulative Model Updates: 254,184
Cumulative Timesteps: 2,119,866,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.43288
Policy Entropy: 2.11197
Value Function Loss: 0.01957

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.61612

Collected Steps per Second: 22,657.79249
Overall Steps per Second: 10,676.38190

Timestep Collection Time: 2.20736
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.68455

Cumulative Model Updates: 254,190
Cumulative Timesteps: 2,119,916,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2119916154...
Checkpoint 2119916154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.94505
Policy Entropy: 2.10006
Value Function Loss: 0.02003

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.63800

Collected Steps per Second: 22,195.38258
Overall Steps per Second: 10,627.63451

Timestep Collection Time: 2.25272
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.70472

Cumulative Model Updates: 254,196
Cumulative Timesteps: 2,119,966,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.85975
Policy Entropy: 2.08897
Value Function Loss: 0.01883

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.67088

Collected Steps per Second: 23,644.39309
Overall Steps per Second: 10,816.72244

Timestep Collection Time: 2.11560
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.62451

Cumulative Model Updates: 254,202
Cumulative Timesteps: 2,120,016,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2120016176...
Checkpoint 2120016176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.33982
Policy Entropy: 2.07730
Value Function Loss: 0.01875

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.67598

Collected Steps per Second: 22,277.39707
Overall Steps per Second: 10,518.22665

Timestep Collection Time: 2.24515
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.75517

Cumulative Model Updates: 254,208
Cumulative Timesteps: 2,120,066,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.38014
Policy Entropy: 2.09321
Value Function Loss: 0.01784

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.66652

Collected Steps per Second: 23,368.14327
Overall Steps per Second: 10,905.50554

Timestep Collection Time: 2.14078
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.58722

Cumulative Model Updates: 254,214
Cumulative Timesteps: 2,120,116,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2120116218...
Checkpoint 2120116218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.64978
Policy Entropy: 2.11090
Value Function Loss: 0.01785

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.52300
Value Function Update Magnitude: 0.64105

Collected Steps per Second: 22,698.41613
Overall Steps per Second: 10,819.93297

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.41937
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.62313

Cumulative Model Updates: 254,220
Cumulative Timesteps: 2,120,166,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.55981
Policy Entropy: 2.11756
Value Function Loss: 0.01725

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.52130
Value Function Update Magnitude: 0.59248

Collected Steps per Second: 23,597.55160
Overall Steps per Second: 10,881.52087

Timestep Collection Time: 2.11997
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.59734

Cumulative Model Updates: 254,226
Cumulative Timesteps: 2,120,216,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2120216266...
Checkpoint 2120216266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.82616
Policy Entropy: 2.10850
Value Function Loss: 0.01762

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.53039
Value Function Update Magnitude: 0.58247

Collected Steps per Second: 23,142.32721
Overall Steps per Second: 10,905.73004

Timestep Collection Time: 2.16054
Timestep Consumption Time: 2.42420
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.58475

Cumulative Model Updates: 254,232
Cumulative Timesteps: 2,120,266,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.10593
Policy Entropy: 2.11377
Value Function Loss: 0.01636

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.52029
Value Function Update Magnitude: 0.59345

Collected Steps per Second: 23,181.09935
Overall Steps per Second: 11,021.22659

Timestep Collection Time: 2.15779
Timestep Consumption Time: 2.38072
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.53851

Cumulative Model Updates: 254,238
Cumulative Timesteps: 2,120,316,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2120316286...
Checkpoint 2120316286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.01812
Policy Entropy: 2.11120
Value Function Loss: 0.01684

Mean KL Divergence: 0.02847
SB3 Clip Fraction: 0.16530
Policy Update Magnitude: 0.50445
Value Function Update Magnitude: 0.58879

Collected Steps per Second: 22,566.00002
Overall Steps per Second: 10,979.81253

Timestep Collection Time: 2.21705
Timestep Consumption Time: 2.33949
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.55654

Cumulative Model Updates: 254,244
Cumulative Timesteps: 2,120,366,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.91124
Policy Entropy: 2.09970
Value Function Loss: 0.01729

Mean KL Divergence: 0.02667
SB3 Clip Fraction: 0.16843
Policy Update Magnitude: 0.45939
Value Function Update Magnitude: 0.62070

Collected Steps per Second: 22,537.28699
Overall Steps per Second: 10,621.05274

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70876

Cumulative Model Updates: 254,250
Cumulative Timesteps: 2,120,416,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2120416328...
Checkpoint 2120416328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.57350
Policy Entropy: 2.06982
Value Function Loss: 0.01825

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.47525
Value Function Update Magnitude: 0.65350

Collected Steps per Second: 22,403.22856
Overall Steps per Second: 10,534.48021

Timestep Collection Time: 2.23307
Timestep Consumption Time: 2.51591
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.74898

Cumulative Model Updates: 254,256
Cumulative Timesteps: 2,120,466,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.86653
Policy Entropy: 2.06202
Value Function Loss: 0.01741

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.48853
Value Function Update Magnitude: 0.64891

Collected Steps per Second: 22,929.86854
Overall Steps per Second: 10,890.81533

Timestep Collection Time: 2.18056
Timestep Consumption Time: 2.41046
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.59102

Cumulative Model Updates: 254,262
Cumulative Timesteps: 2,120,516,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2120516356...
Checkpoint 2120516356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.74402
Policy Entropy: 2.06527
Value Function Loss: 0.01835

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.14793
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 22,665.21056
Overall Steps per Second: 10,775.52992

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.64256

Cumulative Model Updates: 254,268
Cumulative Timesteps: 2,120,566,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.06737
Policy Entropy: 2.06110
Value Function Loss: 0.01742

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.62295

Collected Steps per Second: 23,604.00292
Overall Steps per Second: 10,779.83882

Timestep Collection Time: 2.11862
Timestep Consumption Time: 2.52041
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.63903

Cumulative Model Updates: 254,274
Cumulative Timesteps: 2,120,616,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2120616390...
Checkpoint 2120616390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.33266
Policy Entropy: 2.05196
Value Function Loss: 0.01802

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.53690
Value Function Update Magnitude: 0.62392

Collected Steps per Second: 22,763.18067
Overall Steps per Second: 10,660.60242

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.49414
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.69110

Cumulative Model Updates: 254,280
Cumulative Timesteps: 2,120,666,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.31831
Policy Entropy: 2.03146
Value Function Loss: 0.01877

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.53978
Value Function Update Magnitude: 0.62113

Collected Steps per Second: 21,912.29955
Overall Steps per Second: 10,433.15662

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.51169
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.79452

Cumulative Model Updates: 254,286
Cumulative Timesteps: 2,120,716,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2120716422...
Checkpoint 2120716422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.90041
Policy Entropy: 2.04679
Value Function Loss: 0.01999

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.55686
Value Function Update Magnitude: 0.65065

Collected Steps per Second: 22,821.43901
Overall Steps per Second: 10,907.50841

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.39355
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.58492

Cumulative Model Updates: 254,292
Cumulative Timesteps: 2,120,766,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.89071
Policy Entropy: 2.08242
Value Function Loss: 0.01888

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.66212

Collected Steps per Second: 23,774.14420
Overall Steps per Second: 10,906.14762

Timestep Collection Time: 2.10439
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.58732

Cumulative Model Updates: 254,298
Cumulative Timesteps: 2,120,816,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2120816462...
Checkpoint 2120816462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.21167
Policy Entropy: 2.10476
Value Function Loss: 0.01826

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.66098

Collected Steps per Second: 22,322.13109
Overall Steps per Second: 10,591.84660

Timestep Collection Time: 2.24002
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.72080

Cumulative Model Updates: 254,304
Cumulative Timesteps: 2,120,866,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.23979
Policy Entropy: 2.11980
Value Function Loss: 0.01752

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.53115
Value Function Update Magnitude: 0.64221

Collected Steps per Second: 23,046.66897
Overall Steps per Second: 10,749.36109

Timestep Collection Time: 2.16960
Timestep Consumption Time: 2.48203
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.65163

Cumulative Model Updates: 254,310
Cumulative Timesteps: 2,120,916,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2120916466...
Checkpoint 2120916466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.32030
Policy Entropy: 2.11737
Value Function Loss: 0.01793

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11963
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.63026

Collected Steps per Second: 22,204.44829
Overall Steps per Second: 10,743.60882

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.40299
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.65561

Cumulative Model Updates: 254,316
Cumulative Timesteps: 2,120,966,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.74790
Policy Entropy: 2.10511
Value Function Loss: 0.01780

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.62704

Collected Steps per Second: 22,656.64728
Overall Steps per Second: 10,795.75103

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.63256

Cumulative Model Updates: 254,322
Cumulative Timesteps: 2,121,016,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2121016496...
Checkpoint 2121016496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.00251
Policy Entropy: 2.09932
Value Function Loss: 0.01847

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.63329

Collected Steps per Second: 22,527.08984
Overall Steps per Second: 10,631.33977

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.48353
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.70308

Cumulative Model Updates: 254,328
Cumulative Timesteps: 2,121,066,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.99930
Policy Entropy: 2.08563
Value Function Loss: 0.01854

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.64547

Collected Steps per Second: 23,401.69264
Overall Steps per Second: 10,933.57090

Timestep Collection Time: 2.13822
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.57655

Cumulative Model Updates: 254,334
Cumulative Timesteps: 2,121,116,534

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2121116534...
Checkpoint 2121116534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.00558
Policy Entropy: 2.09687
Value Function Loss: 0.01827

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.53412
Value Function Update Magnitude: 0.65366

Collected Steps per Second: 22,928.61811
Overall Steps per Second: 10,780.64866

Timestep Collection Time: 2.18094
Timestep Consumption Time: 2.45755
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.63850

Cumulative Model Updates: 254,340
Cumulative Timesteps: 2,121,166,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.54486
Policy Entropy: 2.07295
Value Function Loss: 0.01852

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.53068
Value Function Update Magnitude: 0.63281

Collected Steps per Second: 21,880.13123
Overall Steps per Second: 10,731.46382

Timestep Collection Time: 2.28582
Timestep Consumption Time: 2.37468
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.66050

Cumulative Model Updates: 254,346
Cumulative Timesteps: 2,121,216,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2121216554...
Checkpoint 2121216554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.82143
Policy Entropy: 2.06379
Value Function Loss: 0.01880

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.62037

Collected Steps per Second: 22,570.36985
Overall Steps per Second: 10,660.26329

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.47601
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69219

Cumulative Model Updates: 254,352
Cumulative Timesteps: 2,121,266,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.99731
Policy Entropy: 2.03966
Value Function Loss: 0.01860

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.16160
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.63699

Collected Steps per Second: 22,860.84673
Overall Steps per Second: 10,815.75938

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62399

Cumulative Model Updates: 254,358
Cumulative Timesteps: 2,121,316,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2121316586...
Checkpoint 2121316586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.66595
Policy Entropy: 2.06110
Value Function Loss: 0.01838

Mean KL Divergence: 0.02971
SB3 Clip Fraction: 0.17316
Policy Update Magnitude: 0.52511
Value Function Update Magnitude: 0.63633

Collected Steps per Second: 22,270.62966
Overall Steps per Second: 10,700.35492

Timestep Collection Time: 2.24511
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.67274

Cumulative Model Updates: 254,364
Cumulative Timesteps: 2,121,366,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.06365
Policy Entropy: 2.07319
Value Function Loss: 0.01807

Mean KL Divergence: 0.02732
SB3 Clip Fraction: 0.16506
Policy Update Magnitude: 0.53437
Value Function Update Magnitude: 0.62796

Collected Steps per Second: 22,626.48351
Overall Steps per Second: 10,961.64057

Timestep Collection Time: 2.21042
Timestep Consumption Time: 2.35222
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.56264

Cumulative Model Updates: 254,370
Cumulative Timesteps: 2,121,416,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2121416600...
Checkpoint 2121416600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.19078
Policy Entropy: 2.09068
Value Function Loss: 0.01867

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 0.62462

Collected Steps per Second: 22,616.54758
Overall Steps per Second: 10,599.18488

Timestep Collection Time: 2.21201
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71999

Cumulative Model Updates: 254,376
Cumulative Timesteps: 2,121,466,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.31174
Policy Entropy: 2.08659
Value Function Loss: 0.01795

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.62964

Collected Steps per Second: 23,427.50944
Overall Steps per Second: 10,944.65316

Timestep Collection Time: 2.13561
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.57136

Cumulative Model Updates: 254,382
Cumulative Timesteps: 2,121,516,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2121516660...
Checkpoint 2121516660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.26736
Policy Entropy: 2.07645
Value Function Loss: 0.01854

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.63858

Collected Steps per Second: 22,640.98388
Overall Steps per Second: 10,673.07452

Timestep Collection Time: 2.20865
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.68525

Cumulative Model Updates: 254,388
Cumulative Timesteps: 2,121,566,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.11668
Policy Entropy: 2.09110
Value Function Loss: 0.01752

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.53202
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 22,969.78832
Overall Steps per Second: 10,837.82968

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.61439

Cumulative Model Updates: 254,394
Cumulative Timesteps: 2,121,616,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2121616676...
Checkpoint 2121616676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.35228
Policy Entropy: 2.07446
Value Function Loss: 0.01807

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.60655

Collected Steps per Second: 22,630.01977
Overall Steps per Second: 10,667.84976

Timestep Collection Time: 2.20963
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.68736

Cumulative Model Updates: 254,400
Cumulative Timesteps: 2,121,666,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.46989
Policy Entropy: 2.06554
Value Function Loss: 0.01818

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.54812
Value Function Update Magnitude: 0.61367

Collected Steps per Second: 23,082.77880
Overall Steps per Second: 10,866.90020

Timestep Collection Time: 2.16724
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60352

Cumulative Model Updates: 254,406
Cumulative Timesteps: 2,121,716,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2121716706...
Checkpoint 2121716706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.42888
Policy Entropy: 2.05638
Value Function Loss: 0.01858

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.62267

Collected Steps per Second: 22,236.86144
Overall Steps per Second: 10,694.58704

Timestep Collection Time: 2.24906
Timestep Consumption Time: 2.42733
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.67638

Cumulative Model Updates: 254,412
Cumulative Timesteps: 2,121,766,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.36986
Policy Entropy: 2.08439
Value Function Loss: 0.01870

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.64170

Collected Steps per Second: 23,088.77034
Overall Steps per Second: 10,927.19672

Timestep Collection Time: 2.16590
Timestep Consumption Time: 2.41057
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.57647

Cumulative Model Updates: 254,418
Cumulative Timesteps: 2,121,816,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2121816726...
Checkpoint 2121816726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.45243
Policy Entropy: 2.10623
Value Function Loss: 0.01830

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.65057

Collected Steps per Second: 22,305.24975
Overall Steps per Second: 10,636.27125

Timestep Collection Time: 2.24279
Timestep Consumption Time: 2.46055
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.70334

Cumulative Model Updates: 254,424
Cumulative Timesteps: 2,121,866,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.47893
Policy Entropy: 2.08657
Value Function Loss: 0.01790

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.65421

Collected Steps per Second: 23,025.11939
Overall Steps per Second: 10,860.56134

Timestep Collection Time: 2.17154
Timestep Consumption Time: 2.43227
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60381

Cumulative Model Updates: 254,430
Cumulative Timesteps: 2,121,916,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2121916752...
Checkpoint 2121916752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.66378
Policy Entropy: 2.07603
Value Function Loss: 0.01678

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.53562
Value Function Update Magnitude: 0.64761

Collected Steps per Second: 22,939.68143
Overall Steps per Second: 11,049.23569

Timestep Collection Time: 2.18094
Timestep Consumption Time: 2.34698
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.52792

Cumulative Model Updates: 254,436
Cumulative Timesteps: 2,121,966,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.60977
Policy Entropy: 2.08983
Value Function Loss: 0.01664

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.53474
Value Function Update Magnitude: 0.62098

Collected Steps per Second: 23,271.92900
Overall Steps per Second: 10,922.61198

Timestep Collection Time: 2.14937
Timestep Consumption Time: 2.43012
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.57949

Cumulative Model Updates: 254,442
Cumulative Timesteps: 2,122,016,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2122016802...
Checkpoint 2122016802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.00482
Policy Entropy: 2.09270
Value Function Loss: 0.01676

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.52707
Value Function Update Magnitude: 0.62823

Collected Steps per Second: 22,525.00129
Overall Steps per Second: 10,758.03688

Timestep Collection Time: 2.21976
Timestep Consumption Time: 2.42793
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.64769

Cumulative Model Updates: 254,448
Cumulative Timesteps: 2,122,066,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.74604
Policy Entropy: 2.10472
Value Function Loss: 0.01673

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.52627
Value Function Update Magnitude: 0.62312

Collected Steps per Second: 23,268.13238
Overall Steps per Second: 10,868.81126

Timestep Collection Time: 2.14955
Timestep Consumption Time: 2.45224
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.60179

Cumulative Model Updates: 254,454
Cumulative Timesteps: 2,122,116,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2122116818...
Checkpoint 2122116818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.63918
Policy Entropy: 2.11123
Value Function Loss: 0.01623

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.52561
Value Function Update Magnitude: 0.62546

Collected Steps per Second: 22,577.42880
Overall Steps per Second: 10,855.71745

Timestep Collection Time: 2.21549
Timestep Consumption Time: 2.39222
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.60771

Cumulative Model Updates: 254,460
Cumulative Timesteps: 2,122,166,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.51918
Policy Entropy: 2.11868
Value Function Loss: 0.01677

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.61831

Collected Steps per Second: 23,130.22437
Overall Steps per Second: 10,716.54415

Timestep Collection Time: 2.16167
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.66568

Cumulative Model Updates: 254,466
Cumulative Timesteps: 2,122,216,838

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2122216838...
Checkpoint 2122216838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.66088
Policy Entropy: 2.10585
Value Function Loss: 0.01831

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.62430

Collected Steps per Second: 22,153.46158
Overall Steps per Second: 10,678.83477

Timestep Collection Time: 2.25753
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.68328

Cumulative Model Updates: 254,472
Cumulative Timesteps: 2,122,266,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.25395
Policy Entropy: 2.07809
Value Function Loss: 0.01847

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.53754
Value Function Update Magnitude: 0.62333

Collected Steps per Second: 22,902.08924
Overall Steps per Second: 10,888.94907

Timestep Collection Time: 2.18434
Timestep Consumption Time: 2.40986
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.59420

Cumulative Model Updates: 254,478
Cumulative Timesteps: 2,122,316,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2122316876...
Checkpoint 2122316876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.27488
Policy Entropy: 2.08610
Value Function Loss: 0.01914

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.62664

Collected Steps per Second: 22,443.88502
Overall Steps per Second: 10,585.19956

Timestep Collection Time: 2.22858
Timestep Consumption Time: 2.49670
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.72528

Cumulative Model Updates: 254,484
Cumulative Timesteps: 2,122,366,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.21183
Policy Entropy: 2.10425
Value Function Loss: 0.01777

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.63572

Collected Steps per Second: 23,368.43178
Overall Steps per Second: 10,941.33532

Timestep Collection Time: 2.13998
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.57056

Cumulative Model Updates: 254,490
Cumulative Timesteps: 2,122,416,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2122416902...
Checkpoint 2122416902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.50455
Policy Entropy: 2.11792
Value Function Loss: 0.01732

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.64090

Collected Steps per Second: 22,753.31796
Overall Steps per Second: 10,653.79748

Timestep Collection Time: 2.19836
Timestep Consumption Time: 2.49668
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.69504

Cumulative Model Updates: 254,496
Cumulative Timesteps: 2,122,466,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.93765
Policy Entropy: 2.12879
Value Function Loss: 0.01753

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.63726

Collected Steps per Second: 22,959.36376
Overall Steps per Second: 10,838.58162

Timestep Collection Time: 2.17863
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61499

Cumulative Model Updates: 254,502
Cumulative Timesteps: 2,122,516,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2122516942...
Checkpoint 2122516942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.41946
Policy Entropy: 2.11898
Value Function Loss: 0.01842

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.54260
Value Function Update Magnitude: 0.63375

Collected Steps per Second: 22,531.21357
Overall Steps per Second: 10,659.04780

Timestep Collection Time: 2.21959
Timestep Consumption Time: 2.47220
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.69179

Cumulative Model Updates: 254,508
Cumulative Timesteps: 2,122,566,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.96008
Policy Entropy: 2.12132
Value Function Loss: 0.01896

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.55230
Value Function Update Magnitude: 0.65137

Collected Steps per Second: 23,303.04388
Overall Steps per Second: 10,967.14113

Timestep Collection Time: 2.14650
Timestep Consumption Time: 2.41440
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.56090

Cumulative Model Updates: 254,514
Cumulative Timesteps: 2,122,616,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2122616972...
Checkpoint 2122616972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.39712
Policy Entropy: 2.09772
Value Function Loss: 0.01877

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.66712

Collected Steps per Second: 22,801.70424
Overall Steps per Second: 10,687.22708

Timestep Collection Time: 2.19317
Timestep Consumption Time: 2.48606
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.67923

Cumulative Model Updates: 254,520
Cumulative Timesteps: 2,122,666,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.61318
Policy Entropy: 2.09821
Value Function Loss: 0.01909

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.64633

Collected Steps per Second: 22,717.14272
Overall Steps per Second: 10,802.50908

Timestep Collection Time: 2.20116
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62892

Cumulative Model Updates: 254,526
Cumulative Timesteps: 2,122,716,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2122716984...
Checkpoint 2122716984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.80926
Policy Entropy: 2.07900
Value Function Loss: 0.01912

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.55397
Value Function Update Magnitude: 0.65103

Collected Steps per Second: 21,807.37608
Overall Steps per Second: 10,634.51486

Timestep Collection Time: 2.29427
Timestep Consumption Time: 2.41041
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.70468

Cumulative Model Updates: 254,532
Cumulative Timesteps: 2,122,767,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.53352
Policy Entropy: 2.05575
Value Function Loss: 0.01996

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.65370

Collected Steps per Second: 22,797.15753
Overall Steps per Second: 10,979.36102

Timestep Collection Time: 2.19387
Timestep Consumption Time: 2.36140
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.55527

Cumulative Model Updates: 254,538
Cumulative Timesteps: 2,122,817,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2122817030...
Checkpoint 2122817030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.38547
Policy Entropy: 2.03940
Value Function Loss: 0.01915

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.55679
Value Function Update Magnitude: 0.65764

Collected Steps per Second: 22,364.10543
Overall Steps per Second: 10,610.93649

Timestep Collection Time: 2.23707
Timestep Consumption Time: 2.47788
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.71495

Cumulative Model Updates: 254,544
Cumulative Timesteps: 2,122,867,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.64183
Policy Entropy: 2.04371
Value Function Loss: 0.01823

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.54840
Value Function Update Magnitude: 0.65450

Collected Steps per Second: 23,283.63477
Overall Steps per Second: 10,862.57458

Timestep Collection Time: 2.14863
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60554

Cumulative Model Updates: 254,550
Cumulative Timesteps: 2,122,917,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2122917088...
Checkpoint 2122917088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.08664
Policy Entropy: 2.07237
Value Function Loss: 0.01699

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.65035

Collected Steps per Second: 22,848.49957
Overall Steps per Second: 10,589.41222

Timestep Collection Time: 2.18938
Timestep Consumption Time: 2.53459
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.72396

Cumulative Model Updates: 254,556
Cumulative Timesteps: 2,122,967,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.37437
Policy Entropy: 2.08506
Value Function Loss: 0.01771

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.55574
Value Function Update Magnitude: 0.63605

Collected Steps per Second: 23,627.54945
Overall Steps per Second: 11,013.32672

Timestep Collection Time: 2.11626
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.54014

Cumulative Model Updates: 254,562
Cumulative Timesteps: 2,123,017,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2123017114...
Checkpoint 2123017114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.06929
Policy Entropy: 2.10527
Value Function Loss: 0.01704

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.54052
Value Function Update Magnitude: 0.61665

Collected Steps per Second: 22,803.61986
Overall Steps per Second: 10,659.13139

Timestep Collection Time: 2.19360
Timestep Consumption Time: 2.49928
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.69288

Cumulative Model Updates: 254,568
Cumulative Timesteps: 2,123,067,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.90405
Policy Entropy: 2.11873
Value Function Loss: 0.01593

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.53348
Value Function Update Magnitude: 0.60509

Collected Steps per Second: 23,476.01615
Overall Steps per Second: 10,902.99623

Timestep Collection Time: 2.13060
Timestep Consumption Time: 2.45695
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.58755

Cumulative Model Updates: 254,574
Cumulative Timesteps: 2,123,117,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2123117154...
Checkpoint 2123117154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.06101
Policy Entropy: 2.09380
Value Function Loss: 0.01583

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.60861

Collected Steps per Second: 22,546.80865
Overall Steps per Second: 10,625.03388

Timestep Collection Time: 2.21876
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.70831

Cumulative Model Updates: 254,580
Cumulative Timesteps: 2,123,167,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.40362
Policy Entropy: 2.07481
Value Function Loss: 0.01709

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.60517

Collected Steps per Second: 22,349.17125
Overall Steps per Second: 10,896.69439

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.35152
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.58891

Cumulative Model Updates: 254,586
Cumulative Timesteps: 2,123,217,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2123217184...
Checkpoint 2123217184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.64366
Policy Entropy: 2.06377
Value Function Loss: 0.01798

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.60372

Collected Steps per Second: 22,558.05756
Overall Steps per Second: 10,703.32169

Timestep Collection Time: 2.21650
Timestep Consumption Time: 2.45494
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.67145

Cumulative Model Updates: 254,592
Cumulative Timesteps: 2,123,267,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.68841
Policy Entropy: 2.08186
Value Function Loss: 0.01787

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.58561

Collected Steps per Second: 23,142.46406
Overall Steps per Second: 10,876.15912

Timestep Collection Time: 2.16165
Timestep Consumption Time: 2.43795
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59960

Cumulative Model Updates: 254,598
Cumulative Timesteps: 2,123,317,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2123317210...
Checkpoint 2123317210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.20826
Policy Entropy: 2.06387
Value Function Loss: 0.01757

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.58935

Collected Steps per Second: 22,802.82021
Overall Steps per Second: 10,775.54401

Timestep Collection Time: 2.19341
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.64162

Cumulative Model Updates: 254,604
Cumulative Timesteps: 2,123,367,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.56771
Policy Entropy: 2.04564
Value Function Loss: 0.01745

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.53740
Value Function Update Magnitude: 0.59782

Collected Steps per Second: 23,528.32593
Overall Steps per Second: 10,787.04447

Timestep Collection Time: 2.12578
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.63667

Cumulative Model Updates: 254,610
Cumulative Timesteps: 2,123,417,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2123417242...
Checkpoint 2123417242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.61199
Policy Entropy: 2.04996
Value Function Loss: 0.01815

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.60516

Collected Steps per Second: 22,241.80064
Overall Steps per Second: 10,716.66847

Timestep Collection Time: 2.24919
Timestep Consumption Time: 2.41887
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.66806

Cumulative Model Updates: 254,616
Cumulative Timesteps: 2,123,467,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.56232
Policy Entropy: 2.05805
Value Function Loss: 0.01925

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.54390
Value Function Update Magnitude: 0.62438

Collected Steps per Second: 23,357.68850
Overall Steps per Second: 10,841.36194

Timestep Collection Time: 2.14174
Timestep Consumption Time: 2.47263
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.61436

Cumulative Model Updates: 254,622
Cumulative Timesteps: 2,123,517,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2123517294...
Checkpoint 2123517294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.97769
Policy Entropy: 2.06459
Value Function Loss: 0.01955

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.55528
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,873.12831
Overall Steps per Second: 11,017.40177

Timestep Collection Time: 2.18685
Timestep Consumption Time: 2.35324
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.54009

Cumulative Model Updates: 254,628
Cumulative Timesteps: 2,123,567,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.22521
Policy Entropy: 2.05789
Value Function Loss: 0.01895

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 23,498.13120
Overall Steps per Second: 10,976.67346

Timestep Collection Time: 2.12791
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.55530

Cumulative Model Updates: 254,634
Cumulative Timesteps: 2,123,617,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2123617316...
Checkpoint 2123617316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.76332
Policy Entropy: 2.05371
Value Function Loss: 0.01886

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.55048
Value Function Update Magnitude: 0.63180

Collected Steps per Second: 22,108.57483
Overall Steps per Second: 10,700.10365

Timestep Collection Time: 2.26265
Timestep Consumption Time: 2.41244
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.67509

Cumulative Model Updates: 254,640
Cumulative Timesteps: 2,123,667,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.12210
Policy Entropy: 2.04704
Value Function Loss: 0.01837

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.55777
Value Function Update Magnitude: 0.63525

Collected Steps per Second: 22,881.06052
Overall Steps per Second: 10,839.90263

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.42854
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.61480

Cumulative Model Updates: 254,646
Cumulative Timesteps: 2,123,717,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2123717364...
Checkpoint 2123717364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.22558
Policy Entropy: 2.04724
Value Function Loss: 0.01941

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.65843

Collected Steps per Second: 22,427.36691
Overall Steps per Second: 10,667.23140

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.68800

Cumulative Model Updates: 254,652
Cumulative Timesteps: 2,123,767,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.81713
Policy Entropy: 2.03561
Value Function Loss: 0.01887

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.66732

Collected Steps per Second: 23,759.35794
Overall Steps per Second: 10,959.68827

Timestep Collection Time: 2.10544
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.56436

Cumulative Model Updates: 254,658
Cumulative Timesteps: 2,123,817,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2123817396...
Checkpoint 2123817396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.18148
Policy Entropy: 2.02640
Value Function Loss: 0.01872

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.66017

Collected Steps per Second: 22,589.06516
Overall Steps per Second: 10,590.84025

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.72182

Cumulative Model Updates: 254,664
Cumulative Timesteps: 2,123,867,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.57254
Policy Entropy: 2.03243
Value Function Loss: 0.01723

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.64918

Collected Steps per Second: 23,101.48445
Overall Steps per Second: 10,902.03210

Timestep Collection Time: 2.16497
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.58759

Cumulative Model Updates: 254,670
Cumulative Timesteps: 2,123,917,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2123917418...
Checkpoint 2123917418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.58096
Policy Entropy: 2.07006
Value Function Loss: 0.01709

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.53750
Value Function Update Magnitude: 0.63211

Collected Steps per Second: 22,683.63362
Overall Steps per Second: 10,888.19956

Timestep Collection Time: 2.20450
Timestep Consumption Time: 2.38818
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.59268

Cumulative Model Updates: 254,676
Cumulative Timesteps: 2,123,967,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.76708
Policy Entropy: 2.09214
Value Function Loss: 0.01767

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.53535
Value Function Update Magnitude: 0.62934

Collected Steps per Second: 23,579.87401
Overall Steps per Second: 10,925.56576

Timestep Collection Time: 2.12054
Timestep Consumption Time: 2.45607
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.57661

Cumulative Model Updates: 254,682
Cumulative Timesteps: 2,124,017,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2124017426...
Checkpoint 2124017426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.97095
Policy Entropy: 2.08290
Value Function Loss: 0.01929

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.63122

Collected Steps per Second: 22,607.47260
Overall Steps per Second: 10,787.57352

Timestep Collection Time: 2.21272
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.63719

Cumulative Model Updates: 254,688
Cumulative Timesteps: 2,124,067,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.84871
Policy Entropy: 2.06589
Value Function Loss: 0.01957

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.65268

Collected Steps per Second: 23,047.59195
Overall Steps per Second: 10,913.20829

Timestep Collection Time: 2.16994
Timestep Consumption Time: 2.41276
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.58270

Cumulative Model Updates: 254,694
Cumulative Timesteps: 2,124,117,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2124117462...
Checkpoint 2124117462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.10007
Policy Entropy: 2.05436
Value Function Loss: 0.01910

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.67348

Collected Steps per Second: 22,179.90061
Overall Steps per Second: 10,687.63218

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.68055

Cumulative Model Updates: 254,700
Cumulative Timesteps: 2,124,167,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.86178
Policy Entropy: 2.05938
Value Function Loss: 0.01936

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.65918

Collected Steps per Second: 23,047.83174
Overall Steps per Second: 10,885.78475

Timestep Collection Time: 2.17001
Timestep Consumption Time: 2.42442
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59443

Cumulative Model Updates: 254,706
Cumulative Timesteps: 2,124,217,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2124217500...
Checkpoint 2124217500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.88704
Policy Entropy: 2.05310
Value Function Loss: 0.01906

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.64334

Collected Steps per Second: 22,476.59321
Overall Steps per Second: 10,684.80700

Timestep Collection Time: 2.22507
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.68066

Cumulative Model Updates: 254,712
Cumulative Timesteps: 2,124,267,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.41116
Policy Entropy: 2.05958
Value Function Loss: 0.01919

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.15015
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.65324

Collected Steps per Second: 22,947.71542
Overall Steps per Second: 10,939.67735

Timestep Collection Time: 2.18009
Timestep Consumption Time: 2.39299
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.57308

Cumulative Model Updates: 254,718
Cumulative Timesteps: 2,124,317,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2124317540...
Checkpoint 2124317540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.24972
Policy Entropy: 2.08747
Value Function Loss: 0.01787

Mean KL Divergence: 0.03212
SB3 Clip Fraction: 0.17926
Policy Update Magnitude: 0.51146
Value Function Update Magnitude: 0.67209

Collected Steps per Second: 22,918.76897
Overall Steps per Second: 10,663.05145

Timestep Collection Time: 2.18223
Timestep Consumption Time: 2.50817
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69040

Cumulative Model Updates: 254,724
Cumulative Timesteps: 2,124,367,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.86899
Policy Entropy: 2.08807
Value Function Loss: 0.01787

Mean KL Divergence: 0.03029
SB3 Clip Fraction: 0.17396
Policy Update Magnitude: 0.51844
Value Function Update Magnitude: 0.68267

Collected Steps per Second: 23,290.19148
Overall Steps per Second: 10,976.57307

Timestep Collection Time: 2.14743
Timestep Consumption Time: 2.40900
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.55643

Cumulative Model Updates: 254,730
Cumulative Timesteps: 2,124,417,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2124417568...
Checkpoint 2124417568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.55304
Policy Entropy: 2.08613
Value Function Loss: 0.01704

Mean KL Divergence: 0.03520
SB3 Clip Fraction: 0.18425
Policy Update Magnitude: 0.51906
Value Function Update Magnitude: 0.67998

Collected Steps per Second: 22,762.12789
Overall Steps per Second: 10,679.92536

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68430

Cumulative Model Updates: 254,736
Cumulative Timesteps: 2,124,467,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.25063
Policy Entropy: 2.06462
Value Function Loss: 0.01735

Mean KL Divergence: 0.03647
SB3 Clip Fraction: 0.19477
Policy Update Magnitude: 0.50440
Value Function Update Magnitude: 0.67812

Collected Steps per Second: 23,291.30721
Overall Steps per Second: 10,752.03378

Timestep Collection Time: 2.14741
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.65177

Cumulative Model Updates: 254,742
Cumulative Timesteps: 2,124,517,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2124517612...
Checkpoint 2124517612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.81289
Policy Entropy: 2.05958
Value Function Loss: 0.01887

Mean KL Divergence: 0.03104
SB3 Clip Fraction: 0.18028
Policy Update Magnitude: 0.54999
Value Function Update Magnitude: 0.68714

Collected Steps per Second: 23,047.90348
Overall Steps per Second: 10,849.12666

Timestep Collection Time: 2.17052
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.61106

Cumulative Model Updates: 254,748
Cumulative Timesteps: 2,124,567,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.09202
Policy Entropy: 2.06744
Value Function Loss: 0.01859

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.16917
Policy Update Magnitude: 0.56097
Value Function Update Magnitude: 0.70488

Collected Steps per Second: 23,250.46870
Overall Steps per Second: 11,147.05619

Timestep Collection Time: 2.15144
Timestep Consumption Time: 2.33602
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.48746

Cumulative Model Updates: 254,754
Cumulative Timesteps: 2,124,617,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2124617660...
Checkpoint 2124617660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.68254
Policy Entropy: 2.06771
Value Function Loss: 0.01927

Mean KL Divergence: 0.02973
SB3 Clip Fraction: 0.17238
Policy Update Magnitude: 0.52212
Value Function Update Magnitude: 0.67980

Collected Steps per Second: 22,266.21994
Overall Steps per Second: 10,663.47699

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.44364
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.68946

Cumulative Model Updates: 254,760
Cumulative Timesteps: 2,124,667,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.61401
Policy Entropy: 2.08820
Value Function Loss: 0.01874

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.15800
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.66768

Collected Steps per Second: 22,646.37825
Overall Steps per Second: 10,784.68214

Timestep Collection Time: 2.20812
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.63676

Cumulative Model Updates: 254,766
Cumulative Timesteps: 2,124,717,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2124717672...
Checkpoint 2124717672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.84340
Policy Entropy: 2.08437
Value Function Loss: 0.01974

Mean KL Divergence: 0.03203
SB3 Clip Fraction: 0.17991
Policy Update Magnitude: 0.54074
Value Function Update Magnitude: 0.67181

Collected Steps per Second: 22,169.70197
Overall Steps per Second: 10,752.07200

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.39513
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.65064

Cumulative Model Updates: 254,772
Cumulative Timesteps: 2,124,767,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.40969
Policy Entropy: 2.07101
Value Function Loss: 0.01907

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.17488
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.67112

Collected Steps per Second: 22,377.26060
Overall Steps per Second: 10,659.24222

Timestep Collection Time: 2.23450
Timestep Consumption Time: 2.45645
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.69095

Cumulative Model Updates: 254,778
Cumulative Timesteps: 2,124,817,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2124817678...
Checkpoint 2124817678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.72517
Policy Entropy: 2.06386
Value Function Loss: 0.01752

Mean KL Divergence: 0.03407
SB3 Clip Fraction: 0.18615
Policy Update Magnitude: 0.53161
Value Function Update Magnitude: 0.66581

Collected Steps per Second: 22,482.96466
Overall Steps per Second: 10,901.29747

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.36270
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.58661

Cumulative Model Updates: 254,784
Cumulative Timesteps: 2,124,867,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.26160
Policy Entropy: 2.06761
Value Function Loss: 0.01799

Mean KL Divergence: 0.03395
SB3 Clip Fraction: 0.18247
Policy Update Magnitude: 0.50915
Value Function Update Magnitude: 0.65345

Collected Steps per Second: 23,467.30677
Overall Steps per Second: 10,839.59469

Timestep Collection Time: 2.13165
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.61493

Cumulative Model Updates: 254,790
Cumulative Timesteps: 2,124,917,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2124917702...
Checkpoint 2124917702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.69344
Policy Entropy: 2.08051
Value Function Loss: 0.01748

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.65088

Collected Steps per Second: 22,718.52408
Overall Steps per Second: 10,626.14255

Timestep Collection Time: 2.20164
Timestep Consumption Time: 2.50543
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.70707

Cumulative Model Updates: 254,796
Cumulative Timesteps: 2,124,967,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.14075
Policy Entropy: 2.06104
Value Function Loss: 0.01957

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.55651
Value Function Update Magnitude: 0.65879

Collected Steps per Second: 23,248.30877
Overall Steps per Second: 10,922.66968

Timestep Collection Time: 2.15138
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.57910

Cumulative Model Updates: 254,802
Cumulative Timesteps: 2,125,017,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2125017736...
Checkpoint 2125017736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.98020
Policy Entropy: 2.06087
Value Function Loss: 0.01878

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.55407
Value Function Update Magnitude: 0.66286

Collected Steps per Second: 21,537.88212
Overall Steps per Second: 10,666.48673

Timestep Collection Time: 2.32223
Timestep Consumption Time: 2.36685
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68908

Cumulative Model Updates: 254,808
Cumulative Timesteps: 2,125,067,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.76384
Policy Entropy: 2.07026
Value Function Loss: 0.01809

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.54228
Value Function Update Magnitude: 0.65054

Collected Steps per Second: 23,092.34491
Overall Steps per Second: 10,881.09767

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59733

Cumulative Model Updates: 254,814
Cumulative Timesteps: 2,125,117,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2125117776...
Checkpoint 2125117776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.44126
Policy Entropy: 2.07666
Value Function Loss: 0.01819

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.63277

Collected Steps per Second: 22,378.41119
Overall Steps per Second: 10,764.80831

Timestep Collection Time: 2.23474
Timestep Consumption Time: 2.41095
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.64569

Cumulative Model Updates: 254,820
Cumulative Timesteps: 2,125,167,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.74113
Policy Entropy: 2.10867
Value Function Loss: 0.01772

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.52938
Value Function Update Magnitude: 0.63526

Collected Steps per Second: 22,953.65136
Overall Steps per Second: 10,848.08004

Timestep Collection Time: 2.17839
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.60929

Cumulative Model Updates: 254,826
Cumulative Timesteps: 2,125,217,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2125217788...
Checkpoint 2125217788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.52522
Policy Entropy: 2.09268
Value Function Loss: 0.01934

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.53745
Value Function Update Magnitude: 0.63838

Collected Steps per Second: 22,258.56142
Overall Steps per Second: 10,713.26615

Timestep Collection Time: 2.24740
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.66935

Cumulative Model Updates: 254,832
Cumulative Timesteps: 2,125,267,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.34596
Policy Entropy: 2.06636
Value Function Loss: 0.01797

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.54400
Value Function Update Magnitude: 0.65118

Collected Steps per Second: 22,995.97865
Overall Steps per Second: 10,806.69142

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.62676

Cumulative Model Updates: 254,838
Cumulative Timesteps: 2,125,317,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2125317812...
Checkpoint 2125317812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.68793
Policy Entropy: 2.05952
Value Function Loss: 0.01808

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.54452
Value Function Update Magnitude: 0.66815

Collected Steps per Second: 22,080.78966
Overall Steps per Second: 10,647.10877

Timestep Collection Time: 2.26468
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69667

Cumulative Model Updates: 254,844
Cumulative Timesteps: 2,125,367,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.12002
Policy Entropy: 2.08748
Value Function Loss: 0.01692

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.65960

Collected Steps per Second: 23,281.44326
Overall Steps per Second: 10,937.61626

Timestep Collection Time: 2.14798
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.57211

Cumulative Model Updates: 254,850
Cumulative Timesteps: 2,125,417,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2125417826...
Checkpoint 2125417826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.59120
Policy Entropy: 2.10178
Value Function Loss: 0.01732

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.64302

Collected Steps per Second: 22,843.78436
Overall Steps per Second: 11,012.58572

Timestep Collection Time: 2.18895
Timestep Consumption Time: 2.35167
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.54062

Cumulative Model Updates: 254,856
Cumulative Timesteps: 2,125,467,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.79558
Policy Entropy: 2.09419
Value Function Loss: 0.01780

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.53662
Value Function Update Magnitude: 0.64509

Collected Steps per Second: 23,373.35341
Overall Steps per Second: 10,937.53782

Timestep Collection Time: 2.14030
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.57379

Cumulative Model Updates: 254,862
Cumulative Timesteps: 2,125,517,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2125517856...
Checkpoint 2125517856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.41086
Policy Entropy: 2.06854
Value Function Loss: 0.01894

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.63523

Collected Steps per Second: 22,672.58538
Overall Steps per Second: 10,687.33797

Timestep Collection Time: 2.20672
Timestep Consumption Time: 2.47471
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.68143

Cumulative Model Updates: 254,868
Cumulative Timesteps: 2,125,567,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.24751
Policy Entropy: 2.07534
Value Function Loss: 0.01967

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.63807

Collected Steps per Second: 23,155.86490
Overall Steps per Second: 10,933.86235

Timestep Collection Time: 2.16040
Timestep Consumption Time: 2.41492
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.57533

Cumulative Model Updates: 254,874
Cumulative Timesteps: 2,125,617,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2125617914...
Checkpoint 2125617914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.90335
Policy Entropy: 2.04782
Value Function Loss: 0.02067

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.54189
Value Function Update Magnitude: 0.66225

Collected Steps per Second: 22,412.08509
Overall Steps per Second: 10,785.42956

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.40639
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.63867

Cumulative Model Updates: 254,880
Cumulative Timesteps: 2,125,667,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.61133
Policy Entropy: 2.05852
Value Function Loss: 0.02034

Mean KL Divergence: 0.02859
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.53707
Value Function Update Magnitude: 0.65971

Collected Steps per Second: 22,859.09059
Overall Steps per Second: 10,759.15320

Timestep Collection Time: 2.18863
Timestep Consumption Time: 2.46137
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.64999

Cumulative Model Updates: 254,886
Cumulative Timesteps: 2,125,717,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2125717974...
Checkpoint 2125717974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.84411
Policy Entropy: 2.05449
Value Function Loss: 0.01985

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.65704

Collected Steps per Second: 22,382.65736
Overall Steps per Second: 10,644.66500

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.46479
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.70001

Cumulative Model Updates: 254,892
Cumulative Timesteps: 2,125,768,004

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.18738
Policy Entropy: 2.07487
Value Function Loss: 0.01788

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.63923

Collected Steps per Second: 22,858.49916
Overall Steps per Second: 10,887.37815

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.40520
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59266

Cumulative Model Updates: 254,898
Cumulative Timesteps: 2,125,818,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2125818006...
Checkpoint 2125818006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.86192
Policy Entropy: 2.07257
Value Function Loss: 0.01742

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.53971
Value Function Update Magnitude: 0.62669

Collected Steps per Second: 22,131.33761
Overall Steps per Second: 10,691.41347

Timestep Collection Time: 2.26060
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.67946

Cumulative Model Updates: 254,904
Cumulative Timesteps: 2,125,868,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.95855
Policy Entropy: 2.07294
Value Function Loss: 0.01868

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.54064
Value Function Update Magnitude: 0.62367

Collected Steps per Second: 23,323.56350
Overall Steps per Second: 10,912.18155

Timestep Collection Time: 2.14470
Timestep Consumption Time: 2.43935
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.58405

Cumulative Model Updates: 254,910
Cumulative Timesteps: 2,125,918,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2125918058...
Checkpoint 2125918058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.13751
Policy Entropy: 2.06757
Value Function Loss: 0.02023

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.63702

Collected Steps per Second: 22,890.13304
Overall Steps per Second: 10,685.01334

Timestep Collection Time: 2.18531
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.68151

Cumulative Model Updates: 254,916
Cumulative Timesteps: 2,125,968,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.95158
Policy Entropy: 2.08002
Value Function Loss: 0.02015

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.55093
Value Function Update Magnitude: 0.66114

Collected Steps per Second: 22,649.84846
Overall Steps per Second: 10,765.64432

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.64719

Cumulative Model Updates: 254,922
Cumulative Timesteps: 2,126,018,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2126018110...
Checkpoint 2126018110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.30373
Policy Entropy: 2.07772
Value Function Loss: 0.01896

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.54433
Value Function Update Magnitude: 0.65773

Collected Steps per Second: 22,795.68569
Overall Steps per Second: 10,707.95746

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.66942

Cumulative Model Updates: 254,928
Cumulative Timesteps: 2,126,068,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.28495
Policy Entropy: 2.08226
Value Function Loss: 0.01776

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.52867
Value Function Update Magnitude: 0.64275

Collected Steps per Second: 24,155.12127
Overall Steps per Second: 10,960.44264

Timestep Collection Time: 2.07078
Timestep Consumption Time: 2.49290
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.56368

Cumulative Model Updates: 254,934
Cumulative Timesteps: 2,126,118,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2126118130...
Checkpoint 2126118130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.63161
Policy Entropy: 2.07576
Value Function Loss: 0.01749

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.52576
Value Function Update Magnitude: 0.62150

Collected Steps per Second: 22,642.01987
Overall Steps per Second: 10,656.47154

Timestep Collection Time: 2.20899
Timestep Consumption Time: 2.48450
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.69349

Cumulative Model Updates: 254,940
Cumulative Timesteps: 2,126,168,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.45232
Policy Entropy: 2.09029
Value Function Loss: 0.01772

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.52786
Value Function Update Magnitude: 0.60793

Collected Steps per Second: 22,826.81649
Overall Steps per Second: 10,824.27122

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61943

Cumulative Model Updates: 254,946
Cumulative Timesteps: 2,126,218,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2126218148...
Checkpoint 2126218148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.66020
Policy Entropy: 2.10532
Value Function Loss: 0.01663

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.52546
Value Function Update Magnitude: 0.60071

Collected Steps per Second: 22,342.58533
Overall Steps per Second: 10,755.60050

Timestep Collection Time: 2.23913
Timestep Consumption Time: 2.41221
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.65134

Cumulative Model Updates: 254,952
Cumulative Timesteps: 2,126,268,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.21730
Policy Entropy: 2.11070
Value Function Loss: 0.01708

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.52191
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 22,767.90309
Overall Steps per Second: 10,850.72317

Timestep Collection Time: 2.19607
Timestep Consumption Time: 2.41191
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.60799

Cumulative Model Updates: 254,958
Cumulative Timesteps: 2,126,318,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2126318176...
Checkpoint 2126318176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.85729
Policy Entropy: 2.08879
Value Function Loss: 0.01655

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.52783
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 22,044.20894
Overall Steps per Second: 10,580.72610

Timestep Collection Time: 2.26853
Timestep Consumption Time: 2.45780
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.72633

Cumulative Model Updates: 254,964
Cumulative Timesteps: 2,126,368,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.35174
Policy Entropy: 2.07365
Value Function Loss: 0.01864

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.52776
Value Function Update Magnitude: 0.62071

Collected Steps per Second: 23,271.15195
Overall Steps per Second: 10,720.35005

Timestep Collection Time: 2.14970
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.66645

Cumulative Model Updates: 254,970
Cumulative Timesteps: 2,126,418,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2126418210...
Checkpoint 2126418210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.92672
Policy Entropy: 2.08064
Value Function Loss: 0.01771

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.52734
Value Function Update Magnitude: 0.63621

Collected Steps per Second: 22,550.80693
Overall Steps per Second: 10,789.45242

Timestep Collection Time: 2.21846
Timestep Consumption Time: 2.41829
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.63675

Cumulative Model Updates: 254,976
Cumulative Timesteps: 2,126,468,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.63135
Policy Entropy: 2.07797
Value Function Loss: 0.01926

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.64677

Collected Steps per Second: 23,060.14134
Overall Steps per Second: 11,013.81340

Timestep Collection Time: 2.16902
Timestep Consumption Time: 2.37236
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.54139

Cumulative Model Updates: 254,982
Cumulative Timesteps: 2,126,518,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2126518256...
Checkpoint 2126518256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.73588
Policy Entropy: 2.07327
Value Function Loss: 0.01869

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.65788

Collected Steps per Second: 22,618.55135
Overall Steps per Second: 10,611.92754

Timestep Collection Time: 2.21128
Timestep Consumption Time: 2.50190
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.71319

Cumulative Model Updates: 254,988
Cumulative Timesteps: 2,126,568,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.55530
Policy Entropy: 2.04364
Value Function Loss: 0.01983

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.65800

Collected Steps per Second: 23,279.53118
Overall Steps per Second: 10,937.39081

Timestep Collection Time: 2.14867
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.57330

Cumulative Model Updates: 254,994
Cumulative Timesteps: 2,126,618,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2126618292...
Checkpoint 2126618292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.06575
Policy Entropy: 2.04753
Value Function Loss: 0.01953

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.53877
Value Function Update Magnitude: 0.66626

Collected Steps per Second: 22,388.57669
Overall Steps per Second: 10,610.57420

Timestep Collection Time: 2.23453
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.71492

Cumulative Model Updates: 255,000
Cumulative Timesteps: 2,126,668,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.34983
Policy Entropy: 2.03797
Value Function Loss: 0.02037

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.66780

Collected Steps per Second: 22,917.66608
Overall Steps per Second: 10,941.07983

Timestep Collection Time: 2.18294
Timestep Consumption Time: 2.38955
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.57249

Cumulative Model Updates: 255,006
Cumulative Timesteps: 2,126,718,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2126718348...
Checkpoint 2126718348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.03026
Policy Entropy: 2.03552
Value Function Loss: 0.02002

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.66451

Collected Steps per Second: 22,333.51810
Overall Steps per Second: 10,662.36686

Timestep Collection Time: 2.23888
Timestep Consumption Time: 2.45070
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.68958

Cumulative Model Updates: 255,012
Cumulative Timesteps: 2,126,768,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.76271
Policy Entropy: 2.04731
Value Function Loss: 0.01961

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.66214

Collected Steps per Second: 23,156.49039
Overall Steps per Second: 10,867.33246

Timestep Collection Time: 2.15991
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60242

Cumulative Model Updates: 255,018
Cumulative Timesteps: 2,126,818,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2126818366...
Checkpoint 2126818366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.81236
Policy Entropy: 2.06013
Value Function Loss: 0.01943

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.54194
Value Function Update Magnitude: 0.66331

Collected Steps per Second: 22,496.05350
Overall Steps per Second: 10,658.02103

Timestep Collection Time: 2.22323
Timestep Consumption Time: 2.46938
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.69262

Cumulative Model Updates: 255,024
Cumulative Timesteps: 2,126,868,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.16481
Policy Entropy: 2.07046
Value Function Loss: 0.02004

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.66823

Collected Steps per Second: 23,342.64621
Overall Steps per Second: 10,939.25796

Timestep Collection Time: 2.14252
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.57179

Cumulative Model Updates: 255,030
Cumulative Timesteps: 2,126,918,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2126918392...
Checkpoint 2126918392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.00399
Policy Entropy: 2.07298
Value Function Loss: 0.01981

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.68603

Collected Steps per Second: 23,075.66370
Overall Steps per Second: 10,785.66593

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.63652

Cumulative Model Updates: 255,036
Cumulative Timesteps: 2,126,968,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.71688
Policy Entropy: 2.05782
Value Function Loss: 0.01926

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.65574

Collected Steps per Second: 22,325.05438
Overall Steps per Second: 10,716.61577

Timestep Collection Time: 2.24026
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.66696

Cumulative Model Updates: 255,042
Cumulative Timesteps: 2,127,018,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2127018414...
Checkpoint 2127018414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.40530
Policy Entropy: 2.05990
Value Function Loss: 0.01861

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.53429
Value Function Update Magnitude: 0.62243

Collected Steps per Second: 22,254.32721
Overall Steps per Second: 10,639.95508

Timestep Collection Time: 2.24693
Timestep Consumption Time: 2.45271
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.69964

Cumulative Model Updates: 255,048
Cumulative Timesteps: 2,127,068,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.99716
Policy Entropy: 2.06333
Value Function Loss: 0.01853

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.53355
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 23,771.57609
Overall Steps per Second: 10,935.68708

Timestep Collection Time: 2.10352
Timestep Consumption Time: 2.46903
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.57255

Cumulative Model Updates: 255,054
Cumulative Timesteps: 2,127,118,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2127118422...
Checkpoint 2127118422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.31126
Policy Entropy: 2.06526
Value Function Loss: 0.01898

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.53834
Value Function Update Magnitude: 0.60946

Collected Steps per Second: 22,745.05270
Overall Steps per Second: 10,619.27487

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.70936

Cumulative Model Updates: 255,060
Cumulative Timesteps: 2,127,168,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.99836
Policy Entropy: 2.05804
Value Function Loss: 0.01926

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.53744
Value Function Update Magnitude: 0.60088

Collected Steps per Second: 23,361.97919
Overall Steps per Second: 10,896.90818

Timestep Collection Time: 2.14091
Timestep Consumption Time: 2.44901
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.58993

Cumulative Model Updates: 255,066
Cumulative Timesteps: 2,127,218,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2127218448...
Checkpoint 2127218448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.80306
Policy Entropy: 2.04604
Value Function Loss: 0.01870

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.60469

Collected Steps per Second: 22,569.47123
Overall Steps per Second: 10,823.05916

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.40573
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.62235

Cumulative Model Updates: 255,072
Cumulative Timesteps: 2,127,268,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.34972
Policy Entropy: 2.03268
Value Function Loss: 0.01942

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.61857

Collected Steps per Second: 23,551.21971
Overall Steps per Second: 10,854.17165

Timestep Collection Time: 2.12346
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.60745

Cumulative Model Updates: 255,078
Cumulative Timesteps: 2,127,318,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2127318486...
Checkpoint 2127318486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.07230
Policy Entropy: 2.02151
Value Function Loss: 0.01968

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.62901

Collected Steps per Second: 22,844.07501
Overall Steps per Second: 10,708.45392

Timestep Collection Time: 2.18936
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.67052

Cumulative Model Updates: 255,084
Cumulative Timesteps: 2,127,368,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.12998
Policy Entropy: 2.02862
Value Function Loss: 0.01962

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.63046

Collected Steps per Second: 23,506.34403
Overall Steps per Second: 10,921.46851

Timestep Collection Time: 2.12836
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.58089

Cumulative Model Updates: 255,090
Cumulative Timesteps: 2,127,418,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2127418530...
Checkpoint 2127418530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.78179
Policy Entropy: 2.05981
Value Function Loss: 0.01953

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.54922
Value Function Update Magnitude: 0.61532

Collected Steps per Second: 22,660.57371
Overall Steps per Second: 10,933.70921

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.36739
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.57466

Cumulative Model Updates: 255,096
Cumulative Timesteps: 2,127,468,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.43297
Policy Entropy: 2.07442
Value Function Loss: 0.01952

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.61471

Collected Steps per Second: 22,886.26905
Overall Steps per Second: 10,846.09894

Timestep Collection Time: 2.18533
Timestep Consumption Time: 2.42592
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61124

Cumulative Model Updates: 255,102
Cumulative Timesteps: 2,127,518,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2127518562...
Checkpoint 2127518562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.85810
Policy Entropy: 2.07966
Value Function Loss: 0.01967

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.54221
Value Function Update Magnitude: 0.62611

Collected Steps per Second: 22,398.97973
Overall Steps per Second: 10,708.58056

Timestep Collection Time: 2.23251
Timestep Consumption Time: 2.43720
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.66971

Cumulative Model Updates: 255,108
Cumulative Timesteps: 2,127,568,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.20650
Policy Entropy: 2.08459
Value Function Loss: 0.01938

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.52806
Value Function Update Magnitude: 0.61964

Collected Steps per Second: 22,977.48924
Overall Steps per Second: 10,851.88466

Timestep Collection Time: 2.17709
Timestep Consumption Time: 2.43262
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60971

Cumulative Model Updates: 255,114
Cumulative Timesteps: 2,127,618,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2127618592...
Checkpoint 2127618592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.84122
Policy Entropy: 2.07082
Value Function Loss: 0.02004

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.53350
Value Function Update Magnitude: 0.59623

Collected Steps per Second: 22,851.13369
Overall Steps per Second: 11,010.39514

Timestep Collection Time: 2.18904
Timestep Consumption Time: 2.35412
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.54316

Cumulative Model Updates: 255,120
Cumulative Timesteps: 2,127,668,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.59635
Policy Entropy: 2.06558
Value Function Loss: 0.02001

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.59719

Collected Steps per Second: 23,132.31036
Overall Steps per Second: 10,746.49903

Timestep Collection Time: 2.16226
Timestep Consumption Time: 2.49210
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.65435

Cumulative Model Updates: 255,126
Cumulative Timesteps: 2,127,718,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2127718632...
Checkpoint 2127718632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.17803
Policy Entropy: 2.06340
Value Function Loss: 0.01997

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.53331
Value Function Update Magnitude: 0.61335

Collected Steps per Second: 22,573.64150
Overall Steps per Second: 10,848.15587

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.39545
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.61166

Cumulative Model Updates: 255,132
Cumulative Timesteps: 2,127,768,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.50988
Policy Entropy: 2.09092
Value Function Loss: 0.01860

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.52561
Value Function Update Magnitude: 0.61543

Collected Steps per Second: 23,107.36483
Overall Steps per Second: 11,011.52656

Timestep Collection Time: 2.16416
Timestep Consumption Time: 2.37726
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.54142

Cumulative Model Updates: 255,138
Cumulative Timesteps: 2,127,818,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2127818668...
Checkpoint 2127818668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.36965
Policy Entropy: 2.08447
Value Function Loss: 0.01943

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.63361

Collected Steps per Second: 22,520.68704
Overall Steps per Second: 10,621.95115

Timestep Collection Time: 2.22098
Timestep Consumption Time: 2.48795
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.70893

Cumulative Model Updates: 255,144
Cumulative Timesteps: 2,127,868,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.37577
Policy Entropy: 2.07777
Value Function Loss: 0.01871

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.65167

Collected Steps per Second: 22,918.48505
Overall Steps per Second: 10,859.52219

Timestep Collection Time: 2.18234
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.60573

Cumulative Model Updates: 255,150
Cumulative Timesteps: 2,127,918,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2127918702...
Checkpoint 2127918702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.19390
Policy Entropy: 2.07150
Value Function Loss: 0.01872

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.63185

Collected Steps per Second: 22,064.09401
Overall Steps per Second: 10,694.63504

Timestep Collection Time: 2.26748
Timestep Consumption Time: 2.41056
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.67805

Cumulative Model Updates: 255,156
Cumulative Timesteps: 2,127,968,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.91093
Policy Entropy: 2.10038
Value Function Loss: 0.01844

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.63193

Collected Steps per Second: 22,685.03948
Overall Steps per Second: 10,912.42095

Timestep Collection Time: 2.20480
Timestep Consumption Time: 2.37860
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.58340

Cumulative Model Updates: 255,162
Cumulative Timesteps: 2,128,018,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2128018748...
Checkpoint 2128018748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.95374
Policy Entropy: 2.08831
Value Function Loss: 0.01786

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.53181
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,535.10615
Overall Steps per Second: 10,630.61767

Timestep Collection Time: 2.21885
Timestep Consumption Time: 2.48473
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.70358

Cumulative Model Updates: 255,168
Cumulative Timesteps: 2,128,068,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.97337
Policy Entropy: 2.08971
Value Function Loss: 0.01830

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.62269

Collected Steps per Second: 23,415.63963
Overall Steps per Second: 10,898.82040

Timestep Collection Time: 2.13618
Timestep Consumption Time: 2.45331
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.58949

Cumulative Model Updates: 255,174
Cumulative Timesteps: 2,128,118,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2128118770...
Checkpoint 2128118770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.55079
Policy Entropy: 2.06187
Value Function Loss: 0.01853

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.53066
Value Function Update Magnitude: 0.61222

Collected Steps per Second: 23,125.23748
Overall Steps per Second: 10,813.54444

Timestep Collection Time: 2.16309
Timestep Consumption Time: 2.46277
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.62587

Cumulative Model Updates: 255,180
Cumulative Timesteps: 2,128,168,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.85469
Policy Entropy: 2.06371
Value Function Loss: 0.01927

Mean KL Divergence: 0.02775
SB3 Clip Fraction: 0.16633
Policy Update Magnitude: 0.51080
Value Function Update Magnitude: 0.63949

Collected Steps per Second: 23,383.58885
Overall Steps per Second: 11,138.12777

Timestep Collection Time: 2.13894
Timestep Consumption Time: 2.35159
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.49052

Cumulative Model Updates: 255,186
Cumulative Timesteps: 2,128,218,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2128218808...
Checkpoint 2128218808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.76666
Policy Entropy: 2.06219
Value Function Loss: 0.01858

Mean KL Divergence: 0.02549
SB3 Clip Fraction: 0.15726
Policy Update Magnitude: 0.51238
Value Function Update Magnitude: 0.66763

Collected Steps per Second: 22,446.31942
Overall Steps per Second: 10,768.78762

Timestep Collection Time: 2.22834
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.64472

Cumulative Model Updates: 255,192
Cumulative Timesteps: 2,128,268,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.90704
Policy Entropy: 2.04700
Value Function Loss: 0.01880

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.14966
Policy Update Magnitude: 0.52463
Value Function Update Magnitude: 0.65481

Collected Steps per Second: 23,415.61523
Overall Steps per Second: 10,886.08880

Timestep Collection Time: 2.13601
Timestep Consumption Time: 2.45848
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.59449

Cumulative Model Updates: 255,198
Cumulative Timesteps: 2,128,318,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2128318842...
Checkpoint 2128318842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.66283
Policy Entropy: 2.04705
Value Function Loss: 0.01958

Mean KL Divergence: 0.02723
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 0.53747
Value Function Update Magnitude: 0.63024

Collected Steps per Second: 22,142.47669
Overall Steps per Second: 10,591.08285

Timestep Collection Time: 2.25955
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.72397

Cumulative Model Updates: 255,204
Cumulative Timesteps: 2,128,368,874

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.89837
Policy Entropy: 2.05005
Value Function Loss: 0.02069

Mean KL Divergence: 0.03169
SB3 Clip Fraction: 0.18203
Policy Update Magnitude: 0.49958
Value Function Update Magnitude: 0.61390

Collected Steps per Second: 22,900.32921
Overall Steps per Second: 10,946.61109

Timestep Collection Time: 2.18381
Timestep Consumption Time: 2.38473
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.56854

Cumulative Model Updates: 255,210
Cumulative Timesteps: 2,128,418,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2128418884...
Checkpoint 2128418884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.29681
Policy Entropy: 2.05722
Value Function Loss: 0.02021

Mean KL Divergence: 0.02754
SB3 Clip Fraction: 0.16337
Policy Update Magnitude: 0.52632
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 22,247.07956
Overall Steps per Second: 10,612.77353

Timestep Collection Time: 2.24856
Timestep Consumption Time: 2.46500
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.71357

Cumulative Model Updates: 255,216
Cumulative Timesteps: 2,128,468,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.37431
Policy Entropy: 2.03673
Value Function Loss: 0.02070

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.15562
Policy Update Magnitude: 0.54148
Value Function Update Magnitude: 0.61911

Collected Steps per Second: 23,295.52369
Overall Steps per Second: 10,984.20415

Timestep Collection Time: 2.14651
Timestep Consumption Time: 2.40585
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.55236

Cumulative Model Updates: 255,222
Cumulative Timesteps: 2,128,518,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2128518912...
Checkpoint 2128518912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.34855
Policy Entropy: 2.03182
Value Function Loss: 0.01984

Mean KL Divergence: 0.02758
SB3 Clip Fraction: 0.16840
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.64099

Collected Steps per Second: 22,821.94635
Overall Steps per Second: 10,649.42210

Timestep Collection Time: 2.19210
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.69772

Cumulative Model Updates: 255,228
Cumulative Timesteps: 2,128,568,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.37367
Policy Entropy: 2.03611
Value Function Loss: 0.02086

Mean KL Divergence: 0.03015
SB3 Clip Fraction: 0.16963
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 23,137.19508
Overall Steps per Second: 10,864.29263

Timestep Collection Time: 2.16137
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.60297

Cumulative Model Updates: 255,234
Cumulative Timesteps: 2,128,618,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2128618948...
Checkpoint 2128618948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.90931
Policy Entropy: 2.03801
Value Function Loss: 0.01985

Mean KL Divergence: 0.03360
SB3 Clip Fraction: 0.17987
Policy Update Magnitude: 0.54499
Value Function Update Magnitude: 0.69283

Collected Steps per Second: 22,818.54350
Overall Steps per Second: 10,609.62258

Timestep Collection Time: 2.19243
Timestep Consumption Time: 2.52291
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.71534

Cumulative Model Updates: 255,240
Cumulative Timesteps: 2,128,668,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.37731
Policy Entropy: 2.03950
Value Function Loss: 0.01926

Mean KL Divergence: 0.02970
SB3 Clip Fraction: 0.16480
Policy Update Magnitude: 0.54447
Value Function Update Magnitude: 0.70478

Collected Steps per Second: 23,263.78194
Overall Steps per Second: 10,935.98959

Timestep Collection Time: 2.15047
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.57462

Cumulative Model Updates: 255,246
Cumulative Timesteps: 2,128,719,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2128719004...
Checkpoint 2128719004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.93776
Policy Entropy: 2.04058
Value Function Loss: 0.01845

Mean KL Divergence: 0.02553
SB3 Clip Fraction: 0.15652
Policy Update Magnitude: 0.53423
Value Function Update Magnitude: 0.67420

Collected Steps per Second: 22,552.92655
Overall Steps per Second: 10,799.85457

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.63228

Cumulative Model Updates: 255,252
Cumulative Timesteps: 2,128,769,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.05294
Policy Entropy: 2.03982
Value Function Loss: 0.01969

Mean KL Divergence: 0.02977
SB3 Clip Fraction: 0.17194
Policy Update Magnitude: 0.51958
Value Function Update Magnitude: 0.66286

Collected Steps per Second: 23,274.37487
Overall Steps per Second: 10,750.61161

Timestep Collection Time: 2.14880
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.65201

Cumulative Model Updates: 255,258
Cumulative Timesteps: 2,128,819,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2128819044...
Checkpoint 2128819044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.68847
Policy Entropy: 2.05542
Value Function Loss: 0.02038

Mean KL Divergence: 0.02703
SB3 Clip Fraction: 0.16257
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.67111

Collected Steps per Second: 22,321.29612
Overall Steps per Second: 10,684.14102

Timestep Collection Time: 2.24136
Timestep Consumption Time: 2.44128
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.68264

Cumulative Model Updates: 255,264
Cumulative Timesteps: 2,128,869,074

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.23139
Policy Entropy: 2.05617
Value Function Loss: 0.01992

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.15694
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.67100

Collected Steps per Second: 22,207.31121
Overall Steps per Second: 10,576.91614

Timestep Collection Time: 2.25277
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.72992

Cumulative Model Updates: 255,270
Cumulative Timesteps: 2,128,919,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2128919102...
Checkpoint 2128919102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.95169
Policy Entropy: 2.07523
Value Function Loss: 0.01906

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.56138
Value Function Update Magnitude: 0.66071

Collected Steps per Second: 22,187.37454
Overall Steps per Second: 10,886.51033

Timestep Collection Time: 2.25425
Timestep Consumption Time: 2.34005
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.59431

Cumulative Model Updates: 255,276
Cumulative Timesteps: 2,128,969,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.95467
Policy Entropy: 2.07086
Value Function Loss: 0.01924

Mean KL Divergence: 0.02447
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.65473

Collected Steps per Second: 23,210.85756
Overall Steps per Second: 10,894.23596

Timestep Collection Time: 2.15563
Timestep Consumption Time: 2.43707
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59270

Cumulative Model Updates: 255,282
Cumulative Timesteps: 2,129,019,152

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2129019152...
Checkpoint 2129019152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.07907
Policy Entropy: 2.06264
Value Function Loss: 0.01908

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,170.17620
Overall Steps per Second: 10,631.24522

Timestep Collection Time: 2.25664
Timestep Consumption Time: 2.44930
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.70594

Cumulative Model Updates: 255,288
Cumulative Timesteps: 2,129,069,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.85505
Policy Entropy: 2.03178
Value Function Loss: 0.01950

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.55062
Value Function Update Magnitude: 0.66701

Collected Steps per Second: 23,188.27148
Overall Steps per Second: 10,921.27836

Timestep Collection Time: 2.15799
Timestep Consumption Time: 2.42389
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.58188

Cumulative Model Updates: 255,294
Cumulative Timesteps: 2,129,119,222

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2129119222...
Checkpoint 2129119222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.23192
Policy Entropy: 2.02819
Value Function Loss: 0.01985

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.67407

Collected Steps per Second: 22,656.60701
Overall Steps per Second: 10,800.67481

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.42277
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.62990

Cumulative Model Updates: 255,300
Cumulative Timesteps: 2,129,169,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.43792
Policy Entropy: 2.03364
Value Function Loss: 0.01950

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.55265
Value Function Update Magnitude: 0.66563

Collected Steps per Second: 23,666.07971
Overall Steps per Second: 10,825.04506

Timestep Collection Time: 2.11315
Timestep Consumption Time: 2.50669
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.61984

Cumulative Model Updates: 255,306
Cumulative Timesteps: 2,129,219,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2129219238...
Checkpoint 2129219238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.32227
Policy Entropy: 2.04111
Value Function Loss: 0.01994

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.55978
Value Function Update Magnitude: 0.65982

Collected Steps per Second: 22,598.28174
Overall Steps per Second: 10,636.30051

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.70088

Cumulative Model Updates: 255,312
Cumulative Timesteps: 2,129,269,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.86030
Policy Entropy: 2.05952
Value Function Loss: 0.01872

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.55534
Value Function Update Magnitude: 0.68750

Collected Steps per Second: 23,187.27722
Overall Steps per Second: 10,991.31588

Timestep Collection Time: 2.15739
Timestep Consumption Time: 2.39384
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.55123

Cumulative Model Updates: 255,318
Cumulative Timesteps: 2,129,319,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2129319262...
Checkpoint 2129319262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.17814
Policy Entropy: 2.04780
Value Function Loss: 0.01973

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.67965

Collected Steps per Second: 22,182.63797
Overall Steps per Second: 10,585.48879

Timestep Collection Time: 2.25438
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.72420

Cumulative Model Updates: 255,324
Cumulative Timesteps: 2,129,369,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.54182
Policy Entropy: 2.04476
Value Function Loss: 0.01995

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.67311

Collected Steps per Second: 23,623.17996
Overall Steps per Second: 10,913.11675

Timestep Collection Time: 2.11741
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.58348

Cumulative Model Updates: 255,330
Cumulative Timesteps: 2,129,419,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2129419290...
Checkpoint 2129419290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.93441
Policy Entropy: 2.03856
Value Function Loss: 0.02008

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.67537

Collected Steps per Second: 22,266.20507
Overall Steps per Second: 10,653.80759

Timestep Collection Time: 2.24663
Timestep Consumption Time: 2.44878
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.69541

Cumulative Model Updates: 255,336
Cumulative Timesteps: 2,129,469,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.90244
Policy Entropy: 2.04258
Value Function Loss: 0.01953

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.68417

Collected Steps per Second: 22,856.62472
Overall Steps per Second: 10,897.68278

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.40116
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.58923

Cumulative Model Updates: 255,342
Cumulative Timesteps: 2,129,519,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2129519326...
Checkpoint 2129519326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.09220
Policy Entropy: 2.06273
Value Function Loss: 0.01819

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.68054

Collected Steps per Second: 22,273.63174
Overall Steps per Second: 10,674.74863

Timestep Collection Time: 2.24597
Timestep Consumption Time: 2.44041
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.68639

Cumulative Model Updates: 255,348
Cumulative Timesteps: 2,129,569,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.37756
Policy Entropy: 2.06479
Value Function Loss: 0.01843

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.54271
Value Function Update Magnitude: 0.67010

Collected Steps per Second: 23,961.69310
Overall Steps per Second: 10,901.47780

Timestep Collection Time: 2.08716
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.58763

Cumulative Model Updates: 255,354
Cumulative Timesteps: 2,129,619,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2129619364...
Checkpoint 2129619364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.86484
Policy Entropy: 2.09113
Value Function Loss: 0.01701

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.53270
Value Function Update Magnitude: 0.66453

Collected Steps per Second: 22,807.50157
Overall Steps per Second: 10,588.10471

Timestep Collection Time: 2.19288
Timestep Consumption Time: 2.53073
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.72360

Cumulative Model Updates: 255,360
Cumulative Timesteps: 2,129,669,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.86204
Policy Entropy: 2.08716
Value Function Loss: 0.01767

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.53471
Value Function Update Magnitude: 0.65536

Collected Steps per Second: 23,318.22523
Overall Steps per Second: 10,952.46041

Timestep Collection Time: 2.14459
Timestep Consumption Time: 2.42133
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.56591

Cumulative Model Updates: 255,366
Cumulative Timesteps: 2,129,719,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2129719386...
Checkpoint 2129719386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.26652
Policy Entropy: 2.09442
Value Function Loss: 0.01848

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.54595
Value Function Update Magnitude: 0.65827

Collected Steps per Second: 22,715.81856
Overall Steps per Second: 10,993.42795

Timestep Collection Time: 2.20146
Timestep Consumption Time: 2.34744
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.54890

Cumulative Model Updates: 255,372
Cumulative Timesteps: 2,129,769,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.32189
Policy Entropy: 2.05748
Value Function Loss: 0.01950

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.65806

Collected Steps per Second: 23,446.98639
Overall Steps per Second: 10,970.77978

Timestep Collection Time: 2.13324
Timestep Consumption Time: 2.42596
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.55920

Cumulative Model Updates: 255,378
Cumulative Timesteps: 2,129,819,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2129819412...
Checkpoint 2129819412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.13591
Policy Entropy: 2.04984
Value Function Loss: 0.02064

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.67859

Collected Steps per Second: 22,750.55854
Overall Steps per Second: 10,666.53972

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.49041
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68868

Cumulative Model Updates: 255,384
Cumulative Timesteps: 2,129,869,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.56824
Policy Entropy: 2.03902
Value Function Loss: 0.01971

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.70085

Collected Steps per Second: 22,700.30893
Overall Steps per Second: 10,668.95013

Timestep Collection Time: 2.20270
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.68668

Cumulative Model Updates: 255,390
Cumulative Timesteps: 2,129,919,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2129919426...
Checkpoint 2129919426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.33252
Policy Entropy: 2.05882
Value Function Loss: 0.01903

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.70767

Collected Steps per Second: 22,525.98831
Overall Steps per Second: 10,825.38496

Timestep Collection Time: 2.22055
Timestep Consumption Time: 2.40007
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.62062

Cumulative Model Updates: 255,396
Cumulative Timesteps: 2,129,969,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.14855
Policy Entropy: 2.05556
Value Function Loss: 0.01841

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.53255
Value Function Update Magnitude: 0.70968

Collected Steps per Second: 22,865.42563
Overall Steps per Second: 11,043.80720

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.34072
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.52742

Cumulative Model Updates: 255,402
Cumulative Timesteps: 2,130,019,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2130019446...
Checkpoint 2130019446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.85907
Policy Entropy: 2.04480
Value Function Loss: 0.01896

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.52640
Value Function Update Magnitude: 0.70619

Collected Steps per Second: 22,386.72640
Overall Steps per Second: 10,617.80314

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.47600
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.70983

Cumulative Model Updates: 255,408
Cumulative Timesteps: 2,130,069,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.64798
Policy Entropy: 2.05936
Value Function Loss: 0.01887

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.52753
Value Function Update Magnitude: 0.70147

Collected Steps per Second: 23,467.97798
Overall Steps per Second: 10,889.00629

Timestep Collection Time: 2.13184
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59454

Cumulative Model Updates: 255,414
Cumulative Timesteps: 2,130,119,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2130119484...
Checkpoint 2130119484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.16490
Policy Entropy: 2.07303
Value Function Loss: 0.01919

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.69599

Collected Steps per Second: 22,550.11303
Overall Steps per Second: 10,631.50412

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.70488

Cumulative Model Updates: 255,420
Cumulative Timesteps: 2,130,169,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.38215
Policy Entropy: 2.08484
Value Function Loss: 0.01891

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.69191

Collected Steps per Second: 23,148.91953
Overall Steps per Second: 11,003.99799

Timestep Collection Time: 2.16062
Timestep Consumption Time: 2.38464
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.54526

Cumulative Model Updates: 255,426
Cumulative Timesteps: 2,130,219,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2130219520...
Checkpoint 2130219520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.03466
Policy Entropy: 2.09085
Value Function Loss: 0.01897

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.53616
Value Function Update Magnitude: 0.68709

Collected Steps per Second: 22,973.51582
Overall Steps per Second: 11,092.82097

Timestep Collection Time: 2.17694
Timestep Consumption Time: 2.33156
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.50850

Cumulative Model Updates: 255,432
Cumulative Timesteps: 2,130,269,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.86443
Policy Entropy: 2.09504
Value Function Loss: 0.01871

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.53672
Value Function Update Magnitude: 0.67685

Collected Steps per Second: 23,190.21308
Overall Steps per Second: 10,904.03790

Timestep Collection Time: 2.15617
Timestep Consumption Time: 2.42947
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.58564

Cumulative Model Updates: 255,438
Cumulative Timesteps: 2,130,319,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2130319534...
Checkpoint 2130319534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.68971
Policy Entropy: 2.07024
Value Function Loss: 0.01869

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.53416
Value Function Update Magnitude: 0.66190

Collected Steps per Second: 22,528.62104
Overall Steps per Second: 10,587.35989

Timestep Collection Time: 2.21993
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.72375

Cumulative Model Updates: 255,444
Cumulative Timesteps: 2,130,369,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.86218
Policy Entropy: 2.05578
Value Function Loss: 0.01933

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.67026

Collected Steps per Second: 23,045.54533
Overall Steps per Second: 10,898.48482

Timestep Collection Time: 2.16962
Timestep Consumption Time: 2.41818
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.58779

Cumulative Model Updates: 255,450
Cumulative Timesteps: 2,130,419,546

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2130419546...
Checkpoint 2130419546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.46792
Policy Entropy: 2.04828
Value Function Loss: 0.01927

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.68546

Collected Steps per Second: 22,042.82852
Overall Steps per Second: 10,646.64667

Timestep Collection Time: 2.26849
Timestep Consumption Time: 2.42820
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.69669

Cumulative Model Updates: 255,456
Cumulative Timesteps: 2,130,469,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.33016
Policy Entropy: 2.06634
Value Function Loss: 0.01935

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.69473

Collected Steps per Second: 22,700.42345
Overall Steps per Second: 10,670.85899

Timestep Collection Time: 2.20295
Timestep Consumption Time: 2.48345
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.68641

Cumulative Model Updates: 255,462
Cumulative Timesteps: 2,130,519,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2130519558...
Checkpoint 2130519558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.64853
Policy Entropy: 2.05408
Value Function Loss: 0.01773

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.68164

Collected Steps per Second: 22,565.67655
Overall Steps per Second: 10,782.19107

Timestep Collection Time: 2.21655
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.63895

Cumulative Model Updates: 255,468
Cumulative Timesteps: 2,130,569,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.14911
Policy Entropy: 2.06147
Value Function Loss: 0.01814

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.65993

Collected Steps per Second: 23,021.48259
Overall Steps per Second: 10,742.02471

Timestep Collection Time: 2.17241
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.65573

Cumulative Model Updates: 255,474
Cumulative Timesteps: 2,130,619,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2130619588...
Checkpoint 2130619588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.72787
Policy Entropy: 2.04841
Value Function Loss: 0.01885

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.55352
Value Function Update Magnitude: 0.66425

Collected Steps per Second: 23,108.49192
Overall Steps per Second: 10,872.28034

Timestep Collection Time: 2.16379
Timestep Consumption Time: 2.43524
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.59904

Cumulative Model Updates: 255,480
Cumulative Timesteps: 2,130,669,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.56890
Policy Entropy: 2.08364
Value Function Loss: 0.01937

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.54171
Value Function Update Magnitude: 0.65862

Collected Steps per Second: 23,517.05452
Overall Steps per Second: 10,945.05804

Timestep Collection Time: 2.12612
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.56827

Cumulative Model Updates: 255,486
Cumulative Timesteps: 2,130,719,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2130719590...
Checkpoint 2130719590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.78525
Policy Entropy: 2.08123
Value Function Loss: 0.01892

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.53794
Value Function Update Magnitude: 0.65601

Collected Steps per Second: 22,815.91313
Overall Steps per Second: 10,642.61721

Timestep Collection Time: 2.19259
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.70054

Cumulative Model Updates: 255,492
Cumulative Timesteps: 2,130,769,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.24134
Policy Entropy: 2.09863
Value Function Loss: 0.01901

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.53236
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 23,282.35170
Overall Steps per Second: 10,915.77380

Timestep Collection Time: 2.14832
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.58218

Cumulative Model Updates: 255,498
Cumulative Timesteps: 2,130,819,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2130819634...
Checkpoint 2130819634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.77064
Policy Entropy: 2.10175
Value Function Loss: 0.01863

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.63816

Collected Steps per Second: 22,191.43750
Overall Steps per Second: 10,630.35502

Timestep Collection Time: 2.25429
Timestep Consumption Time: 2.45166
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.70596

Cumulative Model Updates: 255,504
Cumulative Timesteps: 2,130,869,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.23084
Policy Entropy: 2.13306
Value Function Loss: 0.01745

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.53018
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 22,723.12126
Overall Steps per Second: 10,795.95445

Timestep Collection Time: 2.20075
Timestep Consumption Time: 2.43135
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63211

Cumulative Model Updates: 255,510
Cumulative Timesteps: 2,130,919,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2130919668...
Checkpoint 2130919668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.50018
Policy Entropy: 2.14131
Value Function Loss: 0.01690

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.63535

Collected Steps per Second: 21,981.62760
Overall Steps per Second: 10,505.75536

Timestep Collection Time: 2.27545
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.76101

Cumulative Model Updates: 255,516
Cumulative Timesteps: 2,130,969,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.30568
Policy Entropy: 2.13628
Value Function Loss: 0.01784

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.52621
Value Function Update Magnitude: 0.65618

Collected Steps per Second: 22,946.46423
Overall Steps per Second: 10,726.71257

Timestep Collection Time: 2.17907
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.66145

Cumulative Model Updates: 255,522
Cumulative Timesteps: 2,131,019,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2131019688...
Checkpoint 2131019688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.48652
Policy Entropy: 2.10925
Value Function Loss: 0.01813

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.52560
Value Function Update Magnitude: 0.68042

Collected Steps per Second: 22,130.70345
Overall Steps per Second: 10,678.78549

Timestep Collection Time: 2.25994
Timestep Consumption Time: 2.42355
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.68349

Cumulative Model Updates: 255,528
Cumulative Timesteps: 2,131,069,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.46686
Policy Entropy: 2.11818
Value Function Loss: 0.01813

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.67477

Collected Steps per Second: 23,430.85868
Overall Steps per Second: 10,840.33468

Timestep Collection Time: 2.13436
Timestep Consumption Time: 2.47896
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.61333

Cumulative Model Updates: 255,534
Cumulative Timesteps: 2,131,119,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2131119712...
Checkpoint 2131119712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.06098
Policy Entropy: 2.12075
Value Function Loss: 0.01827

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.66822

Collected Steps per Second: 22,442.24369
Overall Steps per Second: 10,631.60171

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.70371

Cumulative Model Updates: 255,540
Cumulative Timesteps: 2,131,169,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.19183
Policy Entropy: 2.11382
Value Function Loss: 0.01903

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.53895
Value Function Update Magnitude: 0.65943

Collected Steps per Second: 22,818.21315
Overall Steps per Second: 10,876.15236

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.40608
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.59740

Cumulative Model Updates: 255,546
Cumulative Timesteps: 2,131,219,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2131219722...
Checkpoint 2131219722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.63629
Policy Entropy: 2.08893
Value Function Loss: 0.01965

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.67556

Collected Steps per Second: 23,301.90261
Overall Steps per Second: 10,810.13487

Timestep Collection Time: 2.14652
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.62695

Cumulative Model Updates: 255,552
Cumulative Timesteps: 2,131,269,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.35746
Policy Entropy: 2.08298
Value Function Loss: 0.01911

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.54224
Value Function Update Magnitude: 0.69534

Collected Steps per Second: 23,488.93249
Overall Steps per Second: 10,792.93271

Timestep Collection Time: 2.13071
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.63711

Cumulative Model Updates: 255,558
Cumulative Timesteps: 2,131,319,788

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2131319788...
Checkpoint 2131319788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.43899
Policy Entropy: 2.08080
Value Function Loss: 0.01881

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.69562

Collected Steps per Second: 22,625.56214
Overall Steps per Second: 10,618.38146

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.71070

Cumulative Model Updates: 255,564
Cumulative Timesteps: 2,131,369,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.98621
Policy Entropy: 2.09042
Value Function Loss: 0.01824

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.69041

Collected Steps per Second: 22,837.12518
Overall Steps per Second: 10,952.62288

Timestep Collection Time: 2.19029
Timestep Consumption Time: 2.37665
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.56694

Cumulative Model Updates: 255,570
Cumulative Timesteps: 2,131,419,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2131419828...
Checkpoint 2131419828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.16457
Policy Entropy: 2.08558
Value Function Loss: 0.01891

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.53333
Value Function Update Magnitude: 0.70236

Collected Steps per Second: 22,312.58008
Overall Steps per Second: 10,604.35517

Timestep Collection Time: 2.24161
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.71655

Cumulative Model Updates: 255,576
Cumulative Timesteps: 2,131,469,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.58218
Policy Entropy: 2.09192
Value Function Loss: 0.01894

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.71147

Collected Steps per Second: 22,862.93330
Overall Steps per Second: 10,830.72759

Timestep Collection Time: 2.18765
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61797

Cumulative Model Updates: 255,582
Cumulative Timesteps: 2,131,519,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2131519860...
Checkpoint 2131519860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.30215
Policy Entropy: 2.08214
Value Function Loss: 0.01923

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.69216

Collected Steps per Second: 22,356.66597
Overall Steps per Second: 10,717.51303

Timestep Collection Time: 2.23719
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.66675

Cumulative Model Updates: 255,588
Cumulative Timesteps: 2,131,569,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.81668
Policy Entropy: 2.07206
Value Function Loss: 0.01958

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.67574

Collected Steps per Second: 23,409.62142
Overall Steps per Second: 10,935.73625

Timestep Collection Time: 2.13630
Timestep Consumption Time: 2.43678
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.57308

Cumulative Model Updates: 255,594
Cumulative Timesteps: 2,131,619,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2131619886...
Checkpoint 2131619886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.10181
Policy Entropy: 2.04273
Value Function Loss: 0.01910

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.51656
Value Function Update Magnitude: 0.66799

Collected Steps per Second: 22,845.53263
Overall Steps per Second: 10,679.64867

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.49409
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.68349

Cumulative Model Updates: 255,600
Cumulative Timesteps: 2,131,669,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.97590
Policy Entropy: 2.03429
Value Function Loss: 0.01964

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.16694
Policy Update Magnitude: 0.50361
Value Function Update Magnitude: 0.68004

Collected Steps per Second: 23,199.56663
Overall Steps per Second: 10,862.83359

Timestep Collection Time: 2.15651
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.60561

Cumulative Model Updates: 255,606
Cumulative Timesteps: 2,131,719,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2131719934...
Checkpoint 2131719934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.20661
Policy Entropy: 2.05078
Value Function Loss: 0.01955

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.52902
Value Function Update Magnitude: 0.68723

Collected Steps per Second: 22,619.67740
Overall Steps per Second: 10,664.26012

Timestep Collection Time: 2.21108
Timestep Consumption Time: 2.47879
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68987

Cumulative Model Updates: 255,612
Cumulative Timesteps: 2,131,769,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.54561
Policy Entropy: 2.08899
Value Function Loss: 0.01916

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.55688
Value Function Update Magnitude: 0.69215

Collected Steps per Second: 22,955.71830
Overall Steps per Second: 10,868.16006

Timestep Collection Time: 2.17906
Timestep Consumption Time: 2.42355
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.60262

Cumulative Model Updates: 255,618
Cumulative Timesteps: 2,131,819,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2131819970...
Checkpoint 2131819970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.90543
Policy Entropy: 2.07334
Value Function Loss: 0.01826

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.66725

Collected Steps per Second: 22,681.65635
Overall Steps per Second: 10,643.45025

Timestep Collection Time: 2.20460
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.69810

Cumulative Model Updates: 255,624
Cumulative Timesteps: 2,131,869,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.48516
Policy Entropy: 2.05662
Value Function Loss: 0.01898

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.53917
Value Function Update Magnitude: 0.62749

Collected Steps per Second: 22,764.54593
Overall Steps per Second: 10,684.09379

Timestep Collection Time: 2.19772
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.68266

Cumulative Model Updates: 255,630
Cumulative Timesteps: 2,131,920,004

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2131920004...
Checkpoint 2131920004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.89968
Policy Entropy: 2.04258
Value Function Loss: 0.01878

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.62471

Collected Steps per Second: 22,713.80403
Overall Steps per Second: 10,911.29115

Timestep Collection Time: 2.20157
Timestep Consumption Time: 2.38139
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.58296

Cumulative Model Updates: 255,636
Cumulative Timesteps: 2,131,970,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.11804
Policy Entropy: 2.03958
Value Function Loss: 0.01914

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.63469

Collected Steps per Second: 23,032.70379
Overall Steps per Second: 10,872.90298

Timestep Collection Time: 2.17204
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.60116

Cumulative Model Updates: 255,642
Cumulative Timesteps: 2,132,020,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2132020038...
Checkpoint 2132020038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.76380
Policy Entropy: 2.02491
Value Function Loss: 0.01907

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.65633

Collected Steps per Second: 23,094.84498
Overall Steps per Second: 10,658.55930

Timestep Collection Time: 2.16576
Timestep Consumption Time: 2.52699
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.69275

Cumulative Model Updates: 255,648
Cumulative Timesteps: 2,132,070,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.68683
Policy Entropy: 2.02459
Value Function Loss: 0.02001

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.66219

Collected Steps per Second: 23,153.52297
Overall Steps per Second: 10,832.67870

Timestep Collection Time: 2.16071
Timestep Consumption Time: 2.45754
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61825

Cumulative Model Updates: 255,654
Cumulative Timesteps: 2,132,120,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2132120084...
Checkpoint 2132120084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.92965
Policy Entropy: 2.04192
Value Function Loss: 0.02005

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.67192

Collected Steps per Second: 22,739.68619
Overall Steps per Second: 10,694.93835

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.47720
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.67679

Cumulative Model Updates: 255,660
Cumulative Timesteps: 2,132,170,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.28376
Policy Entropy: 2.06475
Value Function Loss: 0.01861

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.54938
Value Function Update Magnitude: 0.67792

Collected Steps per Second: 23,081.15672
Overall Steps per Second: 10,916.91831

Timestep Collection Time: 2.16653
Timestep Consumption Time: 2.41407
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.58060

Cumulative Model Updates: 255,666
Cumulative Timesteps: 2,132,220,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2132220108...
Checkpoint 2132220108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.29996
Policy Entropy: 2.07200
Value Function Loss: 0.01778

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.53329
Value Function Update Magnitude: 0.66457

Collected Steps per Second: 22,845.50759
Overall Steps per Second: 10,689.80282

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.48964
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.67904

Cumulative Model Updates: 255,672
Cumulative Timesteps: 2,132,270,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.45356
Policy Entropy: 2.06118
Value Function Loss: 0.01866

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.64398

Collected Steps per Second: 23,509.79565
Overall Steps per Second: 10,894.27643

Timestep Collection Time: 2.12694
Timestep Consumption Time: 2.46299
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.58993

Cumulative Model Updates: 255,678
Cumulative Timesteps: 2,132,320,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2132320130...
Checkpoint 2132320130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.52811
Policy Entropy: 2.03121
Value Function Loss: 0.01971

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.54160
Value Function Update Magnitude: 0.65300

Collected Steps per Second: 22,366.53840
Overall Steps per Second: 10,610.25781

Timestep Collection Time: 2.23656
Timestep Consumption Time: 2.47813
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.71468

Cumulative Model Updates: 255,684
Cumulative Timesteps: 2,132,370,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.69755
Policy Entropy: 2.02375
Value Function Loss: 0.02054

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.55513
Value Function Update Magnitude: 0.68130

Collected Steps per Second: 22,860.42665
Overall Steps per Second: 10,924.67714

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.39095
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.57936

Cumulative Model Updates: 255,690
Cumulative Timesteps: 2,132,420,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2132420182...
Checkpoint 2132420182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.18996
Policy Entropy: 2.01791
Value Function Loss: 0.01864

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.68645

Collected Steps per Second: 21,928.63777
Overall Steps per Second: 10,602.82854

Timestep Collection Time: 2.28021
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.71591

Cumulative Model Updates: 255,696
Cumulative Timesteps: 2,132,470,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.10740
Policy Entropy: 2.03312
Value Function Loss: 0.01811

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.53922
Value Function Update Magnitude: 0.67507

Collected Steps per Second: 22,932.87404
Overall Steps per Second: 10,860.32239

Timestep Collection Time: 2.18167
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60686

Cumulative Model Updates: 255,702
Cumulative Timesteps: 2,132,520,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2132520216...
Checkpoint 2132520216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.07822
Policy Entropy: 2.01675
Value Function Loss: 0.01846

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.67579

Collected Steps per Second: 22,316.96732
Overall Steps per Second: 10,736.31910

Timestep Collection Time: 2.24152
Timestep Consumption Time: 2.41780
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.65933

Cumulative Model Updates: 255,708
Cumulative Timesteps: 2,132,570,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.78205
Policy Entropy: 2.01567
Value Function Loss: 0.01981

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.66167

Collected Steps per Second: 23,111.86823
Overall Steps per Second: 10,924.42302

Timestep Collection Time: 2.16469
Timestep Consumption Time: 2.41496
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.57965

Cumulative Model Updates: 255,714
Cumulative Timesteps: 2,132,620,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2132620270...
Checkpoint 2132620270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.72576
Policy Entropy: 2.02023
Value Function Loss: 0.01995

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.65928

Collected Steps per Second: 22,992.34624
Overall Steps per Second: 10,676.28140

Timestep Collection Time: 2.17525
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.68459

Cumulative Model Updates: 255,720
Cumulative Timesteps: 2,132,670,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.47874
Policy Entropy: 2.03649
Value Function Loss: 0.01912

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.53812
Value Function Update Magnitude: 0.66317

Collected Steps per Second: 23,207.94955
Overall Steps per Second: 10,912.31782

Timestep Collection Time: 2.15478
Timestep Consumption Time: 2.42793
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.58271

Cumulative Model Updates: 255,726
Cumulative Timesteps: 2,132,720,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2132720292...
Checkpoint 2132720292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.94050
Policy Entropy: 2.06419
Value Function Loss: 0.01813

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.63722

Collected Steps per Second: 22,776.14759
Overall Steps per Second: 10,652.53901

Timestep Collection Time: 2.19712
Timestep Consumption Time: 2.50054
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.69766

Cumulative Model Updates: 255,732
Cumulative Timesteps: 2,132,770,334

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.71719
Policy Entropy: 2.05699
Value Function Loss: 0.01775

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.52671
Value Function Update Magnitude: 0.62475

Collected Steps per Second: 22,873.01721
Overall Steps per Second: 10,807.24134

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.62875

Cumulative Model Updates: 255,738
Cumulative Timesteps: 2,132,820,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2132820358...
Checkpoint 2132820358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.56065
Policy Entropy: 2.05128
Value Function Loss: 0.01784

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.52460
Value Function Update Magnitude: 0.63875

Collected Steps per Second: 22,411.22560
Overall Steps per Second: 10,775.57950

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.40958
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.64105

Cumulative Model Updates: 255,744
Cumulative Timesteps: 2,132,870,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.65392
Policy Entropy: 2.04896
Value Function Loss: 0.01751

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.53265
Value Function Update Magnitude: 0.62903

Collected Steps per Second: 22,938.83956
Overall Steps per Second: 10,813.07960

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.44530
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.62588

Cumulative Model Updates: 255,750
Cumulative Timesteps: 2,132,920,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2132920388...
Checkpoint 2132920388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.42163
Policy Entropy: 2.04673
Value Function Loss: 0.01842

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.62575

Collected Steps per Second: 22,917.07416
Overall Steps per Second: 10,640.69242

Timestep Collection Time: 2.18204
Timestep Consumption Time: 2.51747
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.69951

Cumulative Model Updates: 255,756
Cumulative Timesteps: 2,132,970,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.98935
Policy Entropy: 2.05140
Value Function Loss: 0.01899

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.54924
Value Function Update Magnitude: 0.63704

Collected Steps per Second: 23,943.21228
Overall Steps per Second: 10,879.76728

Timestep Collection Time: 2.08878
Timestep Consumption Time: 2.50801
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.59679

Cumulative Model Updates: 255,762
Cumulative Timesteps: 2,133,020,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2133020406...
Checkpoint 2133020406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.97097
Policy Entropy: 2.05277
Value Function Loss: 0.01919

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.54922
Value Function Update Magnitude: 0.64596

Collected Steps per Second: 22,652.31679
Overall Steps per Second: 10,690.00921

Timestep Collection Time: 2.20772
Timestep Consumption Time: 2.47048
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.67820

Cumulative Model Updates: 255,768
Cumulative Timesteps: 2,133,070,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.90373
Policy Entropy: 2.07047
Value Function Loss: 0.01831

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.53432
Value Function Update Magnitude: 0.63111

Collected Steps per Second: 22,789.76695
Overall Steps per Second: 10,863.22026

Timestep Collection Time: 2.19449
Timestep Consumption Time: 2.40930
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.60379

Cumulative Model Updates: 255,774
Cumulative Timesteps: 2,133,120,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2133120428...
Checkpoint 2133120428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.42921
Policy Entropy: 2.06611
Value Function Loss: 0.01836

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.52397
Value Function Update Magnitude: 0.59584

Collected Steps per Second: 22,650.44550
Overall Steps per Second: 10,801.79266

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.42140
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.62886

Cumulative Model Updates: 255,780
Cumulative Timesteps: 2,133,170,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.94903
Policy Entropy: 2.07108
Value Function Loss: 0.01856

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.53516
Value Function Update Magnitude: 0.59596

Collected Steps per Second: 23,419.53830
Overall Steps per Second: 10,766.36229

Timestep Collection Time: 2.13505
Timestep Consumption Time: 2.50923
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.64428

Cumulative Model Updates: 255,786
Cumulative Timesteps: 2,133,220,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2133220430...
Checkpoint 2133220430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.92853
Policy Entropy: 2.06646
Value Function Loss: 0.01880

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.52905
Value Function Update Magnitude: 0.60875

Collected Steps per Second: 22,263.66024
Overall Steps per Second: 10,737.12035

Timestep Collection Time: 2.24689
Timestep Consumption Time: 2.41209
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.65898

Cumulative Model Updates: 255,792
Cumulative Timesteps: 2,133,270,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.91920
Policy Entropy: 2.07481
Value Function Loss: 0.01855

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.62367

Collected Steps per Second: 22,756.35432
Overall Steps per Second: 10,804.12047

Timestep Collection Time: 2.19789
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.62934

Cumulative Model Updates: 255,798
Cumulative Timesteps: 2,133,320,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2133320470...
Checkpoint 2133320470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.11096
Policy Entropy: 2.05346
Value Function Loss: 0.01966

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.55205
Value Function Update Magnitude: 0.63373

Collected Steps per Second: 22,608.06819
Overall Steps per Second: 10,831.40764

Timestep Collection Time: 2.21293
Timestep Consumption Time: 2.40605
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.61897

Cumulative Model Updates: 255,804
Cumulative Timesteps: 2,133,370,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.56885
Policy Entropy: 2.03458
Value Function Loss: 0.01935

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.56374
Value Function Update Magnitude: 0.63952

Collected Steps per Second: 23,291.38584
Overall Steps per Second: 10,795.10576

Timestep Collection Time: 2.14809
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.63469

Cumulative Model Updates: 255,810
Cumulative Timesteps: 2,133,420,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2133420532...
Checkpoint 2133420532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.67805
Policy Entropy: 2.04542
Value Function Loss: 0.01897

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,554.58416
Overall Steps per Second: 10,631.18863

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.48759
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.70559

Cumulative Model Updates: 255,816
Cumulative Timesteps: 2,133,470,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.62446
Policy Entropy: 2.04015
Value Function Loss: 0.01785

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.53570
Value Function Update Magnitude: 0.60706

Collected Steps per Second: 23,293.72704
Overall Steps per Second: 10,937.87440

Timestep Collection Time: 2.14702
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.57237

Cumulative Model Updates: 255,822
Cumulative Timesteps: 2,133,520,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2133520570...
Checkpoint 2133520570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.89695
Policy Entropy: 2.04184
Value Function Loss: 0.01918

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.14766
Policy Update Magnitude: 0.53182
Value Function Update Magnitude: 0.61680

Collected Steps per Second: 22,985.27299
Overall Steps per Second: 11,040.59580

Timestep Collection Time: 2.17600
Timestep Consumption Time: 2.35419
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.53019

Cumulative Model Updates: 255,828
Cumulative Timesteps: 2,133,570,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.45781
Policy Entropy: 2.05087
Value Function Loss: 0.01906

Mean KL Divergence: 0.03538
SB3 Clip Fraction: 0.18383
Policy Update Magnitude: 0.50968
Value Function Update Magnitude: 0.63639

Collected Steps per Second: 23,604.20689
Overall Steps per Second: 10,972.17962

Timestep Collection Time: 2.11835
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.55716

Cumulative Model Updates: 255,834
Cumulative Timesteps: 2,133,620,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2133620588...
Checkpoint 2133620588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.56476
Policy Entropy: 2.07483
Value Function Loss: 0.02025

Mean KL Divergence: 0.05754
SB3 Clip Fraction: 0.24340
Policy Update Magnitude: 0.45670
Value Function Update Magnitude: 0.65230

Collected Steps per Second: 22,838.13707
Overall Steps per Second: 10,673.15774

Timestep Collection Time: 2.18941
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.68484

Cumulative Model Updates: 255,840
Cumulative Timesteps: 2,133,670,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.16280
Policy Entropy: 2.07151
Value Function Loss: 0.02106

Mean KL Divergence: 0.04596
SB3 Clip Fraction: 0.20644
Policy Update Magnitude: 0.48636
Value Function Update Magnitude: 0.67069

Collected Steps per Second: 23,237.80699
Overall Steps per Second: 10,833.74792

Timestep Collection Time: 2.15278
Timestep Consumption Time: 2.46482
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.61761

Cumulative Model Updates: 255,846
Cumulative Timesteps: 2,133,720,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2133720616...
Checkpoint 2133720616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.60526
Policy Entropy: 2.07910
Value Function Loss: 0.02094

Mean KL Divergence: 0.02812
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.52252
Value Function Update Magnitude: 0.69889

Collected Steps per Second: 22,267.70322
Overall Steps per Second: 10,683.10099

Timestep Collection Time: 2.24621
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.68197

Cumulative Model Updates: 255,852
Cumulative Timesteps: 2,133,770,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.35449
Policy Entropy: 2.08292
Value Function Loss: 0.01931

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.16986
Policy Update Magnitude: 0.55650
Value Function Update Magnitude: 0.68382

Collected Steps per Second: 23,124.19281
Overall Steps per Second: 10,908.78467

Timestep Collection Time: 2.16336
Timestep Consumption Time: 2.42248
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.58585

Cumulative Model Updates: 255,858
Cumulative Timesteps: 2,133,820,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2133820660...
Checkpoint 2133820660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.97161
Policy Entropy: 2.09742
Value Function Loss: 0.01885

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.15970
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.65917

Collected Steps per Second: 22,393.87037
Overall Steps per Second: 10,661.45493

Timestep Collection Time: 2.23418
Timestep Consumption Time: 2.45861
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.69279

Cumulative Model Updates: 255,864
Cumulative Timesteps: 2,133,870,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.45797
Policy Entropy: 2.07720
Value Function Loss: 0.01922

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.15512
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.65273

Collected Steps per Second: 22,854.62210
Overall Steps per Second: 10,830.41232

Timestep Collection Time: 2.18800
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61718

Cumulative Model Updates: 255,870
Cumulative Timesteps: 2,133,920,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2133920698...
Checkpoint 2133920698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.87315
Policy Entropy: 2.07206
Value Function Loss: 0.01919

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.54485
Value Function Update Magnitude: 0.64735

Collected Steps per Second: 22,472.13832
Overall Steps per Second: 10,680.33362

Timestep Collection Time: 2.22542
Timestep Consumption Time: 2.45702
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.68244

Cumulative Model Updates: 255,876
Cumulative Timesteps: 2,133,970,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.74071
Policy Entropy: 2.08609
Value Function Loss: 0.01785

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.54693
Value Function Update Magnitude: 0.66024

Collected Steps per Second: 22,977.92302
Overall Steps per Second: 10,953.61113

Timestep Collection Time: 2.17661
Timestep Consumption Time: 2.38937
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.56598

Cumulative Model Updates: 255,882
Cumulative Timesteps: 2,134,020,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2134020722...
Checkpoint 2134020722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.52237
Policy Entropy: 2.09825
Value Function Loss: 0.01791

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.65319

Collected Steps per Second: 22,693.15354
Overall Steps per Second: 10,620.31396

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.70852

Cumulative Model Updates: 255,888
Cumulative Timesteps: 2,134,070,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.19928
Policy Entropy: 2.08789
Value Function Loss: 0.01840

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.56119
Value Function Update Magnitude: 0.65388

Collected Steps per Second: 22,848.47243
Overall Steps per Second: 10,654.51678

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69566

Cumulative Model Updates: 255,894
Cumulative Timesteps: 2,134,120,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2134120758...
Checkpoint 2134120758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.75612
Policy Entropy: 2.07927
Value Function Loss: 0.01863

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.56678
Value Function Update Magnitude: 0.65984

Collected Steps per Second: 22,942.45179
Overall Steps per Second: 10,926.80882

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.39701
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.57682

Cumulative Model Updates: 255,900
Cumulative Timesteps: 2,134,170,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.65929
Policy Entropy: 2.08063
Value Function Loss: 0.01866

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.64824

Collected Steps per Second: 23,316.75667
Overall Steps per Second: 10,866.56525

Timestep Collection Time: 2.14567
Timestep Consumption Time: 2.45836
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.60403

Cumulative Model Updates: 255,906
Cumulative Timesteps: 2,134,220,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2134220798...
Checkpoint 2134220798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.63056
Policy Entropy: 2.09202
Value Function Loss: 0.01833

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.55402
Value Function Update Magnitude: 0.63297

Collected Steps per Second: 22,720.67426
Overall Steps per Second: 11,034.59946

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.33196
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.53392

Cumulative Model Updates: 255,912
Cumulative Timesteps: 2,134,270,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.44874
Policy Entropy: 2.09277
Value Function Loss: 0.01825

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.63227

Collected Steps per Second: 22,892.02140
Overall Steps per Second: 10,729.32603

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.47685
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.66180

Cumulative Model Updates: 255,918
Cumulative Timesteps: 2,134,320,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2134320846...
Checkpoint 2134320846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.35064
Policy Entropy: 2.09574
Value Function Loss: 0.01823

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.53417
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 22,225.26747
Overall Steps per Second: 10,535.01192

Timestep Collection Time: 2.25050
Timestep Consumption Time: 2.49729
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.74779

Cumulative Model Updates: 255,924
Cumulative Timesteps: 2,134,370,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.98319
Policy Entropy: 2.08751
Value Function Loss: 0.01824

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.51416
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 22,894.82148
Overall Steps per Second: 10,824.31675

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.62163

Cumulative Model Updates: 255,930
Cumulative Timesteps: 2,134,420,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2134420890...
Checkpoint 2134420890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.96782
Policy Entropy: 2.07339
Value Function Loss: 0.01926

Mean KL Divergence: 0.02780
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.61330

Collected Steps per Second: 22,172.79767
Overall Steps per Second: 10,706.73527

Timestep Collection Time: 2.25637
Timestep Consumption Time: 2.41639
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.67276

Cumulative Model Updates: 255,936
Cumulative Timesteps: 2,134,470,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.12594
Policy Entropy: 2.09465
Value Function Loss: 0.01858

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.54298
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 23,059.26886
Overall Steps per Second: 10,782.01647

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.47031
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.63976

Cumulative Model Updates: 255,942
Cumulative Timesteps: 2,134,520,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2134520946...
Checkpoint 2134520946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.66991
Policy Entropy: 2.09598
Value Function Loss: 0.01876

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.62902

Collected Steps per Second: 22,659.79364
Overall Steps per Second: 10,665.75697

Timestep Collection Time: 2.20708
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.68902

Cumulative Model Updates: 255,948
Cumulative Timesteps: 2,134,570,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.82943
Policy Entropy: 2.12161
Value Function Loss: 0.01895

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.54093
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 23,166.40228
Overall Steps per Second: 10,915.30404

Timestep Collection Time: 2.15907
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.58237

Cumulative Model Updates: 255,954
Cumulative Timesteps: 2,134,620,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2134620976...
Checkpoint 2134620976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.29847
Policy Entropy: 2.09593
Value Function Loss: 0.01974

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.53535
Value Function Update Magnitude: 0.61970

Collected Steps per Second: 23,517.35760
Overall Steps per Second: 10,902.84021

Timestep Collection Time: 2.12609
Timestep Consumption Time: 2.45987
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.58596

Cumulative Model Updates: 255,960
Cumulative Timesteps: 2,134,670,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.84744
Policy Entropy: 2.10624
Value Function Loss: 0.01922

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.62303

Collected Steps per Second: 23,101.78018
Overall Steps per Second: 10,664.72365

Timestep Collection Time: 2.16555
Timestep Consumption Time: 2.52543
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69098

Cumulative Model Updates: 255,966
Cumulative Timesteps: 2,134,721,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2134721004...
Checkpoint 2134721004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.66327
Policy Entropy: 2.10828
Value Function Loss: 0.01837

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.53018
Value Function Update Magnitude: 0.61451

Collected Steps per Second: 22,753.18756
Overall Steps per Second: 10,659.47300

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.69198

Cumulative Model Updates: 255,972
Cumulative Timesteps: 2,134,771,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.95675
Policy Entropy: 2.10989
Value Function Loss: 0.01851

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.53516
Value Function Update Magnitude: 0.61560

Collected Steps per Second: 22,667.85220
Overall Steps per Second: 10,849.01068

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.40362
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.61001

Cumulative Model Updates: 255,978
Cumulative Timesteps: 2,134,821,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2134821032...
Checkpoint 2134821032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.84749
Policy Entropy: 2.08749
Value Function Loss: 0.01867

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.15301
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,419.49340
Overall Steps per Second: 10,754.29208

Timestep Collection Time: 2.23083
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.65061

Cumulative Model Updates: 255,984
Cumulative Timesteps: 2,134,871,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.40534
Policy Entropy: 2.08806
Value Function Loss: 0.01901

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.64345

Collected Steps per Second: 23,228.34724
Overall Steps per Second: 10,939.10056

Timestep Collection Time: 2.15254
Timestep Consumption Time: 2.41822
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.57076

Cumulative Model Updates: 255,990
Cumulative Timesteps: 2,134,921,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2134921046...
Checkpoint 2134921046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.58756
Policy Entropy: 2.08676
Value Function Loss: 0.01863

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.65059

Collected Steps per Second: 22,661.23385
Overall Steps per Second: 10,561.51298

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.52867
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.73587

Cumulative Model Updates: 255,996
Cumulative Timesteps: 2,134,971,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.23791
Policy Entropy: 2.07772
Value Function Loss: 0.01930

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.64760

Collected Steps per Second: 22,831.08567
Overall Steps per Second: 10,885.58678

Timestep Collection Time: 2.19043
Timestep Consumption Time: 2.40371
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.59415

Cumulative Model Updates: 256,002
Cumulative Timesteps: 2,135,021,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2135021074...
Checkpoint 2135021074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.71462
Policy Entropy: 2.07041
Value Function Loss: 0.01909

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.65284

Collected Steps per Second: 22,702.81583
Overall Steps per Second: 10,674.25216

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.68698

Cumulative Model Updates: 256,008
Cumulative Timesteps: 2,135,071,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.64336
Policy Entropy: 2.07194
Value Function Loss: 0.02016

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.66150

Collected Steps per Second: 23,388.81192
Overall Steps per Second: 10,952.67774

Timestep Collection Time: 2.13812
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.56582

Cumulative Model Updates: 256,014
Cumulative Timesteps: 2,135,121,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2135121112...
Checkpoint 2135121112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.52094
Policy Entropy: 2.08197
Value Function Loss: 0.01937

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.66105

Collected Steps per Second: 22,882.44712
Overall Steps per Second: 10,710.83062

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.48369
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.66929

Cumulative Model Updates: 256,020
Cumulative Timesteps: 2,135,171,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.21473
Policy Entropy: 2.06457
Value Function Loss: 0.02033

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.55554
Value Function Update Magnitude: 0.66298

Collected Steps per Second: 23,085.08551
Overall Steps per Second: 10,935.89655

Timestep Collection Time: 2.16668
Timestep Consumption Time: 2.40706
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.57374

Cumulative Model Updates: 256,026
Cumulative Timesteps: 2,135,221,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2135221142...
Checkpoint 2135221142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.64714
Policy Entropy: 2.04638
Value Function Loss: 0.01910

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.64672

Collected Steps per Second: 22,668.74530
Overall Steps per Second: 10,687.91234

Timestep Collection Time: 2.20639
Timestep Consumption Time: 2.47329
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.67968

Cumulative Model Updates: 256,032
Cumulative Timesteps: 2,135,271,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.06220
Policy Entropy: 2.03566
Value Function Loss: 0.01937

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.63490

Collected Steps per Second: 22,768.75365
Overall Steps per Second: 10,750.64604

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.45548
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.65200

Cumulative Model Updates: 256,038
Cumulative Timesteps: 2,135,321,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2135321170...
Checkpoint 2135321170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.86973
Policy Entropy: 2.06468
Value Function Loss: 0.01950

Mean KL Divergence: 0.02737
SB3 Clip Fraction: 0.16356
Policy Update Magnitude: 0.50682
Value Function Update Magnitude: 0.62739

Collected Steps per Second: 22,182.61499
Overall Steps per Second: 10,594.19901

Timestep Collection Time: 2.25492
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.72145

Cumulative Model Updates: 256,044
Cumulative Timesteps: 2,135,371,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.08072
Policy Entropy: 2.06795
Value Function Loss: 0.02044

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.52530
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 22,644.89616
Overall Steps per Second: 10,917.06465

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.37217
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.58035

Cumulative Model Updates: 256,050
Cumulative Timesteps: 2,135,421,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2135421194...
Checkpoint 2135421194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.40186
Policy Entropy: 2.07864
Value Function Loss: 0.02038

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.63737

Collected Steps per Second: 22,813.75550
Overall Steps per Second: 10,651.44201

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.69589

Cumulative Model Updates: 256,056
Cumulative Timesteps: 2,135,471,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.08647
Policy Entropy: 2.06291
Value Function Loss: 0.02065

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.64144

Collected Steps per Second: 23,549.40451
Overall Steps per Second: 10,949.20785

Timestep Collection Time: 2.12430
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.56891

Cumulative Model Updates: 256,062
Cumulative Timesteps: 2,135,521,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2135521238...
Checkpoint 2135521238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.98300
Policy Entropy: 2.08430
Value Function Loss: 0.01972

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.65967

Collected Steps per Second: 22,615.93413
Overall Steps per Second: 10,673.09511

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.47464
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.68618

Cumulative Model Updates: 256,068
Cumulative Timesteps: 2,135,571,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.99886
Policy Entropy: 2.09097
Value Function Loss: 0.01821

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.53176
Value Function Update Magnitude: 0.64888

Collected Steps per Second: 23,313.62850
Overall Steps per Second: 10,985.74762

Timestep Collection Time: 2.14467
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.55135

Cumulative Model Updates: 256,074
Cumulative Timesteps: 2,135,621,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2135621254...
Checkpoint 2135621254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.68886
Policy Entropy: 2.11636
Value Function Loss: 0.01724

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 23,082.22169
Overall Steps per Second: 10,882.81149

Timestep Collection Time: 2.16617
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59440

Cumulative Model Updates: 256,080
Cumulative Timesteps: 2,135,671,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.34706
Policy Entropy: 2.09687
Value Function Loss: 0.01777

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.52805
Value Function Update Magnitude: 0.59958

Collected Steps per Second: 22,882.41041
Overall Steps per Second: 10,698.86035

Timestep Collection Time: 2.18543
Timestep Consumption Time: 2.48871
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.67414

Cumulative Model Updates: 256,086
Cumulative Timesteps: 2,135,721,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2135721262...
Checkpoint 2135721262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.13752
Policy Entropy: 2.10235
Value Function Loss: 0.01823

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 22,650.97282
Overall Steps per Second: 10,842.42423

Timestep Collection Time: 2.20768
Timestep Consumption Time: 2.40439
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.61207

Cumulative Model Updates: 256,092
Cumulative Timesteps: 2,135,771,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.07809
Policy Entropy: 2.09578
Value Function Loss: 0.01857

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.52457
Value Function Update Magnitude: 0.62785

Collected Steps per Second: 22,594.05843
Overall Steps per Second: 10,961.94965

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.34939
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.56342

Cumulative Model Updates: 256,098
Cumulative Timesteps: 2,135,821,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2135821292...
Checkpoint 2135821292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.53836
Policy Entropy: 2.08631
Value Function Loss: 0.01974

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.62914

Collected Steps per Second: 22,757.09352
Overall Steps per Second: 10,701.43168

Timestep Collection Time: 2.19844
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.67508

Cumulative Model Updates: 256,104
Cumulative Timesteps: 2,135,871,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.03632
Policy Entropy: 2.07082
Value Function Loss: 0.02015

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.64703

Collected Steps per Second: 23,580.25302
Overall Steps per Second: 10,882.23173

Timestep Collection Time: 2.12144
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.59685

Cumulative Model Updates: 256,110
Cumulative Timesteps: 2,135,921,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2135921346...
Checkpoint 2135921346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.31529
Policy Entropy: 2.06411
Value Function Loss: 0.02093

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.64701

Collected Steps per Second: 22,803.53328
Overall Steps per Second: 10,702.44500

Timestep Collection Time: 2.19317
Timestep Consumption Time: 2.47978
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.67295

Cumulative Model Updates: 256,116
Cumulative Timesteps: 2,135,971,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.73115
Policy Entropy: 2.08035
Value Function Loss: 0.01953

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.64571

Collected Steps per Second: 23,103.43913
Overall Steps per Second: 10,848.39328

Timestep Collection Time: 2.16513
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.61101

Cumulative Model Updates: 256,122
Cumulative Timesteps: 2,136,021,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2136021380...
Checkpoint 2136021380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.05261
Policy Entropy: 2.07970
Value Function Loss: 0.01907

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.63038

Collected Steps per Second: 22,939.50787
Overall Steps per Second: 10,655.27082

Timestep Collection Time: 2.18034
Timestep Consumption Time: 2.51367
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.69401

Cumulative Model Updates: 256,128
Cumulative Timesteps: 2,136,071,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.40411
Policy Entropy: 2.08893
Value Function Loss: 0.01828

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.53065
Value Function Update Magnitude: 0.63851

Collected Steps per Second: 23,159.59132
Overall Steps per Second: 10,911.05998

Timestep Collection Time: 2.15902
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.58269

Cumulative Model Updates: 256,134
Cumulative Timesteps: 2,136,121,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2136121398...
Checkpoint 2136121398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.01569
Policy Entropy: 2.10165
Value Function Loss: 0.01845

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.65838

Collected Steps per Second: 22,301.79455
Overall Steps per Second: 10,643.32125

Timestep Collection Time: 2.24260
Timestep Consumption Time: 2.45650
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.69910

Cumulative Model Updates: 256,140
Cumulative Timesteps: 2,136,171,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.24692
Policy Entropy: 2.10902
Value Function Loss: 0.01872

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.53611
Value Function Update Magnitude: 0.66581

Collected Steps per Second: 22,825.40414
Overall Steps per Second: 10,937.86879

Timestep Collection Time: 2.19168
Timestep Consumption Time: 2.38197
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.57365

Cumulative Model Updates: 256,146
Cumulative Timesteps: 2,136,221,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2136221438...
Checkpoint 2136221438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.31101
Policy Entropy: 2.09792
Value Function Loss: 0.01857

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.52942
Value Function Update Magnitude: 0.67904

Collected Steps per Second: 22,525.68931
Overall Steps per Second: 10,633.35675

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.70369

Cumulative Model Updates: 256,152
Cumulative Timesteps: 2,136,271,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.63444
Policy Entropy: 2.08889
Value Function Loss: 0.01948

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.68300

Collected Steps per Second: 22,976.46273
Overall Steps per Second: 10,828.79145

Timestep Collection Time: 2.17649
Timestep Consumption Time: 2.44157
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.61806

Cumulative Model Updates: 256,158
Cumulative Timesteps: 2,136,321,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2136321462...
Checkpoint 2136321462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.39432
Policy Entropy: 2.09163
Value Function Loss: 0.01834

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.51690
Value Function Update Magnitude: 0.69520

Collected Steps per Second: 22,587.17700
Overall Steps per Second: 10,677.30637

Timestep Collection Time: 2.21427
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.68414

Cumulative Model Updates: 256,164
Cumulative Timesteps: 2,136,371,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.17500
Policy Entropy: 2.07683
Value Function Loss: 0.01804

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.52151
Value Function Update Magnitude: 0.69965

Collected Steps per Second: 23,842.48515
Overall Steps per Second: 10,927.93043

Timestep Collection Time: 2.09777
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.57690

Cumulative Model Updates: 256,170
Cumulative Timesteps: 2,136,421,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2136421492...
Checkpoint 2136421492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.10476
Policy Entropy: 2.06478
Value Function Loss: 0.01798

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.53889
Value Function Update Magnitude: 0.70260

Collected Steps per Second: 22,877.79411
Overall Steps per Second: 10,691.25449

Timestep Collection Time: 2.18596
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.67765

Cumulative Model Updates: 256,176
Cumulative Timesteps: 2,136,471,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.01843
Policy Entropy: 2.05637
Value Function Loss: 0.01867

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.54154
Value Function Update Magnitude: 0.71463

Collected Steps per Second: 23,422.89736
Overall Steps per Second: 10,859.23867

Timestep Collection Time: 2.13483
Timestep Consumption Time: 2.46991
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.60474

Cumulative Model Updates: 256,182
Cumulative Timesteps: 2,136,521,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2136521506...
Checkpoint 2136521506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.47794
Policy Entropy: 2.06588
Value Function Loss: 0.01939

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.72049

Collected Steps per Second: 23,111.73976
Overall Steps per Second: 10,800.14318

Timestep Collection Time: 2.16366
Timestep Consumption Time: 2.46646
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.63012

Cumulative Model Updates: 256,188
Cumulative Timesteps: 2,136,571,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.67713
Policy Entropy: 2.05971
Value Function Loss: 0.01946

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.72441

Collected Steps per Second: 24,271.79872
Overall Steps per Second: 11,178.21227

Timestep Collection Time: 2.06058
Timestep Consumption Time: 2.41366
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.47424

Cumulative Model Updates: 256,194
Cumulative Timesteps: 2,136,621,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2136621526...
Checkpoint 2136621526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.25558
Policy Entropy: 2.05358
Value Function Loss: 0.01881

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.53898
Value Function Update Magnitude: 0.71323

Collected Steps per Second: 21,148.77772
Overall Steps per Second: 10,256.55496

Timestep Collection Time: 2.36486
Timestep Consumption Time: 2.51143
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.87630

Cumulative Model Updates: 256,200
Cumulative Timesteps: 2,136,671,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.87569
Policy Entropy: 2.06085
Value Function Loss: 0.01809

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.53676
Value Function Update Magnitude: 0.69035

Collected Steps per Second: 22,555.49288
Overall Steps per Second: 10,623.49388

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.49089
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.70862

Cumulative Model Updates: 256,206
Cumulative Timesteps: 2,136,721,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2136721562...
Checkpoint 2136721562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.15748
Policy Entropy: 2.07271
Value Function Loss: 0.01760

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.53642
Value Function Update Magnitude: 0.66126

Collected Steps per Second: 22,492.47137
Overall Steps per Second: 10,728.87464

Timestep Collection Time: 2.22421
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.66293

Cumulative Model Updates: 256,212
Cumulative Timesteps: 2,136,771,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.53727
Policy Entropy: 2.08530
Value Function Loss: 0.01776

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.53940
Value Function Update Magnitude: 0.65456

Collected Steps per Second: 14,523.01611
Overall Steps per Second: 8,402.11319

Timestep Collection Time: 3.44364
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 5.95231

Cumulative Model Updates: 256,218
Cumulative Timesteps: 2,136,821,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2136821602...
Checkpoint 2136821602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.08010
Policy Entropy: 2.06760
Value Function Loss: 0.01845

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.52335
Value Function Update Magnitude: 0.65534

Collected Steps per Second: 21,288.96583
Overall Steps per Second: 10,397.30781

Timestep Collection Time: 2.34901
Timestep Consumption Time: 2.46070
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.80971

Cumulative Model Updates: 256,224
Cumulative Timesteps: 2,136,871,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.25646
Policy Entropy: 2.05928
Value Function Loss: 0.01761

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.51352
Value Function Update Magnitude: 0.64374

Collected Steps per Second: 21,711.61709
Overall Steps per Second: 10,393.25584

Timestep Collection Time: 2.30402
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.81312

Cumulative Model Updates: 256,230
Cumulative Timesteps: 2,136,921,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2136921634...
Checkpoint 2136921634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.32664
Policy Entropy: 2.07005
Value Function Loss: 0.01807

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.53025
Value Function Update Magnitude: 0.61880

Collected Steps per Second: 22,454.43114
Overall Steps per Second: 10,642.22821

Timestep Collection Time: 2.22727
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.69939

Cumulative Model Updates: 256,236
Cumulative Timesteps: 2,136,971,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.33728
Policy Entropy: 2.08797
Value Function Loss: 0.01816

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.62107

Collected Steps per Second: 24,040.08205
Overall Steps per Second: 10,973.29258

Timestep Collection Time: 2.08119
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.55943

Cumulative Model Updates: 256,242
Cumulative Timesteps: 2,137,021,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2137021678...
Checkpoint 2137021678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.38927
Policy Entropy: 2.10069
Value Function Loss: 0.01899

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.63992

Collected Steps per Second: 23,082.94201
Overall Steps per Second: 10,773.60252

Timestep Collection Time: 2.16688
Timestep Consumption Time: 2.47576
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.64264

Cumulative Model Updates: 256,248
Cumulative Timesteps: 2,137,071,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.46775
Policy Entropy: 2.09591
Value Function Loss: 0.01928

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.63732

Collected Steps per Second: 23,178.16367
Overall Steps per Second: 10,711.14876

Timestep Collection Time: 2.15807
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.66990

Cumulative Model Updates: 256,254
Cumulative Timesteps: 2,137,121,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2137121716...
Checkpoint 2137121716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.04046
Policy Entropy: 2.07435
Value Function Loss: 0.01918

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.63879

Collected Steps per Second: 22,798.94688
Overall Steps per Second: 10,689.16330

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.67801

Cumulative Model Updates: 256,260
Cumulative Timesteps: 2,137,171,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.82463
Policy Entropy: 2.06597
Value Function Loss: 0.01868

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.53831
Value Function Update Magnitude: 0.62901

Collected Steps per Second: 22,992.72732
Overall Steps per Second: 10,905.71173

Timestep Collection Time: 2.17547
Timestep Consumption Time: 2.41112
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.58659

Cumulative Model Updates: 256,266
Cumulative Timesteps: 2,137,221,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2137221740...
Checkpoint 2137221740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.05188
Policy Entropy: 2.03418
Value Function Loss: 0.01942

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.54704
Value Function Update Magnitude: 0.64607

Collected Steps per Second: 22,831.37220
Overall Steps per Second: 10,662.00533

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.69199

Cumulative Model Updates: 256,272
Cumulative Timesteps: 2,137,271,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.17430
Policy Entropy: 2.04669
Value Function Loss: 0.01916

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.54782
Value Function Update Magnitude: 0.65585

Collected Steps per Second: 22,663.44914
Overall Steps per Second: 10,786.32946

Timestep Collection Time: 2.20708
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.63735

Cumulative Model Updates: 256,278
Cumulative Timesteps: 2,137,321,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2137321786...
Checkpoint 2137321786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.94743
Policy Entropy: 2.03984
Value Function Loss: 0.01963

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.53647
Value Function Update Magnitude: 0.64988

Collected Steps per Second: 22,443.65064
Overall Steps per Second: 10,719.41242

Timestep Collection Time: 2.22807
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.66499

Cumulative Model Updates: 256,284
Cumulative Timesteps: 2,137,371,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.42882
Policy Entropy: 2.06704
Value Function Loss: 0.01842

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.52786
Value Function Update Magnitude: 0.62985

Collected Steps per Second: 23,393.33813
Overall Steps per Second: 10,958.80782

Timestep Collection Time: 2.13787
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.56364

Cumulative Model Updates: 256,290
Cumulative Timesteps: 2,137,421,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2137421804...
Checkpoint 2137421804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.43645
Policy Entropy: 2.05376
Value Function Loss: 0.01800

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.52784
Value Function Update Magnitude: 0.62340

Collected Steps per Second: 23,147.80967
Overall Steps per Second: 10,723.21923

Timestep Collection Time: 2.16107
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.66502

Cumulative Model Updates: 256,296
Cumulative Timesteps: 2,137,471,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.40405
Policy Entropy: 2.06400
Value Function Loss: 0.01715

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.53260
Value Function Update Magnitude: 0.62371

Collected Steps per Second: 23,240.25972
Overall Steps per Second: 10,810.82903

Timestep Collection Time: 2.15256
Timestep Consumption Time: 2.47484
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.62740

Cumulative Model Updates: 256,302
Cumulative Timesteps: 2,137,521,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2137521854...
Checkpoint 2137521854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.70634
Policy Entropy: 2.06422
Value Function Loss: 0.01843

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.61784

Collected Steps per Second: 23,181.53442
Overall Steps per Second: 11,108.40427

Timestep Collection Time: 2.15741
Timestep Consumption Time: 2.34477
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.50218

Cumulative Model Updates: 256,308
Cumulative Timesteps: 2,137,571,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.46602
Policy Entropy: 2.07122
Value Function Loss: 0.01903

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.63125

Collected Steps per Second: 22,921.35344
Overall Steps per Second: 10,849.66434

Timestep Collection Time: 2.18207
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60991

Cumulative Model Updates: 256,314
Cumulative Timesteps: 2,137,621,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2137621882...
Checkpoint 2137621882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.62659
Policy Entropy: 2.08705
Value Function Loss: 0.01888

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.63215

Collected Steps per Second: 22,911.24559
Overall Steps per Second: 10,697.41576

Timestep Collection Time: 2.18268
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.67477

Cumulative Model Updates: 256,320
Cumulative Timesteps: 2,137,671,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.40405
Policy Entropy: 2.08572
Value Function Loss: 0.01843

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.63252

Collected Steps per Second: 23,281.13761
Overall Steps per Second: 10,886.53011

Timestep Collection Time: 2.14800
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.59357

Cumulative Model Updates: 256,326
Cumulative Timesteps: 2,137,721,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2137721898...
Checkpoint 2137721898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.33883
Policy Entropy: 2.07965
Value Function Loss: 0.01741

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.62627

Collected Steps per Second: 22,686.73302
Overall Steps per Second: 10,997.07067

Timestep Collection Time: 2.20508
Timestep Consumption Time: 2.34395
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.54903

Cumulative Model Updates: 256,332
Cumulative Timesteps: 2,137,771,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.64093
Policy Entropy: 2.05801
Value Function Loss: 0.01722

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.62120

Collected Steps per Second: 22,647.89478
Overall Steps per Second: 10,660.83403

Timestep Collection Time: 2.20859
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.69194

Cumulative Model Updates: 256,338
Cumulative Timesteps: 2,137,821,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2137821944...
Checkpoint 2137821944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.63420
Policy Entropy: 2.06600
Value Function Loss: 0.01743

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.52458
Value Function Update Magnitude: 0.62603

Collected Steps per Second: 22,732.19184
Overall Steps per Second: 10,673.04526

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.68601

Cumulative Model Updates: 256,344
Cumulative Timesteps: 2,137,871,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.53133
Policy Entropy: 2.05184
Value Function Loss: 0.01874

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.53025
Value Function Update Magnitude: 0.62463

Collected Steps per Second: 22,867.25355
Overall Steps per Second: 10,724.14657

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.66480

Cumulative Model Updates: 256,350
Cumulative Timesteps: 2,137,921,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2137921984...
Checkpoint 2137921984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.99658
Policy Entropy: 2.07118
Value Function Loss: 0.01860

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.52815
Value Function Update Magnitude: 0.63722

Collected Steps per Second: 22,059.47662
Overall Steps per Second: 10,641.15218

Timestep Collection Time: 2.26751
Timestep Consumption Time: 2.43311
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.70062

Cumulative Model Updates: 256,356
Cumulative Timesteps: 2,137,972,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.22143
Policy Entropy: 2.04546
Value Function Loss: 0.01789

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.51037
Value Function Update Magnitude: 0.63000

Collected Steps per Second: 22,788.36491
Overall Steps per Second: 10,813.53194

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.62606

Cumulative Model Updates: 256,362
Cumulative Timesteps: 2,138,022,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2138022028...
Checkpoint 2138022028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.28211
Policy Entropy: 2.06536
Value Function Loss: 0.01839

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.62143

Collected Steps per Second: 23,089.76974
Overall Steps per Second: 10,778.31969

Timestep Collection Time: 2.16650
Timestep Consumption Time: 2.47467
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.64117

Cumulative Model Updates: 256,368
Cumulative Timesteps: 2,138,072,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.58250
Policy Entropy: 2.05240
Value Function Loss: 0.01850

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.63734

Collected Steps per Second: 22,957.78924
Overall Steps per Second: 10,923.49516

Timestep Collection Time: 2.17922
Timestep Consumption Time: 2.40082
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.58004

Cumulative Model Updates: 256,374
Cumulative Timesteps: 2,138,122,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2138122082...
Checkpoint 2138122082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.55752
Policy Entropy: 2.06778
Value Function Loss: 0.01992

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.54400
Value Function Update Magnitude: 0.64519

Collected Steps per Second: 23,067.97732
Overall Steps per Second: 11,054.79390

Timestep Collection Time: 2.16768
Timestep Consumption Time: 2.35561
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.52329

Cumulative Model Updates: 256,380
Cumulative Timesteps: 2,138,172,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.88061
Policy Entropy: 2.06226
Value Function Loss: 0.01988

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.55060
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 23,044.13110
Overall Steps per Second: 10,859.12736

Timestep Collection Time: 2.17105
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.60718

Cumulative Model Updates: 256,386
Cumulative Timesteps: 2,138,222,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2138222116...
Checkpoint 2138222116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.10717
Policy Entropy: 2.09181
Value Function Loss: 0.01893

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.66313

Collected Steps per Second: 22,373.65198
Overall Steps per Second: 10,748.26376

Timestep Collection Time: 2.23486
Timestep Consumption Time: 2.41724
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.65210

Cumulative Model Updates: 256,392
Cumulative Timesteps: 2,138,272,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.40735
Policy Entropy: 2.10243
Value Function Loss: 0.01923

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.65135

Collected Steps per Second: 22,554.12481
Overall Steps per Second: 10,826.54546

Timestep Collection Time: 2.21831
Timestep Consumption Time: 2.40293
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62123

Cumulative Model Updates: 256,398
Cumulative Timesteps: 2,138,322,150

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2138322150...
Checkpoint 2138322150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.55879
Policy Entropy: 2.11104
Value Function Loss: 0.01946

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.66239

Collected Steps per Second: 22,399.68417
Overall Steps per Second: 10,738.74493

Timestep Collection Time: 2.23307
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.65790

Cumulative Model Updates: 256,404
Cumulative Timesteps: 2,138,372,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.84389
Policy Entropy: 2.06261
Value Function Loss: 0.01985

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.54988
Value Function Update Magnitude: 0.66875

Collected Steps per Second: 23,159.62856
Overall Steps per Second: 10,899.61360

Timestep Collection Time: 2.15988
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.58934

Cumulative Model Updates: 256,410
Cumulative Timesteps: 2,138,422,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2138422192...
Checkpoint 2138422192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.95930
Policy Entropy: 2.04841
Value Function Loss: 0.01933

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.55430
Value Function Update Magnitude: 0.67269

Collected Steps per Second: 22,986.75819
Overall Steps per Second: 10,629.43247

Timestep Collection Time: 2.17577
Timestep Consumption Time: 2.52946
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.70524

Cumulative Model Updates: 256,416
Cumulative Timesteps: 2,138,472,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.82982
Policy Entropy: 2.05106
Value Function Loss: 0.01842

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.68474

Collected Steps per Second: 22,624.12534
Overall Steps per Second: 10,659.24573

Timestep Collection Time: 2.21083
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.69245

Cumulative Model Updates: 256,422
Cumulative Timesteps: 2,138,522,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2138522224...
Checkpoint 2138522224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.62503
Policy Entropy: 2.07954
Value Function Loss: 0.01763

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.52739
Value Function Update Magnitude: 0.66050

Collected Steps per Second: 22,328.12134
Overall Steps per Second: 10,574.91536

Timestep Collection Time: 2.24022
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.73006

Cumulative Model Updates: 256,428
Cumulative Timesteps: 2,138,572,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.71388
Policy Entropy: 2.08805
Value Function Loss: 0.01807

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.17478
Policy Update Magnitude: 0.50981
Value Function Update Magnitude: 0.65967

Collected Steps per Second: 23,362.30783
Overall Steps per Second: 11,118.34700

Timestep Collection Time: 2.14106
Timestep Consumption Time: 2.35781
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.49887

Cumulative Model Updates: 256,434
Cumulative Timesteps: 2,138,622,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2138622264...
Checkpoint 2138622264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.28762
Policy Entropy: 2.08064
Value Function Loss: 0.01756

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.16337
Policy Update Magnitude: 0.51212
Value Function Update Magnitude: 0.65765

Collected Steps per Second: 22,707.92068
Overall Steps per Second: 10,717.96153

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.46349
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.66563

Cumulative Model Updates: 256,440
Cumulative Timesteps: 2,138,672,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.53589
Policy Entropy: 2.05162
Value Function Loss: 0.01920

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.16386
Policy Update Magnitude: 0.53705
Value Function Update Magnitude: 0.64457

Collected Steps per Second: 23,129.91964
Overall Steps per Second: 10,883.37409

Timestep Collection Time: 2.16300
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.59692

Cumulative Model Updates: 256,446
Cumulative Timesteps: 2,138,722,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2138722300...
Checkpoint 2138722300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.27604
Policy Entropy: 2.04911
Value Function Loss: 0.01903

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.65217

Collected Steps per Second: 22,444.97770
Overall Steps per Second: 10,753.80043

Timestep Collection Time: 2.22838
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.65101

Cumulative Model Updates: 256,452
Cumulative Timesteps: 2,138,772,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.31221
Policy Entropy: 2.02776
Value Function Loss: 0.02005

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.55304
Value Function Update Magnitude: 0.66611

Collected Steps per Second: 22,659.53232
Overall Steps per Second: 10,788.84857

Timestep Collection Time: 2.20675
Timestep Consumption Time: 2.42803
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.63479

Cumulative Model Updates: 256,458
Cumulative Timesteps: 2,138,822,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2138822320...
Checkpoint 2138822320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.13171
Policy Entropy: 2.04939
Value Function Loss: 0.01918

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.52843
Value Function Update Magnitude: 0.65550

Collected Steps per Second: 22,524.15152
Overall Steps per Second: 10,699.60630

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.45392
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.67438

Cumulative Model Updates: 256,464
Cumulative Timesteps: 2,138,872,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.65791
Policy Entropy: 2.04638
Value Function Loss: 0.01989

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.65369

Collected Steps per Second: 23,175.07413
Overall Steps per Second: 10,833.29229

Timestep Collection Time: 2.15801
Timestep Consumption Time: 2.45850
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.61651

Cumulative Model Updates: 256,470
Cumulative Timesteps: 2,138,922,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2138922346...
Checkpoint 2138922346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.46528
Policy Entropy: 2.05967
Value Function Loss: 0.01968

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.53437
Value Function Update Magnitude: 0.63636

Collected Steps per Second: 23,045.92788
Overall Steps per Second: 11,072.67030

Timestep Collection Time: 2.17106
Timestep Consumption Time: 2.34764
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.51869

Cumulative Model Updates: 256,476
Cumulative Timesteps: 2,138,972,380

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.93034
Policy Entropy: 2.04768
Value Function Loss: 0.02073

Mean KL Divergence: 0.03161
SB3 Clip Fraction: 0.17367
Policy Update Magnitude: 0.50529
Value Function Update Magnitude: 0.63580

Collected Steps per Second: 22,957.03841
Overall Steps per Second: 10,736.47122

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.47964
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.65814

Cumulative Model Updates: 256,482
Cumulative Timesteps: 2,139,022,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2139022392...
Checkpoint 2139022392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.49399
Policy Entropy: 2.05099
Value Function Loss: 0.02066

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.15556
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.64860

Collected Steps per Second: 23,149.65823
Overall Steps per Second: 10,960.74119

Timestep Collection Time: 2.15986
Timestep Consumption Time: 2.40188
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.56174

Cumulative Model Updates: 256,488
Cumulative Timesteps: 2,139,072,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.66918
Policy Entropy: 2.04517
Value Function Loss: 0.02087

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.15057
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.65377

Collected Steps per Second: 23,029.21481
Overall Steps per Second: 10,867.00854

Timestep Collection Time: 2.17168
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.60219

Cumulative Model Updates: 256,494
Cumulative Timesteps: 2,139,122,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2139122404...
Checkpoint 2139122404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.09316
Policy Entropy: 2.05155
Value Function Loss: 0.02034

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.55709
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 22,939.64663
Overall Steps per Second: 11,053.21727

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.34412
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.52393

Cumulative Model Updates: 256,500
Cumulative Timesteps: 2,139,172,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.52565
Policy Entropy: 2.04299
Value Function Loss: 0.02094

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.54657
Value Function Update Magnitude: 0.65602

Collected Steps per Second: 22,308.80079
Overall Steps per Second: 10,554.92498

Timestep Collection Time: 2.24243
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.73959

Cumulative Model Updates: 256,506
Cumulative Timesteps: 2,139,222,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2139222434...
Checkpoint 2139222434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.48242
Policy Entropy: 2.06734
Value Function Loss: 0.01998

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.54287
Value Function Update Magnitude: 0.65799

Collected Steps per Second: 22,261.67684
Overall Steps per Second: 10,596.08061

Timestep Collection Time: 2.24601
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.71873

Cumulative Model Updates: 256,512
Cumulative Timesteps: 2,139,272,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.00495
Policy Entropy: 2.05808
Value Function Loss: 0.02043

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.53042
Value Function Update Magnitude: 0.64784

Collected Steps per Second: 22,681.79463
Overall Steps per Second: 10,831.57439

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.41298
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61853

Cumulative Model Updates: 256,518
Cumulative Timesteps: 2,139,322,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2139322460...
Checkpoint 2139322460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.10608
Policy Entropy: 2.05316
Value Function Loss: 0.02083

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.54068
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 23,368.78438
Overall Steps per Second: 10,822.61081

Timestep Collection Time: 2.14055
Timestep Consumption Time: 2.48144
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.62199

Cumulative Model Updates: 256,524
Cumulative Timesteps: 2,139,372,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.34735
Policy Entropy: 2.03737
Value Function Loss: 0.02129

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.66100

Collected Steps per Second: 23,457.70536
Overall Steps per Second: 10,797.28552

Timestep Collection Time: 2.13167
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.63116

Cumulative Model Updates: 256,530
Cumulative Timesteps: 2,139,422,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2139422486...
Checkpoint 2139422486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.75362
Policy Entropy: 2.01048
Value Function Loss: 0.02144

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.66555

Collected Steps per Second: 22,920.42498
Overall Steps per Second: 10,775.13588

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.46033
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.64310

Cumulative Model Updates: 256,536
Cumulative Timesteps: 2,139,472,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.21149
Policy Entropy: 2.04509
Value Function Loss: 0.01956

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.55578
Value Function Update Magnitude: 0.67251

Collected Steps per Second: 23,255.58262
Overall Steps per Second: 10,966.70099

Timestep Collection Time: 2.15131
Timestep Consumption Time: 2.41068
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.56199

Cumulative Model Updates: 256,542
Cumulative Timesteps: 2,139,522,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2139522546...
Checkpoint 2139522546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.60490
Policy Entropy: 2.02467
Value Function Loss: 0.01947

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.54913
Value Function Update Magnitude: 0.66411

Collected Steps per Second: 23,290.18815
Overall Steps per Second: 10,923.33996

Timestep Collection Time: 2.14777
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.57937

Cumulative Model Updates: 256,548
Cumulative Timesteps: 2,139,572,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.48765
Policy Entropy: 2.06775
Value Function Loss: 0.01940

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.66317

Collected Steps per Second: 23,096.52204
Overall Steps per Second: 10,886.60365

Timestep Collection Time: 2.16613
Timestep Consumption Time: 2.42943
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.59556

Cumulative Model Updates: 256,554
Cumulative Timesteps: 2,139,622,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2139622598...
Checkpoint 2139622598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.77460
Policy Entropy: 2.06142
Value Function Loss: 0.01911

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.54117
Value Function Update Magnitude: 0.65086

Collected Steps per Second: 22,953.11586
Overall Steps per Second: 10,717.58483

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.66803

Cumulative Model Updates: 256,560
Cumulative Timesteps: 2,139,672,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.64133
Policy Entropy: 2.06864
Value Function Loss: 0.01941

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.53877
Value Function Update Magnitude: 0.63743

Collected Steps per Second: 22,727.07653
Overall Steps per Second: 10,845.45295

Timestep Collection Time: 2.20099
Timestep Consumption Time: 2.41127
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.61226

Cumulative Model Updates: 256,566
Cumulative Timesteps: 2,139,722,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2139722650...
Checkpoint 2139722650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.92980
Policy Entropy: 2.07253
Value Function Loss: 0.01866

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 22,768.89877
Overall Steps per Second: 10,644.03680

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.50209
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.69859

Cumulative Model Updates: 256,572
Cumulative Timesteps: 2,139,772,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.19460
Policy Entropy: 2.08015
Value Function Loss: 0.01892

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.64059

Collected Steps per Second: 22,781.17897
Overall Steps per Second: 10,814.53112

Timestep Collection Time: 2.19611
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62618

Cumulative Model Updates: 256,578
Cumulative Timesteps: 2,139,822,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2139822692...
Checkpoint 2139822692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.18374
Policy Entropy: 2.09002
Value Function Loss: 0.01801

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.53580
Value Function Update Magnitude: 0.62699

Collected Steps per Second: 22,364.34768
Overall Steps per Second: 10,698.05298

Timestep Collection Time: 2.23651
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.67543

Cumulative Model Updates: 256,584
Cumulative Timesteps: 2,139,872,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.66959
Policy Entropy: 2.08185
Value Function Loss: 0.01857

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.61210

Collected Steps per Second: 23,066.29887
Overall Steps per Second: 10,923.05682

Timestep Collection Time: 2.16871
Timestep Consumption Time: 2.41097
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.57967

Cumulative Model Updates: 256,590
Cumulative Timesteps: 2,139,922,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2139922734...
Checkpoint 2139922734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.95132
Policy Entropy: 2.06044
Value Function Loss: 0.01945

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.60381

Collected Steps per Second: 22,978.88314
Overall Steps per Second: 10,687.47687

Timestep Collection Time: 2.17591
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.67837

Cumulative Model Updates: 256,596
Cumulative Timesteps: 2,139,972,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.38161
Policy Entropy: 2.06559
Value Function Loss: 0.02001

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.53380
Value Function Update Magnitude: 0.63154

Collected Steps per Second: 23,323.17412
Overall Steps per Second: 10,856.96287

Timestep Collection Time: 2.14439
Timestep Consumption Time: 2.46224
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.60663

Cumulative Model Updates: 256,602
Cumulative Timesteps: 2,140,022,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2140022748...
Checkpoint 2140022748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.79179
Policy Entropy: 2.05821
Value Function Loss: 0.01944

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.62770

Collected Steps per Second: 22,776.00173
Overall Steps per Second: 10,714.29757

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.66946

Cumulative Model Updates: 256,608
Cumulative Timesteps: 2,140,072,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.90048
Policy Entropy: 2.08589
Value Function Loss: 0.01924

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.60666

Collected Steps per Second: 23,321.64687
Overall Steps per Second: 10,863.58414

Timestep Collection Time: 2.14479
Timestep Consumption Time: 2.45959
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.60437

Cumulative Model Updates: 256,614
Cumulative Timesteps: 2,140,122,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2140122798...
Checkpoint 2140122798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.46450
Policy Entropy: 2.08893
Value Function Loss: 0.01871

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.53502
Value Function Update Magnitude: 0.59405

Collected Steps per Second: 23,495.29594
Overall Steps per Second: 10,868.71459

Timestep Collection Time: 2.12860
Timestep Consumption Time: 2.47287
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.60146

Cumulative Model Updates: 256,620
Cumulative Timesteps: 2,140,172,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.76020
Policy Entropy: 2.12258
Value Function Loss: 0.01808

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.53120
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 22,907.78579
Overall Steps per Second: 10,730.35923

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.66173

Cumulative Model Updates: 256,626
Cumulative Timesteps: 2,140,222,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2140222832...
Checkpoint 2140222832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.59719
Policy Entropy: 2.12390
Value Function Loss: 0.01779

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.64818

Collected Steps per Second: 22,446.06342
Overall Steps per Second: 10,648.71673

Timestep Collection Time: 2.22783
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.69596

Cumulative Model Updates: 256,632
Cumulative Timesteps: 2,140,272,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.67066
Policy Entropy: 2.12536
Value Function Loss: 0.01707

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.53119
Value Function Update Magnitude: 0.65305

Collected Steps per Second: 22,894.02929
Overall Steps per Second: 10,849.02577

Timestep Collection Time: 2.18406
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.60889

Cumulative Model Updates: 256,638
Cumulative Timesteps: 2,140,322,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2140322840...
Checkpoint 2140322840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.35547
Policy Entropy: 2.08182
Value Function Loss: 0.01898

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.63775

Collected Steps per Second: 22,672.42176
Overall Steps per Second: 10,643.04043

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.70054

Cumulative Model Updates: 256,644
Cumulative Timesteps: 2,140,372,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.71532
Policy Entropy: 2.06022
Value Function Loss: 0.01960

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.53927
Value Function Update Magnitude: 0.63652

Collected Steps per Second: 23,306.69921
Overall Steps per Second: 10,897.85086

Timestep Collection Time: 2.14651
Timestep Consumption Time: 2.44412
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.59063

Cumulative Model Updates: 256,650
Cumulative Timesteps: 2,140,422,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2140422896...
Checkpoint 2140422896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.88548
Policy Entropy: 2.06085
Value Function Loss: 0.01999

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.63538

Collected Steps per Second: 23,039.05271
Overall Steps per Second: 10,814.65617

Timestep Collection Time: 2.17101
Timestep Consumption Time: 2.45401
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.62502

Cumulative Model Updates: 256,656
Cumulative Timesteps: 2,140,472,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.99888
Policy Entropy: 2.10717
Value Function Loss: 0.01821

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.62562

Collected Steps per Second: 21,770.26740
Overall Steps per Second: 10,456.54963

Timestep Collection Time: 2.29735
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.78303

Cumulative Model Updates: 256,662
Cumulative Timesteps: 2,140,522,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2140522928...
Checkpoint 2140522928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.53462
Policy Entropy: 2.11712
Value Function Loss: 0.01811

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.52520
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 22,902.73633
Overall Steps per Second: 10,943.55989

Timestep Collection Time: 2.18332
Timestep Consumption Time: 2.38594
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.56926

Cumulative Model Updates: 256,668
Cumulative Timesteps: 2,140,572,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.63871
Policy Entropy: 2.10328
Value Function Loss: 0.01700

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.60559

Collected Steps per Second: 23,040.68894
Overall Steps per Second: 10,879.42316

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.59583

Cumulative Model Updates: 256,674
Cumulative Timesteps: 2,140,622,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2140622932...
Checkpoint 2140622932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.12231
Policy Entropy: 2.09761
Value Function Loss: 0.01740

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.53097
Value Function Update Magnitude: 0.61214

Collected Steps per Second: 23,147.54184
Overall Steps per Second: 10,753.36432

Timestep Collection Time: 2.16092
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.65157

Cumulative Model Updates: 256,680
Cumulative Timesteps: 2,140,672,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.90995
Policy Entropy: 2.08412
Value Function Loss: 0.01744

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.52750
Value Function Update Magnitude: 0.61948

Collected Steps per Second: 22,755.99712
Overall Steps per Second: 10,880.36975

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.39898
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.59690

Cumulative Model Updates: 256,686
Cumulative Timesteps: 2,140,722,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2140722968...
Checkpoint 2140722968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.40638
Policy Entropy: 2.08144
Value Function Loss: 0.01746

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.63743

Collected Steps per Second: 22,264.26527
Overall Steps per Second: 10,759.46717

Timestep Collection Time: 2.24611
Timestep Consumption Time: 2.40170
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.64781

Cumulative Model Updates: 256,692
Cumulative Timesteps: 2,140,772,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.85518
Policy Entropy: 2.04296
Value Function Loss: 0.01879

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 22,755.68705
Overall Steps per Second: 10,740.63652

Timestep Collection Time: 2.19840
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.65764

Cumulative Model Updates: 256,698
Cumulative Timesteps: 2,140,823,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2140823002...
Checkpoint 2140823002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.25382
Policy Entropy: 2.06573
Value Function Loss: 0.01789

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.60316

Collected Steps per Second: 22,728.20536
Overall Steps per Second: 10,631.20206

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.70445

Cumulative Model Updates: 256,704
Cumulative Timesteps: 2,140,873,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.59727
Policy Entropy: 2.07833
Value Function Loss: 0.01938

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.54171
Value Function Update Magnitude: 0.59656

Collected Steps per Second: 23,055.43816
Overall Steps per Second: 10,833.26498

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.44829
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61837

Cumulative Model Updates: 256,710
Cumulative Timesteps: 2,140,923,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2140923048...
Checkpoint 2140923048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.60894
Policy Entropy: 2.10507
Value Function Loss: 0.01847

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.54337
Value Function Update Magnitude: 0.60654

Collected Steps per Second: 22,947.27695
Overall Steps per Second: 10,902.26473

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.40855
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.58859

Cumulative Model Updates: 256,716
Cumulative Timesteps: 2,140,973,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.04638
Policy Entropy: 2.09611
Value Function Loss: 0.01876

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.53426
Value Function Update Magnitude: 0.61452

Collected Steps per Second: 23,135.79983
Overall Steps per Second: 10,756.94278

Timestep Collection Time: 2.16141
Timestep Consumption Time: 2.48731
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.64872

Cumulative Model Updates: 256,722
Cumulative Timesteps: 2,141,023,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2141023080...
Checkpoint 2141023080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.11836
Policy Entropy: 2.09013
Value Function Loss: 0.01892

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.52852
Value Function Update Magnitude: 0.61521

Collected Steps per Second: 22,943.04542
Overall Steps per Second: 10,708.22661

Timestep Collection Time: 2.17975
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.67024

Cumulative Model Updates: 256,728
Cumulative Timesteps: 2,141,073,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.95136
Policy Entropy: 2.07240
Value Function Loss: 0.01983

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.60887

Collected Steps per Second: 23,455.47071
Overall Steps per Second: 10,813.12649

Timestep Collection Time: 2.13264
Timestep Consumption Time: 2.49341
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.62604

Cumulative Model Updates: 256,734
Cumulative Timesteps: 2,141,123,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2141123112...
Checkpoint 2141123112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.65115
Policy Entropy: 2.09450
Value Function Loss: 0.01950

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.60470

Collected Steps per Second: 23,543.92527
Overall Steps per Second: 11,032.99974

Timestep Collection Time: 2.12394
Timestep Consumption Time: 2.40846
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.53240

Cumulative Model Updates: 256,740
Cumulative Timesteps: 2,141,173,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.86084
Policy Entropy: 2.10068
Value Function Loss: 0.02011

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.53238
Value Function Update Magnitude: 0.60879

Collected Steps per Second: 22,461.84215
Overall Steps per Second: 10,581.15620

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.49988
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72633

Cumulative Model Updates: 256,746
Cumulative Timesteps: 2,141,223,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2141223128...
Checkpoint 2141223128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.50269
Policy Entropy: 2.12570
Value Function Loss: 0.01984

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.60913

Collected Steps per Second: 22,470.30905
Overall Steps per Second: 10,612.34099

Timestep Collection Time: 2.22605
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.71338

Cumulative Model Updates: 256,752
Cumulative Timesteps: 2,141,273,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.36588
Policy Entropy: 2.11517
Value Function Loss: 0.02042

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.17069
Policy Update Magnitude: 0.49863
Value Function Update Magnitude: 0.62528

Collected Steps per Second: 22,516.68784
Overall Steps per Second: 10,786.44954

Timestep Collection Time: 2.22111
Timestep Consumption Time: 2.41545
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.63656

Cumulative Model Updates: 256,758
Cumulative Timesteps: 2,141,323,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2141323160...
Checkpoint 2141323160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.73246
Policy Entropy: 2.10099
Value Function Loss: 0.02074

Mean KL Divergence: 0.04015
SB3 Clip Fraction: 0.19408
Policy Update Magnitude: 0.47248
Value Function Update Magnitude: 0.63473

Collected Steps per Second: 23,652.16398
Overall Steps per Second: 10,765.51974

Timestep Collection Time: 2.11516
Timestep Consumption Time: 2.53190
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.64706

Cumulative Model Updates: 256,764
Cumulative Timesteps: 2,141,373,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.30816
Policy Entropy: 2.08454
Value Function Loss: 0.02080

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.16372
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.63978

Collected Steps per Second: 23,230.40161
Overall Steps per Second: 10,867.98130

Timestep Collection Time: 2.15295
Timestep Consumption Time: 2.44900
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60196

Cumulative Model Updates: 256,770
Cumulative Timesteps: 2,141,423,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2141423202...
Checkpoint 2141423202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.41250
Policy Entropy: 2.06935
Value Function Loss: 0.02118

Mean KL Divergence: 0.02834
SB3 Clip Fraction: 0.16533
Policy Update Magnitude: 0.54562
Value Function Update Magnitude: 0.63633

Collected Steps per Second: 22,751.32716
Overall Steps per Second: 10,664.15696

Timestep Collection Time: 2.19776
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68879

Cumulative Model Updates: 256,776
Cumulative Timesteps: 2,141,473,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.91584
Policy Entropy: 2.07319
Value Function Loss: 0.02015

Mean KL Divergence: 0.02860
SB3 Clip Fraction: 0.17653
Policy Update Magnitude: 0.51801
Value Function Update Magnitude: 0.62937

Collected Steps per Second: 22,978.44599
Overall Steps per Second: 10,902.20593

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.41105
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.58770

Cumulative Model Updates: 256,782
Cumulative Timesteps: 2,141,523,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2141523220...
Checkpoint 2141523220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.63314
Policy Entropy: 2.07529
Value Function Loss: 0.02009

Mean KL Divergence: 0.02868
SB3 Clip Fraction: 0.17224
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.62449

Collected Steps per Second: 22,997.79506
Overall Steps per Second: 11,065.28581

Timestep Collection Time: 2.17430
Timestep Consumption Time: 2.34470
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.51900

Cumulative Model Updates: 256,788
Cumulative Timesteps: 2,141,573,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.05548
Policy Entropy: 2.08111
Value Function Loss: 0.01965

Mean KL Divergence: 0.02677
SB3 Clip Fraction: 0.16193
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 23,274.39823
Overall Steps per Second: 10,912.38103

Timestep Collection Time: 2.14923
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.58397

Cumulative Model Updates: 256,794
Cumulative Timesteps: 2,141,623,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2141623246...
Checkpoint 2141623246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.80411
Policy Entropy: 2.09334
Value Function Loss: 0.01940

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.61036

Collected Steps per Second: 22,039.18978
Overall Steps per Second: 10,647.51975

Timestep Collection Time: 2.27014
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.69893

Cumulative Model Updates: 256,800
Cumulative Timesteps: 2,141,673,278

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.20718
Policy Entropy: 2.08198
Value Function Loss: 0.01937

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.60153

Collected Steps per Second: 22,792.31317
Overall Steps per Second: 10,991.31158

Timestep Collection Time: 2.19381
Timestep Consumption Time: 2.35542
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.54923

Cumulative Model Updates: 256,806
Cumulative Timesteps: 2,141,723,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2141723280...
Checkpoint 2141723280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.28282
Policy Entropy: 2.07569
Value Function Loss: 0.02028

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.53095
Value Function Update Magnitude: 0.60506

Collected Steps per Second: 22,864.74267
Overall Steps per Second: 10,642.44369

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.51180
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.69892

Cumulative Model Updates: 256,812
Cumulative Timesteps: 2,141,773,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.10218
Policy Entropy: 2.07017
Value Function Loss: 0.02020

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.52250
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 23,329.32106
Overall Steps per Second: 10,835.48143

Timestep Collection Time: 2.14417
Timestep Consumption Time: 2.47233
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61650

Cumulative Model Updates: 256,818
Cumulative Timesteps: 2,141,823,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2141823310...
Checkpoint 2141823310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.43734
Policy Entropy: 2.08094
Value Function Loss: 0.02025

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.53290
Value Function Update Magnitude: 0.61590

Collected Steps per Second: 22,940.75699
Overall Steps per Second: 10,750.29141

Timestep Collection Time: 2.18014
Timestep Consumption Time: 2.47220
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.65234

Cumulative Model Updates: 256,824
Cumulative Timesteps: 2,141,873,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.46982
Policy Entropy: 2.08177
Value Function Loss: 0.02005

Mean KL Divergence: 0.02933
SB3 Clip Fraction: 0.17050
Policy Update Magnitude: 0.50987
Value Function Update Magnitude: 0.63618

Collected Steps per Second: 23,104.27139
Overall Steps per Second: 10,909.68161

Timestep Collection Time: 2.16531
Timestep Consumption Time: 2.42034
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.58565

Cumulative Model Updates: 256,830
Cumulative Timesteps: 2,141,923,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2141923352...
Checkpoint 2141923352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.72604
Policy Entropy: 2.08134
Value Function Loss: 0.02054

Mean KL Divergence: 0.02892
SB3 Clip Fraction: 0.17064
Policy Update Magnitude: 0.50333
Value Function Update Magnitude: 0.63289

Collected Steps per Second: 22,421.38898
Overall Steps per Second: 10,602.14773

Timestep Collection Time: 2.23091
Timestep Consumption Time: 2.48701
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.71791

Cumulative Model Updates: 256,836
Cumulative Timesteps: 2,141,973,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.60684
Policy Entropy: 2.07641
Value Function Loss: 0.02010

Mean KL Divergence: 0.03125
SB3 Clip Fraction: 0.17618
Policy Update Magnitude: 0.51053
Value Function Update Magnitude: 0.62972

Collected Steps per Second: 23,135.57422
Overall Steps per Second: 10,900.11352

Timestep Collection Time: 2.16221
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.58931

Cumulative Model Updates: 256,842
Cumulative Timesteps: 2,142,023,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2142023396...
Checkpoint 2142023396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.83810
Policy Entropy: 2.09407
Value Function Loss: 0.01985

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.15774
Policy Update Magnitude: 0.53244
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 23,041.17538
Overall Steps per Second: 10,829.29436

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.61951

Cumulative Model Updates: 256,848
Cumulative Timesteps: 2,142,073,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.54631
Policy Entropy: 2.07279
Value Function Loss: 0.01952

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 22,665.08341
Overall Steps per Second: 10,785.72318

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.63780

Cumulative Model Updates: 256,854
Cumulative Timesteps: 2,142,123,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2142123444...
Checkpoint 2142123444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.25534
Policy Entropy: 2.08796
Value Function Loss: 0.01943

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.53008
Value Function Update Magnitude: 0.60125

Collected Steps per Second: 22,659.55058
Overall Steps per Second: 10,631.26155

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.70462

Cumulative Model Updates: 256,860
Cumulative Timesteps: 2,142,173,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.34668
Policy Entropy: 2.06567
Value Function Loss: 0.01907

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.53267
Value Function Update Magnitude: 0.58879

Collected Steps per Second: 22,860.13891
Overall Steps per Second: 10,838.27174

Timestep Collection Time: 2.18879
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61660

Cumulative Model Updates: 256,866
Cumulative Timesteps: 2,142,223,496

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2142223496...
Checkpoint 2142223496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.07072
Policy Entropy: 2.07874
Value Function Loss: 0.01913

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.58870

Collected Steps per Second: 22,517.87466
Overall Steps per Second: 10,723.11450

Timestep Collection Time: 2.22179
Timestep Consumption Time: 2.44383
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.66562

Cumulative Model Updates: 256,872
Cumulative Timesteps: 2,142,273,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.48090
Policy Entropy: 2.06623
Value Function Loss: 0.01973

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.58933

Collected Steps per Second: 22,792.73098
Overall Steps per Second: 10,829.47435

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.42470
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61961

Cumulative Model Updates: 256,878
Cumulative Timesteps: 2,142,323,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2142323554...
Checkpoint 2142323554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.22754
Policy Entropy: 2.07565
Value Function Loss: 0.01947

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.58996

Collected Steps per Second: 23,015.90431
Overall Steps per Second: 11,039.19005

Timestep Collection Time: 2.17337
Timestep Consumption Time: 2.35794
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.53131

Cumulative Model Updates: 256,884
Cumulative Timesteps: 2,142,373,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.25528
Policy Entropy: 2.07468
Value Function Loss: 0.01898

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.59655

Collected Steps per Second: 22,968.71015
Overall Steps per Second: 10,728.38755

Timestep Collection Time: 2.17766
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.66221

Cumulative Model Updates: 256,890
Cumulative Timesteps: 2,142,423,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2142423594...
Checkpoint 2142423594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.83934
Policy Entropy: 2.07059
Value Function Loss: 0.01860

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.53155
Value Function Update Magnitude: 0.59814

Collected Steps per Second: 22,455.98079
Overall Steps per Second: 10,645.53329

Timestep Collection Time: 2.22711
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.69793

Cumulative Model Updates: 256,896
Cumulative Timesteps: 2,142,473,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.21721
Policy Entropy: 2.07759
Value Function Loss: 0.02018

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.54133
Value Function Update Magnitude: 0.61548

Collected Steps per Second: 22,857.53883
Overall Steps per Second: 10,749.13653

Timestep Collection Time: 2.18772
Timestep Consumption Time: 2.46437
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.65209

Cumulative Model Updates: 256,902
Cumulative Timesteps: 2,142,523,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2142523612...
Checkpoint 2142523612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.34196
Policy Entropy: 2.08653
Value Function Loss: 0.01949

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.65037

Collected Steps per Second: 22,743.56872
Overall Steps per Second: 11,001.93819

Timestep Collection Time: 2.19895
Timestep Consumption Time: 2.34679
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.54574

Cumulative Model Updates: 256,908
Cumulative Timesteps: 2,142,573,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.40922
Policy Entropy: 2.09835
Value Function Loss: 0.01952

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.53122
Value Function Update Magnitude: 0.64303

Collected Steps per Second: 22,630.58561
Overall Steps per Second: 10,641.91409

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.69840

Cumulative Model Updates: 256,914
Cumulative Timesteps: 2,142,623,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2142623624...
Checkpoint 2142623624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.66323
Policy Entropy: 2.11701
Value Function Loss: 0.01789

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.52297
Value Function Update Magnitude: 0.61848

Collected Steps per Second: 22,663.73762
Overall Steps per Second: 10,671.91780

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.48022
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.68744

Cumulative Model Updates: 256,920
Cumulative Timesteps: 2,142,673,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.11062
Policy Entropy: 2.13146
Value Function Loss: 0.01803

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.51291
Value Function Update Magnitude: 0.58782

Collected Steps per Second: 22,852.98086
Overall Steps per Second: 10,714.96019

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.66768

Cumulative Model Updates: 256,926
Cumulative Timesteps: 2,142,723,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2142723662...
Checkpoint 2142723662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.92258
Policy Entropy: 2.12523
Value Function Loss: 0.01646

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.50959
Value Function Update Magnitude: 0.57506

Collected Steps per Second: 23,774.04251
Overall Steps per Second: 11,022.57000

Timestep Collection Time: 2.10406
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.53814

Cumulative Model Updates: 256,932
Cumulative Timesteps: 2,142,773,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.97525
Policy Entropy: 2.10576
Value Function Loss: 0.01732

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.51092
Value Function Update Magnitude: 0.57841

Collected Steps per Second: 22,879.17892
Overall Steps per Second: 10,702.73200

Timestep Collection Time: 2.18644
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.67395

Cumulative Model Updates: 256,938
Cumulative Timesteps: 2,142,823,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2142823708...
Checkpoint 2142823708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.32385
Policy Entropy: 2.10835
Value Function Loss: 0.01724

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.52314
Value Function Update Magnitude: 0.60273

Collected Steps per Second: 23,002.15782
Overall Steps per Second: 10,880.50223

Timestep Collection Time: 2.17423
Timestep Consumption Time: 2.42225
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.59648

Cumulative Model Updates: 256,944
Cumulative Timesteps: 2,142,873,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.77363
Policy Entropy: 2.10495
Value Function Loss: 0.01886

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.53184
Value Function Update Magnitude: 0.61970

Collected Steps per Second: 23,342.35824
Overall Steps per Second: 10,978.54338

Timestep Collection Time: 2.14314
Timestep Consumption Time: 2.41356
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.55671

Cumulative Model Updates: 256,950
Cumulative Timesteps: 2,142,923,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2142923746...
Checkpoint 2142923746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.14731
Policy Entropy: 2.11263
Value Function Loss: 0.01900

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.52403
Value Function Update Magnitude: 0.61592

Collected Steps per Second: 22,261.32105
Overall Steps per Second: 10,710.62253

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.67050

Cumulative Model Updates: 256,956
Cumulative Timesteps: 2,142,973,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.49502
Policy Entropy: 2.11214
Value Function Loss: 0.01993

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.53211
Value Function Update Magnitude: 0.62605

Collected Steps per Second: 22,770.73303
Overall Steps per Second: 10,812.46526

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.42888
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62503

Cumulative Model Updates: 256,962
Cumulative Timesteps: 2,143,023,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2143023778...
Checkpoint 2143023778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.85113
Policy Entropy: 2.10851
Value Function Loss: 0.01898

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.53296
Value Function Update Magnitude: 0.64063

Collected Steps per Second: 22,200.35873
Overall Steps per Second: 10,731.98289

Timestep Collection Time: 2.25348
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.66158

Cumulative Model Updates: 256,968
Cumulative Timesteps: 2,143,073,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.36538
Policy Entropy: 2.09020
Value Function Loss: 0.01857

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.63853

Collected Steps per Second: 22,748.47691
Overall Steps per Second: 10,854.18708

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.40992
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.60910

Cumulative Model Updates: 256,974
Cumulative Timesteps: 2,143,123,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2143123834...
Checkpoint 2143123834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.55093
Policy Entropy: 2.07983
Value Function Loss: 0.01801

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.64299

Collected Steps per Second: 22,486.43799
Overall Steps per Second: 10,800.99519

Timestep Collection Time: 2.22401
Timestep Consumption Time: 2.40612
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.63013

Cumulative Model Updates: 256,980
Cumulative Timesteps: 2,143,173,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.31237
Policy Entropy: 2.07293
Value Function Loss: 0.01834

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.53155
Value Function Update Magnitude: 0.63702

Collected Steps per Second: 23,167.01365
Overall Steps per Second: 10,766.55458

Timestep Collection Time: 2.15954
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.64680

Cumulative Model Updates: 256,986
Cumulative Timesteps: 2,143,223,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2143223874...
Checkpoint 2143223874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.36322
Policy Entropy: 2.07876
Value Function Loss: 0.01852

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.51890
Value Function Update Magnitude: 0.61606

Collected Steps per Second: 22,809.07641
Overall Steps per Second: 10,619.49961

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.51752
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.71077

Cumulative Model Updates: 256,992
Cumulative Timesteps: 2,143,273,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.32552
Policy Entropy: 2.07262
Value Function Loss: 0.01955

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.50174
Value Function Update Magnitude: 0.61732

Collected Steps per Second: 22,973.90721
Overall Steps per Second: 10,913.62600

Timestep Collection Time: 2.17751
Timestep Consumption Time: 2.40630
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.58381

Cumulative Model Updates: 256,998
Cumulative Timesteps: 2,143,323,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2143323926...
Checkpoint 2143323926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.99515
Policy Entropy: 2.06133
Value Function Loss: 0.02103

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.51188
Value Function Update Magnitude: 0.63660

Collected Steps per Second: 23,171.59344
Overall Steps per Second: 11,094.37966

Timestep Collection Time: 2.15859
Timestep Consumption Time: 2.34982
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.50841

Cumulative Model Updates: 257,004
Cumulative Timesteps: 2,143,373,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.15435
Policy Entropy: 2.06052
Value Function Loss: 0.02059

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.16138
Policy Update Magnitude: 0.49881
Value Function Update Magnitude: 0.63616

Collected Steps per Second: 22,930.69061
Overall Steps per Second: 10,865.18104

Timestep Collection Time: 2.18127
Timestep Consumption Time: 2.42224
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.60351

Cumulative Model Updates: 257,010
Cumulative Timesteps: 2,143,423,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2143423962...
Checkpoint 2143423962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.44692
Policy Entropy: 2.05008
Value Function Loss: 0.02056

Mean KL Divergence: 0.03266
SB3 Clip Fraction: 0.18314
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 22,654.80170
Overall Steps per Second: 10,759.40683

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.44025
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.64747

Cumulative Model Updates: 257,016
Cumulative Timesteps: 2,143,473,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.87662
Policy Entropy: 2.07876
Value Function Loss: 0.01992

Mean KL Divergence: 0.03751
SB3 Clip Fraction: 0.19144
Policy Update Magnitude: 0.48791
Value Function Update Magnitude: 0.62319

Collected Steps per Second: 22,689.20256
Overall Steps per Second: 10,827.22422

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.41536
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62002

Cumulative Model Updates: 257,022
Cumulative Timesteps: 2,143,523,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2143523988...
Checkpoint 2143523988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.45752
Policy Entropy: 2.10048
Value Function Loss: 0.01949

Mean KL Divergence: 0.04260
SB3 Clip Fraction: 0.20865
Policy Update Magnitude: 0.48350
Value Function Update Magnitude: 0.62953

Collected Steps per Second: 23,460.40286
Overall Steps per Second: 10,833.43539

Timestep Collection Time: 2.13227
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.61756

Cumulative Model Updates: 257,028
Cumulative Timesteps: 2,143,574,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.80949
Policy Entropy: 2.11545
Value Function Loss: 0.02022

Mean KL Divergence: 0.03547
SB3 Clip Fraction: 0.17545
Policy Update Magnitude: 0.52942
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 22,537.06327
Overall Steps per Second: 10,763.10769

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.42722
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.64606

Cumulative Model Updates: 257,034
Cumulative Timesteps: 2,143,624,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2143624018...
Checkpoint 2143624018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.24957
Policy Entropy: 2.10926
Value Function Loss: 0.02041

Mean KL Divergence: 0.03428
SB3 Clip Fraction: 0.18468
Policy Update Magnitude: 0.55221
Value Function Update Magnitude: 0.61857

Collected Steps per Second: 22,532.96346
Overall Steps per Second: 10,655.16893

Timestep Collection Time: 2.22013
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.69500

Cumulative Model Updates: 257,040
Cumulative Timesteps: 2,143,674,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.62871
Policy Entropy: 2.10289
Value Function Loss: 0.02200

Mean KL Divergence: 0.03352
SB3 Clip Fraction: 0.18877
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.63581

Collected Steps per Second: 23,236.48230
Overall Steps per Second: 10,914.51163

Timestep Collection Time: 2.15299
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.58362

Cumulative Model Updates: 257,046
Cumulative Timesteps: 2,143,724,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2143724072...
Checkpoint 2143724072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.83212
Policy Entropy: 2.10200
Value Function Loss: 0.02073

Mean KL Divergence: 0.03552
SB3 Clip Fraction: 0.19489
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.65408

Collected Steps per Second: 23,075.05409
Overall Steps per Second: 10,715.93626

Timestep Collection Time: 2.16736
Timestep Consumption Time: 2.49971
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.66707

Cumulative Model Updates: 257,052
Cumulative Timesteps: 2,143,774,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.77902
Policy Entropy: 2.10978
Value Function Loss: 0.02022

Mean KL Divergence: 0.03384
SB3 Clip Fraction: 0.18929
Policy Update Magnitude: 0.52067
Value Function Update Magnitude: 0.64031

Collected Steps per Second: 23,190.98344
Overall Steps per Second: 10,828.59116

Timestep Collection Time: 2.15679
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.61907

Cumulative Model Updates: 257,058
Cumulative Timesteps: 2,143,824,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2143824102...
Checkpoint 2143824102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.71386
Policy Entropy: 2.10637
Value Function Loss: 0.01940

Mean KL Divergence: 0.02800
SB3 Clip Fraction: 0.17538
Policy Update Magnitude: 0.51321
Value Function Update Magnitude: 0.63317

Collected Steps per Second: 22,794.16886
Overall Steps per Second: 10,652.64505

Timestep Collection Time: 2.19363
Timestep Consumption Time: 2.50023
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.69386

Cumulative Model Updates: 257,064
Cumulative Timesteps: 2,143,874,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.20345
Policy Entropy: 2.13708
Value Function Loss: 0.01956

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.17363
Policy Update Magnitude: 0.50773
Value Function Update Magnitude: 0.64941

Collected Steps per Second: 23,120.77606
Overall Steps per Second: 10,872.43701

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.43759
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.60136

Cumulative Model Updates: 257,070
Cumulative Timesteps: 2,143,924,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2143924132...
Checkpoint 2143924132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.43544
Policy Entropy: 2.14565
Value Function Loss: 0.01915

Mean KL Divergence: 0.02636
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.53336
Value Function Update Magnitude: 0.65431

Collected Steps per Second: 22,753.04681
Overall Steps per Second: 10,907.47916

Timestep Collection Time: 2.19883
Timestep Consumption Time: 2.38793
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.58676

Cumulative Model Updates: 257,076
Cumulative Timesteps: 2,143,974,162

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.53554
Policy Entropy: 2.14633
Value Function Loss: 0.01958

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.53707
Value Function Update Magnitude: 0.63678

Collected Steps per Second: 22,561.25563
Overall Steps per Second: 10,679.16413

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.46622
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.68276

Cumulative Model Updates: 257,082
Cumulative Timesteps: 2,144,024,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2144024170...
Checkpoint 2144024170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.77348
Policy Entropy: 2.13771
Value Function Loss: 0.01958

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.61554

Collected Steps per Second: 22,266.06780
Overall Steps per Second: 10,645.80128

Timestep Collection Time: 2.24566
Timestep Consumption Time: 2.45122
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.69688

Cumulative Model Updates: 257,088
Cumulative Timesteps: 2,144,074,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.30976
Policy Entropy: 2.12827
Value Function Loss: 0.02007

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.54215
Value Function Update Magnitude: 0.60606

Collected Steps per Second: 22,626.68851
Overall Steps per Second: 10,811.76256

Timestep Collection Time: 2.21013
Timestep Consumption Time: 2.41520
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62533

Cumulative Model Updates: 257,094
Cumulative Timesteps: 2,144,124,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2144124180...
Checkpoint 2144124180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.08230
Policy Entropy: 2.11360
Value Function Loss: 0.02125

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.54444
Value Function Update Magnitude: 0.61066

Collected Steps per Second: 23,569.61215
Overall Steps per Second: 10,865.86891

Timestep Collection Time: 2.12231
Timestep Consumption Time: 2.48128
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.60359

Cumulative Model Updates: 257,100
Cumulative Timesteps: 2,144,174,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.94784
Policy Entropy: 2.09269
Value Function Loss: 0.02050

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.54089
Value Function Update Magnitude: 0.62596

Collected Steps per Second: 23,284.71652
Overall Steps per Second: 10,748.08262

Timestep Collection Time: 2.14828
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.65404

Cumulative Model Updates: 257,106
Cumulative Timesteps: 2,144,224,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2144224224...
Checkpoint 2144224224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.76425
Policy Entropy: 2.09116
Value Function Loss: 0.02010

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.53705
Value Function Update Magnitude: 0.63501

Collected Steps per Second: 23,047.71559
Overall Steps per Second: 10,705.87999

Timestep Collection Time: 2.16941
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.67033

Cumulative Model Updates: 257,112
Cumulative Timesteps: 2,144,274,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.86626
Policy Entropy: 2.08376
Value Function Loss: 0.01902

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 23,305.58488
Overall Steps per Second: 10,835.33281

Timestep Collection Time: 2.14644
Timestep Consumption Time: 2.47031
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.61675

Cumulative Model Updates: 257,118
Cumulative Timesteps: 2,144,324,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2144324248...
Checkpoint 2144324248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.60000
Policy Entropy: 2.09401
Value Function Loss: 0.01826

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.61671

Collected Steps per Second: 22,565.04712
Overall Steps per Second: 10,741.67226

Timestep Collection Time: 2.21599
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.65514

Cumulative Model Updates: 257,124
Cumulative Timesteps: 2,144,374,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.74907
Policy Entropy: 2.10453
Value Function Loss: 0.01791

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.51132
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 23,130.32387
Overall Steps per Second: 10,852.03205

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.60909

Cumulative Model Updates: 257,130
Cumulative Timesteps: 2,144,424,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2144424270...
Checkpoint 2144424270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.39693
Policy Entropy: 2.11976
Value Function Loss: 0.01854

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.50681
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 22,900.42492
Overall Steps per Second: 10,694.84036

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.49179
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.67515

Cumulative Model Updates: 257,136
Cumulative Timesteps: 2,144,474,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.81497
Policy Entropy: 2.13577
Value Function Loss: 0.01831

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.50226
Value Function Update Magnitude: 0.59837

Collected Steps per Second: 23,169.55641
Overall Steps per Second: 10,838.75213

Timestep Collection Time: 2.15887
Timestep Consumption Time: 2.45605
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.61492

Cumulative Model Updates: 257,142
Cumulative Timesteps: 2,144,524,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2144524290...
Checkpoint 2144524290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.73350
Policy Entropy: 2.12172
Value Function Loss: 0.01858

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.51595
Value Function Update Magnitude: 0.59642

Collected Steps per Second: 23,123.65998
Overall Steps per Second: 10,757.83383

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.64908

Cumulative Model Updates: 257,148
Cumulative Timesteps: 2,144,574,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.06763
Policy Entropy: 2.11159
Value Function Loss: 0.01814

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.51342
Value Function Update Magnitude: 0.59613

Collected Steps per Second: 22,779.98042
Overall Steps per Second: 10,773.22983

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.44622
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.64113

Cumulative Model Updates: 257,154
Cumulative Timesteps: 2,144,624,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2144624304...
Checkpoint 2144624304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.38900
Policy Entropy: 2.08385
Value Function Loss: 0.02005

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.53091
Value Function Update Magnitude: 0.59814

Collected Steps per Second: 22,191.55568
Overall Steps per Second: 10,593.96671

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72061

Cumulative Model Updates: 257,160
Cumulative Timesteps: 2,144,674,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.82385
Policy Entropy: 2.08773
Value Function Loss: 0.01963

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.53492
Value Function Update Magnitude: 0.60479

Collected Steps per Second: 22,738.62658
Overall Steps per Second: 10,843.15867

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.41317
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.61286

Cumulative Model Updates: 257,166
Cumulative Timesteps: 2,144,724,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2144724332...
Checkpoint 2144724332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.24969
Policy Entropy: 2.10148
Value Function Loss: 0.01932

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.52583
Value Function Update Magnitude: 0.60205

Collected Steps per Second: 23,792.20208
Overall Steps per Second: 10,846.60859

Timestep Collection Time: 2.10237
Timestep Consumption Time: 2.50921
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.61158

Cumulative Model Updates: 257,172
Cumulative Timesteps: 2,144,774,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.35115
Policy Entropy: 2.11966
Value Function Loss: 0.01865

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.52844
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 23,384.43870
Overall Steps per Second: 10,830.92995

Timestep Collection Time: 2.13929
Timestep Consumption Time: 2.47952
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.61881

Cumulative Model Updates: 257,178
Cumulative Timesteps: 2,144,824,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2144824378...
Checkpoint 2144824378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.11970
Policy Entropy: 2.10914
Value Function Loss: 0.01848

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.58900

Collected Steps per Second: 22,741.54999
Overall Steps per Second: 10,646.58251

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.69916

Cumulative Model Updates: 257,184
Cumulative Timesteps: 2,144,874,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.35646
Policy Entropy: 2.11428
Value Function Loss: 0.01864

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.52473
Value Function Update Magnitude: 0.60057

Collected Steps per Second: 23,237.44789
Overall Steps per Second: 10,895.42067

Timestep Collection Time: 2.15273
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.59129

Cumulative Model Updates: 257,190
Cumulative Timesteps: 2,144,924,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2144924432...
Checkpoint 2144924432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.67367
Policy Entropy: 2.10667
Value Function Loss: 0.01800

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.61055

Collected Steps per Second: 22,966.14197
Overall Steps per Second: 11,040.53390

Timestep Collection Time: 2.17799
Timestep Consumption Time: 2.35259
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.53058

Cumulative Model Updates: 257,196
Cumulative Timesteps: 2,144,974,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.19527
Policy Entropy: 2.10473
Value Function Loss: 0.01970

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.53959
Value Function Update Magnitude: 0.63348

Collected Steps per Second: 23,024.23475
Overall Steps per Second: 10,878.78320

Timestep Collection Time: 2.17171
Timestep Consumption Time: 2.42457
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.59629

Cumulative Model Updates: 257,202
Cumulative Timesteps: 2,145,024,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2145024454...
Checkpoint 2145024454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.85815
Policy Entropy: 2.10025
Value Function Loss: 0.02031

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.53964
Value Function Update Magnitude: 0.63214

Collected Steps per Second: 22,679.18529
Overall Steps per Second: 10,754.52843

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.65106

Cumulative Model Updates: 257,208
Cumulative Timesteps: 2,145,074,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.40784
Policy Entropy: 2.11892
Value Function Loss: 0.02055

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.54160
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 22,373.87924
Overall Steps per Second: 10,642.12186

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.46366
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.69850

Cumulative Model Updates: 257,214
Cumulative Timesteps: 2,145,124,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2145124476...
Checkpoint 2145124476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.03024
Policy Entropy: 2.12812
Value Function Loss: 0.01965

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.61233

Collected Steps per Second: 22,547.30018
Overall Steps per Second: 10,880.69096

Timestep Collection Time: 2.21756
Timestep Consumption Time: 2.37774
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.59530

Cumulative Model Updates: 257,220
Cumulative Timesteps: 2,145,174,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.72947
Policy Entropy: 2.13260
Value Function Loss: 0.01954

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.54554
Value Function Update Magnitude: 0.61380

Collected Steps per Second: 22,830.38109
Overall Steps per Second: 10,810.47172

Timestep Collection Time: 2.19050
Timestep Consumption Time: 2.43557
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.62607

Cumulative Model Updates: 257,226
Cumulative Timesteps: 2,145,224,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2145224486...
Checkpoint 2145224486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.03943
Policy Entropy: 2.11641
Value Function Loss: 0.02018

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.63166

Collected Steps per Second: 22,841.05289
Overall Steps per Second: 10,666.79383

Timestep Collection Time: 2.18983
Timestep Consumption Time: 2.49930
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.68913

Cumulative Model Updates: 257,232
Cumulative Timesteps: 2,145,274,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.46003
Policy Entropy: 2.12400
Value Function Loss: 0.01989

Mean KL Divergence: 0.02742
SB3 Clip Fraction: 0.15938
Policy Update Magnitude: 0.51151
Value Function Update Magnitude: 0.64596

Collected Steps per Second: 23,010.03340
Overall Steps per Second: 10,946.22034

Timestep Collection Time: 2.17427
Timestep Consumption Time: 2.39626
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.57053

Cumulative Model Updates: 257,238
Cumulative Timesteps: 2,145,324,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2145324534...
Checkpoint 2145324534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.60307
Policy Entropy: 2.12513
Value Function Loss: 0.01931

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.52573
Value Function Update Magnitude: 0.64420

Collected Steps per Second: 22,779.81186
Overall Steps per Second: 10,671.41612

Timestep Collection Time: 2.19616
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.68804

Cumulative Model Updates: 257,244
Cumulative Timesteps: 2,145,374,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.38935
Policy Entropy: 2.14329
Value Function Loss: 0.01874

Mean KL Divergence: 0.03215
SB3 Clip Fraction: 0.17346
Policy Update Magnitude: 0.51971
Value Function Update Magnitude: 0.64002

Collected Steps per Second: 23,267.71200
Overall Steps per Second: 10,941.06602

Timestep Collection Time: 2.14907
Timestep Consumption Time: 2.42123
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.57030

Cumulative Model Updates: 257,250
Cumulative Timesteps: 2,145,424,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2145424566...
Checkpoint 2145424566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.17145
Policy Entropy: 2.13671
Value Function Loss: 0.01837

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.16236
Policy Update Magnitude: 0.52666
Value Function Update Magnitude: 0.64760

Collected Steps per Second: 23,024.31951
Overall Steps per Second: 10,857.39508

Timestep Collection Time: 2.17196
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.60589

Cumulative Model Updates: 257,256
Cumulative Timesteps: 2,145,474,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.04382
Policy Entropy: 2.12812
Value Function Loss: 0.01908

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.52134
Value Function Update Magnitude: 0.63567

Collected Steps per Second: 22,558.34141
Overall Steps per Second: 10,665.97158

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.47232
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.68968

Cumulative Model Updates: 257,262
Cumulative Timesteps: 2,145,524,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2145524594...
Checkpoint 2145524594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.10382
Policy Entropy: 2.10646
Value Function Loss: 0.01987

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.63202

Collected Steps per Second: 23,525.93491
Overall Steps per Second: 11,007.37488

Timestep Collection Time: 2.12565
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.54314

Cumulative Model Updates: 257,268
Cumulative Timesteps: 2,145,574,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.46266
Policy Entropy: 2.09583
Value Function Loss: 0.01987

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.64093

Collected Steps per Second: 22,489.43904
Overall Steps per Second: 10,587.12222

Timestep Collection Time: 2.22335
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.72291

Cumulative Model Updates: 257,274
Cumulative Timesteps: 2,145,624,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2145624604...
Checkpoint 2145624604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.59798
Policy Entropy: 2.11427
Value Function Loss: 0.01914

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.65552

Collected Steps per Second: 22,182.06742
Overall Steps per Second: 10,623.52045

Timestep Collection Time: 2.25488
Timestep Consumption Time: 2.45335
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.70823

Cumulative Model Updates: 257,280
Cumulative Timesteps: 2,145,674,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.42737
Policy Entropy: 2.12272
Value Function Loss: 0.01903

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.52735
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,930.67905
Overall Steps per Second: 10,904.77829

Timestep Collection Time: 2.18127
Timestep Consumption Time: 2.40553
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.58680

Cumulative Model Updates: 257,286
Cumulative Timesteps: 2,145,724,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2145724640...
Checkpoint 2145724640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.79965
Policy Entropy: 2.13878
Value Function Loss: 0.01922

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.53072
Value Function Update Magnitude: 0.64127

Collected Steps per Second: 23,011.94891
Overall Steps per Second: 10,606.61120

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.54177
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.71498

Cumulative Model Updates: 257,292
Cumulative Timesteps: 2,145,774,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.48078
Policy Entropy: 2.12354
Value Function Loss: 0.01961

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.65691

Collected Steps per Second: 22,855.65898
Overall Steps per Second: 10,826.21497

Timestep Collection Time: 2.18887
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.62101

Cumulative Model Updates: 257,298
Cumulative Timesteps: 2,145,824,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2145824678...
Checkpoint 2145824678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.35379
Policy Entropy: 2.13824
Value Function Loss: 0.01926

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.53972
Value Function Update Magnitude: 0.64204

Collected Steps per Second: 22,800.77585
Overall Steps per Second: 10,754.68105

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.64988

Cumulative Model Updates: 257,304
Cumulative Timesteps: 2,145,874,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.32466
Policy Entropy: 2.11883
Value Function Loss: 0.02002

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.63678

Collected Steps per Second: 23,040.42842
Overall Steps per Second: 10,913.63236

Timestep Collection Time: 2.17149
Timestep Consumption Time: 2.41287
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.58436

Cumulative Model Updates: 257,310
Cumulative Timesteps: 2,145,924,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2145924718...
Checkpoint 2145924718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.88196
Policy Entropy: 2.12819
Value Function Loss: 0.01953

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.53704
Value Function Update Magnitude: 0.63531

Collected Steps per Second: 22,903.24186
Overall Steps per Second: 10,654.11018

Timestep Collection Time: 2.18397
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.69490

Cumulative Model Updates: 257,316
Cumulative Timesteps: 2,145,974,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.91212
Policy Entropy: 2.12987
Value Function Loss: 0.01941

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.64323

Collected Steps per Second: 22,959.41645
Overall Steps per Second: 10,846.12198

Timestep Collection Time: 2.17863
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61179

Cumulative Model Updates: 257,322
Cumulative Timesteps: 2,146,024,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2146024758...
Checkpoint 2146024758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.50901
Policy Entropy: 2.15532
Value Function Loss: 0.01796

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.53110
Value Function Update Magnitude: 0.62211

Collected Steps per Second: 22,317.00538
Overall Steps per Second: 10,674.61637

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.44376
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.68438

Cumulative Model Updates: 257,328
Cumulative Timesteps: 2,146,074,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.95569
Policy Entropy: 2.14631
Value Function Loss: 0.01706

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.51719
Value Function Update Magnitude: 0.62602

Collected Steps per Second: 22,534.24681
Overall Steps per Second: 10,948.60706

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.34889
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.56862

Cumulative Model Updates: 257,334
Cumulative Timesteps: 2,146,124,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2146124782...
Checkpoint 2146124782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.76716
Policy Entropy: 2.14938
Value Function Loss: 0.01703

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.52015
Value Function Update Magnitude: 0.62032

Collected Steps per Second: 22,365.78950
Overall Steps per Second: 10,611.51553

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.47710
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.71337

Cumulative Model Updates: 257,340
Cumulative Timesteps: 2,146,174,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.26623
Policy Entropy: 2.13447
Value Function Loss: 0.01791

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.51600
Value Function Update Magnitude: 0.61115

Collected Steps per Second: 22,810.70996
Overall Steps per Second: 10,829.57910

Timestep Collection Time: 2.19283
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.61883

Cumulative Model Updates: 257,346
Cumulative Timesteps: 2,146,224,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2146224818...
Checkpoint 2146224818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.29053
Policy Entropy: 2.15171
Value Function Loss: 0.01900

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.52236
Value Function Update Magnitude: 0.62429

Collected Steps per Second: 22,326.05757
Overall Steps per Second: 10,722.96490

Timestep Collection Time: 2.24034
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.66457

Cumulative Model Updates: 257,352
Cumulative Timesteps: 2,146,274,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.16323
Policy Entropy: 2.15136
Value Function Loss: 0.01839

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.52960
Value Function Update Magnitude: 0.65725

Collected Steps per Second: 21,853.38045
Overall Steps per Second: 10,431.09135

Timestep Collection Time: 2.28825
Timestep Consumption Time: 2.50569
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.79394

Cumulative Model Updates: 257,358
Cumulative Timesteps: 2,146,324,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2146324842...
Checkpoint 2146324842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.00773
Policy Entropy: 2.13984
Value Function Loss: 0.01871

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.53144
Value Function Update Magnitude: 0.65901

Collected Steps per Second: 22,676.82281
Overall Steps per Second: 10,629.45920

Timestep Collection Time: 2.20525
Timestep Consumption Time: 2.49941
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70466

Cumulative Model Updates: 257,364
Cumulative Timesteps: 2,146,374,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.37291
Policy Entropy: 2.14274
Value Function Loss: 0.01867

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.53172
Value Function Update Magnitude: 0.63719

Collected Steps per Second: 22,979.83492
Overall Steps per Second: 10,908.20745

Timestep Collection Time: 2.17774
Timestep Consumption Time: 2.41000
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.58774

Cumulative Model Updates: 257,370
Cumulative Timesteps: 2,146,424,894

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2146424894...
Checkpoint 2146424894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.64305
Policy Entropy: 2.14573
Value Function Loss: 0.01860

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.52020
Value Function Update Magnitude: 0.63640

Collected Steps per Second: 22,620.29766
Overall Steps per Second: 10,673.60131

Timestep Collection Time: 2.21173
Timestep Consumption Time: 2.47553
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.68727

Cumulative Model Updates: 257,376
Cumulative Timesteps: 2,146,474,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.38841
Policy Entropy: 2.14831
Value Function Loss: 0.01856

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.52005
Value Function Update Magnitude: 0.63517

Collected Steps per Second: 23,317.47561
Overall Steps per Second: 10,927.68134

Timestep Collection Time: 2.14449
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.57590

Cumulative Model Updates: 257,382
Cumulative Timesteps: 2,146,524,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2146524928...
Checkpoint 2146524928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.03424
Policy Entropy: 2.14572
Value Function Loss: 0.01928

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.52888
Value Function Update Magnitude: 0.64199

Collected Steps per Second: 22,983.61373
Overall Steps per Second: 10,695.10619

Timestep Collection Time: 2.17572
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.67560

Cumulative Model Updates: 257,388
Cumulative Timesteps: 2,146,574,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.99825
Policy Entropy: 2.13931
Value Function Loss: 0.02040

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.64693

Collected Steps per Second: 23,291.40415
Overall Steps per Second: 10,862.09037

Timestep Collection Time: 2.14757
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.60501

Cumulative Model Updates: 257,394
Cumulative Timesteps: 2,146,624,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2146624954...
Checkpoint 2146624954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.05565
Policy Entropy: 2.14601
Value Function Loss: 0.02027

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.66473

Collected Steps per Second: 22,866.84028
Overall Steps per Second: 11,031.61864

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.34717
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.53496

Cumulative Model Updates: 257,400
Cumulative Timesteps: 2,146,674,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.95282
Policy Entropy: 2.13934
Value Function Loss: 0.01970

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.53037
Value Function Update Magnitude: 0.67121

Collected Steps per Second: 23,268.16260
Overall Steps per Second: 10,935.38065

Timestep Collection Time: 2.14937
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.57341

Cumulative Model Updates: 257,406
Cumulative Timesteps: 2,146,724,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2146724994...
Checkpoint 2146724994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.62315
Policy Entropy: 2.14703
Value Function Loss: 0.01899

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.52194
Value Function Update Magnitude: 0.65488

Collected Steps per Second: 22,549.59206
Overall Steps per Second: 10,646.51315

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.69675

Cumulative Model Updates: 257,412
Cumulative Timesteps: 2,146,774,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.71183
Policy Entropy: 2.14984
Value Function Loss: 0.01933

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.50686
Value Function Update Magnitude: 0.64512

Collected Steps per Second: 22,671.68122
Overall Steps per Second: 10,849.09567

Timestep Collection Time: 2.20566
Timestep Consumption Time: 2.40357
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.60923

Cumulative Model Updates: 257,418
Cumulative Timesteps: 2,146,825,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2146825004...
Checkpoint 2146825004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.53868
Policy Entropy: 2.15828
Value Function Loss: 0.01923

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.51705
Value Function Update Magnitude: 0.64621

Collected Steps per Second: 22,171.58844
Overall Steps per Second: 10,735.47031

Timestep Collection Time: 2.25550
Timestep Consumption Time: 2.40270
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.65820

Cumulative Model Updates: 257,424
Cumulative Timesteps: 2,146,875,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.22950
Policy Entropy: 2.15198
Value Function Loss: 0.02048

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.53144
Value Function Update Magnitude: 0.65637

Collected Steps per Second: 23,492.18269
Overall Steps per Second: 10,922.92470

Timestep Collection Time: 2.12964
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.58028

Cumulative Model Updates: 257,430
Cumulative Timesteps: 2,146,925,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2146925042...
Checkpoint 2146925042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.75794
Policy Entropy: 2.15766
Value Function Loss: 0.02051

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.65571

Collected Steps per Second: 22,887.74526
Overall Steps per Second: 10,606.74032

Timestep Collection Time: 2.18545
Timestep Consumption Time: 2.53042
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.71587

Cumulative Model Updates: 257,436
Cumulative Timesteps: 2,146,975,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.93198
Policy Entropy: 2.13385
Value Function Loss: 0.01993

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.53806
Value Function Update Magnitude: 0.66260

Collected Steps per Second: 23,051.23569
Overall Steps per Second: 10,904.50336

Timestep Collection Time: 2.17030
Timestep Consumption Time: 2.41753
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.58783

Cumulative Model Updates: 257,442
Cumulative Timesteps: 2,147,025,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2147025090...
Checkpoint 2147025090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.47670
Policy Entropy: 2.13805
Value Function Loss: 0.01989

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.67957

Collected Steps per Second: 22,998.25305
Overall Steps per Second: 11,062.57292

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.34585
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.52011

Cumulative Model Updates: 257,448
Cumulative Timesteps: 2,147,075,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.92084
Policy Entropy: 2.14405
Value Function Loss: 0.01889

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.52909
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 23,404.08720
Overall Steps per Second: 10,952.58934

Timestep Collection Time: 2.13749
Timestep Consumption Time: 2.43001
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.56750

Cumulative Model Updates: 257,454
Cumulative Timesteps: 2,147,125,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2147125120...
Checkpoint 2147125120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.54612
Policy Entropy: 2.17089
Value Function Loss: 0.01898

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.52668
Value Function Update Magnitude: 0.65757

Collected Steps per Second: 22,923.68963
Overall Steps per Second: 10,652.68794

Timestep Collection Time: 2.18124
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.69384

Cumulative Model Updates: 257,460
Cumulative Timesteps: 2,147,175,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.82638
Policy Entropy: 2.18015
Value Function Loss: 0.01789

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.51567
Value Function Update Magnitude: 0.64867

Collected Steps per Second: 21,752.92534
Overall Steps per Second: 10,480.15179

Timestep Collection Time: 2.29937
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.77264

Cumulative Model Updates: 257,466
Cumulative Timesteps: 2,147,225,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2147225140...
Checkpoint 2147225140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.81688
Policy Entropy: 2.17279
Value Function Loss: 0.01830

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.52581
Value Function Update Magnitude: 0.61959

Collected Steps per Second: 23,153.69624
Overall Steps per Second: 10,784.65981

Timestep Collection Time: 2.15957
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.63640

Cumulative Model Updates: 257,472
Cumulative Timesteps: 2,147,275,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.56003
Policy Entropy: 2.15653
Value Function Loss: 0.01932

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.53449
Value Function Update Magnitude: 0.62622

Collected Steps per Second: 22,555.53021
Overall Steps per Second: 10,738.55505

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.65649

Cumulative Model Updates: 257,478
Cumulative Timesteps: 2,147,325,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2147325146...
Checkpoint 2147325146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.51403
Policy Entropy: 2.15007
Value Function Loss: 0.01888

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.53402
Value Function Update Magnitude: 0.66597

Collected Steps per Second: 22,472.19276
Overall Steps per Second: 10,666.61367

Timestep Collection Time: 2.22613
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.68996

Cumulative Model Updates: 257,484
Cumulative Timesteps: 2,147,375,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.39387
Policy Entropy: 2.15833
Value Function Loss: 0.01865

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.53132
Value Function Update Magnitude: 0.66896

Collected Steps per Second: 22,699.52874
Overall Steps per Second: 10,842.60978

Timestep Collection Time: 2.20269
Timestep Consumption Time: 2.40875
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.61144

Cumulative Model Updates: 257,490
Cumulative Timesteps: 2,147,425,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2147425172...
Checkpoint 2147425172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.69489
Policy Entropy: 2.16418
Value Function Loss: 0.01876

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.52160
Value Function Update Magnitude: 0.65788

Collected Steps per Second: 23,304.76725
Overall Steps per Second: 10,753.62858

Timestep Collection Time: 2.14737
Timestep Consumption Time: 2.50631
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.65369

Cumulative Model Updates: 257,496
Cumulative Timesteps: 2,147,475,216

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.09395
Policy Entropy: 2.16793
Value Function Loss: 0.01897

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.51333
Value Function Update Magnitude: 0.64571

Collected Steps per Second: 23,455.71226
Overall Steps per Second: 10,866.83032

Timestep Collection Time: 2.13168
Timestep Consumption Time: 2.46948
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.60116

Cumulative Model Updates: 257,502
Cumulative Timesteps: 2,147,525,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2147525216...
Checkpoint 2147525216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.99610
Policy Entropy: 2.17400
Value Function Loss: 0.01882

Mean KL Divergence: 0.02820
SB3 Clip Fraction: 0.17103
Policy Update Magnitude: 0.49431
Value Function Update Magnitude: 0.63607

Collected Steps per Second: 22,764.86797
Overall Steps per Second: 10,622.77811

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.51070
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.70724

Cumulative Model Updates: 257,508
Cumulative Timesteps: 2,147,575,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.22311
Policy Entropy: 2.18274
Value Function Loss: 0.01913

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.51923
Value Function Update Magnitude: 0.64253

Collected Steps per Second: 23,060.37188
Overall Steps per Second: 10,965.77951

Timestep Collection Time: 2.16866
Timestep Consumption Time: 2.39190
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.56055

Cumulative Model Updates: 257,514
Cumulative Timesteps: 2,147,625,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2147625230...
Checkpoint 2147625230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.84717
Policy Entropy: 2.16966
Value Function Loss: 0.01957

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.53124
Value Function Update Magnitude: 0.64949

Collected Steps per Second: 23,122.14821
Overall Steps per Second: 11,130.27121

Timestep Collection Time: 2.16347
Timestep Consumption Time: 2.33094
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.49441

Cumulative Model Updates: 257,520
Cumulative Timesteps: 2,147,675,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.67375
Policy Entropy: 2.15745
Value Function Loss: 0.01943

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.66456

Collected Steps per Second: 23,492.48859
Overall Steps per Second: 10,856.07233

Timestep Collection Time: 2.12868
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.60645

Cumulative Model Updates: 257,526
Cumulative Timesteps: 2,147,725,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2147725262...
Checkpoint 2147725262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.87444
Policy Entropy: 2.16664
Value Function Loss: 0.01880

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.53397
Value Function Update Magnitude: 0.65600

Collected Steps per Second: 22,539.92239
Overall Steps per Second: 10,683.77050

Timestep Collection Time: 2.21926
Timestep Consumption Time: 2.46279
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.68205

Cumulative Model Updates: 257,532
Cumulative Timesteps: 2,147,775,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.25650
Policy Entropy: 2.16597
Value Function Loss: 0.01843

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.52701
Value Function Update Magnitude: 0.64744

Collected Steps per Second: 22,791.99994
Overall Steps per Second: 10,848.83711

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.41523
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.60916

Cumulative Model Updates: 257,538
Cumulative Timesteps: 2,147,825,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2147825288...
Checkpoint 2147825288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.14010
Policy Entropy: 2.15519
Value Function Loss: 0.01961

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.53440
Value Function Update Magnitude: 0.65788

Collected Steps per Second: 22,475.78908
Overall Steps per Second: 10,791.04955

Timestep Collection Time: 2.22577
Timestep Consumption Time: 2.41011
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.63588

Cumulative Model Updates: 257,544
Cumulative Timesteps: 2,147,875,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.11007
Policy Entropy: 2.13860
Value Function Loss: 0.01948

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.53119
Value Function Update Magnitude: 0.67155

Collected Steps per Second: 22,967.25554
Overall Steps per Second: 10,766.90985

Timestep Collection Time: 2.17788
Timestep Consumption Time: 2.46783
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.64572

Cumulative Model Updates: 257,550
Cumulative Timesteps: 2,147,925,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2147925334...
Checkpoint 2147925334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.12038
Policy Entropy: 2.15734
Value Function Loss: 0.02062

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.52759
Value Function Update Magnitude: 0.67090

Collected Steps per Second: 22,585.83831
Overall Steps per Second: 10,670.56644

Timestep Collection Time: 2.21502
Timestep Consumption Time: 2.47339
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.68841

Cumulative Model Updates: 257,556
Cumulative Timesteps: 2,147,975,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.53737
Policy Entropy: 2.17383
Value Function Loss: 0.01877

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.52347
Value Function Update Magnitude: 0.66855

Collected Steps per Second: 23,221.47347
Overall Steps per Second: 10,832.78702

Timestep Collection Time: 2.15327
Timestep Consumption Time: 2.46254
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61580

Cumulative Model Updates: 257,562
Cumulative Timesteps: 2,148,025,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2148025364...
Checkpoint 2148025364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.06561
Policy Entropy: 2.18281
Value Function Loss: 0.01919

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.51800
Value Function Update Magnitude: 0.65134

Collected Steps per Second: 22,722.21470
Overall Steps per Second: 10,812.96659

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.62667

Cumulative Model Updates: 257,568
Cumulative Timesteps: 2,148,075,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.22690
Policy Entropy: 2.17095
Value Function Loss: 0.01803

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.51925
Value Function Update Magnitude: 0.63267

Collected Steps per Second: 23,559.43018
Overall Steps per Second: 10,799.13444

Timestep Collection Time: 2.12348
Timestep Consumption Time: 2.50911
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.63259

Cumulative Model Updates: 257,574
Cumulative Timesteps: 2,148,125,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2148125420...
Checkpoint 2148125420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.18803
Policy Entropy: 2.15524
Value Function Loss: 0.01888

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.52943
Value Function Update Magnitude: 0.61400

Collected Steps per Second: 23,051.85575
Overall Steps per Second: 10,738.62271

Timestep Collection Time: 2.17006
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.65833

Cumulative Model Updates: 257,580
Cumulative Timesteps: 2,148,175,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.00922
Policy Entropy: 2.13308
Value Function Loss: 0.01810

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.60844

Collected Steps per Second: 23,463.64837
Overall Steps per Second: 10,842.88203

Timestep Collection Time: 2.13206
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.61372

Cumulative Model Updates: 257,586
Cumulative Timesteps: 2,148,225,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2148225470...
Checkpoint 2148225470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.20030
Policy Entropy: 2.13112
Value Function Loss: 0.01889

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.52757
Value Function Update Magnitude: 0.61987

Collected Steps per Second: 22,318.32991
Overall Steps per Second: 10,772.60243

Timestep Collection Time: 2.24031
Timestep Consumption Time: 2.40109
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.64140

Cumulative Model Updates: 257,592
Cumulative Timesteps: 2,148,275,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.25222
Policy Entropy: 2.13390
Value Function Loss: 0.01927

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.53168
Value Function Update Magnitude: 0.62365

Collected Steps per Second: 23,229.98507
Overall Steps per Second: 10,786.27889

Timestep Collection Time: 2.15308
Timestep Consumption Time: 2.48392
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.63700

Cumulative Model Updates: 257,598
Cumulative Timesteps: 2,148,325,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2148325486...
Checkpoint 2148325486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.24791
Policy Entropy: 2.15278
Value Function Loss: 0.01816

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.52563
Value Function Update Magnitude: 0.61891

Collected Steps per Second: 22,561.26967
Overall Steps per Second: 10,622.50076

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.70925

Cumulative Model Updates: 257,604
Cumulative Timesteps: 2,148,375,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.49092
Policy Entropy: 2.17299
Value Function Loss: 0.01741

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.51711
Value Function Update Magnitude: 0.60492

Collected Steps per Second: 22,500.48800
Overall Steps per Second: 10,670.44900

Timestep Collection Time: 2.22235
Timestep Consumption Time: 2.46386
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.68621

Cumulative Model Updates: 257,610
Cumulative Timesteps: 2,148,425,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2148425514...
Checkpoint 2148425514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.55812
Policy Entropy: 2.17293
Value Function Loss: 0.01744

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.51301
Value Function Update Magnitude: 0.60331

Collected Steps per Second: 22,579.45751
Overall Steps per Second: 10,882.80845

Timestep Collection Time: 2.21582
Timestep Consumption Time: 2.38152
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.59734

Cumulative Model Updates: 257,616
Cumulative Timesteps: 2,148,475,546

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.99757
Policy Entropy: 2.17315
Value Function Loss: 0.01763

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.51545
Value Function Update Magnitude: 0.61882

Collected Steps per Second: 23,204.86661
Overall Steps per Second: 10,795.89406

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.47776
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.63343

Cumulative Model Updates: 257,622
Cumulative Timesteps: 2,148,525,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2148525568...
Checkpoint 2148525568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.94413
Policy Entropy: 2.15217
Value Function Loss: 0.01759

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.51415
Value Function Update Magnitude: 0.62972

Collected Steps per Second: 22,482.84334
Overall Steps per Second: 10,748.32366

Timestep Collection Time: 2.22392
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.65189

Cumulative Model Updates: 257,628
Cumulative Timesteps: 2,148,575,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.65640
Policy Entropy: 2.16377
Value Function Loss: 0.01900

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.52367
Value Function Update Magnitude: 0.62964

Collected Steps per Second: 23,506.59168
Overall Steps per Second: 10,909.70792

Timestep Collection Time: 2.12774
Timestep Consumption Time: 2.45680
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.58454

Cumulative Model Updates: 257,634
Cumulative Timesteps: 2,148,625,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2148625584...
Checkpoint 2148625584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.48709
Policy Entropy: 2.14483
Value Function Loss: 0.01979

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.64774

Collected Steps per Second: 22,962.83887
Overall Steps per Second: 11,027.12915

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.35759
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.53572

Cumulative Model Updates: 257,640
Cumulative Timesteps: 2,148,675,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.26581
Policy Entropy: 2.12463
Value Function Loss: 0.02101

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.68819

Collected Steps per Second: 23,163.20639
Overall Steps per Second: 10,923.59149

Timestep Collection Time: 2.15998
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58018

Cumulative Model Updates: 257,646
Cumulative Timesteps: 2,148,725,632

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2148725632...
Checkpoint 2148725632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.21472
Policy Entropy: 2.12725
Value Function Loss: 0.01991

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.68943

Collected Steps per Second: 22,798.28485
Overall Steps per Second: 10,726.75272

Timestep Collection Time: 2.19438
Timestep Consumption Time: 2.46948
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.66385

Cumulative Model Updates: 257,652
Cumulative Timesteps: 2,148,775,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.83180
Policy Entropy: 2.13644
Value Function Loss: 0.02025

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.67427

Collected Steps per Second: 22,620.64248
Overall Steps per Second: 10,845.11006

Timestep Collection Time: 2.21179
Timestep Consumption Time: 2.40154
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.61332

Cumulative Model Updates: 257,658
Cumulative Timesteps: 2,148,825,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2148825692...
Checkpoint 2148825692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.87581
Policy Entropy: 2.15669
Value Function Loss: 0.01883

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.52696
Value Function Update Magnitude: 0.66013

Collected Steps per Second: 22,400.87479
Overall Steps per Second: 10,738.68127

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.65700

Cumulative Model Updates: 257,664
Cumulative Timesteps: 2,148,875,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.57140
Policy Entropy: 2.15152
Value Function Loss: 0.01908

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.53239
Value Function Update Magnitude: 0.64875

Collected Steps per Second: 22,790.80889
Overall Steps per Second: 10,833.73736

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.42144
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61540

Cumulative Model Updates: 257,670
Cumulative Timesteps: 2,148,925,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2148925704...
Checkpoint 2148925704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.52943
Policy Entropy: 2.15633
Value Function Loss: 0.01863

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 22,409.26763
Overall Steps per Second: 10,672.19404

Timestep Collection Time: 2.23318
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.68920

Cumulative Model Updates: 257,676
Cumulative Timesteps: 2,148,975,748

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.56013
Policy Entropy: 2.14747
Value Function Loss: 0.01964

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.53951
Value Function Update Magnitude: 0.64643

Collected Steps per Second: 23,465.69584
Overall Steps per Second: 10,905.76489

Timestep Collection Time: 2.13196
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58730

Cumulative Model Updates: 257,682
Cumulative Timesteps: 2,149,025,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2149025776...
Checkpoint 2149025776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.36572
Policy Entropy: 2.15058
Value Function Loss: 0.01984

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.66947

Collected Steps per Second: 22,928.76754
Overall Steps per Second: 10,738.37825

Timestep Collection Time: 2.18163
Timestep Consumption Time: 2.47662
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.65825

Cumulative Model Updates: 257,688
Cumulative Timesteps: 2,149,075,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.60487
Policy Entropy: 2.13661
Value Function Loss: 0.01996

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.68212

Collected Steps per Second: 23,248.11427
Overall Steps per Second: 10,975.27170

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.40508
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.55588

Cumulative Model Updates: 257,694
Cumulative Timesteps: 2,149,125,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2149125800...
Checkpoint 2149125800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.44692
Policy Entropy: 2.14109
Value Function Loss: 0.01856

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.65833

Collected Steps per Second: 23,042.83386
Overall Steps per Second: 10,888.71918

Timestep Collection Time: 2.16987
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59191

Cumulative Model Updates: 257,700
Cumulative Timesteps: 2,149,175,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.62535
Policy Entropy: 2.12913
Value Function Loss: 0.01900

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.63199

Collected Steps per Second: 23,249.91239
Overall Steps per Second: 10,903.61271

Timestep Collection Time: 2.15158
Timestep Consumption Time: 2.43626
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58784

Cumulative Model Updates: 257,706
Cumulative Timesteps: 2,149,225,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2149225824...
Checkpoint 2149225824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.70270
Policy Entropy: 2.11248
Value Function Loss: 0.01922

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.62590

Collected Steps per Second: 22,880.26067
Overall Steps per Second: 10,906.18364

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.39936
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.58474

Cumulative Model Updates: 257,712
Cumulative Timesteps: 2,149,275,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.97050
Policy Entropy: 2.08872
Value Function Loss: 0.02031

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.53613
Value Function Update Magnitude: 0.65886

Collected Steps per Second: 23,339.24413
Overall Steps per Second: 10,796.89267

Timestep Collection Time: 2.14291
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.63226

Cumulative Model Updates: 257,718
Cumulative Timesteps: 2,149,325,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2149325840...
Checkpoint 2149325840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.54038
Policy Entropy: 2.09758
Value Function Loss: 0.01923

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.68069

Collected Steps per Second: 22,289.52440
Overall Steps per Second: 10,526.39422

Timestep Collection Time: 2.24374
Timestep Consumption Time: 2.50736
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.75110

Cumulative Model Updates: 257,724
Cumulative Timesteps: 2,149,375,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.71201
Policy Entropy: 2.12236
Value Function Loss: 0.02016

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.53206
Value Function Update Magnitude: 0.68190

Collected Steps per Second: 22,732.74838
Overall Steps per Second: 10,874.57334

Timestep Collection Time: 2.19982
Timestep Consumption Time: 2.39880
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.59862

Cumulative Model Updates: 257,730
Cumulative Timesteps: 2,149,425,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2149425860...
Checkpoint 2149425860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.43390
Policy Entropy: 2.13056
Value Function Loss: 0.02041

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.66696

Collected Steps per Second: 22,558.54039
Overall Steps per Second: 10,814.40102

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.40807
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.62550

Cumulative Model Updates: 257,736
Cumulative Timesteps: 2,149,475,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.02635
Policy Entropy: 2.13769
Value Function Loss: 0.02103

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.66622

Collected Steps per Second: 23,709.90938
Overall Steps per Second: 10,813.02142

Timestep Collection Time: 2.11009
Timestep Consumption Time: 2.51674
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.62683

Cumulative Model Updates: 257,742
Cumulative Timesteps: 2,149,525,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2149525912...
Checkpoint 2149525912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.46657
Policy Entropy: 2.13828
Value Function Loss: 0.01985

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.53164
Value Function Update Magnitude: 0.66624

Collected Steps per Second: 22,774.35946
Overall Steps per Second: 10,650.44922

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69539

Cumulative Model Updates: 257,748
Cumulative Timesteps: 2,149,575,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.89458
Policy Entropy: 2.15919
Value Function Loss: 0.01931

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.52917
Value Function Update Magnitude: 0.65926

Collected Steps per Second: 22,961.05489
Overall Steps per Second: 10,867.02157

Timestep Collection Time: 2.17978
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.60568

Cumulative Model Updates: 257,754
Cumulative Timesteps: 2,149,625,970

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2149625970...
Checkpoint 2149625970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.98864
Policy Entropy: 2.16605
Value Function Loss: 0.01914

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.66342

Collected Steps per Second: 22,860.92076
Overall Steps per Second: 10,993.64143

Timestep Collection Time: 2.18836
Timestep Consumption Time: 2.36227
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.55063

Cumulative Model Updates: 257,760
Cumulative Timesteps: 2,149,675,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.79770
Policy Entropy: 2.17536
Value Function Loss: 0.01909

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.53314
Value Function Update Magnitude: 0.66697

Collected Steps per Second: 23,629.07826
Overall Steps per Second: 10,995.40574

Timestep Collection Time: 2.11739
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.55026

Cumulative Model Updates: 257,766
Cumulative Timesteps: 2,149,726,030

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2149726030...
Checkpoint 2149726030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.55757
Policy Entropy: 2.16360
Value Function Loss: 0.01938

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.53125
Value Function Update Magnitude: 0.67575

Collected Steps per Second: 22,613.69462
Overall Steps per Second: 10,711.15449

Timestep Collection Time: 2.21193
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.66990

Cumulative Model Updates: 257,772
Cumulative Timesteps: 2,149,776,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.50933
Policy Entropy: 2.12597
Value Function Loss: 0.02071

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.65961

Collected Steps per Second: 22,519.30997
Overall Steps per Second: 10,811.37978

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.40444
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62476

Cumulative Model Updates: 257,778
Cumulative Timesteps: 2,149,826,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2149826050...
Checkpoint 2149826050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.59056
Policy Entropy: 2.09876
Value Function Loss: 0.02080

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.66121

Collected Steps per Second: 22,117.41137
Overall Steps per Second: 10,680.61730

Timestep Collection Time: 2.26139
Timestep Consumption Time: 2.42149
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.68288

Cumulative Model Updates: 257,784
Cumulative Timesteps: 2,149,876,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.29457
Policy Entropy: 2.12292
Value Function Loss: 0.02053

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.67398

Collected Steps per Second: 22,981.32922
Overall Steps per Second: 10,792.44327

Timestep Collection Time: 2.17664
Timestep Consumption Time: 2.45827
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.63491

Cumulative Model Updates: 257,790
Cumulative Timesteps: 2,149,926,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2149926088...
Checkpoint 2149926088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.80253
Policy Entropy: 2.13818
Value Function Loss: 0.01993

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.54863
Value Function Update Magnitude: 0.69803

Collected Steps per Second: 22,292.85520
Overall Steps per Second: 10,681.97342

Timestep Collection Time: 2.24305
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.68116

Cumulative Model Updates: 257,796
Cumulative Timesteps: 2,149,976,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.18462
Policy Entropy: 2.16379
Value Function Loss: 0.01987

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.54756
Value Function Update Magnitude: 0.70208

Collected Steps per Second: 23,096.15561
Overall Steps per Second: 10,921.89073

Timestep Collection Time: 2.16564
Timestep Consumption Time: 2.41397
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.57961

Cumulative Model Updates: 257,802
Cumulative Timesteps: 2,150,026,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2150026110...
Checkpoint 2150026110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.11216
Policy Entropy: 2.13941
Value Function Loss: 0.01998

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.54310
Value Function Update Magnitude: 0.70647

Collected Steps per Second: 23,016.77718
Overall Steps per Second: 10,672.21809

Timestep Collection Time: 2.17302
Timestep Consumption Time: 2.51354
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.68656

Cumulative Model Updates: 257,808
Cumulative Timesteps: 2,150,076,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.58212
Policy Entropy: 2.14019
Value Function Loss: 0.02026

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.68671

Collected Steps per Second: 23,500.24934
Overall Steps per Second: 10,987.09441

Timestep Collection Time: 2.12764
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.55079

Cumulative Model Updates: 257,814
Cumulative Timesteps: 2,150,126,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2150126126...
Checkpoint 2150126126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.63711
Policy Entropy: 2.14948
Value Function Loss: 0.01889

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.66211

Collected Steps per Second: 22,321.13760
Overall Steps per Second: 10,605.42264

Timestep Collection Time: 2.24003
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.71457

Cumulative Model Updates: 257,820
Cumulative Timesteps: 2,150,176,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.93688
Policy Entropy: 2.16235
Value Function Loss: 0.01827

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.51293
Value Function Update Magnitude: 0.64391

Collected Steps per Second: 22,982.58642
Overall Steps per Second: 10,910.99193

Timestep Collection Time: 2.17678
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.58510

Cumulative Model Updates: 257,826
Cumulative Timesteps: 2,150,226,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2150226154...
Checkpoint 2150226154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.76751
Policy Entropy: 2.18669
Value Function Loss: 0.01768

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.64529

Collected Steps per Second: 23,081.76444
Overall Steps per Second: 10,779.27666

Timestep Collection Time: 2.16691
Timestep Consumption Time: 2.47311
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.64001

Cumulative Model Updates: 257,832
Cumulative Timesteps: 2,150,276,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.88857
Policy Entropy: 2.17379
Value Function Loss: 0.01836

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.53241
Value Function Update Magnitude: 0.66308

Collected Steps per Second: 22,823.18259
Overall Steps per Second: 10,730.60911

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.46901
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.65994

Cumulative Model Updates: 257,838
Cumulative Timesteps: 2,150,326,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2150326174...
Checkpoint 2150326174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.77193
Policy Entropy: 2.18579
Value Function Loss: 0.01957

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.53892
Value Function Update Magnitude: 0.67356

Collected Steps per Second: 21,944.92457
Overall Steps per Second: 10,675.78108

Timestep Collection Time: 2.27852
Timestep Consumption Time: 2.40516
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.68369

Cumulative Model Updates: 257,844
Cumulative Timesteps: 2,150,376,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.46841
Policy Entropy: 2.18508
Value Function Loss: 0.01975

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.53631
Value Function Update Magnitude: 0.66408

Collected Steps per Second: 22,710.29531
Overall Steps per Second: 10,880.60225

Timestep Collection Time: 2.20253
Timestep Consumption Time: 2.39465
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.59717

Cumulative Model Updates: 257,850
Cumulative Timesteps: 2,150,426,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2150426196...
Checkpoint 2150426196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.00381
Policy Entropy: 2.18753
Value Function Loss: 0.02009

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.53807
Value Function Update Magnitude: 0.64889

Collected Steps per Second: 22,966.50050
Overall Steps per Second: 10,643.57588

Timestep Collection Time: 2.17795
Timestep Consumption Time: 2.52159
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.69955

Cumulative Model Updates: 257,856
Cumulative Timesteps: 2,150,476,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.63389
Policy Entropy: 2.15692
Value Function Loss: 0.01880

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.53451
Value Function Update Magnitude: 0.65320

Collected Steps per Second: 23,299.08374
Overall Steps per Second: 10,897.43224

Timestep Collection Time: 2.14678
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.58989

Cumulative Model Updates: 257,862
Cumulative Timesteps: 2,150,526,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2150526234...
Checkpoint 2150526234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.91529
Policy Entropy: 2.14609
Value Function Loss: 0.01835

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.64642

Collected Steps per Second: 22,480.99971
Overall Steps per Second: 10,686.72566

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.67964

Cumulative Model Updates: 257,868
Cumulative Timesteps: 2,150,576,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.98755
Policy Entropy: 2.14187
Value Function Loss: 0.01982

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.53463
Value Function Update Magnitude: 0.65115

Collected Steps per Second: 23,435.44530
Overall Steps per Second: 10,965.42961

Timestep Collection Time: 2.13420
Timestep Consumption Time: 2.42704
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.56124

Cumulative Model Updates: 257,874
Cumulative Timesteps: 2,150,626,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2150626260...
Checkpoint 2150626260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.70627
Policy Entropy: 2.16372
Value Function Loss: 0.01984

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.52910
Value Function Update Magnitude: 0.65320

Collected Steps per Second: 23,244.34818
Overall Steps per Second: 10,949.15148

Timestep Collection Time: 2.15201
Timestep Consumption Time: 2.41657
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.56857

Cumulative Model Updates: 257,880
Cumulative Timesteps: 2,150,676,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.61842
Policy Entropy: 2.14847
Value Function Loss: 0.01994

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.63603

Collected Steps per Second: 23,061.76050
Overall Steps per Second: 10,797.15574

Timestep Collection Time: 2.16809
Timestep Consumption Time: 2.46276
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.63085

Cumulative Model Updates: 257,886
Cumulative Timesteps: 2,150,726,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2150726282...
Checkpoint 2150726282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.12560
Policy Entropy: 2.16201
Value Function Loss: 0.01952

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.53295
Value Function Update Magnitude: 0.64061

Collected Steps per Second: 22,171.87476
Overall Steps per Second: 10,756.06816

Timestep Collection Time: 2.25601
Timestep Consumption Time: 2.39439
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65040

Cumulative Model Updates: 257,892
Cumulative Timesteps: 2,150,776,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.46488
Policy Entropy: 2.16006
Value Function Loss: 0.01944

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.53445
Value Function Update Magnitude: 0.63920

Collected Steps per Second: 22,698.17847
Overall Steps per Second: 10,944.79296

Timestep Collection Time: 2.20397
Timestep Consumption Time: 2.36679
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.57076

Cumulative Model Updates: 257,898
Cumulative Timesteps: 2,150,826,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2150826328...
Checkpoint 2150826328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.33031
Policy Entropy: 2.16396
Value Function Loss: 0.01986

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.53486
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 22,382.60969
Overall Steps per Second: 10,683.21883

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.68080

Cumulative Model Updates: 257,904
Cumulative Timesteps: 2,150,876,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.22878
Policy Entropy: 2.13977
Value Function Loss: 0.02025

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 23,013.90332
Overall Steps per Second: 10,845.55537

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.43944
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61369

Cumulative Model Updates: 257,910
Cumulative Timesteps: 2,150,926,372

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2150926372...
Checkpoint 2150926372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.96326
Policy Entropy: 2.13261
Value Function Loss: 0.02001

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.53961
Value Function Update Magnitude: 0.64745

Collected Steps per Second: 22,114.67832
Overall Steps per Second: 10,377.48808

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.55861
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.82082

Cumulative Model Updates: 257,916
Cumulative Timesteps: 2,150,976,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.01500
Policy Entropy: 2.14123
Value Function Loss: 0.01904

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.53705
Value Function Update Magnitude: 0.66821

Collected Steps per Second: 23,441.76074
Overall Steps per Second: 11,023.69572

Timestep Collection Time: 2.13303
Timestep Consumption Time: 2.40283
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.53587

Cumulative Model Updates: 257,922
Cumulative Timesteps: 2,151,026,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2151026402...
Checkpoint 2151026402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.25627
Policy Entropy: 2.15255
Value Function Loss: 0.01869

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.65966

Collected Steps per Second: 23,174.19374
Overall Steps per Second: 10,942.62522

Timestep Collection Time: 2.15861
Timestep Consumption Time: 2.41287
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.57148

Cumulative Model Updates: 257,928
Cumulative Timesteps: 2,151,076,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.39232
Policy Entropy: 2.15327
Value Function Loss: 0.01829

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.53012
Value Function Update Magnitude: 0.63520

Collected Steps per Second: 23,348.49903
Overall Steps per Second: 10,887.89775

Timestep Collection Time: 2.14266
Timestep Consumption Time: 2.45216
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.59483

Cumulative Model Updates: 257,934
Cumulative Timesteps: 2,151,126,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2151126454...
Checkpoint 2151126454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.93538
Policy Entropy: 2.13719
Value Function Loss: 0.01836

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.61577

Collected Steps per Second: 22,771.63394
Overall Steps per Second: 10,646.45211

Timestep Collection Time: 2.19694
Timestep Consumption Time: 2.50209
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.69903

Cumulative Model Updates: 257,940
Cumulative Timesteps: 2,151,176,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.10052
Policy Entropy: 2.12837
Value Function Loss: 0.01964

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.53280
Value Function Update Magnitude: 0.62728

Collected Steps per Second: 22,975.83665
Overall Steps per Second: 10,900.94254

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.41133
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.58823

Cumulative Model Updates: 257,946
Cumulative Timesteps: 2,151,226,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2151226498...
Checkpoint 2151226498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.22857
Policy Entropy: 2.14172
Value Function Loss: 0.02035

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.64273

Collected Steps per Second: 23,067.35275
Overall Steps per Second: 10,681.37428

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.51398
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.68198

Cumulative Model Updates: 257,952
Cumulative Timesteps: 2,151,276,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.15947
Policy Entropy: 2.15446
Value Function Loss: 0.02138

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.52273
Value Function Update Magnitude: 0.65388

Collected Steps per Second: 23,025.23350
Overall Steps per Second: 10,910.72714

Timestep Collection Time: 2.17162
Timestep Consumption Time: 2.41121
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.58283

Cumulative Model Updates: 257,958
Cumulative Timesteps: 2,151,326,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2151326510...
Checkpoint 2151326510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.53217
Policy Entropy: 2.16665
Value Function Loss: 0.01955

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.49746
Value Function Update Magnitude: 0.65550

Collected Steps per Second: 22,503.13150
Overall Steps per Second: 10,591.11771

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.72320

Cumulative Model Updates: 257,964
Cumulative Timesteps: 2,151,376,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.52427
Policy Entropy: 2.16159
Value Function Loss: 0.01982

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.16200
Policy Update Magnitude: 0.48236
Value Function Update Magnitude: 0.64515

Collected Steps per Second: 22,943.09880
Overall Steps per Second: 10,852.16441

Timestep Collection Time: 2.17983
Timestep Consumption Time: 2.42865
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60848

Cumulative Model Updates: 257,970
Cumulative Timesteps: 2,151,426,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2151426546...
Checkpoint 2151426546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.23906
Policy Entropy: 2.17047
Value Function Loss: 0.01962

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.53312
Value Function Update Magnitude: 0.66051

Collected Steps per Second: 23,086.11475
Overall Steps per Second: 11,063.75882

Timestep Collection Time: 2.16684
Timestep Consumption Time: 2.35459
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.52143

Cumulative Model Updates: 257,976
Cumulative Timesteps: 2,151,476,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.52059
Policy Entropy: 2.16300
Value Function Loss: 0.02031

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.66443

Collected Steps per Second: 23,184.16690
Overall Steps per Second: 10,882.63562

Timestep Collection Time: 2.15725
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.59576

Cumulative Model Updates: 257,982
Cumulative Timesteps: 2,151,526,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2151526584...
Checkpoint 2151526584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.81503
Policy Entropy: 2.16838
Value Function Loss: 0.01981

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.54974
Value Function Update Magnitude: 0.64359

Collected Steps per Second: 22,531.55429
Overall Steps per Second: 10,671.45430

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.46688
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.68652

Cumulative Model Updates: 257,988
Cumulative Timesteps: 2,151,576,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.86240
Policy Entropy: 2.15373
Value Function Loss: 0.02074

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.64572

Collected Steps per Second: 23,153.16628
Overall Steps per Second: 11,016.73985

Timestep Collection Time: 2.16022
Timestep Consumption Time: 2.37978
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.54000

Cumulative Model Updates: 257,994
Cumulative Timesteps: 2,151,626,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2151626612...
Checkpoint 2151626612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.88232
Policy Entropy: 2.14790
Value Function Loss: 0.02063

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.55163
Value Function Update Magnitude: 0.66872

Collected Steps per Second: 22,808.90128
Overall Steps per Second: 10,679.09574

Timestep Collection Time: 2.19292
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.68373

Cumulative Model Updates: 258,000
Cumulative Timesteps: 2,151,676,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.25418
Policy Entropy: 2.16024
Value Function Loss: 0.02008

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.67628

Collected Steps per Second: 22,750.96476
Overall Steps per Second: 10,813.11705

Timestep Collection Time: 2.19876
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.62623

Cumulative Model Updates: 258,006
Cumulative Timesteps: 2,151,726,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2151726654...
Checkpoint 2151726654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.87031
Policy Entropy: 2.16458
Value Function Loss: 0.01914

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.53621
Value Function Update Magnitude: 0.65804

Collected Steps per Second: 22,167.59498
Overall Steps per Second: 10,665.97346

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.69005

Cumulative Model Updates: 258,012
Cumulative Timesteps: 2,151,776,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.58297
Policy Entropy: 2.16928
Value Function Loss: 0.01919

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.53086
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 22,819.31626
Overall Steps per Second: 10,859.28457

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.41468
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60712

Cumulative Model Updates: 258,018
Cumulative Timesteps: 2,151,826,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2151826708...
Checkpoint 2151826708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.32365
Policy Entropy: 2.14303
Value Function Loss: 0.01935

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.53480
Value Function Update Magnitude: 0.66300

Collected Steps per Second: 23,379.25288
Overall Steps per Second: 10,704.77543

Timestep Collection Time: 2.13916
Timestep Consumption Time: 2.53277
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.67193

Cumulative Model Updates: 258,024
Cumulative Timesteps: 2,151,876,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.28918
Policy Entropy: 2.15018
Value Function Loss: 0.01963

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.53171
Value Function Update Magnitude: 0.65903

Collected Steps per Second: 23,240.68805
Overall Steps per Second: 10,882.14687

Timestep Collection Time: 2.15140
Timestep Consumption Time: 2.44328
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.59468

Cumulative Model Updates: 258,030
Cumulative Timesteps: 2,151,926,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2151926720...
Checkpoint 2151926720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.08640
Policy Entropy: 2.15107
Value Function Loss: 0.01926

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.53752
Value Function Update Magnitude: 0.64571

Collected Steps per Second: 22,542.42805
Overall Steps per Second: 10,582.59939

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.50770
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.72663

Cumulative Model Updates: 258,036
Cumulative Timesteps: 2,151,976,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.22223
Policy Entropy: 2.16274
Value Function Loss: 0.01847

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.15390
Policy Update Magnitude: 0.50852
Value Function Update Magnitude: 0.63110

Collected Steps per Second: 23,144.26218
Overall Steps per Second: 10,943.58019

Timestep Collection Time: 2.16175
Timestep Consumption Time: 2.41007
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.57181

Cumulative Model Updates: 258,042
Cumulative Timesteps: 2,152,026,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2152026772...
Checkpoint 2152026772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.28337
Policy Entropy: 2.15742
Value Function Loss: 0.01904

Mean KL Divergence: 0.02752
SB3 Clip Fraction: 0.16716
Policy Update Magnitude: 0.49244
Value Function Update Magnitude: 0.62115

Collected Steps per Second: 23,331.36013
Overall Steps per Second: 10,793.77847

Timestep Collection Time: 2.14355
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.63341

Cumulative Model Updates: 258,048
Cumulative Timesteps: 2,152,076,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.06892
Policy Entropy: 2.16072
Value Function Loss: 0.01933

Mean KL Divergence: 0.02577
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.52623
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 22,221.74550
Overall Steps per Second: 10,544.25618

Timestep Collection Time: 2.25149
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.74495

Cumulative Model Updates: 258,054
Cumulative Timesteps: 2,152,126,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2152126816...
Checkpoint 2152126816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.73877
Policy Entropy: 2.16841
Value Function Loss: 0.01960

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.54682
Value Function Update Magnitude: 0.61885

Collected Steps per Second: 22,419.41259
Overall Steps per Second: 10,632.53329

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.47372
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.70518

Cumulative Model Updates: 258,060
Cumulative Timesteps: 2,152,176,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.06014
Policy Entropy: 2.14983
Value Function Loss: 0.01983

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.61612

Collected Steps per Second: 22,999.79160
Overall Steps per Second: 10,943.25756

Timestep Collection Time: 2.17463
Timestep Consumption Time: 2.39586
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.57049

Cumulative Model Updates: 258,066
Cumulative Timesteps: 2,152,226,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2152226860...
Checkpoint 2152226860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.24852
Policy Entropy: 2.13789
Value Function Loss: 0.02016

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.62481

Collected Steps per Second: 23,024.69969
Overall Steps per Second: 10,804.10006

Timestep Collection Time: 2.17202
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.62880

Cumulative Model Updates: 258,072
Cumulative Timesteps: 2,152,276,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.08202
Policy Entropy: 2.13016
Value Function Loss: 0.02227

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.54843
Value Function Update Magnitude: 0.64616

Collected Steps per Second: 23,381.00254
Overall Steps per Second: 10,883.38340

Timestep Collection Time: 2.13917
Timestep Consumption Time: 2.45646
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59563

Cumulative Model Updates: 258,078
Cumulative Timesteps: 2,152,326,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2152326886...
Checkpoint 2152326886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.76478
Policy Entropy: 2.13223
Value Function Loss: 0.02168

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.66896

Collected Steps per Second: 22,690.35028
Overall Steps per Second: 10,764.15774

Timestep Collection Time: 2.20499
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.64802

Cumulative Model Updates: 258,084
Cumulative Timesteps: 2,152,376,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.21034
Policy Entropy: 2.13302
Value Function Loss: 0.02146

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.66756

Collected Steps per Second: 23,314.95913
Overall Steps per Second: 10,890.86856

Timestep Collection Time: 2.14549
Timestep Consumption Time: 2.44753
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.59302

Cumulative Model Updates: 258,090
Cumulative Timesteps: 2,152,426,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2152426940...
Checkpoint 2152426940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.86693
Policy Entropy: 2.14037
Value Function Loss: 0.02138

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.64894

Collected Steps per Second: 23,714.71971
Overall Steps per Second: 11,051.76843

Timestep Collection Time: 2.10899
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.52543

Cumulative Model Updates: 258,096
Cumulative Timesteps: 2,152,476,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.61143
Policy Entropy: 2.14810
Value Function Loss: 0.02114

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.65595

Collected Steps per Second: 23,075.92916
Overall Steps per Second: 10,890.99091

Timestep Collection Time: 2.16702
Timestep Consumption Time: 2.42448
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.59150

Cumulative Model Updates: 258,102
Cumulative Timesteps: 2,152,526,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2152526960...
Checkpoint 2152526960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.28615
Policy Entropy: 2.16226
Value Function Loss: 0.02036

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.64044

Collected Steps per Second: 22,268.22056
Overall Steps per Second: 10,678.00828

Timestep Collection Time: 2.24670
Timestep Consumption Time: 2.43863
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.68533

Cumulative Model Updates: 258,108
Cumulative Timesteps: 2,152,576,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.31327
Policy Entropy: 2.15632
Value Function Loss: 0.01858

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.52662
Value Function Update Magnitude: 0.61176

Collected Steps per Second: 22,687.93554
Overall Steps per Second: 10,717.52232

Timestep Collection Time: 2.20408
Timestep Consumption Time: 2.46174
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.66582

Cumulative Model Updates: 258,114
Cumulative Timesteps: 2,152,626,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2152626996...
Checkpoint 2152626996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.39471
Policy Entropy: 2.15692
Value Function Loss: 0.01786

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.52235
Value Function Update Magnitude: 0.58608

Collected Steps per Second: 23,042.78174
Overall Steps per Second: 10,891.98772

Timestep Collection Time: 2.17179
Timestep Consumption Time: 2.42278
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59457

Cumulative Model Updates: 258,120
Cumulative Timesteps: 2,152,677,040

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.44870
Policy Entropy: 2.15162
Value Function Loss: 0.01740

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.51382
Value Function Update Magnitude: 0.56999

Collected Steps per Second: 22,804.12907
Overall Steps per Second: 10,815.04859

Timestep Collection Time: 2.19311
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62430

Cumulative Model Updates: 258,126
Cumulative Timesteps: 2,152,727,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2152727052...
Checkpoint 2152727052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.30694
Policy Entropy: 2.15164
Value Function Loss: 0.01744

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.51060
Value Function Update Magnitude: 0.57152

Collected Steps per Second: 22,580.04693
Overall Steps per Second: 10,677.08374

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.68349

Cumulative Model Updates: 258,132
Cumulative Timesteps: 2,152,777,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.53081
Policy Entropy: 2.14928
Value Function Loss: 0.01715

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.51262
Value Function Update Magnitude: 0.57173

Collected Steps per Second: 23,091.28164
Overall Steps per Second: 10,876.58345

Timestep Collection Time: 2.16671
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.59997

Cumulative Model Updates: 258,138
Cumulative Timesteps: 2,152,827,090

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2152827090...
Checkpoint 2152827090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.66000
Policy Entropy: 2.16005
Value Function Loss: 0.01831

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.51489
Value Function Update Magnitude: 0.57455

Collected Steps per Second: 22,978.11474
Overall Steps per Second: 10,928.33988

Timestep Collection Time: 2.17651
Timestep Consumption Time: 2.39985
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.57636

Cumulative Model Updates: 258,144
Cumulative Timesteps: 2,152,877,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.93089
Policy Entropy: 2.16500
Value Function Loss: 0.01895

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.52092
Value Function Update Magnitude: 0.60097

Collected Steps per Second: 23,833.96220
Overall Steps per Second: 11,056.87721

Timestep Collection Time: 2.09818
Timestep Consumption Time: 2.42461
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.52280

Cumulative Model Updates: 258,150
Cumulative Timesteps: 2,152,927,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2152927110...
Checkpoint 2152927110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.88746
Policy Entropy: 2.16783
Value Function Loss: 0.01928

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.51596
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 22,640.16005
Overall Steps per Second: 10,789.80869

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.63567

Cumulative Model Updates: 258,156
Cumulative Timesteps: 2,152,977,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.24213
Policy Entropy: 2.15619
Value Function Loss: 0.02076

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.16158
Policy Update Magnitude: 0.48649
Value Function Update Magnitude: 0.63695

Collected Steps per Second: 23,125.72496
Overall Steps per Second: 10,870.82976

Timestep Collection Time: 2.16253
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.60038

Cumulative Model Updates: 258,162
Cumulative Timesteps: 2,153,027,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2153027138...
Checkpoint 2153027138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.53876
Policy Entropy: 2.15249
Value Function Loss: 0.02003

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.14870
Policy Update Magnitude: 0.51225
Value Function Update Magnitude: 0.65974

Collected Steps per Second: 22,498.64589
Overall Steps per Second: 10,845.90233

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.38883
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.61225

Cumulative Model Updates: 258,168
Cumulative Timesteps: 2,153,077,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.96397
Policy Entropy: 2.16159
Value Function Loss: 0.02056

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.15326
Policy Update Magnitude: 0.53471
Value Function Update Magnitude: 0.67144

Collected Steps per Second: 22,934.09244
Overall Steps per Second: 10,721.58322

Timestep Collection Time: 2.18025
Timestep Consumption Time: 2.48343
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.66368

Cumulative Model Updates: 258,174
Cumulative Timesteps: 2,153,127,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2153127164...
Checkpoint 2153127164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.75335
Policy Entropy: 2.17829
Value Function Loss: 0.01962

Mean KL Divergence: 0.02902
SB3 Clip Fraction: 0.16969
Policy Update Magnitude: 0.52493
Value Function Update Magnitude: 0.66914

Collected Steps per Second: 22,199.98397
Overall Steps per Second: 10,611.68686

Timestep Collection Time: 2.25297
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.71329

Cumulative Model Updates: 258,180
Cumulative Timesteps: 2,153,177,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.34508
Policy Entropy: 2.17385
Value Function Loss: 0.01869

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.50910
Value Function Update Magnitude: 0.65693

Collected Steps per Second: 22,821.67113
Overall Steps per Second: 10,865.13053

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.41223
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60427

Cumulative Model Updates: 258,186
Cumulative Timesteps: 2,153,227,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2153227206...
Checkpoint 2153227206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.18055
Policy Entropy: 2.15022
Value Function Loss: 0.01948

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.47882
Value Function Update Magnitude: 0.64519

Collected Steps per Second: 23,458.09677
Overall Steps per Second: 10,767.00186

Timestep Collection Time: 2.13231
Timestep Consumption Time: 2.51336
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.64568

Cumulative Model Updates: 258,192
Cumulative Timesteps: 2,153,277,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.87202
Policy Entropy: 2.13111
Value Function Loss: 0.01936

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.64989

Collected Steps per Second: 22,222.35745
Overall Steps per Second: 10,423.05629

Timestep Collection Time: 2.25134
Timestep Consumption Time: 2.54860
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.79994

Cumulative Model Updates: 258,198
Cumulative Timesteps: 2,153,327,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2153327256...
Checkpoint 2153327256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.98794
Policy Entropy: 2.12739
Value Function Loss: 0.02030

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.17213
Policy Update Magnitude: 0.52971
Value Function Update Magnitude: 0.66614

Collected Steps per Second: 22,252.23017
Overall Steps per Second: 10,633.95965

Timestep Collection Time: 2.24777
Timestep Consumption Time: 2.45584
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.70361

Cumulative Model Updates: 258,204
Cumulative Timesteps: 2,153,377,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.12688
Policy Entropy: 2.12117
Value Function Loss: 0.02092

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.15878
Policy Update Magnitude: 0.53262
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 23,375.06593
Overall Steps per Second: 10,981.22373

Timestep Collection Time: 2.13903
Timestep Consumption Time: 2.41420
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.55323

Cumulative Model Updates: 258,210
Cumulative Timesteps: 2,153,427,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2153427274...
Checkpoint 2153427274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.32943
Policy Entropy: 2.12749
Value Function Loss: 0.02060

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.66525

Collected Steps per Second: 23,010.93445
Overall Steps per Second: 10,784.31451

Timestep Collection Time: 2.17384
Timestep Consumption Time: 2.46457
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.63840

Cumulative Model Updates: 258,216
Cumulative Timesteps: 2,153,477,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.60805
Policy Entropy: 2.14396
Value Function Loss: 0.02008

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.54577
Value Function Update Magnitude: 0.65482

Collected Steps per Second: 23,164.61493
Overall Steps per Second: 10,740.64905

Timestep Collection Time: 2.15993
Timestep Consumption Time: 2.49845
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.65838

Cumulative Model Updates: 258,222
Cumulative Timesteps: 2,153,527,330

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2153527330...
Checkpoint 2153527330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.99263
Policy Entropy: 2.14721
Value Function Loss: 0.01978

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.54657
Value Function Update Magnitude: 0.63202

Collected Steps per Second: 22,418.73098
Overall Steps per Second: 10,587.03816

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.72295

Cumulative Model Updates: 258,228
Cumulative Timesteps: 2,153,577,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.02526
Policy Entropy: 2.12812
Value Function Loss: 0.01969

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.63117

Collected Steps per Second: 22,809.26864
Overall Steps per Second: 10,855.25091

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.60865

Cumulative Model Updates: 258,234
Cumulative Timesteps: 2,153,627,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2153627360...
Checkpoint 2153627360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.68246
Policy Entropy: 2.11586
Value Function Loss: 0.01994

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.52485
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,703.68967
Overall Steps per Second: 10,700.69945

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.67502

Cumulative Model Updates: 258,240
Cumulative Timesteps: 2,153,677,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.93935
Policy Entropy: 2.11916
Value Function Loss: 0.01975

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.52286
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 22,887.51297
Overall Steps per Second: 10,819.46423

Timestep Collection Time: 2.18591
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62407

Cumulative Model Updates: 258,246
Cumulative Timesteps: 2,153,727,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2153727416...
Checkpoint 2153727416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.48334
Policy Entropy: 2.14336
Value Function Loss: 0.01934

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.61696

Collected Steps per Second: 22,055.42565
Overall Steps per Second: 10,657.50101

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.69416

Cumulative Model Updates: 258,252
Cumulative Timesteps: 2,153,777,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.06280
Policy Entropy: 2.13648
Value Function Loss: 0.01973

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.53405
Value Function Update Magnitude: 0.62176

Collected Steps per Second: 23,440.98605
Overall Steps per Second: 10,921.01928

Timestep Collection Time: 2.13395
Timestep Consumption Time: 2.44639
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.58034

Cumulative Model Updates: 258,258
Cumulative Timesteps: 2,153,827,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2153827466...
Checkpoint 2153827466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.79409
Policy Entropy: 2.14321
Value Function Loss: 0.01883

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.63988

Collected Steps per Second: 23,667.79918
Overall Steps per Second: 10,898.26434

Timestep Collection Time: 2.11359
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.59009

Cumulative Model Updates: 258,264
Cumulative Timesteps: 2,153,877,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.89192
Policy Entropy: 2.16486
Value Function Loss: 0.01834

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.52799
Value Function Update Magnitude: 0.62686

Collected Steps per Second: 23,532.51657
Overall Steps per Second: 10,854.51982

Timestep Collection Time: 2.12574
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.60859

Cumulative Model Updates: 258,270
Cumulative Timesteps: 2,153,927,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2153927514...
Checkpoint 2153927514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.54148
Policy Entropy: 2.17656
Value Function Loss: 0.01762

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.52157
Value Function Update Magnitude: 0.61648

Collected Steps per Second: 22,799.75130
Overall Steps per Second: 10,909.61077

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.39116
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.58513

Cumulative Model Updates: 258,276
Cumulative Timesteps: 2,153,977,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.68014
Policy Entropy: 2.16675
Value Function Loss: 0.01874

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.53255
Value Function Update Magnitude: 0.62029

Collected Steps per Second: 23,255.37611
Overall Steps per Second: 10,980.75245

Timestep Collection Time: 2.15116
Timestep Consumption Time: 2.40463
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.55579

Cumulative Model Updates: 258,282
Cumulative Timesteps: 2,154,027,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2154027562...
Checkpoint 2154027562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.60665
Policy Entropy: 2.13492
Value Function Loss: 0.02000

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.53966
Value Function Update Magnitude: 0.62743

Collected Steps per Second: 22,553.58562
Overall Steps per Second: 10,676.37160

Timestep Collection Time: 2.21810
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.68567

Cumulative Model Updates: 258,288
Cumulative Timesteps: 2,154,077,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.08450
Policy Entropy: 2.12484
Value Function Loss: 0.02071

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.62230

Collected Steps per Second: 22,903.28417
Overall Steps per Second: 10,835.80302

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.61489

Cumulative Model Updates: 258,294
Cumulative Timesteps: 2,154,127,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2154127594...
Checkpoint 2154127594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.60420
Policy Entropy: 2.12550
Value Function Loss: 0.02130

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.54198
Value Function Update Magnitude: 0.61768

Collected Steps per Second: 22,360.16225
Overall Steps per Second: 10,754.16449

Timestep Collection Time: 2.23666
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.65048

Cumulative Model Updates: 258,300
Cumulative Timesteps: 2,154,177,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.38148
Policy Entropy: 2.13733
Value Function Loss: 0.02035

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.61490

Collected Steps per Second: 22,583.80393
Overall Steps per Second: 10,786.79918

Timestep Collection Time: 2.21442
Timestep Consumption Time: 2.42180
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63622

Cumulative Model Updates: 258,306
Cumulative Timesteps: 2,154,227,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2154227616...
Checkpoint 2154227616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.42582
Policy Entropy: 2.14051
Value Function Loss: 0.01959

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.51889
Value Function Update Magnitude: 0.60311

Collected Steps per Second: 22,398.64165
Overall Steps per Second: 10,736.30889

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.65970

Cumulative Model Updates: 258,312
Cumulative Timesteps: 2,154,277,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.39780
Policy Entropy: 2.15604
Value Function Loss: 0.01933

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.16765
Policy Update Magnitude: 0.50258
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 23,674.08668
Overall Steps per Second: 10,906.68669

Timestep Collection Time: 2.11286
Timestep Consumption Time: 2.47332
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.58618

Cumulative Model Updates: 258,318
Cumulative Timesteps: 2,154,327,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2154327664...
Checkpoint 2154327664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.69871
Policy Entropy: 2.13098
Value Function Loss: 0.01897

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.15522
Policy Update Magnitude: 0.53534
Value Function Update Magnitude: 0.61509

Collected Steps per Second: 22,810.61916
Overall Steps per Second: 10,674.57024

Timestep Collection Time: 2.19336
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.68703

Cumulative Model Updates: 258,324
Cumulative Timesteps: 2,154,377,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.18791
Policy Entropy: 2.12362
Value Function Loss: 0.01974

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.54588
Value Function Update Magnitude: 0.61072

Collected Steps per Second: 23,028.06749
Overall Steps per Second: 10,829.45999

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.61888

Cumulative Model Updates: 258,330
Cumulative Timesteps: 2,154,427,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2154427716...
Checkpoint 2154427716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.11962
Policy Entropy: 2.10840
Value Function Loss: 0.01929

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.54742
Value Function Update Magnitude: 0.63556

Collected Steps per Second: 22,598.10986
Overall Steps per Second: 10,823.40372

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.40936
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.62405

Cumulative Model Updates: 258,336
Cumulative Timesteps: 2,154,477,764

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.51960
Policy Entropy: 2.13900
Value Function Loss: 0.01949

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 23,453.35866
Overall Steps per Second: 10,772.11778

Timestep Collection Time: 2.13266
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.64328

Cumulative Model Updates: 258,342
Cumulative Timesteps: 2,154,527,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2154527782...
Checkpoint 2154527782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.05735
Policy Entropy: 2.13183
Value Function Loss: 0.02061

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.54582
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 22,797.17604
Overall Steps per Second: 10,750.04203

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.65356

Cumulative Model Updates: 258,348
Cumulative Timesteps: 2,154,577,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.57043
Policy Entropy: 2.11375
Value Function Loss: 0.02153

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.61277

Collected Steps per Second: 23,049.97468
Overall Steps per Second: 10,774.80125

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.64324

Cumulative Model Updates: 258,354
Cumulative Timesteps: 2,154,627,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2154627838...
Checkpoint 2154627838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.01525
Policy Entropy: 2.10445
Value Function Loss: 0.02133

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.61192

Collected Steps per Second: 22,147.82544
Overall Steps per Second: 10,695.76142

Timestep Collection Time: 2.25846
Timestep Consumption Time: 2.41816
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.67662

Cumulative Model Updates: 258,360
Cumulative Timesteps: 2,154,677,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.31077
Policy Entropy: 2.09090
Value Function Loss: 0.02139

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.58566

Collected Steps per Second: 23,397.48510
Overall Steps per Second: 10,897.02184

Timestep Collection Time: 2.13784
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.59024

Cumulative Model Updates: 258,366
Cumulative Timesteps: 2,154,727,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2154727878...
Checkpoint 2154727878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.91821
Policy Entropy: 2.10228
Value Function Loss: 0.02032

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.57829

Collected Steps per Second: 22,333.81639
Overall Steps per Second: 10,609.57050

Timestep Collection Time: 2.23956
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.71442

Cumulative Model Updates: 258,372
Cumulative Timesteps: 2,154,777,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.34210
Policy Entropy: 2.10298
Value Function Loss: 0.02040

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.58655

Collected Steps per Second: 22,930.76025
Overall Steps per Second: 10,800.48878

Timestep Collection Time: 2.18091
Timestep Consumption Time: 2.44943
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.63035

Cumulative Model Updates: 258,378
Cumulative Timesteps: 2,154,827,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2154827906...
Checkpoint 2154827906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.35533
Policy Entropy: 2.10990
Value Function Loss: 0.01970

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.16322
Policy Update Magnitude: 0.50240
Value Function Update Magnitude: 0.59468

Collected Steps per Second: 22,715.43382
Overall Steps per Second: 10,808.88001

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.62823

Cumulative Model Updates: 258,384
Cumulative Timesteps: 2,154,877,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.38036
Policy Entropy: 2.12170
Value Function Loss: 0.01947

Mean KL Divergence: 0.02898
SB3 Clip Fraction: 0.17743
Policy Update Magnitude: 0.50607
Value Function Update Magnitude: 0.59510

Collected Steps per Second: 22,126.56163
Overall Steps per Second: 10,542.41505

Timestep Collection Time: 2.26063
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.74464

Cumulative Model Updates: 258,390
Cumulative Timesteps: 2,154,927,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2154927952...
Checkpoint 2154927952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.63721
Policy Entropy: 2.11828
Value Function Loss: 0.01861

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.15471
Policy Update Magnitude: 0.50804
Value Function Update Magnitude: 0.61390

Collected Steps per Second: 22,513.32764
Overall Steps per Second: 10,602.82710

Timestep Collection Time: 2.22117
Timestep Consumption Time: 2.49512
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.71629

Cumulative Model Updates: 258,396
Cumulative Timesteps: 2,154,977,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.32387
Policy Entropy: 2.12472
Value Function Loss: 0.01828

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.52249
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 23,571.04432
Overall Steps per Second: 11,163.16497

Timestep Collection Time: 2.12210
Timestep Consumption Time: 2.35871
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.48081

Cumulative Model Updates: 258,402
Cumulative Timesteps: 2,155,027,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2155027978...
Checkpoint 2155027978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.90473
Policy Entropy: 2.11655
Value Function Loss: 0.01916

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.52237
Value Function Update Magnitude: 0.62013

Collected Steps per Second: 22,463.60643
Overall Steps per Second: 10,723.71967

Timestep Collection Time: 2.22698
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.66499

Cumulative Model Updates: 258,408
Cumulative Timesteps: 2,155,078,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.76741
Policy Entropy: 2.11421
Value Function Loss: 0.01951

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.53090
Value Function Update Magnitude: 0.60039

Collected Steps per Second: 22,883.15703
Overall Steps per Second: 10,865.73318

Timestep Collection Time: 2.18624
Timestep Consumption Time: 2.41796
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.60420

Cumulative Model Updates: 258,414
Cumulative Timesteps: 2,155,128,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2155128032...
Checkpoint 2155128032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.61866
Policy Entropy: 2.10131
Value Function Loss: 0.01891

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.52199
Value Function Update Magnitude: 0.59282

Collected Steps per Second: 22,084.05635
Overall Steps per Second: 10,719.59859

Timestep Collection Time: 2.26534
Timestep Consumption Time: 2.40162
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.66697

Cumulative Model Updates: 258,420
Cumulative Timesteps: 2,155,178,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.67062
Policy Entropy: 2.11412
Value Function Loss: 0.01889

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.53006
Value Function Update Magnitude: 0.59786

Collected Steps per Second: 22,597.42621
Overall Steps per Second: 10,900.59936

Timestep Collection Time: 2.21317
Timestep Consumption Time: 2.37483
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58800

Cumulative Model Updates: 258,426
Cumulative Timesteps: 2,155,228,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2155228072...
Checkpoint 2155228072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.63672
Policy Entropy: 2.10536
Value Function Loss: 0.01868

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.53006
Value Function Update Magnitude: 0.61744

Collected Steps per Second: 22,871.84344
Overall Steps per Second: 10,634.88322

Timestep Collection Time: 2.18627
Timestep Consumption Time: 2.51562
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.70189

Cumulative Model Updates: 258,432
Cumulative Timesteps: 2,155,278,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.07529
Policy Entropy: 2.11962
Value Function Loss: 0.01988

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.60874

Collected Steps per Second: 23,219.77078
Overall Steps per Second: 10,883.43816

Timestep Collection Time: 2.15472
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.59708

Cumulative Model Updates: 258,438
Cumulative Timesteps: 2,155,328,108

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2155328108...
Checkpoint 2155328108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.27041
Policy Entropy: 2.11486
Value Function Loss: 0.01988

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 22,731.07012
Overall Steps per Second: 10,669.70821

Timestep Collection Time: 2.20007
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.68710

Cumulative Model Updates: 258,444
Cumulative Timesteps: 2,155,378,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.39692
Policy Entropy: 2.11360
Value Function Loss: 0.01994

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 23,252.49588
Overall Steps per Second: 10,900.19572

Timestep Collection Time: 2.15031
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.58707

Cumulative Model Updates: 258,450
Cumulative Timesteps: 2,155,428,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2155428118...
Checkpoint 2155428118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.88628
Policy Entropy: 2.09740
Value Function Loss: 0.01962

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.53782
Value Function Update Magnitude: 0.62464

Collected Steps per Second: 23,035.95186
Overall Steps per Second: 10,732.74039

Timestep Collection Time: 2.17156
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.66088

Cumulative Model Updates: 258,456
Cumulative Timesteps: 2,155,478,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.99640
Policy Entropy: 2.08303
Value Function Loss: 0.02025

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.61570

Collected Steps per Second: 23,137.78890
Overall Steps per Second: 10,807.07403

Timestep Collection Time: 2.16192
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.62863

Cumulative Model Updates: 258,462
Cumulative Timesteps: 2,155,528,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2155528164...
Checkpoint 2155528164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.06140
Policy Entropy: 2.07358
Value Function Loss: 0.01965

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.60927

Collected Steps per Second: 22,333.62100
Overall Steps per Second: 10,705.89236

Timestep Collection Time: 2.24012
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.67313

Cumulative Model Updates: 258,468
Cumulative Timesteps: 2,155,578,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.44356
Policy Entropy: 2.09138
Value Function Loss: 0.01947

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.54534
Value Function Update Magnitude: 0.60027

Collected Steps per Second: 22,340.30130
Overall Steps per Second: 10,924.70822

Timestep Collection Time: 2.23927
Timestep Consumption Time: 2.33989
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.57916

Cumulative Model Updates: 258,474
Cumulative Timesteps: 2,155,628,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2155628220...
Checkpoint 2155628220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.07044
Policy Entropy: 2.07691
Value Function Loss: 0.01923

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.16288
Policy Update Magnitude: 0.49731
Value Function Update Magnitude: 0.59905

Collected Steps per Second: 22,665.23932
Overall Steps per Second: 10,641.47734

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.70104

Cumulative Model Updates: 258,480
Cumulative Timesteps: 2,155,678,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.74753
Policy Entropy: 2.08742
Value Function Loss: 0.01911

Mean KL Divergence: 0.02784
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.47323
Value Function Update Magnitude: 0.59391

Collected Steps per Second: 23,040.51906
Overall Steps per Second: 10,898.93310

Timestep Collection Time: 2.17009
Timestep Consumption Time: 2.41752
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.58761

Cumulative Model Updates: 258,486
Cumulative Timesteps: 2,155,728,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2155728246...
Checkpoint 2155728246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.70076
Policy Entropy: 2.07150
Value Function Loss: 0.02088

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.16703
Policy Update Magnitude: 0.47531
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,619.21421
Overall Steps per Second: 10,656.83248

Timestep Collection Time: 2.21166
Timestep Consumption Time: 2.48261
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.69427

Cumulative Model Updates: 258,492
Cumulative Timesteps: 2,155,778,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.39505
Policy Entropy: 2.08173
Value Function Loss: 0.02145

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.51760
Value Function Update Magnitude: 0.62631

Collected Steps per Second: 23,321.57991
Overall Steps per Second: 10,916.86425

Timestep Collection Time: 2.14471
Timestep Consumption Time: 2.43701
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.58172

Cumulative Model Updates: 258,498
Cumulative Timesteps: 2,155,828,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2155828290...
Checkpoint 2155828290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.84463
Policy Entropy: 2.08230
Value Function Loss: 0.02186

Mean KL Divergence: 0.02768
SB3 Clip Fraction: 0.17256
Policy Update Magnitude: 0.51258
Value Function Update Magnitude: 0.65618

Collected Steps per Second: 22,962.85661
Overall Steps per Second: 10,721.35096

Timestep Collection Time: 2.17865
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.66620

Cumulative Model Updates: 258,504
Cumulative Timesteps: 2,155,878,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.69576
Policy Entropy: 2.08521
Value Function Loss: 0.02156

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.67715

Collected Steps per Second: 23,437.13943
Overall Steps per Second: 10,783.44649

Timestep Collection Time: 2.13422
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.63859

Cumulative Model Updates: 258,510
Cumulative Timesteps: 2,155,928,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2155928338...
Checkpoint 2155928338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.19631
Policy Entropy: 2.09221
Value Function Loss: 0.02035

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.55292
Value Function Update Magnitude: 0.66252

Collected Steps per Second: 22,089.56273
Overall Steps per Second: 10,615.99160

Timestep Collection Time: 2.26387
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.71063

Cumulative Model Updates: 258,516
Cumulative Timesteps: 2,155,978,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.58478
Policy Entropy: 2.08906
Value Function Loss: 0.02046

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.64737

Collected Steps per Second: 23,214.00353
Overall Steps per Second: 10,904.33616

Timestep Collection Time: 2.15413
Timestep Consumption Time: 2.43175
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.58588

Cumulative Model Updates: 258,522
Cumulative Timesteps: 2,156,028,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2156028352...
Checkpoint 2156028352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.50299
Policy Entropy: 2.11130
Value Function Loss: 0.01930

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.53996
Value Function Update Magnitude: 0.63754

Collected Steps per Second: 22,504.95112
Overall Steps per Second: 10,638.15596

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.47843
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.70025

Cumulative Model Updates: 258,528
Cumulative Timesteps: 2,156,078,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.63380
Policy Entropy: 2.12628
Value Function Loss: 0.02031

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.65006

Collected Steps per Second: 22,857.24003
Overall Steps per Second: 10,900.72125

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.39955
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.58722

Cumulative Model Updates: 258,534
Cumulative Timesteps: 2,156,128,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2156128358...
Checkpoint 2156128358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.41147
Policy Entropy: 2.11625
Value Function Loss: 0.02093

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.66100

Collected Steps per Second: 22,134.18966
Overall Steps per Second: 10,653.17738

Timestep Collection Time: 2.26012
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.69588

Cumulative Model Updates: 258,540
Cumulative Timesteps: 2,156,178,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.32524
Policy Entropy: 2.10380
Value Function Loss: 0.02131

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.54294
Value Function Update Magnitude: 0.67498

Collected Steps per Second: 23,692.64525
Overall Steps per Second: 10,920.68579

Timestep Collection Time: 2.11070
Timestep Consumption Time: 2.46850
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.57920

Cumulative Model Updates: 258,546
Cumulative Timesteps: 2,156,228,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2156228392...
Checkpoint 2156228392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.00144
Policy Entropy: 2.10635
Value Function Loss: 0.01977

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.67562

Collected Steps per Second: 22,594.11520
Overall Steps per Second: 10,635.64794

Timestep Collection Time: 2.21385
Timestep Consumption Time: 2.48920
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.70305

Cumulative Model Updates: 258,552
Cumulative Timesteps: 2,156,278,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.21741
Policy Entropy: 2.12716
Value Function Loss: 0.01968

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.67721

Collected Steps per Second: 23,290.73255
Overall Steps per Second: 10,723.06681

Timestep Collection Time: 2.14712
Timestep Consumption Time: 2.51647
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.66359

Cumulative Model Updates: 258,558
Cumulative Timesteps: 2,156,328,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2156328420...
Checkpoint 2156328420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.95266
Policy Entropy: 2.14166
Value Function Loss: 0.01970

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.68720

Collected Steps per Second: 22,449.29048
Overall Steps per Second: 10,776.28834

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.41335
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.64130

Cumulative Model Updates: 258,564
Cumulative Timesteps: 2,156,378,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.16341
Policy Entropy: 2.13737
Value Function Loss: 0.02032

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.53807
Value Function Update Magnitude: 0.69010

Collected Steps per Second: 24,152.68546
Overall Steps per Second: 10,958.92356

Timestep Collection Time: 2.07049
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.56322

Cumulative Model Updates: 258,570
Cumulative Timesteps: 2,156,428,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2156428444...
Checkpoint 2156428444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.35890
Policy Entropy: 2.13158
Value Function Loss: 0.02027

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.53816
Value Function Update Magnitude: 0.68595

Collected Steps per Second: 22,402.19449
Overall Steps per Second: 10,642.28439

Timestep Collection Time: 2.23308
Timestep Consumption Time: 2.46760
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.70068

Cumulative Model Updates: 258,576
Cumulative Timesteps: 2,156,478,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.82261
Policy Entropy: 2.12946
Value Function Loss: 0.01942

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.53038
Value Function Update Magnitude: 0.66482

Collected Steps per Second: 23,086.46626
Overall Steps per Second: 10,894.50786

Timestep Collection Time: 2.16594
Timestep Consumption Time: 2.42389
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.58984

Cumulative Model Updates: 258,582
Cumulative Timesteps: 2,156,528,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2156528474...
Checkpoint 2156528474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.47723
Policy Entropy: 2.12574
Value Function Loss: 0.01927

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.52328
Value Function Update Magnitude: 0.64742

Collected Steps per Second: 22,485.31635
Overall Steps per Second: 10,667.44263

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.68753

Cumulative Model Updates: 258,588
Cumulative Timesteps: 2,156,578,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.87989
Policy Entropy: 2.12822
Value Function Loss: 0.02027

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.65469

Collected Steps per Second: 22,759.93492
Overall Steps per Second: 10,926.28165

Timestep Collection Time: 2.19763
Timestep Consumption Time: 2.38014
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.57777

Cumulative Model Updates: 258,594
Cumulative Timesteps: 2,156,628,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2156628496...
Checkpoint 2156628496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.55200
Policy Entropy: 2.11951
Value Function Loss: 0.02014

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.67988

Collected Steps per Second: 22,023.27396
Overall Steps per Second: 10,671.29651

Timestep Collection Time: 2.27187
Timestep Consumption Time: 2.41678
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.68865

Cumulative Model Updates: 258,600
Cumulative Timesteps: 2,156,678,530

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.81840
Policy Entropy: 2.13228
Value Function Loss: 0.01844

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.53497
Value Function Update Magnitude: 0.67867

Collected Steps per Second: 22,896.38648
Overall Steps per Second: 10,843.19215

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61340

Cumulative Model Updates: 258,606
Cumulative Timesteps: 2,156,728,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2156728554...
Checkpoint 2156728554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.67955
Policy Entropy: 2.13624
Value Function Loss: 0.01846

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.65506

Collected Steps per Second: 22,242.59021
Overall Steps per Second: 10,670.45871

Timestep Collection Time: 2.24830
Timestep Consumption Time: 2.43828
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.68658

Cumulative Model Updates: 258,612
Cumulative Timesteps: 2,156,778,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.88028
Policy Entropy: 2.12918
Value Function Loss: 0.01907

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.52518
Value Function Update Magnitude: 0.65119

Collected Steps per Second: 23,830.18549
Overall Steps per Second: 10,887.55819

Timestep Collection Time: 2.09935
Timestep Consumption Time: 2.49562
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.59497

Cumulative Model Updates: 258,618
Cumulative Timesteps: 2,156,828,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2156828590...
Checkpoint 2156828590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.84360
Policy Entropy: 2.13175
Value Function Loss: 0.01843

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.52038
Value Function Update Magnitude: 0.68392

Collected Steps per Second: 22,709.02409
Overall Steps per Second: 10,651.49190

Timestep Collection Time: 2.20203
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.69474

Cumulative Model Updates: 258,624
Cumulative Timesteps: 2,156,878,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.24522
Policy Entropy: 2.13512
Value Function Loss: 0.01861

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.52381
Value Function Update Magnitude: 0.68351

Collected Steps per Second: 23,387.38101
Overall Steps per Second: 10,813.25162

Timestep Collection Time: 2.13816
Timestep Consumption Time: 2.48635
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.62451

Cumulative Model Updates: 258,630
Cumulative Timesteps: 2,156,928,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2156928602...
Checkpoint 2156928602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.51102
Policy Entropy: 2.15454
Value Function Loss: 0.01781

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.51564
Value Function Update Magnitude: 0.68555

Collected Steps per Second: 22,700.58733
Overall Steps per Second: 10,831.24792

Timestep Collection Time: 2.20303
Timestep Consumption Time: 2.41417
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.61720

Cumulative Model Updates: 258,636
Cumulative Timesteps: 2,156,978,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.31155
Policy Entropy: 2.14013
Value Function Loss: 0.01959

Mean KL Divergence: 0.02800
SB3 Clip Fraction: 0.16852
Policy Update Magnitude: 0.49115
Value Function Update Magnitude: 0.69129

Collected Steps per Second: 23,497.05392
Overall Steps per Second: 10,865.34050

Timestep Collection Time: 2.12971
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.60565

Cumulative Model Updates: 258,642
Cumulative Timesteps: 2,157,028,654

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2157028654...
Checkpoint 2157028654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.52046
Policy Entropy: 2.14368
Value Function Loss: 0.01911

Mean KL Divergence: 0.02903
SB3 Clip Fraction: 0.17308
Policy Update Magnitude: 0.51556
Value Function Update Magnitude: 0.69263

Collected Steps per Second: 22,551.85251
Overall Steps per Second: 10,627.51109

Timestep Collection Time: 2.21747
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.70552

Cumulative Model Updates: 258,648
Cumulative Timesteps: 2,157,078,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.04737
Policy Entropy: 2.14304
Value Function Loss: 0.01894

Mean KL Divergence: 0.02541
SB3 Clip Fraction: 0.16369
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.68530

Collected Steps per Second: 22,956.57491
Overall Steps per Second: 10,896.44531

Timestep Collection Time: 2.17820
Timestep Consumption Time: 2.41082
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.58902

Cumulative Model Updates: 258,654
Cumulative Timesteps: 2,157,128,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2157128666...
Checkpoint 2157128666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.35071
Policy Entropy: 2.14217
Value Function Loss: 0.01891

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.67033

Collected Steps per Second: 22,000.78333
Overall Steps per Second: 10,695.67226

Timestep Collection Time: 2.27337
Timestep Consumption Time: 2.40291
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.67628

Cumulative Model Updates: 258,660
Cumulative Timesteps: 2,157,178,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.12637
Policy Entropy: 2.12025
Value Function Loss: 0.01905

Mean KL Divergence: 0.02543
SB3 Clip Fraction: 0.15183
Policy Update Magnitude: 0.53789
Value Function Update Magnitude: 0.66868

Collected Steps per Second: 23,083.59601
Overall Steps per Second: 10,844.77449

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61125

Cumulative Model Updates: 258,666
Cumulative Timesteps: 2,157,228,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2157228690...
Checkpoint 2157228690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.56646
Policy Entropy: 2.10280
Value Function Loss: 0.02010

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.66794

Collected Steps per Second: 22,492.46152
Overall Steps per Second: 10,678.99515

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.68396

Cumulative Model Updates: 258,672
Cumulative Timesteps: 2,157,278,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.69622
Policy Entropy: 2.09169
Value Function Loss: 0.01918

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.65230

Collected Steps per Second: 23,118.94424
Overall Steps per Second: 10,829.08841

Timestep Collection Time: 2.16351
Timestep Consumption Time: 2.45535
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61886

Cumulative Model Updates: 258,678
Cumulative Timesteps: 2,157,328,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2157328728...
Checkpoint 2157328728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.46206
Policy Entropy: 2.10427
Value Function Loss: 0.01882

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.53901
Value Function Update Magnitude: 0.62603

Collected Steps per Second: 22,398.67802
Overall Steps per Second: 10,741.16209

Timestep Collection Time: 2.23326
Timestep Consumption Time: 2.42378
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.65704

Cumulative Model Updates: 258,684
Cumulative Timesteps: 2,157,378,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.98629
Policy Entropy: 2.11187
Value Function Loss: 0.01793

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.60324

Collected Steps per Second: 23,953.68775
Overall Steps per Second: 10,883.51118

Timestep Collection Time: 2.08836
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.59631

Cumulative Model Updates: 258,690
Cumulative Timesteps: 2,157,428,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2157428774...
Checkpoint 2157428774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.17604
Policy Entropy: 2.12436
Value Function Loss: 0.01758

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.52271
Value Function Update Magnitude: 0.58482

Collected Steps per Second: 22,992.02119
Overall Steps per Second: 10,723.37667

Timestep Collection Time: 2.17562
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.66476

Cumulative Model Updates: 258,696
Cumulative Timesteps: 2,157,478,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.44089
Policy Entropy: 2.12313
Value Function Loss: 0.01828

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.52001
Value Function Update Magnitude: 0.56882

Collected Steps per Second: 23,514.59563
Overall Steps per Second: 10,823.41908

Timestep Collection Time: 2.12693
Timestep Consumption Time: 2.49397
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.62091

Cumulative Model Updates: 258,702
Cumulative Timesteps: 2,157,528,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2157528810...
Checkpoint 2157528810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.70354
Policy Entropy: 2.11061
Value Function Loss: 0.01811

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.52195
Value Function Update Magnitude: 0.57149

Collected Steps per Second: 22,631.92618
Overall Steps per Second: 10,675.62700

Timestep Collection Time: 2.20936
Timestep Consumption Time: 2.47440
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.68375

Cumulative Model Updates: 258,708
Cumulative Timesteps: 2,157,578,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.69116
Policy Entropy: 2.11774
Value Function Loss: 0.01915

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.52565
Value Function Update Magnitude: 0.59354

Collected Steps per Second: 23,498.04935
Overall Steps per Second: 10,873.93274

Timestep Collection Time: 2.12911
Timestep Consumption Time: 2.47180
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.60091

Cumulative Model Updates: 258,714
Cumulative Timesteps: 2,157,628,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2157628842...
Checkpoint 2157628842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.64426
Policy Entropy: 2.12768
Value Function Loss: 0.01922

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.62840

Collected Steps per Second: 22,385.63037
Overall Steps per Second: 10,641.11064

Timestep Collection Time: 2.23420
Timestep Consumption Time: 2.46587
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.70007

Cumulative Model Updates: 258,720
Cumulative Timesteps: 2,157,678,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.42852
Policy Entropy: 2.14390
Value Function Loss: 0.01932

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.53564
Value Function Update Magnitude: 0.63722

Collected Steps per Second: 23,001.23208
Overall Steps per Second: 10,858.03302

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60525

Cumulative Model Updates: 258,726
Cumulative Timesteps: 2,157,728,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2157728860...
Checkpoint 2157728860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.87349
Policy Entropy: 2.13636
Value Function Loss: 0.01968

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.65047

Collected Steps per Second: 22,053.80988
Overall Steps per Second: 10,741.96406

Timestep Collection Time: 2.26764
Timestep Consumption Time: 2.38794
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.65557

Cumulative Model Updates: 258,732
Cumulative Timesteps: 2,157,778,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.20079
Policy Entropy: 2.11775
Value Function Loss: 0.01933

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 23,649.36140
Overall Steps per Second: 10,964.98441

Timestep Collection Time: 2.11448
Timestep Consumption Time: 2.44604
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.56052

Cumulative Model Updates: 258,738
Cumulative Timesteps: 2,157,828,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2157828876...
Checkpoint 2157828876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.87367
Policy Entropy: 2.10834
Value Function Loss: 0.01980

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.54280
Value Function Update Magnitude: 0.65695

Collected Steps per Second: 23,041.10751
Overall Steps per Second: 10,700.23834

Timestep Collection Time: 2.17142
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.67578

Cumulative Model Updates: 258,744
Cumulative Timesteps: 2,157,878,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.11641
Policy Entropy: 2.10721
Value Function Loss: 0.01978

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.54799
Value Function Update Magnitude: 0.65687

Collected Steps per Second: 22,305.72326
Overall Steps per Second: 10,706.43278

Timestep Collection Time: 2.24247
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.67196

Cumulative Model Updates: 258,750
Cumulative Timesteps: 2,157,928,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2157928928...
Checkpoint 2157928928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.29375
Policy Entropy: 2.11703
Value Function Loss: 0.01970

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.65352

Collected Steps per Second: 21,946.78589
Overall Steps per Second: 10,687.77494

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.40154
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.68124

Cumulative Model Updates: 258,756
Cumulative Timesteps: 2,157,978,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.73193
Policy Entropy: 2.10391
Value Function Loss: 0.01963

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.63915

Collected Steps per Second: 23,851.82800
Overall Steps per Second: 10,984.76398

Timestep Collection Time: 2.09728
Timestep Consumption Time: 2.45666
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.55394

Cumulative Model Updates: 258,762
Cumulative Timesteps: 2,158,028,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2158028984...
Checkpoint 2158028984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.62937
Policy Entropy: 2.10599
Value Function Loss: 0.01955

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.63117

Collected Steps per Second: 22,847.91110
Overall Steps per Second: 10,638.79493

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.69997

Cumulative Model Updates: 258,768
Cumulative Timesteps: 2,158,078,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.30002
Policy Entropy: 2.09885
Value Function Loss: 0.01992

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.53940
Value Function Update Magnitude: 0.64686

Collected Steps per Second: 23,468.42644
Overall Steps per Second: 10,862.05134

Timestep Collection Time: 2.13154
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.60539

Cumulative Model Updates: 258,774
Cumulative Timesteps: 2,158,129,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2158129010...
Checkpoint 2158129010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.24933
Policy Entropy: 2.09329
Value Function Loss: 0.01945

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.15494
Policy Update Magnitude: 0.52777
Value Function Update Magnitude: 0.64969

Collected Steps per Second: 22,622.08983
Overall Steps per Second: 10,683.05824

Timestep Collection Time: 2.21076
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.68143

Cumulative Model Updates: 258,780
Cumulative Timesteps: 2,158,179,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.86040
Policy Entropy: 2.08188
Value Function Loss: 0.01885

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.53764
Value Function Update Magnitude: 0.63269

Collected Steps per Second: 24,454.50685
Overall Steps per Second: 11,027.83127

Timestep Collection Time: 2.04510
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.53507

Cumulative Model Updates: 258,786
Cumulative Timesteps: 2,158,229,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2158229034...
Checkpoint 2158229034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.54189
Policy Entropy: 2.07848
Value Function Loss: 0.01965

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.63357

Collected Steps per Second: 22,724.39809
Overall Steps per Second: 10,616.17202

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.51042
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.71149

Cumulative Model Updates: 258,792
Cumulative Timesteps: 2,158,279,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.34206
Policy Entropy: 2.09252
Value Function Loss: 0.01925

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.66660

Collected Steps per Second: 22,903.49984
Overall Steps per Second: 10,858.65286

Timestep Collection Time: 2.18395
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.60646

Cumulative Model Updates: 258,798
Cumulative Timesteps: 2,158,329,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2158329072...
Checkpoint 2158329072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.99676
Policy Entropy: 2.09785
Value Function Loss: 0.02016

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.66454

Collected Steps per Second: 22,374.18001
Overall Steps per Second: 10,643.44621

Timestep Collection Time: 2.23606
Timestep Consumption Time: 2.46449
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.70055

Cumulative Model Updates: 258,804
Cumulative Timesteps: 2,158,379,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.05522
Policy Entropy: 2.10477
Value Function Loss: 0.02046

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.63773

Collected Steps per Second: 22,970.32165
Overall Steps per Second: 10,866.48263

Timestep Collection Time: 2.17785
Timestep Consumption Time: 2.42584
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.60370

Cumulative Model Updates: 258,810
Cumulative Timesteps: 2,158,429,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2158429128...
Checkpoint 2158429128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.60198
Policy Entropy: 2.09757
Value Function Loss: 0.02078

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.55487
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 22,313.59007
Overall Steps per Second: 10,672.79034

Timestep Collection Time: 2.24168
Timestep Consumption Time: 2.44500
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.68668

Cumulative Model Updates: 258,816
Cumulative Timesteps: 2,158,479,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.52269
Policy Entropy: 2.10535
Value Function Loss: 0.01923

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.63502

Collected Steps per Second: 23,122.97490
Overall Steps per Second: 10,830.50067

Timestep Collection Time: 2.16270
Timestep Consumption Time: 2.45463
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.61733

Cumulative Model Updates: 258,822
Cumulative Timesteps: 2,158,529,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2158529156...
Checkpoint 2158529156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.53309
Policy Entropy: 2.10523
Value Function Loss: 0.01914

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.62838

Collected Steps per Second: 22,757.25110
Overall Steps per Second: 10,711.40668

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.66811

Cumulative Model Updates: 258,828
Cumulative Timesteps: 2,158,579,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.06155
Policy Entropy: 2.08334
Value Function Loss: 0.01914

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 23,466.12933
Overall Steps per Second: 10,992.34191

Timestep Collection Time: 2.13158
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.55044

Cumulative Model Updates: 258,834
Cumulative Timesteps: 2,158,629,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2158629178...
Checkpoint 2158629178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.76586
Policy Entropy: 2.08776
Value Function Loss: 0.02078

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.63385

Collected Steps per Second: 22,837.71330
Overall Steps per Second: 10,659.27887

Timestep Collection Time: 2.18954
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.69112

Cumulative Model Updates: 258,840
Cumulative Timesteps: 2,158,679,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.04379
Policy Entropy: 2.09484
Value Function Loss: 0.02117

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.64401

Collected Steps per Second: 23,556.77110
Overall Steps per Second: 10,853.24318

Timestep Collection Time: 2.12389
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.60987

Cumulative Model Updates: 258,846
Cumulative Timesteps: 2,158,729,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2158729214...
Checkpoint 2158729214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.27695
Policy Entropy: 2.12906
Value Function Loss: 0.02006

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.64593

Collected Steps per Second: 22,940.79487
Overall Steps per Second: 10,785.06724

Timestep Collection Time: 2.18013
Timestep Consumption Time: 2.45720
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.63734

Cumulative Model Updates: 258,852
Cumulative Timesteps: 2,158,779,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.72592
Policy Entropy: 2.13497
Value Function Loss: 0.02003

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.64863

Collected Steps per Second: 23,075.48486
Overall Steps per Second: 10,931.33621

Timestep Collection Time: 2.16776
Timestep Consumption Time: 2.40826
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.57602

Cumulative Model Updates: 258,858
Cumulative Timesteps: 2,158,829,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2158829250...
Checkpoint 2158829250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.04838
Policy Entropy: 2.11687
Value Function Loss: 0.02006

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.65485

Collected Steps per Second: 22,761.39481
Overall Steps per Second: 10,810.75149

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.43056
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.62928

Cumulative Model Updates: 258,864
Cumulative Timesteps: 2,158,879,296

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.09448
Policy Entropy: 2.08949
Value Function Loss: 0.02109

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.64965

Collected Steps per Second: 22,445.62200
Overall Steps per Second: 10,561.62988

Timestep Collection Time: 2.22761
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.73412

Cumulative Model Updates: 258,870
Cumulative Timesteps: 2,158,929,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2158929296...
Checkpoint 2158929296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.58742
Policy Entropy: 2.07255
Value Function Loss: 0.02072

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.54675
Value Function Update Magnitude: 0.64028

Collected Steps per Second: 22,070.44332
Overall Steps per Second: 10,647.27480

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.69904

Cumulative Model Updates: 258,876
Cumulative Timesteps: 2,158,979,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.03727
Policy Entropy: 2.09912
Value Function Loss: 0.01988

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.53558
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 23,663.90518
Overall Steps per Second: 10,908.10902

Timestep Collection Time: 2.11394
Timestep Consumption Time: 2.47201
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.58595

Cumulative Model Updates: 258,882
Cumulative Timesteps: 2,159,029,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2159029352...
Checkpoint 2159029352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.52533
Policy Entropy: 2.11808
Value Function Loss: 0.01991

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.61891

Collected Steps per Second: 22,829.26066
Overall Steps per Second: 10,605.30418

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.52485
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.71538

Cumulative Model Updates: 258,888
Cumulative Timesteps: 2,159,079,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.04806
Policy Entropy: 2.11469
Value Function Loss: 0.02081

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.62594

Collected Steps per Second: 23,290.78480
Overall Steps per Second: 10,966.16185

Timestep Collection Time: 2.14677
Timestep Consumption Time: 2.41271
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.55948

Cumulative Model Updates: 258,894
Cumulative Timesteps: 2,159,129,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2159129360...
Checkpoint 2159129360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.21460
Policy Entropy: 2.11921
Value Function Loss: 0.02073

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.52912
Value Function Update Magnitude: 0.62824

Collected Steps per Second: 22,788.55415
Overall Steps per Second: 11,018.44997

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.34404
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.53839

Cumulative Model Updates: 258,900
Cumulative Timesteps: 2,159,179,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.84155
Policy Entropy: 2.12734
Value Function Loss: 0.02076

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 23,255.27746
Overall Steps per Second: 10,919.76289

Timestep Collection Time: 2.15005
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.57885

Cumulative Model Updates: 258,906
Cumulative Timesteps: 2,159,229,366

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2159229366...
Checkpoint 2159229366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.02648
Policy Entropy: 2.14374
Value Function Loss: 0.01875

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.52525
Value Function Update Magnitude: 0.60208

Collected Steps per Second: 22,681.95379
Overall Steps per Second: 10,645.66123

Timestep Collection Time: 2.20563
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.69938

Cumulative Model Updates: 258,912
Cumulative Timesteps: 2,159,279,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.10451
Policy Entropy: 2.13929
Value Function Loss: 0.01856

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.51308
Value Function Update Magnitude: 0.59938

Collected Steps per Second: 23,195.98039
Overall Steps per Second: 10,982.15266

Timestep Collection Time: 2.15641
Timestep Consumption Time: 2.39825
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.55466

Cumulative Model Updates: 258,918
Cumulative Timesteps: 2,159,329,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2159329414...
Checkpoint 2159329414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.08908
Policy Entropy: 2.12764
Value Function Loss: 0.01859

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.51532
Value Function Update Magnitude: 0.59938

Collected Steps per Second: 22,162.00254
Overall Steps per Second: 10,694.14483

Timestep Collection Time: 2.25629
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.67583

Cumulative Model Updates: 258,924
Cumulative Timesteps: 2,159,379,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.51690
Policy Entropy: 2.11591
Value Function Loss: 0.01927

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.61392

Collected Steps per Second: 23,101.66270
Overall Steps per Second: 10,830.70437

Timestep Collection Time: 2.16461
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.61706

Cumulative Model Updates: 258,930
Cumulative Timesteps: 2,159,429,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2159429424...
Checkpoint 2159429424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.17204
Policy Entropy: 2.10117
Value Function Loss: 0.01908

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.62933

Collected Steps per Second: 22,429.10369
Overall Steps per Second: 10,601.52053

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.71668

Cumulative Model Updates: 258,936
Cumulative Timesteps: 2,159,479,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.77314
Policy Entropy: 2.08536
Value Function Loss: 0.01890

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.63635

Collected Steps per Second: 22,838.67724
Overall Steps per Second: 10,897.09216

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.39959
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.58930

Cumulative Model Updates: 258,942
Cumulative Timesteps: 2,159,529,438

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2159529438...
Checkpoint 2159529438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.46723
Policy Entropy: 2.08257
Value Function Loss: 0.01857

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.66180

Collected Steps per Second: 22,557.68461
Overall Steps per Second: 10,670.06734

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.47036
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.68769

Cumulative Model Updates: 258,948
Cumulative Timesteps: 2,159,579,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.84715
Policy Entropy: 2.07963
Value Function Loss: 0.01886

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.54110
Value Function Update Magnitude: 0.67758

Collected Steps per Second: 24,129.69482
Overall Steps per Second: 10,922.97453

Timestep Collection Time: 2.07222
Timestep Consumption Time: 2.50547
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.57769

Cumulative Model Updates: 258,954
Cumulative Timesteps: 2,159,629,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2159629458...
Checkpoint 2159629458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.66097
Policy Entropy: 2.08741
Value Function Loss: 0.01854

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.53058
Value Function Update Magnitude: 0.66958

Collected Steps per Second: 23,096.44989
Overall Steps per Second: 10,758.50307

Timestep Collection Time: 2.16570
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.64935

Cumulative Model Updates: 258,960
Cumulative Timesteps: 2,159,679,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.55415
Policy Entropy: 2.07117
Value Function Loss: 0.01952

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.53044
Value Function Update Magnitude: 0.65571

Collected Steps per Second: 23,291.45735
Overall Steps per Second: 10,816.89645

Timestep Collection Time: 2.14783
Timestep Consumption Time: 2.47698
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.62480

Cumulative Model Updates: 258,966
Cumulative Timesteps: 2,159,729,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2159729504...
Checkpoint 2159729504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.62929
Policy Entropy: 2.07973
Value Function Loss: 0.01894

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.53490
Value Function Update Magnitude: 0.66386

Collected Steps per Second: 22,694.99556
Overall Steps per Second: 10,989.34388

Timestep Collection Time: 2.20427
Timestep Consumption Time: 2.34795
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.55223

Cumulative Model Updates: 258,972
Cumulative Timesteps: 2,159,779,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.83986
Policy Entropy: 2.08904
Value Function Loss: 0.01896

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.66602

Collected Steps per Second: 22,939.27423
Overall Steps per Second: 10,673.29717

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.68478

Cumulative Model Updates: 258,978
Cumulative Timesteps: 2,159,829,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2159829532...
Checkpoint 2159829532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.41670
Policy Entropy: 2.11217
Value Function Loss: 0.01960

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.66886

Collected Steps per Second: 22,481.34824
Overall Steps per Second: 10,618.80559

Timestep Collection Time: 2.22407
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.70863

Cumulative Model Updates: 258,984
Cumulative Timesteps: 2,159,879,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.82629
Policy Entropy: 2.12721
Value Function Loss: 0.01843

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.52618
Value Function Update Magnitude: 0.67916

Collected Steps per Second: 22,946.24354
Overall Steps per Second: 10,794.96710

Timestep Collection Time: 2.17988
Timestep Consumption Time: 2.45376
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.63364

Cumulative Model Updates: 258,990
Cumulative Timesteps: 2,159,929,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2159929552...
Checkpoint 2159929552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.38383
Policy Entropy: 2.12637
Value Function Loss: 0.01786

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.51212
Value Function Update Magnitude: 0.65849

Collected Steps per Second: 22,344.00109
Overall Steps per Second: 10,635.42974

Timestep Collection Time: 2.23971
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.70540

Cumulative Model Updates: 258,996
Cumulative Timesteps: 2,159,979,596

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.76277
Policy Entropy: 2.13210
Value Function Loss: 0.01796

Mean KL Divergence: 0.02835
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.51829
Value Function Update Magnitude: 0.64858

Collected Steps per Second: 23,330.26328
Overall Steps per Second: 10,938.12764

Timestep Collection Time: 2.14340
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.57171

Cumulative Model Updates: 259,002
Cumulative Timesteps: 2,160,029,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2160029602...
Checkpoint 2160029602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.77567
Policy Entropy: 2.11839
Value Function Loss: 0.01873

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.15038
Policy Update Magnitude: 0.53528
Value Function Update Magnitude: 0.65756

Collected Steps per Second: 23,088.40069
Overall Steps per Second: 10,635.63497

Timestep Collection Time: 2.16602
Timestep Consumption Time: 2.53609
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70212

Cumulative Model Updates: 259,008
Cumulative Timesteps: 2,160,079,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.45622
Policy Entropy: 2.13210
Value Function Loss: 0.01976

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.64647

Collected Steps per Second: 23,347.00907
Overall Steps per Second: 10,777.56066

Timestep Collection Time: 2.14194
Timestep Consumption Time: 2.49807
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.64001

Cumulative Model Updates: 259,014
Cumulative Timesteps: 2,160,129,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2160129620...
Checkpoint 2160129620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.78566
Policy Entropy: 2.11704
Value Function Loss: 0.02053

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.65767

Collected Steps per Second: 22,814.45563
Overall Steps per Second: 10,711.08032

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.66881

Cumulative Model Updates: 259,020
Cumulative Timesteps: 2,160,179,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.41860
Policy Entropy: 2.10594
Value Function Loss: 0.02102

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.58036
Value Function Update Magnitude: 0.67181

Collected Steps per Second: 23,883.47089
Overall Steps per Second: 10,937.83985

Timestep Collection Time: 2.09442
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.57330

Cumulative Model Updates: 259,026
Cumulative Timesteps: 2,160,229,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2160229650...
Checkpoint 2160229650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.02443
Policy Entropy: 2.11112
Value Function Loss: 0.01990

Mean KL Divergence: 0.03030
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.59139
Value Function Update Magnitude: 0.65525

Collected Steps per Second: 22,736.01748
Overall Steps per Second: 10,636.94681

Timestep Collection Time: 2.19924
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.70079

Cumulative Model Updates: 259,032
Cumulative Timesteps: 2,160,279,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.40908
Policy Entropy: 2.11413
Value Function Loss: 0.01931

Mean KL Divergence: 0.02595
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.56892
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 23,094.06564
Overall Steps per Second: 10,869.81295

Timestep Collection Time: 2.16636
Timestep Consumption Time: 2.43630
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60266

Cumulative Model Updates: 259,038
Cumulative Timesteps: 2,160,329,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2160329682...
Checkpoint 2160329682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.81166
Policy Entropy: 2.13808
Value Function Loss: 0.01832

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.55133
Value Function Update Magnitude: 0.60751

Collected Steps per Second: 22,742.96596
Overall Steps per Second: 10,870.65235

Timestep Collection Time: 2.19883
Timestep Consumption Time: 2.40144
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.60028

Cumulative Model Updates: 259,044
Cumulative Timesteps: 2,160,379,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.90096
Policy Entropy: 2.11754
Value Function Loss: 0.01885

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.60442

Collected Steps per Second: 23,217.73717
Overall Steps per Second: 10,696.21688

Timestep Collection Time: 2.15422
Timestep Consumption Time: 2.52183
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.67605

Cumulative Model Updates: 259,050
Cumulative Timesteps: 2,160,429,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2160429706...
Checkpoint 2160429706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.40307
Policy Entropy: 2.10384
Value Function Loss: 0.01947

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.52329
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 22,398.94852
Overall Steps per Second: 10,662.19117

Timestep Collection Time: 2.23350
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.69209

Cumulative Model Updates: 259,056
Cumulative Timesteps: 2,160,479,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.78244
Policy Entropy: 2.08872
Value Function Loss: 0.01965

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.52870
Value Function Update Magnitude: 0.62394

Collected Steps per Second: 22,525.35701
Overall Steps per Second: 10,944.20346

Timestep Collection Time: 2.22087
Timestep Consumption Time: 2.35013
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.57100

Cumulative Model Updates: 259,062
Cumulative Timesteps: 2,160,529,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2160529760...
Checkpoint 2160529760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.25035
Policy Entropy: 2.08876
Value Function Loss: 0.01972

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.63265

Collected Steps per Second: 22,323.14861
Overall Steps per Second: 10,671.97431

Timestep Collection Time: 2.24117
Timestep Consumption Time: 2.44681
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.68798

Cumulative Model Updates: 259,068
Cumulative Timesteps: 2,160,579,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.31928
Policy Entropy: 2.10024
Value Function Loss: 0.01898

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.53168
Value Function Update Magnitude: 0.63473

Collected Steps per Second: 23,419.66878
Overall Steps per Second: 9,727.58578

Timestep Collection Time: 2.13530
Timestep Consumption Time: 3.00554
PPO Batch Consumption Time: 0.32222
Total Iteration Time: 5.14084

Cumulative Model Updates: 259,074
Cumulative Timesteps: 2,160,629,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2160629798...
Checkpoint 2160629798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.63851
Policy Entropy: 2.10250
Value Function Loss: 0.01891

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.52943
Value Function Update Magnitude: 0.62103

Collected Steps per Second: 11,571.26236
Overall Steps per Second: 7,101.87117

Timestep Collection Time: 4.32261
Timestep Consumption Time: 2.72033
PPO Batch Consumption Time: 0.31408
Total Iteration Time: 7.04293

Cumulative Model Updates: 259,080
Cumulative Timesteps: 2,160,679,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2160679816...
Checkpoint 2160679816 saved!
