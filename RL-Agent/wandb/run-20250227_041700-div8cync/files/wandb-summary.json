{"Mean KL Divergence":0.011989726219326258,"Timestep Consumption Time":2.5323710999946343,"Value Function Loss":0.03584931666652361,"Policy Entropy":3.6577812830607095,"_wandb":{"runtime":201346},"Policy Update Magnitude":0.4111196994781494,"x_vel":-3.852419276131031,"_timestamp":1.7406878747750669e+09,"Overall Steps per Second":9085.5692540714,"Timesteps Collected":50000,"Total Iteration Time":5.503232499999285,"_step":84611,"Cumulative Model Updates":92140,"Timestep Collection Time":2.970861400004651,"Policy Reward":75462.57534434892,"SB3 Clip Fraction":0.1583133302628994,"Value Function Update Magnitude":0.5660374164581299,"y_vel":-5.4599073113644225,"Cumulative Timesteps":768306042,"z_vel":-1.0868024913680554,"Collected Steps per Second":16830.135529015835,"_runtime":201346.5318449,"PPO Batch Consumption Time":0.29982078075408936}