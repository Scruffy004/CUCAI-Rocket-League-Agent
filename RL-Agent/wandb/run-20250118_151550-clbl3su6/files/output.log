Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,197.93031
Policy Entropy: 1.96880
Value Function Loss: 0.08119

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00562
Policy Update Magnitude: 0.19574
Value Function Update Magnitude: 0.21652

Collected Steps per Second: 18,434.97727
Overall Steps per Second: 12,421.59458

Timestep Collection Time: 2.71441
Timestep Consumption Time: 1.31406
PPO Batch Consumption Time: 0.34148
Total Iteration Time: 4.02847

Cumulative Model Updates: 83,112
Cumulative Timesteps: 693,152,824

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,379.05658
Policy Entropy: 1.92874
Value Function Loss: 0.07772

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.40856
Value Function Update Magnitude: 0.44944

Collected Steps per Second: 21,768.69470
Overall Steps per Second: 12,108.04623

Timestep Collection Time: 2.29816
Timestep Consumption Time: 1.83364
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.13180

Cumulative Model Updates: 83,116
Cumulative Timesteps: 693,202,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 693202852...
Checkpoint 693202852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,797.41937
Policy Entropy: 1.91514
Value Function Loss: 0.07831

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.59032
Value Function Update Magnitude: 0.68149

Collected Steps per Second: 21,323.66495
Overall Steps per Second: 10,459.79172

Timestep Collection Time: 2.34584
Timestep Consumption Time: 2.43647
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.78231

Cumulative Model Updates: 83,122
Cumulative Timesteps: 693,252,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,810.26687
Policy Entropy: 1.88798
Value Function Loss: 0.08652

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.69136

Collected Steps per Second: 22,120.26104
Overall Steps per Second: 10,883.46552

Timestep Collection Time: 2.26064
Timestep Consumption Time: 2.33403
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.59468

Cumulative Model Updates: 83,128
Cumulative Timesteps: 693,302,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 693302880...
Checkpoint 693302880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,173.52103
Policy Entropy: 1.88909
Value Function Loss: 0.08432

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.75521

Collected Steps per Second: 21,569.86709
Overall Steps per Second: 10,604.49794

Timestep Collection Time: 2.31851
Timestep Consumption Time: 2.39741
PPO Batch Consumption Time: 0.27627
Total Iteration Time: 4.71592

Cumulative Model Updates: 83,134
Cumulative Timesteps: 693,352,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,347.03389
Policy Entropy: 1.90518
Value Function Loss: 0.08613

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.66098

Collected Steps per Second: 22,238.22915
Overall Steps per Second: 10,624.46898

Timestep Collection Time: 2.24847
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.70631

Cumulative Model Updates: 83,140
Cumulative Timesteps: 693,402,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 693402892...
Checkpoint 693402892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,214.22226
Policy Entropy: 1.90665
Value Function Loss: 0.07955

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.66274

Collected Steps per Second: 21,562.42729
Overall Steps per Second: 10,402.54692

Timestep Collection Time: 2.32005
Timestep Consumption Time: 2.48896
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.80901

Cumulative Model Updates: 83,146
Cumulative Timesteps: 693,452,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,430.60040
Policy Entropy: 1.91474
Value Function Loss: 0.07889

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.67650

Collected Steps per Second: 21,883.92715
Overall Steps per Second: 10,469.59688

Timestep Collection Time: 2.28551
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.77726

Cumulative Model Updates: 83,152
Cumulative Timesteps: 693,502,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 693502934...
Checkpoint 693502934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,534.98634
Policy Entropy: 1.90142
Value Function Loss: 0.07427

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.53885
Value Function Update Magnitude: 0.57546

Collected Steps per Second: 21,766.79570
Overall Steps per Second: 10,608.59721

Timestep Collection Time: 2.29781
Timestep Consumption Time: 2.41685
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.71467

Cumulative Model Updates: 83,158
Cumulative Timesteps: 693,552,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,068.31781
Policy Entropy: 1.89262
Value Function Loss: 0.07523

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.54118
Value Function Update Magnitude: 0.54929

Collected Steps per Second: 22,350.40304
Overall Steps per Second: 10,475.43485

Timestep Collection Time: 2.23889
Timestep Consumption Time: 2.53800
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.77689

Cumulative Model Updates: 83,164
Cumulative Timesteps: 693,602,990

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 693602990...
Checkpoint 693602990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,644.35600
Policy Entropy: 1.87231
Value Function Loss: 0.07809

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.54003
Value Function Update Magnitude: 0.54800

Collected Steps per Second: 21,941.55381
Overall Steps per Second: 10,495.27902

Timestep Collection Time: 2.27988
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76633

Cumulative Model Updates: 83,170
Cumulative Timesteps: 693,653,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,634.66950
Policy Entropy: 1.87853
Value Function Loss: 0.08154

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.52726
Value Function Update Magnitude: 0.52002

Collected Steps per Second: 22,247.73676
Overall Steps per Second: 10,632.21271

Timestep Collection Time: 2.24787
Timestep Consumption Time: 2.45576
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.70363

Cumulative Model Updates: 83,176
Cumulative Timesteps: 693,703,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 693703024...
Checkpoint 693703024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,367.31817
Policy Entropy: 1.88177
Value Function Loss: 0.07821

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.52684

Collected Steps per Second: 22,255.64911
Overall Steps per Second: 10,692.58063

Timestep Collection Time: 2.24716
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.67726

Cumulative Model Updates: 83,182
Cumulative Timesteps: 693,753,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,364.88100
Policy Entropy: 1.89873
Value Function Loss: 0.07688

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.56477

Collected Steps per Second: 21,483.15391
Overall Steps per Second: 10,382.44950

Timestep Collection Time: 2.32759
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.81620

Cumulative Model Updates: 83,188
Cumulative Timesteps: 693,803,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 693803040...
Checkpoint 693803040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,876.63379
Policy Entropy: 1.88723
Value Function Loss: 0.08089

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.56953

Collected Steps per Second: 22,081.17698
Overall Steps per Second: 10,582.61794

Timestep Collection Time: 2.26455
Timestep Consumption Time: 2.46055
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.72511

Cumulative Model Updates: 83,194
Cumulative Timesteps: 693,853,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,655.19698
Policy Entropy: 1.89947
Value Function Loss: 0.08850

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.55475
Value Function Update Magnitude: 0.47712

Collected Steps per Second: 21,797.72392
Overall Steps per Second: 10,541.63298

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.45026
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.74500

Cumulative Model Updates: 83,200
Cumulative Timesteps: 693,903,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 693903064...
Checkpoint 693903064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,513.11351
Policy Entropy: 1.91476
Value Function Loss: 0.08742

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.55607
Value Function Update Magnitude: 0.47329

Collected Steps per Second: 21,551.46597
Overall Steps per Second: 10,532.97826

Timestep Collection Time: 2.32077
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.74851

Cumulative Model Updates: 83,206
Cumulative Timesteps: 693,953,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,691.77189
Policy Entropy: 1.91679
Value Function Loss: 0.08497

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.41490

Collected Steps per Second: 22,105.79480
Overall Steps per Second: 10,534.87663

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.74880

Cumulative Model Updates: 83,212
Cumulative Timesteps: 694,003,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 694003108...
Checkpoint 694003108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,149.55294
Policy Entropy: 1.92009
Value Function Loss: 0.07946

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.53417
Value Function Update Magnitude: 0.38912

Collected Steps per Second: 20,662.83547
Overall Steps per Second: 9,884.25464

Timestep Collection Time: 2.42009
Timestep Consumption Time: 2.63906
PPO Batch Consumption Time: 0.29856
Total Iteration Time: 5.05916

Cumulative Model Updates: 83,218
Cumulative Timesteps: 694,053,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,385.99018
Policy Entropy: 1.90545
Value Function Loss: 0.07124

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.51393
Value Function Update Magnitude: 0.42556

Collected Steps per Second: 20,921.02183
Overall Steps per Second: 10,028.24416

Timestep Collection Time: 2.39099
Timestep Consumption Time: 2.59712
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.98811

Cumulative Model Updates: 83,224
Cumulative Timesteps: 694,103,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 694103136...
Checkpoint 694103136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,806.99063
Policy Entropy: 1.90053
Value Function Loss: 0.07328

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.51593
Value Function Update Magnitude: 0.40118

Collected Steps per Second: 18,519.61758
Overall Steps per Second: 9,181.18309

Timestep Collection Time: 2.70265
Timestep Consumption Time: 2.74894
PPO Batch Consumption Time: 0.31807
Total Iteration Time: 5.45158

Cumulative Model Updates: 83,230
Cumulative Timesteps: 694,153,188

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,736.94733
Policy Entropy: 1.91303
Value Function Loss: 0.07573

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.51563
Value Function Update Magnitude: 0.58725

Collected Steps per Second: 21,261.59437
Overall Steps per Second: 10,258.74801

Timestep Collection Time: 2.35269
Timestep Consumption Time: 2.52334
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.87603

Cumulative Model Updates: 83,236
Cumulative Timesteps: 694,203,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 694203210...
Checkpoint 694203210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,954.58176
Policy Entropy: 1.92178
Value Function Loss: 0.07767

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 20,608.69827
Overall Steps per Second: 10,006.59444

Timestep Collection Time: 2.42694
Timestep Consumption Time: 2.57137
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.99830

Cumulative Model Updates: 83,242
Cumulative Timesteps: 694,253,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,156.77490
Policy Entropy: 1.92884
Value Function Loss: 0.07301

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.51846
Value Function Update Magnitude: 0.64812

Collected Steps per Second: 21,778.43230
Overall Steps per Second: 10,079.32596

Timestep Collection Time: 2.29594
Timestep Consumption Time: 2.66491
PPO Batch Consumption Time: 0.31766
Total Iteration Time: 4.96085

Cumulative Model Updates: 83,248
Cumulative Timesteps: 694,303,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 694303228...
Checkpoint 694303228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,618.56229
Policy Entropy: 1.91751
Value Function Loss: 0.08051

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.48281
Value Function Update Magnitude: 0.52408

Collected Steps per Second: 21,007.71799
Overall Steps per Second: 10,189.51948

Timestep Collection Time: 2.38170
Timestep Consumption Time: 2.52864
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.91034

Cumulative Model Updates: 83,254
Cumulative Timesteps: 694,353,262

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,310.53604
Policy Entropy: 1.91283
Value Function Loss: 0.08674

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.51017
Value Function Update Magnitude: 0.45310

Collected Steps per Second: 21,459.77887
Overall Steps per Second: 10,216.70354

Timestep Collection Time: 2.33115
Timestep Consumption Time: 2.56534
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.89649

Cumulative Model Updates: 83,260
Cumulative Timesteps: 694,403,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 694403288...
Checkpoint 694403288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,135.53548
Policy Entropy: 1.91862
Value Function Loss: 0.08701

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.44046

Collected Steps per Second: 20,596.79050
Overall Steps per Second: 10,063.55165

Timestep Collection Time: 2.42824
Timestep Consumption Time: 2.54157
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.96982

Cumulative Model Updates: 83,266
Cumulative Timesteps: 694,453,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,091.44247
Policy Entropy: 1.92519
Value Function Loss: 0.08363

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.37813

Collected Steps per Second: 21,598.82443
Overall Steps per Second: 10,287.40632

Timestep Collection Time: 2.31513
Timestep Consumption Time: 2.54557
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.86070

Cumulative Model Updates: 83,272
Cumulative Timesteps: 694,503,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 694503306...
Checkpoint 694503306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,565.74613
Policy Entropy: 1.93573
Value Function Loss: 0.07435

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.53213
Value Function Update Magnitude: 0.46018

Collected Steps per Second: 20,578.86483
Overall Steps per Second: 10,060.25167

Timestep Collection Time: 2.43016
Timestep Consumption Time: 2.54089
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.97105

Cumulative Model Updates: 83,278
Cumulative Timesteps: 694,553,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,511.63136
Policy Entropy: 1.93591
Value Function Loss: 0.07977

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.53010
Value Function Update Magnitude: 0.48684

Collected Steps per Second: 21,267.06005
Overall Steps per Second: 10,203.61527

Timestep Collection Time: 2.35152
Timestep Consumption Time: 2.54968
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.90120

Cumulative Model Updates: 83,284
Cumulative Timesteps: 694,603,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 694603326...
Checkpoint 694603326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,573.47161
Policy Entropy: 1.93782
Value Function Loss: 0.08257

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14860
Policy Update Magnitude: 0.51415
Value Function Update Magnitude: 0.40699

Collected Steps per Second: 20,517.56291
Overall Steps per Second: 9,979.46306

Timestep Collection Time: 2.43694
Timestep Consumption Time: 2.57335
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 5.01029

Cumulative Model Updates: 83,290
Cumulative Timesteps: 694,653,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,119.26676
Policy Entropy: 1.93332
Value Function Loss: 0.08408

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.50645
Value Function Update Magnitude: 0.42548

Collected Steps per Second: 21,491.78299
Overall Steps per Second: 10,246.74995

Timestep Collection Time: 2.32815
Timestep Consumption Time: 2.55496
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.88311

Cumulative Model Updates: 83,296
Cumulative Timesteps: 694,703,362

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 694703362...
Checkpoint 694703362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,620.05589
Policy Entropy: 1.92263
Value Function Loss: 0.08236

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.53747
Value Function Update Magnitude: 0.52061

Collected Steps per Second: 20,932.76435
Overall Steps per Second: 9,876.22270

Timestep Collection Time: 2.38870
Timestep Consumption Time: 2.67417
PPO Batch Consumption Time: 0.30818
Total Iteration Time: 5.06287

Cumulative Model Updates: 83,302
Cumulative Timesteps: 694,753,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,789.31317
Policy Entropy: 1.92143
Value Function Loss: 0.07973

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.49167

Collected Steps per Second: 21,649.00870
Overall Steps per Second: 10,249.76425

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.57023
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.88128

Cumulative Model Updates: 83,308
Cumulative Timesteps: 694,803,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 694803396...
Checkpoint 694803396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,419.79893
Policy Entropy: 1.92844
Value Function Loss: 0.07830

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.45456

Collected Steps per Second: 20,803.28128
Overall Steps per Second: 10,092.01739

Timestep Collection Time: 2.40472
Timestep Consumption Time: 2.55227
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.95699

Cumulative Model Updates: 83,314
Cumulative Timesteps: 694,853,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,995.14770
Policy Entropy: 1.92931
Value Function Loss: 0.07312

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.52665
Value Function Update Magnitude: 0.47814

Collected Steps per Second: 21,319.08390
Overall Steps per Second: 10,087.82494

Timestep Collection Time: 2.34654
Timestep Consumption Time: 2.61251
PPO Batch Consumption Time: 0.30397
Total Iteration Time: 4.95905

Cumulative Model Updates: 83,320
Cumulative Timesteps: 694,903,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 694903448...
Checkpoint 694903448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,600.23991
Policy Entropy: 1.93306
Value Function Loss: 0.07356

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.52246
Value Function Update Magnitude: 0.58588

Collected Steps per Second: 20,680.04337
Overall Steps per Second: 10,118.13776

Timestep Collection Time: 2.41779
Timestep Consumption Time: 2.52383
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.94162

Cumulative Model Updates: 83,326
Cumulative Timesteps: 694,953,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,011.38434
Policy Entropy: 1.92523
Value Function Loss: 0.06888

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.52907
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 21,590.14854
Overall Steps per Second: 10,219.52759

Timestep Collection Time: 2.31680
Timestep Consumption Time: 2.57775
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.89455

Cumulative Model Updates: 83,332
Cumulative Timesteps: 695,003,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 695003468...
Checkpoint 695003468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,476.01010
Policy Entropy: 1.92194
Value Function Loss: 0.07068

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.52241
Value Function Update Magnitude: 0.59522

Collected Steps per Second: 20,918.01250
Overall Steps per Second: 10,101.67031

Timestep Collection Time: 2.39239
Timestep Consumption Time: 2.56164
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.95403

Cumulative Model Updates: 83,338
Cumulative Timesteps: 695,053,512

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,259.59504
Policy Entropy: 1.90052
Value Function Loss: 0.07531

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.52613
Value Function Update Magnitude: 0.62940

Collected Steps per Second: 21,599.90637
Overall Steps per Second: 10,265.04796

Timestep Collection Time: 2.31547
Timestep Consumption Time: 2.55679
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.87226

Cumulative Model Updates: 83,344
Cumulative Timesteps: 695,103,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 695103526...
Checkpoint 695103526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,396.82666
Policy Entropy: 1.88439
Value Function Loss: 0.07992

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.52303
Value Function Update Magnitude: 0.66574

Collected Steps per Second: 20,972.88683
Overall Steps per Second: 10,061.78636

Timestep Collection Time: 2.38479
Timestep Consumption Time: 2.58609
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 4.97089

Cumulative Model Updates: 83,350
Cumulative Timesteps: 695,153,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,045.86209
Policy Entropy: 1.88801
Value Function Loss: 0.07696

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.47091
Value Function Update Magnitude: 0.59317

Collected Steps per Second: 21,727.13430
Overall Steps per Second: 10,416.74585

Timestep Collection Time: 2.30219
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.80188

Cumulative Model Updates: 83,356
Cumulative Timesteps: 695,203,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 695203562...
Checkpoint 695203562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,296.41346
Policy Entropy: 1.89359
Value Function Loss: 0.07640

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.46697
Value Function Update Magnitude: 0.58511

Collected Steps per Second: 20,890.54804
Overall Steps per Second: 10,146.33141

Timestep Collection Time: 2.39467
Timestep Consumption Time: 2.53578
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.93045

Cumulative Model Updates: 83,362
Cumulative Timesteps: 695,253,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,431.80975
Policy Entropy: 1.89565
Value Function Loss: 0.07103

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.45776
Value Function Update Magnitude: 0.65112

Collected Steps per Second: 20,753.97280
Overall Steps per Second: 10,234.63173

Timestep Collection Time: 2.41091
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.88889

Cumulative Model Updates: 83,368
Cumulative Timesteps: 695,303,624

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 695303624...
Checkpoint 695303624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,155.47254
Policy Entropy: 1.90685
Value Function Loss: 0.08124

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.50366
Value Function Update Magnitude: 0.64476

Collected Steps per Second: 20,275.32391
Overall Steps per Second: 10,039.24826

Timestep Collection Time: 2.46664
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.30184
Total Iteration Time: 4.98165

Cumulative Model Updates: 83,374
Cumulative Timesteps: 695,353,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,057.69990
Policy Entropy: 1.90769
Value Function Loss: 0.08426

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.68346

Collected Steps per Second: 19,582.58459
Overall Steps per Second: 10,020.26995

Timestep Collection Time: 2.55390
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.99108

Cumulative Model Updates: 83,380
Cumulative Timesteps: 695,403,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 695403648...
Checkpoint 695403648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,308.39206
Policy Entropy: 1.90785
Value Function Loss: 0.08234

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.68080

Collected Steps per Second: 20,040.22547
Overall Steps per Second: 10,132.29567

Timestep Collection Time: 2.49628
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.93728

Cumulative Model Updates: 83,386
Cumulative Timesteps: 695,453,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,998.85649
Policy Entropy: 1.89595
Value Function Loss: 0.07549

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.54988
Value Function Update Magnitude: 0.70333

Collected Steps per Second: 20,612.75554
Overall Steps per Second: 10,221.30625

Timestep Collection Time: 2.42753
Timestep Consumption Time: 2.46793
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.89546

Cumulative Model Updates: 83,392
Cumulative Timesteps: 695,503,712

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 695503712...
Checkpoint 695503712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,138.53151
Policy Entropy: 1.88639
Value Function Loss: 0.07195

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.53989
Value Function Update Magnitude: 0.70746

Collected Steps per Second: 20,087.75592
Overall Steps per Second: 10,086.45051

Timestep Collection Time: 2.48997
Timestep Consumption Time: 2.46896
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.95893

Cumulative Model Updates: 83,398
Cumulative Timesteps: 695,553,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,394.87701
Policy Entropy: 1.87614
Value Function Loss: 0.07247

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.53818
Value Function Update Magnitude: 0.63184

Collected Steps per Second: 20,207.25793
Overall Steps per Second: 9,934.01608

Timestep Collection Time: 2.47505
Timestep Consumption Time: 2.55957
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 5.03462

Cumulative Model Updates: 83,404
Cumulative Timesteps: 695,603,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 695603744...
Checkpoint 695603744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,970.74393
Policy Entropy: 1.87428
Value Function Loss: 0.07649

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.50697
Value Function Update Magnitude: 0.62536

Collected Steps per Second: 20,797.87579
Overall Steps per Second: 10,056.22650

Timestep Collection Time: 2.40428
Timestep Consumption Time: 2.56816
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.97244

Cumulative Model Updates: 83,410
Cumulative Timesteps: 695,653,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,359.96096
Policy Entropy: 1.86846
Value Function Loss: 0.08005

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.47788
Value Function Update Magnitude: 0.58999

Collected Steps per Second: 21,406.24012
Overall Steps per Second: 10,392.46092

Timestep Collection Time: 2.33698
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.81368

Cumulative Model Updates: 83,416
Cumulative Timesteps: 695,703,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 695703774...
Checkpoint 695703774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,055.64425
Policy Entropy: 1.88123
Value Function Loss: 0.07416

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.52661
Value Function Update Magnitude: 0.61654

Collected Steps per Second: 21,117.83040
Overall Steps per Second: 10,290.06163

Timestep Collection Time: 2.36814
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.86003

Cumulative Model Updates: 83,422
Cumulative Timesteps: 695,753,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,680.56046
Policy Entropy: 1.89287
Value Function Loss: 0.06843

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.53095
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 21,092.66158
Overall Steps per Second: 10,104.38519

Timestep Collection Time: 2.37248
Timestep Consumption Time: 2.58002
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.95250

Cumulative Model Updates: 83,428
Cumulative Timesteps: 695,803,826

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 695803826...
Checkpoint 695803826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,164.73832
Policy Entropy: 1.90077
Value Function Loss: 0.06253

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.52107
Value Function Update Magnitude: 0.58967

Collected Steps per Second: 20,961.26326
Overall Steps per Second: 10,180.59198

Timestep Collection Time: 2.38726
Timestep Consumption Time: 2.52797
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.91523

Cumulative Model Updates: 83,434
Cumulative Timesteps: 695,853,866

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,464.57131
Policy Entropy: 1.90371
Value Function Loss: 0.06490

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.52193
Value Function Update Magnitude: 0.65064

Collected Steps per Second: 21,544.74791
Overall Steps per Second: 10,385.80357

Timestep Collection Time: 2.32131
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.81542

Cumulative Model Updates: 83,440
Cumulative Timesteps: 695,903,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 695903878...
Checkpoint 695903878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,793.38863
Policy Entropy: 1.88233
Value Function Loss: 0.06335

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.52170
Value Function Update Magnitude: 0.65925

Collected Steps per Second: 21,160.40073
Overall Steps per Second: 10,253.16034

Timestep Collection Time: 2.36517
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.88123

Cumulative Model Updates: 83,446
Cumulative Timesteps: 695,953,926

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,692.69150
Policy Entropy: 1.85853
Value Function Loss: 0.07085

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.69623

Collected Steps per Second: 21,212.11813
Overall Steps per Second: 10,254.20668

Timestep Collection Time: 2.35846
Timestep Consumption Time: 2.52032
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.87878

Cumulative Model Updates: 83,452
Cumulative Timesteps: 696,003,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 696003954...
Checkpoint 696003954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,166.52295
Policy Entropy: 1.85566
Value Function Loss: 0.07425

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.54457
Value Function Update Magnitude: 0.70332

Collected Steps per Second: 21,152.42219
Overall Steps per Second: 10,026.72959

Timestep Collection Time: 2.36474
Timestep Consumption Time: 2.62392
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.98867

Cumulative Model Updates: 83,458
Cumulative Timesteps: 696,053,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,066.47001
Policy Entropy: 1.87148
Value Function Loss: 0.07630

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.70980

Collected Steps per Second: 21,205.09534
Overall Steps per Second: 10,222.38020

Timestep Collection Time: 2.35877
Timestep Consumption Time: 2.53422
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.89299

Cumulative Model Updates: 83,464
Cumulative Timesteps: 696,103,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 696103992...
Checkpoint 696103992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,612.93057
Policy Entropy: 1.87595
Value Function Loss: 0.07507

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.55100
Value Function Update Magnitude: 0.63964

Collected Steps per Second: 21,399.94844
Overall Steps per Second: 10,187.38787

Timestep Collection Time: 2.33786
Timestep Consumption Time: 2.57312
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.91097

Cumulative Model Updates: 83,470
Cumulative Timesteps: 696,154,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,441.92050
Policy Entropy: 1.88409
Value Function Loss: 0.06954

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.53710
Value Function Update Magnitude: 0.61035

Collected Steps per Second: 20,944.57505
Overall Steps per Second: 10,089.28790

Timestep Collection Time: 2.38840
Timestep Consumption Time: 2.56973
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.95813

Cumulative Model Updates: 83,476
Cumulative Timesteps: 696,204,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 696204046...
Checkpoint 696204046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,441.81778
Policy Entropy: 1.87506
Value Function Loss: 0.07168

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.51497
Value Function Update Magnitude: 0.62203

Collected Steps per Second: 21,363.84004
Overall Steps per Second: 10,266.65886

Timestep Collection Time: 2.34087
Timestep Consumption Time: 2.53024
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.87111

Cumulative Model Updates: 83,482
Cumulative Timesteps: 696,254,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,231.78078
Policy Entropy: 1.88964
Value Function Loss: 0.07040

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.16210
Policy Update Magnitude: 0.48856
Value Function Update Magnitude: 0.63824

Collected Steps per Second: 21,596.75659
Overall Steps per Second: 10,219.11934

Timestep Collection Time: 2.31581
Timestep Consumption Time: 2.57835
PPO Batch Consumption Time: 0.30129
Total Iteration Time: 4.89416

Cumulative Model Updates: 83,488
Cumulative Timesteps: 696,304,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 696304070...
Checkpoint 696304070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,517.64486
Policy Entropy: 1.89755
Value Function Loss: 0.07711

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.51286
Value Function Update Magnitude: 0.61809

Collected Steps per Second: 21,191.71146
Overall Steps per Second: 10,132.70414

Timestep Collection Time: 2.35951
Timestep Consumption Time: 2.57521
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.93471

Cumulative Model Updates: 83,494
Cumulative Timesteps: 696,354,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,813.13764
Policy Entropy: 1.91125
Value Function Loss: 0.07707

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.16006
Policy Update Magnitude: 0.53502
Value Function Update Magnitude: 0.66786

Collected Steps per Second: 21,250.08636
Overall Steps per Second: 10,179.45146

Timestep Collection Time: 2.35340
Timestep Consumption Time: 2.55944
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.91284

Cumulative Model Updates: 83,500
Cumulative Timesteps: 696,404,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 696404082...
Checkpoint 696404082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,123.92884
Policy Entropy: 1.90465
Value Function Loss: 0.07692

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.67037

Collected Steps per Second: 21,214.89483
Overall Steps per Second: 10,110.08417

Timestep Collection Time: 2.35749
Timestep Consumption Time: 2.58945
PPO Batch Consumption Time: 0.30422
Total Iteration Time: 4.94694

Cumulative Model Updates: 83,506
Cumulative Timesteps: 696,454,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,224.08763
Policy Entropy: 1.89458
Value Function Loss: 0.08403

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.57386

Collected Steps per Second: 21,472.93980
Overall Steps per Second: 10,351.20803

Timestep Collection Time: 2.32991
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.83325

Cumulative Model Updates: 83,512
Cumulative Timesteps: 696,504,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 696504126...
Checkpoint 696504126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,353.99073
Policy Entropy: 1.88384
Value Function Loss: 0.08774

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.55936
Value Function Update Magnitude: 0.53162

Collected Steps per Second: 21,275.76829
Overall Steps per Second: 10,268.69049

Timestep Collection Time: 2.35019
Timestep Consumption Time: 2.51918
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.86936

Cumulative Model Updates: 83,518
Cumulative Timesteps: 696,554,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,765.83772
Policy Entropy: 1.89350
Value Function Loss: 0.07981

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.63085

Collected Steps per Second: 20,972.81986
Overall Steps per Second: 10,082.00015

Timestep Collection Time: 2.38509
Timestep Consumption Time: 2.57643
PPO Batch Consumption Time: 0.30090
Total Iteration Time: 4.96152

Cumulative Model Updates: 83,524
Cumulative Timesteps: 696,604,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 696604150...
Checkpoint 696604150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,033.39832
Policy Entropy: 1.89959
Value Function Loss: 0.07878

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.55475

Collected Steps per Second: 21,195.10212
Overall Steps per Second: 10,123.58708

Timestep Collection Time: 2.36045
Timestep Consumption Time: 2.58147
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.94192

Cumulative Model Updates: 83,530
Cumulative Timesteps: 696,654,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,812.34338
Policy Entropy: 1.91213
Value Function Loss: 0.08575

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.52198

Collected Steps per Second: 21,479.29174
Overall Steps per Second: 10,343.25520

Timestep Collection Time: 2.32857
Timestep Consumption Time: 2.50705
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.83562

Cumulative Model Updates: 83,536
Cumulative Timesteps: 696,704,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 696704196...
Checkpoint 696704196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,358.43748
Policy Entropy: 1.90574
Value Function Loss: 0.09321

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 21,490.99101
Overall Steps per Second: 10,345.79823

Timestep Collection Time: 2.32674
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.83327

Cumulative Model Updates: 83,542
Cumulative Timesteps: 696,754,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,894.50080
Policy Entropy: 1.89686
Value Function Loss: 0.08858

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.71564

Collected Steps per Second: 21,385.77038
Overall Steps per Second: 10,067.28602

Timestep Collection Time: 2.33838
Timestep Consumption Time: 2.62900
PPO Batch Consumption Time: 0.30757
Total Iteration Time: 4.96738

Cumulative Model Updates: 83,548
Cumulative Timesteps: 696,804,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 696804208...
Checkpoint 696804208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,841.76729
Policy Entropy: 1.89490
Value Function Loss: 0.08700

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.54640
Value Function Update Magnitude: 0.62101

Collected Steps per Second: 20,933.40872
Overall Steps per Second: 10,189.69252

Timestep Collection Time: 2.38939
Timestep Consumption Time: 2.51930
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.90869

Cumulative Model Updates: 83,554
Cumulative Timesteps: 696,854,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,102.62360
Policy Entropy: 1.89372
Value Function Loss: 0.08343

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.55362
Value Function Update Magnitude: 0.59357

Collected Steps per Second: 21,265.26408
Overall Steps per Second: 10,261.59895

Timestep Collection Time: 2.35153
Timestep Consumption Time: 2.52159
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.87312

Cumulative Model Updates: 83,560
Cumulative Timesteps: 696,904,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 696904232...
Checkpoint 696904232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,955.14596
Policy Entropy: 1.89379
Value Function Loss: 0.08536

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.57388

Collected Steps per Second: 21,262.27875
Overall Steps per Second: 10,294.43852

Timestep Collection Time: 2.35281
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.85952

Cumulative Model Updates: 83,566
Cumulative Timesteps: 696,954,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,830.61256
Policy Entropy: 1.88478
Value Function Loss: 0.08288

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.46223

Collected Steps per Second: 21,323.18309
Overall Steps per Second: 10,158.35797

Timestep Collection Time: 2.34609
Timestep Consumption Time: 2.57853
PPO Batch Consumption Time: 0.29854
Total Iteration Time: 4.92461

Cumulative Model Updates: 83,572
Cumulative Timesteps: 697,004,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 697004284...
Checkpoint 697004284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,080.29659
Policy Entropy: 1.88758
Value Function Loss: 0.08200

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.53544

Collected Steps per Second: 20,931.48059
Overall Steps per Second: 10,226.03691

Timestep Collection Time: 2.39018
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.89241

Cumulative Model Updates: 83,578
Cumulative Timesteps: 697,054,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,599.14575
Policy Entropy: 1.87593
Value Function Loss: 0.08076

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.53196
Value Function Update Magnitude: 0.56722

Collected Steps per Second: 21,192.74659
Overall Steps per Second: 10,310.40227

Timestep Collection Time: 2.36024
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.85141

Cumulative Model Updates: 83,584
Cumulative Timesteps: 697,104,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 697104334...
Checkpoint 697104334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,446.64220
Policy Entropy: 1.87652
Value Function Loss: 0.08136

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.52583
Value Function Update Magnitude: 0.58437

Collected Steps per Second: 21,458.66693
Overall Steps per Second: 10,346.06138

Timestep Collection Time: 2.33146
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.83566

Cumulative Model Updates: 83,590
Cumulative Timesteps: 697,154,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,147.91125
Policy Entropy: 1.86469
Value Function Loss: 0.08358

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.66954

Collected Steps per Second: 21,295.20024
Overall Steps per Second: 9,985.27866

Timestep Collection Time: 2.34832
Timestep Consumption Time: 2.65985
PPO Batch Consumption Time: 0.31062
Total Iteration Time: 5.00817

Cumulative Model Updates: 83,596
Cumulative Timesteps: 697,204,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 697204372...
Checkpoint 697204372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,406.89083
Policy Entropy: 1.86579
Value Function Loss: 0.08321

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.74585

Collected Steps per Second: 21,022.27307
Overall Steps per Second: 10,259.17429

Timestep Collection Time: 2.37929
Timestep Consumption Time: 2.49616
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.87544

Cumulative Model Updates: 83,602
Cumulative Timesteps: 697,254,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,789.80086
Policy Entropy: 1.86515
Value Function Loss: 0.07857

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.73363

Collected Steps per Second: 21,201.82812
Overall Steps per Second: 10,158.20955

Timestep Collection Time: 2.35857
Timestep Consumption Time: 2.56415
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.92272

Cumulative Model Updates: 83,608
Cumulative Timesteps: 697,304,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 697304396...
Checkpoint 697304396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,733.26841
Policy Entropy: 1.86947
Value Function Loss: 0.08109

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.71324

Collected Steps per Second: 21,611.16865
Overall Steps per Second: 10,414.67806

Timestep Collection Time: 2.31482
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.80341

Cumulative Model Updates: 83,614
Cumulative Timesteps: 697,354,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,926.83857
Policy Entropy: 1.87146
Value Function Loss: 0.08084

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.72381

Collected Steps per Second: 21,202.08806
Overall Steps per Second: 10,154.89235

Timestep Collection Time: 2.36014
Timestep Consumption Time: 2.56753
PPO Batch Consumption Time: 0.30251
Total Iteration Time: 4.92767

Cumulative Model Updates: 83,620
Cumulative Timesteps: 697,404,462

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 697404462...
Checkpoint 697404462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,542.47188
Policy Entropy: 1.85991
Value Function Loss: 0.08477

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.55495
Value Function Update Magnitude: 0.70163

Collected Steps per Second: 21,223.28351
Overall Steps per Second: 10,168.48565

Timestep Collection Time: 2.35609
Timestep Consumption Time: 2.56145
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.91755

Cumulative Model Updates: 83,626
Cumulative Timesteps: 697,454,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,248.92433
Policy Entropy: 1.86646
Value Function Loss: 0.08572

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.56125

Collected Steps per Second: 21,076.45341
Overall Steps per Second: 10,097.90974

Timestep Collection Time: 2.37279
Timestep Consumption Time: 2.57972
PPO Batch Consumption Time: 0.30269
Total Iteration Time: 4.95251

Cumulative Model Updates: 83,632
Cumulative Timesteps: 697,504,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 697504476...
Checkpoint 697504476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,260.86108
Policy Entropy: 1.85409
Value Function Loss: 0.08487

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.54447
Value Function Update Magnitude: 0.39411

Collected Steps per Second: 21,242.96090
Overall Steps per Second: 10,067.04484

Timestep Collection Time: 2.35382
Timestep Consumption Time: 2.61308
PPO Batch Consumption Time: 0.30882
Total Iteration Time: 4.96690

Cumulative Model Updates: 83,638
Cumulative Timesteps: 697,554,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,838.98265
Policy Entropy: 1.84792
Value Function Loss: 0.08046

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.53142
Value Function Update Magnitude: 0.33511

Collected Steps per Second: 22,217.39006
Overall Steps per Second: 10,594.66032

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.72068

Cumulative Model Updates: 83,644
Cumulative Timesteps: 697,604,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 697604492...
Checkpoint 697604492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,967.91917
Policy Entropy: 1.82693
Value Function Loss: 0.07968

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.52442
Value Function Update Magnitude: 0.31122

Collected Steps per Second: 21,573.64341
Overall Steps per Second: 10,412.13804

Timestep Collection Time: 2.31876
Timestep Consumption Time: 2.48564
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.80439

Cumulative Model Updates: 83,650
Cumulative Timesteps: 697,654,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,899.16400
Policy Entropy: 1.82363
Value Function Loss: 0.08364

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.51270
Value Function Update Magnitude: 0.28500

Collected Steps per Second: 22,408.31740
Overall Steps per Second: 10,689.10825

Timestep Collection Time: 2.23158
Timestep Consumption Time: 2.44664
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.67822

Cumulative Model Updates: 83,656
Cumulative Timesteps: 697,704,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 697704522...
Checkpoint 697704522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,502.09566
Policy Entropy: 1.82657
Value Function Loss: 0.09138

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.50810
Value Function Update Magnitude: 0.33125

Collected Steps per Second: 22,091.57109
Overall Steps per Second: 10,641.00851

Timestep Collection Time: 2.26566
Timestep Consumption Time: 2.43803
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.70369

Cumulative Model Updates: 83,662
Cumulative Timesteps: 697,754,574

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,879.75247
Policy Entropy: 1.83326
Value Function Loss: 0.09357

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.32838

Collected Steps per Second: 22,740.41865
Overall Steps per Second: 10,623.15381

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.50918
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.70896

Cumulative Model Updates: 83,668
Cumulative Timesteps: 697,804,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 697804598...
Checkpoint 697804598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,971.75870
Policy Entropy: 1.83227
Value Function Loss: 0.09258

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.41448

Collected Steps per Second: 22,053.60679
Overall Steps per Second: 10,507.00699

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.76101

Cumulative Model Updates: 83,674
Cumulative Timesteps: 697,854,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,350.60172
Policy Entropy: 1.82747
Value Function Loss: 0.08318

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.55943
Value Function Update Magnitude: 0.61293

Collected Steps per Second: 22,374.87730
Overall Steps per Second: 10,582.52239

Timestep Collection Time: 2.23545
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.72647

Cumulative Model Updates: 83,680
Cumulative Timesteps: 697,904,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 697904640...
Checkpoint 697904640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,422.47724
Policy Entropy: 1.82145
Value Function Loss: 0.08148

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.55753
Value Function Update Magnitude: 0.72025

Collected Steps per Second: 22,464.02259
Overall Steps per Second: 10,536.16576

Timestep Collection Time: 2.22596
Timestep Consumption Time: 2.51998
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.74594

Cumulative Model Updates: 83,686
Cumulative Timesteps: 697,954,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,858.07365
Policy Entropy: 1.84238
Value Function Loss: 0.07307

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.55261
Value Function Update Magnitude: 0.74980

Collected Steps per Second: 22,751.56112
Overall Steps per Second: 10,806.87726

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.62687

Cumulative Model Updates: 83,692
Cumulative Timesteps: 698,004,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 698004646...
Checkpoint 698004646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,468.28364
Policy Entropy: 1.82946
Value Function Loss: 0.07243

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.54109
Value Function Update Magnitude: 0.75253

Collected Steps per Second: 22,142.15209
Overall Steps per Second: 10,656.50118

Timestep Collection Time: 2.25949
Timestep Consumption Time: 2.43530
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.69479

Cumulative Model Updates: 83,698
Cumulative Timesteps: 698,054,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,531.54032
Policy Entropy: 1.83927
Value Function Loss: 0.07256

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.72108

Collected Steps per Second: 22,730.43900
Overall Steps per Second: 10,424.94097

Timestep Collection Time: 2.20075
Timestep Consumption Time: 2.59774
PPO Batch Consumption Time: 0.31368
Total Iteration Time: 4.79849

Cumulative Model Updates: 83,704
Cumulative Timesteps: 698,104,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 698104700...
Checkpoint 698104700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,802.96885
Policy Entropy: 1.82861
Value Function Loss: 0.07527

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.52991
Value Function Update Magnitude: 0.68577

Collected Steps per Second: 20,944.04371
Overall Steps per Second: 10,235.24029

Timestep Collection Time: 2.38836
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.88723

Cumulative Model Updates: 83,710
Cumulative Timesteps: 698,154,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,448.30690
Policy Entropy: 1.81793
Value Function Loss: 0.07462

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.51675
Value Function Update Magnitude: 0.70085

Collected Steps per Second: 22,115.95090
Overall Steps per Second: 10,476.29221

Timestep Collection Time: 2.26172
Timestep Consumption Time: 2.51287
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.77459

Cumulative Model Updates: 83,716
Cumulative Timesteps: 698,204,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 698204742...
Checkpoint 698204742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,799.28592
Policy Entropy: 1.82121
Value Function Loss: 0.08021

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.16184
Policy Update Magnitude: 0.51404
Value Function Update Magnitude: 0.78977

Collected Steps per Second: 20,783.13478
Overall Steps per Second: 10,147.56643

Timestep Collection Time: 2.40628
Timestep Consumption Time: 2.52200
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.92828

Cumulative Model Updates: 83,722
Cumulative Timesteps: 698,254,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,819.57669
Policy Entropy: 1.82798
Value Function Loss: 0.07737

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.17151
Policy Update Magnitude: 0.50458
Value Function Update Magnitude: 0.82464

Collected Steps per Second: 21,905.33499
Overall Steps per Second: 10,363.97543

Timestep Collection Time: 2.28355
Timestep Consumption Time: 2.54297
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.82653

Cumulative Model Updates: 83,728
Cumulative Timesteps: 698,304,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 698304774...
Checkpoint 698304774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,032.78195
Policy Entropy: 1.83168
Value Function Loss: 0.07871

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.69770

Collected Steps per Second: 21,359.39638
Overall Steps per Second: 10,337.02163

Timestep Collection Time: 2.34136
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.83795

Cumulative Model Updates: 83,734
Cumulative Timesteps: 698,354,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,496.39439
Policy Entropy: 1.82340
Value Function Loss: 0.08737

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.16925
Policy Update Magnitude: 0.48601
Value Function Update Magnitude: 0.53785

Collected Steps per Second: 21,858.38668
Overall Steps per Second: 10,404.51082

Timestep Collection Time: 2.28873
Timestep Consumption Time: 2.51957
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.80830

Cumulative Model Updates: 83,740
Cumulative Timesteps: 698,404,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 698404812...
Checkpoint 698404812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,375.82956
Policy Entropy: 1.83534
Value Function Loss: 0.09608

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 20,225.51252
Overall Steps per Second: 9,979.54644

Timestep Collection Time: 2.47371
Timestep Consumption Time: 2.53975
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 5.01345

Cumulative Model Updates: 83,746
Cumulative Timesteps: 698,454,844

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,894.56893
Policy Entropy: 1.84430
Value Function Loss: 0.09158

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.51740
Value Function Update Magnitude: 0.66439

Collected Steps per Second: 21,925.55277
Overall Steps per Second: 10,378.41943

Timestep Collection Time: 2.28190
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.82077

Cumulative Model Updates: 83,752
Cumulative Timesteps: 698,504,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 698504876...
Checkpoint 698504876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,747.36449
Policy Entropy: 1.83894
Value Function Loss: 0.08241

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.49343
Value Function Update Magnitude: 0.71432

Collected Steps per Second: 22,257.17889
Overall Steps per Second: 10,659.57324

Timestep Collection Time: 2.24754
Timestep Consumption Time: 2.44533
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.69287

Cumulative Model Updates: 83,758
Cumulative Timesteps: 698,554,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,341.30419
Policy Entropy: 1.83552
Value Function Loss: 0.07851

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16447
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.77054

Collected Steps per Second: 23,119.47801
Overall Steps per Second: 10,855.69181

Timestep Collection Time: 2.16285
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.60625

Cumulative Model Updates: 83,764
Cumulative Timesteps: 698,604,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 698604904...
Checkpoint 698604904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,646.40865
Policy Entropy: 1.83290
Value Function Loss: 0.07523

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15203
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.77611

Collected Steps per Second: 21,967.89021
Overall Steps per Second: 10,433.12205

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.51698
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.79358

Cumulative Model Updates: 83,770
Cumulative Timesteps: 698,654,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,348.63759
Policy Entropy: 1.84862
Value Function Loss: 0.07862

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.79374

Collected Steps per Second: 22,537.64592
Overall Steps per Second: 10,754.90329

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.65034

Cumulative Model Updates: 83,776
Cumulative Timesteps: 698,704,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 698704930...
Checkpoint 698704930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,134.31683
Policy Entropy: 1.84698
Value Function Loss: 0.07869

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.83091

Collected Steps per Second: 22,658.12876
Overall Steps per Second: 10,652.26803

Timestep Collection Time: 2.20857
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.69778

Cumulative Model Updates: 83,782
Cumulative Timesteps: 698,754,972

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,154.98206
Policy Entropy: 1.84502
Value Function Loss: 0.07673

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.81475

Collected Steps per Second: 22,858.27136
Overall Steps per Second: 10,778.65000

Timestep Collection Time: 2.18748
Timestep Consumption Time: 2.45151
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.63899

Cumulative Model Updates: 83,788
Cumulative Timesteps: 698,804,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 698804974...
Checkpoint 698804974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,885.60119
Policy Entropy: 1.83749
Value Function Loss: 0.07495

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.77469

Collected Steps per Second: 22,059.09171
Overall Steps per Second: 10,631.47470

Timestep Collection Time: 2.26746
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.70471

Cumulative Model Updates: 83,794
Cumulative Timesteps: 698,854,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,104.81753
Policy Entropy: 1.83510
Value Function Loss: 0.07928

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.77113

Collected Steps per Second: 22,555.07765
Overall Steps per Second: 10,564.52033

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.73509

Cumulative Model Updates: 83,800
Cumulative Timesteps: 698,905,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 698905016...
Checkpoint 698905016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,936.43099
Policy Entropy: 1.82948
Value Function Loss: 0.08597

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.56321
Value Function Update Magnitude: 0.71987

Collected Steps per Second: 22,485.72225
Overall Steps per Second: 10,609.94411

Timestep Collection Time: 2.22488
Timestep Consumption Time: 2.49032
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.71520

Cumulative Model Updates: 83,806
Cumulative Timesteps: 698,955,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,775.06757
Policy Entropy: 1.81349
Value Function Loss: 0.08179

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.55780
Value Function Update Magnitude: 0.66463

Collected Steps per Second: 22,659.25369
Overall Steps per Second: 10,602.28106

Timestep Collection Time: 2.20687
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.71653

Cumulative Model Updates: 83,812
Cumulative Timesteps: 699,005,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 699005050...
Checkpoint 699005050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,739.59152
Policy Entropy: 1.81328
Value Function Loss: 0.08003

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.50943
Value Function Update Magnitude: 0.65251

Collected Steps per Second: 22,232.94258
Overall Steps per Second: 10,550.88984

Timestep Collection Time: 2.24910
Timestep Consumption Time: 2.49022
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.73932

Cumulative Model Updates: 83,818
Cumulative Timesteps: 699,055,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,895.16480
Policy Entropy: 1.82350
Value Function Loss: 0.08040

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.48124
Value Function Update Magnitude: 0.65079

Collected Steps per Second: 22,574.31147
Overall Steps per Second: 10,622.20113

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.71108

Cumulative Model Updates: 83,824
Cumulative Timesteps: 699,105,096

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 699105096...
Checkpoint 699105096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,318.36530
Policy Entropy: 1.84271
Value Function Loss: 0.07691

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.50569
Value Function Update Magnitude: 0.75854

Collected Steps per Second: 22,595.58614
Overall Steps per Second: 10,794.26456

Timestep Collection Time: 2.21521
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.63709

Cumulative Model Updates: 83,830
Cumulative Timesteps: 699,155,150

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,891.25712
Policy Entropy: 1.84526
Value Function Loss: 0.07506

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.47253
Value Function Update Magnitude: 0.79756

Collected Steps per Second: 22,530.87756
Overall Steps per Second: 10,565.97930

Timestep Collection Time: 2.21935
Timestep Consumption Time: 2.51319
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.73255

Cumulative Model Updates: 83,836
Cumulative Timesteps: 699,205,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 699205154...
Checkpoint 699205154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,493.87535
Policy Entropy: 1.84220
Value Function Loss: 0.07965

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.51698
Value Function Update Magnitude: 0.70683

Collected Steps per Second: 22,195.12955
Overall Steps per Second: 10,598.53547

Timestep Collection Time: 2.25383
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.71990

Cumulative Model Updates: 83,842
Cumulative Timesteps: 699,255,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,766.14871
Policy Entropy: 1.84038
Value Function Loss: 0.08163

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.73434

Collected Steps per Second: 22,537.03338
Overall Steps per Second: 10,574.66628

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.73131

Cumulative Model Updates: 83,848
Cumulative Timesteps: 699,305,210

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 699305210...
Checkpoint 699305210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,411.03614
Policy Entropy: 1.84292
Value Function Loss: 0.07716

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.73529

Collected Steps per Second: 22,179.93854
Overall Steps per Second: 10,555.08478

Timestep Collection Time: 2.25519
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.73895

Cumulative Model Updates: 83,854
Cumulative Timesteps: 699,355,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,771.04757
Policy Entropy: 1.83684
Value Function Loss: 0.07704

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.65761

Collected Steps per Second: 22,728.52882
Overall Steps per Second: 10,629.88324

Timestep Collection Time: 2.20199
Timestep Consumption Time: 2.50625
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.70824

Cumulative Model Updates: 83,860
Cumulative Timesteps: 699,405,278

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 699405278...
Checkpoint 699405278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,706.52230
Policy Entropy: 1.85270
Value Function Loss: 0.08556

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.55685
Value Function Update Magnitude: 0.76349

Collected Steps per Second: 21,878.88419
Overall Steps per Second: 10,459.72259

Timestep Collection Time: 2.28531
Timestep Consumption Time: 2.49493
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.78024

Cumulative Model Updates: 83,866
Cumulative Timesteps: 699,455,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,511.03178
Policy Entropy: 1.85537
Value Function Loss: 0.08765

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.80527

Collected Steps per Second: 22,467.42959
Overall Steps per Second: 10,417.52947

Timestep Collection Time: 2.22687
Timestep Consumption Time: 2.57581
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 4.80267

Cumulative Model Updates: 83,872
Cumulative Timesteps: 699,505,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 699505310...
Checkpoint 699505310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,802.19185
Policy Entropy: 1.87634
Value Function Loss: 0.08719

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.55209
Value Function Update Magnitude: 0.75913

Collected Steps per Second: 19,425.07962
Overall Steps per Second: 9,894.51109

Timestep Collection Time: 2.57533
Timestep Consumption Time: 2.48060
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 5.05593

Cumulative Model Updates: 83,878
Cumulative Timesteps: 699,555,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,874.63291
Policy Entropy: 1.89357
Value Function Loss: 0.08578

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.51460
Value Function Update Magnitude: 0.72542

Collected Steps per Second: 21,918.63207
Overall Steps per Second: 10,350.97163

Timestep Collection Time: 2.28262
Timestep Consumption Time: 2.55093
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.83356

Cumulative Model Updates: 83,884
Cumulative Timesteps: 699,605,368

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 699605368...
Checkpoint 699605368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,521.36237
Policy Entropy: 1.88032
Value Function Loss: 0.08194

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.16292
Policy Update Magnitude: 0.51630
Value Function Update Magnitude: 0.67955

Collected Steps per Second: 21,896.04973
Overall Steps per Second: 10,442.87161

Timestep Collection Time: 2.28370
Timestep Consumption Time: 2.50464
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.78834

Cumulative Model Updates: 83,890
Cumulative Timesteps: 699,655,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,737.99621
Policy Entropy: 1.87304
Value Function Loss: 0.08077

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.51650
Value Function Update Magnitude: 0.67332

Collected Steps per Second: 22,833.78178
Overall Steps per Second: 10,789.29557

Timestep Collection Time: 2.19070
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.63626

Cumulative Model Updates: 83,896
Cumulative Timesteps: 699,705,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 699705394...
Checkpoint 699705394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,824.16774
Policy Entropy: 1.86286
Value Function Loss: 0.08239

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.53185
Value Function Update Magnitude: 0.57383

Collected Steps per Second: 22,058.03553
Overall Steps per Second: 10,598.09233

Timestep Collection Time: 2.26747
Timestep Consumption Time: 2.45187
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.71934

Cumulative Model Updates: 83,902
Cumulative Timesteps: 699,755,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,588.49935
Policy Entropy: 1.87565
Value Function Loss: 0.09323

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15635
Policy Update Magnitude: 0.54504
Value Function Update Magnitude: 0.47263

Collected Steps per Second: 22,524.37061
Overall Steps per Second: 10,601.01452

Timestep Collection Time: 2.22168
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.72049

Cumulative Model Updates: 83,908
Cumulative Timesteps: 699,805,452

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 699805452...
Checkpoint 699805452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,206.02169
Policy Entropy: 1.87722
Value Function Loss: 0.09511

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.16013
Policy Update Magnitude: 0.54594
Value Function Update Magnitude: 0.41285

Collected Steps per Second: 21,479.49708
Overall Steps per Second: 10,474.46109

Timestep Collection Time: 2.32901
Timestep Consumption Time: 2.44699
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.77600

Cumulative Model Updates: 83,914
Cumulative Timesteps: 699,855,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,647.03360
Policy Entropy: 1.85525
Value Function Loss: 0.09526

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.44617

Collected Steps per Second: 22,145.24842
Overall Steps per Second: 10,470.57313

Timestep Collection Time: 2.25791
Timestep Consumption Time: 2.51757
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.77548

Cumulative Model Updates: 83,920
Cumulative Timesteps: 699,905,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 699905480...
Checkpoint 699905480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,912.46630
Policy Entropy: 1.86802
Value Function Loss: 0.09094

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.51541

Collected Steps per Second: 21,397.97386
Overall Steps per Second: 10,312.39937

Timestep Collection Time: 2.33676
Timestep Consumption Time: 2.51196
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.84873

Cumulative Model Updates: 83,926
Cumulative Timesteps: 699,955,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,159.93598
Policy Entropy: 1.88110
Value Function Loss: 0.08859

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.49999
Value Function Update Magnitude: 0.60967

Collected Steps per Second: 22,296.53410
Overall Steps per Second: 10,523.20774

Timestep Collection Time: 2.24438
Timestep Consumption Time: 2.51101
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.75539

Cumulative Model Updates: 83,932
Cumulative Timesteps: 700,005,524

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 700005524...
Checkpoint 700005524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,236.06433
Policy Entropy: 1.88729
Value Function Loss: 0.08470

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.15152
Policy Update Magnitude: 0.46702
Value Function Update Magnitude: 0.65421

Collected Steps per Second: 20,007.78636
Overall Steps per Second: 10,224.94616

Timestep Collection Time: 2.50053
Timestep Consumption Time: 2.39241
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.89294

Cumulative Model Updates: 83,938
Cumulative Timesteps: 700,055,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,485.06156
Policy Entropy: 1.88228
Value Function Loss: 0.08157

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.49522
Value Function Update Magnitude: 0.65605

Collected Steps per Second: 19,635.48038
Overall Steps per Second: 9,825.90006

Timestep Collection Time: 2.54743
Timestep Consumption Time: 2.54320
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 5.09063

Cumulative Model Updates: 83,944
Cumulative Timesteps: 700,105,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 700105574...
Checkpoint 700105574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,308.22083
Policy Entropy: 1.86696
Value Function Loss: 0.07595

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.52032
Value Function Update Magnitude: 0.70584

Collected Steps per Second: 20,227.33879
Overall Steps per Second: 9,763.44264

Timestep Collection Time: 2.47289
Timestep Consumption Time: 2.65030
PPO Batch Consumption Time: 0.30326
Total Iteration Time: 5.12319

Cumulative Model Updates: 83,950
Cumulative Timesteps: 700,155,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,323.83067
Policy Entropy: 1.87990
Value Function Loss: 0.07452

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.52659
Value Function Update Magnitude: 0.68002

Collected Steps per Second: 21,969.58777
Overall Steps per Second: 10,361.69533

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.55082
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.82778

Cumulative Model Updates: 83,956
Cumulative Timesteps: 700,205,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 700205618...
Checkpoint 700205618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,907.99460
Policy Entropy: 1.87148
Value Function Loss: 0.07737

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.53298
Value Function Update Magnitude: 0.54830

Collected Steps per Second: 20,101.64405
Overall Steps per Second: 9,636.10886

Timestep Collection Time: 2.48806
Timestep Consumption Time: 2.70221
PPO Batch Consumption Time: 0.32094
Total Iteration Time: 5.19027

Cumulative Model Updates: 83,962
Cumulative Timesteps: 700,255,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,563.04286
Policy Entropy: 1.87849
Value Function Loss: 0.08243

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.51898

Collected Steps per Second: 21,578.58001
Overall Steps per Second: 10,374.93869

Timestep Collection Time: 2.31841
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.30145
Total Iteration Time: 4.82200

Cumulative Model Updates: 83,968
Cumulative Timesteps: 700,305,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 700305660...
Checkpoint 700305660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,409.41617
Policy Entropy: 1.90282
Value Function Loss: 0.08470

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.54499
Value Function Update Magnitude: 0.62287

Collected Steps per Second: 18,701.84805
Overall Steps per Second: 9,562.05260

Timestep Collection Time: 2.67385
Timestep Consumption Time: 2.55578
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 5.22963

Cumulative Model Updates: 83,974
Cumulative Timesteps: 700,355,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,250.98095
Policy Entropy: 1.90707
Value Function Loss: 0.09169

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.63997

Collected Steps per Second: 20,394.72619
Overall Steps per Second: 9,752.85304

Timestep Collection Time: 2.45240
Timestep Consumption Time: 2.67595
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 5.12835

Cumulative Model Updates: 83,980
Cumulative Timesteps: 700,405,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 700405682...
Checkpoint 700405682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,469.77429
Policy Entropy: 1.92081
Value Function Loss: 0.09281

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.55342
Value Function Update Magnitude: 0.57606

Collected Steps per Second: 20,183.40764
Overall Steps per Second: 9,943.03223

Timestep Collection Time: 2.47926
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 5.03267

Cumulative Model Updates: 83,986
Cumulative Timesteps: 700,455,722

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,124.17162
Policy Entropy: 1.90315
Value Function Loss: 0.09764

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.61142

Collected Steps per Second: 18,820.82390
Overall Steps per Second: 9,734.44440

Timestep Collection Time: 2.65706
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 5.13722

Cumulative Model Updates: 83,992
Cumulative Timesteps: 700,505,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 700505730...
Checkpoint 700505730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,618.34123
Policy Entropy: 1.91563
Value Function Loss: 0.09799

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.53759
Value Function Update Magnitude: 0.55379

Collected Steps per Second: 14,462.28264
Overall Steps per Second: 7,683.73643

Timestep Collection Time: 3.45727
Timestep Consumption Time: 3.04998
PPO Batch Consumption Time: 0.38341
Total Iteration Time: 6.50725

Cumulative Model Updates: 83,998
Cumulative Timesteps: 700,555,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,494.83766
Policy Entropy: 1.91152
Value Function Loss: 0.09412

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.62467

Collected Steps per Second: 16,332.18937
Overall Steps per Second: 6,804.30374

Timestep Collection Time: 3.06291
Timestep Consumption Time: 4.28891
PPO Batch Consumption Time: 0.55909
Total Iteration Time: 7.35182

Cumulative Model Updates: 84,004
Cumulative Timesteps: 700,605,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 700605754...
Checkpoint 700605754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,832.76388
Policy Entropy: 1.89804
Value Function Loss: 0.08221

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.54353
Value Function Update Magnitude: 0.65856

Collected Steps per Second: 15,744.82443
Overall Steps per Second: 7,566.54901

Timestep Collection Time: 3.17704
Timestep Consumption Time: 3.43390
PPO Batch Consumption Time: 0.44297
Total Iteration Time: 6.61094

Cumulative Model Updates: 84,010
Cumulative Timesteps: 700,655,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,395.49753
Policy Entropy: 1.90490
Value Function Loss: 0.08314

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.57874

Collected Steps per Second: 16,173.46471
Overall Steps per Second: 7,677.56228

Timestep Collection Time: 3.09223
Timestep Consumption Time: 3.42182
PPO Batch Consumption Time: 0.44555
Total Iteration Time: 6.51405

Cumulative Model Updates: 84,016
Cumulative Timesteps: 700,705,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 700705788...
Checkpoint 700705788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,505.02364
Policy Entropy: 1.90459
Value Function Loss: 0.08788

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.55409
Value Function Update Magnitude: 0.50298

Collected Steps per Second: 15,285.32598
Overall Steps per Second: 7,156.24151

Timestep Collection Time: 3.27307
Timestep Consumption Time: 3.71803
PPO Batch Consumption Time: 0.49650
Total Iteration Time: 6.99110

Cumulative Model Updates: 84,022
Cumulative Timesteps: 700,755,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,173.31288
Policy Entropy: 1.92404
Value Function Loss: 0.09432

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.55617
Value Function Update Magnitude: 0.52112

Collected Steps per Second: 15,792.28956
Overall Steps per Second: 7,581.21850

Timestep Collection Time: 3.16775
Timestep Consumption Time: 3.43093
PPO Batch Consumption Time: 0.44237
Total Iteration Time: 6.59868

Cumulative Model Updates: 84,028
Cumulative Timesteps: 700,805,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 700805844...
Checkpoint 700805844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,002.76289
Policy Entropy: 1.91856
Value Function Loss: 0.09090

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.71484

Collected Steps per Second: 15,737.30706
Overall Steps per Second: 7,578.88245

Timestep Collection Time: 3.17767
Timestep Consumption Time: 3.42066
PPO Batch Consumption Time: 0.44753
Total Iteration Time: 6.59833

Cumulative Model Updates: 84,034
Cumulative Timesteps: 700,855,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,296.11712
Policy Entropy: 1.90781
Value Function Loss: 0.08257

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.80023

Collected Steps per Second: 15,137.80965
Overall Steps per Second: 6,971.52656

Timestep Collection Time: 3.30325
Timestep Consumption Time: 3.86935
PPO Batch Consumption Time: 0.51345
Total Iteration Time: 7.17260

Cumulative Model Updates: 84,040
Cumulative Timesteps: 700,905,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 700905856...
Checkpoint 700905856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,896.73653
Policy Entropy: 1.89483
Value Function Loss: 0.08188

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.55084
Value Function Update Magnitude: 0.77870

Collected Steps per Second: 14,960.35455
Overall Steps per Second: 7,047.30145

Timestep Collection Time: 3.34297
Timestep Consumption Time: 3.75365
PPO Batch Consumption Time: 0.49722
Total Iteration Time: 7.09662

Cumulative Model Updates: 84,046
Cumulative Timesteps: 700,955,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,538.55230
Policy Entropy: 1.89483
Value Function Loss: 0.08272

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.79913

Collected Steps per Second: 15,868.75217
Overall Steps per Second: 7,276.27403

Timestep Collection Time: 3.15248
Timestep Consumption Time: 3.72274
PPO Batch Consumption Time: 0.49474
Total Iteration Time: 6.87522

Cumulative Model Updates: 84,052
Cumulative Timesteps: 701,005,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 701005894...
Checkpoint 701005894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,501.85112
Policy Entropy: 1.91837
Value Function Loss: 0.08680

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.76267

Collected Steps per Second: 14,870.67016
Overall Steps per Second: 7,002.03272

Timestep Collection Time: 3.36515
Timestep Consumption Time: 3.78163
PPO Batch Consumption Time: 0.50184
Total Iteration Time: 7.14678

Cumulative Model Updates: 84,058
Cumulative Timesteps: 701,055,936

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,157.46028
Policy Entropy: 1.90954
Value Function Loss: 0.08711

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.54504
Value Function Update Magnitude: 0.64019

Collected Steps per Second: 15,272.01179
Overall Steps per Second: 7,096.41758

Timestep Collection Time: 3.27396
Timestep Consumption Time: 3.77185
PPO Batch Consumption Time: 0.49804
Total Iteration Time: 7.04581

Cumulative Model Updates: 84,064
Cumulative Timesteps: 701,105,936

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 701105936...
Checkpoint 701105936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,889.31525
Policy Entropy: 1.91767
Value Function Loss: 0.09611

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.53486
Value Function Update Magnitude: 0.52224

Collected Steps per Second: 14,066.88425
Overall Steps per Second: 6,840.15270

Timestep Collection Time: 3.55502
Timestep Consumption Time: 3.75593
PPO Batch Consumption Time: 0.49647
Total Iteration Time: 7.31095

Cumulative Model Updates: 84,070
Cumulative Timesteps: 701,155,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,378.83426
Policy Entropy: 1.90825
Value Function Loss: 0.09571

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.16226
Policy Update Magnitude: 0.50320
Value Function Update Magnitude: 0.48948

Collected Steps per Second: 15,686.62748
Overall Steps per Second: 7,511.81888

Timestep Collection Time: 3.19087
Timestep Consumption Time: 3.47250
PPO Batch Consumption Time: 0.44994
Total Iteration Time: 6.66337

Cumulative Model Updates: 84,076
Cumulative Timesteps: 701,205,998

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 701205998...
Checkpoint 701205998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,905.83961
Policy Entropy: 1.90883
Value Function Loss: 0.08919

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14592
Policy Update Magnitude: 0.48522
Value Function Update Magnitude: 0.49333

Collected Steps per Second: 15,658.18502
Overall Steps per Second: 7,163.51664

Timestep Collection Time: 3.19628
Timestep Consumption Time: 3.79023
PPO Batch Consumption Time: 0.50123
Total Iteration Time: 6.98651

Cumulative Model Updates: 84,082
Cumulative Timesteps: 701,256,046

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,663.68854
Policy Entropy: 1.88756
Value Function Loss: 0.07784

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.51674
Value Function Update Magnitude: 0.54956

Collected Steps per Second: 15,474.66348
Overall Steps per Second: 7,278.44394

Timestep Collection Time: 3.23277
Timestep Consumption Time: 3.64040
PPO Batch Consumption Time: 0.47664
Total Iteration Time: 6.87317

Cumulative Model Updates: 84,088
Cumulative Timesteps: 701,306,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 701306072...
Checkpoint 701306072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,112.99329
Policy Entropy: 1.87562
Value Function Loss: 0.07554

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.52265
Value Function Update Magnitude: 0.56766

Collected Steps per Second: 15,262.07836
Overall Steps per Second: 7,013.57335

Timestep Collection Time: 3.27675
Timestep Consumption Time: 3.85371
PPO Batch Consumption Time: 0.51033
Total Iteration Time: 7.13046

Cumulative Model Updates: 84,094
Cumulative Timesteps: 701,356,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,619.65920
Policy Entropy: 1.87773
Value Function Loss: 0.07127

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.52693
Value Function Update Magnitude: 0.68254

Collected Steps per Second: 15,162.99814
Overall Steps per Second: 7,042.09742

Timestep Collection Time: 3.29776
Timestep Consumption Time: 3.80296
PPO Batch Consumption Time: 0.50323
Total Iteration Time: 7.10073

Cumulative Model Updates: 84,100
Cumulative Timesteps: 701,406,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 701406086...
Checkpoint 701406086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,462.35476
Policy Entropy: 1.86579
Value Function Loss: 0.07077

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.52550
Value Function Update Magnitude: 0.74566

Collected Steps per Second: 14,752.26021
Overall Steps per Second: 7,095.40475

Timestep Collection Time: 3.39053
Timestep Consumption Time: 3.65882
PPO Batch Consumption Time: 0.48322
Total Iteration Time: 7.04935

Cumulative Model Updates: 84,106
Cumulative Timesteps: 701,456,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,172.14583
Policy Entropy: 1.86759
Value Function Loss: 0.07400

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.52972
Value Function Update Magnitude: 0.73847

Collected Steps per Second: 15,065.54933
Overall Steps per Second: 7,014.50626

Timestep Collection Time: 3.31910
Timestep Consumption Time: 3.80956
PPO Batch Consumption Time: 0.50762
Total Iteration Time: 7.12866

Cumulative Model Updates: 84,112
Cumulative Timesteps: 701,506,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 701506108...
Checkpoint 701506108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,623.69745
Policy Entropy: 1.86749
Value Function Loss: 0.07652

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.53104
Value Function Update Magnitude: 0.73187

Collected Steps per Second: 15,424.00235
Overall Steps per Second: 7,265.04492

Timestep Collection Time: 3.24313
Timestep Consumption Time: 3.64217
PPO Batch Consumption Time: 0.47658
Total Iteration Time: 6.88530

Cumulative Model Updates: 84,118
Cumulative Timesteps: 701,556,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,117.46258
Policy Entropy: 1.87903
Value Function Loss: 0.07493

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.73656

Collected Steps per Second: 16,908.26769
Overall Steps per Second: 7,947.82418

Timestep Collection Time: 2.95725
Timestep Consumption Time: 3.33403
PPO Batch Consumption Time: 0.42665
Total Iteration Time: 6.29128

Cumulative Model Updates: 84,124
Cumulative Timesteps: 701,606,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 701606132...
Checkpoint 701606132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,426.91754
Policy Entropy: 1.89889
Value Function Loss: 0.07270

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.51785
Value Function Update Magnitude: 0.75126

Collected Steps per Second: 15,825.22352
Overall Steps per Second: 7,658.72276

Timestep Collection Time: 3.16040
Timestep Consumption Time: 3.36993
PPO Batch Consumption Time: 0.43392
Total Iteration Time: 6.53033

Cumulative Model Updates: 84,130
Cumulative Timesteps: 701,656,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,148.64907
Policy Entropy: 1.88627
Value Function Loss: 0.07706

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.52998
Value Function Update Magnitude: 0.74390

Collected Steps per Second: 16,001.41524
Overall Steps per Second: 7,563.14946

Timestep Collection Time: 3.12597
Timestep Consumption Time: 3.48767
PPO Batch Consumption Time: 0.45130
Total Iteration Time: 6.61365

Cumulative Model Updates: 84,136
Cumulative Timesteps: 701,706,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 701706166...
Checkpoint 701706166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,035.51105
Policy Entropy: 1.89869
Value Function Loss: 0.08022

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.54922
Value Function Update Magnitude: 0.72080

Collected Steps per Second: 16,021.64456
Overall Steps per Second: 7,202.93664

Timestep Collection Time: 3.12215
Timestep Consumption Time: 3.82252
PPO Batch Consumption Time: 0.50808
Total Iteration Time: 6.94467

Cumulative Model Updates: 84,142
Cumulative Timesteps: 701,756,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,110.64093
Policy Entropy: 1.88074
Value Function Loss: 0.08254

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.81123

Collected Steps per Second: 14,983.41015
Overall Steps per Second: 7,142.45309

Timestep Collection Time: 3.33876
Timestep Consumption Time: 3.66528
PPO Batch Consumption Time: 0.49492
Total Iteration Time: 7.00404

Cumulative Model Updates: 84,148
Cumulative Timesteps: 701,806,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 701806214...
Checkpoint 701806214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,858.27485
Policy Entropy: 1.89188
Value Function Loss: 0.07881

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.80916

Collected Steps per Second: 15,238.46202
Overall Steps per Second: 7,454.80519

Timestep Collection Time: 3.28419
Timestep Consumption Time: 3.42906
PPO Batch Consumption Time: 0.45836
Total Iteration Time: 6.71325

Cumulative Model Updates: 84,154
Cumulative Timesteps: 701,856,260

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,335.35140
Policy Entropy: 1.89734
Value Function Loss: 0.07587

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.53082
Value Function Update Magnitude: 0.80352

Collected Steps per Second: 15,703.43763
Overall Steps per Second: 7,639.00995

Timestep Collection Time: 3.18567
Timestep Consumption Time: 3.36308
PPO Batch Consumption Time: 0.44742
Total Iteration Time: 6.54875

Cumulative Model Updates: 84,160
Cumulative Timesteps: 701,906,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 701906286...
Checkpoint 701906286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,973.32088
Policy Entropy: 1.90384
Value Function Loss: 0.07588

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.51304
Value Function Update Magnitude: 0.76615

Collected Steps per Second: 15,054.93250
Overall Steps per Second: 7,101.37672

Timestep Collection Time: 3.32130
Timestep Consumption Time: 3.71987
PPO Batch Consumption Time: 0.50573
Total Iteration Time: 7.04117

Cumulative Model Updates: 84,166
Cumulative Timesteps: 701,956,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,461.02930
Policy Entropy: 1.89048
Value Function Loss: 0.08098

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.49176
Value Function Update Magnitude: 0.62821

Collected Steps per Second: 15,209.55663
Overall Steps per Second: 7,126.08175

Timestep Collection Time: 3.28767
Timestep Consumption Time: 3.72937
PPO Batch Consumption Time: 0.50577
Total Iteration Time: 7.01704

Cumulative Model Updates: 84,172
Cumulative Timesteps: 702,006,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 702006292...
Checkpoint 702006292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,738.29341
Policy Entropy: 1.88136
Value Function Loss: 0.09234

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.52615
Value Function Update Magnitude: 0.54054

Collected Steps per Second: 15,160.60173
Overall Steps per Second: 7,447.72387

Timestep Collection Time: 3.29974
Timestep Consumption Time: 3.41721
PPO Batch Consumption Time: 0.45656
Total Iteration Time: 6.71695

Cumulative Model Updates: 84,178
Cumulative Timesteps: 702,056,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,678.84384
Policy Entropy: 1.88592
Value Function Loss: 0.09266

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.56851
Value Function Update Magnitude: 0.67122

Collected Steps per Second: 15,431.37928
Overall Steps per Second: 7,486.04311

Timestep Collection Time: 3.24093
Timestep Consumption Time: 3.43977
PPO Batch Consumption Time: 0.45923
Total Iteration Time: 6.68070

Cumulative Model Updates: 84,184
Cumulative Timesteps: 702,106,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 702106330...
Checkpoint 702106330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,438.08004
Policy Entropy: 1.88921
Value Function Loss: 0.08622

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.82563

Collected Steps per Second: 13,541.37291
Overall Steps per Second: 6,597.12979

Timestep Collection Time: 3.69534
Timestep Consumption Time: 3.88978
PPO Batch Consumption Time: 0.51922
Total Iteration Time: 7.58512

Cumulative Model Updates: 84,190
Cumulative Timesteps: 702,156,370

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,475.17624
Policy Entropy: 1.89611
Value Function Loss: 0.08258

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.82846

Collected Steps per Second: 14,427.54005
Overall Steps per Second: 6,767.79427

Timestep Collection Time: 3.46698
Timestep Consumption Time: 3.92391
PPO Batch Consumption Time: 0.52597
Total Iteration Time: 7.39089

Cumulative Model Updates: 84,196
Cumulative Timesteps: 702,206,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 702206390...
Checkpoint 702206390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,015.64459
Policy Entropy: 1.89716
Value Function Loss: 0.07608

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.53333
Value Function Update Magnitude: 0.76983

Collected Steps per Second: 14,940.14441
Overall Steps per Second: 7,218.17171

Timestep Collection Time: 3.34696
Timestep Consumption Time: 3.58056
PPO Batch Consumption Time: 0.47107
Total Iteration Time: 6.92752

Cumulative Model Updates: 84,202
Cumulative Timesteps: 702,256,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,913.62029
Policy Entropy: 1.91221
Value Function Loss: 0.07857

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.66789

Collected Steps per Second: 16,142.06775
Overall Steps per Second: 7,405.56418

Timestep Collection Time: 3.09886
Timestep Consumption Time: 3.65579
PPO Batch Consumption Time: 0.47915
Total Iteration Time: 6.75465

Cumulative Model Updates: 84,208
Cumulative Timesteps: 702,306,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 702306416...
Checkpoint 702306416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,881.95144
Policy Entropy: 1.91482
Value Function Loss: 0.07373

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.52562
Value Function Update Magnitude: 0.71745

Collected Steps per Second: 15,609.35071
Overall Steps per Second: 7,483.82701

Timestep Collection Time: 3.20462
Timestep Consumption Time: 3.47940
PPO Batch Consumption Time: 0.45567
Total Iteration Time: 6.68401

Cumulative Model Updates: 84,214
Cumulative Timesteps: 702,356,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,577.59691
Policy Entropy: 1.91555
Value Function Loss: 0.07318

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.47643
Value Function Update Magnitude: 0.73422

Collected Steps per Second: 16,124.71776
Overall Steps per Second: 7,622.00756

Timestep Collection Time: 3.10170
Timestep Consumption Time: 3.46009
PPO Batch Consumption Time: 0.45056
Total Iteration Time: 6.56179

Cumulative Model Updates: 84,220
Cumulative Timesteps: 702,406,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 702406452...
Checkpoint 702406452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,098.06780
Policy Entropy: 1.90043
Value Function Loss: 0.07361

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.51928
Value Function Update Magnitude: 0.68258

Collected Steps per Second: 16,033.91890
Overall Steps per Second: 7,593.59235

Timestep Collection Time: 3.11864
Timestep Consumption Time: 3.46639
PPO Batch Consumption Time: 0.44811
Total Iteration Time: 6.58503

Cumulative Model Updates: 84,226
Cumulative Timesteps: 702,456,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,212.30001
Policy Entropy: 1.90126
Value Function Loss: 0.07530

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.53847
Value Function Update Magnitude: 0.71843

Collected Steps per Second: 16,189.09002
Overall Steps per Second: 7,648.13805

Timestep Collection Time: 3.08875
Timestep Consumption Time: 3.44932
PPO Batch Consumption Time: 0.45175
Total Iteration Time: 6.53806

Cumulative Model Updates: 84,232
Cumulative Timesteps: 702,506,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 702506460...
Checkpoint 702506460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,073.97826
Policy Entropy: 1.89840
Value Function Loss: 0.07447

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.53516
Value Function Update Magnitude: 0.71053

Collected Steps per Second: 15,662.87656
Overall Steps per Second: 7,120.94928

Timestep Collection Time: 3.19277
Timestep Consumption Time: 3.82989
PPO Batch Consumption Time: 0.50894
Total Iteration Time: 7.02266

Cumulative Model Updates: 84,238
Cumulative Timesteps: 702,556,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,997.78265
Policy Entropy: 1.91830
Value Function Loss: 0.07878

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.68180

Collected Steps per Second: 15,395.69781
Overall Steps per Second: 7,073.15435

Timestep Collection Time: 3.24922
Timestep Consumption Time: 3.82316
PPO Batch Consumption Time: 0.51240
Total Iteration Time: 7.07237

Cumulative Model Updates: 84,244
Cumulative Timesteps: 702,606,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 702606492...
Checkpoint 702606492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,801.75354
Policy Entropy: 1.92461
Value Function Loss: 0.08082

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14784
Policy Update Magnitude: 0.47674
Value Function Update Magnitude: 0.67602

Collected Steps per Second: 15,210.18380
Overall Steps per Second: 6,995.59308

Timestep Collection Time: 3.28806
Timestep Consumption Time: 3.86101
PPO Batch Consumption Time: 0.51270
Total Iteration Time: 7.14907

Cumulative Model Updates: 84,250
Cumulative Timesteps: 702,656,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,020.99677
Policy Entropy: 1.91100
Value Function Loss: 0.08365

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.47839
Value Function Update Magnitude: 0.56783

Collected Steps per Second: 15,267.81323
Overall Steps per Second: 7,023.03217

Timestep Collection Time: 3.27775
Timestep Consumption Time: 3.84795
PPO Batch Consumption Time: 0.51030
Total Iteration Time: 7.12570

Cumulative Model Updates: 84,256
Cumulative Timesteps: 702,706,548

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 702706548...
Checkpoint 702706548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,012.50323
Policy Entropy: 1.89774
Value Function Loss: 0.08690

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.51398
Value Function Update Magnitude: 0.49806

Collected Steps per Second: 15,074.78250
Overall Steps per Second: 6,978.84677

Timestep Collection Time: 3.31746
Timestep Consumption Time: 3.84848
PPO Batch Consumption Time: 0.51196
Total Iteration Time: 7.16594

Cumulative Model Updates: 84,262
Cumulative Timesteps: 702,756,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,059.14546
Policy Entropy: 1.88733
Value Function Loss: 0.09530

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.55696
Value Function Update Magnitude: 0.52379

Collected Steps per Second: 15,357.20488
Overall Steps per Second: 7,017.11156

Timestep Collection Time: 3.25619
Timestep Consumption Time: 3.87010
PPO Batch Consumption Time: 0.51317
Total Iteration Time: 7.12629

Cumulative Model Updates: 84,268
Cumulative Timesteps: 702,806,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 702806564...
Checkpoint 702806564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,369.47802
Policy Entropy: 1.89052
Value Function Loss: 0.08888

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.57242
Value Function Update Magnitude: 0.59420

Collected Steps per Second: 15,237.73690
Overall Steps per Second: 7,065.10753

Timestep Collection Time: 3.28290
Timestep Consumption Time: 3.79753
PPO Batch Consumption Time: 0.50300
Total Iteration Time: 7.08043

Cumulative Model Updates: 84,274
Cumulative Timesteps: 702,856,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,721.09477
Policy Entropy: 1.89738
Value Function Loss: 0.08076

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.57117

Collected Steps per Second: 15,342.53681
Overall Steps per Second: 7,369.30500

Timestep Collection Time: 3.26035
Timestep Consumption Time: 3.52754
PPO Batch Consumption Time: 0.45921
Total Iteration Time: 6.78789

Cumulative Model Updates: 84,280
Cumulative Timesteps: 702,906,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 702906610...
Checkpoint 702906610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,939.13253
Policy Entropy: 1.90460
Value Function Loss: 0.07667

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.56561

Collected Steps per Second: 15,808.49584
Overall Steps per Second: 7,512.98321

Timestep Collection Time: 3.16324
Timestep Consumption Time: 3.49271
PPO Batch Consumption Time: 0.46049
Total Iteration Time: 6.65594

Cumulative Model Updates: 84,286
Cumulative Timesteps: 702,956,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,797.11256
Policy Entropy: 1.90836
Value Function Loss: 0.07586

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.53732
Value Function Update Magnitude: 0.67600

Collected Steps per Second: 15,822.34892
Overall Steps per Second: 7,388.42629

Timestep Collection Time: 3.16173
Timestep Consumption Time: 3.60913
PPO Batch Consumption Time: 0.47378
Total Iteration Time: 6.77086

Cumulative Model Updates: 84,292
Cumulative Timesteps: 703,006,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 703006642...
Checkpoint 703006642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,163.07795
Policy Entropy: 1.90174
Value Function Loss: 0.07818

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.59649

Collected Steps per Second: 15,686.80798
Overall Steps per Second: 7,677.08168

Timestep Collection Time: 3.18739
Timestep Consumption Time: 3.32550
PPO Batch Consumption Time: 0.42555
Total Iteration Time: 6.51289

Cumulative Model Updates: 84,298
Cumulative Timesteps: 703,056,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,994.50477
Policy Entropy: 1.90009
Value Function Loss: 0.08486

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.64119

Collected Steps per Second: 19,582.72958
Overall Steps per Second: 9,705.87430

Timestep Collection Time: 2.55490
Timestep Consumption Time: 2.59991
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 5.15482

Cumulative Model Updates: 84,304
Cumulative Timesteps: 703,106,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 703106674...
Checkpoint 703106674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,456.67943
Policy Entropy: 1.90043
Value Function Loss: 0.08491

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.55171
Value Function Update Magnitude: 0.60363

Collected Steps per Second: 20,016.37172
Overall Steps per Second: 9,773.55832

Timestep Collection Time: 2.49845
Timestep Consumption Time: 2.61841
PPO Batch Consumption Time: 0.29781
Total Iteration Time: 5.11687

Cumulative Model Updates: 84,310
Cumulative Timesteps: 703,156,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,682.62698
Policy Entropy: 1.90362
Value Function Loss: 0.08023

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.54471
Value Function Update Magnitude: 0.63747

Collected Steps per Second: 21,981.33503
Overall Steps per Second: 10,560.00253

Timestep Collection Time: 2.27538
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.73636

Cumulative Model Updates: 84,316
Cumulative Timesteps: 703,206,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 703206700...
Checkpoint 703206700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,819.39597
Policy Entropy: 1.89493
Value Function Loss: 0.07279

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.54064
Value Function Update Magnitude: 0.59530

Collected Steps per Second: 21,471.66876
Overall Steps per Second: 10,308.89226

Timestep Collection Time: 2.32940
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.85173

Cumulative Model Updates: 84,322
Cumulative Timesteps: 703,256,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,269.41215
Policy Entropy: 1.90230
Value Function Loss: 0.07699

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.48942

Collected Steps per Second: 22,511.05466
Overall Steps per Second: 10,554.32212

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.51818
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.74100

Cumulative Model Updates: 84,328
Cumulative Timesteps: 703,306,754

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 703306754...
Checkpoint 703306754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,935.92971
Policy Entropy: 1.90365
Value Function Loss: 0.08287

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.46075

Collected Steps per Second: 22,165.56822
Overall Steps per Second: 10,463.26313

Timestep Collection Time: 2.25701
Timestep Consumption Time: 2.52429
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.78130

Cumulative Model Updates: 84,334
Cumulative Timesteps: 703,356,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,104.99822
Policy Entropy: 1.89811
Value Function Loss: 0.08820

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.54102
Value Function Update Magnitude: 0.53010

Collected Steps per Second: 22,623.69555
Overall Steps per Second: 10,580.37922

Timestep Collection Time: 2.21087
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.72743

Cumulative Model Updates: 84,340
Cumulative Timesteps: 703,406,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 703406800...
Checkpoint 703406800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,814.87057
Policy Entropy: 1.89179
Value Function Loss: 0.08850

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.55285

Collected Steps per Second: 21,726.78601
Overall Steps per Second: 10,550.91688

Timestep Collection Time: 2.30204
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.74044

Cumulative Model Updates: 84,346
Cumulative Timesteps: 703,456,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,387.65352
Policy Entropy: 1.88047
Value Function Loss: 0.09195

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.61972

Collected Steps per Second: 22,675.88607
Overall Steps per Second: 10,786.47423

Timestep Collection Time: 2.20507
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.63562

Cumulative Model Updates: 84,352
Cumulative Timesteps: 703,506,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 703506818...
Checkpoint 703506818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,780.12973
Policy Entropy: 1.89531
Value Function Loss: 0.08808

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.64165

Collected Steps per Second: 21,983.97869
Overall Steps per Second: 10,430.85866

Timestep Collection Time: 2.27502
Timestep Consumption Time: 2.51979
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.79481

Cumulative Model Updates: 84,358
Cumulative Timesteps: 703,556,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,403.17702
Policy Entropy: 1.89830
Value Function Loss: 0.08969

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.57446
Value Function Update Magnitude: 0.53465

Collected Steps per Second: 21,754.39641
Overall Steps per Second: 10,704.82126

Timestep Collection Time: 2.29866
Timestep Consumption Time: 2.37269
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.67135

Cumulative Model Updates: 84,364
Cumulative Timesteps: 703,606,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 703606838...
Checkpoint 703606838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,857.56090
Policy Entropy: 1.89119
Value Function Loss: 0.07923

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.49612

Collected Steps per Second: 21,048.72952
Overall Steps per Second: 10,379.22856

Timestep Collection Time: 2.37554
Timestep Consumption Time: 2.44197
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.81751

Cumulative Model Updates: 84,370
Cumulative Timesteps: 703,656,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,882.41783
Policy Entropy: 1.88521
Value Function Loss: 0.08306

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.59277

Collected Steps per Second: 21,868.58897
Overall Steps per Second: 10,714.44672

Timestep Collection Time: 2.28776
Timestep Consumption Time: 2.38164
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.66940

Cumulative Model Updates: 84,376
Cumulative Timesteps: 703,706,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 703706870...
Checkpoint 703706870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,863.39728
Policy Entropy: 1.89912
Value Function Loss: 0.08346

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.55955
Value Function Update Magnitude: 0.64781

Collected Steps per Second: 21,150.03629
Overall Steps per Second: 10,424.50189

Timestep Collection Time: 2.36416
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.79658

Cumulative Model Updates: 84,382
Cumulative Timesteps: 703,756,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,436.23072
Policy Entropy: 1.90465
Value Function Loss: 0.08704

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.54977
Value Function Update Magnitude: 0.55143

Collected Steps per Second: 21,751.72898
Overall Steps per Second: 10,678.67314

Timestep Collection Time: 2.29996
Timestep Consumption Time: 2.38490
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.68485

Cumulative Model Updates: 84,388
Cumulative Timesteps: 703,806,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 703806900...
Checkpoint 703806900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,765.71894
Policy Entropy: 1.90734
Value Function Loss: 0.08265

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.55057
Value Function Update Magnitude: 0.57430

Collected Steps per Second: 21,258.65154
Overall Steps per Second: 10,610.29312

Timestep Collection Time: 2.35339
Timestep Consumption Time: 2.36184
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.71523

Cumulative Model Updates: 84,394
Cumulative Timesteps: 703,856,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,575.28728
Policy Entropy: 1.87997
Value Function Loss: 0.07729

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.61243

Collected Steps per Second: 21,629.01144
Overall Steps per Second: 10,534.03950

Timestep Collection Time: 2.31319
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.74956

Cumulative Model Updates: 84,400
Cumulative Timesteps: 703,906,962

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 703906962...
Checkpoint 703906962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,179.83464
Policy Entropy: 1.89080
Value Function Loss: 0.07191

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.54489
Value Function Update Magnitude: 0.58563

Collected Steps per Second: 20,617.16505
Overall Steps per Second: 10,246.54326

Timestep Collection Time: 2.42536
Timestep Consumption Time: 2.45473
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.88008

Cumulative Model Updates: 84,406
Cumulative Timesteps: 703,956,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,349.74355
Policy Entropy: 1.89209
Value Function Loss: 0.07379

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.58285

Collected Steps per Second: 22,198.47942
Overall Steps per Second: 10,462.37852

Timestep Collection Time: 2.25313
Timestep Consumption Time: 2.52743
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.78056

Cumulative Model Updates: 84,412
Cumulative Timesteps: 704,006,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 704006982...
Checkpoint 704006982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,247.71351
Policy Entropy: 1.90640
Value Function Loss: 0.08096

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.55638

Collected Steps per Second: 21,701.26763
Overall Steps per Second: 10,561.32679

Timestep Collection Time: 2.30512
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.73653

Cumulative Model Updates: 84,418
Cumulative Timesteps: 704,057,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,688.73309
Policy Entropy: 1.89479
Value Function Loss: 0.07922

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.55460
Value Function Update Magnitude: 0.60694

Collected Steps per Second: 22,129.51749
Overall Steps per Second: 10,496.00154

Timestep Collection Time: 2.26051
Timestep Consumption Time: 2.50550
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.76601

Cumulative Model Updates: 84,424
Cumulative Timesteps: 704,107,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 704107030...
Checkpoint 704107030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,179.51464
Policy Entropy: 1.90006
Value Function Loss: 0.07833

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.54320
Value Function Update Magnitude: 0.54184

Collected Steps per Second: 21,753.88146
Overall Steps per Second: 10,413.74171

Timestep Collection Time: 2.29844
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.80135

Cumulative Model Updates: 84,430
Cumulative Timesteps: 704,157,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,023.06822
Policy Entropy: 1.89355
Value Function Loss: 0.08436

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 22,632.14395
Overall Steps per Second: 10,665.38796

Timestep Collection Time: 2.21004
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.68975

Cumulative Model Updates: 84,436
Cumulative Timesteps: 704,207,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 704207048...
Checkpoint 704207048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,317.96105
Policy Entropy: 1.89383
Value Function Loss: 0.08299

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.52070
Value Function Update Magnitude: 0.72719

Collected Steps per Second: 21,484.95121
Overall Steps per Second: 10,312.98769

Timestep Collection Time: 2.32730
Timestep Consumption Time: 2.52115
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.84845

Cumulative Model Updates: 84,442
Cumulative Timesteps: 704,257,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,224.50491
Policy Entropy: 1.89340
Value Function Loss: 0.07913

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.50386
Value Function Update Magnitude: 0.70459

Collected Steps per Second: 22,354.23431
Overall Steps per Second: 10,525.17855

Timestep Collection Time: 2.23788
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.75298

Cumulative Model Updates: 84,448
Cumulative Timesteps: 704,307,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 704307076...
Checkpoint 704307076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,331.38309
Policy Entropy: 1.90185
Value Function Loss: 0.07710

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.47962
Value Function Update Magnitude: 0.68491

Collected Steps per Second: 21,892.39183
Overall Steps per Second: 10,494.21590

Timestep Collection Time: 2.28527
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.76739

Cumulative Model Updates: 84,454
Cumulative Timesteps: 704,357,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,151.58052
Policy Entropy: 1.90382
Value Function Loss: 0.07775

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.51862
Value Function Update Magnitude: 0.65436

Collected Steps per Second: 22,595.99698
Overall Steps per Second: 10,553.11545

Timestep Collection Time: 2.21499
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.74268

Cumulative Model Updates: 84,460
Cumulative Timesteps: 704,407,156

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 704407156...
Checkpoint 704407156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,718.66332
Policy Entropy: 1.90569
Value Function Loss: 0.08007

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.61234

Collected Steps per Second: 22,040.64063
Overall Steps per Second: 10,564.47749

Timestep Collection Time: 2.26963
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.73511

Cumulative Model Updates: 84,466
Cumulative Timesteps: 704,457,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,949.22560
Policy Entropy: 1.91415
Value Function Loss: 0.08180

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.53907
Value Function Update Magnitude: 0.62751

Collected Steps per Second: 22,722.47415
Overall Steps per Second: 10,640.51314

Timestep Collection Time: 2.20046
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.69902

Cumulative Model Updates: 84,472
Cumulative Timesteps: 704,507,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 704507180...
Checkpoint 704507180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,254.80092
Policy Entropy: 1.92076
Value Function Loss: 0.08381

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.57363

Collected Steps per Second: 21,838.19609
Overall Steps per Second: 10,267.80868

Timestep Collection Time: 2.28957
Timestep Consumption Time: 2.58002
PPO Batch Consumption Time: 0.30329
Total Iteration Time: 4.86959

Cumulative Model Updates: 84,478
Cumulative Timesteps: 704,557,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,802.14518
Policy Entropy: 1.92767
Value Function Loss: 0.08395

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.55600

Collected Steps per Second: 22,440.08340
Overall Steps per Second: 10,630.78476

Timestep Collection Time: 2.22914
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.70539

Cumulative Model Updates: 84,484
Cumulative Timesteps: 704,607,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 704607202...
Checkpoint 704607202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,727.94955
Policy Entropy: 1.93141
Value Function Loss: 0.08637

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.46249

Collected Steps per Second: 22,119.03504
Overall Steps per Second: 10,621.07290

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.71007

Cumulative Model Updates: 84,490
Cumulative Timesteps: 704,657,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,420.19260
Policy Entropy: 1.93615
Value Function Loss: 0.08674

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.40144

Collected Steps per Second: 22,669.69110
Overall Steps per Second: 10,691.91536

Timestep Collection Time: 2.20762
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.68073

Cumulative Model Updates: 84,496
Cumulative Timesteps: 704,707,274

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 704707274...
Checkpoint 704707274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,043.42455
Policy Entropy: 1.94905
Value Function Loss: 0.08701

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.54532
Value Function Update Magnitude: 0.34868

Collected Steps per Second: 22,012.61032
Overall Steps per Second: 10,421.40515

Timestep Collection Time: 2.27143
Timestep Consumption Time: 2.52639
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.79782

Cumulative Model Updates: 84,502
Cumulative Timesteps: 704,757,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,275.25163
Policy Entropy: 1.93520
Value Function Loss: 0.08990

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.30890

Collected Steps per Second: 22,475.28272
Overall Steps per Second: 10,515.89596

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.53095
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.75642

Cumulative Model Updates: 84,508
Cumulative Timesteps: 704,807,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 704807292...
Checkpoint 704807292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,510.04731
Policy Entropy: 1.93294
Value Function Loss: 0.08634

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.30425

Collected Steps per Second: 21,998.97119
Overall Steps per Second: 10,552.13683

Timestep Collection Time: 2.27447
Timestep Consumption Time: 2.46732
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.74179

Cumulative Model Updates: 84,514
Cumulative Timesteps: 704,857,328

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,462.73591
Policy Entropy: 1.93468
Value Function Loss: 0.07784

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.39719

Collected Steps per Second: 22,370.38076
Overall Steps per Second: 10,508.01525

Timestep Collection Time: 2.23510
Timestep Consumption Time: 2.52317
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.75827

Cumulative Model Updates: 84,520
Cumulative Timesteps: 704,907,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 704907328...
Checkpoint 704907328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,664.03611
Policy Entropy: 1.93469
Value Function Loss: 0.07794

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.44308

Collected Steps per Second: 21,847.47533
Overall Steps per Second: 10,571.74041

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.72978

Cumulative Model Updates: 84,526
Cumulative Timesteps: 704,957,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,186.71094
Policy Entropy: 1.92309
Value Function Loss: 0.07814

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.48138
Value Function Update Magnitude: 0.39040

Collected Steps per Second: 22,678.18222
Overall Steps per Second: 10,584.69352

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.51954
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.72475

Cumulative Model Updates: 84,532
Cumulative Timesteps: 705,007,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 705007340...
Checkpoint 705007340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,350.52182
Policy Entropy: 1.90480
Value Function Loss: 0.08314

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.15583
Policy Update Magnitude: 0.44053
Value Function Update Magnitude: 0.34907

Collected Steps per Second: 21,739.37988
Overall Steps per Second: 10,502.89238

Timestep Collection Time: 2.30080
Timestep Consumption Time: 2.46151
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.76231

Cumulative Model Updates: 84,538
Cumulative Timesteps: 705,057,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,586.98177
Policy Entropy: 1.90336
Value Function Loss: 0.08458

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.46778
Value Function Update Magnitude: 0.36506

Collected Steps per Second: 22,648.41443
Overall Steps per Second: 10,655.92148

Timestep Collection Time: 2.20819
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.69335

Cumulative Model Updates: 84,544
Cumulative Timesteps: 705,107,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 705107370...
Checkpoint 705107370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,890.48631
Policy Entropy: 1.90572
Value Function Loss: 0.08404

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.16111
Policy Update Magnitude: 0.49523
Value Function Update Magnitude: 0.41476

Collected Steps per Second: 22,189.77916
Overall Steps per Second: 10,503.67288

Timestep Collection Time: 2.25482
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.76348

Cumulative Model Updates: 84,550
Cumulative Timesteps: 705,157,404

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,927.41695
Policy Entropy: 1.90379
Value Function Loss: 0.07915

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.15042
Policy Update Magnitude: 0.52468
Value Function Update Magnitude: 0.46802

Collected Steps per Second: 22,136.18869
Overall Steps per Second: 10,256.18431

Timestep Collection Time: 2.25884
Timestep Consumption Time: 2.61647
PPO Batch Consumption Time: 0.30711
Total Iteration Time: 4.87530

Cumulative Model Updates: 84,556
Cumulative Timesteps: 705,207,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 705207406...
Checkpoint 705207406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,354.83205
Policy Entropy: 1.90834
Value Function Loss: 0.08287

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.42165

Collected Steps per Second: 19,364.09927
Overall Steps per Second: 9,819.31495

Timestep Collection Time: 2.58272
Timestep Consumption Time: 2.51051
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 5.09323

Cumulative Model Updates: 84,562
Cumulative Timesteps: 705,257,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,827.80482
Policy Entropy: 1.91095
Value Function Loss: 0.07667

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.52131
Value Function Update Magnitude: 0.48590

Collected Steps per Second: 19,693.36585
Overall Steps per Second: 9,753.39121

Timestep Collection Time: 2.54004
Timestep Consumption Time: 2.58863
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 5.12868

Cumulative Model Updates: 84,568
Cumulative Timesteps: 705,307,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 705307440...
Checkpoint 705307440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,018.62457
Policy Entropy: 1.91930
Value Function Loss: 0.07519

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.52181
Value Function Update Magnitude: 0.64234

Collected Steps per Second: 21,418.56430
Overall Steps per Second: 10,222.35773

Timestep Collection Time: 2.33648
Timestep Consumption Time: 2.55907
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.89554

Cumulative Model Updates: 84,574
Cumulative Timesteps: 705,357,484

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,178.69610
Policy Entropy: 1.91048
Value Function Loss: 0.07476

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.49432
Value Function Update Magnitude: 0.72022

Collected Steps per Second: 20,823.82385
Overall Steps per Second: 9,861.43670

Timestep Collection Time: 2.40177
Timestep Consumption Time: 2.66991
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 5.07167

Cumulative Model Updates: 84,580
Cumulative Timesteps: 705,407,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 705407498...
Checkpoint 705407498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,691.67110
Policy Entropy: 1.91910
Value Function Loss: 0.07742

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.16214
Policy Update Magnitude: 0.46171
Value Function Update Magnitude: 0.73488

Collected Steps per Second: 18,808.29751
Overall Steps per Second: 9,385.03455

Timestep Collection Time: 2.65851
Timestep Consumption Time: 2.66934
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 5.32784

Cumulative Model Updates: 84,586
Cumulative Timesteps: 705,457,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,158.78495
Policy Entropy: 1.92649
Value Function Loss: 0.07921

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.50805
Value Function Update Magnitude: 0.72514

Collected Steps per Second: 20,760.50670
Overall Steps per Second: 10,173.65024

Timestep Collection Time: 2.40958
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.91702

Cumulative Model Updates: 84,592
Cumulative Timesteps: 705,507,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 705507524...
Checkpoint 705507524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,616.71502
Policy Entropy: 1.93853
Value Function Loss: 0.08055

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.64828

Collected Steps per Second: 18,670.96468
Overall Steps per Second: 9,608.20252

Timestep Collection Time: 2.67838
Timestep Consumption Time: 2.52634
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 5.20472

Cumulative Model Updates: 84,598
Cumulative Timesteps: 705,557,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,086.40920
Policy Entropy: 1.95010
Value Function Loss: 0.07601

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.72641

Collected Steps per Second: 21,610.76574
Overall Steps per Second: 9,779.71008

Timestep Collection Time: 2.31375
Timestep Consumption Time: 2.79908
PPO Batch Consumption Time: 0.32084
Total Iteration Time: 5.11283

Cumulative Model Updates: 84,604
Cumulative Timesteps: 705,607,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 705607534...
Checkpoint 705607534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,598.72249
Policy Entropy: 1.95479
Value Function Loss: 0.07355

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.75942

Collected Steps per Second: 18,073.96469
Overall Steps per Second: 9,407.14388

Timestep Collection Time: 2.76840
Timestep Consumption Time: 2.55053
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 5.31894

Cumulative Model Updates: 84,610
Cumulative Timesteps: 705,657,570

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,305.65740
Policy Entropy: 1.95266
Value Function Loss: 0.07234

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.53636
Value Function Update Magnitude: 0.71838

Collected Steps per Second: 19,230.96004
Overall Steps per Second: 9,895.73130

Timestep Collection Time: 2.60029
Timestep Consumption Time: 2.45300
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 5.05329

Cumulative Model Updates: 84,616
Cumulative Timesteps: 705,707,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 705707576...
Checkpoint 705707576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,310.82337
Policy Entropy: 1.93896
Value Function Loss: 0.07548

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.53463
Value Function Update Magnitude: 0.71187

Collected Steps per Second: 19,013.64241
Overall Steps per Second: 9,599.29929

Timestep Collection Time: 2.63116
Timestep Consumption Time: 2.58047
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 5.21163

Cumulative Model Updates: 84,622
Cumulative Timesteps: 705,757,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,546.43062
Policy Entropy: 1.92973
Value Function Loss: 0.07443

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.74905

Collected Steps per Second: 20,424.26862
Overall Steps per Second: 10,093.04038

Timestep Collection Time: 2.44817
Timestep Consumption Time: 2.50594
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.95411

Cumulative Model Updates: 84,628
Cumulative Timesteps: 705,807,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 705807606...
Checkpoint 705807606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,095.61427
Policy Entropy: 1.92458
Value Function Loss: 0.06967

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.53591
Value Function Update Magnitude: 0.74977

Collected Steps per Second: 21,377.71892
Overall Steps per Second: 10,239.14992

Timestep Collection Time: 2.33926
Timestep Consumption Time: 2.54474
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.88400

Cumulative Model Updates: 84,634
Cumulative Timesteps: 705,857,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,689.13276
Policy Entropy: 1.92372
Value Function Loss: 0.07069

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.53298
Value Function Update Magnitude: 0.74803

Collected Steps per Second: 21,787.25148
Overall Steps per Second: 10,540.80033

Timestep Collection Time: 2.29602
Timestep Consumption Time: 2.44973
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.74575

Cumulative Model Updates: 84,640
Cumulative Timesteps: 705,907,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 705907638...
Checkpoint 705907638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,932.31092
Policy Entropy: 1.92440
Value Function Loss: 0.07507

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.73327

Collected Steps per Second: 21,697.67002
Overall Steps per Second: 10,107.46701

Timestep Collection Time: 2.30513
Timestep Consumption Time: 2.64329
PPO Batch Consumption Time: 0.30817
Total Iteration Time: 4.94842

Cumulative Model Updates: 84,646
Cumulative Timesteps: 705,957,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,723.83552
Policy Entropy: 1.92493
Value Function Loss: 0.06875

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.53892
Value Function Update Magnitude: 0.72983

Collected Steps per Second: 20,062.19747
Overall Steps per Second: 9,813.67327

Timestep Collection Time: 2.49245
Timestep Consumption Time: 2.60289
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 5.09534

Cumulative Model Updates: 84,652
Cumulative Timesteps: 706,007,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 706007658...
Checkpoint 706007658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,225.89240
Policy Entropy: 1.93071
Value Function Loss: 0.06934

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.53025
Value Function Update Magnitude: 0.72028

Collected Steps per Second: 21,455.00203
Overall Steps per Second: 10,264.25638

Timestep Collection Time: 2.33158
Timestep Consumption Time: 2.54203
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.87361

Cumulative Model Updates: 84,658
Cumulative Timesteps: 706,057,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,454.57703
Policy Entropy: 1.93545
Value Function Loss: 0.07322

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.53659
Value Function Update Magnitude: 0.70356

Collected Steps per Second: 20,036.75675
Overall Steps per Second: 9,979.26280

Timestep Collection Time: 2.49641
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 5.01239

Cumulative Model Updates: 84,664
Cumulative Timesteps: 706,107,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 706107702...
Checkpoint 706107702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,221.64687
Policy Entropy: 1.93208
Value Function Loss: 0.07368

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.70037

Collected Steps per Second: 21,291.95605
Overall Steps per Second: 10,237.15719

Timestep Collection Time: 2.34924
Timestep Consumption Time: 2.53688
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.88612

Cumulative Model Updates: 84,670
Cumulative Timesteps: 706,157,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,607.83772
Policy Entropy: 1.93491
Value Function Loss: 0.07664

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.53260
Value Function Update Magnitude: 0.69820

Collected Steps per Second: 21,837.21136
Overall Steps per Second: 10,423.00519

Timestep Collection Time: 2.29068
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.79919

Cumulative Model Updates: 84,676
Cumulative Timesteps: 706,207,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 706207744...
Checkpoint 706207744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,743.28607
Policy Entropy: 1.93681
Value Function Loss: 0.07305

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.53319
Value Function Update Magnitude: 0.69776

Collected Steps per Second: 20,714.27814
Overall Steps per Second: 10,244.54782

Timestep Collection Time: 2.41457
Timestep Consumption Time: 2.46764
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.88221

Cumulative Model Updates: 84,682
Cumulative Timesteps: 706,257,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,023.92097
Policy Entropy: 1.92181
Value Function Loss: 0.07544

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.63162

Collected Steps per Second: 21,719.01398
Overall Steps per Second: 10,524.23883

Timestep Collection Time: 2.30333
Timestep Consumption Time: 2.45008
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.75341

Cumulative Model Updates: 84,688
Cumulative Timesteps: 706,307,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 706307786...
Checkpoint 706307786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,266.59704
Policy Entropy: 1.92409
Value Function Loss: 0.07726

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.53811
Value Function Update Magnitude: 0.68255

Collected Steps per Second: 20,761.13887
Overall Steps per Second: 9,993.37829

Timestep Collection Time: 2.41027
Timestep Consumption Time: 2.59704
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 5.00732

Cumulative Model Updates: 84,694
Cumulative Timesteps: 706,357,826

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,041.61610
Policy Entropy: 1.91257
Value Function Loss: 0.07478

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.71364

Collected Steps per Second: 20,743.55404
Overall Steps per Second: 10,211.89769

Timestep Collection Time: 2.41077
Timestep Consumption Time: 2.48626
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.89703

Cumulative Model Updates: 84,700
Cumulative Timesteps: 706,407,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 706407834...
Checkpoint 706407834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,383.22998
Policy Entropy: 1.92184
Value Function Loss: 0.07365

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.71791

Collected Steps per Second: 21,109.02032
Overall Steps per Second: 9,983.17111

Timestep Collection Time: 2.36960
Timestep Consumption Time: 2.64083
PPO Batch Consumption Time: 0.30853
Total Iteration Time: 5.01043

Cumulative Model Updates: 84,706
Cumulative Timesteps: 706,457,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,380.67449
Policy Entropy: 1.92249
Value Function Loss: 0.06863

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.53016
Value Function Update Magnitude: 0.71663

Collected Steps per Second: 20,768.45355
Overall Steps per Second: 10,065.01436

Timestep Collection Time: 2.40750
Timestep Consumption Time: 2.56021
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.96770

Cumulative Model Updates: 84,712
Cumulative Timesteps: 706,507,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 706507854...
Checkpoint 706507854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,367.58540
Policy Entropy: 1.93286
Value Function Loss: 0.07688

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.71381

Collected Steps per Second: 18,782.05651
Overall Steps per Second: 9,613.51447

Timestep Collection Time: 2.66350
Timestep Consumption Time: 2.54022
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 5.20372

Cumulative Model Updates: 84,718
Cumulative Timesteps: 706,557,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,419.04858
Policy Entropy: 1.93088
Value Function Loss: 0.08226

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.61539

Collected Steps per Second: 19,353.69670
Overall Steps per Second: 9,599.24974

Timestep Collection Time: 2.58514
Timestep Consumption Time: 2.62693
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 5.21207

Cumulative Model Updates: 84,724
Cumulative Timesteps: 706,607,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 706607912...
Checkpoint 706607912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,207.54003
Policy Entropy: 1.93950
Value Function Loss: 0.08625

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.59255

Collected Steps per Second: 20,595.25557
Overall Steps per Second: 10,046.30052

Timestep Collection Time: 2.42969
Timestep Consumption Time: 2.55125
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.98094

Cumulative Model Updates: 84,730
Cumulative Timesteps: 706,657,952

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,724.59752
Policy Entropy: 1.94439
Value Function Loss: 0.08975

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.54188

Collected Steps per Second: 22,027.55082
Overall Steps per Second: 10,240.94446

Timestep Collection Time: 2.27134
Timestep Consumption Time: 2.61415
PPO Batch Consumption Time: 0.30160
Total Iteration Time: 4.88549

Cumulative Model Updates: 84,736
Cumulative Timesteps: 706,707,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 706707984...
Checkpoint 706707984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,855.31036
Policy Entropy: 1.95637
Value Function Loss: 0.09027

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.54728

Collected Steps per Second: 19,807.14797
Overall Steps per Second: 9,782.73524

Timestep Collection Time: 2.52555
Timestep Consumption Time: 2.58795
PPO Batch Consumption Time: 0.30489
Total Iteration Time: 5.11350

Cumulative Model Updates: 84,742
Cumulative Timesteps: 706,758,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,342.37787
Policy Entropy: 1.94405
Value Function Loss: 0.08659

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.53048

Collected Steps per Second: 18,980.76243
Overall Steps per Second: 9,597.86772

Timestep Collection Time: 2.63541
Timestep Consumption Time: 2.57638
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 5.21178

Cumulative Model Updates: 84,748
Cumulative Timesteps: 706,808,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 706808030...
Checkpoint 706808030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,083.14804
Policy Entropy: 1.94762
Value Function Loss: 0.09082

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.15585
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.53496

Collected Steps per Second: 19,540.65936
Overall Steps per Second: 9,748.05122

Timestep Collection Time: 2.56020
Timestep Consumption Time: 2.57190
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 5.13210

Cumulative Model Updates: 84,754
Cumulative Timesteps: 706,858,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,318.06363
Policy Entropy: 1.94291
Value Function Loss: 0.08291

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.17237
Policy Update Magnitude: 0.50761
Value Function Update Magnitude: 0.60177

Collected Steps per Second: 20,429.76273
Overall Steps per Second: 10,069.32987

Timestep Collection Time: 2.44809
Timestep Consumption Time: 2.51887
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.96696

Cumulative Model Updates: 84,760
Cumulative Timesteps: 706,908,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 706908072...
Checkpoint 706908072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,799.46209
Policy Entropy: 1.95492
Value Function Loss: 0.07763

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.52611
Value Function Update Magnitude: 0.58293

Collected Steps per Second: 20,057.19799
Overall Steps per Second: 9,896.94104

Timestep Collection Time: 2.49327
Timestep Consumption Time: 2.55960
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 5.05287

Cumulative Model Updates: 84,766
Cumulative Timesteps: 706,958,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,666.07628
Policy Entropy: 1.95407
Value Function Loss: 0.07647

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.49693

Collected Steps per Second: 20,100.11644
Overall Steps per Second: 9,872.95776

Timestep Collection Time: 2.48864
Timestep Consumption Time: 2.57792
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 5.06657

Cumulative Model Updates: 84,772
Cumulative Timesteps: 707,008,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 707008102...
Checkpoint 707008102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,576.63874
Policy Entropy: 1.96194
Value Function Loss: 0.07443

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.16176
Policy Update Magnitude: 0.51120
Value Function Update Magnitude: 0.44472

Collected Steps per Second: 19,325.23288
Overall Steps per Second: 9,431.12039

Timestep Collection Time: 2.59029
Timestep Consumption Time: 2.71745
PPO Batch Consumption Time: 0.31322
Total Iteration Time: 5.30775

Cumulative Model Updates: 84,778
Cumulative Timesteps: 707,058,160

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,681.61423
Policy Entropy: 1.95883
Value Function Loss: 0.07485

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.15692
Policy Update Magnitude: 0.48246
Value Function Update Magnitude: 0.51731

Collected Steps per Second: 20,540.73944
Overall Steps per Second: 9,877.75518

Timestep Collection Time: 2.43555
Timestep Consumption Time: 2.62916
PPO Batch Consumption Time: 0.30702
Total Iteration Time: 5.06471

Cumulative Model Updates: 84,784
Cumulative Timesteps: 707,108,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 707108188...
Checkpoint 707108188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,283.98222
Policy Entropy: 1.95276
Value Function Loss: 0.06944

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.50179
Value Function Update Magnitude: 0.58754

Collected Steps per Second: 20,396.60047
Overall Steps per Second: 10,058.54156

Timestep Collection Time: 2.45227
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.97269

Cumulative Model Updates: 84,790
Cumulative Timesteps: 707,158,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,419.11355
Policy Entropy: 1.95203
Value Function Loss: 0.07003

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.49095
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 21,643.51914
Overall Steps per Second: 10,027.75840

Timestep Collection Time: 2.31071
Timestep Consumption Time: 2.67664
PPO Batch Consumption Time: 0.31899
Total Iteration Time: 4.98736

Cumulative Model Updates: 84,796
Cumulative Timesteps: 707,208,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 707208218...
Checkpoint 707208218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,042.42714
Policy Entropy: 1.96835
Value Function Loss: 0.07269

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.48818
Value Function Update Magnitude: 0.61191

Collected Steps per Second: 20,935.82668
Overall Steps per Second: 10,264.12190

Timestep Collection Time: 2.38930
Timestep Consumption Time: 2.48418
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.87348

Cumulative Model Updates: 84,802
Cumulative Timesteps: 707,258,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,062.28395
Policy Entropy: 1.95735
Value Function Loss: 0.07829

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.51968
Value Function Update Magnitude: 0.56733

Collected Steps per Second: 22,077.17929
Overall Steps per Second: 10,583.76450

Timestep Collection Time: 2.26560
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.72592

Cumulative Model Updates: 84,808
Cumulative Timesteps: 707,308,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 707308258...
Checkpoint 707308258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,937.64459
Policy Entropy: 1.95907
Value Function Loss: 0.08827

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.54288

Collected Steps per Second: 21,300.80252
Overall Steps per Second: 10,228.94821

Timestep Collection Time: 2.34733
Timestep Consumption Time: 2.54076
PPO Batch Consumption Time: 0.30199
Total Iteration Time: 4.88809

Cumulative Model Updates: 84,814
Cumulative Timesteps: 707,358,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,396.65031
Policy Entropy: 1.94069
Value Function Loss: 0.08304

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.64256

Collected Steps per Second: 21,710.29842
Overall Steps per Second: 10,513.61975

Timestep Collection Time: 2.30398
Timestep Consumption Time: 2.45366
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.75764

Cumulative Model Updates: 84,820
Cumulative Timesteps: 707,408,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 707408278...
Checkpoint 707408278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,290.96031
Policy Entropy: 1.93604
Value Function Loss: 0.07472

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15377
Policy Update Magnitude: 0.50542
Value Function Update Magnitude: 0.67303

Collected Steps per Second: 21,534.22949
Overall Steps per Second: 10,332.30529

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.51892
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.84229

Cumulative Model Updates: 84,826
Cumulative Timesteps: 707,458,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,474.16921
Policy Entropy: 1.92558
Value Function Loss: 0.07111

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.52313
Value Function Update Magnitude: 0.66657

Collected Steps per Second: 22,323.89398
Overall Steps per Second: 10,684.80332

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.44096
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.68179

Cumulative Model Updates: 84,832
Cumulative Timesteps: 707,508,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 707508334...
Checkpoint 707508334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,107.43296
Policy Entropy: 1.91976
Value Function Loss: 0.07466

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.54328
Value Function Update Magnitude: 0.68997

Collected Steps per Second: 21,197.44326
Overall Steps per Second: 10,245.77699

Timestep Collection Time: 2.36000
Timestep Consumption Time: 2.52260
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.88260

Cumulative Model Updates: 84,838
Cumulative Timesteps: 707,558,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,918.05571
Policy Entropy: 1.91740
Value Function Loss: 0.07785

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.56053
Value Function Update Magnitude: 0.68700

Collected Steps per Second: 22,375.53591
Overall Steps per Second: 10,432.32519

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.56097
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.79797

Cumulative Model Updates: 84,844
Cumulative Timesteps: 707,608,414

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 707608414...
Checkpoint 707608414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,547.93025
Policy Entropy: 1.90672
Value Function Loss: 0.07632

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.55572
Value Function Update Magnitude: 0.68644

Collected Steps per Second: 21,490.37153
Overall Steps per Second: 10,245.26582

Timestep Collection Time: 2.32700
Timestep Consumption Time: 2.55409
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.88108

Cumulative Model Updates: 84,850
Cumulative Timesteps: 707,658,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,847.20257
Policy Entropy: 1.91710
Value Function Loss: 0.07274

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.68674

Collected Steps per Second: 21,471.22311
Overall Steps per Second: 10,236.87306

Timestep Collection Time: 2.32935
Timestep Consumption Time: 2.55632
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.88567

Cumulative Model Updates: 84,856
Cumulative Timesteps: 707,708,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 707708436...
Checkpoint 707708436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,893.63867
Policy Entropy: 1.91188
Value Function Loss: 0.07105

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.54099
Value Function Update Magnitude: 0.69743

Collected Steps per Second: 20,642.67722
Overall Steps per Second: 9,956.80500

Timestep Collection Time: 2.42246
Timestep Consumption Time: 2.59984
PPO Batch Consumption Time: 0.30688
Total Iteration Time: 5.02229

Cumulative Model Updates: 84,862
Cumulative Timesteps: 707,758,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,517.97861
Policy Entropy: 1.92579
Value Function Loss: 0.06892

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.53259
Value Function Update Magnitude: 0.68684

Collected Steps per Second: 22,014.05154
Overall Steps per Second: 10,487.29410

Timestep Collection Time: 2.27182
Timestep Consumption Time: 2.49700
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.76882

Cumulative Model Updates: 84,868
Cumulative Timesteps: 707,808,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 707808454...
Checkpoint 707808454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,401.29589
Policy Entropy: 1.91018
Value Function Loss: 0.07448

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.67053

Collected Steps per Second: 20,967.59483
Overall Steps per Second: 10,119.80500

Timestep Collection Time: 2.38473
Timestep Consumption Time: 2.55628
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.94100

Cumulative Model Updates: 84,874
Cumulative Timesteps: 707,858,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,034.52412
Policy Entropy: 1.92068
Value Function Loss: 0.07747

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.55568
Value Function Update Magnitude: 0.64104

Collected Steps per Second: 21,910.38586
Overall Steps per Second: 10,510.05280

Timestep Collection Time: 2.28248
Timestep Consumption Time: 2.47582
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.75830

Cumulative Model Updates: 84,880
Cumulative Timesteps: 707,908,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 707908466...
Checkpoint 707908466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,674.09949
Policy Entropy: 1.93366
Value Function Loss: 0.08267

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.56448
Value Function Update Magnitude: 0.57772

Collected Steps per Second: 21,248.66782
Overall Steps per Second: 10,223.71619

Timestep Collection Time: 2.35431
Timestep Consumption Time: 2.53882
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.89313

Cumulative Model Updates: 84,886
Cumulative Timesteps: 707,958,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,819.36614
Policy Entropy: 1.93995
Value Function Loss: 0.08356

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.49797

Collected Steps per Second: 22,120.92246
Overall Steps per Second: 10,482.87599

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.51129
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.77331

Cumulative Model Updates: 84,892
Cumulative Timesteps: 708,008,530

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 708008530...
Checkpoint 708008530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,615.55206
Policy Entropy: 1.94316
Value Function Loss: 0.08468

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.56371
Value Function Update Magnitude: 0.52656

Collected Steps per Second: 21,277.27805
Overall Steps per Second: 10,236.46442

Timestep Collection Time: 2.35124
Timestep Consumption Time: 2.53599
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.88723

Cumulative Model Updates: 84,898
Cumulative Timesteps: 708,058,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,219.75298
Policy Entropy: 1.94398
Value Function Loss: 0.08205

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.49373

Collected Steps per Second: 22,212.99308
Overall Steps per Second: 10,518.56858

Timestep Collection Time: 2.25229
Timestep Consumption Time: 2.50407
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.75635

Cumulative Model Updates: 84,904
Cumulative Timesteps: 708,108,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 708108588...
Checkpoint 708108588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,516.72091
Policy Entropy: 1.93802
Value Function Loss: 0.08119

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.57692

Collected Steps per Second: 21,340.63439
Overall Steps per Second: 10,282.04262

Timestep Collection Time: 2.34370
Timestep Consumption Time: 2.52071
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.86440

Cumulative Model Updates: 84,910
Cumulative Timesteps: 708,158,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,342.19195
Policy Entropy: 1.93932
Value Function Loss: 0.07695

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.69944

Collected Steps per Second: 22,259.20614
Overall Steps per Second: 10,372.93438

Timestep Collection Time: 2.24626
Timestep Consumption Time: 2.57398
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.82024

Cumulative Model Updates: 84,916
Cumulative Timesteps: 708,208,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 708208604...
Checkpoint 708208604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,034.75680
Policy Entropy: 1.93036
Value Function Loss: 0.07617

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.73314

Collected Steps per Second: 21,610.13844
Overall Steps per Second: 10,486.67248

Timestep Collection Time: 2.31539
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.77139

Cumulative Model Updates: 84,922
Cumulative Timesteps: 708,258,640

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,311.42107
Policy Entropy: 1.93342
Value Function Loss: 0.07373

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.73561

Collected Steps per Second: 21,193.44855
Overall Steps per Second: 10,236.56035

Timestep Collection Time: 2.36054
Timestep Consumption Time: 2.52665
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.88719

Cumulative Model Updates: 84,928
Cumulative Timesteps: 708,308,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 708308668...
Checkpoint 708308668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,417.94914
Policy Entropy: 1.94289
Value Function Loss: 0.07416

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.66850

Collected Steps per Second: 21,405.57454
Overall Steps per Second: 10,404.62464

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.47110
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.80825

Cumulative Model Updates: 84,934
Cumulative Timesteps: 708,358,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,015.34799
Policy Entropy: 1.93258
Value Function Loss: 0.07380

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.54827
Value Function Update Magnitude: 0.64185

Collected Steps per Second: 21,708.59061
Overall Steps per Second: 10,504.80424

Timestep Collection Time: 2.30462
Timestep Consumption Time: 2.45797
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.76258

Cumulative Model Updates: 84,940
Cumulative Timesteps: 708,408,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 708408726...
Checkpoint 708408726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,010.18005
Policy Entropy: 1.93684
Value Function Loss: 0.07218

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.53685
Value Function Update Magnitude: 0.65469

Collected Steps per Second: 21,341.43572
Overall Steps per Second: 10,260.69767

Timestep Collection Time: 2.34492
Timestep Consumption Time: 2.53233
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.87725

Cumulative Model Updates: 84,946
Cumulative Timesteps: 708,458,770

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,639.36773
Policy Entropy: 1.92149
Value Function Loss: 0.06990

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.60178

Collected Steps per Second: 22,058.15362
Overall Steps per Second: 10,476.97288

Timestep Collection Time: 2.26764
Timestep Consumption Time: 2.50664
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.77428

Cumulative Model Updates: 84,952
Cumulative Timesteps: 708,508,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 708508790...
Checkpoint 708508790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,038.23542
Policy Entropy: 1.93064
Value Function Loss: 0.07380

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.57444

Collected Steps per Second: 21,158.76494
Overall Steps per Second: 10,185.85759

Timestep Collection Time: 2.36394
Timestep Consumption Time: 2.54660
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.91053

Cumulative Model Updates: 84,958
Cumulative Timesteps: 708,558,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,413.23115
Policy Entropy: 1.92188
Value Function Loss: 0.07343

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.64068

Collected Steps per Second: 22,273.62594
Overall Steps per Second: 10,444.17453

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.54367
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.78946

Cumulative Model Updates: 84,964
Cumulative Timesteps: 708,608,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 708608830...
Checkpoint 708608830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,450.61764
Policy Entropy: 1.93268
Value Function Loss: 0.07955

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 21,466.19992
Overall Steps per Second: 10,291.30785

Timestep Collection Time: 2.32952
Timestep Consumption Time: 2.52953
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.85905

Cumulative Model Updates: 84,970
Cumulative Timesteps: 708,658,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,031.15725
Policy Entropy: 1.93475
Value Function Loss: 0.07922

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.65521

Collected Steps per Second: 21,399.12243
Overall Steps per Second: 10,387.96988

Timestep Collection Time: 2.33682
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.81384

Cumulative Model Updates: 84,976
Cumulative Timesteps: 708,708,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 708708842...
Checkpoint 708708842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,625.91483
Policy Entropy: 1.92687
Value Function Loss: 0.07958

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.68254

Collected Steps per Second: 21,390.17220
Overall Steps per Second: 10,291.57988

Timestep Collection Time: 2.33874
Timestep Consumption Time: 2.52213
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.86087

Cumulative Model Updates: 84,982
Cumulative Timesteps: 708,758,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,159.58237
Policy Entropy: 1.92923
Value Function Loss: 0.07537

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.71083

Collected Steps per Second: 22,093.96889
Overall Steps per Second: 10,430.23554

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.53191
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.79606

Cumulative Model Updates: 84,988
Cumulative Timesteps: 708,808,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 708808892...
Checkpoint 708808892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,815.95334
Policy Entropy: 1.91839
Value Function Loss: 0.07460

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.74301

Collected Steps per Second: 21,448.65500
Overall Steps per Second: 10,326.34989

Timestep Collection Time: 2.33236
Timestep Consumption Time: 2.51214
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.84450

Cumulative Model Updates: 84,994
Cumulative Timesteps: 708,858,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,035.98632
Policy Entropy: 1.93480
Value Function Loss: 0.07231

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.55100
Value Function Update Magnitude: 0.70146

Collected Steps per Second: 22,316.20764
Overall Steps per Second: 10,648.20903

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.69694

Cumulative Model Updates: 85,000
Cumulative Timesteps: 708,908,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 708908932...
Checkpoint 708908932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,201.49980
Policy Entropy: 1.93368
Value Function Loss: 0.07259

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.64093

Collected Steps per Second: 21,691.68519
Overall Steps per Second: 10,344.15245

Timestep Collection Time: 2.30604
Timestep Consumption Time: 2.52973
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.83578

Cumulative Model Updates: 85,006
Cumulative Timesteps: 708,958,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,821.20218
Policy Entropy: 1.94590
Value Function Loss: 0.07265

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.53379
Value Function Update Magnitude: 0.65738

Collected Steps per Second: 21,462.63385
Overall Steps per Second: 10,471.52524

Timestep Collection Time: 2.32963
Timestep Consumption Time: 2.44522
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.77485

Cumulative Model Updates: 85,012
Cumulative Timesteps: 709,008,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 709008954...
Checkpoint 709008954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,467.90348
Policy Entropy: 1.92285
Value Function Loss: 0.07099

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.52887
Value Function Update Magnitude: 0.69262

Collected Steps per Second: 20,835.85841
Overall Steps per Second: 10,475.81588

Timestep Collection Time: 2.40009
Timestep Consumption Time: 2.37357
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.77366

Cumulative Model Updates: 85,018
Cumulative Timesteps: 709,058,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,050.53862
Policy Entropy: 1.90684
Value Function Loss: 0.06824

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.50700
Value Function Update Magnitude: 0.68738

Collected Steps per Second: 21,269.34741
Overall Steps per Second: 10,587.25870

Timestep Collection Time: 2.35212
Timestep Consumption Time: 2.37319
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.72530

Cumulative Model Updates: 85,024
Cumulative Timesteps: 709,108,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 709108990...
Checkpoint 709108990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,031.39556
Policy Entropy: 1.89660
Value Function Loss: 0.07095

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.52190
Value Function Update Magnitude: 0.68036

Collected Steps per Second: 21,235.18337
Overall Steps per Second: 10,547.43810

Timestep Collection Time: 2.35581
Timestep Consumption Time: 2.38715
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.74295

Cumulative Model Updates: 85,030
Cumulative Timesteps: 709,159,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,758.67881
Policy Entropy: 1.90609
Value Function Loss: 0.07116

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.52441
Value Function Update Magnitude: 0.62956

Collected Steps per Second: 21,400.19376
Overall Steps per Second: 10,503.85755

Timestep Collection Time: 2.33718
Timestep Consumption Time: 2.42450
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.76168

Cumulative Model Updates: 85,036
Cumulative Timesteps: 709,209,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 709209032...
Checkpoint 709209032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,599.52537
Policy Entropy: 1.90213
Value Function Loss: 0.07608

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.53372
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 20,198.32032
Overall Steps per Second: 10,136.90085

Timestep Collection Time: 2.47674
Timestep Consumption Time: 2.45830
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.93504

Cumulative Model Updates: 85,042
Cumulative Timesteps: 709,259,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,567.82630
Policy Entropy: 1.91023
Value Function Loss: 0.07551

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.54226
Value Function Update Magnitude: 0.67094

Collected Steps per Second: 21,554.34748
Overall Steps per Second: 10,455.87092

Timestep Collection Time: 2.32167
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.78602

Cumulative Model Updates: 85,048
Cumulative Timesteps: 709,309,100

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 709309100...
Checkpoint 709309100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,080.20527
Policy Entropy: 1.90785
Value Function Loss: 0.07855

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.68509

Collected Steps per Second: 21,268.21637
Overall Steps per Second: 10,273.40657

Timestep Collection Time: 2.35177
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.86869

Cumulative Model Updates: 85,054
Cumulative Timesteps: 709,359,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,691.52088
Policy Entropy: 1.92597
Value Function Loss: 0.08493

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.54924
Value Function Update Magnitude: 0.64912

Collected Steps per Second: 21,792.55172
Overall Steps per Second: 10,471.18271

Timestep Collection Time: 2.29574
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.77787

Cumulative Model Updates: 85,060
Cumulative Timesteps: 709,409,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 709409148...
Checkpoint 709409148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,430.82311
Policy Entropy: 1.91512
Value Function Loss: 0.08025

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.15440
Policy Update Magnitude: 0.54606
Value Function Update Magnitude: 0.59056

Collected Steps per Second: 21,142.65405
Overall Steps per Second: 10,250.23995

Timestep Collection Time: 2.36659
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.88145

Cumulative Model Updates: 85,066
Cumulative Timesteps: 709,459,184

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,922.70881
Policy Entropy: 1.94297
Value Function Loss: 0.08383

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.53312
Value Function Update Magnitude: 0.54055

Collected Steps per Second: 22,124.74625
Overall Steps per Second: 10,476.29391

Timestep Collection Time: 2.26055
Timestep Consumption Time: 2.51347
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.77402

Cumulative Model Updates: 85,072
Cumulative Timesteps: 709,509,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 709509198...
Checkpoint 709509198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,432.86618
Policy Entropy: 1.92523
Value Function Loss: 0.07747

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.53612

Collected Steps per Second: 21,504.98714
Overall Steps per Second: 10,512.62131

Timestep Collection Time: 2.32625
Timestep Consumption Time: 2.43241
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.75866

Cumulative Model Updates: 85,078
Cumulative Timesteps: 709,559,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,114.12714
Policy Entropy: 1.93466
Value Function Loss: 0.08330

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.54075

Collected Steps per Second: 21,935.53651
Overall Steps per Second: 10,537.03723

Timestep Collection Time: 2.27977
Timestep Consumption Time: 2.46616
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.74593

Cumulative Model Updates: 85,084
Cumulative Timesteps: 709,609,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 709609232...
Checkpoint 709609232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,854.27579
Policy Entropy: 1.91780
Value Function Loss: 0.07583

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.55049
Value Function Update Magnitude: 0.66550

Collected Steps per Second: 21,107.62739
Overall Steps per Second: 10,222.14076

Timestep Collection Time: 2.37071
Timestep Consumption Time: 2.52455
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.89526

Cumulative Model Updates: 85,090
Cumulative Timesteps: 709,659,272

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,544.14212
Policy Entropy: 1.90914
Value Function Loss: 0.07330

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.54962
Value Function Update Magnitude: 0.70514

Collected Steps per Second: 21,451.48716
Overall Steps per Second: 10,398.27544

Timestep Collection Time: 2.33187
Timestep Consumption Time: 2.47874
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.81061

Cumulative Model Updates: 85,096
Cumulative Timesteps: 709,709,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 709709294...
Checkpoint 709709294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,391.27566
Policy Entropy: 1.91578
Value Function Loss: 0.07819

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.68153

Collected Steps per Second: 21,369.01727
Overall Steps per Second: 10,323.57350

Timestep Collection Time: 2.34115
Timestep Consumption Time: 2.50485
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.84600

Cumulative Model Updates: 85,102
Cumulative Timesteps: 709,759,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,007.42422
Policy Entropy: 1.89667
Value Function Loss: 0.07409

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.55894
Value Function Update Magnitude: 0.70401

Collected Steps per Second: 22,058.11640
Overall Steps per Second: 10,372.64864

Timestep Collection Time: 2.26683
Timestep Consumption Time: 2.55373
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.82056

Cumulative Model Updates: 85,108
Cumulative Timesteps: 709,809,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 709809324...
Checkpoint 709809324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,298.91697
Policy Entropy: 1.89800
Value Function Loss: 0.07613

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.71557

Collected Steps per Second: 21,213.53140
Overall Steps per Second: 10,209.76603

Timestep Collection Time: 2.35774
Timestep Consumption Time: 2.54110
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.89884

Cumulative Model Updates: 85,114
Cumulative Timesteps: 709,859,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,878.22481
Policy Entropy: 1.88926
Value Function Loss: 0.07124

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.70583

Collected Steps per Second: 21,838.57654
Overall Steps per Second: 10,466.28370

Timestep Collection Time: 2.29008
Timestep Consumption Time: 2.48832
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.77839

Cumulative Model Updates: 85,120
Cumulative Timesteps: 709,909,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 709909352...
Checkpoint 709909352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,136.66028
Policy Entropy: 1.91308
Value Function Loss: 0.07281

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.16430
Policy Update Magnitude: 0.48685
Value Function Update Magnitude: 0.69401

Collected Steps per Second: 21,550.32753
Overall Steps per Second: 10,298.31214

Timestep Collection Time: 2.32089
Timestep Consumption Time: 2.53583
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.85672

Cumulative Model Updates: 85,126
Cumulative Timesteps: 709,959,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,046.50444
Policy Entropy: 1.92360
Value Function Loss: 0.06839

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.51286
Value Function Update Magnitude: 0.67776

Collected Steps per Second: 22,027.32557
Overall Steps per Second: 10,368.15442

Timestep Collection Time: 2.27200
Timestep Consumption Time: 2.55490
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.82690

Cumulative Model Updates: 85,132
Cumulative Timesteps: 710,009,414

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 710009414...
Checkpoint 710009414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,632.58764
Policy Entropy: 1.91913
Value Function Loss: 0.07509

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.54934
Value Function Update Magnitude: 0.67577

Collected Steps per Second: 21,000.62394
Overall Steps per Second: 10,185.90944

Timestep Collection Time: 2.38212
Timestep Consumption Time: 2.52917
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.91129

Cumulative Model Updates: 85,138
Cumulative Timesteps: 710,059,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,999.07224
Policy Entropy: 1.91940
Value Function Loss: 0.07594

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.66532

Collected Steps per Second: 21,449.80428
Overall Steps per Second: 10,439.96061

Timestep Collection Time: 2.33102
Timestep Consumption Time: 2.45827
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.78929

Cumulative Model Updates: 85,144
Cumulative Timesteps: 710,109,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 710109440...
Checkpoint 710109440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,730.50394
Policy Entropy: 1.92290
Value Function Loss: 0.07539

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.54819
Value Function Update Magnitude: 0.67426

Collected Steps per Second: 21,242.42899
Overall Steps per Second: 10,255.70116

Timestep Collection Time: 2.35472
Timestep Consumption Time: 2.52257
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.87729

Cumulative Model Updates: 85,150
Cumulative Timesteps: 710,159,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,750.34166
Policy Entropy: 1.93106
Value Function Loss: 0.06698

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.53845
Value Function Update Magnitude: 0.69454

Collected Steps per Second: 22,125.62974
Overall Steps per Second: 10,476.22071

Timestep Collection Time: 2.26091
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.77500

Cumulative Model Updates: 85,156
Cumulative Timesteps: 710,209,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 710209484...
Checkpoint 710209484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,901.30751
Policy Entropy: 1.92753
Value Function Loss: 0.06927

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.66953

Collected Steps per Second: 21,717.16851
Overall Steps per Second: 10,356.55473

Timestep Collection Time: 2.30260
Timestep Consumption Time: 2.52584
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.82844

Cumulative Model Updates: 85,162
Cumulative Timesteps: 710,259,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,044.79147
Policy Entropy: 1.93568
Value Function Loss: 0.08008

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.69383

Collected Steps per Second: 22,306.20504
Overall Steps per Second: 10,628.45847

Timestep Collection Time: 2.24350
Timestep Consumption Time: 2.46499
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.70849

Cumulative Model Updates: 85,168
Cumulative Timesteps: 710,309,534

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 710309534...
Checkpoint 710309534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,823.19785
Policy Entropy: 1.93075
Value Function Loss: 0.08445

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.57802
Value Function Update Magnitude: 0.69173

Collected Steps per Second: 21,089.53164
Overall Steps per Second: 10,273.72964

Timestep Collection Time: 2.37170
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.86853

Cumulative Model Updates: 85,174
Cumulative Timesteps: 710,359,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,326.23198
Policy Entropy: 1.93542
Value Function Loss: 0.08086

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.56739
Value Function Update Magnitude: 0.63620

Collected Steps per Second: 21,687.43670
Overall Steps per Second: 10,476.02147

Timestep Collection Time: 2.30723
Timestep Consumption Time: 2.46920
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.77643

Cumulative Model Updates: 85,180
Cumulative Timesteps: 710,409,590

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 710409590...
Checkpoint 710409590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,988.59570
Policy Entropy: 1.91393
Value Function Loss: 0.07306

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.63344

Collected Steps per Second: 21,541.11137
Overall Steps per Second: 10,317.64725

Timestep Collection Time: 2.32235
Timestep Consumption Time: 2.52624
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.84859

Cumulative Model Updates: 85,186
Cumulative Timesteps: 710,459,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,348.76786
Policy Entropy: 1.89698
Value Function Loss: 0.07019

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.51191
Value Function Update Magnitude: 0.66199

Collected Steps per Second: 21,932.66058
Overall Steps per Second: 10,338.08498

Timestep Collection Time: 2.28034
Timestep Consumption Time: 2.55750
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.83784

Cumulative Model Updates: 85,192
Cumulative Timesteps: 710,509,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 710509630...
Checkpoint 710509630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,789.22163
Policy Entropy: 1.89448
Value Function Loss: 0.07103

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.52390
Value Function Update Magnitude: 0.70697

Collected Steps per Second: 21,380.32891
Overall Steps per Second: 10,237.03651

Timestep Collection Time: 2.33953
Timestep Consumption Time: 2.54665
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.88618

Cumulative Model Updates: 85,198
Cumulative Timesteps: 710,559,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,427.05072
Policy Entropy: 1.90475
Value Function Loss: 0.07273

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.53211
Value Function Update Magnitude: 0.71918

Collected Steps per Second: 22,333.49653
Overall Steps per Second: 10,467.52024

Timestep Collection Time: 2.24103
Timestep Consumption Time: 2.54043
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.78146

Cumulative Model Updates: 85,204
Cumulative Timesteps: 710,609,700

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 710609700...
Checkpoint 710609700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,986.09928
Policy Entropy: 1.91239
Value Function Loss: 0.07804

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.52331
Value Function Update Magnitude: 0.71813

Collected Steps per Second: 21,574.10469
Overall Steps per Second: 10,062.40959

Timestep Collection Time: 2.31815
Timestep Consumption Time: 2.65203
PPO Batch Consumption Time: 0.31522
Total Iteration Time: 4.97018

Cumulative Model Updates: 85,210
Cumulative Timesteps: 710,659,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,413.04420
Policy Entropy: 1.92349
Value Function Loss: 0.07827

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.71529

Collected Steps per Second: 20,230.68368
Overall Steps per Second: 10,091.52349

Timestep Collection Time: 2.47209
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.95584

Cumulative Model Updates: 85,216
Cumulative Timesteps: 710,709,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 710709724...
Checkpoint 710709724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,874.17643
Policy Entropy: 1.91622
Value Function Loss: 0.07532

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.75307

Collected Steps per Second: 19,674.27687
Overall Steps per Second: 9,713.91614

Timestep Collection Time: 2.54291
Timestep Consumption Time: 2.60743
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 5.15034

Cumulative Model Updates: 85,222
Cumulative Timesteps: 710,759,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,991.71259
Policy Entropy: 1.92671
Value Function Loss: 0.07669

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.55983
Value Function Update Magnitude: 0.72349

Collected Steps per Second: 20,766.44094
Overall Steps per Second: 10,067.21257

Timestep Collection Time: 2.40850
Timestep Consumption Time: 2.55971
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.96821

Cumulative Model Updates: 85,228
Cumulative Timesteps: 710,809,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 710809770...
Checkpoint 710809770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,134.11018
Policy Entropy: 1.91063
Value Function Loss: 0.08042

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.62678

Collected Steps per Second: 18,715.33317
Overall Steps per Second: 9,598.11340

Timestep Collection Time: 2.67278
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 5.21165

Cumulative Model Updates: 85,234
Cumulative Timesteps: 710,859,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,269.80670
Policy Entropy: 1.91390
Value Function Loss: 0.08188

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.56688
Value Function Update Magnitude: 0.58300

Collected Steps per Second: 22,196.62454
Overall Steps per Second: 10,634.70688

Timestep Collection Time: 2.25368
Timestep Consumption Time: 2.45017
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.70384

Cumulative Model Updates: 85,240
Cumulative Timesteps: 710,909,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 710909816...
Checkpoint 710909816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,978.86224
Policy Entropy: 1.92177
Value Function Loss: 0.07557

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.64666

Collected Steps per Second: 21,257.13017
Overall Steps per Second: 10,121.13566

Timestep Collection Time: 2.35243
Timestep Consumption Time: 2.58832
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.94075

Cumulative Model Updates: 85,246
Cumulative Timesteps: 710,959,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,329.75863
Policy Entropy: 1.92775
Value Function Loss: 0.07563

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.52106
Value Function Update Magnitude: 0.52057

Collected Steps per Second: 22,126.06969
Overall Steps per Second: 10,455.40352

Timestep Collection Time: 2.26131
Timestep Consumption Time: 2.52415
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.78547

Cumulative Model Updates: 85,252
Cumulative Timesteps: 711,009,856

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 711009856...
Checkpoint 711009856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,915.03258
Policy Entropy: 1.93331
Value Function Loss: 0.07782

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.16884
Policy Update Magnitude: 0.47293
Value Function Update Magnitude: 0.52974

Collected Steps per Second: 21,503.83830
Overall Steps per Second: 10,252.91179

Timestep Collection Time: 2.32526
Timestep Consumption Time: 2.55160
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.87686

Cumulative Model Updates: 85,258
Cumulative Timesteps: 711,059,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,925.10967
Policy Entropy: 1.93210
Value Function Loss: 0.08325

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.15683
Policy Update Magnitude: 0.46403
Value Function Update Magnitude: 0.65221

Collected Steps per Second: 21,322.64149
Overall Steps per Second: 10,397.94659

Timestep Collection Time: 2.34586
Timestep Consumption Time: 2.46470
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.81057

Cumulative Model Updates: 85,264
Cumulative Timesteps: 711,109,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 711109878...
Checkpoint 711109878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,903.32927
Policy Entropy: 1.93521
Value Function Loss: 0.08268

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.16123
Policy Update Magnitude: 0.49137
Value Function Update Magnitude: 0.71889

Collected Steps per Second: 19,837.91395
Overall Steps per Second: 9,815.39802

Timestep Collection Time: 2.52103
Timestep Consumption Time: 2.57423
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 5.09526

Cumulative Model Updates: 85,270
Cumulative Timesteps: 711,159,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,554.62354
Policy Entropy: 1.92377
Value Function Loss: 0.08986

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.16691
Policy Update Magnitude: 0.50246
Value Function Update Magnitude: 0.71450

Collected Steps per Second: 21,325.22425
Overall Steps per Second: 10,416.32934

Timestep Collection Time: 2.34549
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.80188

Cumulative Model Updates: 85,276
Cumulative Timesteps: 711,209,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 711209908...
Checkpoint 711209908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,213.57555
Policy Entropy: 1.91996
Value Function Loss: 0.09172

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.14741
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.66853

Collected Steps per Second: 20,917.82114
Overall Steps per Second: 10,252.15695

Timestep Collection Time: 2.39174
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.87995

Cumulative Model Updates: 85,282
Cumulative Timesteps: 711,259,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,915.61570
Policy Entropy: 1.90229
Value Function Loss: 0.08961

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.60726

Collected Steps per Second: 18,789.46024
Overall Steps per Second: 9,634.80379

Timestep Collection Time: 2.66149
Timestep Consumption Time: 2.52886
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 5.19035

Cumulative Model Updates: 85,288
Cumulative Timesteps: 711,309,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 711309946...
Checkpoint 711309946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,000.58042
Policy Entropy: 1.90278
Value Function Loss: 0.08264

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.56794
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 20,087.68088
Overall Steps per Second: 9,974.47380

Timestep Collection Time: 2.49108
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 5.01681

Cumulative Model Updates: 85,294
Cumulative Timesteps: 711,359,986

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,479.66475
Policy Entropy: 1.89684
Value Function Loss: 0.07283

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.63235

Collected Steps per Second: 21,657.00508
Overall Steps per Second: 10,332.18000

Timestep Collection Time: 2.30965
Timestep Consumption Time: 2.53154
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.84119

Cumulative Model Updates: 85,300
Cumulative Timesteps: 711,410,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 711410006...
Checkpoint 711410006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,976.19427
Policy Entropy: 1.92915
Value Function Loss: 0.07711

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.53982

Collected Steps per Second: 20,638.83840
Overall Steps per Second: 9,726.00194

Timestep Collection Time: 2.42339
Timestep Consumption Time: 2.71911
PPO Batch Consumption Time: 0.31333
Total Iteration Time: 5.14250

Cumulative Model Updates: 85,306
Cumulative Timesteps: 711,460,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,746.88177
Policy Entropy: 1.94519
Value Function Loss: 0.07871

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.56026
Value Function Update Magnitude: 0.50682

Collected Steps per Second: 21,463.83731
Overall Steps per Second: 10,365.68396

Timestep Collection Time: 2.33080
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.82631

Cumulative Model Updates: 85,312
Cumulative Timesteps: 711,510,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 711510050...
Checkpoint 711510050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,946.30046
Policy Entropy: 1.94753
Value Function Loss: 0.08408

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.42632

Collected Steps per Second: 21,554.98237
Overall Steps per Second: 10,174.05090

Timestep Collection Time: 2.32104
Timestep Consumption Time: 2.59637
PPO Batch Consumption Time: 0.30099
Total Iteration Time: 4.91741

Cumulative Model Updates: 85,318
Cumulative Timesteps: 711,560,080

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,074.00853
Policy Entropy: 1.92770
Value Function Loss: 0.07796

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.53675
Value Function Update Magnitude: 0.42981

Collected Steps per Second: 20,504.02117
Overall Steps per Second: 9,919.87561

Timestep Collection Time: 2.43864
Timestep Consumption Time: 2.60194
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 5.04059

Cumulative Model Updates: 85,324
Cumulative Timesteps: 711,610,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 711610082...
Checkpoint 711610082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,989.59971
Policy Entropy: 1.91218
Value Function Loss: 0.08046

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.53764
Value Function Update Magnitude: 0.41928

Collected Steps per Second: 20,974.22315
Overall Steps per Second: 10,097.38450

Timestep Collection Time: 2.38540
Timestep Consumption Time: 2.56954
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.95495

Cumulative Model Updates: 85,330
Cumulative Timesteps: 711,660,114

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,416.24958
Policy Entropy: 1.90085
Value Function Loss: 0.07931

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.43699

Collected Steps per Second: 20,433.19333
Overall Steps per Second: 10,056.70045

Timestep Collection Time: 2.44954
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.97698

Cumulative Model Updates: 85,336
Cumulative Timesteps: 711,710,166

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 711710166...
Checkpoint 711710166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,999.41610
Policy Entropy: 1.90795
Value Function Loss: 0.08611

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.55644
Value Function Update Magnitude: 0.47633

Collected Steps per Second: 20,391.16611
Overall Steps per Second: 10,200.93696

Timestep Collection Time: 2.45263
Timestep Consumption Time: 2.45006
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.90269

Cumulative Model Updates: 85,342
Cumulative Timesteps: 711,760,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,491.24982
Policy Entropy: 1.92241
Value Function Loss: 0.08454

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.56590
Value Function Update Magnitude: 0.65770

Collected Steps per Second: 21,982.30168
Overall Steps per Second: 10,504.53360

Timestep Collection Time: 2.27601
Timestep Consumption Time: 2.48688
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.76290

Cumulative Model Updates: 85,348
Cumulative Timesteps: 711,810,210

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 711810210...
Checkpoint 711810210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,696.62710
Policy Entropy: 1.93048
Value Function Loss: 0.08101

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.56699
Value Function Update Magnitude: 0.71816

Collected Steps per Second: 20,532.12991
Overall Steps per Second: 10,194.36884

Timestep Collection Time: 2.43686
Timestep Consumption Time: 2.47114
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.90800

Cumulative Model Updates: 85,354
Cumulative Timesteps: 711,860,244

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,062.74354
Policy Entropy: 1.91619
Value Function Loss: 0.07473

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.55925
Value Function Update Magnitude: 0.68758

Collected Steps per Second: 21,298.87174
Overall Steps per Second: 10,447.59021

Timestep Collection Time: 2.34811
Timestep Consumption Time: 2.43884
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.78694

Cumulative Model Updates: 85,360
Cumulative Timesteps: 711,910,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 711910256...
Checkpoint 711910256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,917.05370
Policy Entropy: 1.90002
Value Function Loss: 0.07590

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.59557

Collected Steps per Second: 20,699.34022
Overall Steps per Second: 10,246.99801

Timestep Collection Time: 2.41631
Timestep Consumption Time: 2.46473
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.88104

Cumulative Model Updates: 85,366
Cumulative Timesteps: 711,960,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,012.36615
Policy Entropy: 1.90994
Value Function Loss: 0.07898

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.57226

Collected Steps per Second: 20,782.19062
Overall Steps per Second: 10,427.86830

Timestep Collection Time: 2.40793
Timestep Consumption Time: 2.39094
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.79887

Cumulative Model Updates: 85,372
Cumulative Timesteps: 712,010,314

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 712010314...
Checkpoint 712010314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,188.71822
Policy Entropy: 1.90731
Value Function Loss: 0.08186

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.51660
Value Function Update Magnitude: 0.58116

Collected Steps per Second: 20,881.38829
Overall Steps per Second: 10,323.56705

Timestep Collection Time: 2.39543
Timestep Consumption Time: 2.44979
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.84522

Cumulative Model Updates: 85,378
Cumulative Timesteps: 712,060,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,242.27090
Policy Entropy: 1.90094
Value Function Loss: 0.08666

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15454
Policy Update Magnitude: 0.50277
Value Function Update Magnitude: 0.43733

Collected Steps per Second: 21,390.53986
Overall Steps per Second: 10,456.74372

Timestep Collection Time: 2.33898
Timestep Consumption Time: 2.44569
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.78466

Cumulative Model Updates: 85,384
Cumulative Timesteps: 712,110,366

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 712110366...
Checkpoint 712110366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,438.53615
Policy Entropy: 1.87646
Value Function Loss: 0.09538

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.51853
Value Function Update Magnitude: 0.33113

Collected Steps per Second: 20,581.74366
Overall Steps per Second: 10,324.39090

Timestep Collection Time: 2.43050
Timestep Consumption Time: 2.41472
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.84523

Cumulative Model Updates: 85,390
Cumulative Timesteps: 712,160,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,741.05587
Policy Entropy: 1.88097
Value Function Loss: 0.09251

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.52064
Value Function Update Magnitude: 0.36004

Collected Steps per Second: 21,279.91896
Overall Steps per Second: 10,584.31748

Timestep Collection Time: 2.35161
Timestep Consumption Time: 2.37633
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.72794

Cumulative Model Updates: 85,396
Cumulative Timesteps: 712,210,432

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 712210432...
Checkpoint 712210432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,845.49947
Policy Entropy: 1.88115
Value Function Loss: 0.09234

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.18529
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.37825

Collected Steps per Second: 20,802.13388
Overall Steps per Second: 10,304.20844

Timestep Collection Time: 2.40389
Timestep Consumption Time: 2.44908
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.85297

Cumulative Model Updates: 85,402
Cumulative Timesteps: 712,260,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,238.78221
Policy Entropy: 1.90147
Value Function Loss: 0.08937

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.16951
Policy Update Magnitude: 0.51572
Value Function Update Magnitude: 0.35773

Collected Steps per Second: 21,549.97332
Overall Steps per Second: 10,535.17643

Timestep Collection Time: 2.32158
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.74885

Cumulative Model Updates: 85,408
Cumulative Timesteps: 712,310,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 712310468...
Checkpoint 712310468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,043.45632
Policy Entropy: 1.89571
Value Function Loss: 0.09177

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.16630
Policy Update Magnitude: 0.51932
Value Function Update Magnitude: 0.31687

Collected Steps per Second: 21,308.09934
Overall Steps per Second: 10,462.28055

Timestep Collection Time: 2.34718
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.78041

Cumulative Model Updates: 85,414
Cumulative Timesteps: 712,360,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,984.09682
Policy Entropy: 1.89097
Value Function Loss: 0.09195

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.17118
Policy Update Magnitude: 0.49196
Value Function Update Magnitude: 0.37516

Collected Steps per Second: 21,825.87822
Overall Steps per Second: 10,393.24771

Timestep Collection Time: 2.29123
Timestep Consumption Time: 2.52036
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.81159

Cumulative Model Updates: 85,420
Cumulative Timesteps: 712,410,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 712410490...
Checkpoint 712410490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,625.49239
Policy Entropy: 1.87643
Value Function Loss: 0.09027

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.47295
Value Function Update Magnitude: 0.38264

Collected Steps per Second: 19,982.18481
Overall Steps per Second: 9,898.22185

Timestep Collection Time: 2.50393
Timestep Consumption Time: 2.55092
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 5.05485

Cumulative Model Updates: 85,426
Cumulative Timesteps: 712,460,524

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,767.71748
Policy Entropy: 1.87374
Value Function Loss: 0.08252

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.51750
Value Function Update Magnitude: 0.49014

Collected Steps per Second: 21,260.04113
Overall Steps per Second: 10,231.12824

Timestep Collection Time: 2.35211
Timestep Consumption Time: 2.53552
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.88763

Cumulative Model Updates: 85,432
Cumulative Timesteps: 712,510,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 712510530...
Checkpoint 712510530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,403.26334
Policy Entropy: 1.87208
Value Function Loss: 0.07220

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.54472
Value Function Update Magnitude: 0.60899

Collected Steps per Second: 21,074.70015
Overall Steps per Second: 9,985.54496

Timestep Collection Time: 2.37327
Timestep Consumption Time: 2.63557
PPO Batch Consumption Time: 0.31442
Total Iteration Time: 5.00884

Cumulative Model Updates: 85,438
Cumulative Timesteps: 712,560,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,274.66266
Policy Entropy: 1.87652
Value Function Loss: 0.06826

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.55716

Collected Steps per Second: 21,713.27667
Overall Steps per Second: 10,346.68788

Timestep Collection Time: 2.30384
Timestep Consumption Time: 2.53094
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.83478

Cumulative Model Updates: 85,444
Cumulative Timesteps: 712,610,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 712610570...
Checkpoint 712610570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,214.02034
Policy Entropy: 1.88760
Value Function Loss: 0.07446

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.47665

Collected Steps per Second: 19,959.70623
Overall Steps per Second: 10,036.16084

Timestep Collection Time: 2.50565
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.98318

Cumulative Model Updates: 85,450
Cumulative Timesteps: 712,660,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,552.12784
Policy Entropy: 1.89407
Value Function Loss: 0.07745

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.48452

Collected Steps per Second: 21,586.85066
Overall Steps per Second: 10,424.66273

Timestep Collection Time: 2.31650
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.79689

Cumulative Model Updates: 85,456
Cumulative Timesteps: 712,710,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 712710588...
Checkpoint 712710588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,054.46548
Policy Entropy: 1.90721
Value Function Loss: 0.08102

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.59860

Collected Steps per Second: 21,454.63028
Overall Steps per Second: 10,241.69805

Timestep Collection Time: 2.33069
Timestep Consumption Time: 2.55171
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.88239

Cumulative Model Updates: 85,462
Cumulative Timesteps: 712,760,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,868.01742
Policy Entropy: 1.89917
Value Function Loss: 0.07945

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.16933
Policy Update Magnitude: 0.50910
Value Function Update Magnitude: 0.67787

Collected Steps per Second: 22,012.75648
Overall Steps per Second: 10,463.16811

Timestep Collection Time: 2.27186
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.77962

Cumulative Model Updates: 85,468
Cumulative Timesteps: 712,810,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 712810602...
Checkpoint 712810602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,269.24686
Policy Entropy: 1.90517
Value Function Loss: 0.07594

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.50872
Value Function Update Magnitude: 0.72295

Collected Steps per Second: 20,874.19673
Overall Steps per Second: 10,193.72667

Timestep Collection Time: 2.39568
Timestep Consumption Time: 2.51008
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.90576

Cumulative Model Updates: 85,474
Cumulative Timesteps: 712,860,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,569.25848
Policy Entropy: 1.86455
Value Function Loss: 0.07377

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.73365

Collected Steps per Second: 22,216.58262
Overall Steps per Second: 10,480.26082

Timestep Collection Time: 2.25075
Timestep Consumption Time: 2.52050
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.77126

Cumulative Model Updates: 85,480
Cumulative Timesteps: 712,910,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 712910614...
Checkpoint 712910614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,227.74716
Policy Entropy: 1.83455
Value Function Loss: 0.07230

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.56035
Value Function Update Magnitude: 0.70266

Collected Steps per Second: 20,682.86604
Overall Steps per Second: 10,200.85101

Timestep Collection Time: 2.41959
Timestep Consumption Time: 2.48628
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.90587

Cumulative Model Updates: 85,486
Cumulative Timesteps: 712,960,658

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,512.24096
Policy Entropy: 1.82561
Value Function Loss: 0.07045

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.55740
Value Function Update Magnitude: 0.66361

Collected Steps per Second: 22,021.15550
Overall Steps per Second: 10,591.30773

Timestep Collection Time: 2.27227
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.72444

Cumulative Model Updates: 85,492
Cumulative Timesteps: 713,010,696

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 713010696...
Checkpoint 713010696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,564.71632
Policy Entropy: 1.84997
Value Function Loss: 0.08055

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.58165

Collected Steps per Second: 21,629.81205
Overall Steps per Second: 10,542.94679

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.43127
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.74327

Cumulative Model Updates: 85,498
Cumulative Timesteps: 713,060,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,196.62452
Policy Entropy: 1.86626
Value Function Loss: 0.08496

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.15376
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.64596

Collected Steps per Second: 21,959.99162
Overall Steps per Second: 10,453.02730

Timestep Collection Time: 2.27687
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.78330

Cumulative Model Updates: 85,504
Cumulative Timesteps: 713,110,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 713110704...
Checkpoint 713110704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,219.98627
Policy Entropy: 1.86916
Value Function Loss: 0.08738

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.74575

Collected Steps per Second: 21,593.91919
Overall Steps per Second: 10,276.17118

Timestep Collection Time: 2.31565
Timestep Consumption Time: 2.55036
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.86601

Cumulative Model Updates: 85,510
Cumulative Timesteps: 713,160,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,156.49166
Policy Entropy: 1.86595
Value Function Loss: 0.08318

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.56729
Value Function Update Magnitude: 0.69739

Collected Steps per Second: 22,003.37451
Overall Steps per Second: 10,397.48205

Timestep Collection Time: 2.27274
Timestep Consumption Time: 2.53688
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.80963

Cumulative Model Updates: 85,516
Cumulative Timesteps: 713,210,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 713210716...
Checkpoint 713210716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,189.26259
Policy Entropy: 1.87967
Value Function Loss: 0.08421

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.56566
Value Function Update Magnitude: 0.59960

Collected Steps per Second: 21,278.90071
Overall Steps per Second: 9,976.58648

Timestep Collection Time: 2.35200
Timestep Consumption Time: 2.66454
PPO Batch Consumption Time: 0.31003
Total Iteration Time: 5.01655

Cumulative Model Updates: 85,522
Cumulative Timesteps: 713,260,764

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,975.81574
Policy Entropy: 1.87384
Value Function Loss: 0.08158

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.55772
Value Function Update Magnitude: 0.67499

Collected Steps per Second: 20,293.20436
Overall Steps per Second: 10,006.38557

Timestep Collection Time: 2.46585
Timestep Consumption Time: 2.53496
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 5.00081

Cumulative Model Updates: 85,528
Cumulative Timesteps: 713,310,804

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 713310804...
Checkpoint 713310804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,374.07750
Policy Entropy: 1.87763
Value Function Loss: 0.07593

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.55000
Value Function Update Magnitude: 0.71786

Collected Steps per Second: 21,612.86607
Overall Steps per Second: 10,484.96012

Timestep Collection Time: 2.31390
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.76969

Cumulative Model Updates: 85,534
Cumulative Timesteps: 713,360,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,269.38265
Policy Entropy: 1.86303
Value Function Loss: 0.07838

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.55496
Value Function Update Magnitude: 0.64569

Collected Steps per Second: 21,380.98213
Overall Steps per Second: 10,400.39331

Timestep Collection Time: 2.33918
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.80886

Cumulative Model Updates: 85,540
Cumulative Timesteps: 713,410,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 713410828...
Checkpoint 713410828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,754.94361
Policy Entropy: 1.85144
Value Function Loss: 0.08495

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.56311
Value Function Update Magnitude: 0.48602

Collected Steps per Second: 21,648.99889
Overall Steps per Second: 10,310.89575

Timestep Collection Time: 2.31022
Timestep Consumption Time: 2.54037
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.85060

Cumulative Model Updates: 85,546
Cumulative Timesteps: 713,460,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,990.68189
Policy Entropy: 1.85578
Value Function Loss: 0.08450

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.44900

Collected Steps per Second: 20,535.70659
Overall Steps per Second: 9,883.00078

Timestep Collection Time: 2.43615
Timestep Consumption Time: 2.62588
PPO Batch Consumption Time: 0.30844
Total Iteration Time: 5.06203

Cumulative Model Updates: 85,552
Cumulative Timesteps: 713,510,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 713510870...
Checkpoint 713510870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,376.24438
Policy Entropy: 1.84585
Value Function Loss: 0.07563

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.48854

Collected Steps per Second: 20,943.77142
Overall Steps per Second: 10,107.28934

Timestep Collection Time: 2.38763
Timestep Consumption Time: 2.55989
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.94752

Cumulative Model Updates: 85,558
Cumulative Timesteps: 713,560,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,122.99864
Policy Entropy: 1.83419
Value Function Loss: 0.06850

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.49418

Collected Steps per Second: 20,806.53406
Overall Steps per Second: 10,254.03446

Timestep Collection Time: 2.40328
Timestep Consumption Time: 2.47324
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.87652

Cumulative Model Updates: 85,564
Cumulative Timesteps: 713,610,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 713610880...
Checkpoint 713610880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,700.99282
Policy Entropy: 1.83834
Value Function Loss: 0.06934

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.54448
Value Function Update Magnitude: 0.54710

Collected Steps per Second: 19,773.52952
Overall Steps per Second: 9,574.43662

Timestep Collection Time: 2.52944
Timestep Consumption Time: 2.69447
PPO Batch Consumption Time: 0.31367
Total Iteration Time: 5.22391

Cumulative Model Updates: 85,570
Cumulative Timesteps: 713,660,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,156.22242
Policy Entropy: 1.84332
Value Function Loss: 0.07172

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.58719

Collected Steps per Second: 21,400.26179
Overall Steps per Second: 10,311.77670

Timestep Collection Time: 2.33689
Timestep Consumption Time: 2.51291
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.84979

Cumulative Model Updates: 85,576
Cumulative Timesteps: 713,710,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 713710906...
Checkpoint 713710906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,665.53460
Policy Entropy: 1.85668
Value Function Loss: 0.07458

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.64167

Collected Steps per Second: 21,039.12892
Overall Steps per Second: 10,244.95074

Timestep Collection Time: 2.37786
Timestep Consumption Time: 2.50533
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.88319

Cumulative Model Updates: 85,582
Cumulative Timesteps: 713,760,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,209.23078
Policy Entropy: 1.85071
Value Function Loss: 0.07167

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.71080

Collected Steps per Second: 22,229.45085
Overall Steps per Second: 10,258.90373

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.62612
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.87674

Cumulative Model Updates: 85,588
Cumulative Timesteps: 713,810,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 713810964...
Checkpoint 713810964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,501.25493
Policy Entropy: 1.86422
Value Function Loss: 0.07516

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.75702

Collected Steps per Second: 21,899.25589
Overall Steps per Second: 10,397.12585

Timestep Collection Time: 2.28419
Timestep Consumption Time: 2.52695
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.81114

Cumulative Model Updates: 85,594
Cumulative Timesteps: 713,860,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,062.19409
Policy Entropy: 1.86618
Value Function Loss: 0.08119

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.65342

Collected Steps per Second: 22,380.88227
Overall Steps per Second: 10,497.98571

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.52917
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.76358

Cumulative Model Updates: 85,600
Cumulative Timesteps: 713,910,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 713910994...
Checkpoint 713910994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,757.74391
Policy Entropy: 1.86375
Value Function Loss: 0.08657

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.51702

Collected Steps per Second: 22,218.47372
Overall Steps per Second: 10,403.30384

Timestep Collection Time: 2.25038
Timestep Consumption Time: 2.55579
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.80617

Cumulative Model Updates: 85,606
Cumulative Timesteps: 713,960,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,248.76148
Policy Entropy: 1.85032
Value Function Loss: 0.08957

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.43782

Collected Steps per Second: 22,168.38757
Overall Steps per Second: 10,623.87812

Timestep Collection Time: 2.25646
Timestep Consumption Time: 2.45199
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.70845

Cumulative Model Updates: 85,612
Cumulative Timesteps: 714,011,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 714011016...
Checkpoint 714011016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,959.38331
Policy Entropy: 1.85811
Value Function Loss: 0.08750

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.56473
Value Function Update Magnitude: 0.44205

Collected Steps per Second: 21,857.75066
Overall Steps per Second: 10,615.08376

Timestep Collection Time: 2.28898
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.71329

Cumulative Model Updates: 85,618
Cumulative Timesteps: 714,061,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,863.10192
Policy Entropy: 1.86126
Value Function Loss: 0.08728

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.56917

Collected Steps per Second: 22,301.53121
Overall Steps per Second: 10,233.44973

Timestep Collection Time: 2.24388
Timestep Consumption Time: 2.64616
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 4.89004

Cumulative Model Updates: 85,624
Cumulative Timesteps: 714,111,090

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 714111090...
Checkpoint 714111090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,755.83191
Policy Entropy: 1.86758
Value Function Loss: 0.07955

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.18158
Policy Update Magnitude: 0.55087
Value Function Update Magnitude: 0.59799

Collected Steps per Second: 22,069.16313
Overall Steps per Second: 10,420.56038

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.53422
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.80128

Cumulative Model Updates: 85,630
Cumulative Timesteps: 714,161,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,368.39353
Policy Entropy: 1.86696
Value Function Loss: 0.07892

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.17970
Policy Update Magnitude: 0.46459
Value Function Update Magnitude: 0.59504

Collected Steps per Second: 21,055.39715
Overall Steps per Second: 10,145.40626

Timestep Collection Time: 2.37507
Timestep Consumption Time: 2.55406
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.92913

Cumulative Model Updates: 85,636
Cumulative Timesteps: 714,211,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 714211130...
Checkpoint 714211130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,711.42062
Policy Entropy: 1.86873
Value Function Loss: 0.07317

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15360
Policy Update Magnitude: 0.45483
Value Function Update Magnitude: 0.64837

Collected Steps per Second: 20,703.57921
Overall Steps per Second: 10,073.13822

Timestep Collection Time: 2.41765
Timestep Consumption Time: 2.55141
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.96906

Cumulative Model Updates: 85,642
Cumulative Timesteps: 714,261,184

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,581.99999
Policy Entropy: 1.86542
Value Function Loss: 0.08172

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.47306
Value Function Update Magnitude: 0.64650

Collected Steps per Second: 20,893.35752
Overall Steps per Second: 10,077.18954

Timestep Collection Time: 2.39358
Timestep Consumption Time: 2.56911
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.96269

Cumulative Model Updates: 85,648
Cumulative Timesteps: 714,311,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 714311194...
Checkpoint 714311194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,146.78839
Policy Entropy: 1.87078
Value Function Loss: 0.08583

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.16370
Policy Update Magnitude: 0.49466
Value Function Update Magnitude: 0.50798

Collected Steps per Second: 21,550.60808
Overall Steps per Second: 10,219.58480

Timestep Collection Time: 2.32114
Timestep Consumption Time: 2.57358
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.89472

Cumulative Model Updates: 85,654
Cumulative Timesteps: 714,361,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,064.16037
Policy Entropy: 1.89130
Value Function Loss: 0.09782

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.52735
Value Function Update Magnitude: 0.41844

Collected Steps per Second: 21,391.21781
Overall Steps per Second: 10,377.27611

Timestep Collection Time: 2.33816
Timestep Consumption Time: 2.48161
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.81976

Cumulative Model Updates: 85,660
Cumulative Timesteps: 714,411,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 714411232...
Checkpoint 714411232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,973.64195
Policy Entropy: 1.89106
Value Function Loss: 0.09878

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.54882
Value Function Update Magnitude: 0.33697

Collected Steps per Second: 19,765.38431
Overall Steps per Second: 9,840.31773

Timestep Collection Time: 2.53180
Timestep Consumption Time: 2.55360
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 5.08540

Cumulative Model Updates: 85,666
Cumulative Timesteps: 714,461,274

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,605.36963
Policy Entropy: 1.88183
Value Function Loss: 0.09744

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.29436

Collected Steps per Second: 20,628.36789
Overall Steps per Second: 10,067.08876

Timestep Collection Time: 2.42433
Timestep Consumption Time: 2.54334
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.96767

Cumulative Model Updates: 85,672
Cumulative Timesteps: 714,511,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 714511284...
Checkpoint 714511284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,798.90006
Policy Entropy: 1.86882
Value Function Loss: 0.09786

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.28573

Collected Steps per Second: 20,661.27651
Overall Steps per Second: 10,205.20188

Timestep Collection Time: 2.42095
Timestep Consumption Time: 2.48047
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.90142

Cumulative Model Updates: 85,678
Cumulative Timesteps: 714,561,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,498.43361
Policy Entropy: 1.88079
Value Function Loss: 0.09632

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.42040

Collected Steps per Second: 21,018.12136
Overall Steps per Second: 10,073.47160

Timestep Collection Time: 2.37928
Timestep Consumption Time: 2.58505
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.96433

Cumulative Model Updates: 85,684
Cumulative Timesteps: 714,611,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 714611312...
Checkpoint 714611312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,129.46239
Policy Entropy: 1.90521
Value Function Loss: 0.09063

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15981
Policy Update Magnitude: 0.49494
Value Function Update Magnitude: 0.57662

Collected Steps per Second: 21,720.01862
Overall Steps per Second: 10,347.63841

Timestep Collection Time: 2.30304
Timestep Consumption Time: 2.53111
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.83415

Cumulative Model Updates: 85,690
Cumulative Timesteps: 714,661,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,574.68568
Policy Entropy: 1.89942
Value Function Loss: 0.09002

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.16228
Policy Update Magnitude: 0.49657
Value Function Update Magnitude: 0.60431

Collected Steps per Second: 20,842.12705
Overall Steps per Second: 10,039.42869

Timestep Collection Time: 2.40110
Timestep Consumption Time: 2.58365
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.98475

Cumulative Model Updates: 85,696
Cumulative Timesteps: 714,711,378

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 714711378...
Checkpoint 714711378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,069.39413
Policy Entropy: 1.89308
Value Function Loss: 0.09064

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15751
Policy Update Magnitude: 0.53659
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 21,189.39368
Overall Steps per Second: 10,232.52982

Timestep Collection Time: 2.36043
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.88794

Cumulative Model Updates: 85,702
Cumulative Timesteps: 714,761,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,111.55261
Policy Entropy: 1.87374
Value Function Loss: 0.09702

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.55904
Value Function Update Magnitude: 0.47694

Collected Steps per Second: 21,744.98601
Overall Steps per Second: 10,367.95247

Timestep Collection Time: 2.30067
Timestep Consumption Time: 2.52459
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.82525

Cumulative Model Updates: 85,708
Cumulative Timesteps: 714,811,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 714811422...
Checkpoint 714811422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,366.60580
Policy Entropy: 1.87417
Value Function Loss: 0.09303

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.57804
Value Function Update Magnitude: 0.47479

Collected Steps per Second: 21,419.65682
Overall Steps per Second: 10,309.41862

Timestep Collection Time: 2.33477
Timestep Consumption Time: 2.51613
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.85090

Cumulative Model Updates: 85,714
Cumulative Timesteps: 714,861,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,508.51623
Policy Entropy: 1.88166
Value Function Loss: 0.09198

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.48905

Collected Steps per Second: 22,060.87680
Overall Steps per Second: 10,349.94564

Timestep Collection Time: 2.26754
Timestep Consumption Time: 2.56572
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.83326

Cumulative Model Updates: 85,720
Cumulative Timesteps: 714,911,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 714911456...
Checkpoint 714911456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,916.24283
Policy Entropy: 1.88289
Value Function Loss: 0.08814

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.57401
Value Function Update Magnitude: 0.48683

Collected Steps per Second: 21,535.72471
Overall Steps per Second: 10,368.85353

Timestep Collection Time: 2.32228
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.82329

Cumulative Model Updates: 85,726
Cumulative Timesteps: 714,961,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,474.69683
Policy Entropy: 1.87558
Value Function Loss: 0.08881

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.56886
Value Function Update Magnitude: 0.49459

Collected Steps per Second: 21,481.55227
Overall Steps per Second: 10,298.85830

Timestep Collection Time: 2.32944
Timestep Consumption Time: 2.52935
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.85879

Cumulative Model Updates: 85,732
Cumulative Timesteps: 715,011,508

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 715011508...
Checkpoint 715011508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,944.84937
Policy Entropy: 1.87103
Value Function Loss: 0.08743

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.52525

Collected Steps per Second: 21,577.16226
Overall Steps per Second: 10,394.36444

Timestep Collection Time: 2.31791
Timestep Consumption Time: 2.49373
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.81165

Cumulative Model Updates: 85,738
Cumulative Timesteps: 715,061,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,326.91400
Policy Entropy: 1.86901
Value Function Loss: 0.08406

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.53850

Collected Steps per Second: 22,540.92384
Overall Steps per Second: 10,619.50158

Timestep Collection Time: 2.21819
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.70832

Cumulative Model Updates: 85,744
Cumulative Timesteps: 715,111,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 715111522...
Checkpoint 715111522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,685.08045
Policy Entropy: 1.86201
Value Function Loss: 0.08503

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.58382

Collected Steps per Second: 21,516.57153
Overall Steps per Second: 10,284.19221

Timestep Collection Time: 2.32435
Timestep Consumption Time: 2.53865
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.86300

Cumulative Model Updates: 85,750
Cumulative Timesteps: 715,161,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,266.81635
Policy Entropy: 1.86369
Value Function Loss: 0.08393

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.56740
Value Function Update Magnitude: 0.66283

Collected Steps per Second: 22,022.57587
Overall Steps per Second: 10,444.30964

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.51851
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.79036

Cumulative Model Updates: 85,756
Cumulative Timesteps: 715,211,566

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 715211566...
Checkpoint 715211566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,022.26405
Policy Entropy: 1.86700
Value Function Loss: 0.08751

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.70335

Collected Steps per Second: 22,104.32268
Overall Steps per Second: 10,629.52303

Timestep Collection Time: 2.26245
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.70482

Cumulative Model Updates: 85,762
Cumulative Timesteps: 715,261,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,630.29101
Policy Entropy: 1.86558
Value Function Loss: 0.08095

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.16448
Policy Update Magnitude: 0.48836
Value Function Update Magnitude: 0.71523

Collected Steps per Second: 21,377.22928
Overall Steps per Second: 10,467.80416

Timestep Collection Time: 2.34081
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.78037

Cumulative Model Updates: 85,768
Cumulative Timesteps: 715,311,616

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 715311616...
Checkpoint 715311616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,220.67272
Policy Entropy: 1.85857
Value Function Loss: 0.08207

Mean KL Divergence: 0.02881
SB3 Clip Fraction: 0.20080
Policy Update Magnitude: 0.43924
Value Function Update Magnitude: 0.71527

Collected Steps per Second: 20,576.12491
Overall Steps per Second: 10,251.26128

Timestep Collection Time: 2.43020
Timestep Consumption Time: 2.44764
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.87784

Cumulative Model Updates: 85,774
Cumulative Timesteps: 715,361,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,281.08598
Policy Entropy: 1.85842
Value Function Loss: 0.07677

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.18594
Policy Update Magnitude: 0.49072
Value Function Update Magnitude: 0.74443

Collected Steps per Second: 21,499.16573
Overall Steps per Second: 10,428.20923

Timestep Collection Time: 2.32623
Timestep Consumption Time: 2.46961
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.79584

Cumulative Model Updates: 85,780
Cumulative Timesteps: 715,411,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 715411632...
Checkpoint 715411632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,331.63987
Policy Entropy: 1.86598
Value Function Loss: 0.07855

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.52678
Value Function Update Magnitude: 0.73392

Collected Steps per Second: 20,953.04687
Overall Steps per Second: 10,297.22107

Timestep Collection Time: 2.38667
Timestep Consumption Time: 2.46979
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.85646

Cumulative Model Updates: 85,786
Cumulative Timesteps: 715,461,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,733.78732
Policy Entropy: 1.86752
Value Function Loss: 0.07573

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.71030

Collected Steps per Second: 21,223.33719
Overall Steps per Second: 10,353.38716

Timestep Collection Time: 2.35703
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.83166

Cumulative Model Updates: 85,792
Cumulative Timesteps: 715,511,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 715511664...
Checkpoint 715511664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,837.68984
Policy Entropy: 1.87131
Value Function Loss: 0.07495

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14464
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.70871

Collected Steps per Second: 20,758.55687
Overall Steps per Second: 10,301.98361

Timestep Collection Time: 2.40932
Timestep Consumption Time: 2.44547
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.85479

Cumulative Model Updates: 85,798
Cumulative Timesteps: 715,561,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,822.04133
Policy Entropy: 1.87367
Value Function Loss: 0.08230

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.56041
Value Function Update Magnitude: 0.74354

Collected Steps per Second: 21,260.83621
Overall Steps per Second: 10,421.74924

Timestep Collection Time: 2.35184
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.79785

Cumulative Model Updates: 85,804
Cumulative Timesteps: 715,611,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 715611680...
Checkpoint 715611680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,883.09359
Policy Entropy: 1.87317
Value Function Loss: 0.08249

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.74856

Collected Steps per Second: 20,975.63243
Overall Steps per Second: 9,911.40701

Timestep Collection Time: 2.38400
Timestep Consumption Time: 2.66129
PPO Batch Consumption Time: 0.31513
Total Iteration Time: 5.04530

Cumulative Model Updates: 85,810
Cumulative Timesteps: 715,661,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,420.05955
Policy Entropy: 1.88400
Value Function Loss: 0.08512

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.70897

Collected Steps per Second: 20,394.12609
Overall Steps per Second: 10,073.25369

Timestep Collection Time: 2.45296
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.96622

Cumulative Model Updates: 85,816
Cumulative Timesteps: 715,711,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 715711712...
Checkpoint 715711712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,035.86235
Policy Entropy: 1.88431
Value Function Loss: 0.08590

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.59576

Collected Steps per Second: 19,535.46794
Overall Steps per Second: 9,809.35200

Timestep Collection Time: 2.56068
Timestep Consumption Time: 2.53895
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 5.09962

Cumulative Model Updates: 85,822
Cumulative Timesteps: 715,761,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,476.23791
Policy Entropy: 1.87982
Value Function Loss: 0.08553

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.56489
Value Function Update Magnitude: 0.67486

Collected Steps per Second: 21,809.23272
Overall Steps per Second: 10,487.62225

Timestep Collection Time: 2.29435
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.77115

Cumulative Model Updates: 85,828
Cumulative Timesteps: 715,811,774

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 715811774...
Checkpoint 715811774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,452.70850
Policy Entropy: 1.87818
Value Function Loss: 0.08163

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.75471

Collected Steps per Second: 19,803.20780
Overall Steps per Second: 9,753.55334

Timestep Collection Time: 2.52606
Timestep Consumption Time: 2.60274
PPO Batch Consumption Time: 0.31042
Total Iteration Time: 5.12880

Cumulative Model Updates: 85,834
Cumulative Timesteps: 715,861,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,234.38633
Policy Entropy: 1.87304
Value Function Loss: 0.07977

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.55198
Value Function Update Magnitude: 0.76411

Collected Steps per Second: 19,127.78509
Overall Steps per Second: 9,851.20710

Timestep Collection Time: 2.61431
Timestep Consumption Time: 2.46182
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 5.07613

Cumulative Model Updates: 85,840
Cumulative Timesteps: 715,911,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 715911804...
Checkpoint 715911804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,802.06356
Policy Entropy: 1.87587
Value Function Loss: 0.07840

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.55135
Value Function Update Magnitude: 0.76114

Collected Steps per Second: 19,351.08330
Overall Steps per Second: 9,851.73451

Timestep Collection Time: 2.58466
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 5.07687

Cumulative Model Updates: 85,846
Cumulative Timesteps: 715,961,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,700.80757
Policy Entropy: 1.86422
Value Function Loss: 0.07915

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.55606
Value Function Update Magnitude: 0.73202

Collected Steps per Second: 20,220.44531
Overall Steps per Second: 9,874.06705

Timestep Collection Time: 2.47324
Timestep Consumption Time: 2.59154
PPO Batch Consumption Time: 0.31393
Total Iteration Time: 5.06478

Cumulative Model Updates: 85,852
Cumulative Timesteps: 716,011,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 716011830...
Checkpoint 716011830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,368.42939
Policy Entropy: 1.87058
Value Function Loss: 0.08427

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.71232

Collected Steps per Second: 19,049.57135
Overall Steps per Second: 9,757.37394

Timestep Collection Time: 2.62547
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 5.12576

Cumulative Model Updates: 85,858
Cumulative Timesteps: 716,061,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,955.47523
Policy Entropy: 1.86731
Value Function Loss: 0.08678

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.66272

Collected Steps per Second: 20,126.64425
Overall Steps per Second: 9,820.51789

Timestep Collection Time: 2.48556
Timestep Consumption Time: 2.60847
PPO Batch Consumption Time: 0.30247
Total Iteration Time: 5.09403

Cumulative Model Updates: 85,864
Cumulative Timesteps: 716,111,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 716111870...
Checkpoint 716111870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,566.50509
Policy Entropy: 1.87123
Value Function Loss: 0.08719

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.62616

Collected Steps per Second: 19,019.76124
Overall Steps per Second: 9,763.80941

Timestep Collection Time: 2.62948
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 5.12218

Cumulative Model Updates: 85,870
Cumulative Timesteps: 716,161,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,760.61997
Policy Entropy: 1.87332
Value Function Loss: 0.08596

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.57883

Collected Steps per Second: 20,305.44805
Overall Steps per Second: 9,934.87510

Timestep Collection Time: 2.46328
Timestep Consumption Time: 2.57131
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 5.03459

Cumulative Model Updates: 85,876
Cumulative Timesteps: 716,211,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 716211900...
Checkpoint 716211900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,138.39441
Policy Entropy: 1.86795
Value Function Loss: 0.08085

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.61954

Collected Steps per Second: 21,561.09056
Overall Steps per Second: 10,157.06299

Timestep Collection Time: 2.31936
Timestep Consumption Time: 2.60411
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.92347

Cumulative Model Updates: 85,882
Cumulative Timesteps: 716,261,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,932.62749
Policy Entropy: 1.88062
Value Function Loss: 0.08004

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.56031
Value Function Update Magnitude: 0.61850

Collected Steps per Second: 21,907.92006
Overall Steps per Second: 10,338.81331

Timestep Collection Time: 2.28274
Timestep Consumption Time: 2.55438
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.83711

Cumulative Model Updates: 85,888
Cumulative Timesteps: 716,311,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 716311918...
Checkpoint 716311918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,499.51105
Policy Entropy: 1.87156
Value Function Loss: 0.07752

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.68822

Collected Steps per Second: 18,916.41213
Overall Steps per Second: 9,466.59893

Timestep Collection Time: 2.64331
Timestep Consumption Time: 2.63863
PPO Batch Consumption Time: 0.30153
Total Iteration Time: 5.28194

Cumulative Model Updates: 85,894
Cumulative Timesteps: 716,361,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,294.79433
Policy Entropy: 1.87054
Value Function Loss: 0.07618

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.72532

Collected Steps per Second: 15,901.22691
Overall Steps per Second: 7,805.27178

Timestep Collection Time: 3.14630
Timestep Consumption Time: 3.26347
PPO Batch Consumption Time: 0.38953
Total Iteration Time: 6.40977

Cumulative Model Updates: 85,900
Cumulative Timesteps: 716,411,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 716411950...
Checkpoint 716411950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,973.06513
Policy Entropy: 1.86064
Value Function Loss: 0.07655

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.54900
Value Function Update Magnitude: 0.70438

Collected Steps per Second: 14,680.73479
Overall Steps per Second: 7,350.32287

Timestep Collection Time: 3.40882
Timestep Consumption Time: 3.39959
PPO Batch Consumption Time: 0.43583
Total Iteration Time: 6.80841

Cumulative Model Updates: 85,906
Cumulative Timesteps: 716,461,994

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,688.41838
Policy Entropy: 1.86083
Value Function Loss: 0.07547

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.59162

Collected Steps per Second: 15,475.44747
Overall Steps per Second: 7,600.76094

Timestep Collection Time: 3.23286
Timestep Consumption Time: 3.34937
PPO Batch Consumption Time: 0.42701
Total Iteration Time: 6.58224

Cumulative Model Updates: 85,912
Cumulative Timesteps: 716,512,024

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 716512024...
Checkpoint 716512024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,669.44885
Policy Entropy: 1.85069
Value Function Loss: 0.08022

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.47492

Collected Steps per Second: 15,774.91876
Overall Steps per Second: 7,639.58207

Timestep Collection Time: 3.17060
Timestep Consumption Time: 3.37635
PPO Batch Consumption Time: 0.43352
Total Iteration Time: 6.54695

Cumulative Model Updates: 85,918
Cumulative Timesteps: 716,562,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,352.16491
Policy Entropy: 1.84730
Value Function Loss: 0.07734

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.54580
Value Function Update Magnitude: 0.46660

Collected Steps per Second: 16,076.41835
Overall Steps per Second: 7,625.16132

Timestep Collection Time: 3.11039
Timestep Consumption Time: 3.44737
PPO Batch Consumption Time: 0.43748
Total Iteration Time: 6.55776

Cumulative Model Updates: 85,924
Cumulative Timesteps: 716,612,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 716612044...
Checkpoint 716612044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,299.18967
Policy Entropy: 1.84302
Value Function Loss: 0.07905

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.53880
Value Function Update Magnitude: 0.44825

Collected Steps per Second: 15,712.97712
Overall Steps per Second: 7,532.47366

Timestep Collection Time: 3.18259
Timestep Consumption Time: 3.45640
PPO Batch Consumption Time: 0.44950
Total Iteration Time: 6.63899

Cumulative Model Updates: 85,930
Cumulative Timesteps: 716,662,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,623.04195
Policy Entropy: 1.85220
Value Function Loss: 0.07918

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.41552

Collected Steps per Second: 15,543.53514
Overall Steps per Second: 7,477.15398

Timestep Collection Time: 3.21741
Timestep Consumption Time: 3.47096
PPO Batch Consumption Time: 0.44722
Total Iteration Time: 6.68837

Cumulative Model Updates: 85,936
Cumulative Timesteps: 716,712,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 716712062...
Checkpoint 716712062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,087.04149
Policy Entropy: 1.84905
Value Function Loss: 0.08037

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.40238

Collected Steps per Second: 15,505.27291
Overall Steps per Second: 7,557.64190

Timestep Collection Time: 3.22742
Timestep Consumption Time: 3.39396
PPO Batch Consumption Time: 0.43783
Total Iteration Time: 6.62138

Cumulative Model Updates: 85,942
Cumulative Timesteps: 716,762,104

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,565.83971
Policy Entropy: 1.84758
Value Function Loss: 0.07646

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.41627

Collected Steps per Second: 15,122.41962
Overall Steps per Second: 7,059.63205

Timestep Collection Time: 3.30635
Timestep Consumption Time: 3.77617
PPO Batch Consumption Time: 0.49450
Total Iteration Time: 7.08252

Cumulative Model Updates: 85,948
Cumulative Timesteps: 716,812,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 716812104...
Checkpoint 716812104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,509.55430
Policy Entropy: 1.85318
Value Function Loss: 0.08220

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.41179

Collected Steps per Second: 15,359.30197
Overall Steps per Second: 7,090.36308

Timestep Collection Time: 3.25562
Timestep Consumption Time: 3.79677
PPO Batch Consumption Time: 0.50442
Total Iteration Time: 7.05239

Cumulative Model Updates: 85,954
Cumulative Timesteps: 716,862,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,564.71365
Policy Entropy: 1.85721
Value Function Loss: 0.07945

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.40891

Collected Steps per Second: 15,153.11791
Overall Steps per Second: 7,387.71382

Timestep Collection Time: 3.30018
Timestep Consumption Time: 3.46890
PPO Batch Consumption Time: 0.44444
Total Iteration Time: 6.76908

Cumulative Model Updates: 85,960
Cumulative Timesteps: 716,912,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 716912116...
Checkpoint 716912116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,263.70382
Policy Entropy: 1.85665
Value Function Loss: 0.08496

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.51875
Value Function Update Magnitude: 0.40649

Collected Steps per Second: 15,434.59511
Overall Steps per Second: 7,423.88030

Timestep Collection Time: 3.24116
Timestep Consumption Time: 3.49736
PPO Batch Consumption Time: 0.45038
Total Iteration Time: 6.73852

Cumulative Model Updates: 85,966
Cumulative Timesteps: 716,962,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,784.38140
Policy Entropy: 1.86037
Value Function Loss: 0.08722

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.44852

Collected Steps per Second: 15,879.29980
Overall Steps per Second: 7,469.18617

Timestep Collection Time: 3.15115
Timestep Consumption Time: 3.54811
PPO Batch Consumption Time: 0.46057
Total Iteration Time: 6.69926

Cumulative Model Updates: 85,972
Cumulative Timesteps: 717,012,180

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 717012180...
Checkpoint 717012180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,991.83836
Policy Entropy: 1.86633
Value Function Loss: 0.09006

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.56506
Value Function Update Magnitude: 0.46339

Collected Steps per Second: 14,466.26372
Overall Steps per Second: 7,106.57418

Timestep Collection Time: 3.45798
Timestep Consumption Time: 3.58114
PPO Batch Consumption Time: 0.46910
Total Iteration Time: 7.03912

Cumulative Model Updates: 85,978
Cumulative Timesteps: 717,062,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,608.57855
Policy Entropy: 1.87304
Value Function Loss: 0.08447

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.46721

Collected Steps per Second: 15,209.65058
Overall Steps per Second: 7,002.63076

Timestep Collection Time: 3.28739
Timestep Consumption Time: 3.85279
PPO Batch Consumption Time: 0.50797
Total Iteration Time: 7.14017

Cumulative Model Updates: 85,984
Cumulative Timesteps: 717,112,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 717112204...
Checkpoint 717112204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,790.13214
Policy Entropy: 1.85923
Value Function Loss: 0.08326

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.54998
Value Function Update Magnitude: 0.44351

Collected Steps per Second: 14,837.73354
Overall Steps per Second: 7,074.55078

Timestep Collection Time: 3.37127
Timestep Consumption Time: 3.69943
PPO Batch Consumption Time: 0.48679
Total Iteration Time: 7.07070

Cumulative Model Updates: 85,990
Cumulative Timesteps: 717,162,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,082.44119
Policy Entropy: 1.83792
Value Function Loss: 0.07964

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.45689

Collected Steps per Second: 15,374.68912
Overall Steps per Second: 7,332.58044

Timestep Collection Time: 3.25353
Timestep Consumption Time: 3.56835
PPO Batch Consumption Time: 0.45529
Total Iteration Time: 6.82188

Cumulative Model Updates: 85,996
Cumulative Timesteps: 717,212,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 717212248...
Checkpoint 717212248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,755.57773
Policy Entropy: 1.83882
Value Function Loss: 0.08121

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.45345

Collected Steps per Second: 14,747.68908
Overall Steps per Second: 7,225.45795

Timestep Collection Time: 3.39145
Timestep Consumption Time: 3.53074
PPO Batch Consumption Time: 0.46051
Total Iteration Time: 6.92219

Cumulative Model Updates: 86,002
Cumulative Timesteps: 717,262,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,709.62972
Policy Entropy: 1.82313
Value Function Loss: 0.08090

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.53364
Value Function Update Magnitude: 0.48034

Collected Steps per Second: 15,272.16852
Overall Steps per Second: 7,282.08960

Timestep Collection Time: 3.27576
Timestep Consumption Time: 3.59424
PPO Batch Consumption Time: 0.46811
Total Iteration Time: 6.87001

Cumulative Model Updates: 86,008
Cumulative Timesteps: 717,312,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 717312292...
Checkpoint 717312292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,203.27857
Policy Entropy: 1.83409
Value Function Loss: 0.08623

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.48077

Collected Steps per Second: 15,847.11394
Overall Steps per Second: 7,408.10514

Timestep Collection Time: 3.15641
Timestep Consumption Time: 3.59565
PPO Batch Consumption Time: 0.47108
Total Iteration Time: 6.75206

Cumulative Model Updates: 86,014
Cumulative Timesteps: 717,362,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,010.71412
Policy Entropy: 1.82435
Value Function Loss: 0.08303

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.56775
Value Function Update Magnitude: 0.53794

Collected Steps per Second: 15,255.55107
Overall Steps per Second: 7,504.36350

Timestep Collection Time: 3.27802
Timestep Consumption Time: 3.38584
PPO Batch Consumption Time: 0.45127
Total Iteration Time: 6.66386

Cumulative Model Updates: 86,020
Cumulative Timesteps: 717,412,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 717412320...
Checkpoint 717412320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,650.47506
Policy Entropy: 1.83793
Value Function Loss: 0.07320

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.56229
Value Function Update Magnitude: 0.69862

Collected Steps per Second: 14,891.47425
Overall Steps per Second: 7,257.90397

Timestep Collection Time: 3.35964
Timestep Consumption Time: 3.53353
PPO Batch Consumption Time: 0.47423
Total Iteration Time: 6.89317

Cumulative Model Updates: 86,026
Cumulative Timesteps: 717,462,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,681.90782
Policy Entropy: 1.83429
Value Function Loss: 0.07378

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.68042

Collected Steps per Second: 15,578.29532
Overall Steps per Second: 7,500.71957

Timestep Collection Time: 3.21113
Timestep Consumption Time: 3.45809
PPO Batch Consumption Time: 0.45972
Total Iteration Time: 6.66923

Cumulative Model Updates: 86,032
Cumulative Timesteps: 717,512,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 717512374...
Checkpoint 717512374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,894.83748
Policy Entropy: 1.82966
Value Function Loss: 0.07975

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.16434
Policy Update Magnitude: 0.50601
Value Function Update Magnitude: 0.67320

Collected Steps per Second: 15,383.16061
Overall Steps per Second: 7,539.33994

Timestep Collection Time: 3.25083
Timestep Consumption Time: 3.38211
PPO Batch Consumption Time: 0.44945
Total Iteration Time: 6.63294

Cumulative Model Updates: 86,038
Cumulative Timesteps: 717,562,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,690.48565
Policy Entropy: 1.81632
Value Function Loss: 0.07853

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.17768
Policy Update Magnitude: 0.49750
Value Function Update Magnitude: 0.73726

Collected Steps per Second: 14,905.60222
Overall Steps per Second: 7,130.80529

Timestep Collection Time: 3.35485
Timestep Consumption Time: 3.65783
PPO Batch Consumption Time: 0.49521
Total Iteration Time: 7.01267

Cumulative Model Updates: 86,044
Cumulative Timesteps: 717,612,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 717612388...
Checkpoint 717612388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,058.69796
Policy Entropy: 1.81062
Value Function Loss: 0.08064

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.16322
Policy Update Magnitude: 0.51052
Value Function Update Magnitude: 0.76186

Collected Steps per Second: 14,963.23840
Overall Steps per Second: 7,295.16152

Timestep Collection Time: 3.34339
Timestep Consumption Time: 3.51430
PPO Batch Consumption Time: 0.47144
Total Iteration Time: 6.85770

Cumulative Model Updates: 86,050
Cumulative Timesteps: 717,662,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,564.27858
Policy Entropy: 1.81392
Value Function Loss: 0.07484

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.74265

Collected Steps per Second: 14,745.46862
Overall Steps per Second: 7,357.62726

Timestep Collection Time: 3.39155
Timestep Consumption Time: 3.40548
PPO Batch Consumption Time: 0.45089
Total Iteration Time: 6.79703

Cumulative Model Updates: 86,056
Cumulative Timesteps: 717,712,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 717712426...
Checkpoint 717712426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,467.08982
Policy Entropy: 1.80372
Value Function Loss: 0.07665

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.72016

Collected Steps per Second: 15,269.94912
Overall Steps per Second: 7,298.97370

Timestep Collection Time: 3.27742
Timestep Consumption Time: 3.57916
PPO Batch Consumption Time: 0.47070
Total Iteration Time: 6.85658

Cumulative Model Updates: 86,062
Cumulative Timesteps: 717,762,472

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,463.50786
Policy Entropy: 1.80601
Value Function Loss: 0.07255

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.55620
Value Function Update Magnitude: 0.65751

Collected Steps per Second: 15,173.07091
Overall Steps per Second: 7,222.38409

Timestep Collection Time: 3.29716
Timestep Consumption Time: 3.62964
PPO Batch Consumption Time: 0.47840
Total Iteration Time: 6.92680

Cumulative Model Updates: 86,068
Cumulative Timesteps: 717,812,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 717812500...
Checkpoint 717812500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,311.32079
Policy Entropy: 1.80311
Value Function Loss: 0.07325

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.54734
Value Function Update Magnitude: 0.66009

Collected Steps per Second: 14,927.12221
Overall Steps per Second: 7,225.68354

Timestep Collection Time: 3.35189
Timestep Consumption Time: 3.57258
PPO Batch Consumption Time: 0.46898
Total Iteration Time: 6.92447

Cumulative Model Updates: 86,074
Cumulative Timesteps: 717,862,534

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,300.10429
Policy Entropy: 1.80511
Value Function Loss: 0.07581

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.16614
Policy Update Magnitude: 0.49876
Value Function Update Magnitude: 0.72091

Collected Steps per Second: 16,355.25498
Overall Steps per Second: 8,696.35060

Timestep Collection Time: 3.05712
Timestep Consumption Time: 2.69242
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 5.74954

Cumulative Model Updates: 86,080
Cumulative Timesteps: 717,912,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 717912534...
Checkpoint 717912534 saved!
