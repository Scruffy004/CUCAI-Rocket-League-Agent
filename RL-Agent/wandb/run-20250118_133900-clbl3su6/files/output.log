Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,381.04041
Policy Entropy: 1.84933
Value Function Loss: 0.11505

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01282
Policy Update Magnitude: 0.19510
Value Function Update Magnitude: 0.17114

Collected Steps per Second: 6,836.93108
Overall Steps per Second: 4,639.15712

Timestep Collection Time: 7.31761
Timestep Consumption Time: 3.46668
PPO Batch Consumption Time: 1.32834
Total Iteration Time: 10.78429

Cumulative Model Updates: 75,990
Cumulative Timesteps: 633,731,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,946.38592
Policy Entropy: 1.78187
Value Function Loss: 0.09854

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.40646
Value Function Update Magnitude: 0.30357

Collected Steps per Second: 21,982.66655
Overall Steps per Second: 12,115.82001

Timestep Collection Time: 2.27561
Timestep Consumption Time: 1.85321
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.12882

Cumulative Model Updates: 75,994
Cumulative Timesteps: 633,781,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 633781248...
Checkpoint 633781248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,812.45608
Policy Entropy: 1.75336
Value Function Loss: 0.10432

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.61746
Value Function Update Magnitude: 0.41551

Collected Steps per Second: 20,872.42916
Overall Steps per Second: 10,551.98748

Timestep Collection Time: 2.39694
Timestep Consumption Time: 2.34435
PPO Batch Consumption Time: 0.27505
Total Iteration Time: 4.74129

Cumulative Model Updates: 76,000
Cumulative Timesteps: 633,831,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,057.76193
Policy Entropy: 1.69807
Value Function Loss: 0.09662

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.59942
Value Function Update Magnitude: 0.44769

Collected Steps per Second: 21,936.83164
Overall Steps per Second: 10,584.65233

Timestep Collection Time: 2.28027
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.72590

Cumulative Model Updates: 76,006
Cumulative Timesteps: 633,881,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 633881300...
Checkpoint 633881300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,626.82874
Policy Entropy: 1.69309
Value Function Loss: 0.10187

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.57460
Value Function Update Magnitude: 0.40589

Collected Steps per Second: 21,338.69059
Overall Steps per Second: 10,540.83653

Timestep Collection Time: 2.34429
Timestep Consumption Time: 2.40145
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.74573

Cumulative Model Updates: 76,012
Cumulative Timesteps: 633,931,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,911.14640
Policy Entropy: 1.67402
Value Function Loss: 0.10223

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.40514

Collected Steps per Second: 21,712.47341
Overall Steps per Second: 10,362.33364

Timestep Collection Time: 2.30513
Timestep Consumption Time: 2.52487
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.82999

Cumulative Model Updates: 76,018
Cumulative Timesteps: 633,981,374

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 633981374...
Checkpoint 633981374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,061.94063
Policy Entropy: 1.66945
Value Function Loss: 0.10730

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.15064
Policy Update Magnitude: 0.58349
Value Function Update Magnitude: 0.46794

Collected Steps per Second: 21,214.74948
Overall Steps per Second: 10,369.57464

Timestep Collection Time: 2.35770
Timestep Consumption Time: 2.46584
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.82353

Cumulative Model Updates: 76,024
Cumulative Timesteps: 634,031,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,689.55549
Policy Entropy: 1.64723
Value Function Loss: 0.10951

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.17213
Policy Update Magnitude: 0.57235
Value Function Update Magnitude: 0.43709

Collected Steps per Second: 22,371.69896
Overall Steps per Second: 10,793.15135

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.39770
PPO Batch Consumption Time: 0.27634
Total Iteration Time: 4.63275

Cumulative Model Updates: 76,030
Cumulative Timesteps: 634,081,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 634081394...
Checkpoint 634081394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,112.31638
Policy Entropy: 1.64287
Value Function Loss: 0.10756

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.17943
Policy Update Magnitude: 0.56810
Value Function Update Magnitude: 0.36996

Collected Steps per Second: 21,928.86169
Overall Steps per Second: 10,691.62376

Timestep Collection Time: 2.28211
Timestep Consumption Time: 2.39857
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.68067

Cumulative Model Updates: 76,036
Cumulative Timesteps: 634,131,438

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,910.92798
Policy Entropy: 1.64014
Value Function Loss: 0.10504

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.18858
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.39173

Collected Steps per Second: 22,797.40424
Overall Steps per Second: 10,920.02582

Timestep Collection Time: 2.19367
Timestep Consumption Time: 2.38599
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.57966

Cumulative Model Updates: 76,042
Cumulative Timesteps: 634,181,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 634181448...
Checkpoint 634181448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,463.23705
Policy Entropy: 1.62602
Value Function Loss: 0.09923

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.18058
Policy Update Magnitude: 0.56751
Value Function Update Magnitude: 0.55527

Collected Steps per Second: 21,906.34386
Overall Steps per Second: 10,608.97132

Timestep Collection Time: 2.28482
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.71789

Cumulative Model Updates: 76,048
Cumulative Timesteps: 634,231,500

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,117.78304
Policy Entropy: 1.63292
Value Function Loss: 0.10137

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.16536
Policy Update Magnitude: 0.57871
Value Function Update Magnitude: 0.49636

Collected Steps per Second: 22,536.84654
Overall Steps per Second: 10,871.04858

Timestep Collection Time: 2.21939
Timestep Consumption Time: 2.38164
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.60103

Cumulative Model Updates: 76,054
Cumulative Timesteps: 634,281,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 634281518...
Checkpoint 634281518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,166.85141
Policy Entropy: 1.62424
Value Function Loss: 0.10274

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.18270
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.62889

Collected Steps per Second: 22,577.04448
Overall Steps per Second: 10,564.24470

Timestep Collection Time: 2.21499
Timestep Consumption Time: 2.51871
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.73370

Cumulative Model Updates: 76,060
Cumulative Timesteps: 634,331,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,852.00481
Policy Entropy: 1.62062
Value Function Loss: 0.10075

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.18241
Policy Update Magnitude: 0.48485
Value Function Update Magnitude: 0.68347

Collected Steps per Second: 21,979.15997
Overall Steps per Second: 10,486.30568

Timestep Collection Time: 2.27506
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.76850

Cumulative Model Updates: 76,066
Cumulative Timesteps: 634,381,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 634381530...
Checkpoint 634381530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,130.67398
Policy Entropy: 1.61405
Value Function Loss: 0.10227

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.53034
Value Function Update Magnitude: 0.54221

Collected Steps per Second: 22,298.38061
Overall Steps per Second: 10,724.62011

Timestep Collection Time: 2.24232
Timestep Consumption Time: 2.41985
PPO Batch Consumption Time: 0.27615
Total Iteration Time: 4.66217

Cumulative Model Updates: 76,072
Cumulative Timesteps: 634,431,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,690.40052
Policy Entropy: 1.61773
Value Function Loss: 0.10700

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.16661
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.65929

Collected Steps per Second: 22,327.51537
Overall Steps per Second: 10,510.89595

Timestep Collection Time: 2.24029
Timestep Consumption Time: 2.51859
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.75887

Cumulative Model Updates: 76,078
Cumulative Timesteps: 634,481,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 634481550...
Checkpoint 634481550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,128.66605
Policy Entropy: 1.62419
Value Function Loss: 0.10509

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.17952
Policy Update Magnitude: 0.50101
Value Function Update Magnitude: 0.81542

Collected Steps per Second: 21,665.65699
Overall Steps per Second: 10,234.00253

Timestep Collection Time: 2.30817
Timestep Consumption Time: 2.57829
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 4.88646

Cumulative Model Updates: 76,084
Cumulative Timesteps: 634,531,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,191.74143
Policy Entropy: 1.63163
Value Function Loss: 0.10572

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.50941
Value Function Update Magnitude: 0.73449

Collected Steps per Second: 22,567.74825
Overall Steps per Second: 10,678.59645

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.46750
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.68376

Cumulative Model Updates: 76,090
Cumulative Timesteps: 634,581,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 634581574...
Checkpoint 634581574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,808.08973
Policy Entropy: 1.61322
Value Function Loss: 0.10883

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.17999
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 21,590.86247
Overall Steps per Second: 10,495.46139

Timestep Collection Time: 2.31820
Timestep Consumption Time: 2.45072
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.76892

Cumulative Model Updates: 76,096
Cumulative Timesteps: 634,631,626

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,772.02042
Policy Entropy: 1.60612
Value Function Loss: 0.10618

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.58662
Value Function Update Magnitude: 0.53624

Collected Steps per Second: 22,101.53039
Overall Steps per Second: 10,647.81809

Timestep Collection Time: 2.26419
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.69974

Cumulative Model Updates: 76,102
Cumulative Timesteps: 634,681,668

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 634681668...
Checkpoint 634681668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,364.06907
Policy Entropy: 1.60826
Value Function Loss: 0.10295

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.59382
Value Function Update Magnitude: 0.49986

Collected Steps per Second: 22,027.43755
Overall Steps per Second: 10,671.29740

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.41663
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.68753

Cumulative Model Updates: 76,108
Cumulative Timesteps: 634,731,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,349.43414
Policy Entropy: 1.62420
Value Function Loss: 0.10782

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.58767
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 21,915.41325
Overall Steps per Second: 10,472.69441

Timestep Collection Time: 2.28196
Timestep Consumption Time: 2.49332
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.77528

Cumulative Model Updates: 76,114
Cumulative Timesteps: 634,781,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 634781700...
Checkpoint 634781700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,961.75069
Policy Entropy: 1.63701
Value Function Loss: 0.10441

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.74310

Collected Steps per Second: 21,895.39684
Overall Steps per Second: 10,638.35331

Timestep Collection Time: 2.28441
Timestep Consumption Time: 2.41726
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.70167

Cumulative Model Updates: 76,120
Cumulative Timesteps: 634,831,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,315.47020
Policy Entropy: 1.61539
Value Function Loss: 0.10110

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.65850

Collected Steps per Second: 22,387.66026
Overall Steps per Second: 10,568.19803

Timestep Collection Time: 2.23445
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73345

Cumulative Model Updates: 76,126
Cumulative Timesteps: 634,881,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 634881742...
Checkpoint 634881742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,792.51421
Policy Entropy: 1.59690
Value Function Loss: 0.09970

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.15947
Policy Update Magnitude: 0.47541
Value Function Update Magnitude: 0.58620

Collected Steps per Second: 22,577.92758
Overall Steps per Second: 10,578.82085

Timestep Collection Time: 2.21473
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72680

Cumulative Model Updates: 76,132
Cumulative Timesteps: 634,931,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,768.13819
Policy Entropy: 1.58334
Value Function Loss: 0.09970

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.50285
Value Function Update Magnitude: 0.48332

Collected Steps per Second: 22,759.91323
Overall Steps per Second: 10,745.44996

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.65406

Cumulative Model Updates: 76,138
Cumulative Timesteps: 634,981,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 634981756...
Checkpoint 634981756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,752.94645
Policy Entropy: 1.58829
Value Function Loss: 0.09958

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.16146
Policy Update Magnitude: 0.50235
Value Function Update Magnitude: 0.56133

Collected Steps per Second: 22,269.76739
Overall Steps per Second: 10,678.46169

Timestep Collection Time: 2.24600
Timestep Consumption Time: 2.43800
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.68401

Cumulative Model Updates: 76,144
Cumulative Timesteps: 635,031,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,246.61581
Policy Entropy: 1.57678
Value Function Loss: 0.10158

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.17325
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.56797

Collected Steps per Second: 22,613.00865
Overall Steps per Second: 10,603.66009

Timestep Collection Time: 2.21200
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.71724

Cumulative Model Updates: 76,150
Cumulative Timesteps: 635,081,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 635081794...
Checkpoint 635081794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,257.60037
Policy Entropy: 1.58200
Value Function Loss: 0.11484

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.17081
Policy Update Magnitude: 0.52953
Value Function Update Magnitude: 0.53846

Collected Steps per Second: 22,227.43435
Overall Steps per Second: 10,567.42095

Timestep Collection Time: 2.25073
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.73417

Cumulative Model Updates: 76,156
Cumulative Timesteps: 635,131,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,621.32295
Policy Entropy: 1.59194
Value Function Loss: 0.12197

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.17191
Policy Update Magnitude: 0.55936
Value Function Update Magnitude: 0.48310

Collected Steps per Second: 20,902.78309
Overall Steps per Second: 10,081.53551

Timestep Collection Time: 2.39289
Timestep Consumption Time: 2.56846
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.96135

Cumulative Model Updates: 76,162
Cumulative Timesteps: 635,181,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 635181840...
Checkpoint 635181840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,477.03397
Policy Entropy: 1.58885
Value Function Loss: 0.12431

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.16688
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.50616

Collected Steps per Second: 21,883.13501
Overall Steps per Second: 10,512.05173

Timestep Collection Time: 2.28614
Timestep Consumption Time: 2.47296
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.75911

Cumulative Model Updates: 76,168
Cumulative Timesteps: 635,231,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,741.34677
Policy Entropy: 1.60291
Value Function Loss: 0.12344

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.15658
Policy Update Magnitude: 0.58980
Value Function Update Magnitude: 0.47653

Collected Steps per Second: 22,241.77712
Overall Steps per Second: 10,530.20247

Timestep Collection Time: 2.24928
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.75091

Cumulative Model Updates: 76,174
Cumulative Timesteps: 635,281,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 635281896...
Checkpoint 635281896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,074.41902
Policy Entropy: 1.60584
Value Function Loss: 0.12187

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.52026

Collected Steps per Second: 22,043.05918
Overall Steps per Second: 10,663.40270

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.68893

Cumulative Model Updates: 76,180
Cumulative Timesteps: 635,331,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,126.74678
Policy Entropy: 1.63540
Value Function Loss: 0.13012

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.17922
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.48742

Collected Steps per Second: 22,768.34024
Overall Steps per Second: 10,844.30015

Timestep Collection Time: 2.19638
Timestep Consumption Time: 2.41507
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.61145

Cumulative Model Updates: 76,186
Cumulative Timesteps: 635,381,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 635381904...
Checkpoint 635381904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,802.33015
Policy Entropy: 1.62299
Value Function Loss: 0.13529

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.19877
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.51092

Collected Steps per Second: 22,483.68126
Overall Steps per Second: 10,646.21150

Timestep Collection Time: 2.22464
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.69820

Cumulative Model Updates: 76,192
Cumulative Timesteps: 635,431,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,515.19599
Policy Entropy: 1.62882
Value Function Loss: 0.13271

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.18126
Policy Update Magnitude: 0.58428
Value Function Update Magnitude: 0.52920

Collected Steps per Second: 22,776.35470
Overall Steps per Second: 10,654.77872

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.69630

Cumulative Model Updates: 76,198
Cumulative Timesteps: 635,481,960

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 635481960...
Checkpoint 635481960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,968.78990
Policy Entropy: 1.62399
Value Function Loss: 0.11847

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15947
Policy Update Magnitude: 0.59715
Value Function Update Magnitude: 0.56879

Collected Steps per Second: 22,535.00207
Overall Steps per Second: 10,840.95016

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.39375
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61288

Cumulative Model Updates: 76,204
Cumulative Timesteps: 635,531,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,273.72817
Policy Entropy: 1.63897
Value Function Loss: 0.12450

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.16983
Policy Update Magnitude: 0.58103
Value Function Update Magnitude: 0.57441

Collected Steps per Second: 22,371.01847
Overall Steps per Second: 10,571.95301

Timestep Collection Time: 2.23593
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.73139

Cumulative Model Updates: 76,210
Cumulative Timesteps: 635,581,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 635581988...
Checkpoint 635581988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,006.70896
Policy Entropy: 1.61923
Value Function Loss: 0.12839

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.19038
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.58163

Collected Steps per Second: 21,963.77497
Overall Steps per Second: 10,585.95124

Timestep Collection Time: 2.27648
Timestep Consumption Time: 2.44677
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.72324

Cumulative Model Updates: 76,216
Cumulative Timesteps: 635,631,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,344.73589
Policy Entropy: 1.61854
Value Function Loss: 0.12953

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.18365
Policy Update Magnitude: 0.59107
Value Function Update Magnitude: 0.65644

Collected Steps per Second: 22,227.82000
Overall Steps per Second: 10,477.11630

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.52317
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.77288

Cumulative Model Updates: 76,222
Cumulative Timesteps: 635,681,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 635681994...
Checkpoint 635681994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,372.56098
Policy Entropy: 1.63251
Value Function Loss: 0.12290

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.20314
Policy Update Magnitude: 0.56672
Value Function Update Magnitude: 0.66177

Collected Steps per Second: 21,619.63933
Overall Steps per Second: 10,558.38724

Timestep Collection Time: 2.31345
Timestep Consumption Time: 2.42364
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.73709

Cumulative Model Updates: 76,228
Cumulative Timesteps: 635,732,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,665.49556
Policy Entropy: 1.65152
Value Function Loss: 0.12502

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.17292
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.52769

Collected Steps per Second: 21,979.88991
Overall Steps per Second: 10,465.49788

Timestep Collection Time: 2.27553
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.77913

Cumulative Model Updates: 76,234
Cumulative Timesteps: 635,782,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 635782026...
Checkpoint 635782026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,493.57888
Policy Entropy: 1.65722
Value Function Loss: 0.12467

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.17757
Policy Update Magnitude: 0.52388
Value Function Update Magnitude: 0.58536

Collected Steps per Second: 21,676.50908
Overall Steps per Second: 10,383.37781

Timestep Collection Time: 2.30794
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.81809

Cumulative Model Updates: 76,240
Cumulative Timesteps: 635,832,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,003.57827
Policy Entropy: 1.65407
Value Function Loss: 0.12269

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.54873

Collected Steps per Second: 22,281.52279
Overall Steps per Second: 10,531.84889

Timestep Collection Time: 2.24446
Timestep Consumption Time: 2.50399
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.74845

Cumulative Model Updates: 76,246
Cumulative Timesteps: 635,882,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 635882064...
Checkpoint 635882064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,261.59505
Policy Entropy: 1.67554
Value Function Loss: 0.11917

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.17764
Policy Update Magnitude: 0.57485
Value Function Update Magnitude: 0.49222

Collected Steps per Second: 22,473.19648
Overall Steps per Second: 10,509.98982

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.53332
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.75890

Cumulative Model Updates: 76,252
Cumulative Timesteps: 635,932,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,799.11732
Policy Entropy: 1.68072
Value Function Loss: 0.10961

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.17985
Policy Update Magnitude: 0.53030
Value Function Update Magnitude: 0.47197

Collected Steps per Second: 22,482.11447
Overall Steps per Second: 10,705.77340

Timestep Collection Time: 2.22399
Timestep Consumption Time: 2.44639
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.67038

Cumulative Model Updates: 76,258
Cumulative Timesteps: 635,982,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 635982080...
Checkpoint 635982080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,831.69973
Policy Entropy: 1.67060
Value Function Loss: 0.10473

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.17448
Policy Update Magnitude: 0.53354
Value Function Update Magnitude: 0.42961

Collected Steps per Second: 21,430.46972
Overall Steps per Second: 10,293.18246

Timestep Collection Time: 2.33443
Timestep Consumption Time: 2.52587
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.86030

Cumulative Model Updates: 76,264
Cumulative Timesteps: 636,032,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,412.65071
Policy Entropy: 1.67116
Value Function Loss: 0.10970

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16585
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.41598

Collected Steps per Second: 22,496.61503
Overall Steps per Second: 10,597.01310

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.49615
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.71907

Cumulative Model Updates: 76,270
Cumulative Timesteps: 636,082,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 636082116...
Checkpoint 636082116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,523.17848
Policy Entropy: 1.65877
Value Function Loss: 0.11253

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.16335
Policy Update Magnitude: 0.55331
Value Function Update Magnitude: 0.47480

Collected Steps per Second: 22,486.30036
Overall Steps per Second: 10,525.89056

Timestep Collection Time: 2.22482
Timestep Consumption Time: 2.52803
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.75285

Cumulative Model Updates: 76,276
Cumulative Timesteps: 636,132,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,858.53331
Policy Entropy: 1.65959
Value Function Loss: 0.10895

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.15906
Policy Update Magnitude: 0.55905
Value Function Update Magnitude: 0.48029

Collected Steps per Second: 22,463.35460
Overall Steps per Second: 10,593.51598

Timestep Collection Time: 2.22709
Timestep Consumption Time: 2.49542
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.72251

Cumulative Model Updates: 76,282
Cumulative Timesteps: 636,182,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 636182172...
Checkpoint 636182172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,888.42942
Policy Entropy: 1.67455
Value Function Loss: 0.10687

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.16309
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.56183

Collected Steps per Second: 22,166.15307
Overall Steps per Second: 10,510.30129

Timestep Collection Time: 2.25614
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.75819

Cumulative Model Updates: 76,288
Cumulative Timesteps: 636,232,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,318.20778
Policy Entropy: 1.69070
Value Function Loss: 0.10096

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.17198
Policy Update Magnitude: 0.51091
Value Function Update Magnitude: 0.63501

Collected Steps per Second: 22,094.46465
Overall Steps per Second: 10,477.23640

Timestep Collection Time: 2.26500
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.77645

Cumulative Model Updates: 76,294
Cumulative Timesteps: 636,282,226

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 636282226...
Checkpoint 636282226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,105.73350
Policy Entropy: 1.69350
Value Function Loss: 0.09569

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.50117
Value Function Update Magnitude: 0.63620

Collected Steps per Second: 21,682.48620
Overall Steps per Second: 10,619.08948

Timestep Collection Time: 2.30712
Timestep Consumption Time: 2.40365
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.71076

Cumulative Model Updates: 76,300
Cumulative Timesteps: 636,332,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,814.63726
Policy Entropy: 1.69449
Value Function Loss: 0.10067

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.15775
Policy Update Magnitude: 0.47820
Value Function Update Magnitude: 0.71070

Collected Steps per Second: 21,900.55913
Overall Steps per Second: 10,441.26791

Timestep Collection Time: 2.28332
Timestep Consumption Time: 2.50594
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.78927

Cumulative Model Updates: 76,306
Cumulative Timesteps: 636,382,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 636382256...
Checkpoint 636382256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,994.44607
Policy Entropy: 1.69689
Value Function Loss: 0.09594

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.48333
Value Function Update Magnitude: 0.77109

Collected Steps per Second: 21,653.22170
Overall Steps per Second: 10,405.69778

Timestep Collection Time: 2.30940
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.80564

Cumulative Model Updates: 76,312
Cumulative Timesteps: 636,432,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,989.49266
Policy Entropy: 1.73555
Value Function Loss: 0.10603

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15294
Policy Update Magnitude: 0.48650
Value Function Update Magnitude: 0.66778

Collected Steps per Second: 22,436.45475
Overall Steps per Second: 10,706.80860

Timestep Collection Time: 2.22967
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.67235

Cumulative Model Updates: 76,318
Cumulative Timesteps: 636,482,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 636482288...
Checkpoint 636482288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,019.31658
Policy Entropy: 1.73102
Value Function Loss: 0.11080

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.49481
Value Function Update Magnitude: 0.66517

Collected Steps per Second: 22,146.69913
Overall Steps per Second: 10,532.39563

Timestep Collection Time: 2.25912
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.75030

Cumulative Model Updates: 76,324
Cumulative Timesteps: 636,532,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,719.67060
Policy Entropy: 1.73771
Value Function Loss: 0.11570

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.73704

Collected Steps per Second: 22,493.17885
Overall Steps per Second: 10,536.26203

Timestep Collection Time: 2.22334
Timestep Consumption Time: 2.52312
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.74647

Cumulative Model Updates: 76,330
Cumulative Timesteps: 636,582,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 636582330...
Checkpoint 636582330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,466.54991
Policy Entropy: 1.71036
Value Function Loss: 0.12054

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14874
Policy Update Magnitude: 0.58525
Value Function Update Magnitude: 0.76627

Collected Steps per Second: 22,156.90790
Overall Steps per Second: 10,719.00070

Timestep Collection Time: 2.25681
Timestep Consumption Time: 2.40817
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.66499

Cumulative Model Updates: 76,336
Cumulative Timesteps: 636,632,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,553.62646
Policy Entropy: 1.72061
Value Function Loss: 0.11331

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.83117

Collected Steps per Second: 22,958.61943
Overall Steps per Second: 10,910.17812

Timestep Collection Time: 2.17783
Timestep Consumption Time: 2.40505
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.58288

Cumulative Model Updates: 76,342
Cumulative Timesteps: 636,682,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 636682334...
Checkpoint 636682334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.06624
Policy Entropy: 1.74189
Value Function Loss: 0.11579

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.72489

Collected Steps per Second: 22,515.51317
Overall Steps per Second: 10,655.58674

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.47307
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.69500

Cumulative Model Updates: 76,348
Cumulative Timesteps: 636,732,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,022.09269
Policy Entropy: 1.74492
Value Function Loss: 0.10761

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.15952
Policy Update Magnitude: 0.51230
Value Function Update Magnitude: 0.56406

Collected Steps per Second: 22,582.63857
Overall Steps per Second: 10,758.84613

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.43500
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.65068

Cumulative Model Updates: 76,354
Cumulative Timesteps: 636,782,398

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 636782398...
Checkpoint 636782398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,153.36415
Policy Entropy: 1.76429
Value Function Loss: 0.11161

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.15167
Policy Update Magnitude: 0.55894
Value Function Update Magnitude: 0.68412

Collected Steps per Second: 21,355.66488
Overall Steps per Second: 10,268.59643

Timestep Collection Time: 2.34139
Timestep Consumption Time: 2.52802
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.86941

Cumulative Model Updates: 76,360
Cumulative Timesteps: 636,832,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,531.63152
Policy Entropy: 1.73157
Value Function Loss: 0.09803

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.15103
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.82624

Collected Steps per Second: 22,335.67540
Overall Steps per Second: 10,615.45606

Timestep Collection Time: 2.24000
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.71313

Cumulative Model Updates: 76,366
Cumulative Timesteps: 636,882,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 636882432...
Checkpoint 636882432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,502.35574
Policy Entropy: 1.75474
Value Function Loss: 0.09882

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.56422
Value Function Update Magnitude: 0.74000

Collected Steps per Second: 21,975.98628
Overall Steps per Second: 10,504.36133

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.48661
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.76355

Cumulative Model Updates: 76,372
Cumulative Timesteps: 636,932,470

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,062.18026
Policy Entropy: 1.73972
Value Function Loss: 0.10162

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.56006
Value Function Update Magnitude: 0.62314

Collected Steps per Second: 22,151.18266
Overall Steps per Second: 10,434.69769

Timestep Collection Time: 2.25740
Timestep Consumption Time: 2.53469
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.79209

Cumulative Model Updates: 76,378
Cumulative Timesteps: 636,982,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 636982474...
Checkpoint 636982474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,903.65113
Policy Entropy: 1.73669
Value Function Loss: 0.10426

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14418
Policy Update Magnitude: 0.53852
Value Function Update Magnitude: 0.54815

Collected Steps per Second: 21,707.60911
Overall Steps per Second: 10,546.99559

Timestep Collection Time: 2.30389
Timestep Consumption Time: 2.43793
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.74182

Cumulative Model Updates: 76,384
Cumulative Timesteps: 637,032,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,941.57604
Policy Entropy: 1.72986
Value Function Loss: 0.10761

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.52263

Collected Steps per Second: 22,088.66368
Overall Steps per Second: 10,552.47212

Timestep Collection Time: 2.26388
Timestep Consumption Time: 2.47492
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.73879

Cumulative Model Updates: 76,390
Cumulative Timesteps: 637,082,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 637082492...
Checkpoint 637082492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,988.20727
Policy Entropy: 1.73708
Value Function Loss: 0.10849

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.50248

Collected Steps per Second: 22,303.05188
Overall Steps per Second: 10,653.89143

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.45186
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.69425

Cumulative Model Updates: 76,396
Cumulative Timesteps: 637,132,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,587.67587
Policy Entropy: 1.75717
Value Function Loss: 0.10853

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.44435

Collected Steps per Second: 22,004.58206
Overall Steps per Second: 10,451.21159

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.78643

Cumulative Model Updates: 76,402
Cumulative Timesteps: 637,182,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 637182528...
Checkpoint 637182528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,342.14115
Policy Entropy: 1.75493
Value Function Loss: 0.10950

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.42346

Collected Steps per Second: 22,224.36182
Overall Steps per Second: 10,711.20220

Timestep Collection Time: 2.25068
Timestep Consumption Time: 2.41919
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.66988

Cumulative Model Updates: 76,408
Cumulative Timesteps: 637,232,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,491.05376
Policy Entropy: 1.75363
Value Function Loss: 0.10013

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.54872
Value Function Update Magnitude: 0.49600

Collected Steps per Second: 22,545.90981
Overall Steps per Second: 10,742.45619

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.43732
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.65555

Cumulative Model Updates: 76,414
Cumulative Timesteps: 637,282,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 637282560...
Checkpoint 637282560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,915.51690
Policy Entropy: 1.74518
Value Function Loss: 0.10040

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.54035

Collected Steps per Second: 22,444.41082
Overall Steps per Second: 10,723.17488

Timestep Collection Time: 2.22960
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.66671

Cumulative Model Updates: 76,420
Cumulative Timesteps: 637,332,602

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,877.33202
Policy Entropy: 1.74220
Value Function Loss: 0.08936

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.54472
Value Function Update Magnitude: 0.60670

Collected Steps per Second: 22,110.45211
Overall Steps per Second: 10,483.98837

Timestep Collection Time: 2.26264
Timestep Consumption Time: 2.50921
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.77185

Cumulative Model Updates: 76,426
Cumulative Timesteps: 637,382,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 637382630...
Checkpoint 637382630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,570.72410
Policy Entropy: 1.73987
Value Function Loss: 0.09753

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.55051

Collected Steps per Second: 21,462.29833
Overall Steps per Second: 10,377.94514

Timestep Collection Time: 2.33051
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.81964

Cumulative Model Updates: 76,432
Cumulative Timesteps: 637,432,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,228.35036
Policy Entropy: 1.73405
Value Function Loss: 0.10181

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14533
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.52921

Collected Steps per Second: 22,094.37618
Overall Steps per Second: 10,632.30228

Timestep Collection Time: 2.26383
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.70434

Cumulative Model Updates: 76,438
Cumulative Timesteps: 637,482,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 637482666...
Checkpoint 637482666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,850.38995
Policy Entropy: 1.72385
Value Function Loss: 0.10195

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.55303
Value Function Update Magnitude: 0.60065

Collected Steps per Second: 21,844.86522
Overall Steps per Second: 10,419.15637

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.80269

Cumulative Model Updates: 76,444
Cumulative Timesteps: 637,532,706

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,911.60428
Policy Entropy: 1.72402
Value Function Loss: 0.10321

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.56256
Value Function Update Magnitude: 0.63584

Collected Steps per Second: 23,076.05704
Overall Steps per Second: 10,806.35957

Timestep Collection Time: 2.16813
Timestep Consumption Time: 2.46173
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.62987

Cumulative Model Updates: 76,450
Cumulative Timesteps: 637,582,738

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 637582738...
Checkpoint 637582738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,051.74850
Policy Entropy: 1.71398
Value Function Loss: 0.10273

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.16596
Policy Update Magnitude: 0.56321
Value Function Update Magnitude: 0.70280

Collected Steps per Second: 22,146.43041
Overall Steps per Second: 10,592.61872

Timestep Collection Time: 2.25788
Timestep Consumption Time: 2.46276
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.72065

Cumulative Model Updates: 76,456
Cumulative Timesteps: 637,632,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,720.77635
Policy Entropy: 1.71235
Value Function Loss: 0.10742

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.15554
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.77676

Collected Steps per Second: 22,865.39129
Overall Steps per Second: 10,700.82167

Timestep Collection Time: 2.18750
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.67422

Cumulative Model Updates: 76,462
Cumulative Timesteps: 637,682,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 637682760...
Checkpoint 637682760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,062.67660
Policy Entropy: 1.72350
Value Function Loss: 0.10528

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.77365

Collected Steps per Second: 22,277.91950
Overall Steps per Second: 10,544.71112

Timestep Collection Time: 2.24491
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.74285

Cumulative Model Updates: 76,468
Cumulative Timesteps: 637,732,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,985.21063
Policy Entropy: 1.72503
Value Function Loss: 0.09471

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.55951
Value Function Update Magnitude: 0.81828

Collected Steps per Second: 22,915.27303
Overall Steps per Second: 10,813.39235

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.62704

Cumulative Model Updates: 76,474
Cumulative Timesteps: 637,782,806

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 637782806...
Checkpoint 637782806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,548.92107
Policy Entropy: 1.74231
Value Function Loss: 0.09660

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.77954

Collected Steps per Second: 22,068.10557
Overall Steps per Second: 10,556.56223

Timestep Collection Time: 2.26734
Timestep Consumption Time: 2.47246
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.73980

Cumulative Model Updates: 76,480
Cumulative Timesteps: 637,832,842

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,240.00901
Policy Entropy: 1.73158
Value Function Loss: 0.10363

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.55847
Value Function Update Magnitude: 0.68503

Collected Steps per Second: 21,953.09879
Overall Steps per Second: 10,532.19804

Timestep Collection Time: 2.27786
Timestep Consumption Time: 2.47006
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.74792

Cumulative Model Updates: 76,486
Cumulative Timesteps: 637,882,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 637882848...
Checkpoint 637882848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,811.66896
Policy Entropy: 1.73421
Value Function Loss: 0.10672

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.55982
Value Function Update Magnitude: 0.76037

Collected Steps per Second: 21,606.11471
Overall Steps per Second: 10,535.33525

Timestep Collection Time: 2.31527
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.74821

Cumulative Model Updates: 76,492
Cumulative Timesteps: 637,932,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,435.00243
Policy Entropy: 1.72754
Value Function Loss: 0.10552

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.69145

Collected Steps per Second: 22,015.10265
Overall Steps per Second: 10,490.20247

Timestep Collection Time: 2.27262
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.76940

Cumulative Model Updates: 76,498
Cumulative Timesteps: 637,982,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 637982904...
Checkpoint 637982904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,692.16782
Policy Entropy: 1.73949
Value Function Loss: 0.10422

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.56000

Collected Steps per Second: 21,647.18687
Overall Steps per Second: 10,424.53605

Timestep Collection Time: 2.31023
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.79734

Cumulative Model Updates: 76,504
Cumulative Timesteps: 638,032,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,425.54818
Policy Entropy: 1.73124
Value Function Loss: 0.10798

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.67014

Collected Steps per Second: 22,660.18973
Overall Steps per Second: 10,722.50810

Timestep Collection Time: 2.20687
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.66383

Cumulative Model Updates: 76,510
Cumulative Timesteps: 638,082,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 638082922...
Checkpoint 638082922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,857.14111
Policy Entropy: 1.73595
Value Function Loss: 0.10070

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.77863

Collected Steps per Second: 22,452.00842
Overall Steps per Second: 10,621.26770

Timestep Collection Time: 2.22724
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.70810

Cumulative Model Updates: 76,516
Cumulative Timesteps: 638,132,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,925.06779
Policy Entropy: 1.71624
Value Function Loss: 0.09870

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.88836

Collected Steps per Second: 22,561.60210
Overall Steps per Second: 10,592.43039

Timestep Collection Time: 2.21678
Timestep Consumption Time: 2.50490
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.72167

Cumulative Model Updates: 76,522
Cumulative Timesteps: 638,182,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 638182942...
Checkpoint 638182942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,022.93664
Policy Entropy: 1.71937
Value Function Loss: 0.09853

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.56147
Value Function Update Magnitude: 0.88145

Collected Steps per Second: 21,723.26400
Overall Steps per Second: 10,549.72931

Timestep Collection Time: 2.30251
Timestep Consumption Time: 2.43866
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.74116

Cumulative Model Updates: 76,528
Cumulative Timesteps: 638,232,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,023.38897
Policy Entropy: 1.71161
Value Function Loss: 0.09640

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.79116

Collected Steps per Second: 21,920.19968
Overall Steps per Second: 10,754.52389

Timestep Collection Time: 2.28210
Timestep Consumption Time: 2.36934
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.65144

Cumulative Model Updates: 76,534
Cumulative Timesteps: 638,282,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 638282984...
Checkpoint 638282984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,764.61853
Policy Entropy: 1.70526
Value Function Loss: 0.08833

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.50026
Value Function Update Magnitude: 0.76701

Collected Steps per Second: 21,582.26518
Overall Steps per Second: 10,690.56316

Timestep Collection Time: 2.31811
Timestep Consumption Time: 2.36172
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.67983

Cumulative Model Updates: 76,540
Cumulative Timesteps: 638,333,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,208.91959
Policy Entropy: 1.71285
Value Function Loss: 0.08738

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.46911
Value Function Update Magnitude: 0.78574

Collected Steps per Second: 21,760.92076
Overall Steps per Second: 10,556.78724

Timestep Collection Time: 2.29779
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.73648

Cumulative Model Updates: 76,546
Cumulative Timesteps: 638,383,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 638383016...
Checkpoint 638383016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,236.15753
Policy Entropy: 1.72624
Value Function Loss: 0.10088

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.49828
Value Function Update Magnitude: 0.76633

Collected Steps per Second: 21,126.75908
Overall Steps per Second: 10,560.31715

Timestep Collection Time: 2.36818
Timestep Consumption Time: 2.36955
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.73774

Cumulative Model Updates: 76,552
Cumulative Timesteps: 638,433,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,104.87674
Policy Entropy: 1.73327
Value Function Loss: 0.10204

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15096
Policy Update Magnitude: 0.51022
Value Function Update Magnitude: 0.68061

Collected Steps per Second: 21,544.30123
Overall Steps per Second: 10,332.09085

Timestep Collection Time: 2.32099
Timestep Consumption Time: 2.51869
PPO Batch Consumption Time: 0.30782
Total Iteration Time: 4.83968

Cumulative Model Updates: 76,558
Cumulative Timesteps: 638,483,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 638483052...
Checkpoint 638483052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,525.36273
Policy Entropy: 1.72202
Value Function Loss: 0.10137

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.16401
Policy Update Magnitude: 0.51695
Value Function Update Magnitude: 0.81806

Collected Steps per Second: 21,179.75640
Overall Steps per Second: 10,354.35280

Timestep Collection Time: 2.36103
Timestep Consumption Time: 2.46844
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.82947

Cumulative Model Updates: 76,564
Cumulative Timesteps: 638,533,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,997.46992
Policy Entropy: 1.73048
Value Function Loss: 0.09475

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.87697

Collected Steps per Second: 22,036.55025
Overall Steps per Second: 10,479.90719

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.50228
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.77142

Cumulative Model Updates: 76,570
Cumulative Timesteps: 638,583,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 638583062...
Checkpoint 638583062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,416.79308
Policy Entropy: 1.72526
Value Function Loss: 0.09619

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.50300
Value Function Update Magnitude: 0.78950

Collected Steps per Second: 22,241.94899
Overall Steps per Second: 10,653.78397

Timestep Collection Time: 2.25007
Timestep Consumption Time: 2.44741
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.69749

Cumulative Model Updates: 76,576
Cumulative Timesteps: 638,633,108

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,141.39207
Policy Entropy: 1.74163
Value Function Loss: 0.10202

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.50861
Value Function Update Magnitude: 0.66787

Collected Steps per Second: 22,091.52700
Overall Steps per Second: 10,198.96961

Timestep Collection Time: 2.26449
Timestep Consumption Time: 2.64052
PPO Batch Consumption Time: 0.30151
Total Iteration Time: 4.90501

Cumulative Model Updates: 76,582
Cumulative Timesteps: 638,683,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 638683134...
Checkpoint 638683134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,462.46438
Policy Entropy: 1.73437
Value Function Loss: 0.11100

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.52588

Collected Steps per Second: 19,567.91269
Overall Steps per Second: 9,907.97423

Timestep Collection Time: 2.55582
Timestep Consumption Time: 2.49183
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 5.04765

Cumulative Model Updates: 76,588
Cumulative Timesteps: 638,733,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,306.77258
Policy Entropy: 1.73497
Value Function Loss: 0.10374

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.16766
Policy Update Magnitude: 0.50241
Value Function Update Magnitude: 0.70364

Collected Steps per Second: 22,544.67317
Overall Steps per Second: 10,611.01560

Timestep Collection Time: 2.21782
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.71208

Cumulative Model Updates: 76,594
Cumulative Timesteps: 638,783,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 638783146...
Checkpoint 638783146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,650.04285
Policy Entropy: 1.72652
Value Function Loss: 0.09994

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.17263
Policy Update Magnitude: 0.48476
Value Function Update Magnitude: 0.76511

Collected Steps per Second: 22,159.33512
Overall Steps per Second: 10,614.60977

Timestep Collection Time: 2.25657
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.71087

Cumulative Model Updates: 76,600
Cumulative Timesteps: 638,833,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,061.14248
Policy Entropy: 1.73746
Value Function Loss: 0.09415

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.48970
Value Function Update Magnitude: 0.74392

Collected Steps per Second: 22,873.65707
Overall Steps per Second: 10,864.08607

Timestep Collection Time: 2.18645
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.60342

Cumulative Model Updates: 76,606
Cumulative Timesteps: 638,883,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 638883162...
Checkpoint 638883162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,297.91440
Policy Entropy: 1.72730
Value Function Loss: 0.09287

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.15126
Policy Update Magnitude: 0.50360
Value Function Update Magnitude: 0.67197

Collected Steps per Second: 22,447.91229
Overall Steps per Second: 10,630.07275

Timestep Collection Time: 2.22782
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.70458

Cumulative Model Updates: 76,612
Cumulative Timesteps: 638,933,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,070.16739
Policy Entropy: 1.72412
Value Function Loss: 0.09252

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.51740
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 22,030.43699
Overall Steps per Second: 10,456.21993

Timestep Collection Time: 2.26959
Timestep Consumption Time: 2.51226
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.78184

Cumulative Model Updates: 76,618
Cumulative Timesteps: 638,983,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 638983172...
Checkpoint 638983172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,747.02122
Policy Entropy: 1.72634
Value Function Loss: 0.10615

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.55258
Value Function Update Magnitude: 0.53504

Collected Steps per Second: 21,841.83811
Overall Steps per Second: 10,569.32240

Timestep Collection Time: 2.29010
Timestep Consumption Time: 2.44246
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.73256

Cumulative Model Updates: 76,624
Cumulative Timesteps: 639,033,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,058.76391
Policy Entropy: 1.72402
Value Function Loss: 0.10461

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 21,835.93518
Overall Steps per Second: 10,579.27741

Timestep Collection Time: 2.29054
Timestep Consumption Time: 2.43720
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.72773

Cumulative Model Updates: 76,630
Cumulative Timesteps: 639,083,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 639083208...
Checkpoint 639083208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,258.53557
Policy Entropy: 1.73153
Value Function Loss: 0.10472

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.66917

Collected Steps per Second: 21,575.04748
Overall Steps per Second: 10,519.74586

Timestep Collection Time: 2.31833
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.75468

Cumulative Model Updates: 76,636
Cumulative Timesteps: 639,133,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,734.75781
Policy Entropy: 1.71735
Value Function Loss: 0.10236

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.54840
Value Function Update Magnitude: 0.65474

Collected Steps per Second: 22,467.31531
Overall Steps per Second: 10,528.47628

Timestep Collection Time: 2.22724
Timestep Consumption Time: 2.52559
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.75282

Cumulative Model Updates: 76,642
Cumulative Timesteps: 639,183,266

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 639183266...
Checkpoint 639183266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,085.37685
Policy Entropy: 1.72141
Value Function Loss: 0.10414

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.53778
Value Function Update Magnitude: 0.67358

Collected Steps per Second: 21,913.69722
Overall Steps per Second: 10,412.89669

Timestep Collection Time: 2.28268
Timestep Consumption Time: 2.52117
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.80385

Cumulative Model Updates: 76,648
Cumulative Timesteps: 639,233,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,135.62949
Policy Entropy: 1.72362
Value Function Loss: 0.10505

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.54287
Value Function Update Magnitude: 0.70680

Collected Steps per Second: 22,765.32765
Overall Steps per Second: 10,688.23939

Timestep Collection Time: 2.19659
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.67860

Cumulative Model Updates: 76,654
Cumulative Timesteps: 639,283,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 639283294...
Checkpoint 639283294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,654.91544
Policy Entropy: 1.73673
Value Function Loss: 0.09760

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.55053
Value Function Update Magnitude: 0.65632

Collected Steps per Second: 21,276.03358
Overall Steps per Second: 10,289.62710

Timestep Collection Time: 2.35034
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.85985

Cumulative Model Updates: 76,660
Cumulative Timesteps: 639,333,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,053.82501
Policy Entropy: 1.73735
Value Function Loss: 0.10389

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.68542

Collected Steps per Second: 22,342.38860
Overall Steps per Second: 10,564.89853

Timestep Collection Time: 2.23906
Timestep Consumption Time: 2.49605
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.73511

Cumulative Model Updates: 76,666
Cumulative Timesteps: 639,383,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 639383326...
Checkpoint 639383326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,200.61027
Policy Entropy: 1.74390
Value Function Loss: 0.09784

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.78895

Collected Steps per Second: 22,632.61442
Overall Steps per Second: 10,642.99152

Timestep Collection Time: 2.21044
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.70056

Cumulative Model Updates: 76,672
Cumulative Timesteps: 639,433,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,436.33502
Policy Entropy: 1.74414
Value Function Loss: 0.09550

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.73249

Collected Steps per Second: 22,995.49536
Overall Steps per Second: 10,754.37340

Timestep Collection Time: 2.17564
Timestep Consumption Time: 2.47642
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.65206

Cumulative Model Updates: 76,678
Cumulative Timesteps: 639,483,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 639483384...
Checkpoint 639483384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,091.22605
Policy Entropy: 1.73278
Value Function Loss: 0.09620

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.52520
Value Function Update Magnitude: 0.64583

Collected Steps per Second: 22,500.96539
Overall Steps per Second: 10,657.04368

Timestep Collection Time: 2.22319
Timestep Consumption Time: 2.47079
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.69398

Cumulative Model Updates: 76,684
Cumulative Timesteps: 639,533,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,638.56126
Policy Entropy: 1.72057
Value Function Loss: 0.10075

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.54006
Value Function Update Magnitude: 0.60908

Collected Steps per Second: 22,523.26399
Overall Steps per Second: 10,588.47506

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.72325

Cumulative Model Updates: 76,690
Cumulative Timesteps: 639,583,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 639583420...
Checkpoint 639583420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,317.08472
Policy Entropy: 1.71830
Value Function Loss: 0.09931

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.68750

Collected Steps per Second: 21,552.46439
Overall Steps per Second: 10,520.20887

Timestep Collection Time: 2.32038
Timestep Consumption Time: 2.43332
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.75371

Cumulative Model Updates: 76,696
Cumulative Timesteps: 639,633,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,245.04328
Policy Entropy: 1.71948
Value Function Loss: 0.09997

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.81551

Collected Steps per Second: 21,698.48960
Overall Steps per Second: 10,379.02524

Timestep Collection Time: 2.30615
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.82126

Cumulative Model Updates: 76,702
Cumulative Timesteps: 639,683,470

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 639683470...
Checkpoint 639683470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,901.07103
Policy Entropy: 1.74034
Value Function Loss: 0.09745

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.55860
Value Function Update Magnitude: 0.84741

Collected Steps per Second: 21,630.50514
Overall Steps per Second: 10,421.96067

Timestep Collection Time: 2.31294
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.80044

Cumulative Model Updates: 76,708
Cumulative Timesteps: 639,733,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,345.62043
Policy Entropy: 1.74004
Value Function Loss: 0.09783

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.80531

Collected Steps per Second: 22,474.06223
Overall Steps per Second: 10,691.81778

Timestep Collection Time: 2.22514
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.67722

Cumulative Model Updates: 76,714
Cumulative Timesteps: 639,783,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 639783508...
Checkpoint 639783508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,822.37511
Policy Entropy: 1.73342
Value Function Loss: 0.09884

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.51546
Value Function Update Magnitude: 0.72328

Collected Steps per Second: 22,325.50814
Overall Steps per Second: 10,600.98513

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.47745
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.71749

Cumulative Model Updates: 76,720
Cumulative Timesteps: 639,833,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,076.30601
Policy Entropy: 1.72095
Value Function Loss: 0.09876

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.18581
Policy Update Magnitude: 0.46610
Value Function Update Magnitude: 0.67316

Collected Steps per Second: 22,646.97594
Overall Steps per Second: 10,603.39830

Timestep Collection Time: 2.20789
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71566

Cumulative Model Updates: 76,726
Cumulative Timesteps: 639,883,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 639883520...
Checkpoint 639883520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,113.28959
Policy Entropy: 1.71396
Value Function Loss: 0.09772

Mean KL Divergence: 0.03109
SB3 Clip Fraction: 0.20958
Policy Update Magnitude: 0.42240
Value Function Update Magnitude: 0.71248

Collected Steps per Second: 22,315.56101
Overall Steps per Second: 10,560.81303

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.73789

Cumulative Model Updates: 76,732
Cumulative Timesteps: 639,933,556

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,604.61196
Policy Entropy: 1.69375
Value Function Loss: 0.09722

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.17353
Policy Update Magnitude: 0.41951
Value Function Update Magnitude: 0.75092

Collected Steps per Second: 22,910.60652
Overall Steps per Second: 10,792.85500

Timestep Collection Time: 2.18240
Timestep Consumption Time: 2.45030
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.63269

Cumulative Model Updates: 76,738
Cumulative Timesteps: 639,983,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 639983556...
Checkpoint 639983556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,501.49623
Policy Entropy: 1.68807
Value Function Loss: 0.10766

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.15391
Policy Update Magnitude: 0.48895
Value Function Update Magnitude: 0.81685

Collected Steps per Second: 22,033.23483
Overall Steps per Second: 10,500.60066

Timestep Collection Time: 2.27157
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.76639

Cumulative Model Updates: 76,744
Cumulative Timesteps: 640,033,606

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,970.48331
Policy Entropy: 1.68140
Value Function Loss: 0.11299

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.52139
Value Function Update Magnitude: 0.74730

Collected Steps per Second: 23,035.66323
Overall Steps per Second: 10,731.96628

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.66028

Cumulative Model Updates: 76,750
Cumulative Timesteps: 640,083,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 640083620...
Checkpoint 640083620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,084.11891
Policy Entropy: 1.69144
Value Function Loss: 0.11484

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.53109
Value Function Update Magnitude: 0.70873

Collected Steps per Second: 22,149.07220
Overall Steps per Second: 10,701.71624

Timestep Collection Time: 2.25743
Timestep Consumption Time: 2.41472
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.67215

Cumulative Model Updates: 76,756
Cumulative Timesteps: 640,133,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,209.64282
Policy Entropy: 1.69687
Value Function Loss: 0.10167

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.53965
Value Function Update Magnitude: 0.70039

Collected Steps per Second: 22,702.11566
Overall Steps per Second: 10,769.65746

Timestep Collection Time: 2.20253
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.64286

Cumulative Model Updates: 76,762
Cumulative Timesteps: 640,183,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 640183622...
Checkpoint 640183622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,368.19732
Policy Entropy: 1.70647
Value Function Loss: 0.10036

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.68346

Collected Steps per Second: 21,528.55124
Overall Steps per Second: 10,366.46636

Timestep Collection Time: 2.32305
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.82440

Cumulative Model Updates: 76,768
Cumulative Timesteps: 640,233,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,802.67429
Policy Entropy: 1.72138
Value Function Loss: 0.09863

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.71938

Collected Steps per Second: 22,546.83659
Overall Steps per Second: 10,728.64382

Timestep Collection Time: 2.21769
Timestep Consumption Time: 2.44291
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.66061

Cumulative Model Updates: 76,774
Cumulative Timesteps: 640,283,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 640283636...
Checkpoint 640283636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,922.59839
Policy Entropy: 1.73201
Value Function Loss: 0.09467

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.82786

Collected Steps per Second: 21,736.42850
Overall Steps per Second: 10,441.44552

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.48832
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.78861

Cumulative Model Updates: 76,780
Cumulative Timesteps: 640,333,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,755.22959
Policy Entropy: 1.73110
Value Function Loss: 0.09643

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.85207

Collected Steps per Second: 23,029.45253
Overall Steps per Second: 10,699.13338

Timestep Collection Time: 2.17226
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.67571

Cumulative Model Updates: 76,786
Cumulative Timesteps: 640,383,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 640383662...
Checkpoint 640383662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,839.61142
Policy Entropy: 1.72493
Value Function Loss: 0.09706

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.85504

Collected Steps per Second: 22,084.28897
Overall Steps per Second: 10,567.63515

Timestep Collection Time: 2.26541
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.73427

Cumulative Model Updates: 76,792
Cumulative Timesteps: 640,433,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,982.93954
Policy Entropy: 1.73577
Value Function Loss: 0.10016

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.78722

Collected Steps per Second: 22,886.07239
Overall Steps per Second: 10,675.48405

Timestep Collection Time: 2.18517
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.68457

Cumulative Model Updates: 76,798
Cumulative Timesteps: 640,483,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 640483702...
Checkpoint 640483702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,390.41947
Policy Entropy: 1.73739
Value Function Loss: 0.10194

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.67130

Collected Steps per Second: 22,718.45354
Overall Steps per Second: 10,722.12815

Timestep Collection Time: 2.20129
Timestep Consumption Time: 2.46289
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.66419

Cumulative Model Updates: 76,804
Cumulative Timesteps: 640,533,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,723.75830
Policy Entropy: 1.74714
Value Function Loss: 0.09842

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.64351

Collected Steps per Second: 22,114.69908
Overall Steps per Second: 10,673.12962

Timestep Collection Time: 2.26130
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.68541

Cumulative Model Updates: 76,810
Cumulative Timesteps: 640,583,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 640583720...
Checkpoint 640583720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,467.44986
Policy Entropy: 1.73315
Value Function Loss: 0.10766

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.49903
Value Function Update Magnitude: 0.61007

Collected Steps per Second: 21,582.96979
Overall Steps per Second: 10,570.62655

Timestep Collection Time: 2.31701
Timestep Consumption Time: 2.41383
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.73085

Cumulative Model Updates: 76,816
Cumulative Timesteps: 640,633,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,060.14935
Policy Entropy: 1.72349
Value Function Loss: 0.10359

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.50490
Value Function Update Magnitude: 0.57764

Collected Steps per Second: 21,547.32737
Overall Steps per Second: 10,536.11571

Timestep Collection Time: 2.32047
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.74558

Cumulative Model Updates: 76,822
Cumulative Timesteps: 640,683,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 640683728...
Checkpoint 640683728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,975.10321
Policy Entropy: 1.71481
Value Function Loss: 0.10380

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.64555

Collected Steps per Second: 21,141.43909
Overall Steps per Second: 10,591.84664

Timestep Collection Time: 2.36635
Timestep Consumption Time: 2.35691
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72326

Cumulative Model Updates: 76,828
Cumulative Timesteps: 640,733,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,883.54932
Policy Entropy: 1.72309
Value Function Loss: 0.09339

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.52245
Value Function Update Magnitude: 0.65657

Collected Steps per Second: 21,704.24306
Overall Steps per Second: 10,519.54802

Timestep Collection Time: 2.30443
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.75458

Cumulative Model Updates: 76,834
Cumulative Timesteps: 640,783,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 640783772...
Checkpoint 640783772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,326.62938
Policy Entropy: 1.73157
Value Function Loss: 0.08965

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.51472
Value Function Update Magnitude: 0.57469

Collected Steps per Second: 20,892.56681
Overall Steps per Second: 10,475.21228

Timestep Collection Time: 2.39406
Timestep Consumption Time: 2.38083
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.77489

Cumulative Model Updates: 76,840
Cumulative Timesteps: 640,833,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,031.05931
Policy Entropy: 1.73784
Value Function Loss: 0.09884

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.15054
Policy Update Magnitude: 0.51978
Value Function Update Magnitude: 0.58027

Collected Steps per Second: 22,047.87093
Overall Steps per Second: 10,589.23439

Timestep Collection Time: 2.26961
Timestep Consumption Time: 2.45595
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.72555

Cumulative Model Updates: 76,846
Cumulative Timesteps: 640,883,830

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 640883830...
Checkpoint 640883830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,004.50153
Policy Entropy: 1.71950
Value Function Loss: 0.10481

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.53078
Value Function Update Magnitude: 0.50514

Collected Steps per Second: 21,607.71453
Overall Steps per Second: 10,586.90748

Timestep Collection Time: 2.31482
Timestep Consumption Time: 2.40969
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.72451

Cumulative Model Updates: 76,852
Cumulative Timesteps: 640,933,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,513.07904
Policy Entropy: 1.71763
Value Function Loss: 0.09709

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.54305
Value Function Update Magnitude: 0.58129

Collected Steps per Second: 22,110.07233
Overall Steps per Second: 10,485.69805

Timestep Collection Time: 2.26177
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.76916

Cumulative Model Updates: 76,858
Cumulative Timesteps: 640,983,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 640983856...
Checkpoint 640983856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,843.27908
Policy Entropy: 1.71588
Value Function Loss: 0.08762

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.52958
Value Function Update Magnitude: 0.58701

Collected Steps per Second: 21,962.89439
Overall Steps per Second: 10,669.81912

Timestep Collection Time: 2.27748
Timestep Consumption Time: 2.41051
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.68799

Cumulative Model Updates: 76,864
Cumulative Timesteps: 641,033,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,677.64410
Policy Entropy: 1.72671
Value Function Loss: 0.08679

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.15458
Policy Update Magnitude: 0.49522
Value Function Update Magnitude: 0.56653

Collected Steps per Second: 22,401.31614
Overall Steps per Second: 10,692.86344

Timestep Collection Time: 2.23344
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.67901

Cumulative Model Updates: 76,870
Cumulative Timesteps: 641,083,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 641083908...
Checkpoint 641083908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,222.81567
Policy Entropy: 1.71046
Value Function Loss: 0.09742

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.16708
Policy Update Magnitude: 0.46316
Value Function Update Magnitude: 0.61628

Collected Steps per Second: 22,178.93477
Overall Steps per Second: 10,759.72748

Timestep Collection Time: 2.25665
Timestep Consumption Time: 2.39496
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.65160

Cumulative Model Updates: 76,876
Cumulative Timesteps: 641,133,958

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,273.13720
Policy Entropy: 1.71258
Value Function Loss: 0.09824

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.52513
Value Function Update Magnitude: 0.66968

Collected Steps per Second: 22,261.73039
Overall Steps per Second: 10,568.36864

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.73299

Cumulative Model Updates: 76,882
Cumulative Timesteps: 641,183,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 641183978...
Checkpoint 641183978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,952.14850
Policy Entropy: 1.69469
Value Function Loss: 0.10601

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.55091
Value Function Update Magnitude: 0.65025

Collected Steps per Second: 21,334.16475
Overall Steps per Second: 10,353.91116

Timestep Collection Time: 2.34394
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.82967

Cumulative Model Updates: 76,888
Cumulative Timesteps: 641,233,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,423.80049
Policy Entropy: 1.69971
Value Function Loss: 0.10546

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.16005
Policy Update Magnitude: 0.53208
Value Function Update Magnitude: 0.65747

Collected Steps per Second: 22,203.92933
Overall Steps per Second: 10,581.74438

Timestep Collection Time: 2.25248
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.72644

Cumulative Model Updates: 76,894
Cumulative Timesteps: 641,283,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 641283998...
Checkpoint 641283998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,217.82476
Policy Entropy: 1.70478
Value Function Loss: 0.11203

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.51096
Value Function Update Magnitude: 0.67259

Collected Steps per Second: 21,797.45693
Overall Steps per Second: 10,322.88424

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.55058
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.84516

Cumulative Model Updates: 76,900
Cumulative Timesteps: 641,334,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,104.01738
Policy Entropy: 1.69854
Value Function Loss: 0.10214

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.51825
Value Function Update Magnitude: 0.68221

Collected Steps per Second: 22,194.98318
Overall Steps per Second: 10,444.19444

Timestep Collection Time: 2.25330
Timestep Consumption Time: 2.53520
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.78850

Cumulative Model Updates: 76,906
Cumulative Timesteps: 641,384,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 641384026...
Checkpoint 641384026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,170.39436
Policy Entropy: 1.70663
Value Function Loss: 0.10415

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.68540

Collected Steps per Second: 22,235.83826
Overall Steps per Second: 10,547.86240

Timestep Collection Time: 2.24898
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.74106

Cumulative Model Updates: 76,912
Cumulative Timesteps: 641,434,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,635.93674
Policy Entropy: 1.70099
Value Function Loss: 0.10404

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.54452
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 22,457.36507
Overall Steps per Second: 10,578.28217

Timestep Collection Time: 2.22849
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.73101

Cumulative Model Updates: 76,918
Cumulative Timesteps: 641,484,080

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 641484080...
Checkpoint 641484080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,799.19710
Policy Entropy: 1.70653
Value Function Loss: 0.11116

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.55749

Collected Steps per Second: 22,168.27028
Overall Steps per Second: 10,635.64037

Timestep Collection Time: 2.25629
Timestep Consumption Time: 2.44658
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.70287

Cumulative Model Updates: 76,924
Cumulative Timesteps: 641,534,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,923.84812
Policy Entropy: 1.70119
Value Function Loss: 0.10578

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.49229

Collected Steps per Second: 22,334.51520
Overall Steps per Second: 10,496.84397

Timestep Collection Time: 2.23869
Timestep Consumption Time: 2.52465
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.76334

Cumulative Model Updates: 76,930
Cumulative Timesteps: 641,584,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 641584098...
Checkpoint 641584098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,754.94109
Policy Entropy: 1.71445
Value Function Loss: 0.10776

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.56362
Value Function Update Magnitude: 0.48731

Collected Steps per Second: 22,253.02363
Overall Steps per Second: 10,553.21192

Timestep Collection Time: 2.24716
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.73846

Cumulative Model Updates: 76,936
Cumulative Timesteps: 641,634,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,265.95483
Policy Entropy: 1.71137
Value Function Loss: 0.10284

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.61454

Collected Steps per Second: 22,531.98114
Overall Steps per Second: 10,545.28869

Timestep Collection Time: 2.21925
Timestep Consumption Time: 2.52259
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.74183

Cumulative Model Updates: 76,942
Cumulative Timesteps: 641,684,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 641684108...
Checkpoint 641684108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,878.56074
Policy Entropy: 1.71605
Value Function Loss: 0.10091

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.75031

Collected Steps per Second: 22,258.39717
Overall Steps per Second: 10,550.63753

Timestep Collection Time: 2.24661
Timestep Consumption Time: 2.49301
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.73962

Cumulative Model Updates: 76,948
Cumulative Timesteps: 641,734,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,149.91619
Policy Entropy: 1.70807
Value Function Loss: 0.09611

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.77205

Collected Steps per Second: 21,800.23010
Overall Steps per Second: 10,442.99858

Timestep Collection Time: 2.29557
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.79211

Cumulative Model Updates: 76,954
Cumulative Timesteps: 641,784,158

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 641784158...
Checkpoint 641784158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,110.17791
Policy Entropy: 1.70502
Value Function Loss: 0.09316

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.74800

Collected Steps per Second: 21,541.08455
Overall Steps per Second: 10,565.12722

Timestep Collection Time: 2.32217
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.73463

Cumulative Model Updates: 76,960
Cumulative Timesteps: 641,834,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,951.14488
Policy Entropy: 1.70304
Value Function Loss: 0.09892

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.68184

Collected Steps per Second: 21,882.96047
Overall Steps per Second: 10,583.85475

Timestep Collection Time: 2.28488
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.72418

Cumulative Model Updates: 76,966
Cumulative Timesteps: 641,884,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 641884180...
Checkpoint 641884180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,468.53335
Policy Entropy: 1.69841
Value Function Loss: 0.10145

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.77915

Collected Steps per Second: 21,771.76367
Overall Steps per Second: 10,454.61546

Timestep Collection Time: 2.29747
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.78449

Cumulative Model Updates: 76,972
Cumulative Timesteps: 641,934,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,745.53903
Policy Entropy: 1.71106
Value Function Loss: 0.10267

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.74439

Collected Steps per Second: 22,303.74570
Overall Steps per Second: 10,490.09122

Timestep Collection Time: 2.24276
Timestep Consumption Time: 2.52574
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.76850

Cumulative Model Updates: 76,978
Cumulative Timesteps: 641,984,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 641984222...
Checkpoint 641984222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,308.79471
Policy Entropy: 1.71642
Value Function Loss: 0.10024

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.63071

Collected Steps per Second: 22,419.59792
Overall Steps per Second: 10,658.01648

Timestep Collection Time: 2.23082
Timestep Consumption Time: 2.46180
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.69262

Cumulative Model Updates: 76,984
Cumulative Timesteps: 642,034,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,447.46556
Policy Entropy: 1.69740
Value Function Loss: 0.09785

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.51255
Value Function Update Magnitude: 0.48571

Collected Steps per Second: 22,678.75081
Overall Steps per Second: 10,696.85891

Timestep Collection Time: 2.20524
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67539

Cumulative Model Updates: 76,990
Cumulative Timesteps: 642,084,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 642084248...
Checkpoint 642084248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,304.97046
Policy Entropy: 1.69467
Value Function Loss: 0.09816

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14687
Policy Update Magnitude: 0.49193
Value Function Update Magnitude: 0.48285

Collected Steps per Second: 22,333.11946
Overall Steps per Second: 10,522.58963

Timestep Collection Time: 2.23999
Timestep Consumption Time: 2.51416
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.75415

Cumulative Model Updates: 76,996
Cumulative Timesteps: 642,134,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,021.85665
Policy Entropy: 1.68229
Value Function Loss: 0.10014

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.51475
Value Function Update Magnitude: 0.47246

Collected Steps per Second: 22,620.26275
Overall Steps per Second: 10,766.82014

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.43427
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.64538

Cumulative Model Updates: 77,002
Cumulative Timesteps: 642,184,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 642184290...
Checkpoint 642184290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,761.39343
Policy Entropy: 1.69477
Value Function Loss: 0.10026

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.52640
Value Function Update Magnitude: 0.47602

Collected Steps per Second: 21,866.76604
Overall Steps per Second: 10,444.27302

Timestep Collection Time: 2.28676
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.78770

Cumulative Model Updates: 77,008
Cumulative Timesteps: 642,234,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,617.98515
Policy Entropy: 1.68454
Value Function Loss: 0.09937

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.51212

Collected Steps per Second: 22,793.04947
Overall Steps per Second: 10,767.68436

Timestep Collection Time: 2.19444
Timestep Consumption Time: 2.45075
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.64520

Cumulative Model Updates: 77,014
Cumulative Timesteps: 642,284,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 642284312...
Checkpoint 642284312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,089.80698
Policy Entropy: 1.68151
Value Function Loss: 0.09786

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.58313

Collected Steps per Second: 21,672.02978
Overall Steps per Second: 10,543.95675

Timestep Collection Time: 2.30731
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.74243

Cumulative Model Updates: 77,020
Cumulative Timesteps: 642,334,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,348.56964
Policy Entropy: 1.68850
Value Function Loss: 0.09213

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.72507

Collected Steps per Second: 22,128.20639
Overall Steps per Second: 10,524.67419

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.75340

Cumulative Model Updates: 77,026
Cumulative Timesteps: 642,384,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 642384344...
Checkpoint 642384344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,475.00240
Policy Entropy: 1.68464
Value Function Loss: 0.09054

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.51429
Value Function Update Magnitude: 0.79016

Collected Steps per Second: 21,647.50570
Overall Steps per Second: 10,430.11136

Timestep Collection Time: 2.31084
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.79611

Cumulative Model Updates: 77,032
Cumulative Timesteps: 642,434,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,802.70342
Policy Entropy: 1.68235
Value Function Loss: 0.08672

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.47718
Value Function Update Magnitude: 0.74766

Collected Steps per Second: 22,150.00790
Overall Steps per Second: 10,624.57206

Timestep Collection Time: 2.25923
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.71003

Cumulative Model Updates: 77,038
Cumulative Timesteps: 642,484,410

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 642484410...
Checkpoint 642484410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,434.22720
Policy Entropy: 1.67998
Value Function Loss: 0.08845

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.51797
Value Function Update Magnitude: 0.78636

Collected Steps per Second: 21,140.29263
Overall Steps per Second: 10,285.56985

Timestep Collection Time: 2.36600
Timestep Consumption Time: 2.49693
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.86293

Cumulative Model Updates: 77,044
Cumulative Timesteps: 642,534,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,147.68838
Policy Entropy: 1.67102
Value Function Loss: 0.09451

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.75225

Collected Steps per Second: 22,727.12302
Overall Steps per Second: 10,800.34834

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63226

Cumulative Model Updates: 77,050
Cumulative Timesteps: 642,584,458

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 642584458...
Checkpoint 642584458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,600.40286
Policy Entropy: 1.67778
Value Function Loss: 0.09514

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.55093
Value Function Update Magnitude: 0.76505

Collected Steps per Second: 21,871.66507
Overall Steps per Second: 10,285.54962

Timestep Collection Time: 2.28734
Timestep Consumption Time: 2.57657
PPO Batch Consumption Time: 0.30404
Total Iteration Time: 4.86391

Cumulative Model Updates: 77,056
Cumulative Timesteps: 642,634,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,181.87067
Policy Entropy: 1.67089
Value Function Loss: 0.09455

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.79823

Collected Steps per Second: 22,689.69653
Overall Steps per Second: 10,635.49802

Timestep Collection Time: 2.20364
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.70124

Cumulative Model Updates: 77,062
Cumulative Timesteps: 642,684,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 642684486...
Checkpoint 642684486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,917.72158
Policy Entropy: 1.68070
Value Function Loss: 0.09489

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.79067

Collected Steps per Second: 21,518.72985
Overall Steps per Second: 10,199.21970

Timestep Collection Time: 2.32374
Timestep Consumption Time: 2.57898
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.90273

Cumulative Model Updates: 77,068
Cumulative Timesteps: 642,734,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,471.37719
Policy Entropy: 1.67942
Value Function Loss: 0.10135

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.77328

Collected Steps per Second: 22,830.57197
Overall Steps per Second: 10,750.34004

Timestep Collection Time: 2.19118
Timestep Consumption Time: 2.46225
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.65343

Cumulative Model Updates: 77,074
Cumulative Timesteps: 642,784,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 642784516...
Checkpoint 642784516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,599.71721
Policy Entropy: 1.68865
Value Function Loss: 0.10063

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.56493
Value Function Update Magnitude: 0.82316

Collected Steps per Second: 22,125.90791
Overall Steps per Second: 10,630.78213

Timestep Collection Time: 2.26061
Timestep Consumption Time: 2.44441
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.70502

Cumulative Model Updates: 77,080
Cumulative Timesteps: 642,834,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,340.86185
Policy Entropy: 1.68853
Value Function Loss: 0.10767

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.67870

Collected Steps per Second: 21,721.59441
Overall Steps per Second: 10,555.09360

Timestep Collection Time: 2.30296
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.73932

Cumulative Model Updates: 77,086
Cumulative Timesteps: 642,884,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 642884558...
Checkpoint 642884558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,701.45585
Policy Entropy: 1.68702
Value Function Loss: 0.10575

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.54784
Value Function Update Magnitude: 0.54594

Collected Steps per Second: 22,003.26073
Overall Steps per Second: 10,635.24208

Timestep Collection Time: 2.27384
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.70436

Cumulative Model Updates: 77,092
Cumulative Timesteps: 642,934,590

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,808.71565
Policy Entropy: 1.68173
Value Function Loss: 0.10530

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.53658
Value Function Update Magnitude: 0.47813

Collected Steps per Second: 22,242.21329
Overall Steps per Second: 10,502.07491

Timestep Collection Time: 2.24834
Timestep Consumption Time: 2.51339
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.76173

Cumulative Model Updates: 77,098
Cumulative Timesteps: 642,984,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 642984598...
Checkpoint 642984598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,755.33152
Policy Entropy: 1.67336
Value Function Loss: 0.10598

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.54629
Value Function Update Magnitude: 0.47678

Collected Steps per Second: 22,170.71325
Overall Steps per Second: 10,516.53639

Timestep Collection Time: 2.25622
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.75651

Cumulative Model Updates: 77,104
Cumulative Timesteps: 643,034,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,308.56596
Policy Entropy: 1.67757
Value Function Loss: 0.10955

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.52141

Collected Steps per Second: 22,723.33107
Overall Steps per Second: 10,637.95531

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.70485

Cumulative Model Updates: 77,110
Cumulative Timesteps: 643,084,670

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 643084670...
Checkpoint 643084670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,774.30288
Policy Entropy: 1.68282
Value Function Loss: 0.10554

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.54762
Value Function Update Magnitude: 0.50167

Collected Steps per Second: 22,015.62608
Overall Steps per Second: 10,397.26274

Timestep Collection Time: 2.27202
Timestep Consumption Time: 2.53886
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.81088

Cumulative Model Updates: 77,116
Cumulative Timesteps: 643,134,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,445.88420
Policy Entropy: 1.67247
Value Function Loss: 0.09687

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.53631
Value Function Update Magnitude: 0.44869

Collected Steps per Second: 21,933.37534
Overall Steps per Second: 10,527.55828

Timestep Collection Time: 2.28082
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.75191

Cumulative Model Updates: 77,122
Cumulative Timesteps: 643,184,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 643184716...
Checkpoint 643184716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,568.50161
Policy Entropy: 1.65131
Value Function Loss: 0.09099

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.52356
Value Function Update Magnitude: 0.51345

Collected Steps per Second: 22,110.18365
Overall Steps per Second: 10,627.90010

Timestep Collection Time: 2.26158
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.70497

Cumulative Model Updates: 77,128
Cumulative Timesteps: 643,234,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,534.67748
Policy Entropy: 1.64756
Value Function Loss: 0.09472

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.52241
Value Function Update Magnitude: 0.66966

Collected Steps per Second: 21,801.82854
Overall Steps per Second: 10,432.56777

Timestep Collection Time: 2.29412
Timestep Consumption Time: 2.50010
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.79422

Cumulative Model Updates: 77,134
Cumulative Timesteps: 643,284,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 643284736...
Checkpoint 643284736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,631.58254
Policy Entropy: 1.64805
Value Function Loss: 0.09482

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.51916
Value Function Update Magnitude: 0.71097

Collected Steps per Second: 22,164.22447
Overall Steps per Second: 10,666.60503

Timestep Collection Time: 2.25706
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.68996

Cumulative Model Updates: 77,140
Cumulative Timesteps: 643,334,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,093.23431
Policy Entropy: 1.65841
Value Function Loss: 0.09937

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.51894
Value Function Update Magnitude: 0.73220

Collected Steps per Second: 22,258.98334
Overall Steps per Second: 10,627.96815

Timestep Collection Time: 2.24736
Timestep Consumption Time: 2.45946
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70683

Cumulative Model Updates: 77,146
Cumulative Timesteps: 643,384,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 643384786...
Checkpoint 643384786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,808.43171
Policy Entropy: 1.64712
Value Function Loss: 0.09545

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.49559
Value Function Update Magnitude: 0.73852

Collected Steps per Second: 21,832.24393
Overall Steps per Second: 10,432.79803

Timestep Collection Time: 2.29129
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.79488

Cumulative Model Updates: 77,152
Cumulative Timesteps: 643,434,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,537.29531
Policy Entropy: 1.67172
Value Function Loss: 0.09558

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.45160
Value Function Update Magnitude: 0.74225

Collected Steps per Second: 21,542.52214
Overall Steps per Second: 10,589.00134

Timestep Collection Time: 2.32099
Timestep Consumption Time: 2.40089
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.72188

Cumulative Model Updates: 77,158
Cumulative Timesteps: 643,484,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 643484810...
Checkpoint 643484810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,520.66304
Policy Entropy: 1.65659
Value Function Loss: 0.09504

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.15619
Policy Update Magnitude: 0.46091
Value Function Update Magnitude: 0.76357

Collected Steps per Second: 21,777.50347
Overall Steps per Second: 10,562.41669

Timestep Collection Time: 2.29622
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.73433

Cumulative Model Updates: 77,164
Cumulative Timesteps: 643,534,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,880.22179
Policy Entropy: 1.65544
Value Function Loss: 0.09264

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15296
Policy Update Magnitude: 0.51190
Value Function Update Magnitude: 0.72063

Collected Steps per Second: 22,122.82933
Overall Steps per Second: 10,415.06705

Timestep Collection Time: 2.26128
Timestep Consumption Time: 2.54195
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.80323

Cumulative Model Updates: 77,170
Cumulative Timesteps: 643,584,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 643584842...
Checkpoint 643584842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,897.24130
Policy Entropy: 1.63865
Value Function Loss: 0.09594

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.15591
Policy Update Magnitude: 0.52706
Value Function Update Magnitude: 0.62578

Collected Steps per Second: 21,368.36197
Overall Steps per Second: 10,216.39036

Timestep Collection Time: 2.34112
Timestep Consumption Time: 2.55552
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.89664

Cumulative Model Updates: 77,176
Cumulative Timesteps: 643,634,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,137.27440
Policy Entropy: 1.64818
Value Function Loss: 0.09974

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.51154
Value Function Update Magnitude: 0.57789

Collected Steps per Second: 22,550.74911
Overall Steps per Second: 10,491.83916

Timestep Collection Time: 2.21758
Timestep Consumption Time: 2.54880
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.76637

Cumulative Model Updates: 77,182
Cumulative Timesteps: 643,684,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 643684876...
Checkpoint 643684876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,579.53963
Policy Entropy: 1.65499
Value Function Loss: 0.09664

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.66798

Collected Steps per Second: 21,700.98274
Overall Steps per Second: 10,521.63561

Timestep Collection Time: 2.30506
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.75420

Cumulative Model Updates: 77,188
Cumulative Timesteps: 643,734,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,790.59468
Policy Entropy: 1.65994
Value Function Loss: 0.09900

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.54163
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 22,578.04748
Overall Steps per Second: 10,540.07109

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.53078
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.74665

Cumulative Model Updates: 77,194
Cumulative Timesteps: 643,784,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 643784928...
Checkpoint 643784928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,530.93141
Policy Entropy: 1.65062
Value Function Loss: 0.09250

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.64432

Collected Steps per Second: 21,875.81457
Overall Steps per Second: 10,558.47492

Timestep Collection Time: 2.28609
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.73648

Cumulative Model Updates: 77,200
Cumulative Timesteps: 643,834,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,366.84237
Policy Entropy: 1.64938
Value Function Loss: 0.09863

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.53852
Value Function Update Magnitude: 0.58919

Collected Steps per Second: 22,550.08076
Overall Steps per Second: 10,643.31037

Timestep Collection Time: 2.21791
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.69910

Cumulative Model Updates: 77,206
Cumulative Timesteps: 643,884,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 643884952...
Checkpoint 643884952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,037.68682
Policy Entropy: 1.65311
Value Function Loss: 0.10353

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.53341
Value Function Update Magnitude: 0.49556

Collected Steps per Second: 21,891.54596
Overall Steps per Second: 10,614.61056

Timestep Collection Time: 2.28536
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.71331

Cumulative Model Updates: 77,212
Cumulative Timesteps: 643,934,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,340.96166
Policy Entropy: 1.66858
Value Function Loss: 0.10461

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.48983

Collected Steps per Second: 22,401.15008
Overall Steps per Second: 10,554.07057

Timestep Collection Time: 2.23372
Timestep Consumption Time: 2.50738
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.74111

Cumulative Model Updates: 77,218
Cumulative Timesteps: 643,985,020

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 643985020...
Checkpoint 643985020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,584.67280
Policy Entropy: 1.67207
Value Function Loss: 0.09786

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.45906

Collected Steps per Second: 21,660.60792
Overall Steps per Second: 10,492.41232

Timestep Collection Time: 2.30917
Timestep Consumption Time: 2.45790
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.76706

Cumulative Model Updates: 77,224
Cumulative Timesteps: 644,035,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,530.16474
Policy Entropy: 1.66511
Value Function Loss: 0.09589

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.52952
Value Function Update Magnitude: 0.54837

Collected Steps per Second: 21,902.24588
Overall Steps per Second: 10,485.60389

Timestep Collection Time: 2.28342
Timestep Consumption Time: 2.48617
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.76959

Cumulative Model Updates: 77,230
Cumulative Timesteps: 644,085,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644085050...
Checkpoint 644085050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,729.04808
Policy Entropy: 1.65079
Value Function Loss: 0.09909

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.15521
Policy Update Magnitude: 0.49499
Value Function Update Magnitude: 0.63549

Collected Steps per Second: 21,605.56915
Overall Steps per Second: 10,543.88005

Timestep Collection Time: 2.31551
Timestep Consumption Time: 2.42923
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.74474

Cumulative Model Updates: 77,236
Cumulative Timesteps: 644,135,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,763.24267
Policy Entropy: 1.65852
Value Function Loss: 0.09904

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.71879

Collected Steps per Second: 22,015.26309
Overall Steps per Second: 10,521.04198

Timestep Collection Time: 2.27115
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.75238

Cumulative Model Updates: 77,242
Cumulative Timesteps: 644,185,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 644185078...
Checkpoint 644185078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,420.97233
Policy Entropy: 1.67067
Value Function Loss: 0.09341

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.63052

Collected Steps per Second: 22,083.05839
Overall Steps per Second: 10,566.00970

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.46807
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73234

Cumulative Model Updates: 77,248
Cumulative Timesteps: 644,235,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,889.56126
Policy Entropy: 1.67276
Value Function Loss: 0.09146

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.61236

Collected Steps per Second: 22,380.06291
Overall Steps per Second: 10,534.24907

Timestep Collection Time: 2.23476
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.74775

Cumulative Model Updates: 77,254
Cumulative Timesteps: 644,285,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 644285094...
Checkpoint 644285094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,639.28523
Policy Entropy: 1.67501
Value Function Loss: 0.08786

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.52763
Value Function Update Magnitude: 0.64915

Collected Steps per Second: 22,307.92627
Overall Steps per Second: 10,674.88117

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68595

Cumulative Model Updates: 77,260
Cumulative Timesteps: 644,335,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,179.07195
Policy Entropy: 1.66800
Value Function Loss: 0.09351

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.53895
Value Function Update Magnitude: 0.66811

Collected Steps per Second: 22,790.38825
Overall Steps per Second: 10,766.29688

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.45120
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.64598

Cumulative Model Updates: 77,266
Cumulative Timesteps: 644,385,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 644385136...
Checkpoint 644385136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,240.89100
Policy Entropy: 1.67144
Value Function Loss: 0.09897

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.53966
Value Function Update Magnitude: 0.70602

Collected Steps per Second: 21,961.29063
Overall Steps per Second: 10,492.84081

Timestep Collection Time: 2.27710
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.76592

Cumulative Model Updates: 77,272
Cumulative Timesteps: 644,435,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,874.14661
Policy Entropy: 1.67124
Value Function Loss: 0.09768

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.72103

Collected Steps per Second: 22,548.32297
Overall Steps per Second: 10,768.66069

Timestep Collection Time: 2.21808
Timestep Consumption Time: 2.42632
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.64440

Cumulative Model Updates: 77,278
Cumulative Timesteps: 644,485,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 644485158...
Checkpoint 644485158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,860.11425
Policy Entropy: 1.65791
Value Function Loss: 0.09421

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.52940
Value Function Update Magnitude: 0.68794

Collected Steps per Second: 22,175.12197
Overall Steps per Second: 10,582.41957

Timestep Collection Time: 2.25712
Timestep Consumption Time: 2.47261
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.72973

Cumulative Model Updates: 77,284
Cumulative Timesteps: 644,535,210

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,221.87241
Policy Entropy: 1.65896
Value Function Loss: 0.09384

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.65837

Collected Steps per Second: 21,858.91229
Overall Steps per Second: 10,452.97048

Timestep Collection Time: 2.28795
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.78448

Cumulative Model Updates: 77,290
Cumulative Timesteps: 644,585,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644585222...
Checkpoint 644585222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,067.51023
Policy Entropy: 1.66262
Value Function Loss: 0.08810

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.53596
Value Function Update Magnitude: 0.60315

Collected Steps per Second: 20,081.69528
Overall Steps per Second: 10,137.58863

Timestep Collection Time: 2.49033
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.93313

Cumulative Model Updates: 77,296
Cumulative Timesteps: 644,635,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,353.40218
Policy Entropy: 1.68063
Value Function Loss: 0.07915

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.51853
Value Function Update Magnitude: 0.69166

Collected Steps per Second: 22,177.47325
Overall Steps per Second: 10,588.32057

Timestep Collection Time: 2.25589
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.72502

Cumulative Model Updates: 77,302
Cumulative Timesteps: 644,685,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 644685262...
Checkpoint 644685262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,064.13558
Policy Entropy: 1.67478
Value Function Loss: 0.07903

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.51826
Value Function Update Magnitude: 0.70737

Collected Steps per Second: 22,320.78897
Overall Steps per Second: 10,471.87886

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.53514
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.77565

Cumulative Model Updates: 77,308
Cumulative Timesteps: 644,735,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,058.42427
Policy Entropy: 1.67583
Value Function Loss: 0.08225

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.70814

Collected Steps per Second: 22,539.17581
Overall Steps per Second: 10,576.76537

Timestep Collection Time: 2.21854
Timestep Consumption Time: 2.50918
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72772

Cumulative Model Updates: 77,314
Cumulative Timesteps: 644,785,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 644785276...
Checkpoint 644785276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,212.61959
Policy Entropy: 1.67310
Value Function Loss: 0.08380

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.71250

Collected Steps per Second: 22,354.10032
Overall Steps per Second: 10,607.11312

Timestep Collection Time: 2.23735
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.71514

Cumulative Model Updates: 77,320
Cumulative Timesteps: 644,835,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,454.80822
Policy Entropy: 1.67787
Value Function Loss: 0.08528

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.52852
Value Function Update Magnitude: 0.66334

Collected Steps per Second: 21,867.77846
Overall Steps per Second: 10,603.11142

Timestep Collection Time: 2.28738
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.71748

Cumulative Model Updates: 77,326
Cumulative Timesteps: 644,885,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 644885310...
Checkpoint 644885310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,532.89418
Policy Entropy: 1.67813
Value Function Loss: 0.07847

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.52551
Value Function Update Magnitude: 0.72986

Collected Steps per Second: 21,648.60257
Overall Steps per Second: 10,531.37883

Timestep Collection Time: 2.30962
Timestep Consumption Time: 2.43810
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.74772

Cumulative Model Updates: 77,332
Cumulative Timesteps: 644,935,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,676.10399
Policy Entropy: 1.68856
Value Function Loss: 0.08876

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.53562
Value Function Update Magnitude: 0.75116

Collected Steps per Second: 21,669.36342
Overall Steps per Second: 10,558.02658

Timestep Collection Time: 2.30777
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.73649

Cumulative Model Updates: 77,338
Cumulative Timesteps: 644,985,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 644985318...
Checkpoint 644985318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,214.05413
Policy Entropy: 1.69306
Value Function Loss: 0.09115

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.73409

Collected Steps per Second: 21,322.50961
Overall Steps per Second: 10,492.37991

Timestep Collection Time: 2.34625
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.76803

Cumulative Model Updates: 77,344
Cumulative Timesteps: 645,035,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,914.78747
Policy Entropy: 1.68518
Value Function Loss: 0.09136

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.53898
Value Function Update Magnitude: 0.74198

Collected Steps per Second: 21,204.88132
Overall Steps per Second: 10,447.68670

Timestep Collection Time: 2.35823
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.78632

Cumulative Model Updates: 77,350
Cumulative Timesteps: 645,085,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 645085352...
Checkpoint 645085352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,976.14850
Policy Entropy: 1.68999
Value Function Loss: 0.08984

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.53789
Value Function Update Magnitude: 0.79269

Collected Steps per Second: 21,365.13679
Overall Steps per Second: 10,635.78994

Timestep Collection Time: 2.34054
Timestep Consumption Time: 2.36113
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.70167

Cumulative Model Updates: 77,356
Cumulative Timesteps: 645,135,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,089.17278
Policy Entropy: 1.69218
Value Function Loss: 0.08728

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.52969
Value Function Update Magnitude: 0.75500

Collected Steps per Second: 21,510.89732
Overall Steps per Second: 10,459.39965

Timestep Collection Time: 2.32505
Timestep Consumption Time: 2.45667
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.78173

Cumulative Model Updates: 77,362
Cumulative Timesteps: 645,185,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 645185372...
Checkpoint 645185372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,330.24434
Policy Entropy: 1.70139
Value Function Loss: 0.09482

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.53203
Value Function Update Magnitude: 0.63129

Collected Steps per Second: 21,114.45236
Overall Steps per Second: 10,497.20613

Timestep Collection Time: 2.36994
Timestep Consumption Time: 2.39704
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.76698

Cumulative Model Updates: 77,368
Cumulative Timesteps: 645,235,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,715.79016
Policy Entropy: 1.71076
Value Function Loss: 0.09557

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.69766

Collected Steps per Second: 21,502.12360
Overall Steps per Second: 10,591.42673

Timestep Collection Time: 2.32591
Timestep Consumption Time: 2.39602
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.72193

Cumulative Model Updates: 77,374
Cumulative Timesteps: 645,285,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 645285424...
Checkpoint 645285424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,694.86282
Policy Entropy: 1.71585
Value Function Loss: 0.08809

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.77531

Collected Steps per Second: 21,624.14047
Overall Steps per Second: 10,626.03532

Timestep Collection Time: 2.31251
Timestep Consumption Time: 2.39348
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.70599

Cumulative Model Updates: 77,380
Cumulative Timesteps: 645,335,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,191.52388
Policy Entropy: 1.71329
Value Function Loss: 0.08539

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.52021
Value Function Update Magnitude: 0.74553

Collected Steps per Second: 21,888.92055
Overall Steps per Second: 10,484.84265

Timestep Collection Time: 2.28536
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.77108

Cumulative Model Updates: 77,386
Cumulative Timesteps: 645,385,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 645385454...
Checkpoint 645385454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,001.06584
Policy Entropy: 1.70416
Value Function Loss: 0.09399

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.51539
Value Function Update Magnitude: 0.66150

Collected Steps per Second: 22,010.82973
Overall Steps per Second: 10,645.96966

Timestep Collection Time: 2.27225
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.69793

Cumulative Model Updates: 77,392
Cumulative Timesteps: 645,435,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,347.64860
Policy Entropy: 1.71030
Value Function Loss: 0.09393

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.46751
Value Function Update Magnitude: 0.65780

Collected Steps per Second: 22,326.81519
Overall Steps per Second: 10,592.98454

Timestep Collection Time: 2.24018
Timestep Consumption Time: 2.48144
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72162

Cumulative Model Updates: 77,398
Cumulative Timesteps: 645,485,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 645485484...
Checkpoint 645485484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,149.26640
Policy Entropy: 1.72613
Value Function Loss: 0.10359

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.43255
Value Function Update Magnitude: 0.59440

Collected Steps per Second: 22,325.80193
Overall Steps per Second: 10,623.90938

Timestep Collection Time: 2.24064
Timestep Consumption Time: 2.46799
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.70862

Cumulative Model Updates: 77,404
Cumulative Timesteps: 645,535,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,054.38797
Policy Entropy: 1.73903
Value Function Loss: 0.10399

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.44119
Value Function Update Magnitude: 0.68407

Collected Steps per Second: 21,941.13059
Overall Steps per Second: 10,517.87438

Timestep Collection Time: 2.27910
Timestep Consumption Time: 2.47528
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.75438

Cumulative Model Updates: 77,410
Cumulative Timesteps: 645,585,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 645585514...
Checkpoint 645585514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,702.00336
Policy Entropy: 1.73498
Value Function Loss: 0.10287

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.48036
Value Function Update Magnitude: 0.74481

Collected Steps per Second: 21,439.38771
Overall Steps per Second: 10,421.05692

Timestep Collection Time: 2.33253
Timestep Consumption Time: 2.46622
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.79875

Cumulative Model Updates: 77,416
Cumulative Timesteps: 645,635,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,396.16625
Policy Entropy: 1.73341
Value Function Loss: 0.10252

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.72778

Collected Steps per Second: 22,150.01972
Overall Steps per Second: 10,490.11623

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.50956
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.76734

Cumulative Model Updates: 77,422
Cumulative Timesteps: 645,685,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 645685532...
Checkpoint 645685532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,059.85495
Policy Entropy: 1.72903
Value Function Loss: 0.09443

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.53119
Value Function Update Magnitude: 0.73916

Collected Steps per Second: 21,668.23493
Overall Steps per Second: 10,424.34880

Timestep Collection Time: 2.30882
Timestep Consumption Time: 2.49033
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.79915

Cumulative Model Updates: 77,428
Cumulative Timesteps: 645,735,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,014.10940
Policy Entropy: 1.73121
Value Function Loss: 0.09599

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.16861
Policy Update Magnitude: 0.44344
Value Function Update Magnitude: 0.69894

Collected Steps per Second: 22,493.97420
Overall Steps per Second: 10,639.87192

Timestep Collection Time: 2.22406
Timestep Consumption Time: 2.47787
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.70194

Cumulative Model Updates: 77,434
Cumulative Timesteps: 645,785,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 645785588...
Checkpoint 645785588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,355.43463
Policy Entropy: 1.73078
Value Function Loss: 0.09262

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.48446
Value Function Update Magnitude: 0.64003

Collected Steps per Second: 22,231.73459
Overall Steps per Second: 10,690.59422

Timestep Collection Time: 2.24994
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.67888

Cumulative Model Updates: 77,440
Cumulative Timesteps: 645,835,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,448.56814
Policy Entropy: 1.73663
Value Function Loss: 0.09695

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.53503
Value Function Update Magnitude: 0.68433

Collected Steps per Second: 22,391.76474
Overall Steps per Second: 10,412.74517

Timestep Collection Time: 2.23395
Timestep Consumption Time: 2.56997
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.80392

Cumulative Model Updates: 77,446
Cumulative Timesteps: 645,885,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 645885630...
Checkpoint 645885630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,898.47677
Policy Entropy: 1.75277
Value Function Loss: 0.09874

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.54452
Value Function Update Magnitude: 0.79591

Collected Steps per Second: 21,976.79244
Overall Steps per Second: 10,381.42973

Timestep Collection Time: 2.27549
Timestep Consumption Time: 2.54157
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.81706

Cumulative Model Updates: 77,452
Cumulative Timesteps: 645,935,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,133.39141
Policy Entropy: 1.74665
Value Function Loss: 0.09982

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.54418
Value Function Update Magnitude: 0.78894

Collected Steps per Second: 22,589.20297
Overall Steps per Second: 10,707.04063

Timestep Collection Time: 2.21522
Timestep Consumption Time: 2.45834
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.67356

Cumulative Model Updates: 77,458
Cumulative Timesteps: 645,985,678

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 645985678...
Checkpoint 645985678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,436.23968
Policy Entropy: 1.73950
Value Function Loss: 0.09744

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.68205

Collected Steps per Second: 22,343.76935
Overall Steps per Second: 10,687.16756

Timestep Collection Time: 2.23776
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.67851

Cumulative Model Updates: 77,464
Cumulative Timesteps: 646,035,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,379.30982
Policy Entropy: 1.73623
Value Function Loss: 0.09582

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.53397
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 22,352.81632
Overall Steps per Second: 10,500.23078

Timestep Collection Time: 2.23685
Timestep Consumption Time: 2.52495
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.76180

Cumulative Model Updates: 77,470
Cumulative Timesteps: 646,085,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 646085678...
Checkpoint 646085678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,332.27538
Policy Entropy: 1.74978
Value Function Loss: 0.09342

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.52890
Value Function Update Magnitude: 0.69471

Collected Steps per Second: 21,510.36430
Overall Steps per Second: 10,370.89202

Timestep Collection Time: 2.32474
Timestep Consumption Time: 2.49702
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.82176

Cumulative Model Updates: 77,476
Cumulative Timesteps: 646,135,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,536.10405
Policy Entropy: 1.75570
Value Function Loss: 0.09066

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.47414
Value Function Update Magnitude: 0.66721

Collected Steps per Second: 22,441.87287
Overall Steps per Second: 10,674.55886

Timestep Collection Time: 2.22825
Timestep Consumption Time: 2.45635
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.68460

Cumulative Model Updates: 77,482
Cumulative Timesteps: 646,185,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 646185690...
Checkpoint 646185690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,900.88249
Policy Entropy: 1.74521
Value Function Loss: 0.08726

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.48241
Value Function Update Magnitude: 0.53878

Collected Steps per Second: 21,627.74638
Overall Steps per Second: 10,415.26910

Timestep Collection Time: 2.31369
Timestep Consumption Time: 2.49079
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.80448

Cumulative Model Updates: 77,488
Cumulative Timesteps: 646,235,730

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,862.80254
Policy Entropy: 1.74454
Value Function Loss: 0.09510

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.52213
Value Function Update Magnitude: 0.50040

Collected Steps per Second: 21,994.80904
Overall Steps per Second: 10,497.54757

Timestep Collection Time: 2.27399
Timestep Consumption Time: 2.49055
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.76454

Cumulative Model Updates: 77,494
Cumulative Timesteps: 646,285,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 646285746...
Checkpoint 646285746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,954.15592
Policy Entropy: 1.76278
Value Function Loss: 0.10118

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.53857
Value Function Update Magnitude: 0.54166

Collected Steps per Second: 22,062.46143
Overall Steps per Second: 10,456.64456

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.51747
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.78567

Cumulative Model Updates: 77,500
Cumulative Timesteps: 646,335,788

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,093.21117
Policy Entropy: 1.77769
Value Function Loss: 0.09760

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.52894
Value Function Update Magnitude: 0.51853

Collected Steps per Second: 22,663.03177
Overall Steps per Second: 10,518.68037

Timestep Collection Time: 2.20650
Timestep Consumption Time: 2.54752
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.75402

Cumulative Model Updates: 77,506
Cumulative Timesteps: 646,385,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 646385794...
Checkpoint 646385794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,539.26419
Policy Entropy: 1.78847
Value Function Loss: 0.09435

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.51762
Value Function Update Magnitude: 0.60636

Collected Steps per Second: 22,103.01886
Overall Steps per Second: 10,508.38454

Timestep Collection Time: 2.26295
Timestep Consumption Time: 2.49687
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.75982

Cumulative Model Updates: 77,512
Cumulative Timesteps: 646,435,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,884.72984
Policy Entropy: 1.78586
Value Function Loss: 0.08620

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.51859
Value Function Update Magnitude: 0.57438

Collected Steps per Second: 22,377.32364
Overall Steps per Second: 10,486.43402

Timestep Collection Time: 2.23601
Timestep Consumption Time: 2.53548
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.77150

Cumulative Model Updates: 77,518
Cumulative Timesteps: 646,485,848

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 646485848...
Checkpoint 646485848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,207.03660
Policy Entropy: 1.79122
Value Function Loss: 0.09468

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.52263
Value Function Update Magnitude: 0.46082

Collected Steps per Second: 21,392.54020
Overall Steps per Second: 10,133.56045

Timestep Collection Time: 2.33867
Timestep Consumption Time: 2.59839
PPO Batch Consumption Time: 0.30737
Total Iteration Time: 4.93706

Cumulative Model Updates: 77,524
Cumulative Timesteps: 646,535,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,589.98477
Policy Entropy: 1.77760
Value Function Loss: 0.09422

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.52772
Value Function Update Magnitude: 0.47475

Collected Steps per Second: 21,930.13031
Overall Steps per Second: 10,543.15591

Timestep Collection Time: 2.28088
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.74431

Cumulative Model Updates: 77,530
Cumulative Timesteps: 646,585,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 646585898...
Checkpoint 646585898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,942.11061
Policy Entropy: 1.76836
Value Function Loss: 0.08945

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.53731

Collected Steps per Second: 21,402.24046
Overall Steps per Second: 10,322.84911

Timestep Collection Time: 2.33676
Timestep Consumption Time: 2.50802
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.84479

Cumulative Model Updates: 77,536
Cumulative Timesteps: 646,635,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,650.80130
Policy Entropy: 1.76437
Value Function Loss: 0.08814

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.51806
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 22,075.44202
Overall Steps per Second: 10,434.37629

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.52750
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.79300

Cumulative Model Updates: 77,542
Cumulative Timesteps: 646,685,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 646685922...
Checkpoint 646685922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,277.31095
Policy Entropy: 1.77692
Value Function Loss: 0.09311

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.63759

Collected Steps per Second: 22,411.63129
Overall Steps per Second: 10,570.34010

Timestep Collection Time: 2.23232
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.73305

Cumulative Model Updates: 77,548
Cumulative Timesteps: 646,735,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,338.96788
Policy Entropy: 1.78601
Value Function Loss: 0.10087

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.58609

Collected Steps per Second: 22,513.92599
Overall Steps per Second: 10,548.03566

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.74041

Cumulative Model Updates: 77,554
Cumulative Timesteps: 646,785,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 646785954...
Checkpoint 646785954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,685.37001
Policy Entropy: 1.78741
Value Function Loss: 0.09909

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.53645
Value Function Update Magnitude: 0.52045

Collected Steps per Second: 22,225.17650
Overall Steps per Second: 10,527.50946

Timestep Collection Time: 2.25060
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.75136

Cumulative Model Updates: 77,560
Cumulative Timesteps: 646,835,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,337.18225
Policy Entropy: 1.77785
Value Function Loss: 0.09966

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.53483
Value Function Update Magnitude: 0.46630

Collected Steps per Second: 22,549.27062
Overall Steps per Second: 10,543.62654

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.52524
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.74296

Cumulative Model Updates: 77,566
Cumulative Timesteps: 646,885,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 646885982...
Checkpoint 646885982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,109.32601
Policy Entropy: 1.78571
Value Function Loss: 0.09747

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.53829
Value Function Update Magnitude: 0.55571

Collected Steps per Second: 22,347.29405
Overall Steps per Second: 10,565.55698

Timestep Collection Time: 2.23866
Timestep Consumption Time: 2.49635
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.73501

Cumulative Model Updates: 77,572
Cumulative Timesteps: 646,936,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,137.94352
Policy Entropy: 1.78522
Value Function Loss: 0.09758

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.54194
Value Function Update Magnitude: 0.66174

Collected Steps per Second: 22,617.01554
Overall Steps per Second: 10,614.89448

Timestep Collection Time: 2.21126
Timestep Consumption Time: 2.50024
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.71149

Cumulative Model Updates: 77,578
Cumulative Timesteps: 646,986,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 646986022...
Checkpoint 646986022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,235.22331
Policy Entropy: 1.79666
Value Function Loss: 0.09309

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.72750

Collected Steps per Second: 21,970.21603
Overall Steps per Second: 10,437.86968

Timestep Collection Time: 2.27581
Timestep Consumption Time: 2.51444
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.79025

Cumulative Model Updates: 77,584
Cumulative Timesteps: 647,036,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,749.73077
Policy Entropy: 1.79443
Value Function Loss: 0.09243

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.75852

Collected Steps per Second: 22,017.30534
Overall Steps per Second: 10,467.40761

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.77807

Cumulative Model Updates: 77,590
Cumulative Timesteps: 647,086,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 647086036...
Checkpoint 647086036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,542.64103
Policy Entropy: 1.80193
Value Function Loss: 0.09634

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.54141
Value Function Update Magnitude: 0.76056

Collected Steps per Second: 21,681.93914
Overall Steps per Second: 10,585.07678

Timestep Collection Time: 2.30607
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72363

Cumulative Model Updates: 77,596
Cumulative Timesteps: 647,136,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,475.20222
Policy Entropy: 1.79604
Value Function Loss: 0.09315

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.52910
Value Function Update Magnitude: 0.77124

Collected Steps per Second: 21,962.13808
Overall Steps per Second: 10,311.03343

Timestep Collection Time: 2.27710
Timestep Consumption Time: 2.57304
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.85014

Cumulative Model Updates: 77,602
Cumulative Timesteps: 647,186,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 647186046...
Checkpoint 647186046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,853.13764
Policy Entropy: 1.78090
Value Function Loss: 0.09039

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.51649
Value Function Update Magnitude: 0.75478

Collected Steps per Second: 22,258.34277
Overall Steps per Second: 10,446.70805

Timestep Collection Time: 2.24797
Timestep Consumption Time: 2.54168
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78964

Cumulative Model Updates: 77,608
Cumulative Timesteps: 647,236,082

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,028.07972
Policy Entropy: 1.77703
Value Function Loss: 0.08264

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.52828
Value Function Update Magnitude: 0.74356

Collected Steps per Second: 22,816.74324
Overall Steps per Second: 10,608.59108

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.52249
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.71448

Cumulative Model Updates: 77,614
Cumulative Timesteps: 647,286,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 647286096...
Checkpoint 647286096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,949.19612
Policy Entropy: 1.79249
Value Function Loss: 0.08191

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.52693
Value Function Update Magnitude: 0.73237

Collected Steps per Second: 22,053.70401
Overall Steps per Second: 10,464.55039

Timestep Collection Time: 2.26828
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.78033

Cumulative Model Updates: 77,620
Cumulative Timesteps: 647,336,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,701.67148
Policy Entropy: 1.80660
Value Function Loss: 0.08562

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.52505
Value Function Update Magnitude: 0.72516

Collected Steps per Second: 22,802.42454
Overall Steps per Second: 10,791.41360

Timestep Collection Time: 2.19468
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.63739

Cumulative Model Updates: 77,626
Cumulative Timesteps: 647,386,164

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 647386164...
Checkpoint 647386164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,021.25625
Policy Entropy: 1.81459
Value Function Loss: 0.09024

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.52499
Value Function Update Magnitude: 0.75977

Collected Steps per Second: 22,170.86703
Overall Steps per Second: 10,644.50645

Timestep Collection Time: 2.25566
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.69820

Cumulative Model Updates: 77,632
Cumulative Timesteps: 647,436,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,651.85028
Policy Entropy: 1.80152
Value Function Loss: 0.09094

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.52419
Value Function Update Magnitude: 0.75485

Collected Steps per Second: 22,464.77027
Overall Steps per Second: 10,530.51075

Timestep Collection Time: 2.22615
Timestep Consumption Time: 2.52291
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.74906

Cumulative Model Updates: 77,638
Cumulative Timesteps: 647,486,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 647486184...
Checkpoint 647486184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,647.89612
Policy Entropy: 1.79967
Value Function Loss: 0.09614

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.52285
Value Function Update Magnitude: 0.77051

Collected Steps per Second: 21,865.72421
Overall Steps per Second: 10,576.04995

Timestep Collection Time: 2.28815
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.73069

Cumulative Model Updates: 77,644
Cumulative Timesteps: 647,536,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,715.12595
Policy Entropy: 1.78530
Value Function Loss: 0.09209

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.51607
Value Function Update Magnitude: 0.74231

Collected Steps per Second: 21,924.58411
Overall Steps per Second: 10,571.77240

Timestep Collection Time: 2.28109
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.73071

Cumulative Model Updates: 77,650
Cumulative Timesteps: 647,586,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 647586228...
Checkpoint 647586228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,147.57449
Policy Entropy: 1.78688
Value Function Loss: 0.08619

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.50950
Value Function Update Magnitude: 0.72469

Collected Steps per Second: 21,858.68210
Overall Steps per Second: 10,537.44421

Timestep Collection Time: 2.28779
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.74574

Cumulative Model Updates: 77,656
Cumulative Timesteps: 647,636,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,878.77688
Policy Entropy: 1.78943
Value Function Loss: 0.08606

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.51499
Value Function Update Magnitude: 0.66862

Collected Steps per Second: 22,129.40425
Overall Steps per Second: 10,462.55952

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.52102
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.78181

Cumulative Model Updates: 77,662
Cumulative Timesteps: 647,686,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 647686266...
Checkpoint 647686266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,841.79166
Policy Entropy: 1.79077
Value Function Loss: 0.09105

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 21,336.58586
Overall Steps per Second: 10,258.05585

Timestep Collection Time: 2.34386
Timestep Consumption Time: 2.53133
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.87519

Cumulative Model Updates: 77,668
Cumulative Timesteps: 647,736,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,406.03788
Policy Entropy: 1.78984
Value Function Loss: 0.08935

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.52961
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 22,621.64734
Overall Steps per Second: 10,467.86044

Timestep Collection Time: 2.21045
Timestep Consumption Time: 2.56646
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.77691

Cumulative Model Updates: 77,674
Cumulative Timesteps: 647,786,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 647786280...
Checkpoint 647786280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,355.44510
Policy Entropy: 1.79355
Value Function Loss: 0.09518

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.51481
Value Function Update Magnitude: 0.64905

Collected Steps per Second: 22,174.54355
Overall Steps per Second: 10,323.46563

Timestep Collection Time: 2.25547
Timestep Consumption Time: 2.58922
PPO Batch Consumption Time: 0.30482
Total Iteration Time: 4.84469

Cumulative Model Updates: 77,680
Cumulative Timesteps: 647,836,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,927.55504
Policy Entropy: 1.78631
Value Function Loss: 0.09936

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.51417
Value Function Update Magnitude: 0.65757

Collected Steps per Second: 22,767.67811
Overall Steps per Second: 10,628.68457

Timestep Collection Time: 2.19610
Timestep Consumption Time: 2.50816
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.70425

Cumulative Model Updates: 77,686
Cumulative Timesteps: 647,886,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 647886294...
Checkpoint 647886294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,191.53253
Policy Entropy: 1.81329
Value Function Loss: 0.10418

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.67385

Collected Steps per Second: 22,294.89804
Overall Steps per Second: 10,676.38958

Timestep Collection Time: 2.24320
Timestep Consumption Time: 2.44115
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.68436

Cumulative Model Updates: 77,692
Cumulative Timesteps: 647,936,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,275.20380
Policy Entropy: 1.80978
Value Function Loss: 0.10103

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.47255
Value Function Update Magnitude: 0.61500

Collected Steps per Second: 22,637.63858
Overall Steps per Second: 10,579.36592

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.73110

Cumulative Model Updates: 77,698
Cumulative Timesteps: 647,986,358

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 647986358...
Checkpoint 647986358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,744.11017
Policy Entropy: 1.82091
Value Function Loss: 0.10061

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.15516
Policy Update Magnitude: 0.49478
Value Function Update Magnitude: 0.65443

Collected Steps per Second: 22,200.67757
Overall Steps per Second: 10,491.77780

Timestep Collection Time: 2.25227
Timestep Consumption Time: 2.51355
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.76583

Cumulative Model Updates: 77,704
Cumulative Timesteps: 648,036,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,716.00999
Policy Entropy: 1.80949
Value Function Loss: 0.09997

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.17136
Policy Update Magnitude: 0.49185
Value Function Update Magnitude: 0.66178

Collected Steps per Second: 22,533.01669
Overall Steps per Second: 10,555.61694

Timestep Collection Time: 2.22110
Timestep Consumption Time: 2.52027
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.74136

Cumulative Model Updates: 77,710
Cumulative Timesteps: 648,086,408

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 648086408...
Checkpoint 648086408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,037.71649
Policy Entropy: 1.79734
Value Function Loss: 0.09703

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.17021
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.66141

Collected Steps per Second: 21,747.34197
Overall Steps per Second: 10,567.83232

Timestep Collection Time: 2.30005
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.73323

Cumulative Model Updates: 77,716
Cumulative Timesteps: 648,136,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,309.58284
Policy Entropy: 1.79092
Value Function Loss: 0.09218

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.51431
Value Function Update Magnitude: 0.64494

Collected Steps per Second: 21,909.93451
Overall Steps per Second: 10,575.49182

Timestep Collection Time: 2.28317
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.73018

Cumulative Model Updates: 77,722
Cumulative Timesteps: 648,186,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 648186452...
Checkpoint 648186452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,543.58355
Policy Entropy: 1.78682
Value Function Loss: 0.08671

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.51111
Value Function Update Magnitude: 0.65668

Collected Steps per Second: 21,702.43884
Overall Steps per Second: 10,543.94857

Timestep Collection Time: 2.30499
Timestep Consumption Time: 2.43934
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.74433

Cumulative Model Updates: 77,728
Cumulative Timesteps: 648,236,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,273.41214
Policy Entropy: 1.80971
Value Function Loss: 0.08791

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.49496
Value Function Update Magnitude: 0.58804

Collected Steps per Second: 22,270.63169
Overall Steps per Second: 10,509.41335

Timestep Collection Time: 2.24520
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.75783

Cumulative Model Updates: 77,734
Cumulative Timesteps: 648,286,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 648286478...
Checkpoint 648286478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,953.18067
Policy Entropy: 1.83375
Value Function Loss: 0.08702

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.45627
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 21,706.23369
Overall Steps per Second: 10,416.56692

Timestep Collection Time: 2.30524
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.80369

Cumulative Model Updates: 77,740
Cumulative Timesteps: 648,336,516

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,810.16877
Policy Entropy: 1.85504
Value Function Loss: 0.09692

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.45822
Value Function Update Magnitude: 0.67846

Collected Steps per Second: 22,661.76326
Overall Steps per Second: 10,661.04465

Timestep Collection Time: 2.20742
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.69222

Cumulative Model Updates: 77,746
Cumulative Timesteps: 648,386,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 648386540...
Checkpoint 648386540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,747.78900
Policy Entropy: 1.84380
Value Function Loss: 0.09696

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.49356
Value Function Update Magnitude: 0.61993

Collected Steps per Second: 22,357.61162
Overall Steps per Second: 10,660.73921

Timestep Collection Time: 2.23664
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.69067

Cumulative Model Updates: 77,752
Cumulative Timesteps: 648,436,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,060.21626
Policy Entropy: 1.84967
Value Function Loss: 0.10508

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.50662
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 22,395.73756
Overall Steps per Second: 10,540.34740

Timestep Collection Time: 2.23301
Timestep Consumption Time: 2.51161
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.74463

Cumulative Model Updates: 77,758
Cumulative Timesteps: 648,486,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 648486556...
Checkpoint 648486556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,812.99564
Policy Entropy: 1.83144
Value Function Loss: 0.10346

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.50052
Value Function Update Magnitude: 0.64601

Collected Steps per Second: 22,077.57267
Overall Steps per Second: 10,417.28251

Timestep Collection Time: 2.26583
Timestep Consumption Time: 2.53619
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.80202

Cumulative Model Updates: 77,764
Cumulative Timesteps: 648,536,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,938.60652
Policy Entropy: 1.84117
Value Function Loss: 0.10751

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.67069

Collected Steps per Second: 22,123.45254
Overall Steps per Second: 10,607.12642

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.45504
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.71626

Cumulative Model Updates: 77,770
Cumulative Timesteps: 648,586,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 648586606...
Checkpoint 648586606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,403.35314
Policy Entropy: 1.83445
Value Function Loss: 0.10459

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 21,834.10213
Overall Steps per Second: 10,542.11609

Timestep Collection Time: 2.29000
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.74288

Cumulative Model Updates: 77,776
Cumulative Timesteps: 648,636,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,763.64519
Policy Entropy: 1.83441
Value Function Loss: 0.09608

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.52123
Value Function Update Magnitude: 0.54153

Collected Steps per Second: 21,797.36696
Overall Steps per Second: 10,626.06670

Timestep Collection Time: 2.29413
Timestep Consumption Time: 2.41184
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.70597

Cumulative Model Updates: 77,782
Cumulative Timesteps: 648,686,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 648686612...
Checkpoint 648686612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,436.70233
Policy Entropy: 1.82920
Value Function Loss: 0.09351

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.54018

Collected Steps per Second: 21,965.96435
Overall Steps per Second: 10,575.75198

Timestep Collection Time: 2.27625
Timestep Consumption Time: 2.45155
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.72780

Cumulative Model Updates: 77,788
Cumulative Timesteps: 648,736,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,069.81135
Policy Entropy: 1.81664
Value Function Loss: 0.08431

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.44617
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 22,382.32736
Overall Steps per Second: 10,447.84298

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.55320
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.78836

Cumulative Model Updates: 77,794
Cumulative Timesteps: 648,786,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 648786640...
Checkpoint 648786640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,826.92847
Policy Entropy: 1.80776
Value Function Loss: 0.08512

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.46584
Value Function Update Magnitude: 0.66601

Collected Steps per Second: 22,539.75858
Overall Steps per Second: 10,610.47979

Timestep Collection Time: 2.21892
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.71364

Cumulative Model Updates: 77,800
Cumulative Timesteps: 648,836,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,072.09208
Policy Entropy: 1.80421
Value Function Loss: 0.09093

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.47245
Value Function Update Magnitude: 0.68374

Collected Steps per Second: 22,459.95133
Overall Steps per Second: 10,535.83073

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.74932

Cumulative Model Updates: 77,806
Cumulative Timesteps: 648,886,692

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 648886692...
Checkpoint 648886692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,488.30217
Policy Entropy: 1.81592
Value Function Loss: 0.10027

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.47881
Value Function Update Magnitude: 0.67214

Collected Steps per Second: 22,248.72497
Overall Steps per Second: 10,600.56707

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.71918

Cumulative Model Updates: 77,812
Cumulative Timesteps: 648,936,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,707.76735
Policy Entropy: 1.82635
Value Function Loss: 0.10259

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.61448

Collected Steps per Second: 22,731.67542
Overall Steps per Second: 10,799.06075

Timestep Collection Time: 2.20010
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63114

Cumulative Model Updates: 77,818
Cumulative Timesteps: 648,986,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 648986730...
Checkpoint 648986730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,663.85686
Policy Entropy: 1.82872
Value Function Loss: 0.09745

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.54366
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 22,436.38641
Overall Steps per Second: 10,776.00838

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.41151
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.64012

Cumulative Model Updates: 77,824
Cumulative Timesteps: 649,036,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,568.90853
Policy Entropy: 1.82613
Value Function Loss: 0.09448

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.60227

Collected Steps per Second: 22,716.60201
Overall Steps per Second: 10,788.54226

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.63584

Cumulative Model Updates: 77,830
Cumulative Timesteps: 649,086,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 649086746...
Checkpoint 649086746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,242.00701
Policy Entropy: 1.81930
Value Function Loss: 0.09404

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.51482
Value Function Update Magnitude: 0.50652

Collected Steps per Second: 21,736.26071
Overall Steps per Second: 10,642.94580

Timestep Collection Time: 2.30214
Timestep Consumption Time: 2.39956
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.70171

Cumulative Model Updates: 77,836
Cumulative Timesteps: 649,136,786

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,128.08005
Policy Entropy: 1.82608
Value Function Loss: 0.09547

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.52494
Value Function Update Magnitude: 0.64603

Collected Steps per Second: 22,205.18344
Overall Steps per Second: 10,555.60036

Timestep Collection Time: 2.25173
Timestep Consumption Time: 2.48510
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.73682

Cumulative Model Updates: 77,842
Cumulative Timesteps: 649,186,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 649186786...
Checkpoint 649186786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,576.87512
Policy Entropy: 1.82455
Value Function Loss: 0.08874

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.52992
Value Function Update Magnitude: 0.75739

Collected Steps per Second: 22,111.53535
Overall Steps per Second: 10,637.41544

Timestep Collection Time: 2.26190
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.70171

Cumulative Model Updates: 77,848
Cumulative Timesteps: 649,236,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.63756
Policy Entropy: 1.82586
Value Function Loss: 0.08763

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.52926
Value Function Update Magnitude: 0.74612

Collected Steps per Second: 22,371.17551
Overall Steps per Second: 10,545.65220

Timestep Collection Time: 2.23547
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.74224

Cumulative Model Updates: 77,854
Cumulative Timesteps: 649,286,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 649286810...
Checkpoint 649286810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,478.74126
Policy Entropy: 1.83788
Value Function Loss: 0.09151

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.70708

Collected Steps per Second: 21,551.08890
Overall Steps per Second: 10,486.83296

Timestep Collection Time: 2.32063
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.76903

Cumulative Model Updates: 77,860
Cumulative Timesteps: 649,336,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,377.11812
Policy Entropy: 1.83908
Value Function Loss: 0.09418

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.53677
Value Function Update Magnitude: 0.54878

Collected Steps per Second: 23,074.47269
Overall Steps per Second: 10,830.55156

Timestep Collection Time: 2.16889
Timestep Consumption Time: 2.45193
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.62082

Cumulative Model Updates: 77,866
Cumulative Timesteps: 649,386,868

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 649386868...
Checkpoint 649386868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,577.81206
Policy Entropy: 1.83234
Value Function Loss: 0.10263

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.48606

Collected Steps per Second: 22,550.77960
Overall Steps per Second: 10,733.01912

Timestep Collection Time: 2.21837
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.66094

Cumulative Model Updates: 77,872
Cumulative Timesteps: 649,436,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,925.22501
Policy Entropy: 1.82310
Value Function Loss: 0.08825

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.53233
Value Function Update Magnitude: 0.56348

Collected Steps per Second: 22,649.93351
Overall Steps per Second: 10,637.97447

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.49293
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70071

Cumulative Model Updates: 77,878
Cumulative Timesteps: 649,486,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 649486900...
Checkpoint 649486900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,858.31963
Policy Entropy: 1.81534
Value Function Loss: 0.08952

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.51531
Value Function Update Magnitude: 0.56751

Collected Steps per Second: 22,299.42137
Overall Steps per Second: 10,671.48041

Timestep Collection Time: 2.24257
Timestep Consumption Time: 2.44357
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.68614

Cumulative Model Updates: 77,884
Cumulative Timesteps: 649,536,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,774.02155
Policy Entropy: 1.81577
Value Function Loss: 0.08787

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.48821
Value Function Update Magnitude: 0.56324

Collected Steps per Second: 22,909.11175
Overall Steps per Second: 10,682.77215

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.68081

Cumulative Model Updates: 77,890
Cumulative Timesteps: 649,586,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 649586912...
Checkpoint 649586912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,049.47129
Policy Entropy: 1.82061
Value Function Loss: 0.09820

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.49536
Value Function Update Magnitude: 0.56980

Collected Steps per Second: 22,283.89123
Overall Steps per Second: 10,663.35009

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69046

Cumulative Model Updates: 77,896
Cumulative Timesteps: 649,636,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,198.54044
Policy Entropy: 1.82715
Value Function Loss: 0.09763

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.52600
Value Function Update Magnitude: 0.56686

Collected Steps per Second: 22,247.88720
Overall Steps per Second: 10,478.98166

Timestep Collection Time: 2.24785
Timestep Consumption Time: 2.52456
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.77241

Cumulative Model Updates: 77,902
Cumulative Timesteps: 649,686,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 649686938...
Checkpoint 649686938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,013.52458
Policy Entropy: 1.84357
Value Function Loss: 0.09979

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.52464

Collected Steps per Second: 21,943.71021
Overall Steps per Second: 10,653.56011

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.69571

Cumulative Model Updates: 77,908
Cumulative Timesteps: 649,736,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,867.71488
Policy Entropy: 1.85709
Value Function Loss: 0.09780

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.49965

Collected Steps per Second: 22,050.26061
Overall Steps per Second: 10,401.22317

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.53978
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.80751

Cumulative Model Updates: 77,914
Cumulative Timesteps: 649,786,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 649786968...
Checkpoint 649786968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,794.98149
Policy Entropy: 1.85907
Value Function Loss: 0.09602

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.47504

Collected Steps per Second: 22,130.73499
Overall Steps per Second: 10,624.05302

Timestep Collection Time: 2.26084
Timestep Consumption Time: 2.44866
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.70950

Cumulative Model Updates: 77,920
Cumulative Timesteps: 649,837,002

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,772.99179
Policy Entropy: 1.83854
Value Function Loss: 0.09898

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.51519
Value Function Update Magnitude: 0.46162

Collected Steps per Second: 22,725.15282
Overall Steps per Second: 10,474.75160

Timestep Collection Time: 2.20100
Timestep Consumption Time: 2.57410
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.77510

Cumulative Model Updates: 77,926
Cumulative Timesteps: 649,887,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 649887020...
Checkpoint 649887020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,838.90447
Policy Entropy: 1.83124
Value Function Loss: 0.09593

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.48860
Value Function Update Magnitude: 0.46524

Collected Steps per Second: 22,450.94576
Overall Steps per Second: 10,661.46595

Timestep Collection Time: 2.22904
Timestep Consumption Time: 2.46488
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.69391

Cumulative Model Updates: 77,932
Cumulative Timesteps: 649,937,064

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,612.78764
Policy Entropy: 1.82720
Value Function Loss: 0.10177

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.51573
Value Function Update Magnitude: 0.46840

Collected Steps per Second: 22,691.48686
Overall Steps per Second: 10,644.17245

Timestep Collection Time: 2.20453
Timestep Consumption Time: 2.49513
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.69966

Cumulative Model Updates: 77,938
Cumulative Timesteps: 649,987,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 649987088...
Checkpoint 649987088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,625.56664
Policy Entropy: 1.83744
Value Function Loss: 0.10030

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.44691

Collected Steps per Second: 22,612.79657
Overall Steps per Second: 10,658.99859

Timestep Collection Time: 2.21193
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.69256

Cumulative Model Updates: 77,944
Cumulative Timesteps: 650,037,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,488.38821
Policy Entropy: 1.83574
Value Function Loss: 0.09554

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.53058
Value Function Update Magnitude: 0.45281

Collected Steps per Second: 23,023.93636
Overall Steps per Second: 10,700.75033

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.67687

Cumulative Model Updates: 77,950
Cumulative Timesteps: 650,087,152

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 650087152...
Checkpoint 650087152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,521.26982
Policy Entropy: 1.83656
Value Function Loss: 0.08519

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.51895
Value Function Update Magnitude: 0.54785

Collected Steps per Second: 22,340.26139
Overall Steps per Second: 10,651.19203

Timestep Collection Time: 2.23928
Timestep Consumption Time: 2.45748
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.69675

Cumulative Model Updates: 77,956
Cumulative Timesteps: 650,137,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,733.45742
Policy Entropy: 1.84377
Value Function Loss: 0.08540

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.51691
Value Function Update Magnitude: 0.53208

Collected Steps per Second: 22,692.41462
Overall Steps per Second: 10,649.05569

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.69713

Cumulative Model Updates: 77,962
Cumulative Timesteps: 650,187,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 650187198...
Checkpoint 650187198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,451.06045
Policy Entropy: 1.84402
Value Function Loss: 0.08668

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.51788
Value Function Update Magnitude: 0.52366

Collected Steps per Second: 22,126.73857
Overall Steps per Second: 10,487.08247

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.50926
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.77006

Cumulative Model Updates: 77,968
Cumulative Timesteps: 650,237,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,880.43536
Policy Entropy: 1.83332
Value Function Loss: 0.09095

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.51488
Value Function Update Magnitude: 0.59627

Collected Steps per Second: 22,278.10107
Overall Steps per Second: 10,452.92883

Timestep Collection Time: 2.24525
Timestep Consumption Time: 2.54001
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.78526

Cumulative Model Updates: 77,974
Cumulative Timesteps: 650,287,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 650287242...
Checkpoint 650287242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,380.20531
Policy Entropy: 1.81106
Value Function Loss: 0.08508

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.50998
Value Function Update Magnitude: 0.58756

Collected Steps per Second: 21,659.41944
Overall Steps per Second: 10,535.57969

Timestep Collection Time: 2.30976
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.74848

Cumulative Model Updates: 77,980
Cumulative Timesteps: 650,337,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,323.09166
Policy Entropy: 1.81285
Value Function Loss: 0.08322

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.51287
Value Function Update Magnitude: 0.58949

Collected Steps per Second: 22,417.21068
Overall Steps per Second: 10,506.38574

Timestep Collection Time: 2.23177
Timestep Consumption Time: 2.53010
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.76187

Cumulative Model Updates: 77,986
Cumulative Timesteps: 650,387,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 650387300...
Checkpoint 650387300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,954.81523
Policy Entropy: 1.82334
Value Function Loss: 0.08813

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.52134
Value Function Update Magnitude: 0.59820

Collected Steps per Second: 22,281.06030
Overall Steps per Second: 10,677.23945

Timestep Collection Time: 2.24496
Timestep Consumption Time: 2.43978
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.68473

Cumulative Model Updates: 77,992
Cumulative Timesteps: 650,437,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,175.02763
Policy Entropy: 1.82474
Value Function Loss: 0.08877

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.52617
Value Function Update Magnitude: 0.66537

Collected Steps per Second: 22,949.67665
Overall Steps per Second: 10,806.84538

Timestep Collection Time: 2.17973
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.62892

Cumulative Model Updates: 77,998
Cumulative Timesteps: 650,487,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 650487344...
Checkpoint 650487344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,553.16620
Policy Entropy: 1.82848
Value Function Loss: 0.08699

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.69887

Collected Steps per Second: 22,422.13482
Overall Steps per Second: 10,687.04306

Timestep Collection Time: 2.23056
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.67987

Cumulative Model Updates: 78,004
Cumulative Timesteps: 650,537,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,763.57992
Policy Entropy: 1.82362
Value Function Loss: 0.08971

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.52230
Value Function Update Magnitude: 0.68733

Collected Steps per Second: 22,793.67250
Overall Steps per Second: 10,685.62535

Timestep Collection Time: 2.19394
Timestep Consumption Time: 2.48599
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.67993

Cumulative Model Updates: 78,010
Cumulative Timesteps: 650,587,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 650587366...
Checkpoint 650587366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,070.55051
Policy Entropy: 1.80752
Value Function Loss: 0.08871

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.52550
Value Function Update Magnitude: 0.68975

Collected Steps per Second: 22,684.64237
Overall Steps per Second: 10,768.13237

Timestep Collection Time: 2.20458
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.64426

Cumulative Model Updates: 78,016
Cumulative Timesteps: 650,637,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,693.84700
Policy Entropy: 1.81980
Value Function Loss: 0.08665

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.52048
Value Function Update Magnitude: 0.68215

Collected Steps per Second: 23,046.90943
Overall Steps per Second: 10,714.68569

Timestep Collection Time: 2.17027
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.66817

Cumulative Model Updates: 78,022
Cumulative Timesteps: 650,687,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 650687394...
Checkpoint 650687394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,233.45133
Policy Entropy: 1.82835
Value Function Loss: 0.08621

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.52262
Value Function Update Magnitude: 0.62313

Collected Steps per Second: 22,235.55253
Overall Steps per Second: 10,509.64905

Timestep Collection Time: 2.24901
Timestep Consumption Time: 2.50928
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.75829

Cumulative Model Updates: 78,028
Cumulative Timesteps: 650,737,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,948.32923
Policy Entropy: 1.83809
Value Function Loss: 0.08668

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.51520
Value Function Update Magnitude: 0.54760

Collected Steps per Second: 22,620.61002
Overall Steps per Second: 10,633.42674

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.70422

Cumulative Model Updates: 78,034
Cumulative Timesteps: 650,787,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 650787424...
Checkpoint 650787424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,162.16805
Policy Entropy: 1.83021
Value Function Loss: 0.09678

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.51921
Value Function Update Magnitude: 0.49221

Collected Steps per Second: 21,644.17187
Overall Steps per Second: 10,414.98543

Timestep Collection Time: 2.31028
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.80116

Cumulative Model Updates: 78,040
Cumulative Timesteps: 650,837,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,521.42556
Policy Entropy: 1.83042
Value Function Loss: 0.09233

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.50870

Collected Steps per Second: 22,313.63182
Overall Steps per Second: 10,604.06634

Timestep Collection Time: 2.24195
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.71762

Cumulative Model Updates: 78,046
Cumulative Timesteps: 650,887,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 650887454...
Checkpoint 650887454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,536.64271
Policy Entropy: 1.82644
Value Function Loss: 0.09892

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.53740

Collected Steps per Second: 21,904.79941
Overall Steps per Second: 10,500.42705

Timestep Collection Time: 2.28288
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.76228

Cumulative Model Updates: 78,052
Cumulative Timesteps: 650,937,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,224.83952
Policy Entropy: 1.83021
Value Function Loss: 0.09423

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.52814
Value Function Update Magnitude: 0.63271

Collected Steps per Second: 22,761.14256
Overall Steps per Second: 10,553.33705

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.54203
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.73954

Cumulative Model Updates: 78,058
Cumulative Timesteps: 650,987,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 650987478...
Checkpoint 650987478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,738.05781
Policy Entropy: 1.83136
Value Function Loss: 0.08765

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.52097
Value Function Update Magnitude: 0.68627

Collected Steps per Second: 21,986.91436
Overall Steps per Second: 10,565.75386

Timestep Collection Time: 2.27408
Timestep Consumption Time: 2.45819
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.73227

Cumulative Model Updates: 78,064
Cumulative Timesteps: 651,037,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,673.97174
Policy Entropy: 1.82610
Value Function Loss: 0.08060

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.67176

Collected Steps per Second: 22,972.96608
Overall Steps per Second: 10,894.62992

Timestep Collection Time: 2.17656
Timestep Consumption Time: 2.41304
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.58960

Cumulative Model Updates: 78,070
Cumulative Timesteps: 651,087,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 651087480...
Checkpoint 651087480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,323.64826
Policy Entropy: 1.82720
Value Function Loss: 0.08028

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.49561
Value Function Update Magnitude: 0.56242

Collected Steps per Second: 22,305.21563
Overall Steps per Second: 10,646.84670

Timestep Collection Time: 2.24261
Timestep Consumption Time: 2.45568
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.69829

Cumulative Model Updates: 78,076
Cumulative Timesteps: 651,137,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,152.71912
Policy Entropy: 1.83003
Value Function Loss: 0.08267

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.49947
Value Function Update Magnitude: 0.45178

Collected Steps per Second: 23,133.55716
Overall Steps per Second: 10,852.41638

Timestep Collection Time: 2.16188
Timestep Consumption Time: 2.44649
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60837

Cumulative Model Updates: 78,082
Cumulative Timesteps: 651,187,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 651187514...
Checkpoint 651187514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,863.86776
Policy Entropy: 1.82633
Value Function Loss: 0.09070

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.51209
Value Function Update Magnitude: 0.44195

Collected Steps per Second: 22,498.86480
Overall Steps per Second: 10,681.73514

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.68220

Cumulative Model Updates: 78,088
Cumulative Timesteps: 651,237,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,283.08336
Policy Entropy: 1.80870
Value Function Loss: 0.08576

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.51972
Value Function Update Magnitude: 0.45321

Collected Steps per Second: 22,301.19255
Overall Steps per Second: 10,531.07967

Timestep Collection Time: 2.24284
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.74956

Cumulative Model Updates: 78,094
Cumulative Timesteps: 651,287,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 651287546...
Checkpoint 651287546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,640.70655
Policy Entropy: 1.80592
Value Function Loss: 0.08675

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.51896
Value Function Update Magnitude: 0.61354

Collected Steps per Second: 21,751.93614
Overall Steps per Second: 10,505.12217

Timestep Collection Time: 2.29874
Timestep Consumption Time: 2.46104
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.75977

Cumulative Model Updates: 78,100
Cumulative Timesteps: 651,337,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,507.15306
Policy Entropy: 1.82456
Value Function Loss: 0.08621

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.51831
Value Function Update Magnitude: 0.62852

Collected Steps per Second: 22,108.87827
Overall Steps per Second: 10,506.89442

Timestep Collection Time: 2.26226
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.76030

Cumulative Model Updates: 78,106
Cumulative Timesteps: 651,387,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 651387564...
Checkpoint 651387564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,631.49129
Policy Entropy: 1.82669
Value Function Loss: 0.09230

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.52700
Value Function Update Magnitude: 0.65896

Collected Steps per Second: 22,089.10411
Overall Steps per Second: 10,603.80803

Timestep Collection Time: 2.26456
Timestep Consumption Time: 2.45281
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.71736

Cumulative Model Updates: 78,112
Cumulative Timesteps: 651,437,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,022.11677
Policy Entropy: 1.83157
Value Function Loss: 0.09456

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.52388
Value Function Update Magnitude: 0.69113

Collected Steps per Second: 23,136.70786
Overall Steps per Second: 10,707.84297

Timestep Collection Time: 2.16159
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.67060

Cumulative Model Updates: 78,118
Cumulative Timesteps: 651,487,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 651487598...
Checkpoint 651487598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,388.25907
Policy Entropy: 1.82464
Value Function Loss: 0.09381

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.52678
Value Function Update Magnitude: 0.72620

Collected Steps per Second: 22,573.67018
Overall Steps per Second: 10,802.43266

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.41371
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.62877

Cumulative Model Updates: 78,124
Cumulative Timesteps: 651,537,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,258.56660
Policy Entropy: 1.83780
Value Function Loss: 0.09268

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.52992
Value Function Update Magnitude: 0.68511

Collected Steps per Second: 22,601.00536
Overall Steps per Second: 10,568.85796

Timestep Collection Time: 2.21300
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.73239

Cumulative Model Updates: 78,130
Cumulative Timesteps: 651,587,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 651587616...
Checkpoint 651587616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,815.53371
Policy Entropy: 1.83609
Value Function Loss: 0.09350

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.52851
Value Function Update Magnitude: 0.53606

Collected Steps per Second: 22,386.12941
Overall Steps per Second: 10,599.38434

Timestep Collection Time: 2.23460
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.71952

Cumulative Model Updates: 78,136
Cumulative Timesteps: 651,637,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,658.55346
Policy Entropy: 1.84406
Value Function Loss: 0.08868

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.52904
Value Function Update Magnitude: 0.67019

Collected Steps per Second: 22,980.92047
Overall Steps per Second: 10,931.96881

Timestep Collection Time: 2.17633
Timestep Consumption Time: 2.39870
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.57502

Cumulative Model Updates: 78,142
Cumulative Timesteps: 651,687,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 651687654...
Checkpoint 651687654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,430.41594
Policy Entropy: 1.83717
Value Function Loss: 0.08864

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.52147
Value Function Update Magnitude: 0.67395

Collected Steps per Second: 22,416.53250
Overall Steps per Second: 10,648.91124

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.69701

Cumulative Model Updates: 78,148
Cumulative Timesteps: 651,737,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,834.97879
Policy Entropy: 1.83051
Value Function Loss: 0.09675

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.51776
Value Function Update Magnitude: 0.54161

Collected Steps per Second: 22,207.99532
Overall Steps per Second: 10,513.66243

Timestep Collection Time: 2.25207
Timestep Consumption Time: 2.50498
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.75705

Cumulative Model Updates: 78,154
Cumulative Timesteps: 651,787,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 651787686...
Checkpoint 651787686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,008.56508
Policy Entropy: 1.81090
Value Function Loss: 0.09578

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.52605
Value Function Update Magnitude: 0.64286

Collected Steps per Second: 21,915.20819
Overall Steps per Second: 10,610.12908

Timestep Collection Time: 2.28280
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.71512

Cumulative Model Updates: 78,160
Cumulative Timesteps: 651,837,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,566.50966
Policy Entropy: 1.81772
Value Function Loss: 0.09371

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.48297
Value Function Update Magnitude: 0.69713

Collected Steps per Second: 22,237.14121
Overall Steps per Second: 10,566.13621

Timestep Collection Time: 2.24993
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.73513

Cumulative Model Updates: 78,166
Cumulative Timesteps: 651,887,746

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 651887746...
Checkpoint 651887746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,327.47644
Policy Entropy: 1.82436
Value Function Loss: 0.08731

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.49665
Value Function Update Magnitude: 0.61483

Collected Steps per Second: 21,926.49271
Overall Steps per Second: 10,442.53647

Timestep Collection Time: 2.28062
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.78868

Cumulative Model Updates: 78,172
Cumulative Timesteps: 651,937,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,101.18532
Policy Entropy: 1.82931
Value Function Loss: 0.08893

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.50879
Value Function Update Magnitude: 0.59609

Collected Steps per Second: 22,609.46172
Overall Steps per Second: 10,596.44720

Timestep Collection Time: 2.21323
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.72234

Cumulative Model Updates: 78,178
Cumulative Timesteps: 651,987,792

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 651987792...
Checkpoint 651987792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,280.50994
Policy Entropy: 1.81495
Value Function Loss: 0.08218

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.16125
Policy Update Magnitude: 0.46722
Value Function Update Magnitude: 0.62074

Collected Steps per Second: 22,413.40676
Overall Steps per Second: 10,529.27849

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.75170

Cumulative Model Updates: 78,184
Cumulative Timesteps: 652,037,824

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,863.37716
Policy Entropy: 1.80882
Value Function Loss: 0.08157

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.44423
Value Function Update Magnitude: 0.61717

Collected Steps per Second: 22,905.52946
Overall Steps per Second: 10,853.06402

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60902

Cumulative Model Updates: 78,190
Cumulative Timesteps: 652,087,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 652087846...
Checkpoint 652087846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,415.82433
Policy Entropy: 1.81854
Value Function Loss: 0.08664

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.47635
Value Function Update Magnitude: 0.48702

Collected Steps per Second: 22,165.70125
Overall Steps per Second: 10,649.39184

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.69548

Cumulative Model Updates: 78,196
Cumulative Timesteps: 652,137,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,580.41236
Policy Entropy: 1.82814
Value Function Loss: 0.09344

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.50290
Value Function Update Magnitude: 0.51381

Collected Steps per Second: 22,823.66623
Overall Steps per Second: 10,646.63085

Timestep Collection Time: 2.19158
Timestep Consumption Time: 2.50662
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69820

Cumulative Model Updates: 78,202
Cumulative Timesteps: 652,187,870

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 652187870...
Checkpoint 652187870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,244.36331
Policy Entropy: 1.81700
Value Function Loss: 0.09639

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.51392
Value Function Update Magnitude: 0.57976

Collected Steps per Second: 22,312.30735
Overall Steps per Second: 10,497.24661

Timestep Collection Time: 2.24163
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.76468

Cumulative Model Updates: 78,208
Cumulative Timesteps: 652,237,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,231.15806
Policy Entropy: 1.80291
Value Function Loss: 0.08939

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.47426
Value Function Update Magnitude: 0.60943

Collected Steps per Second: 22,757.15740
Overall Steps per Second: 10,657.73629

Timestep Collection Time: 2.19746
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.69218

Cumulative Model Updates: 78,214
Cumulative Timesteps: 652,287,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 652287894...
Checkpoint 652287894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,781.92915
Policy Entropy: 1.80955
Value Function Loss: 0.08913

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.46818
Value Function Update Magnitude: 0.54777

Collected Steps per Second: 21,684.54745
Overall Steps per Second: 10,446.55154

Timestep Collection Time: 2.30662
Timestep Consumption Time: 2.48137
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.78799

Cumulative Model Updates: 78,220
Cumulative Timesteps: 652,337,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,119.69966
Policy Entropy: 1.81304
Value Function Loss: 0.08979

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.50639
Value Function Update Magnitude: 0.64129

Collected Steps per Second: 22,338.78097
Overall Steps per Second: 10,559.38370

Timestep Collection Time: 2.23942
Timestep Consumption Time: 2.49816
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.73759

Cumulative Model Updates: 78,226
Cumulative Timesteps: 652,387,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 652387938...
Checkpoint 652387938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,725.38378
Policy Entropy: 1.81484
Value Function Loss: 0.09377

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.49921
Value Function Update Magnitude: 0.71914

Collected Steps per Second: 22,320.68524
Overall Steps per Second: 10,533.92697

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.74676

Cumulative Model Updates: 78,232
Cumulative Timesteps: 652,437,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,374.15590
Policy Entropy: 1.81504
Value Function Loss: 0.09056

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.52909
Value Function Update Magnitude: 0.68524

Collected Steps per Second: 22,263.30049
Overall Steps per Second: 10,531.54564

Timestep Collection Time: 2.24585
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.74764

Cumulative Model Updates: 78,238
Cumulative Timesteps: 652,487,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 652487940...
Checkpoint 652487940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,753.05677
Policy Entropy: 1.81169
Value Function Loss: 0.09289

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.57084

Collected Steps per Second: 22,044.90335
Overall Steps per Second: 10,543.88275

Timestep Collection Time: 2.26982
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.74569

Cumulative Model Updates: 78,244
Cumulative Timesteps: 652,537,978

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,632.14548
Policy Entropy: 1.81127
Value Function Loss: 0.08917

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.51221
Value Function Update Magnitude: 0.65892

Collected Steps per Second: 22,762.76666
Overall Steps per Second: 10,542.98256

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.54796
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.74628

Cumulative Model Updates: 78,250
Cumulative Timesteps: 652,588,018

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 652588018...
Checkpoint 652588018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,157.35211
Policy Entropy: 1.80817
Value Function Loss: 0.09335

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.15708
Policy Update Magnitude: 0.47732
Value Function Update Magnitude: 0.58134

Collected Steps per Second: 22,679.83649
Overall Steps per Second: 10,582.03678

Timestep Collection Time: 2.20478
Timestep Consumption Time: 2.52059
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.72537

Cumulative Model Updates: 78,256
Cumulative Timesteps: 652,638,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,819.36532
Policy Entropy: 1.81932
Value Function Loss: 0.09503

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.47850
Value Function Update Magnitude: 0.50216

Collected Steps per Second: 22,739.39337
Overall Steps per Second: 10,767.86609

Timestep Collection Time: 2.19892
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.64363

Cumulative Model Updates: 78,262
Cumulative Timesteps: 652,688,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 652688024...
Checkpoint 652688024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,369.35791
Policy Entropy: 1.83390
Value Function Loss: 0.09831

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.50334
Value Function Update Magnitude: 0.48883

Collected Steps per Second: 22,305.02306
Overall Steps per Second: 10,699.87742

Timestep Collection Time: 2.24201
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.67370

Cumulative Model Updates: 78,268
Cumulative Timesteps: 652,738,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,639.61287
Policy Entropy: 1.83191
Value Function Loss: 0.09072

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.51937
Value Function Update Magnitude: 0.51838

Collected Steps per Second: 22,736.82745
Overall Steps per Second: 10,611.11019

Timestep Collection Time: 2.20048
Timestep Consumption Time: 2.51458
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.71506

Cumulative Model Updates: 78,274
Cumulative Timesteps: 652,788,064

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 652788064...
Checkpoint 652788064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,440.48021
Policy Entropy: 1.81994
Value Function Loss: 0.09241

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.53028
Value Function Update Magnitude: 0.64314

Collected Steps per Second: 22,272.83785
Overall Steps per Second: 10,507.68116

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.51384
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.75899

Cumulative Model Updates: 78,280
Cumulative Timesteps: 652,838,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,375.77740
Policy Entropy: 1.82585
Value Function Loss: 0.08754

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.53421
Value Function Update Magnitude: 0.61057

Collected Steps per Second: 22,591.42625
Overall Steps per Second: 10,620.07060

Timestep Collection Time: 2.21349
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.70863

Cumulative Model Updates: 78,286
Cumulative Timesteps: 652,888,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 652888076...
Checkpoint 652888076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,244.11361
Policy Entropy: 1.84040
Value Function Loss: 0.09147

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.58019

Collected Steps per Second: 21,687.54344
Overall Steps per Second: 10,561.30511

Timestep Collection Time: 2.30602
Timestep Consumption Time: 2.42938
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73540

Cumulative Model Updates: 78,292
Cumulative Timesteps: 652,938,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,537.40777
Policy Entropy: 1.85184
Value Function Loss: 0.08994

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.52763
Value Function Update Magnitude: 0.53571

Collected Steps per Second: 21,506.47614
Overall Steps per Second: 10,369.94287

Timestep Collection Time: 2.32497
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.82182

Cumulative Model Updates: 78,298
Cumulative Timesteps: 652,988,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 652988090...
Checkpoint 652988090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,437.69982
Policy Entropy: 1.84436
Value Function Loss: 0.09425

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.56428

Collected Steps per Second: 22,182.92647
Overall Steps per Second: 10,606.76093

Timestep Collection Time: 2.25453
Timestep Consumption Time: 2.46058
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.71511

Cumulative Model Updates: 78,304
Cumulative Timesteps: 653,038,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,033.52592
Policy Entropy: 1.83365
Value Function Loss: 0.08695

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.52678
Value Function Update Magnitude: 0.62838

Collected Steps per Second: 22,797.35565
Overall Steps per Second: 10,600.36675

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.52520
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71984

Cumulative Model Updates: 78,310
Cumulative Timesteps: 653,088,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 653088134...
Checkpoint 653088134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,140.15108
Policy Entropy: 1.82655
Value Function Loss: 0.08912

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.55657

Collected Steps per Second: 22,291.16694
Overall Steps per Second: 10,519.32273

Timestep Collection Time: 2.24537
Timestep Consumption Time: 2.51273
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.75810

Cumulative Model Updates: 78,316
Cumulative Timesteps: 653,138,186

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,857.54856
Policy Entropy: 1.83208
Value Function Loss: 0.08967

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.52431
Value Function Update Magnitude: 0.44462

Collected Steps per Second: 22,535.49236
Overall Steps per Second: 10,593.84397

Timestep Collection Time: 2.22067
Timestep Consumption Time: 2.50320
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.72388

Cumulative Model Updates: 78,322
Cumulative Timesteps: 653,188,230

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 653188230...
Checkpoint 653188230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,713.70734
Policy Entropy: 1.82925
Value Function Loss: 0.09282

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.47160

Collected Steps per Second: 22,635.65299
Overall Steps per Second: 10,565.61004

Timestep Collection Time: 2.20908
Timestep Consumption Time: 2.52363
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.73271

Cumulative Model Updates: 78,328
Cumulative Timesteps: 653,238,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,974.48498
Policy Entropy: 1.85269
Value Function Loss: 0.08776

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.52675
Value Function Update Magnitude: 0.60028

Collected Steps per Second: 22,727.48135
Overall Steps per Second: 10,771.16539

Timestep Collection Time: 2.20060
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.64332

Cumulative Model Updates: 78,334
Cumulative Timesteps: 653,288,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 653288248...
Checkpoint 653288248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,235.42828
Policy Entropy: 1.83968
Value Function Loss: 0.08145

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.51988
Value Function Update Magnitude: 0.55720

Collected Steps per Second: 22,131.04816
Overall Steps per Second: 10,677.40348

Timestep Collection Time: 2.25990
Timestep Consumption Time: 2.42420
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.68410

Cumulative Model Updates: 78,340
Cumulative Timesteps: 653,338,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,560.56804
Policy Entropy: 1.84275
Value Function Loss: 0.08056

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.52000
Value Function Update Magnitude: 0.63692

Collected Steps per Second: 22,325.41709
Overall Steps per Second: 10,476.13469

Timestep Collection Time: 2.23969
Timestep Consumption Time: 2.53325
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.77294

Cumulative Model Updates: 78,346
Cumulative Timesteps: 653,388,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 653388264...
Checkpoint 653388264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,753.35614
Policy Entropy: 1.82698
Value Function Loss: 0.08622

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.52570
Value Function Update Magnitude: 0.64037

Collected Steps per Second: 21,306.36254
Overall Steps per Second: 10,268.22157

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.52348
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.87095

Cumulative Model Updates: 78,352
Cumulative Timesteps: 653,438,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,170.60342
Policy Entropy: 1.83371
Value Function Loss: 0.08847

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.53186
Value Function Update Magnitude: 0.66492

Collected Steps per Second: 22,406.85255
Overall Steps per Second: 10,546.81541

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.51152
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.74494

Cumulative Model Updates: 78,358
Cumulative Timesteps: 653,488,324

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 653488324...
Checkpoint 653488324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,434.45904
Policy Entropy: 1.81609
Value Function Loss: 0.08352

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.52674
Value Function Update Magnitude: 0.70910

Collected Steps per Second: 21,768.42235
Overall Steps per Second: 10,617.86580

Timestep Collection Time: 2.29801
Timestep Consumption Time: 2.41330
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.71130

Cumulative Model Updates: 78,364
Cumulative Timesteps: 653,538,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,018.43835
Policy Entropy: 1.82410
Value Function Loss: 0.09223

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.52974
Value Function Update Magnitude: 0.73025

Collected Steps per Second: 22,803.90411
Overall Steps per Second: 10,731.99143

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.66288

Cumulative Model Updates: 78,370
Cumulative Timesteps: 653,588,390

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 653588390...
Checkpoint 653588390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,260.32681
Policy Entropy: 1.83037
Value Function Loss: 0.09800

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.71154

Collected Steps per Second: 22,731.89501
Overall Steps per Second: 10,770.14553

Timestep Collection Time: 2.19982
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.64302

Cumulative Model Updates: 78,376
Cumulative Timesteps: 653,638,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,307.90847
Policy Entropy: 1.84467
Value Function Loss: 0.09914

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.55320
Value Function Update Magnitude: 0.67450

Collected Steps per Second: 22,595.08985
Overall Steps per Second: 10,748.33943

Timestep Collection Time: 2.21314
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.65244

Cumulative Model Updates: 78,382
Cumulative Timesteps: 653,688,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 653688402...
Checkpoint 653688402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,361.17537
Policy Entropy: 1.83439
Value Function Loss: 0.09301

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.55294
Value Function Update Magnitude: 0.70440

Collected Steps per Second: 22,701.14280
Overall Steps per Second: 10,778.14301

Timestep Collection Time: 2.20333
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.64069

Cumulative Model Updates: 78,388
Cumulative Timesteps: 653,738,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,555.48427
Policy Entropy: 1.83493
Value Function Loss: 0.09112

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.53804
Value Function Update Magnitude: 0.73610

Collected Steps per Second: 22,247.72194
Overall Steps per Second: 10,474.65183

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.52641
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.77419

Cumulative Model Updates: 78,394
Cumulative Timesteps: 653,788,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 653788428...
Checkpoint 653788428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,544.53778
Policy Entropy: 1.83944
Value Function Loss: 0.08895

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.70859

Collected Steps per Second: 22,320.84302
Overall Steps per Second: 10,594.33495

Timestep Collection Time: 2.24149
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.72252

Cumulative Model Updates: 78,400
Cumulative Timesteps: 653,838,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,951.63875
Policy Entropy: 1.85001
Value Function Loss: 0.08916

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.53631
Value Function Update Magnitude: 0.64218

Collected Steps per Second: 22,384.51641
Overall Steps per Second: 10,545.02013

Timestep Collection Time: 2.23378
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.74176

Cumulative Model Updates: 78,406
Cumulative Timesteps: 653,888,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 653888462...
Checkpoint 653888462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,373.88082
Policy Entropy: 1.86474
Value Function Loss: 0.09174

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.68515

Collected Steps per Second: 21,588.96695
Overall Steps per Second: 10,536.26803

Timestep Collection Time: 2.31739
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.74836

Cumulative Model Updates: 78,412
Cumulative Timesteps: 653,938,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,352.90360
Policy Entropy: 1.85552
Value Function Loss: 0.09310

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.65959

Collected Steps per Second: 22,027.21067
Overall Steps per Second: 10,520.47846

Timestep Collection Time: 2.27065
Timestep Consumption Time: 2.48351
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75416

Cumulative Model Updates: 78,418
Cumulative Timesteps: 653,988,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 653988508...
Checkpoint 653988508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,330.29595
Policy Entropy: 1.85372
Value Function Loss: 0.09638

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.60313

Collected Steps per Second: 22,142.72176
Overall Steps per Second: 10,652.18165

Timestep Collection Time: 2.25916
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.69613

Cumulative Model Updates: 78,424
Cumulative Timesteps: 654,038,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,147.28839
Policy Entropy: 1.83878
Value Function Loss: 0.10026

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.53358
Value Function Update Magnitude: 0.54061

Collected Steps per Second: 22,834.18658
Overall Steps per Second: 10,556.99460

Timestep Collection Time: 2.19040
Timestep Consumption Time: 2.54731
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.73771

Cumulative Model Updates: 78,430
Cumulative Timesteps: 654,088,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 654088548...
Checkpoint 654088548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,191.54088
Policy Entropy: 1.83668
Value Function Loss: 0.09268

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.65274

Collected Steps per Second: 22,771.00901
Overall Steps per Second: 10,603.03439

Timestep Collection Time: 2.19674
Timestep Consumption Time: 2.52097
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.71771

Cumulative Model Updates: 78,436
Cumulative Timesteps: 654,138,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,225.08742
Policy Entropy: 1.82488
Value Function Loss: 0.09050

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 22,666.64328
Overall Steps per Second: 10,831.36323

Timestep Collection Time: 2.20606
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.61659

Cumulative Model Updates: 78,442
Cumulative Timesteps: 654,188,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 654188574...
Checkpoint 654188574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,543.52235
Policy Entropy: 1.81862
Value Function Loss: 0.08440

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.53504
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 22,421.20896
Overall Steps per Second: 10,587.33472

Timestep Collection Time: 2.23003
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.72262

Cumulative Model Updates: 78,448
Cumulative Timesteps: 654,238,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,688.09704
Policy Entropy: 1.82492
Value Function Loss: 0.08183

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.50465
Value Function Update Magnitude: 0.58254

Collected Steps per Second: 22,855.63123
Overall Steps per Second: 10,834.71082

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61554

Cumulative Model Updates: 78,454
Cumulative Timesteps: 654,288,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 654288582...
Checkpoint 654288582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,563.92240
Policy Entropy: 1.83972
Value Function Loss: 0.08310

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.45401
Value Function Update Magnitude: 0.59995

Collected Steps per Second: 22,544.26889
Overall Steps per Second: 10,773.92292

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.42317
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.64121

Cumulative Model Updates: 78,460
Cumulative Timesteps: 654,338,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,857.41915
Policy Entropy: 1.85308
Value Function Loss: 0.09650

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.46353
Value Function Update Magnitude: 0.60529

Collected Steps per Second: 22,547.16830
Overall Steps per Second: 10,744.58353

Timestep Collection Time: 2.21846
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.65537

Cumulative Model Updates: 78,466
Cumulative Timesteps: 654,388,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 654388606...
Checkpoint 654388606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,214.54947
Policy Entropy: 1.83766
Value Function Loss: 0.09913

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.50927
Value Function Update Magnitude: 0.58799

Collected Steps per Second: 22,155.62282
Overall Steps per Second: 10,660.84898

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.69043

Cumulative Model Updates: 78,472
Cumulative Timesteps: 654,438,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,660.03273
Policy Entropy: 1.82212
Value Function Loss: 0.10059

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.54114
Value Function Update Magnitude: 0.53197

Collected Steps per Second: 22,094.97162
Overall Steps per Second: 10,535.09844

Timestep Collection Time: 2.26332
Timestep Consumption Time: 2.48348
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.74680

Cumulative Model Updates: 78,478
Cumulative Timesteps: 654,488,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 654488618...
Checkpoint 654488618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,777.10064
Policy Entropy: 1.82597
Value Function Loss: 0.09350

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.54712
Value Function Update Magnitude: 0.56521

Collected Steps per Second: 22,291.09763
Overall Steps per Second: 10,673.45333

Timestep Collection Time: 2.24341
Timestep Consumption Time: 2.44186
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.68527

Cumulative Model Updates: 78,484
Cumulative Timesteps: 654,538,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,724.01340
Policy Entropy: 1.83911
Value Function Loss: 0.09214

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.52770
Value Function Update Magnitude: 0.68424

Collected Steps per Second: 22,797.55761
Overall Steps per Second: 10,847.97413

Timestep Collection Time: 2.19383
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.61045

Cumulative Model Updates: 78,490
Cumulative Timesteps: 654,588,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 654588640...
Checkpoint 654588640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,285.84846
Policy Entropy: 1.83976
Value Function Loss: 0.08493

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.52475
Value Function Update Magnitude: 0.71307

Collected Steps per Second: 22,181.04763
Overall Steps per Second: 10,627.06099

Timestep Collection Time: 2.25436
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.70535

Cumulative Model Updates: 78,496
Cumulative Timesteps: 654,638,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,469.54862
Policy Entropy: 1.81867
Value Function Loss: 0.09204

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.15785
Policy Update Magnitude: 0.50092
Value Function Update Magnitude: 0.70505

Collected Steps per Second: 22,665.29451
Overall Steps per Second: 10,847.13053

Timestep Collection Time: 2.20646
Timestep Consumption Time: 2.40398
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.61044

Cumulative Model Updates: 78,502
Cumulative Timesteps: 654,688,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 654688654...
Checkpoint 654688654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,157.98153
Policy Entropy: 1.80269
Value Function Loss: 0.09752

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.50516
Value Function Update Magnitude: 0.80744

Collected Steps per Second: 22,274.60290
Overall Steps per Second: 10,691.19716

Timestep Collection Time: 2.24570
Timestep Consumption Time: 2.43311
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.67880

Cumulative Model Updates: 78,508
Cumulative Timesteps: 654,738,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,054.91062
Policy Entropy: 1.81091
Value Function Loss: 0.09811

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.52096
Value Function Update Magnitude: 0.85647

Collected Steps per Second: 22,801.25154
Overall Steps per Second: 10,870.08436

Timestep Collection Time: 2.19295
Timestep Consumption Time: 2.40701
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.59996

Cumulative Model Updates: 78,514
Cumulative Timesteps: 654,788,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 654788678...
Checkpoint 654788678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,812.74126
Policy Entropy: 1.81352
Value Function Loss: 0.09701

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.50040
Value Function Update Magnitude: 0.83858

Collected Steps per Second: 22,098.17264
Overall Steps per Second: 10,724.87397

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.40077
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.66467

Cumulative Model Updates: 78,520
Cumulative Timesteps: 654,838,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.63703
Policy Entropy: 1.81883
Value Function Loss: 0.08759

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.51397
Value Function Update Magnitude: 0.80086

Collected Steps per Second: 22,203.71666
Overall Steps per Second: 10,488.15593

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.51641
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.76919

Cumulative Model Updates: 78,526
Cumulative Timesteps: 654,888,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 654888726...
Checkpoint 654888726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,419.76485
Policy Entropy: 1.83583
Value Function Loss: 0.08835

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.53841
Value Function Update Magnitude: 0.80001

Collected Steps per Second: 21,953.11254
Overall Steps per Second: 10,622.35463

Timestep Collection Time: 2.27858
Timestep Consumption Time: 2.43054
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.70913

Cumulative Model Updates: 78,532
Cumulative Timesteps: 654,938,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,325.42792
Policy Entropy: 1.84425
Value Function Loss: 0.08969

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.74873

Collected Steps per Second: 22,523.18557
Overall Steps per Second: 10,619.36092

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.71177

Cumulative Model Updates: 78,538
Cumulative Timesteps: 654,988,784

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 654988784...
Checkpoint 654988784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,636.56845
Policy Entropy: 1.84742
Value Function Loss: 0.09749

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.59680

Collected Steps per Second: 22,748.59199
Overall Steps per Second: 10,615.41943

Timestep Collection Time: 2.19829
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.71088

Cumulative Model Updates: 78,544
Cumulative Timesteps: 655,038,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,061.07736
Policy Entropy: 1.84202
Value Function Loss: 0.09589

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.55551
Value Function Update Magnitude: 0.52348

Collected Steps per Second: 22,770.71107
Overall Steps per Second: 10,669.38322

Timestep Collection Time: 2.19747
Timestep Consumption Time: 2.49240
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.68987

Cumulative Model Updates: 78,550
Cumulative Timesteps: 655,088,830

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 655088830...
Checkpoint 655088830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,169.36893
Policy Entropy: 1.83999
Value Function Loss: 0.09243

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.55105
Value Function Update Magnitude: 0.57727

Collected Steps per Second: 22,397.00294
Overall Steps per Second: 10,708.11302

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.43906
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.67347

Cumulative Model Updates: 78,556
Cumulative Timesteps: 655,138,874

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,758.63379
Policy Entropy: 1.83142
Value Function Loss: 0.08929

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.53923
Value Function Update Magnitude: 0.67566

Collected Steps per Second: 22,583.31797
Overall Steps per Second: 10,808.87401

Timestep Collection Time: 2.21526
Timestep Consumption Time: 2.41316
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62842

Cumulative Model Updates: 78,562
Cumulative Timesteps: 655,188,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 655188902...
Checkpoint 655188902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,324.99200
Policy Entropy: 1.82373
Value Function Loss: 0.09170

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.71868

Collected Steps per Second: 22,305.97742
Overall Steps per Second: 10,667.10485

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.68843

Cumulative Model Updates: 78,568
Cumulative Timesteps: 655,238,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,687.12479
Policy Entropy: 1.82156
Value Function Loss: 0.09230

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.62436

Collected Steps per Second: 22,637.92500
Overall Steps per Second: 10,625.20138

Timestep Collection Time: 2.21018
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.70899

Cumulative Model Updates: 78,574
Cumulative Timesteps: 655,288,948

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 655288948...
Checkpoint 655288948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,543.80179
Policy Entropy: 1.82670
Value Function Loss: 0.09518

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.53037
Value Function Update Magnitude: 0.50245

Collected Steps per Second: 22,388.67286
Overall Steps per Second: 10,647.34073

Timestep Collection Time: 2.23336
Timestep Consumption Time: 2.46283
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.69620

Cumulative Model Updates: 78,580
Cumulative Timesteps: 655,338,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,798.91045
Policy Entropy: 1.82315
Value Function Loss: 0.09814

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.53649
Value Function Update Magnitude: 0.41695

Collected Steps per Second: 22,246.74410
Overall Steps per Second: 10,531.84823

Timestep Collection Time: 2.24788
Timestep Consumption Time: 2.50038
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.74826

Cumulative Model Updates: 78,586
Cumulative Timesteps: 655,388,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 655388958...
Checkpoint 655388958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,829.11485
Policy Entropy: 1.81721
Value Function Loss: 0.09731

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.49149
Value Function Update Magnitude: 0.44517

Collected Steps per Second: 21,899.13339
Overall Steps per Second: 10,419.49805

Timestep Collection Time: 2.28329
Timestep Consumption Time: 2.51560
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.79889

Cumulative Model Updates: 78,592
Cumulative Timesteps: 655,438,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,043.26148
Policy Entropy: 1.82284
Value Function Loss: 0.10211

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.46341
Value Function Update Magnitude: 0.45111

Collected Steps per Second: 22,200.02319
Overall Steps per Second: 10,517.44107

Timestep Collection Time: 2.25315
Timestep Consumption Time: 2.50276
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.75591

Cumulative Model Updates: 78,598
Cumulative Timesteps: 655,488,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 655488980...
Checkpoint 655488980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,817.47527
Policy Entropy: 1.82561
Value Function Loss: 0.10105

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.46596
Value Function Update Magnitude: 0.46849

Collected Steps per Second: 22,172.67783
Overall Steps per Second: 10,645.58796

Timestep Collection Time: 2.25674
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.70035

Cumulative Model Updates: 78,604
Cumulative Timesteps: 655,539,018

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,786.27734
Policy Entropy: 1.83117
Value Function Loss: 0.10381

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.50124
Value Function Update Magnitude: 0.42330

Collected Steps per Second: 22,502.75456
Overall Steps per Second: 10,716.23155

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.66582

Cumulative Model Updates: 78,610
Cumulative Timesteps: 655,589,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 655589018...
Checkpoint 655589018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,844.51406
Policy Entropy: 1.82888
Value Function Loss: 0.10031

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.53328
Value Function Update Magnitude: 0.45151

Collected Steps per Second: 22,416.28779
Overall Steps per Second: 10,706.07784

Timestep Collection Time: 2.23150
Timestep Consumption Time: 2.44080
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.67230

Cumulative Model Updates: 78,616
Cumulative Timesteps: 655,639,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,823.12113
Policy Entropy: 1.83588
Value Function Loss: 0.09195

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.59704

Collected Steps per Second: 22,785.06353
Overall Steps per Second: 10,743.90269

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.45997
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.65492

Cumulative Model Updates: 78,622
Cumulative Timesteps: 655,689,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 655689052...
Checkpoint 655689052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,313.15999
Policy Entropy: 1.82023
Value Function Loss: 0.09072

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.51137
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 22,504.38811
Overall Steps per Second: 10,636.52507

Timestep Collection Time: 2.22277
Timestep Consumption Time: 2.48009
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.70285

Cumulative Model Updates: 78,628
Cumulative Timesteps: 655,739,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,782.27716
Policy Entropy: 1.82226
Value Function Loss: 0.08317

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.47068
Value Function Update Magnitude: 0.66936

Collected Steps per Second: 22,796.01559
Overall Steps per Second: 10,680.28874

Timestep Collection Time: 2.19398
Timestep Consumption Time: 2.48885
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.68283

Cumulative Model Updates: 78,634
Cumulative Timesteps: 655,789,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 655789088...
Checkpoint 655789088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,366.62626
Policy Entropy: 1.80522
Value Function Loss: 0.09128

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.15954
Policy Update Magnitude: 0.46336
Value Function Update Magnitude: 0.68562

Collected Steps per Second: 21,930.58404
Overall Steps per Second: 10,654.04861

Timestep Collection Time: 2.28111
Timestep Consumption Time: 2.41439
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.69549

Cumulative Model Updates: 78,640
Cumulative Timesteps: 655,839,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,773.94546
Policy Entropy: 1.80710
Value Function Loss: 0.09437

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.63212

Collected Steps per Second: 22,437.08368
Overall Steps per Second: 10,699.77939

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.44581
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.67542

Cumulative Model Updates: 78,646
Cumulative Timesteps: 655,889,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 655889140...
Checkpoint 655889140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,325.41335
Policy Entropy: 1.80417
Value Function Loss: 0.08921

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.52463
Value Function Update Magnitude: 0.71553

Collected Steps per Second: 22,034.42949
Overall Steps per Second: 10,406.46019

Timestep Collection Time: 2.26963
Timestep Consumption Time: 2.53604
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.80567

Cumulative Model Updates: 78,652
Cumulative Timesteps: 655,939,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,297.91680
Policy Entropy: 1.80503
Value Function Loss: 0.08375

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.53939
Value Function Update Magnitude: 0.69642

Collected Steps per Second: 22,596.13612
Overall Steps per Second: 10,587.67771

Timestep Collection Time: 2.21365
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.72436

Cumulative Model Updates: 78,658
Cumulative Timesteps: 655,989,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 655989170...
Checkpoint 655989170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,363.27476
Policy Entropy: 1.80202
Value Function Loss: 0.08882

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.60696

Collected Steps per Second: 21,669.41236
Overall Steps per Second: 10,554.29912

Timestep Collection Time: 2.30749
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.73760

Cumulative Model Updates: 78,664
Cumulative Timesteps: 656,039,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,677.58474
Policy Entropy: 1.79540
Value Function Loss: 0.09434

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.55373
Value Function Update Magnitude: 0.59683

Collected Steps per Second: 22,729.85494
Overall Steps per Second: 10,593.36169

Timestep Collection Time: 2.20037
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.72126

Cumulative Model Updates: 78,670
Cumulative Timesteps: 656,089,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 656089186...
Checkpoint 656089186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,363.90569
Policy Entropy: 1.80532
Value Function Loss: 0.09570

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.55803
Value Function Update Magnitude: 0.65274

Collected Steps per Second: 22,655.43917
Overall Steps per Second: 10,841.77479

Timestep Collection Time: 2.20839
Timestep Consumption Time: 2.40635
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.61474

Cumulative Model Updates: 78,676
Cumulative Timesteps: 656,139,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,844.12215
Policy Entropy: 1.79626
Value Function Loss: 0.09104

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.55527
Value Function Update Magnitude: 0.74716

Collected Steps per Second: 22,929.08653
Overall Steps per Second: 10,659.03660

Timestep Collection Time: 2.18177
Timestep Consumption Time: 2.51152
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.69329

Cumulative Model Updates: 78,682
Cumulative Timesteps: 656,189,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 656189244...
Checkpoint 656189244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,092.49208
Policy Entropy: 1.79686
Value Function Loss: 0.09574

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15315
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.78735

Collected Steps per Second: 22,287.21869
Overall Steps per Second: 10,583.98835

Timestep Collection Time: 2.24487
Timestep Consumption Time: 2.48227
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.72714

Cumulative Model Updates: 78,688
Cumulative Timesteps: 656,239,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,088.03277
Policy Entropy: 1.78140
Value Function Loss: 0.09811

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16873
Policy Update Magnitude: 0.50142
Value Function Update Magnitude: 0.73277

Collected Steps per Second: 22,853.81485
Overall Steps per Second: 10,811.96229

Timestep Collection Time: 2.18887
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.62673

Cumulative Model Updates: 78,694
Cumulative Timesteps: 656,289,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 656289300...
Checkpoint 656289300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,050.11229
Policy Entropy: 1.79236
Value Function Loss: 0.09491

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15860
Policy Update Magnitude: 0.47434
Value Function Update Magnitude: 0.71227

Collected Steps per Second: 22,493.77212
Overall Steps per Second: 10,756.77768

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.64972

Cumulative Model Updates: 78,700
Cumulative Timesteps: 656,339,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,601.34614
Policy Entropy: 1.80247
Value Function Loss: 0.08751

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15690
Policy Update Magnitude: 0.48260
Value Function Update Magnitude: 0.73461

Collected Steps per Second: 22,296.69604
Overall Steps per Second: 10,563.33635

Timestep Collection Time: 2.24428
Timestep Consumption Time: 2.49286
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.73714

Cumulative Model Updates: 78,706
Cumulative Timesteps: 656,389,356

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 656389356...
Checkpoint 656389356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,262.36769
Policy Entropy: 1.77697
Value Function Loss: 0.08323

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15122
Policy Update Magnitude: 0.49763
Value Function Update Magnitude: 0.64700

Collected Steps per Second: 21,796.12001
Overall Steps per Second: 10,454.45469

Timestep Collection Time: 2.29527
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.78533

Cumulative Model Updates: 78,712
Cumulative Timesteps: 656,439,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,785.46153
Policy Entropy: 1.77491
Value Function Loss: 0.08727

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 22,386.51052
Overall Steps per Second: 10,552.60180

Timestep Collection Time: 2.23420
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.73968

Cumulative Model Updates: 78,718
Cumulative Timesteps: 656,489,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 656489400...
Checkpoint 656489400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,252.18508
Policy Entropy: 1.76243
Value Function Loss: 0.09306

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.66873

Collected Steps per Second: 22,049.38450
Overall Steps per Second: 10,590.32046

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.45375
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.72148

Cumulative Model Updates: 78,724
Cumulative Timesteps: 656,539,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,090.77269
Policy Entropy: 1.78991
Value Function Loss: 0.09321

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.52806
Value Function Update Magnitude: 0.65505

Collected Steps per Second: 22,924.20835
Overall Steps per Second: 10,756.67115

Timestep Collection Time: 2.18110
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.64828

Cumulative Model Updates: 78,730
Cumulative Timesteps: 656,589,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 656589402...
Checkpoint 656589402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,812.69112
Policy Entropy: 1.80240
Value Function Loss: 0.09432

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.16978
Policy Update Magnitude: 0.49181
Value Function Update Magnitude: 0.67860

Collected Steps per Second: 22,176.56494
Overall Steps per Second: 10,656.83143

Timestep Collection Time: 2.25535
Timestep Consumption Time: 2.43797
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.69333

Cumulative Model Updates: 78,736
Cumulative Timesteps: 656,639,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,869.80958
Policy Entropy: 1.80799
Value Function Loss: 0.09457

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.15612
Policy Update Magnitude: 0.52866
Value Function Update Magnitude: 0.69526

Collected Steps per Second: 22,928.04504
Overall Steps per Second: 10,678.40657

Timestep Collection Time: 2.18126
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.68347

Cumulative Model Updates: 78,742
Cumulative Timesteps: 656,689,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 656689430...
Checkpoint 656689430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,492.01346
Policy Entropy: 1.81034
Value Function Loss: 0.09729

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14288
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.75805

Collected Steps per Second: 22,482.48107
Overall Steps per Second: 10,512.84617

Timestep Collection Time: 2.22467
Timestep Consumption Time: 2.53294
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.75761

Cumulative Model Updates: 78,748
Cumulative Timesteps: 656,739,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,003.08657
Policy Entropy: 1.81345
Value Function Loss: 0.08482

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.72391

Collected Steps per Second: 23,119.10263
Overall Steps per Second: 10,848.30819

Timestep Collection Time: 2.16271
Timestep Consumption Time: 2.44630
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60901

Cumulative Model Updates: 78,754
Cumulative Timesteps: 656,789,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 656789446...
Checkpoint 656789446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,722.01559
Policy Entropy: 1.81107
Value Function Loss: 0.07723

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.51743
Value Function Update Magnitude: 0.61995

Collected Steps per Second: 21,940.95019
Overall Steps per Second: 10,605.21011

Timestep Collection Time: 2.27939
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.71580

Cumulative Model Updates: 78,760
Cumulative Timesteps: 656,839,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,267.16874
Policy Entropy: 1.80640
Value Function Loss: 0.08245

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.51383
Value Function Update Magnitude: 0.66862

Collected Steps per Second: 22,307.44950
Overall Steps per Second: 10,572.69378

Timestep Collection Time: 2.24203
Timestep Consumption Time: 2.48846
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.73049

Cumulative Model Updates: 78,766
Cumulative Timesteps: 656,889,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 656889472...
Checkpoint 656889472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,743.48903
Policy Entropy: 1.80811
Value Function Loss: 0.09098

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.52588
Value Function Update Magnitude: 0.66529

Collected Steps per Second: 21,984.54704
Overall Steps per Second: 10,596.84209

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.72311

Cumulative Model Updates: 78,772
Cumulative Timesteps: 656,939,522

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,661.94129
Policy Entropy: 1.82126
Value Function Loss: 0.10265

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.63606

Collected Steps per Second: 21,953.66570
Overall Steps per Second: 10,449.64215

Timestep Collection Time: 2.27980
Timestep Consumption Time: 2.50984
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.78964

Cumulative Model Updates: 78,778
Cumulative Timesteps: 656,989,572

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 656989572...
Checkpoint 656989572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,871.86624
Policy Entropy: 1.81991
Value Function Loss: 0.09948

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.48079
Value Function Update Magnitude: 0.69965

Collected Steps per Second: 21,747.03091
Overall Steps per Second: 10,579.72478

Timestep Collection Time: 2.29926
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.72621

Cumulative Model Updates: 78,784
Cumulative Timesteps: 657,039,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,260.39232
Policy Entropy: 1.81680
Value Function Loss: 0.09302

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.50222
Value Function Update Magnitude: 0.74681

Collected Steps per Second: 22,499.19313
Overall Steps per Second: 10,573.68970

Timestep Collection Time: 2.22248
Timestep Consumption Time: 2.50662
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.72910

Cumulative Model Updates: 78,790
Cumulative Timesteps: 657,089,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 657089578...
Checkpoint 657089578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,029.30124
Policy Entropy: 1.81725
Value Function Loss: 0.09962

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.50201
Value Function Update Magnitude: 0.76199

Collected Steps per Second: 22,291.48796
Overall Steps per Second: 10,655.66914

Timestep Collection Time: 2.24418
Timestep Consumption Time: 2.45060
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.69478

Cumulative Model Updates: 78,796
Cumulative Timesteps: 657,139,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,729.58714
Policy Entropy: 1.82584
Value Function Loss: 0.09466

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.49365
Value Function Update Magnitude: 0.73540

Collected Steps per Second: 22,838.58186
Overall Steps per Second: 10,784.52760

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.44797
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.63813

Cumulative Model Updates: 78,802
Cumulative Timesteps: 657,189,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 657189624...
Checkpoint 657189624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,859.04119
Policy Entropy: 1.82644
Value Function Loss: 0.09934

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.53145
Value Function Update Magnitude: 0.76016

Collected Steps per Second: 22,053.74680
Overall Steps per Second: 10,650.96692

Timestep Collection Time: 2.26900
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.69816

Cumulative Model Updates: 78,808
Cumulative Timesteps: 657,239,664

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,774.75658
Policy Entropy: 1.84691
Value Function Loss: 0.09630

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.68288

Collected Steps per Second: 23,018.40598
Overall Steps per Second: 10,735.88172

Timestep Collection Time: 2.17244
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.65784

Cumulative Model Updates: 78,814
Cumulative Timesteps: 657,289,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 657289670...
Checkpoint 657289670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,250.90224
Policy Entropy: 1.85128
Value Function Loss: 0.09571

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.54812
Value Function Update Magnitude: 0.74810

Collected Steps per Second: 22,639.22289
Overall Steps per Second: 10,803.17546

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.62882

Cumulative Model Updates: 78,820
Cumulative Timesteps: 657,339,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,888.18568
Policy Entropy: 1.84985
Value Function Loss: 0.08923

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.71694

Collected Steps per Second: 22,281.73405
Overall Steps per Second: 10,525.42644

Timestep Collection Time: 2.24426
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.75097

Cumulative Model Updates: 78,826
Cumulative Timesteps: 657,389,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 657389682...
Checkpoint 657389682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,179.10401
Policy Entropy: 1.83072
Value Function Loss: 0.08801

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.62477

Collected Steps per Second: 21,767.32546
Overall Steps per Second: 10,599.09261

Timestep Collection Time: 2.29812
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71965

Cumulative Model Updates: 78,832
Cumulative Timesteps: 657,439,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,582.50594
Policy Entropy: 1.81578
Value Function Loss: 0.09121

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.54194
Value Function Update Magnitude: 0.54068

Collected Steps per Second: 22,078.71211
Overall Steps per Second: 10,527.57451

Timestep Collection Time: 2.26490
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.75000

Cumulative Model Updates: 78,838
Cumulative Timesteps: 657,489,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 657489712...
Checkpoint 657489712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,581.08311
Policy Entropy: 1.82070
Value Function Loss: 0.09316

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.54072
Value Function Update Magnitude: 0.50628

Collected Steps per Second: 22,002.81579
Overall Steps per Second: 10,599.15979

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.71905

Cumulative Model Updates: 78,844
Cumulative Timesteps: 657,539,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,627.22140
Policy Entropy: 1.80907
Value Function Loss: 0.09771

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.53981
Value Function Update Magnitude: 0.68120

Collected Steps per Second: 22,275.09926
Overall Steps per Second: 10,493.63207

Timestep Collection Time: 2.24538
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.76632

Cumulative Model Updates: 78,850
Cumulative Timesteps: 657,589,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 657589746...
Checkpoint 657589746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,880.68201
Policy Entropy: 1.82320
Value Function Loss: 0.09109

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.48795
Value Function Update Magnitude: 0.75957

Collected Steps per Second: 21,966.36318
Overall Steps per Second: 10,559.16572

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.73768

Cumulative Model Updates: 78,856
Cumulative Timesteps: 657,639,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,565.50277
Policy Entropy: 1.82541
Value Function Loss: 0.08879

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.45872
Value Function Update Magnitude: 0.74862

Collected Steps per Second: 22,987.73526
Overall Steps per Second: 10,699.52763

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.67310

Cumulative Model Updates: 78,862
Cumulative Timesteps: 657,689,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 657689772...
Checkpoint 657689772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,599.81017
Policy Entropy: 1.84276
Value Function Loss: 0.08002

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.47821
Value Function Update Magnitude: 0.68422

Collected Steps per Second: 22,444.31285
Overall Steps per Second: 10,563.13948

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.73477

Cumulative Model Updates: 78,868
Cumulative Timesteps: 657,739,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,482.37719
Policy Entropy: 1.83407
Value Function Loss: 0.07929

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.49526
Value Function Update Magnitude: 0.68187

Collected Steps per Second: 23,025.73502
Overall Steps per Second: 10,826.59875

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.61844

Cumulative Model Updates: 78,874
Cumulative Timesteps: 657,789,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 657789788...
Checkpoint 657789788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,216.85741
Policy Entropy: 1.83175
Value Function Loss: 0.08037

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.49120
Value Function Update Magnitude: 0.71509

Collected Steps per Second: 22,233.57224
Overall Steps per Second: 10,576.96961

Timestep Collection Time: 2.25002
Timestep Consumption Time: 2.47969
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.72971

Cumulative Model Updates: 78,880
Cumulative Timesteps: 657,839,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,522.47264
Policy Entropy: 1.83226
Value Function Loss: 0.08758

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.47365
Value Function Update Magnitude: 0.74031

Collected Steps per Second: 22,589.98841
Overall Steps per Second: 10,599.45867

Timestep Collection Time: 2.21443
Timestep Consumption Time: 2.50505
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.71949

Cumulative Model Updates: 78,886
Cumulative Timesteps: 657,889,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 657889838...
Checkpoint 657889838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,564.67290
Policy Entropy: 1.84566
Value Function Loss: 0.08708

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.49710
Value Function Update Magnitude: 0.64927

Collected Steps per Second: 21,135.52112
Overall Steps per Second: 10,452.94173

Timestep Collection Time: 2.36777
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.78755

Cumulative Model Updates: 78,892
Cumulative Timesteps: 657,939,882

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,093.07783
Policy Entropy: 1.85602
Value Function Loss: 0.10036

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.48227

Collected Steps per Second: 22,445.19739
Overall Steps per Second: 10,554.36407

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73927

Cumulative Model Updates: 78,898
Cumulative Timesteps: 657,989,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 657989902...
Checkpoint 657989902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,870.04342
Policy Entropy: 1.85463
Value Function Loss: 0.09918

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.54584
Value Function Update Magnitude: 0.52217

Collected Steps per Second: 22,107.34819
Overall Steps per Second: 10,600.72342

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.45507
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.71685

Cumulative Model Updates: 78,904
Cumulative Timesteps: 658,039,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,069.47781
Policy Entropy: 1.83417
Value Function Loss: 0.10213

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.54912
Value Function Update Magnitude: 0.55979

Collected Steps per Second: 22,671.95658
Overall Steps per Second: 10,588.73341

Timestep Collection Time: 2.20616
Timestep Consumption Time: 2.51754
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.72370

Cumulative Model Updates: 78,910
Cumulative Timesteps: 658,089,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 658089922...
Checkpoint 658089922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,743.50087
Policy Entropy: 1.82606
Value Function Loss: 0.09228

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.54459
Value Function Update Magnitude: 0.68448

Collected Steps per Second: 22,568.55165
Overall Steps per Second: 10,515.21705

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.54086
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.75749

Cumulative Model Updates: 78,916
Cumulative Timesteps: 658,139,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,079.09362
Policy Entropy: 1.82012
Value Function Loss: 0.08700

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.60183

Collected Steps per Second: 22,923.72528
Overall Steps per Second: 10,799.01247

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.63061

Cumulative Model Updates: 78,922
Cumulative Timesteps: 658,189,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 658189954...
Checkpoint 658189954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,360.47278
Policy Entropy: 1.82461
Value Function Loss: 0.08315

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.60385

Collected Steps per Second: 22,336.36004
Overall Steps per Second: 10,660.88924

Timestep Collection Time: 2.23940
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.69192

Cumulative Model Updates: 78,928
Cumulative Timesteps: 658,239,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,530.88449
Policy Entropy: 1.82632
Value Function Loss: 0.08243

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.55115
Value Function Update Magnitude: 0.70344

Collected Steps per Second: 22,934.62737
Overall Steps per Second: 10,709.75494

Timestep Collection Time: 2.18124
Timestep Consumption Time: 2.48983
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.67107

Cumulative Model Updates: 78,934
Cumulative Timesteps: 658,290,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 658290000...
Checkpoint 658290000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,863.21849
Policy Entropy: 1.82986
Value Function Loss: 0.08185

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.75564

Collected Steps per Second: 22,497.79309
Overall Steps per Second: 10,842.83225

Timestep Collection Time: 2.22280
Timestep Consumption Time: 2.38928
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61208

Cumulative Model Updates: 78,940
Cumulative Timesteps: 658,340,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,146.88355
Policy Entropy: 1.84383
Value Function Loss: 0.08821

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.68960

Collected Steps per Second: 22,609.90908
Overall Steps per Second: 10,707.79928

Timestep Collection Time: 2.21177
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.67024

Cumulative Model Updates: 78,946
Cumulative Timesteps: 658,390,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 658390016...
Checkpoint 658390016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,503.54882
Policy Entropy: 1.84138
Value Function Loss: 0.08988

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.70534

Collected Steps per Second: 22,220.17212
Overall Steps per Second: 10,502.90542

Timestep Collection Time: 2.25030
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.76078

Cumulative Model Updates: 78,952
Cumulative Timesteps: 658,440,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,120.22652
Policy Entropy: 1.83491
Value Function Loss: 0.08743

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.54400
Value Function Update Magnitude: 0.77761

Collected Steps per Second: 22,333.67684
Overall Steps per Second: 10,787.23719

Timestep Collection Time: 2.24029
Timestep Consumption Time: 2.39797
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.63826

Cumulative Model Updates: 78,958
Cumulative Timesteps: 658,490,052

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 658490052...
Checkpoint 658490052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,914.74362
Policy Entropy: 1.82151
Value Function Loss: 0.08295

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.78172

Collected Steps per Second: 21,585.78272
Overall Steps per Second: 10,613.42033

Timestep Collection Time: 2.31643
Timestep Consumption Time: 2.39477
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.71121

Cumulative Model Updates: 78,964
Cumulative Timesteps: 658,540,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,572.08966
Policy Entropy: 1.82300
Value Function Loss: 0.08602

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.79445

Collected Steps per Second: 22,299.56842
Overall Steps per Second: 10,531.84778

Timestep Collection Time: 2.24264
Timestep Consumption Time: 2.50581
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.74845

Cumulative Model Updates: 78,970
Cumulative Timesteps: 658,590,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 658590064...
Checkpoint 658590064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,166.36431
Policy Entropy: 1.82929
Value Function Loss: 0.08756

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.75668

Collected Steps per Second: 22,010.81556
Overall Steps per Second: 10,554.15805

Timestep Collection Time: 2.27343
Timestep Consumption Time: 2.46783
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.74126

Cumulative Model Updates: 78,976
Cumulative Timesteps: 658,640,104

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,766.46624
Policy Entropy: 1.83955
Value Function Loss: 0.08405

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.68478

Collected Steps per Second: 22,955.07788
Overall Steps per Second: 10,664.75919

Timestep Collection Time: 2.17947
Timestep Consumption Time: 2.51168
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69115

Cumulative Model Updates: 78,982
Cumulative Timesteps: 658,690,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 658690134...
Checkpoint 658690134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,006.05799
Policy Entropy: 1.83188
Value Function Loss: 0.08770

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.54693
Value Function Update Magnitude: 0.56170

Collected Steps per Second: 22,449.28795
Overall Steps per Second: 10,587.82111

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.72486

Cumulative Model Updates: 78,988
Cumulative Timesteps: 658,740,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,309.60496
Policy Entropy: 1.84369
Value Function Loss: 0.08855

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.63482

Collected Steps per Second: 23,010.57985
Overall Steps per Second: 10,819.59316

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.44882
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.62217

Cumulative Model Updates: 78,994
Cumulative Timesteps: 658,790,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 658790170...
Checkpoint 658790170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,801.22914
Policy Entropy: 1.82410
Value Function Loss: 0.08774

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.69843

Collected Steps per Second: 22,253.60479
Overall Steps per Second: 10,680.65074

Timestep Collection Time: 2.24782
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.68342

Cumulative Model Updates: 79,000
Cumulative Timesteps: 658,840,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,354.38343
Policy Entropy: 1.84735
Value Function Loss: 0.08500

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.68481

Collected Steps per Second: 21,270.08788
Overall Steps per Second: 10,414.85231

Timestep Collection Time: 2.35100
Timestep Consumption Time: 2.45041
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.80141

Cumulative Model Updates: 79,006
Cumulative Timesteps: 658,890,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 658890198...
Checkpoint 658890198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,563.53874
Policy Entropy: 1.84985
Value Function Loss: 0.07674

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.62881

Collected Steps per Second: 22,564.15938
Overall Steps per Second: 10,649.77307

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.47983
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.69644

Cumulative Model Updates: 79,012
Cumulative Timesteps: 658,940,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,685.86665
Policy Entropy: 1.86139
Value Function Loss: 0.07878

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.52256
Value Function Update Magnitude: 0.55874

Collected Steps per Second: 21,958.29505
Overall Steps per Second: 10,415.17866

Timestep Collection Time: 2.27713
Timestep Consumption Time: 2.52374
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.80088

Cumulative Model Updates: 79,018
Cumulative Timesteps: 658,990,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 658990216...
Checkpoint 658990216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,032.32949
Policy Entropy: 1.84369
Value Function Loss: 0.08235

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.62123

Collected Steps per Second: 21,900.16560
Overall Steps per Second: 10,602.20130

Timestep Collection Time: 2.28364
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.71713

Cumulative Model Updates: 79,024
Cumulative Timesteps: 659,040,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,848.72797
Policy Entropy: 1.83388
Value Function Loss: 0.08728

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.53652
Value Function Update Magnitude: 0.64879

Collected Steps per Second: 22,098.88797
Overall Steps per Second: 10,541.96052

Timestep Collection Time: 2.26310
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.74409

Cumulative Model Updates: 79,030
Cumulative Timesteps: 659,090,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 659090240...
Checkpoint 659090240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,793.78271
Policy Entropy: 1.83071
Value Function Loss: 0.09072

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.63983

Collected Steps per Second: 21,675.22218
Overall Steps per Second: 10,546.48430

Timestep Collection Time: 2.30687
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.74111

Cumulative Model Updates: 79,036
Cumulative Timesteps: 659,140,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,477.24681
Policy Entropy: 1.82705
Value Function Loss: 0.08678

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.53331
Value Function Update Magnitude: 0.53082

Collected Steps per Second: 22,631.11019
Overall Steps per Second: 10,524.81971

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.54245
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.75277

Cumulative Model Updates: 79,042
Cumulative Timesteps: 659,190,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 659190264...
Checkpoint 659190264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,371.42558
Policy Entropy: 1.82512
Value Function Loss: 0.09060

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.52464
Value Function Update Magnitude: 0.43879

Collected Steps per Second: 22,375.39326
Overall Steps per Second: 10,619.35320

Timestep Collection Time: 2.23513
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.70951

Cumulative Model Updates: 79,048
Cumulative Timesteps: 659,240,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,284.97073
Policy Entropy: 1.81138
Value Function Loss: 0.08607

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.53379
Value Function Update Magnitude: 0.45361

Collected Steps per Second: 22,618.24834
Overall Steps per Second: 10,604.34302

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.71637

Cumulative Model Updates: 79,054
Cumulative Timesteps: 659,290,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 659290290...
Checkpoint 659290290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,188.07787
Policy Entropy: 1.80894
Value Function Loss: 0.09949

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.53456
Value Function Update Magnitude: 0.51396

Collected Steps per Second: 22,439.19014
Overall Steps per Second: 10,549.89831

Timestep Collection Time: 2.22851
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.73995

Cumulative Model Updates: 79,060
Cumulative Timesteps: 659,340,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,401.72830
Policy Entropy: 1.80237
Value Function Loss: 0.09769

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.54054
Value Function Update Magnitude: 0.60146

Collected Steps per Second: 22,820.79164
Overall Steps per Second: 10,809.06810

Timestep Collection Time: 2.19195
Timestep Consumption Time: 2.43583
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62778

Cumulative Model Updates: 79,066
Cumulative Timesteps: 659,390,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 659390318...
Checkpoint 659390318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,151.57064
Policy Entropy: 1.80006
Value Function Loss: 0.09750

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.49513
Value Function Update Magnitude: 0.66631

Collected Steps per Second: 22,453.25191
Overall Steps per Second: 10,657.45955

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.46519
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.69249

Cumulative Model Updates: 79,072
Cumulative Timesteps: 659,440,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,398.52930
Policy Entropy: 1.81019
Value Function Loss: 0.09452

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.16135
Policy Update Magnitude: 0.48437
Value Function Update Magnitude: 0.66851

Collected Steps per Second: 22,630.27599
Overall Steps per Second: 10,576.24866

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.72947

Cumulative Model Updates: 79,078
Cumulative Timesteps: 659,490,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 659490348...
Checkpoint 659490348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,911.39456
Policy Entropy: 1.81900
Value Function Loss: 0.08753

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.72671

Collected Steps per Second: 21,977.21644
Overall Steps per Second: 10,645.41240

Timestep Collection Time: 2.27545
Timestep Consumption Time: 2.42216
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.69761

Cumulative Model Updates: 79,084
Cumulative Timesteps: 659,540,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,300.42451
Policy Entropy: 1.84050
Value Function Loss: 0.08568

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.52599
Value Function Update Magnitude: 0.72858

Collected Steps per Second: 21,973.88335
Overall Steps per Second: 10,500.74071

Timestep Collection Time: 2.27607
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76290

Cumulative Model Updates: 79,090
Cumulative Timesteps: 659,590,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 659590370...
Checkpoint 659590370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,643.55095
Policy Entropy: 1.83539
Value Function Loss: 0.08579

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.52800
Value Function Update Magnitude: 0.64251

Collected Steps per Second: 22,286.00079
Overall Steps per Second: 10,566.67872

Timestep Collection Time: 2.24356
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.73186

Cumulative Model Updates: 79,096
Cumulative Timesteps: 659,640,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,316.29660
Policy Entropy: 1.83740
Value Function Loss: 0.09744

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.48367

Collected Steps per Second: 22,393.04535
Overall Steps per Second: 10,544.73827

Timestep Collection Time: 2.23418
Timestep Consumption Time: 2.51037
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74455

Cumulative Model Updates: 79,102
Cumulative Timesteps: 659,690,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 659690400...
Checkpoint 659690400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,639.77393
Policy Entropy: 1.81737
Value Function Loss: 0.09439

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.54934
Value Function Update Magnitude: 0.56526

Collected Steps per Second: 22,131.29454
Overall Steps per Second: 10,538.01773

Timestep Collection Time: 2.26060
Timestep Consumption Time: 2.48697
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.74757

Cumulative Model Updates: 79,108
Cumulative Timesteps: 659,740,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,402.33943
Policy Entropy: 1.80430
Value Function Loss: 0.08528

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.71727

Collected Steps per Second: 22,642.15367
Overall Steps per Second: 10,619.93984

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.49985
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70812

Cumulative Model Updates: 79,114
Cumulative Timesteps: 659,790,430

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 659790430...
Checkpoint 659790430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,681.65450
Policy Entropy: 1.78954
Value Function Loss: 0.07833

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.74118

Collected Steps per Second: 21,653.69840
Overall Steps per Second: 10,547.99980

Timestep Collection Time: 2.31000
Timestep Consumption Time: 2.43213
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.74213

Cumulative Model Updates: 79,120
Cumulative Timesteps: 659,840,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,055.36555
Policy Entropy: 1.78552
Value Function Loss: 0.07821

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.69945

Collected Steps per Second: 22,114.83473
Overall Steps per Second: 10,490.30518

Timestep Collection Time: 2.26219
Timestep Consumption Time: 2.50678
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.76897

Cumulative Model Updates: 79,126
Cumulative Timesteps: 659,890,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 659890478...
Checkpoint 659890478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,342.95663
Policy Entropy: 1.80291
Value Function Loss: 0.09051

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.61915

Collected Steps per Second: 21,902.99638
Overall Steps per Second: 10,543.30291

Timestep Collection Time: 2.28444
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.74576

Cumulative Model Updates: 79,132
Cumulative Timesteps: 659,940,514

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,803.42169
Policy Entropy: 1.81144
Value Function Loss: 0.09033

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 22,403.38975
Overall Steps per Second: 10,606.10511

Timestep Collection Time: 2.23252
Timestep Consumption Time: 2.48326
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.71577

Cumulative Model Updates: 79,138
Cumulative Timesteps: 659,990,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 659990530...
Checkpoint 659990530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,388.09290
Policy Entropy: 1.83006
Value Function Loss: 0.08721

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.69176

Collected Steps per Second: 22,525.30574
Overall Steps per Second: 10,601.48624

Timestep Collection Time: 2.22132
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.71972

Cumulative Model Updates: 79,144
Cumulative Timesteps: 660,040,566

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,153.89998
Policy Entropy: 1.80200
Value Function Loss: 0.08736

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.66029

Collected Steps per Second: 22,800.83581
Overall Steps per Second: 10,750.28862

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.65141

Cumulative Model Updates: 79,150
Cumulative Timesteps: 660,090,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 660090570...
Checkpoint 660090570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,602.03950
Policy Entropy: 1.80092
Value Function Loss: 0.08502

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.63119

Collected Steps per Second: 22,735.75250
Overall Steps per Second: 10,683.04817

Timestep Collection Time: 2.19962
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.68125

Cumulative Model Updates: 79,156
Cumulative Timesteps: 660,140,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,988.92640
Policy Entropy: 1.80093
Value Function Loss: 0.08547

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.61975

Collected Steps per Second: 22,937.59530
Overall Steps per Second: 10,810.22199

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62673

Cumulative Model Updates: 79,162
Cumulative Timesteps: 660,190,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 660190596...
Checkpoint 660190596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,921.25448
Policy Entropy: 1.79516
Value Function Loss: 0.08489

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.73008

Collected Steps per Second: 22,451.19709
Overall Steps per Second: 10,713.70677

Timestep Collection Time: 2.22875
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.67047

Cumulative Model Updates: 79,168
Cumulative Timesteps: 660,240,634

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,441.84506
Policy Entropy: 1.78366
Value Function Loss: 0.08553

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.83014

Collected Steps per Second: 22,424.31424
Overall Steps per Second: 10,708.39452

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.67241

Cumulative Model Updates: 79,174
Cumulative Timesteps: 660,290,668

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 660290668...
Checkpoint 660290668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,709.23552
Policy Entropy: 1.77708
Value Function Loss: 0.08735

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.82295

Collected Steps per Second: 22,061.21831
Overall Steps per Second: 10,480.70011

Timestep Collection Time: 2.26687
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.77163

Cumulative Model Updates: 79,180
Cumulative Timesteps: 660,340,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,176.10686
Policy Entropy: 1.79173
Value Function Loss: 0.08447

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.53142
Value Function Update Magnitude: 0.79171

Collected Steps per Second: 22,111.15348
Overall Steps per Second: 10,474.49921

Timestep Collection Time: 2.26130
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.77350

Cumulative Model Updates: 79,186
Cumulative Timesteps: 660,390,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 660390678...
Checkpoint 660390678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,962.56195
Policy Entropy: 1.78850
Value Function Loss: 0.08309

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.52856
Value Function Update Magnitude: 0.76875

Collected Steps per Second: 21,826.34144
Overall Steps per Second: 10,491.70068

Timestep Collection Time: 2.29182
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.76777

Cumulative Model Updates: 79,192
Cumulative Timesteps: 660,440,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,708.08120
Policy Entropy: 1.77971
Value Function Loss: 0.08202

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.53394
Value Function Update Magnitude: 0.67641

Collected Steps per Second: 22,411.42164
Overall Steps per Second: 10,527.43378

Timestep Collection Time: 2.23127
Timestep Consumption Time: 2.51879
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75007

Cumulative Model Updates: 79,198
Cumulative Timesteps: 660,490,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 660490706...
Checkpoint 660490706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,134.58790
Policy Entropy: 1.77260
Value Function Loss: 0.08825

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.52727
Value Function Update Magnitude: 0.70544

Collected Steps per Second: 22,026.36288
Overall Steps per Second: 10,629.57029

Timestep Collection Time: 2.27182
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.70762

Cumulative Model Updates: 79,204
Cumulative Timesteps: 660,540,746

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,478.81951
Policy Entropy: 1.77658
Value Function Loss: 0.09225

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.51874
Value Function Update Magnitude: 0.69864

Collected Steps per Second: 22,971.22923
Overall Steps per Second: 10,796.75874

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.45468
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.63158

Cumulative Model Updates: 79,210
Cumulative Timesteps: 660,590,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 660590752...
Checkpoint 660590752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,760.61727
Policy Entropy: 1.78657
Value Function Loss: 0.08998

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.49095
Value Function Update Magnitude: 0.73442

Collected Steps per Second: 22,410.36403
Overall Steps per Second: 10,706.01348

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.67083

Cumulative Model Updates: 79,216
Cumulative Timesteps: 660,640,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,689.45004
Policy Entropy: 1.79255
Value Function Loss: 0.09580

Mean KL Divergence: 0.03066
SB3 Clip Fraction: 0.20158
Policy Update Magnitude: 0.42779
Value Function Update Magnitude: 0.67935

Collected Steps per Second: 22,788.37977
Overall Steps per Second: 10,687.25162

Timestep Collection Time: 2.19410
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.67847

Cumulative Model Updates: 79,222
Cumulative Timesteps: 660,690,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 660690758...
Checkpoint 660690758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,168.04095
Policy Entropy: 1.77114
Value Function Loss: 0.09294

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.18303
Policy Update Magnitude: 0.43421
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 22,592.97982
Overall Steps per Second: 10,787.24180

Timestep Collection Time: 2.21414
Timestep Consumption Time: 2.42319
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.63733

Cumulative Model Updates: 79,228
Cumulative Timesteps: 660,740,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,830.30572
Policy Entropy: 1.76826
Value Function Loss: 0.10632

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.18821
Policy Update Magnitude: 0.42203
Value Function Update Magnitude: 0.45743

Collected Steps per Second: 22,463.61081
Overall Steps per Second: 10,651.16857

Timestep Collection Time: 2.22680
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.69639

Cumulative Model Updates: 79,234
Cumulative Timesteps: 660,790,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 660790804...
Checkpoint 660790804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,478.25805
Policy Entropy: 1.76872
Value Function Loss: 0.11983

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.18813
Policy Update Magnitude: 0.40612
Value Function Update Magnitude: 0.52447

Collected Steps per Second: 22,488.13291
Overall Steps per Second: 10,563.75166

Timestep Collection Time: 2.22464
Timestep Consumption Time: 2.51118
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73582

Cumulative Model Updates: 79,240
Cumulative Timesteps: 660,840,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,312.53014
Policy Entropy: 1.78984
Value Function Loss: 0.12881

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.17018
Policy Update Magnitude: 0.43830
Value Function Update Magnitude: 0.61809

Collected Steps per Second: 22,270.76342
Overall Steps per Second: 10,537.39914

Timestep Collection Time: 2.24707
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.74918

Cumulative Model Updates: 79,246
Cumulative Timesteps: 660,890,876

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 660890876...
Checkpoint 660890876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,065.96959
Policy Entropy: 1.81598
Value Function Loss: 0.12905

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.58025

Collected Steps per Second: 21,823.61202
Overall Steps per Second: 10,561.37010

Timestep Collection Time: 2.29183
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.73575

Cumulative Model Updates: 79,252
Cumulative Timesteps: 660,940,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,403.31695
Policy Entropy: 1.81218
Value Function Loss: 0.11585

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16067
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.69056

Collected Steps per Second: 22,387.28191
Overall Steps per Second: 10,533.21785

Timestep Collection Time: 2.23555
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.75144

Cumulative Model Updates: 79,258
Cumulative Timesteps: 660,990,940

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 660990940...
Checkpoint 660990940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,932.03693
Policy Entropy: 1.82912
Value Function Loss: 0.11542

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.16667
Policy Update Magnitude: 0.52318
Value Function Update Magnitude: 0.58825

Collected Steps per Second: 21,834.83207
Overall Steps per Second: 10,512.59403

Timestep Collection Time: 2.29120
Timestep Consumption Time: 2.46766
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.75886

Cumulative Model Updates: 79,264
Cumulative Timesteps: 661,040,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,950.57154
Policy Entropy: 1.83026
Value Function Loss: 0.11617

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.16705
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.54604

Collected Steps per Second: 22,787.84417
Overall Steps per Second: 10,515.96417

Timestep Collection Time: 2.19459
Timestep Consumption Time: 2.56104
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.75563

Cumulative Model Updates: 79,270
Cumulative Timesteps: 661,090,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 661090978...
Checkpoint 661090978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,732.37538
Policy Entropy: 1.83736
Value Function Loss: 0.12112

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.17522
Policy Update Magnitude: 0.53391
Value Function Update Magnitude: 0.42941

Collected Steps per Second: 22,167.85763
Overall Steps per Second: 10,600.61273

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.71841

Cumulative Model Updates: 79,276
Cumulative Timesteps: 661,140,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,697.06717
Policy Entropy: 1.83329
Value Function Loss: 0.11675

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.16639
Policy Update Magnitude: 0.50893
Value Function Update Magnitude: 0.40378

Collected Steps per Second: 22,831.30022
Overall Steps per Second: 10,814.07684

Timestep Collection Time: 2.19182
Timestep Consumption Time: 2.43567
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.62749

Cumulative Model Updates: 79,282
Cumulative Timesteps: 661,191,038

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 661191038...
Checkpoint 661191038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,348.10957
Policy Entropy: 1.82587
Value Function Loss: 0.11478

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15439
Policy Update Magnitude: 0.48349
Value Function Update Magnitude: 0.40765

Collected Steps per Second: 22,412.90341
Overall Steps per Second: 10,710.72864

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.67158

Cumulative Model Updates: 79,288
Cumulative Timesteps: 661,241,074

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,484.11049
Policy Entropy: 1.83107
Value Function Loss: 0.10423

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.51928
Value Function Update Magnitude: 0.41568

Collected Steps per Second: 22,721.36001
Overall Steps per Second: 10,608.99357

Timestep Collection Time: 2.20057
Timestep Consumption Time: 2.51241
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.71298

Cumulative Model Updates: 79,294
Cumulative Timesteps: 661,291,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 661291074...
Checkpoint 661291074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,080.41078
Policy Entropy: 1.83583
Value Function Loss: 0.10698

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.39055

Collected Steps per Second: 22,500.66651
Overall Steps per Second: 10,574.26925

Timestep Collection Time: 2.22278
Timestep Consumption Time: 2.50700
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72978

Cumulative Model Updates: 79,300
Cumulative Timesteps: 661,341,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,664.63096
Policy Entropy: 1.82045
Value Function Loss: 0.10523

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.56889
Value Function Update Magnitude: 0.33468

Collected Steps per Second: 22,428.39416
Overall Steps per Second: 10,612.14860

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.71422

Cumulative Model Updates: 79,306
Cumulative Timesteps: 661,391,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 661391116...
Checkpoint 661391116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,949.89362
Policy Entropy: 1.81807
Value Function Loss: 0.11625

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.57461
Value Function Update Magnitude: 0.34692

Collected Steps per Second: 22,174.62482
Overall Steps per Second: 10,607.23719

Timestep Collection Time: 2.25591
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.71603

Cumulative Model Updates: 79,312
Cumulative Timesteps: 661,441,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,622.12483
Policy Entropy: 1.81177
Value Function Loss: 0.11652

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.57446
Value Function Update Magnitude: 0.32133

Collected Steps per Second: 22,448.55293
Overall Steps per Second: 10,705.19853

Timestep Collection Time: 2.22803
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.67212

Cumulative Model Updates: 79,318
Cumulative Timesteps: 661,491,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 661491156...
Checkpoint 661491156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,636.44390
Policy Entropy: 1.81814
Value Function Loss: 0.10798

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.56739
Value Function Update Magnitude: 0.31609

Collected Steps per Second: 21,962.63077
Overall Steps per Second: 10,624.36777

Timestep Collection Time: 2.27760
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.70823

Cumulative Model Updates: 79,324
Cumulative Timesteps: 661,541,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,184.23464
Policy Entropy: 1.81028
Value Function Loss: 0.10437

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.28867

Collected Steps per Second: 22,130.31192
Overall Steps per Second: 10,431.71403

Timestep Collection Time: 2.26061
Timestep Consumption Time: 2.53515
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.79576

Cumulative Model Updates: 79,330
Cumulative Timesteps: 661,591,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 661591206...
Checkpoint 661591206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,914.45243
Policy Entropy: 1.82197
Value Function Loss: 0.11436

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.57157
Value Function Update Magnitude: 0.31641

Collected Steps per Second: 21,934.63498
Overall Steps per Second: 10,634.69586

Timestep Collection Time: 2.28078
Timestep Consumption Time: 2.42345
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.70422

Cumulative Model Updates: 79,336
Cumulative Timesteps: 661,641,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,727.83517
Policy Entropy: 1.82733
Value Function Loss: 0.11562

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.32127

Collected Steps per Second: 22,736.25171
Overall Steps per Second: 10,593.02066

Timestep Collection Time: 2.19983
Timestep Consumption Time: 2.52176
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.72160

Cumulative Model Updates: 79,342
Cumulative Timesteps: 661,691,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 661691250...
Checkpoint 661691250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,104.68290
Policy Entropy: 1.82781
Value Function Loss: 0.10992

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.55478
Value Function Update Magnitude: 0.36852

Collected Steps per Second: 20,945.02348
Overall Steps per Second: 10,313.21658

Timestep Collection Time: 2.38806
Timestep Consumption Time: 2.46183
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.84989

Cumulative Model Updates: 79,348
Cumulative Timesteps: 661,741,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,934.69997
Policy Entropy: 1.82430
Value Function Loss: 0.09839

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.55891
Value Function Update Magnitude: 0.50433

Collected Steps per Second: 22,194.39516
Overall Steps per Second: 10,642.45853

Timestep Collection Time: 2.25336
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.69929

Cumulative Model Updates: 79,354
Cumulative Timesteps: 661,791,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 661791280...
Checkpoint 661791280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,778.26072
Policy Entropy: 1.81071
Value Function Loss: 0.09135

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.54896
Value Function Update Magnitude: 0.63723

Collected Steps per Second: 22,003.41672
Overall Steps per Second: 10,682.76068

Timestep Collection Time: 2.27347
Timestep Consumption Time: 2.40922
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.68268

Cumulative Model Updates: 79,360
Cumulative Timesteps: 661,841,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,747.85311
Policy Entropy: 1.81161
Value Function Loss: 0.08532

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.71157

Collected Steps per Second: 22,605.76574
Overall Steps per Second: 10,550.70784

Timestep Collection Time: 2.21280
Timestep Consumption Time: 2.52831
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.74110

Cumulative Model Updates: 79,366
Cumulative Timesteps: 661,891,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 661891326...
Checkpoint 661891326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,307.76869
Policy Entropy: 1.81434
Value Function Loss: 0.08336

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.74399

Collected Steps per Second: 22,507.63724
Overall Steps per Second: 10,564.85061

Timestep Collection Time: 2.22165
Timestep Consumption Time: 2.51141
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.73305

Cumulative Model Updates: 79,372
Cumulative Timesteps: 661,941,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,226.38526
Policy Entropy: 1.81599
Value Function Loss: 0.08564

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.52791
Value Function Update Magnitude: 0.69843

Collected Steps per Second: 22,714.16984
Overall Steps per Second: 10,634.25043

Timestep Collection Time: 2.20233
Timestep Consumption Time: 2.50172
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.70405

Cumulative Model Updates: 79,378
Cumulative Timesteps: 661,991,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 661991354...
Checkpoint 661991354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,010.81201
Policy Entropy: 1.81701
Value Function Loss: 0.08438

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.51446
Value Function Update Magnitude: 0.65396

Collected Steps per Second: 22,338.80110
Overall Steps per Second: 10,569.63248

Timestep Collection Time: 2.23888
Timestep Consumption Time: 2.49297
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.73186

Cumulative Model Updates: 79,384
Cumulative Timesteps: 662,041,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,917.51476
Policy Entropy: 1.80036
Value Function Loss: 0.08141

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.48238
Value Function Update Magnitude: 0.69480

Collected Steps per Second: 22,846.67903
Overall Steps per Second: 10,797.39074

Timestep Collection Time: 2.18876
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.63130

Cumulative Model Updates: 79,390
Cumulative Timesteps: 662,091,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 662091374...
Checkpoint 662091374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,609.75481
Policy Entropy: 1.80829
Value Function Loss: 0.08574

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.52750
Value Function Update Magnitude: 0.72618

Collected Steps per Second: 22,382.66854
Overall Steps per Second: 10,635.61901

Timestep Collection Time: 2.23459
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.70269

Cumulative Model Updates: 79,396
Cumulative Timesteps: 662,141,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,521.24661
Policy Entropy: 1.81764
Value Function Loss: 0.09156

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.54725

Collected Steps per Second: 22,719.69109
Overall Steps per Second: 10,821.11295

Timestep Collection Time: 2.20179
Timestep Consumption Time: 2.42102
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.62281

Cumulative Model Updates: 79,402
Cumulative Timesteps: 662,191,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 662191414...
Checkpoint 662191414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,827.23627
Policy Entropy: 1.84513
Value Function Loss: 0.10291

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.45912

Collected Steps per Second: 21,252.89113
Overall Steps per Second: 10,339.97149

Timestep Collection Time: 2.35272
Timestep Consumption Time: 2.48308
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.83580

Cumulative Model Updates: 79,408
Cumulative Timesteps: 662,241,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,841.30632
Policy Entropy: 1.84506
Value Function Loss: 0.09838

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.61000

Collected Steps per Second: 22,602.05938
Overall Steps per Second: 10,752.13768

Timestep Collection Time: 2.21431
Timestep Consumption Time: 2.44039
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.65470

Cumulative Model Updates: 79,414
Cumulative Timesteps: 662,291,464

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 662291464...
Checkpoint 662291464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,793.39481
Policy Entropy: 1.84129
Value Function Loss: 0.09260

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.72480

Collected Steps per Second: 21,597.42514
Overall Steps per Second: 10,467.50801

Timestep Collection Time: 2.31537
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.77726

Cumulative Model Updates: 79,420
Cumulative Timesteps: 662,341,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,173.16229
Policy Entropy: 1.81037
Value Function Loss: 0.08343

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.15964
Policy Update Magnitude: 0.48266
Value Function Update Magnitude: 0.71792

Collected Steps per Second: 22,536.86861
Overall Steps per Second: 10,767.27499

Timestep Collection Time: 2.21974
Timestep Consumption Time: 2.42637
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.64612

Cumulative Model Updates: 79,426
Cumulative Timesteps: 662,391,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 662391496...
Checkpoint 662391496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,849.62852
Policy Entropy: 1.80458
Value Function Loss: 0.08567

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.46366
Value Function Update Magnitude: 0.69217

Collected Steps per Second: 22,098.07600
Overall Steps per Second: 10,637.70951

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.70289

Cumulative Model Updates: 79,432
Cumulative Timesteps: 662,441,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,926.05345
Policy Entropy: 1.79163
Value Function Loss: 0.08705

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.48785
Value Function Update Magnitude: 0.69375

Collected Steps per Second: 23,213.40052
Overall Steps per Second: 10,836.40644

Timestep Collection Time: 2.15470
Timestep Consumption Time: 2.46103
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61574

Cumulative Model Updates: 79,438
Cumulative Timesteps: 662,491,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662491542...
Checkpoint 662491542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,928.60022
Policy Entropy: 1.80169
Value Function Loss: 0.08999

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.48653
Value Function Update Magnitude: 0.60490

Collected Steps per Second: 22,303.68077
Overall Steps per Second: 10,714.55391

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.66879

Cumulative Model Updates: 79,444
Cumulative Timesteps: 662,541,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,008.29589
Policy Entropy: 1.81316
Value Function Loss: 0.09207

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.51373
Value Function Update Magnitude: 0.60443

Collected Steps per Second: 23,031.62873
Overall Steps per Second: 10,828.81200

Timestep Collection Time: 2.17171
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.61897

Cumulative Model Updates: 79,450
Cumulative Timesteps: 662,591,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662591584...
Checkpoint 662591584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,605.82624
Policy Entropy: 1.82673
Value Function Loss: 0.09346

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.51805

Collected Steps per Second: 22,451.64780
Overall Steps per Second: 10,719.74254

Timestep Collection Time: 2.22897
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.66840

Cumulative Model Updates: 79,456
Cumulative Timesteps: 662,641,628

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,300.69085
Policy Entropy: 1.80906
Value Function Loss: 0.09398

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.52110
Value Function Update Magnitude: 0.44266

Collected Steps per Second: 22,759.96986
Overall Steps per Second: 10,803.26532

Timestep Collection Time: 2.19772
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.63008

Cumulative Model Updates: 79,462
Cumulative Timesteps: 662,691,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 662691648...
Checkpoint 662691648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,854.64902
Policy Entropy: 1.78626
Value Function Loss: 0.09592

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.51557
Value Function Update Magnitude: 0.37313

Collected Steps per Second: 21,730.57476
Overall Steps per Second: 10,422.53486

Timestep Collection Time: 2.30155
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.79864

Cumulative Model Updates: 79,468
Cumulative Timesteps: 662,741,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,637.58397
Policy Entropy: 1.77417
Value Function Loss: 0.09430

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.52435
Value Function Update Magnitude: 0.44070

Collected Steps per Second: 22,639.01850
Overall Steps per Second: 10,771.33208

Timestep Collection Time: 2.20937
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.64362

Cumulative Model Updates: 79,474
Cumulative Timesteps: 662,791,680

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662791680...
Checkpoint 662791680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,230.19882
Policy Entropy: 1.77816
Value Function Loss: 0.09361

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.16100
Policy Update Magnitude: 0.49509
Value Function Update Magnitude: 0.54515

Collected Steps per Second: 21,671.36634
Overall Steps per Second: 10,539.56920

Timestep Collection Time: 2.30913
Timestep Consumption Time: 2.43888
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.74801

Cumulative Model Updates: 79,480
Cumulative Timesteps: 662,841,722

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,524.84320
Policy Entropy: 1.77916
Value Function Loss: 0.08572

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.16143
Policy Update Magnitude: 0.47513
Value Function Update Magnitude: 0.56467

Collected Steps per Second: 22,865.32511
Overall Steps per Second: 10,615.46095

Timestep Collection Time: 2.18759
Timestep Consumption Time: 2.52440
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71200

Cumulative Model Updates: 79,486
Cumulative Timesteps: 662,891,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 662891742...
Checkpoint 662891742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,806.18156
Policy Entropy: 1.79653
Value Function Loss: 0.08912

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.16478
Policy Update Magnitude: 0.48422
Value Function Update Magnitude: 0.55524

Collected Steps per Second: 22,534.55831
Overall Steps per Second: 10,531.10191

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.74860

Cumulative Model Updates: 79,492
Cumulative Timesteps: 662,941,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,808.75428
Policy Entropy: 1.80831
Value Function Loss: 0.09406

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.15789
Policy Update Magnitude: 0.50499
Value Function Update Magnitude: 0.49263

Collected Steps per Second: 22,875.40324
Overall Steps per Second: 10,827.20125

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61911

Cumulative Model Updates: 79,498
Cumulative Timesteps: 662,991,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 662991762...
Checkpoint 662991762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,269.83749
Policy Entropy: 1.82546
Value Function Loss: 0.09482

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.53333
Value Function Update Magnitude: 0.67275

Collected Steps per Second: 22,339.68717
Overall Steps per Second: 10,776.94067

Timestep Collection Time: 2.24014
Timestep Consumption Time: 2.40348
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.64362

Cumulative Model Updates: 79,504
Cumulative Timesteps: 663,041,806

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,334.33881
Policy Entropy: 1.82555
Value Function Loss: 0.08735

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.71149

Collected Steps per Second: 22,915.03341
Overall Steps per Second: 10,844.19211

Timestep Collection Time: 2.18276
Timestep Consumption Time: 2.42966
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.61242

Cumulative Model Updates: 79,510
Cumulative Timesteps: 663,091,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 663091824...
Checkpoint 663091824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,887.58543
Policy Entropy: 1.84086
Value Function Loss: 0.08744

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.53036
Value Function Update Magnitude: 0.67620

Collected Steps per Second: 22,362.01911
Overall Steps per Second: 10,680.29627

Timestep Collection Time: 2.23701
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.68377

Cumulative Model Updates: 79,516
Cumulative Timesteps: 663,141,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,430.83071
Policy Entropy: 1.83786
Value Function Loss: 0.08818

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.52824
Value Function Update Magnitude: 0.68619

Collected Steps per Second: 22,625.67934
Overall Steps per Second: 10,814.60470

Timestep Collection Time: 2.21165
Timestep Consumption Time: 2.41543
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62708

Cumulative Model Updates: 79,522
Cumulative Timesteps: 663,191,888

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 663191888...
Checkpoint 663191888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,132.75222
Policy Entropy: 1.82283
Value Function Loss: 0.09033

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.72411

Collected Steps per Second: 21,866.36528
Overall Steps per Second: 10,435.41289

Timestep Collection Time: 2.28735
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.79291

Cumulative Model Updates: 79,528
Cumulative Timesteps: 663,241,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,515.03779
Policy Entropy: 1.80825
Value Function Loss: 0.08932

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.55179
Value Function Update Magnitude: 0.77422

Collected Steps per Second: 22,243.40105
Overall Steps per Second: 10,702.23640

Timestep Collection Time: 2.24795
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.67211

Cumulative Model Updates: 79,534
Cumulative Timesteps: 663,291,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 663291906...
Checkpoint 663291906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,598.22538
Policy Entropy: 1.81283
Value Function Loss: 0.08678

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.73004

Collected Steps per Second: 21,626.73103
Overall Steps per Second: 10,379.64468

Timestep Collection Time: 2.31306
Timestep Consumption Time: 2.50637
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.81943

Cumulative Model Updates: 79,540
Cumulative Timesteps: 663,341,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,324.55970
Policy Entropy: 1.82882
Value Function Loss: 0.08967

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.62443

Collected Steps per Second: 22,478.32021
Overall Steps per Second: 10,841.06884

Timestep Collection Time: 2.22472
Timestep Consumption Time: 2.38811
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.61283

Cumulative Model Updates: 79,546
Cumulative Timesteps: 663,391,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 663391938...
Checkpoint 663391938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,056.79389
Policy Entropy: 1.82988
Value Function Loss: 0.08886

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.60434

Collected Steps per Second: 22,573.70177
Overall Steps per Second: 10,660.97649

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.69019

Cumulative Model Updates: 79,552
Cumulative Timesteps: 663,441,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,507.24765
Policy Entropy: 1.83143
Value Function Loss: 0.10624

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.66499

Collected Steps per Second: 22,816.21757
Overall Steps per Second: 10,806.94631

Timestep Collection Time: 2.19265
Timestep Consumption Time: 2.43659
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62924

Cumulative Model Updates: 79,558
Cumulative Timesteps: 663,491,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 663491968...
Checkpoint 663491968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,836.45743
Policy Entropy: 1.83046
Value Function Loss: 0.09732

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.56152
Value Function Update Magnitude: 0.77348

Collected Steps per Second: 22,180.33107
Overall Steps per Second: 10,633.39307

Timestep Collection Time: 2.25452
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.70273

Cumulative Model Updates: 79,564
Cumulative Timesteps: 663,541,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,947.57931
Policy Entropy: 1.82491
Value Function Loss: 0.09402

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.73781

Collected Steps per Second: 22,607.30677
Overall Steps per Second: 10,571.90548

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.51976
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.73311

Cumulative Model Updates: 79,570
Cumulative Timesteps: 663,592,012

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 663592012...
Checkpoint 663592012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,617.94570
Policy Entropy: 1.82084
Value Function Loss: 0.08503

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.58173

Collected Steps per Second: 21,092.79683
Overall Steps per Second: 10,250.78303

Timestep Collection Time: 2.37105
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.87885

Cumulative Model Updates: 79,576
Cumulative Timesteps: 663,642,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,823.96919
Policy Entropy: 1.80593
Value Function Loss: 0.08344

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.54847
Value Function Update Magnitude: 0.56131

Collected Steps per Second: 23,194.75039
Overall Steps per Second: 10,810.58439

Timestep Collection Time: 2.15635
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.62658

Cumulative Model Updates: 79,582
Cumulative Timesteps: 663,692,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 663692040...
Checkpoint 663692040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,838.03404
Policy Entropy: 1.82336
Value Function Loss: 0.09228

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.69169

Collected Steps per Second: 21,875.14724
Overall Steps per Second: 10,697.40772

Timestep Collection Time: 2.28798
Timestep Consumption Time: 2.39072
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.67870

Cumulative Model Updates: 79,588
Cumulative Timesteps: 663,742,090

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,344.70490
Policy Entropy: 1.82808
Value Function Loss: 0.08650

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.67439

Collected Steps per Second: 22,396.58805
Overall Steps per Second: 10,588.36977

Timestep Collection Time: 2.23347
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.72424

Cumulative Model Updates: 79,594
Cumulative Timesteps: 663,792,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 663792112...
Checkpoint 663792112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,174.11537
Policy Entropy: 1.83301
Value Function Loss: 0.08839

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.54329
Value Function Update Magnitude: 0.48144

Collected Steps per Second: 22,264.01982
Overall Steps per Second: 10,528.00279

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.74962

Cumulative Model Updates: 79,600
Cumulative Timesteps: 663,842,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,195.70932
Policy Entropy: 1.83141
Value Function Loss: 0.08599

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.59531

Collected Steps per Second: 22,221.61522
Overall Steps per Second: 10,572.23109

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.48090
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.73240

Cumulative Model Updates: 79,606
Cumulative Timesteps: 663,892,148

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 663892148...
Checkpoint 663892148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,878.80848
Policy Entropy: 1.83241
Value Function Loss: 0.08028

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.67925

Collected Steps per Second: 22,028.77293
Overall Steps per Second: 10,458.14077

Timestep Collection Time: 2.27112
Timestep Consumption Time: 2.51271
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.78383

Cumulative Model Updates: 79,612
Cumulative Timesteps: 663,942,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,643.45999
Policy Entropy: 1.81583
Value Function Loss: 0.07782

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.73454

Collected Steps per Second: 22,873.44982
Overall Steps per Second: 10,640.87327

Timestep Collection Time: 2.18760
Timestep Consumption Time: 2.51483
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.70243

Cumulative Model Updates: 79,618
Cumulative Timesteps: 663,992,216

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 663992216...
Checkpoint 663992216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,313.39162
Policy Entropy: 1.82152
Value Function Loss: 0.07334

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.52179
Value Function Update Magnitude: 0.72257

Collected Steps per Second: 22,517.36828
Overall Steps per Second: 10,573.74873

Timestep Collection Time: 2.22069
Timestep Consumption Time: 2.50838
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.72907

Cumulative Model Updates: 79,624
Cumulative Timesteps: 664,042,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,821.94357
Policy Entropy: 1.80246
Value Function Loss: 0.07831

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.72818

Collected Steps per Second: 22,949.56620
Overall Steps per Second: 10,738.21469

Timestep Collection Time: 2.17939
Timestep Consumption Time: 2.47837
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.65776

Cumulative Model Updates: 79,630
Cumulative Timesteps: 664,092,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 664092236...
Checkpoint 664092236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,807.92231
Policy Entropy: 1.81486
Value Function Loss: 0.07885

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.67723

Collected Steps per Second: 22,408.44566
Overall Steps per Second: 10,654.77952

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.46281
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.69536

Cumulative Model Updates: 79,636
Cumulative Timesteps: 664,142,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,812.64269
Policy Entropy: 1.81643
Value Function Loss: 0.07777

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.66322

Collected Steps per Second: 22,239.38034
Overall Steps per Second: 10,476.87891

Timestep Collection Time: 2.24979
Timestep Consumption Time: 2.52587
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.77566

Cumulative Model Updates: 79,642
Cumulative Timesteps: 664,192,298

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 664192298...
Checkpoint 664192298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,627.65251
Policy Entropy: 1.80433
Value Function Loss: 0.08538

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.54710
Value Function Update Magnitude: 0.65766

Collected Steps per Second: 22,417.69237
Overall Steps per Second: 10,611.39284

Timestep Collection Time: 2.23145
Timestep Consumption Time: 2.48273
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.71418

Cumulative Model Updates: 79,648
Cumulative Timesteps: 664,242,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,666.01092
Policy Entropy: 1.80880
Value Function Loss: 0.08250

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.74736

Collected Steps per Second: 22,358.11144
Overall Steps per Second: 10,627.47104

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70855

Cumulative Model Updates: 79,654
Cumulative Timesteps: 664,292,362

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 664292362...
Checkpoint 664292362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,503.82813
Policy Entropy: 1.79793
Value Function Loss: 0.08493

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.54445
Value Function Update Magnitude: 0.72235

Collected Steps per Second: 22,005.94523
Overall Steps per Second: 10,495.30062

Timestep Collection Time: 2.27248
Timestep Consumption Time: 2.49232
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.76480

Cumulative Model Updates: 79,660
Cumulative Timesteps: 664,342,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,792.27987
Policy Entropy: 1.81306
Value Function Loss: 0.07967

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.72821

Collected Steps per Second: 22,296.38103
Overall Steps per Second: 10,556.15563

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.49495
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.73828

Cumulative Model Updates: 79,666
Cumulative Timesteps: 664,392,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 664392388...
Checkpoint 664392388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,586.83385
Policy Entropy: 1.80930
Value Function Loss: 0.07666

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.72123

Collected Steps per Second: 21,942.70910
Overall Steps per Second: 10,519.21423

Timestep Collection Time: 2.27884
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.75359

Cumulative Model Updates: 79,672
Cumulative Timesteps: 664,442,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,943.09347
Policy Entropy: 1.81983
Value Function Loss: 0.08419

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.68773

Collected Steps per Second: 22,005.12242
Overall Steps per Second: 10,473.33639

Timestep Collection Time: 2.27311
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.77594

Cumulative Model Updates: 79,678
Cumulative Timesteps: 664,492,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 664492412...
Checkpoint 664492412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,360.21303
Policy Entropy: 1.83268
Value Function Loss: 0.09222

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.54680
Value Function Update Magnitude: 0.62689

Collected Steps per Second: 22,221.90535
Overall Steps per Second: 10,705.04854

Timestep Collection Time: 2.25120
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.67312

Cumulative Model Updates: 79,684
Cumulative Timesteps: 664,542,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,408.50886
Policy Entropy: 1.83726
Value Function Loss: 0.09791

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.62730

Collected Steps per Second: 23,021.91658
Overall Steps per Second: 10,810.95922

Timestep Collection Time: 2.17219
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.62568

Cumulative Model Updates: 79,690
Cumulative Timesteps: 664,592,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 664592446...
Checkpoint 664592446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,504.35051
Policy Entropy: 1.83047
Value Function Loss: 0.09687

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.54603
Value Function Update Magnitude: 0.56725

Collected Steps per Second: 22,740.94576
Overall Steps per Second: 10,678.46181

Timestep Collection Time: 2.20008
Timestep Consumption Time: 2.48523
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.68532

Cumulative Model Updates: 79,696
Cumulative Timesteps: 664,642,478

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,508.36844
Policy Entropy: 1.83811
Value Function Loss: 0.09201

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.52430
Value Function Update Magnitude: 0.58078

Collected Steps per Second: 23,063.43657
Overall Steps per Second: 10,863.04894

Timestep Collection Time: 2.16923
Timestep Consumption Time: 2.43629
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60552

Cumulative Model Updates: 79,702
Cumulative Timesteps: 664,692,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 664692508...
Checkpoint 664692508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,822.15456
Policy Entropy: 1.83273
Value Function Loss: 0.08993

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.47907
Value Function Update Magnitude: 0.55993

Collected Steps per Second: 22,405.68916
Overall Steps per Second: 10,745.22493

Timestep Collection Time: 2.23274
Timestep Consumption Time: 2.42291
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.65565

Cumulative Model Updates: 79,708
Cumulative Timesteps: 664,742,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,807.95264
Policy Entropy: 1.84245
Value Function Loss: 0.09137

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.48588
Value Function Update Magnitude: 0.52752

Collected Steps per Second: 22,805.38617
Overall Steps per Second: 10,819.02572

Timestep Collection Time: 2.19360
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.62389

Cumulative Model Updates: 79,714
Cumulative Timesteps: 664,792,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 664792560...
Checkpoint 664792560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,662.45666
Policy Entropy: 1.83640
Value Function Loss: 0.09198

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.49003
Value Function Update Magnitude: 0.46359

Collected Steps per Second: 22,064.52798
Overall Steps per Second: 10,643.49861

Timestep Collection Time: 2.26681
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.69921

Cumulative Model Updates: 79,720
Cumulative Timesteps: 664,842,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,481.11147
Policy Entropy: 1.83081
Value Function Loss: 0.08762

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.50130
Value Function Update Magnitude: 0.50872

Collected Steps per Second: 22,454.69972
Overall Steps per Second: 10,713.98257

Timestep Collection Time: 2.22769
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.66885

Cumulative Model Updates: 79,726
Cumulative Timesteps: 664,892,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 664892598...
Checkpoint 664892598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,477.12240
Policy Entropy: 1.82702
Value Function Loss: 0.08816

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.53841
Value Function Update Magnitude: 0.48605

Collected Steps per Second: 21,626.22163
Overall Steps per Second: 10,413.99081

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.80143

Cumulative Model Updates: 79,732
Cumulative Timesteps: 664,942,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,582.58223
Policy Entropy: 1.83087
Value Function Loss: 0.08610

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.54482
Value Function Update Magnitude: 0.60835

Collected Steps per Second: 22,491.10258
Overall Steps per Second: 10,574.72463

Timestep Collection Time: 2.22337
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.72882

Cumulative Model Updates: 79,738
Cumulative Timesteps: 664,992,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 664992606...
Checkpoint 664992606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,648.75059
Policy Entropy: 1.83200
Value Function Loss: 0.08645

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.54045
Value Function Update Magnitude: 0.62383

Collected Steps per Second: 22,392.08166
Overall Steps per Second: 10,514.08990

Timestep Collection Time: 2.23400
Timestep Consumption Time: 2.52380
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.75781

Cumulative Model Updates: 79,744
Cumulative Timesteps: 665,042,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,345.09904
Policy Entropy: 1.82609
Value Function Loss: 0.07740

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.52905
Value Function Update Magnitude: 0.66749

Collected Steps per Second: 22,646.46555
Overall Steps per Second: 10,586.83157

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.51610
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.72493

Cumulative Model Updates: 79,750
Cumulative Timesteps: 665,092,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 665092652...
Checkpoint 665092652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,125.44124
Policy Entropy: 1.81843
Value Function Loss: 0.07442

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.52578
Value Function Update Magnitude: 0.65401

Collected Steps per Second: 22,262.44253
Overall Steps per Second: 10,487.34476

Timestep Collection Time: 2.24701
Timestep Consumption Time: 2.52293
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.76994

Cumulative Model Updates: 79,756
Cumulative Timesteps: 665,142,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,970.48976
Policy Entropy: 1.82550
Value Function Loss: 0.07863

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.52580
Value Function Update Magnitude: 0.52791

Collected Steps per Second: 22,625.96063
Overall Steps per Second: 10,603.99785

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.71596

Cumulative Model Updates: 79,762
Cumulative Timesteps: 665,192,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 665192684...
Checkpoint 665192684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,610.91676
Policy Entropy: 1.82390
Value Function Loss: 0.07797

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.52697
Value Function Update Magnitude: 0.53030

Collected Steps per Second: 22,773.61086
Overall Steps per Second: 10,682.07654

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.68167

Cumulative Model Updates: 79,768
Cumulative Timesteps: 665,242,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,478.46540
Policy Entropy: 1.84126
Value Function Loss: 0.07832

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.65654

Collected Steps per Second: 22,837.35842
Overall Steps per Second: 10,700.02071

Timestep Collection Time: 2.18966
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.67345

Cumulative Model Updates: 79,774
Cumulative Timesteps: 665,292,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 665292700...
Checkpoint 665292700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,766.27816
Policy Entropy: 1.82524
Value Function Loss: 0.08341

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.52896
Value Function Update Magnitude: 0.70054

Collected Steps per Second: 22,429.91694
Overall Steps per Second: 10,671.09087

Timestep Collection Time: 2.22925
Timestep Consumption Time: 2.45649
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.68574

Cumulative Model Updates: 79,780
Cumulative Timesteps: 665,342,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,122.00372
Policy Entropy: 1.83143
Value Function Loss: 0.08866

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.69846

Collected Steps per Second: 21,656.72941
Overall Steps per Second: 10,409.39941

Timestep Collection Time: 2.30986
Timestep Consumption Time: 2.49580
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.80566

Cumulative Model Updates: 79,786
Cumulative Timesteps: 665,392,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 665392726...
Checkpoint 665392726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,822.72456
Policy Entropy: 1.82578
Value Function Loss: 0.09052

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.60138

Collected Steps per Second: 21,927.49224
Overall Steps per Second: 10,599.26446

Timestep Collection Time: 2.28106
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.71901

Cumulative Model Updates: 79,792
Cumulative Timesteps: 665,442,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,478.20921
Policy Entropy: 1.82144
Value Function Loss: 0.09116

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.50290

Collected Steps per Second: 22,431.83777
Overall Steps per Second: 10,519.46653

Timestep Collection Time: 2.22996
Timestep Consumption Time: 2.52523
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75518

Cumulative Model Updates: 79,798
Cumulative Timesteps: 665,492,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 665492766...
Checkpoint 665492766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,143.86636
Policy Entropy: 1.82736
Value Function Loss: 0.08879

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.55786

Collected Steps per Second: 20,725.76293
Overall Steps per Second: 10,190.22555

Timestep Collection Time: 2.41400
Timestep Consumption Time: 2.49580
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.90980

Cumulative Model Updates: 79,804
Cumulative Timesteps: 665,542,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,207.36659
Policy Entropy: 1.82347
Value Function Loss: 0.08606

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.57990

Collected Steps per Second: 22,963.93693
Overall Steps per Second: 10,653.48131

Timestep Collection Time: 2.17863
Timestep Consumption Time: 2.51748
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.69612

Cumulative Model Updates: 79,810
Cumulative Timesteps: 665,592,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 665592828...
Checkpoint 665592828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,924.55838
Policy Entropy: 1.82686
Value Function Loss: 0.09088

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.53943
Value Function Update Magnitude: 0.45876

Collected Steps per Second: 22,640.50119
Overall Steps per Second: 10,648.87896

Timestep Collection Time: 2.20896
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69646

Cumulative Model Updates: 79,816
Cumulative Timesteps: 665,642,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,180.81486
Policy Entropy: 1.81369
Value Function Loss: 0.08790

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.53803
Value Function Update Magnitude: 0.31956

Collected Steps per Second: 22,875.00736
Overall Steps per Second: 10,731.83378

Timestep Collection Time: 2.18649
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.66053

Cumulative Model Updates: 79,822
Cumulative Timesteps: 665,692,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 665692856...
Checkpoint 665692856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,346.89102
Policy Entropy: 1.81192
Value Function Loss: 0.08947

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.52022
Value Function Update Magnitude: 0.28376

Collected Steps per Second: 22,599.05181
Overall Steps per Second: 10,644.53833

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69875

Cumulative Model Updates: 79,828
Cumulative Timesteps: 665,742,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,262.89918
Policy Entropy: 1.81083
Value Function Loss: 0.08635

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.51516
Value Function Update Magnitude: 0.32952

Collected Steps per Second: 22,684.53528
Overall Steps per Second: 10,675.43440

Timestep Collection Time: 2.20538
Timestep Consumption Time: 2.48089
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.68627

Cumulative Model Updates: 79,834
Cumulative Timesteps: 665,792,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 665792900...
Checkpoint 665792900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,618.37404
Policy Entropy: 1.82176
Value Function Loss: 0.08981

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.49724
Value Function Update Magnitude: 0.48199

Collected Steps per Second: 22,367.31665
Overall Steps per Second: 10,567.73885

Timestep Collection Time: 2.23603
Timestep Consumption Time: 2.49668
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.73271

Cumulative Model Updates: 79,840
Cumulative Timesteps: 665,842,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,645.82955
Policy Entropy: 1.82462
Value Function Loss: 0.09151

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.47794
Value Function Update Magnitude: 0.56868

Collected Steps per Second: 22,381.40774
Overall Steps per Second: 10,696.89970

Timestep Collection Time: 2.23444
Timestep Consumption Time: 2.44074
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.67519

Cumulative Model Updates: 79,846
Cumulative Timesteps: 665,892,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 665892924...
Checkpoint 665892924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,012.93975
Policy Entropy: 1.81275
Value Function Loss: 0.09816

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.15646
Policy Update Magnitude: 0.48676
Value Function Update Magnitude: 0.51107

Collected Steps per Second: 21,716.10096
Overall Steps per Second: 10,579.65740

Timestep Collection Time: 2.30253
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.72624

Cumulative Model Updates: 79,852
Cumulative Timesteps: 665,942,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,640.57424
Policy Entropy: 1.81235
Value Function Loss: 0.09536

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.52551
Value Function Update Magnitude: 0.43608

Collected Steps per Second: 22,074.66051
Overall Steps per Second: 10,597.52030

Timestep Collection Time: 2.26522
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.71846

Cumulative Model Updates: 79,858
Cumulative Timesteps: 665,992,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 665992930...
Checkpoint 665992930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,560.31214
Policy Entropy: 1.82911
Value Function Loss: 0.09312

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.16224
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.43055

Collected Steps per Second: 22,119.71570
Overall Steps per Second: 10,557.02461

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.73637

Cumulative Model Updates: 79,864
Cumulative Timesteps: 666,042,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,020.46053
Policy Entropy: 1.85081
Value Function Loss: 0.09091

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16170
Policy Update Magnitude: 0.52637
Value Function Update Magnitude: 0.41871

Collected Steps per Second: 22,593.69412
Overall Steps per Second: 10,434.38705

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.58008
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.79415

Cumulative Model Updates: 79,870
Cumulative Timesteps: 666,092,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 666092956...
Checkpoint 666092956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,824.67401
Policy Entropy: 1.85981
Value Function Loss: 0.09413

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.18354
Policy Update Magnitude: 0.52002
Value Function Update Magnitude: 0.40197

Collected Steps per Second: 22,560.92722
Overall Steps per Second: 10,707.16601

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.45522
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.67295

Cumulative Model Updates: 79,876
Cumulative Timesteps: 666,142,990

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,797.65505
Policy Entropy: 1.84231
Value Function Loss: 0.09507

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.16810
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.41970

Collected Steps per Second: 23,012.24416
Overall Steps per Second: 10,886.22621

Timestep Collection Time: 2.17389
Timestep Consumption Time: 2.42146
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.59535

Cumulative Model Updates: 79,882
Cumulative Timesteps: 666,193,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 666193016...
Checkpoint 666193016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,744.13148
Policy Entropy: 1.85201
Value Function Loss: 0.09000

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.15212
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.39511

Collected Steps per Second: 22,598.25749
Overall Steps per Second: 10,651.06855

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.69643

Cumulative Model Updates: 79,888
Cumulative Timesteps: 666,243,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,837.04044
Policy Entropy: 1.83746
Value Function Loss: 0.09335

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.37256

Collected Steps per Second: 22,998.70367
Overall Steps per Second: 10,841.02849

Timestep Collection Time: 2.17421
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61248

Cumulative Model Updates: 79,894
Cumulative Timesteps: 666,293,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 666293042...
Checkpoint 666293042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,405.27231
Policy Entropy: 1.83784
Value Function Loss: 0.10149

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.53427
Value Function Update Magnitude: 0.40270

Collected Steps per Second: 21,827.75693
Overall Steps per Second: 10,653.38322

Timestep Collection Time: 2.29139
Timestep Consumption Time: 2.40345
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.69485

Cumulative Model Updates: 79,900
Cumulative Timesteps: 666,343,058

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,362.05035
Policy Entropy: 1.84405
Value Function Loss: 0.10720

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.43519

Collected Steps per Second: 22,781.06015
Overall Steps per Second: 10,670.72059

Timestep Collection Time: 2.19674
Timestep Consumption Time: 2.49311
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.68984

Cumulative Model Updates: 79,906
Cumulative Timesteps: 666,393,102

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 666393102...
Checkpoint 666393102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,338.25753
Policy Entropy: 1.85317
Value Function Loss: 0.10275

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.47742

Collected Steps per Second: 22,253.84256
Overall Steps per Second: 10,568.01630

Timestep Collection Time: 2.24806
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.73391

Cumulative Model Updates: 79,912
Cumulative Timesteps: 666,443,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,179.37768
Policy Entropy: 1.84224
Value Function Loss: 0.09492

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.41949

Collected Steps per Second: 22,444.65664
Overall Steps per Second: 10,749.61421

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.42469
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.65338

Cumulative Model Updates: 79,918
Cumulative Timesteps: 666,493,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 666493152...
Checkpoint 666493152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,062.16063
Policy Entropy: 1.84643
Value Function Loss: 0.09189

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.39461

Collected Steps per Second: 22,115.06246
Overall Steps per Second: 10,654.25228

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.43206
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.69296

Cumulative Model Updates: 79,924
Cumulative Timesteps: 666,543,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,622.03919
Policy Entropy: 1.84698
Value Function Loss: 0.09953

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.16328
Policy Update Magnitude: 0.49812
Value Function Update Magnitude: 0.38958

Collected Steps per Second: 22,577.95855
Overall Steps per Second: 10,555.41682

Timestep Collection Time: 2.21552
Timestep Consumption Time: 2.52346
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.73899

Cumulative Model Updates: 79,930
Cumulative Timesteps: 666,593,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 666593174...
Checkpoint 666593174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,838.00956
Policy Entropy: 1.86025
Value Function Loss: 0.10041

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.53207
Value Function Update Magnitude: 0.42803

Collected Steps per Second: 22,599.97515
Overall Steps per Second: 10,564.53302

Timestep Collection Time: 2.21266
Timestep Consumption Time: 2.52073
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.73338

Cumulative Model Updates: 79,936
Cumulative Timesteps: 666,643,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,873.33019
Policy Entropy: 1.85292
Value Function Loss: 0.09237

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.57243

Collected Steps per Second: 22,904.98540
Overall Steps per Second: 10,678.96880

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.68229

Cumulative Model Updates: 79,942
Cumulative Timesteps: 666,693,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 666693182...
Checkpoint 666693182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,786.19385
Policy Entropy: 1.85405
Value Function Loss: 0.08578

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.53430
Value Function Update Magnitude: 0.68457

Collected Steps per Second: 22,627.46707
Overall Steps per Second: 10,663.68536

Timestep Collection Time: 2.21121
Timestep Consumption Time: 2.48079
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.69200

Cumulative Model Updates: 79,948
Cumulative Timesteps: 666,743,216

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,782.12753
Policy Entropy: 1.84790
Value Function Loss: 0.09126

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.16730
Policy Update Magnitude: 0.48673
Value Function Update Magnitude: 0.68459

Collected Steps per Second: 22,758.56729
Overall Steps per Second: 10,654.11391

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.49725
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.69528

Cumulative Model Updates: 79,954
Cumulative Timesteps: 666,793,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 666793240...
Checkpoint 666793240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,625.11791
Policy Entropy: 1.86031
Value Function Loss: 0.09147

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.51352
Value Function Update Magnitude: 0.66533

Collected Steps per Second: 22,329.31780
Overall Steps per Second: 10,620.93533

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.46966
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.70994

Cumulative Model Updates: 79,960
Cumulative Timesteps: 666,843,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,899.91154
Policy Entropy: 1.85178
Value Function Loss: 0.09963

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.50496
Value Function Update Magnitude: 0.61365

Collected Steps per Second: 22,892.99737
Overall Steps per Second: 10,697.80972

Timestep Collection Time: 2.18451
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.67479

Cumulative Model Updates: 79,966
Cumulative Timesteps: 666,893,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 666893274...
Checkpoint 666893274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,901.00310
Policy Entropy: 1.84495
Value Function Loss: 0.09966

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.55068
Value Function Update Magnitude: 0.70745

Collected Steps per Second: 22,575.17564
Overall Steps per Second: 10,818.13339

Timestep Collection Time: 2.21597
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.62427

Cumulative Model Updates: 79,972
Cumulative Timesteps: 666,943,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,478.76445
Policy Entropy: 1.84016
Value Function Loss: 0.09984

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.57935
Value Function Update Magnitude: 0.71175

Collected Steps per Second: 22,286.23050
Overall Steps per Second: 10,508.50457

Timestep Collection Time: 2.24381
Timestep Consumption Time: 2.51481
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.75862

Cumulative Model Updates: 79,978
Cumulative Timesteps: 666,993,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 666993306...
Checkpoint 666993306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,682.10722
Policy Entropy: 1.84373
Value Function Loss: 0.09976

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.58512
Value Function Update Magnitude: 0.74146

Collected Steps per Second: 21,848.77722
Overall Steps per Second: 10,579.12819

Timestep Collection Time: 2.28992
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72931

Cumulative Model Updates: 79,984
Cumulative Timesteps: 667,043,338

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,498.13743
Policy Entropy: 1.86155
Value Function Loss: 0.09322

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.57736
Value Function Update Magnitude: 0.78765

Collected Steps per Second: 21,903.89669
Overall Steps per Second: 10,520.41823

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.47046
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.75361

Cumulative Model Updates: 79,990
Cumulative Timesteps: 667,093,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 667093348...
Checkpoint 667093348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,560.45366
Policy Entropy: 1.86091
Value Function Loss: 0.09688

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.57003
Value Function Update Magnitude: 0.78712

Collected Steps per Second: 22,262.29447
Overall Steps per Second: 10,659.90585

Timestep Collection Time: 2.24811
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.69498

Cumulative Model Updates: 79,996
Cumulative Timesteps: 667,143,396

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,095.07513
Policy Entropy: 1.86576
Value Function Loss: 0.09125

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.55716
Value Function Update Magnitude: 0.78712

Collected Steps per Second: 22,541.22656
Overall Steps per Second: 10,464.77168

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.56090
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.78004

Cumulative Model Updates: 80,002
Cumulative Timesteps: 667,193,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 667193418...
Checkpoint 667193418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,986.74763
Policy Entropy: 1.86647
Value Function Loss: 0.09010

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.52023
Value Function Update Magnitude: 0.74848

Collected Steps per Second: 22,638.89603
Overall Steps per Second: 10,568.21843

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.52429
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73438

Cumulative Model Updates: 80,008
Cumulative Timesteps: 667,243,452

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,889.61174
Policy Entropy: 1.88045
Value Function Loss: 0.08912

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.49690
Value Function Update Magnitude: 0.72295

Collected Steps per Second: 22,922.38502
Overall Steps per Second: 10,881.74485

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.41435
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.59632

Cumulative Model Updates: 80,014
Cumulative Timesteps: 667,293,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 667293468...
Checkpoint 667293468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,166.47687
Policy Entropy: 1.87470
Value Function Loss: 0.08458

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15442
Policy Update Magnitude: 0.48758
Value Function Update Magnitude: 0.71577

Collected Steps per Second: 22,609.48562
Overall Steps per Second: 10,725.78023

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.45089
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.66297

Cumulative Model Updates: 80,020
Cumulative Timesteps: 667,343,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,800.75001
Policy Entropy: 1.88073
Value Function Loss: 0.08529

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.51395
Value Function Update Magnitude: 0.75893

Collected Steps per Second: 22,489.00848
Overall Steps per Second: 10,650.80114

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69486

Cumulative Model Updates: 80,026
Cumulative Timesteps: 667,393,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 667393486...
Checkpoint 667393486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,884.76845
Policy Entropy: 1.86387
Value Function Loss: 0.08336

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.72876

Collected Steps per Second: 22,204.83655
Overall Steps per Second: 10,390.96429

Timestep Collection Time: 2.25230
Timestep Consumption Time: 2.56073
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.81303

Cumulative Model Updates: 80,032
Cumulative Timesteps: 667,443,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,546.44217
Policy Entropy: 1.86467
Value Function Loss: 0.09039

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15702
Policy Update Magnitude: 0.50465
Value Function Update Magnitude: 0.58889

Collected Steps per Second: 22,331.74009
Overall Steps per Second: 10,498.53012

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.52482
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.76486

Cumulative Model Updates: 80,038
Cumulative Timesteps: 667,493,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 667493522...
Checkpoint 667493522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,221.74845
Policy Entropy: 1.86016
Value Function Loss: 0.08962

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14708
Policy Update Magnitude: 0.52365
Value Function Update Magnitude: 0.46341

Collected Steps per Second: 22,169.13984
Overall Steps per Second: 10,682.99945

Timestep Collection Time: 2.25620
Timestep Consumption Time: 2.42582
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.68202

Cumulative Model Updates: 80,044
Cumulative Timesteps: 667,543,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,832.45542
Policy Entropy: 1.87721
Value Function Loss: 0.09083

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.49964

Collected Steps per Second: 22,365.84229
Overall Steps per Second: 10,565.41110

Timestep Collection Time: 2.23618
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.73375

Cumulative Model Updates: 80,050
Cumulative Timesteps: 667,593,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 667593554...
Checkpoint 667593554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,059.29514
Policy Entropy: 1.86658
Value Function Loss: 0.07966

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.53399
Value Function Update Magnitude: 0.54858

Collected Steps per Second: 22,181.97567
Overall Steps per Second: 10,459.22489

Timestep Collection Time: 2.25471
Timestep Consumption Time: 2.52709
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.78181

Cumulative Model Updates: 80,056
Cumulative Timesteps: 667,643,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,086.32864
Policy Entropy: 1.86439
Value Function Loss: 0.08655

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.54072
Value Function Update Magnitude: 0.48843

Collected Steps per Second: 22,527.19216
Overall Steps per Second: 10,502.90255

Timestep Collection Time: 2.21963
Timestep Consumption Time: 2.54115
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.76078

Cumulative Model Updates: 80,062
Cumulative Timesteps: 667,693,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 667693570...
Checkpoint 667693570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,427.46937
Policy Entropy: 1.84325
Value Function Loss: 0.09542

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.41556

Collected Steps per Second: 22,537.82180
Overall Steps per Second: 10,594.39445

Timestep Collection Time: 2.21982
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.72231

Cumulative Model Updates: 80,068
Cumulative Timesteps: 667,743,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,580.16433
Policy Entropy: 1.85750
Value Function Loss: 0.09759

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.54957
Value Function Update Magnitude: 0.49015

Collected Steps per Second: 22,750.91604
Overall Steps per Second: 10,811.24447

Timestep Collection Time: 2.19868
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62685

Cumulative Model Updates: 80,074
Cumulative Timesteps: 667,793,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 667793622...
Checkpoint 667793622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,532.91461
Policy Entropy: 1.86347
Value Function Loss: 0.10169

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.44452

Collected Steps per Second: 21,955.00523
Overall Steps per Second: 10,642.52590

Timestep Collection Time: 2.27775
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.69888

Cumulative Model Updates: 80,080
Cumulative Timesteps: 667,843,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,655.36322
Policy Entropy: 1.87360
Value Function Loss: 0.09579

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.54603
Value Function Update Magnitude: 0.39415

Collected Steps per Second: 22,653.45419
Overall Steps per Second: 10,562.03753

Timestep Collection Time: 2.20796
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73564

Cumulative Model Updates: 80,086
Cumulative Timesteps: 667,893,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 667893648...
Checkpoint 667893648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,392.54899
Policy Entropy: 1.85856
Value Function Loss: 0.08921

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.47236

Collected Steps per Second: 22,527.40834
Overall Steps per Second: 10,685.74751

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.67932

Cumulative Model Updates: 80,092
Cumulative Timesteps: 667,943,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,820.93802
Policy Entropy: 1.85449
Value Function Loss: 0.08828

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.51025

Collected Steps per Second: 22,238.79251
Overall Steps per Second: 10,512.74494

Timestep Collection Time: 2.25021
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.76013

Cumulative Model Updates: 80,098
Cumulative Timesteps: 667,993,692

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 667993692...
Checkpoint 667993692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,963.42813
Policy Entropy: 1.85200
Value Function Loss: 0.08718

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.51742

Collected Steps per Second: 21,998.92604
Overall Steps per Second: 10,553.25435

Timestep Collection Time: 2.27402
Timestep Consumption Time: 2.46632
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.74034

Cumulative Model Updates: 80,104
Cumulative Timesteps: 668,043,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,379.13446
Policy Entropy: 1.86210
Value Function Loss: 0.09349

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.64124

Collected Steps per Second: 22,130.87833
Overall Steps per Second: 10,464.71348

Timestep Collection Time: 2.26037
Timestep Consumption Time: 2.51988
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.78026

Cumulative Model Updates: 80,110
Cumulative Timesteps: 668,093,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 668093742...
Checkpoint 668093742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,928.53386
Policy Entropy: 1.86438
Value Function Loss: 0.08229

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.54673
Value Function Update Magnitude: 0.59147

Collected Steps per Second: 22,096.60943
Overall Steps per Second: 10,620.61820

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.70952

Cumulative Model Updates: 80,116
Cumulative Timesteps: 668,143,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,035.61989
Policy Entropy: 1.87785
Value Function Loss: 0.07944

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.53344

Collected Steps per Second: 22,833.22051
Overall Steps per Second: 10,629.13355

Timestep Collection Time: 2.19023
Timestep Consumption Time: 2.51476
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.70499

Cumulative Model Updates: 80,122
Cumulative Timesteps: 668,193,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 668193770...
Checkpoint 668193770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,763.99579
Policy Entropy: 1.86636
Value Function Loss: 0.08382

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.55389

Collected Steps per Second: 22,455.65419
Overall Steps per Second: 10,583.65715

Timestep Collection Time: 2.22812
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.72748

Cumulative Model Updates: 80,128
Cumulative Timesteps: 668,243,804

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,278.40092
Policy Entropy: 1.87470
Value Function Loss: 0.08928

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.50218
Value Function Update Magnitude: 0.57918

Collected Steps per Second: 23,341.00791
Overall Steps per Second: 10,818.99025

Timestep Collection Time: 2.14318
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.62372

Cumulative Model Updates: 80,134
Cumulative Timesteps: 668,293,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 668293828...
Checkpoint 668293828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,322.32218
Policy Entropy: 1.87019
Value Function Loss: 0.08947

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.51985
Value Function Update Magnitude: 0.56741

Collected Steps per Second: 22,205.96116
Overall Steps per Second: 10,705.40562

Timestep Collection Time: 2.25228
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.67185

Cumulative Model Updates: 80,140
Cumulative Timesteps: 668,343,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,633.95481
Policy Entropy: 1.88130
Value Function Loss: 0.08490

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.53168
Value Function Update Magnitude: 0.60598

Collected Steps per Second: 22,982.95991
Overall Steps per Second: 10,840.82173

Timestep Collection Time: 2.17622
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.61367

Cumulative Model Updates: 80,146
Cumulative Timesteps: 668,393,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 668393858...
Checkpoint 668393858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,477.20693
Policy Entropy: 1.88973
Value Function Loss: 0.08322

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.49179

Collected Steps per Second: 20,588.79610
Overall Steps per Second: 10,321.75496

Timestep Collection Time: 2.42928
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.84569

Cumulative Model Updates: 80,152
Cumulative Timesteps: 668,443,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,851.78826
Policy Entropy: 1.90334
Value Function Loss: 0.08680

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.49961

Collected Steps per Second: 21,624.59596
Overall Steps per Second: 10,715.58963

Timestep Collection Time: 2.31385
Timestep Consumption Time: 2.35561
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.66946

Cumulative Model Updates: 80,158
Cumulative Timesteps: 668,493,910

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 668493910...
Checkpoint 668493910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,293.95070
Policy Entropy: 1.89401
Value Function Loss: 0.09007

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.53580
Value Function Update Magnitude: 0.51469

Collected Steps per Second: 21,192.50775
Overall Steps per Second: 10,638.29719

Timestep Collection Time: 2.36027
Timestep Consumption Time: 2.34161
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.70188

Cumulative Model Updates: 80,164
Cumulative Timesteps: 668,543,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,508.66266
Policy Entropy: 1.90580
Value Function Loss: 0.09197

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.47319

Collected Steps per Second: 21,717.10080
Overall Steps per Second: 10,528.03515

Timestep Collection Time: 2.30371
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.75207

Cumulative Model Updates: 80,170
Cumulative Timesteps: 668,593,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 668593960...
Checkpoint 668593960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,358.81330
Policy Entropy: 1.90422
Value Function Loss: 0.09061

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.54864
Value Function Update Magnitude: 0.51620

Collected Steps per Second: 21,297.67714
Overall Steps per Second: 10,601.59954

Timestep Collection Time: 2.34814
Timestep Consumption Time: 2.36907
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.71721

Cumulative Model Updates: 80,176
Cumulative Timesteps: 668,643,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,646.90464
Policy Entropy: 1.89736
Value Function Loss: 0.08613

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.64233

Collected Steps per Second: 22,067.62396
Overall Steps per Second: 10,596.67944

Timestep Collection Time: 2.26685
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.72072

Cumulative Model Updates: 80,182
Cumulative Timesteps: 668,693,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 668693994...
Checkpoint 668693994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,407.86462
Policy Entropy: 1.89594
Value Function Loss: 0.08392

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.54311
Value Function Update Magnitude: 0.71817

Collected Steps per Second: 22,166.75976
Overall Steps per Second: 10,719.93383

Timestep Collection Time: 2.25590
Timestep Consumption Time: 2.40887
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.66477

Cumulative Model Updates: 80,188
Cumulative Timesteps: 668,744,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,477.00033
Policy Entropy: 1.90067
Value Function Loss: 0.07720

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.74403

Collected Steps per Second: 22,543.11267
Overall Steps per Second: 10,647.32581

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.69677

Cumulative Model Updates: 80,194
Cumulative Timesteps: 668,794,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 668794008...
Checkpoint 668794008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.94397
Policy Entropy: 1.89578
Value Function Loss: 0.08094

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.54375
Value Function Update Magnitude: 0.65663

Collected Steps per Second: 22,360.32685
Overall Steps per Second: 10,674.86444

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.44897
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.68615

Cumulative Model Updates: 80,200
Cumulative Timesteps: 668,844,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,668.93590
Policy Entropy: 1.88503
Value Function Loss: 0.08360

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.54624
Value Function Update Magnitude: 0.65625

Collected Steps per Second: 22,557.56015
Overall Steps per Second: 10,695.76069

Timestep Collection Time: 2.21673
Timestep Consumption Time: 2.45839
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.67512

Cumulative Model Updates: 80,206
Cumulative Timesteps: 668,894,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 668894036...
Checkpoint 668894036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,496.82077
Policy Entropy: 1.86551
Value Function Loss: 0.08273

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.55230
Value Function Update Magnitude: 0.75779

Collected Steps per Second: 22,443.13820
Overall Steps per Second: 10,801.23722

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.40240
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63132

Cumulative Model Updates: 80,212
Cumulative Timesteps: 668,944,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,123.45182
Policy Entropy: 1.87735
Value Function Loss: 0.07735

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.78020

Collected Steps per Second: 22,097.09645
Overall Steps per Second: 10,529.49756

Timestep Collection Time: 2.26346
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.75008

Cumulative Model Updates: 80,218
Cumulative Timesteps: 668,994,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 668994076...
Checkpoint 668994076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,972.82716
Policy Entropy: 1.86927
Value Function Loss: 0.08347

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.51380
Value Function Update Magnitude: 0.74970

Collected Steps per Second: 20,434.85285
Overall Steps per Second: 10,167.22978

Timestep Collection Time: 2.44680
Timestep Consumption Time: 2.47096
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.91776

Cumulative Model Updates: 80,224
Cumulative Timesteps: 669,044,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,003.90881
Policy Entropy: 1.87962
Value Function Loss: 0.08408

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.54358
Value Function Update Magnitude: 0.74055

Collected Steps per Second: 22,207.19429
Overall Steps per Second: 10,505.12989

Timestep Collection Time: 2.25269
Timestep Consumption Time: 2.50936
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.76205

Cumulative Model Updates: 80,230
Cumulative Timesteps: 669,094,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 669094102...
Checkpoint 669094102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,502.42634
Policy Entropy: 1.86788
Value Function Loss: 0.08838

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.56169
Value Function Update Magnitude: 0.71473

Collected Steps per Second: 22,230.27291
Overall Steps per Second: 10,682.45006

Timestep Collection Time: 2.24964
Timestep Consumption Time: 2.43188
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.68151

Cumulative Model Updates: 80,236
Cumulative Timesteps: 669,144,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,574.28750
Policy Entropy: 1.88157
Value Function Loss: 0.08356

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.75032

Collected Steps per Second: 23,133.47100
Overall Steps per Second: 10,803.96279

Timestep Collection Time: 2.16275
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.63089

Cumulative Model Updates: 80,242
Cumulative Timesteps: 669,194,144

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 669194144...
Checkpoint 669194144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,879.71058
Policy Entropy: 1.87678
Value Function Loss: 0.08076

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.53692
Value Function Update Magnitude: 0.67299

Collected Steps per Second: 21,895.07034
Overall Steps per Second: 10,582.15004

Timestep Collection Time: 2.28472
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.72721

Cumulative Model Updates: 80,248
Cumulative Timesteps: 669,244,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,497.87859
Policy Entropy: 1.87916
Value Function Loss: 0.07535

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.51612
Value Function Update Magnitude: 0.66278

Collected Steps per Second: 22,796.58631
Overall Steps per Second: 10,666.89478

Timestep Collection Time: 2.19454
Timestep Consumption Time: 2.49549
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.69002

Cumulative Model Updates: 80,254
Cumulative Timesteps: 669,294,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 669294196...
Checkpoint 669294196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,635.47313
Policy Entropy: 1.87516
Value Function Loss: 0.08296

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.52177
Value Function Update Magnitude: 0.62938

Collected Steps per Second: 21,757.87476
Overall Steps per Second: 10,493.24483

Timestep Collection Time: 2.29820
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.76535

Cumulative Model Updates: 80,260
Cumulative Timesteps: 669,344,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,342.43735
Policy Entropy: 1.85930
Value Function Loss: 0.08768

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.14947
Policy Update Magnitude: 0.54466
Value Function Update Magnitude: 0.60689

Collected Steps per Second: 23,071.03535
Overall Steps per Second: 10,857.05883

Timestep Collection Time: 2.16722
Timestep Consumption Time: 2.43808
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60530

Cumulative Model Updates: 80,266
Cumulative Timesteps: 669,394,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 669394200...
Checkpoint 669394200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,474.01180
Policy Entropy: 1.85854
Value Function Loss: 0.09380

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.17176
Policy Update Magnitude: 0.54385
Value Function Update Magnitude: 0.55778

Collected Steps per Second: 22,078.76679
Overall Steps per Second: 10,627.60380

Timestep Collection Time: 2.26543
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.70642

Cumulative Model Updates: 80,272
Cumulative Timesteps: 669,444,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,806.32132
Policy Entropy: 1.86095
Value Function Loss: 0.08312

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.52110
Value Function Update Magnitude: 0.68104

Collected Steps per Second: 22,239.76909
Overall Steps per Second: 10,558.08966

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.48857
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.73779

Cumulative Model Updates: 80,278
Cumulative Timesteps: 669,494,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 669494240...
Checkpoint 669494240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,359.01296
Policy Entropy: 1.86504
Value Function Loss: 0.08442

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.16602
Policy Update Magnitude: 0.51182
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 22,091.11758
Overall Steps per Second: 10,663.68510

Timestep Collection Time: 2.26435
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.69087

Cumulative Model Updates: 80,284
Cumulative Timesteps: 669,544,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,908.54754
Policy Entropy: 1.84800
Value Function Loss: 0.08112

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.60188

Collected Steps per Second: 22,412.55899
Overall Steps per Second: 10,569.84902

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.73327

Cumulative Model Updates: 80,290
Cumulative Timesteps: 669,594,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 669594292...
Checkpoint 669594292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,960.61265
Policy Entropy: 1.83802
Value Function Loss: 0.08016

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.58725

Collected Steps per Second: 21,465.37160
Overall Steps per Second: 10,454.04727

Timestep Collection Time: 2.33064
Timestep Consumption Time: 2.45488
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.78552

Cumulative Model Updates: 80,296
Cumulative Timesteps: 669,644,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,495.36578
Policy Entropy: 1.83784
Value Function Loss: 0.08144

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.53966
Value Function Update Magnitude: 0.61319

Collected Steps per Second: 22,588.74560
Overall Steps per Second: 10,515.50407

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.54149
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.75507

Cumulative Model Updates: 80,302
Cumulative Timesteps: 669,694,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 669694322...
Checkpoint 669694322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,624.18120
Policy Entropy: 1.85818
Value Function Loss: 0.08146

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.53356
Value Function Update Magnitude: 0.61501

Collected Steps per Second: 22,455.75888
Overall Steps per Second: 10,672.79810

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.45909
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.68649

Cumulative Model Updates: 80,308
Cumulative Timesteps: 669,744,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,543.99004
Policy Entropy: 1.86346
Value Function Loss: 0.08105

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.53314
Value Function Update Magnitude: 0.59833

Collected Steps per Second: 22,890.16369
Overall Steps per Second: 10,796.92929

Timestep Collection Time: 2.18522
Timestep Consumption Time: 2.44758
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.63280

Cumulative Model Updates: 80,314
Cumulative Timesteps: 669,794,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 669794360...
Checkpoint 669794360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,964.79154
Policy Entropy: 1.86448
Value Function Loss: 0.07817

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.58771

Collected Steps per Second: 22,037.89552
Overall Steps per Second: 10,619.40071

Timestep Collection Time: 2.26955
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.70987

Cumulative Model Updates: 80,320
Cumulative Timesteps: 669,844,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,045.68811
Policy Entropy: 1.88627
Value Function Loss: 0.07628

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.70647

Collected Steps per Second: 22,872.87497
Overall Steps per Second: 10,663.41719

Timestep Collection Time: 2.18748
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.69212

Cumulative Model Updates: 80,326
Cumulative Timesteps: 669,894,410

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 669894410...
Checkpoint 669894410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,039.93839
Policy Entropy: 1.88558
Value Function Loss: 0.07577

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.67352

Collected Steps per Second: 22,472.65006
Overall Steps per Second: 10,558.80401

Timestep Collection Time: 2.22608
Timestep Consumption Time: 2.51176
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.73785

Cumulative Model Updates: 80,332
Cumulative Timesteps: 669,944,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,559.14387
Policy Entropy: 1.87045
Value Function Loss: 0.08393

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.53441
Value Function Update Magnitude: 0.52494

Collected Steps per Second: 23,022.09920
Overall Steps per Second: 10,845.36649

Timestep Collection Time: 2.17304
Timestep Consumption Time: 2.43980
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.61285

Cumulative Model Updates: 80,338
Cumulative Timesteps: 669,994,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 669994464...
Checkpoint 669994464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,628.63684
Policy Entropy: 1.85391
Value Function Loss: 0.08605

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.54196
Value Function Update Magnitude: 0.47881

Collected Steps per Second: 21,543.16357
Overall Steps per Second: 10,385.64304

Timestep Collection Time: 2.32194
Timestep Consumption Time: 2.49451
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.81646

Cumulative Model Updates: 80,344
Cumulative Timesteps: 670,044,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,439.66427
Policy Entropy: 1.86217
Value Function Loss: 0.08724

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.57653

Collected Steps per Second: 22,683.66677
Overall Steps per Second: 10,808.51142

Timestep Collection Time: 2.20643
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.63061

Cumulative Model Updates: 80,350
Cumulative Timesteps: 670,094,536

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 670094536...
Checkpoint 670094536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,138.15137
Policy Entropy: 1.87122
Value Function Loss: 0.08695

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.52628
Value Function Update Magnitude: 0.71799

Collected Steps per Second: 22,000.15842
Overall Steps per Second: 10,651.14248

Timestep Collection Time: 2.27371
Timestep Consumption Time: 2.42269
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.69640

Cumulative Model Updates: 80,356
Cumulative Timesteps: 670,144,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,851.71506
Policy Entropy: 1.86953
Value Function Loss: 0.08289

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.54148
Value Function Update Magnitude: 0.75973

Collected Steps per Second: 22,098.58826
Overall Steps per Second: 10,462.34088

Timestep Collection Time: 2.26331
Timestep Consumption Time: 2.51726
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.78057

Cumulative Model Updates: 80,362
Cumulative Timesteps: 670,194,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 670194574...
Checkpoint 670194574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,411.96970
Policy Entropy: 1.86184
Value Function Loss: 0.08160

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.75384

Collected Steps per Second: 21,734.80839
Overall Steps per Second: 10,492.07262

Timestep Collection Time: 2.30064
Timestep Consumption Time: 2.46524
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.76588

Cumulative Model Updates: 80,368
Cumulative Timesteps: 670,244,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,893.54678
Policy Entropy: 1.86060
Value Function Loss: 0.07633

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.53290
Value Function Update Magnitude: 0.72763

Collected Steps per Second: 22,602.09385
Overall Steps per Second: 10,517.87913

Timestep Collection Time: 2.21236
Timestep Consumption Time: 2.54183
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.75419

Cumulative Model Updates: 80,374
Cumulative Timesteps: 670,294,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 670294582...
Checkpoint 670294582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,525.58539
Policy Entropy: 1.86245
Value Function Loss: 0.07920

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.53457
Value Function Update Magnitude: 0.71457

Collected Steps per Second: 22,574.15515
Overall Steps per Second: 10,634.69321

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.70253

Cumulative Model Updates: 80,380
Cumulative Timesteps: 670,344,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,797.05157
Policy Entropy: 1.87408
Value Function Loss: 0.07604

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.67256

Collected Steps per Second: 22,755.18743
Overall Steps per Second: 10,656.16092

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.69381

Cumulative Model Updates: 80,386
Cumulative Timesteps: 670,394,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 670394610...
Checkpoint 670394610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,384.52426
Policy Entropy: 1.88219
Value Function Loss: 0.07949

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.66852

Collected Steps per Second: 22,652.59372
Overall Steps per Second: 10,779.83850

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.63940

Cumulative Model Updates: 80,392
Cumulative Timesteps: 670,444,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,476.44528
Policy Entropy: 1.89466
Value Function Loss: 0.09039

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.54390
Value Function Update Magnitude: 0.70399

Collected Steps per Second: 22,720.60636
Overall Steps per Second: 10,622.36919

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.70855

Cumulative Model Updates: 80,398
Cumulative Timesteps: 670,494,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 670494638...
Checkpoint 670494638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,634.95782
Policy Entropy: 1.89139
Value Function Loss: 0.09546

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.65778

Collected Steps per Second: 22,460.77156
Overall Steps per Second: 10,592.36069

Timestep Collection Time: 2.22690
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.72208

Cumulative Model Updates: 80,404
Cumulative Timesteps: 670,544,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,054.12784
Policy Entropy: 1.90441
Value Function Loss: 0.09879

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.61659

Collected Steps per Second: 22,524.24708
Overall Steps per Second: 10,628.76110

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.48478
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.70497

Cumulative Model Updates: 80,410
Cumulative Timesteps: 670,594,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 670594664...
Checkpoint 670594664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,521.56155
Policy Entropy: 1.92009
Value Function Loss: 0.09782

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.66979

Collected Steps per Second: 21,826.33572
Overall Steps per Second: 10,436.46680

Timestep Collection Time: 2.29182
Timestep Consumption Time: 2.50118
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.79300

Cumulative Model Updates: 80,416
Cumulative Timesteps: 670,644,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,812.80880
Policy Entropy: 1.92105
Value Function Loss: 0.08459

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.78099

Collected Steps per Second: 21,955.77363
Overall Steps per Second: 10,644.01620

Timestep Collection Time: 2.27749
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.69785

Cumulative Model Updates: 80,422
Cumulative Timesteps: 670,694,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 670694690...
Checkpoint 670694690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,379.32385
Policy Entropy: 1.91109
Value Function Loss: 0.07514

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.79172

Collected Steps per Second: 21,326.97119
Overall Steps per Second: 10,468.74226

Timestep Collection Time: 2.34604
Timestep Consumption Time: 2.43333
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.77937

Cumulative Model Updates: 80,428
Cumulative Timesteps: 670,744,724

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,263.44376
Policy Entropy: 1.90201
Value Function Loss: 0.08078

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.53227
Value Function Update Magnitude: 0.83175

Collected Steps per Second: 21,670.88690
Overall Steps per Second: 10,507.26699

Timestep Collection Time: 2.30817
Timestep Consumption Time: 2.45235
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.76051

Cumulative Model Updates: 80,434
Cumulative Timesteps: 670,794,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 670794744...
Checkpoint 670794744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,944.08959
Policy Entropy: 1.89723
Value Function Loss: 0.08394

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.85750

Collected Steps per Second: 21,951.99615
Overall Steps per Second: 10,531.97489

Timestep Collection Time: 2.27779
Timestep Consumption Time: 2.46985
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.74764

Cumulative Model Updates: 80,440
Cumulative Timesteps: 670,844,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,262.79723
Policy Entropy: 1.89117
Value Function Loss: 0.09065

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.75504

Collected Steps per Second: 22,072.37922
Overall Steps per Second: 10,711.17695

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.40275
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.66802

Cumulative Model Updates: 80,446
Cumulative Timesteps: 670,894,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 670894746...
Checkpoint 670894746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,620.46560
Policy Entropy: 1.86860
Value Function Loss: 0.09009

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.68583

Collected Steps per Second: 22,010.40580
Overall Steps per Second: 10,813.95759

Timestep Collection Time: 2.27193
Timestep Consumption Time: 2.35228
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.62421

Cumulative Model Updates: 80,452
Cumulative Timesteps: 670,944,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,870.47268
Policy Entropy: 1.86462
Value Function Loss: 0.08972

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.53890
Value Function Update Magnitude: 0.65993

Collected Steps per Second: 22,121.20652
Overall Steps per Second: 10,716.14857

Timestep Collection Time: 2.26073
Timestep Consumption Time: 2.40606
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.66679

Cumulative Model Updates: 80,458
Cumulative Timesteps: 670,994,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 670994762...
Checkpoint 670994762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,330.28395
Policy Entropy: 1.87147
Value Function Loss: 0.08736

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.49849
Value Function Update Magnitude: 0.74148

Collected Steps per Second: 21,941.73667
Overall Steps per Second: 10,820.39835

Timestep Collection Time: 2.27986
Timestep Consumption Time: 2.34326
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.62312

Cumulative Model Updates: 80,464
Cumulative Timesteps: 671,044,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,095.03669
Policy Entropy: 1.88954
Value Function Loss: 0.08557

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.48936
Value Function Update Magnitude: 0.75271

Collected Steps per Second: 22,088.95263
Overall Steps per Second: 10,523.55385

Timestep Collection Time: 2.26367
Timestep Consumption Time: 2.48777
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.75144

Cumulative Model Updates: 80,470
Cumulative Timesteps: 671,094,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 671094788...
Checkpoint 671094788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,345.94706
Policy Entropy: 1.88751
Value Function Loss: 0.08944

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.73795

Collected Steps per Second: 22,048.82299
Overall Steps per Second: 10,729.69702

Timestep Collection Time: 2.26951
Timestep Consumption Time: 2.39418
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.66369

Cumulative Model Updates: 80,476
Cumulative Timesteps: 671,144,828

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,000.88593
Policy Entropy: 1.88450
Value Function Loss: 0.09046

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.78002

Collected Steps per Second: 22,409.41398
Overall Steps per Second: 10,781.77182

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63801

Cumulative Model Updates: 80,482
Cumulative Timesteps: 671,194,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 671194834...
Checkpoint 671194834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,021.18521
Policy Entropy: 1.86855
Value Function Loss: 0.09048

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.76986

Collected Steps per Second: 21,492.28807
Overall Steps per Second: 10,322.32150

Timestep Collection Time: 2.32828
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.84775

Cumulative Model Updates: 80,488
Cumulative Timesteps: 671,244,874

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,521.26482
Policy Entropy: 1.87255
Value Function Loss: 0.08998

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.73104

Collected Steps per Second: 22,448.04879
Overall Steps per Second: 10,792.20525

Timestep Collection Time: 2.22870
Timestep Consumption Time: 2.40705
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.63575

Cumulative Model Updates: 80,494
Cumulative Timesteps: 671,294,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 671294904...
Checkpoint 671294904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,108.15027
Policy Entropy: 1.85632
Value Function Loss: 0.09088

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15437
Policy Update Magnitude: 0.49053
Value Function Update Magnitude: 0.73377

Collected Steps per Second: 22,451.93533
Overall Steps per Second: 10,667.23161

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.46175
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.69006

Cumulative Model Updates: 80,500
Cumulative Timesteps: 671,344,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,243.55840
Policy Entropy: 1.88573
Value Function Loss: 0.09195

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.52329
Value Function Update Magnitude: 0.70958

Collected Steps per Second: 22,762.46660
Overall Steps per Second: 10,822.82520

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.61987

Cumulative Model Updates: 80,506
Cumulative Timesteps: 671,394,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 671394934...
Checkpoint 671394934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,543.06966
Policy Entropy: 1.88740
Value Function Loss: 0.08831

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.54568
Value Function Update Magnitude: 0.65709

Collected Steps per Second: 22,366.52527
Overall Steps per Second: 10,678.53366

Timestep Collection Time: 2.23557
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.68248

Cumulative Model Updates: 80,512
Cumulative Timesteps: 671,444,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,170.72100
Policy Entropy: 1.89663
Value Function Loss: 0.08495

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.72082

Collected Steps per Second: 22,564.27471
Overall Steps per Second: 10,567.29973

Timestep Collection Time: 2.21642
Timestep Consumption Time: 2.51629
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73271

Cumulative Model Updates: 80,518
Cumulative Timesteps: 671,494,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 671494948...
Checkpoint 671494948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,573.04584
Policy Entropy: 1.87903
Value Function Loss: 0.07739

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.74806

Collected Steps per Second: 22,587.45173
Overall Steps per Second: 10,596.96235

Timestep Collection Time: 2.21371
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.71852

Cumulative Model Updates: 80,524
Cumulative Timesteps: 671,544,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,295.66025
Policy Entropy: 1.87376
Value Function Loss: 0.07460

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.52860
Value Function Update Magnitude: 0.73603

Collected Steps per Second: 22,502.27048
Overall Steps per Second: 10,620.35805

Timestep Collection Time: 2.22200
Timestep Consumption Time: 2.48594
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.70794

Cumulative Model Updates: 80,530
Cumulative Timesteps: 671,594,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 671594950...
Checkpoint 671594950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,128.45599
Policy Entropy: 1.87833
Value Function Loss: 0.07504

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.52812
Value Function Update Magnitude: 0.72284

Collected Steps per Second: 22,496.48133
Overall Steps per Second: 10,593.13348

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.72004

Cumulative Model Updates: 80,536
Cumulative Timesteps: 671,644,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,462.27430
Policy Entropy: 1.89881
Value Function Loss: 0.08384

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.74054

Collected Steps per Second: 22,708.20008
Overall Steps per Second: 10,807.62947

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.62766

Cumulative Model Updates: 80,542
Cumulative Timesteps: 671,694,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 671694964...
Checkpoint 671694964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,270.54018
Policy Entropy: 1.90266
Value Function Loss: 0.08011

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.73008

Collected Steps per Second: 21,867.71232
Overall Steps per Second: 10,563.01397

Timestep Collection Time: 2.28721
Timestep Consumption Time: 2.44780
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.73501

Cumulative Model Updates: 80,548
Cumulative Timesteps: 671,744,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,094.28551
Policy Entropy: 1.89404
Value Function Loss: 0.08011

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.52893
Value Function Update Magnitude: 0.62533

Collected Steps per Second: 22,182.84127
Overall Steps per Second: 10,466.44793

Timestep Collection Time: 2.25399
Timestep Consumption Time: 2.52318
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.77717

Cumulative Model Updates: 80,554
Cumulative Timesteps: 671,794,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 671794980...
Checkpoint 671794980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,936.32700
Policy Entropy: 1.88741
Value Function Loss: 0.07408

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.52563
Value Function Update Magnitude: 0.68588

Collected Steps per Second: 22,077.63632
Overall Steps per Second: 10,595.72874

Timestep Collection Time: 2.26555
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.72058

Cumulative Model Updates: 80,560
Cumulative Timesteps: 671,844,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,521.87230
Policy Entropy: 1.87742
Value Function Loss: 0.07790

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.52834
Value Function Update Magnitude: 0.72035

Collected Steps per Second: 22,845.68988
Overall Steps per Second: 10,632.21368

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.51631
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.70683

Cumulative Model Updates: 80,566
Cumulative Timesteps: 671,895,042

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 671895042...
Checkpoint 671895042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,177.44086
Policy Entropy: 1.87470
Value Function Loss: 0.08408

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.54568
Value Function Update Magnitude: 0.75937

Collected Steps per Second: 22,448.77535
Overall Steps per Second: 10,562.92345

Timestep Collection Time: 2.22827
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.73562

Cumulative Model Updates: 80,572
Cumulative Timesteps: 671,945,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,165.84193
Policy Entropy: 1.85978
Value Function Loss: 0.08565

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.72822

Collected Steps per Second: 22,883.41452
Overall Steps per Second: 10,810.69727

Timestep Collection Time: 2.18621
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62764

Cumulative Model Updates: 80,578
Cumulative Timesteps: 671,995,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 671995092...
Checkpoint 671995092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,834.97283
Policy Entropy: 1.86543
Value Function Loss: 0.09197

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.74769

Collected Steps per Second: 22,539.78808
Overall Steps per Second: 10,662.16869

Timestep Collection Time: 2.21865
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.69023

Cumulative Model Updates: 80,584
Cumulative Timesteps: 672,045,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,769.41042
Policy Entropy: 1.87395
Value Function Loss: 0.08146

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.75519

Collected Steps per Second: 22,367.43200
Overall Steps per Second: 10,636.29806

Timestep Collection Time: 2.23620
Timestep Consumption Time: 2.46638
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70258

Cumulative Model Updates: 80,590
Cumulative Timesteps: 672,095,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 672095118...
Checkpoint 672095118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,541.83366
Policy Entropy: 1.87811
Value Function Loss: 0.08291

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.54181
Value Function Update Magnitude: 0.71824

Collected Steps per Second: 22,101.64326
Overall Steps per Second: 10,455.73246

Timestep Collection Time: 2.26354
Timestep Consumption Time: 2.52120
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.78474

Cumulative Model Updates: 80,596
Cumulative Timesteps: 672,145,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,599.95741
Policy Entropy: 1.86465
Value Function Loss: 0.09114

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.58295

Collected Steps per Second: 22,452.16703
Overall Steps per Second: 10,546.22250

Timestep Collection Time: 2.22749
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.74217

Cumulative Model Updates: 80,602
Cumulative Timesteps: 672,195,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 672195158...
Checkpoint 672195158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,493.30376
Policy Entropy: 1.86791
Value Function Loss: 0.09223

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.55993

Collected Steps per Second: 22,245.12605
Overall Steps per Second: 10,539.15884

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.74744

Cumulative Model Updates: 80,608
Cumulative Timesteps: 672,245,192

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,047.55494
Policy Entropy: 1.86210
Value Function Loss: 0.08568

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.54385
Value Function Update Magnitude: 0.67814

Collected Steps per Second: 22,053.22580
Overall Steps per Second: 10,466.33463

Timestep Collection Time: 2.26733
Timestep Consumption Time: 2.51008
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.77741

Cumulative Model Updates: 80,614
Cumulative Timesteps: 672,295,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 672295194...
Checkpoint 672295194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,621.38342
Policy Entropy: 1.86069
Value Function Loss: 0.08034

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.74468

Collected Steps per Second: 22,246.02459
Overall Steps per Second: 10,679.70676

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.68234

Cumulative Model Updates: 80,620
Cumulative Timesteps: 672,345,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,537.21335
Policy Entropy: 1.85571
Value Function Loss: 0.08493

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.54969
Value Function Update Magnitude: 0.76522

Collected Steps per Second: 22,492.41948
Overall Steps per Second: 10,530.06100

Timestep Collection Time: 2.22359
Timestep Consumption Time: 2.52605
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.74964

Cumulative Model Updates: 80,626
Cumulative Timesteps: 672,395,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 672395214...
Checkpoint 672395214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,223.78627
Policy Entropy: 1.85367
Value Function Loss: 0.08860

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.77470

Collected Steps per Second: 22,500.52034
Overall Steps per Second: 10,673.88194

Timestep Collection Time: 2.22306
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.68621

Cumulative Model Updates: 80,632
Cumulative Timesteps: 672,445,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,874.68799
Policy Entropy: 1.86046
Value Function Loss: 0.08856

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.77776

Collected Steps per Second: 22,977.91817
Overall Steps per Second: 10,758.53477

Timestep Collection Time: 2.17713
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.64989

Cumulative Model Updates: 80,638
Cumulative Timesteps: 672,495,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 672495260...
Checkpoint 672495260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,997.94918
Policy Entropy: 1.85708
Value Function Loss: 0.08158

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.51864
Value Function Update Magnitude: 0.69013

Collected Steps per Second: 22,653.33786
Overall Steps per Second: 10,623.41483

Timestep Collection Time: 2.20824
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.70884

Cumulative Model Updates: 80,644
Cumulative Timesteps: 672,545,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,344.10359
Policy Entropy: 1.85849
Value Function Loss: 0.07573

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.51013
Value Function Update Magnitude: 0.56047

Collected Steps per Second: 22,749.08299
Overall Steps per Second: 10,595.54285

Timestep Collection Time: 2.19851
Timestep Consumption Time: 2.52178
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.72029

Cumulative Model Updates: 80,650
Cumulative Timesteps: 672,595,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 672595298...
Checkpoint 672595298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,259.41232
Policy Entropy: 1.85000
Value Function Loss: 0.07918

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.52336
Value Function Update Magnitude: 0.47674

Collected Steps per Second: 22,488.77214
Overall Steps per Second: 10,522.88773

Timestep Collection Time: 2.22360
Timestep Consumption Time: 2.52852
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.75212

Cumulative Model Updates: 80,656
Cumulative Timesteps: 672,645,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,478.00899
Policy Entropy: 1.84525
Value Function Loss: 0.08513

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.51265

Collected Steps per Second: 21,810.64557
Overall Steps per Second: 10,433.28356

Timestep Collection Time: 2.29292
Timestep Consumption Time: 2.50040
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.79331

Cumulative Model Updates: 80,662
Cumulative Timesteps: 672,695,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 672695314...
Checkpoint 672695314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,737.33252
Policy Entropy: 1.84689
Value Function Loss: 0.09568

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.54430
Value Function Update Magnitude: 0.65810

Collected Steps per Second: 22,259.41967
Overall Steps per Second: 10,647.04618

Timestep Collection Time: 2.24669
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.69708

Cumulative Model Updates: 80,668
Cumulative Timesteps: 672,745,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,466.42830
Policy Entropy: 1.86101
Value Function Loss: 0.08710

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.78471

Collected Steps per Second: 22,568.38452
Overall Steps per Second: 10,617.33280

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.49399
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.70966

Cumulative Model Updates: 80,674
Cumulative Timesteps: 672,795,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 672795328...
Checkpoint 672795328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,221.71551
Policy Entropy: 1.88420
Value Function Loss: 0.07494

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.77431

Collected Steps per Second: 21,986.78499
Overall Steps per Second: 10,462.59706

Timestep Collection Time: 2.27555
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.78199

Cumulative Model Updates: 80,680
Cumulative Timesteps: 672,845,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,332.45984
Policy Entropy: 1.87822
Value Function Loss: 0.07377

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.73050

Collected Steps per Second: 22,459.38881
Overall Steps per Second: 10,652.12422

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.69709

Cumulative Model Updates: 80,686
Cumulative Timesteps: 672,895,394

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 672895394...
Checkpoint 672895394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,446.28934
Policy Entropy: 1.87047
Value Function Loss: 0.07884

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.81874

Collected Steps per Second: 22,560.40680
Overall Steps per Second: 10,550.62687

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.52359
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.74057

Cumulative Model Updates: 80,692
Cumulative Timesteps: 672,945,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,701.57179
Policy Entropy: 1.85834
Value Function Loss: 0.07981

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.54412
Value Function Update Magnitude: 0.82210

Collected Steps per Second: 22,728.03393
Overall Steps per Second: 10,800.66902

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.43000
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.63045

Cumulative Model Updates: 80,698
Cumulative Timesteps: 672,995,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 672995422...
Checkpoint 672995422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,313.35469
Policy Entropy: 1.84946
Value Function Loss: 0.07830

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.82949

Collected Steps per Second: 22,317.83225
Overall Steps per Second: 10,699.34465

Timestep Collection Time: 2.24063
Timestep Consumption Time: 2.43311
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.67374

Cumulative Model Updates: 80,704
Cumulative Timesteps: 673,045,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,180.76038
Policy Entropy: 1.84530
Value Function Loss: 0.07849

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.80305

Collected Steps per Second: 22,925.50705
Overall Steps per Second: 10,822.69937

Timestep Collection Time: 2.18133
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.62066

Cumulative Model Updates: 80,710
Cumulative Timesteps: 673,095,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 673095436...
Checkpoint 673095436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,082.59895
Policy Entropy: 1.84965
Value Function Loss: 0.07691

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.53970
Value Function Update Magnitude: 0.75994

Collected Steps per Second: 22,341.17678
Overall Steps per Second: 10,616.75373

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.47162
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.70973

Cumulative Model Updates: 80,716
Cumulative Timesteps: 673,145,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,257.21347
Policy Entropy: 1.84288
Value Function Loss: 0.08390

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.71346

Collected Steps per Second: 22,781.61082
Overall Steps per Second: 10,651.61574

Timestep Collection Time: 2.19581
Timestep Consumption Time: 2.50057
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.69638

Cumulative Model Updates: 80,722
Cumulative Timesteps: 673,195,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 673195462...
Checkpoint 673195462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,513.33819
Policy Entropy: 1.83769
Value Function Loss: 0.08586

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.63513

Collected Steps per Second: 22,136.00162
Overall Steps per Second: 10,465.03593

Timestep Collection Time: 2.26048
Timestep Consumption Time: 2.52097
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.78145

Cumulative Model Updates: 80,728
Cumulative Timesteps: 673,245,500

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,245.74139
Policy Entropy: 1.84933
Value Function Loss: 0.08294

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.68284

Collected Steps per Second: 22,333.16298
Overall Steps per Second: 10,481.19945

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.53172
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.77064

Cumulative Model Updates: 80,734
Cumulative Timesteps: 673,295,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 673295502...
Checkpoint 673295502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,885.27128
Policy Entropy: 1.85642
Value Function Loss: 0.08032

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.52503
Value Function Update Magnitude: 0.69951

Collected Steps per Second: 21,709.56230
Overall Steps per Second: 10,559.21973

Timestep Collection Time: 2.30470
Timestep Consumption Time: 2.43372
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73842

Cumulative Model Updates: 80,740
Cumulative Timesteps: 673,345,536

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,721.05613
Policy Entropy: 1.85856
Value Function Loss: 0.07548

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.52079
Value Function Update Magnitude: 0.61782

Collected Steps per Second: 22,224.55061
Overall Steps per Second: 10,484.27648

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.77057

Cumulative Model Updates: 80,746
Cumulative Timesteps: 673,395,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 673395552...
Checkpoint 673395552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,953.44078
Policy Entropy: 1.84749
Value Function Loss: 0.08564

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.52699
Value Function Update Magnitude: 0.69365

Collected Steps per Second: 22,388.22706
Overall Steps per Second: 10,652.19817

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.46134
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.69537

Cumulative Model Updates: 80,752
Cumulative Timesteps: 673,445,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,627.79209
Policy Entropy: 1.84311
Value Function Loss: 0.08768

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.74881

Collected Steps per Second: 22,642.59306
Overall Steps per Second: 10,802.91445

Timestep Collection Time: 2.20991
Timestep Consumption Time: 2.42199
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.63190

Cumulative Model Updates: 80,758
Cumulative Timesteps: 673,495,606

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 673495606...
Checkpoint 673495606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,819.76244
Policy Entropy: 1.84838
Value Function Loss: 0.08724

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.53597
Value Function Update Magnitude: 0.74235

Collected Steps per Second: 22,342.25705
Overall Steps per Second: 10,691.71242

Timestep Collection Time: 2.23916
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.67914

Cumulative Model Updates: 80,764
Cumulative Timesteps: 673,545,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,244.68525
Policy Entropy: 1.85145
Value Function Loss: 0.08221

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.53173
Value Function Update Magnitude: 0.69118

Collected Steps per Second: 22,582.96309
Overall Steps per Second: 10,565.83692

Timestep Collection Time: 2.21486
Timestep Consumption Time: 2.51908
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.73394

Cumulative Model Updates: 80,770
Cumulative Timesteps: 673,595,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 673595652...
Checkpoint 673595652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,725.70096
Policy Entropy: 1.85738
Value Function Loss: 0.07651

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.67864

Collected Steps per Second: 22,210.36674
Overall Steps per Second: 10,547.43704

Timestep Collection Time: 2.25156
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.74125

Cumulative Model Updates: 80,776
Cumulative Timesteps: 673,645,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,012.67720
Policy Entropy: 1.86473
Value Function Loss: 0.07919

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.52733
Value Function Update Magnitude: 0.65963

Collected Steps per Second: 22,508.16471
Overall Steps per Second: 10,561.72224

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.51457
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.73767

Cumulative Model Updates: 80,782
Cumulative Timesteps: 673,695,698

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 673695698...
Checkpoint 673695698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,428.33661
Policy Entropy: 1.87138
Value Function Loss: 0.07434

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 22,329.97839
Overall Steps per Second: 10,607.58435

Timestep Collection Time: 2.23950
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.71436

Cumulative Model Updates: 80,788
Cumulative Timesteps: 673,745,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,763.13918
Policy Entropy: 1.85752
Value Function Loss: 0.07956

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.52349
Value Function Update Magnitude: 0.53803

Collected Steps per Second: 22,442.30241
Overall Steps per Second: 10,546.60368

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.51293
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.74086

Cumulative Model Updates: 80,794
Cumulative Timesteps: 673,795,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 673795706...
Checkpoint 673795706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,349.25616
Policy Entropy: 1.85112
Value Function Loss: 0.08922

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.52695
Value Function Update Magnitude: 0.55739

Collected Steps per Second: 21,646.18932
Overall Steps per Second: 10,499.83702

Timestep Collection Time: 2.31154
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.76541

Cumulative Model Updates: 80,800
Cumulative Timesteps: 673,845,742

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,695.37176
Policy Entropy: 1.83968
Value Function Loss: 0.09136

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.17043
Policy Update Magnitude: 0.48394
Value Function Update Magnitude: 0.56146

Collected Steps per Second: 22,278.25242
Overall Steps per Second: 10,562.04565

Timestep Collection Time: 2.24506
Timestep Consumption Time: 2.49039
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.73545

Cumulative Model Updates: 80,806
Cumulative Timesteps: 673,895,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 673895758...
Checkpoint 673895758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,618.27967
Policy Entropy: 1.85239
Value Function Loss: 0.08790

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15410
Policy Update Magnitude: 0.45998
Value Function Update Magnitude: 0.48041

Collected Steps per Second: 21,891.15312
Overall Steps per Second: 10,522.74342

Timestep Collection Time: 2.28448
Timestep Consumption Time: 2.46808
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.75256

Cumulative Model Updates: 80,812
Cumulative Timesteps: 673,945,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,914.89675
Policy Entropy: 1.85730
Value Function Loss: 0.08626

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.46531
Value Function Update Magnitude: 0.49831

Collected Steps per Second: 23,014.88663
Overall Steps per Second: 10,849.52986

Timestep Collection Time: 2.17268
Timestep Consumption Time: 2.43618
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.60886

Cumulative Model Updates: 80,818
Cumulative Timesteps: 673,995,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 673995772...
Checkpoint 673995772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,667.08141
Policy Entropy: 1.86328
Value Function Loss: 0.08691

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.16567
Policy Update Magnitude: 0.48200
Value Function Update Magnitude: 0.60436

Collected Steps per Second: 22,239.12505
Overall Steps per Second: 10,662.19485

Timestep Collection Time: 2.24946
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.69190

Cumulative Model Updates: 80,824
Cumulative Timesteps: 674,045,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,651.56271
Policy Entropy: 1.86178
Value Function Loss: 0.08939

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.16762
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.58230

Collected Steps per Second: 21,023.88611
Overall Steps per Second: 10,134.46191

Timestep Collection Time: 2.37958
Timestep Consumption Time: 2.55684
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.93642

Cumulative Model Updates: 80,830
Cumulative Timesteps: 674,095,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 674095826...
Checkpoint 674095826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,081.41607
Policy Entropy: 1.86844
Value Function Loss: 0.08851

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.49125
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 19,612.91610
Overall Steps per Second: 9,797.35174

Timestep Collection Time: 2.54985
Timestep Consumption Time: 2.55459
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 5.10444

Cumulative Model Updates: 80,836
Cumulative Timesteps: 674,145,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,507.12435
Policy Entropy: 1.86719
Value Function Loss: 0.09161

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.16915
Policy Update Magnitude: 0.51084
Value Function Update Magnitude: 0.64214

Collected Steps per Second: 22,068.73300
Overall Steps per Second: 10,480.38668

Timestep Collection Time: 2.26610
Timestep Consumption Time: 2.50567
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.77177

Cumulative Model Updates: 80,842
Cumulative Timesteps: 674,195,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 674195846...
Checkpoint 674195846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,414.04213
Policy Entropy: 1.88290
Value Function Loss: 0.09308

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.16575
Policy Update Magnitude: 0.54764
Value Function Update Magnitude: 0.68891

Collected Steps per Second: 22,006.05567
Overall Steps per Second: 10,557.50797

Timestep Collection Time: 2.27301
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.73786

Cumulative Model Updates: 80,848
Cumulative Timesteps: 674,245,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,660.77981
Policy Entropy: 1.89382
Value Function Loss: 0.09626

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16324
Policy Update Magnitude: 0.55724
Value Function Update Magnitude: 0.54330

Collected Steps per Second: 22,660.59769
Overall Steps per Second: 10,852.41411

Timestep Collection Time: 2.20762
Timestep Consumption Time: 2.40205
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.60967

Cumulative Model Updates: 80,854
Cumulative Timesteps: 674,295,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 674295892...
Checkpoint 674295892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,549.03795
Policy Entropy: 1.90482
Value Function Loss: 0.10783

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.40396

Collected Steps per Second: 21,995.59138
Overall Steps per Second: 10,667.14730

Timestep Collection Time: 2.27418
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.68935

Cumulative Model Updates: 80,860
Cumulative Timesteps: 674,345,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,600.45146
Policy Entropy: 1.90729
Value Function Loss: 0.11566

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.56057
Value Function Update Magnitude: 0.32630

Collected Steps per Second: 22,209.41900
Overall Steps per Second: 10,544.71856

Timestep Collection Time: 2.25256
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.74437

Cumulative Model Updates: 80,866
Cumulative Timesteps: 674,395,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 674395942...
Checkpoint 674395942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,562.81380
Policy Entropy: 1.89806
Value Function Loss: 0.10784

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.55844
Value Function Update Magnitude: 0.46327

Collected Steps per Second: 21,949.19928
Overall Steps per Second: 10,590.98380

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.44438
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.72364

Cumulative Model Updates: 80,872
Cumulative Timesteps: 674,445,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,125.75811
Policy Entropy: 1.88765
Value Function Loss: 0.09362

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.54158

Collected Steps per Second: 22,291.15422
Overall Steps per Second: 10,452.89127

Timestep Collection Time: 2.24421
Timestep Consumption Time: 2.54164
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.78585

Cumulative Model Updates: 80,878
Cumulative Timesteps: 674,495,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 674495996...
Checkpoint 674495996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,245.15614
Policy Entropy: 1.87563
Value Function Loss: 0.07807

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.50336
Value Function Update Magnitude: 0.55475

Collected Steps per Second: 21,894.59336
Overall Steps per Second: 10,581.56616

Timestep Collection Time: 2.28540
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.72879

Cumulative Model Updates: 80,884
Cumulative Timesteps: 674,546,034

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,247.35264
Policy Entropy: 1.86633
Value Function Loss: 0.07915

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.46434
Value Function Update Magnitude: 0.53388

Collected Steps per Second: 22,285.23434
Overall Steps per Second: 10,493.75918

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.52251
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.76741

Cumulative Model Updates: 80,890
Cumulative Timesteps: 674,596,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 674596062...
Checkpoint 674596062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,124.75755
Policy Entropy: 1.87152
Value Function Loss: 0.08462

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.49125
Value Function Update Magnitude: 0.55134

Collected Steps per Second: 22,443.54299
Overall Steps per Second: 10,499.55108

Timestep Collection Time: 2.22817
Timestep Consumption Time: 2.53470
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.76287

Cumulative Model Updates: 80,896
Cumulative Timesteps: 674,646,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,196.36015
Policy Entropy: 1.88126
Value Function Loss: 0.08137

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.15675
Policy Update Magnitude: 0.51257
Value Function Update Magnitude: 0.63125

Collected Steps per Second: 22,948.23403
Overall Steps per Second: 10,642.65490

Timestep Collection Time: 2.17899
Timestep Consumption Time: 2.51946
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.69845

Cumulative Model Updates: 80,902
Cumulative Timesteps: 674,696,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 674696074...
Checkpoint 674696074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,395.64374
Policy Entropy: 1.91445
Value Function Loss: 0.08831

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.52042
Value Function Update Magnitude: 0.55548

Collected Steps per Second: 22,269.33750
Overall Steps per Second: 10,632.44191

Timestep Collection Time: 2.24551
Timestep Consumption Time: 2.45764
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.70315

Cumulative Model Updates: 80,908
Cumulative Timesteps: 674,746,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,400.44393
Policy Entropy: 1.92441
Value Function Loss: 0.08127

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.52507
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 22,736.70844
Overall Steps per Second: 10,816.00021

Timestep Collection Time: 2.20005
Timestep Consumption Time: 2.42476
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.62482

Cumulative Model Updates: 80,914
Cumulative Timesteps: 674,796,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 674796102...
Checkpoint 674796102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,475.54494
Policy Entropy: 1.93968
Value Function Loss: 0.08712

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.52982
Value Function Update Magnitude: 0.65098

Collected Steps per Second: 22,519.21644
Overall Steps per Second: 10,677.96882

Timestep Collection Time: 2.22086
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.68366

Cumulative Model Updates: 80,920
Cumulative Timesteps: 674,846,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,746.29683
Policy Entropy: 1.92987
Value Function Loss: 0.08760

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.53750
Value Function Update Magnitude: 0.65648

Collected Steps per Second: 22,305.51275
Overall Steps per Second: 10,544.66089

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.74344

Cumulative Model Updates: 80,926
Cumulative Timesteps: 674,896,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 674896132...
Checkpoint 674896132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,291.19701
Policy Entropy: 1.92443
Value Function Loss: 0.08744

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.52733
Value Function Update Magnitude: 0.64763

Collected Steps per Second: 21,638.09544
Overall Steps per Second: 10,531.64469

Timestep Collection Time: 2.31194
Timestep Consumption Time: 2.43812
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.75007

Cumulative Model Updates: 80,932
Cumulative Timesteps: 674,946,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,874.77082
Policy Entropy: 1.93253
Value Function Loss: 0.09132

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.53307
Value Function Update Magnitude: 0.55050

Collected Steps per Second: 22,470.16164
Overall Steps per Second: 10,655.81486

Timestep Collection Time: 2.22731
Timestep Consumption Time: 2.46947
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.69678

Cumulative Model Updates: 80,938
Cumulative Timesteps: 674,996,206

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 674996206...
Checkpoint 674996206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,631.88576
Policy Entropy: 1.93727
Value Function Loss: 0.09174

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.49378
Value Function Update Magnitude: 0.43914

Collected Steps per Second: 21,996.32454
Overall Steps per Second: 10,448.31898

Timestep Collection Time: 2.27411
Timestep Consumption Time: 2.51346
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.78756

Cumulative Model Updates: 80,944
Cumulative Timesteps: 675,046,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,530.94824
Policy Entropy: 1.93041
Value Function Loss: 0.09466

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.46753
Value Function Update Magnitude: 0.47595

Collected Steps per Second: 22,823.04925
Overall Steps per Second: 10,851.67318

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.41701
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.60795

Cumulative Model Updates: 80,950
Cumulative Timesteps: 675,096,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 675096232...
Checkpoint 675096232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,733.93775
Policy Entropy: 1.90481
Value Function Loss: 0.08974

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.50248
Value Function Update Magnitude: 0.52137

Collected Steps per Second: 22,192.83367
Overall Steps per Second: 10,686.66181

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.68135

Cumulative Model Updates: 80,956
Cumulative Timesteps: 675,146,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,381.26689
Policy Entropy: 1.89658
Value Function Loss: 0.09023

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.59471

Collected Steps per Second: 22,682.11268
Overall Steps per Second: 10,591.70257

Timestep Collection Time: 2.20579
Timestep Consumption Time: 2.51791
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.72370

Cumulative Model Updates: 80,962
Cumulative Timesteps: 675,196,292

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 675196292...
Checkpoint 675196292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,928.56131
Policy Entropy: 1.90184
Value Function Loss: 0.08939

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.61558

Collected Steps per Second: 22,431.32051
Overall Steps per Second: 10,553.30832

Timestep Collection Time: 2.22983
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.73956

Cumulative Model Updates: 80,968
Cumulative Timesteps: 675,246,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,705.61032
Policy Entropy: 1.92062
Value Function Loss: 0.09181

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.67210

Collected Steps per Second: 22,612.91787
Overall Steps per Second: 10,659.75194

Timestep Collection Time: 2.21166
Timestep Consumption Time: 2.48001
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.69167

Cumulative Model Updates: 80,974
Cumulative Timesteps: 675,296,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 675296322...
Checkpoint 675296322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,807.24780
Policy Entropy: 1.92775
Value Function Loss: 0.08599

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.67850

Collected Steps per Second: 22,235.92537
Overall Steps per Second: 10,524.81009

Timestep Collection Time: 2.24879
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75106

Cumulative Model Updates: 80,980
Cumulative Timesteps: 675,346,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,502.14264
Policy Entropy: 1.93678
Value Function Loss: 0.09172

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.70602

Collected Steps per Second: 22,664.93725
Overall Steps per Second: 10,804.36173

Timestep Collection Time: 2.20737
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.63054

Cumulative Model Updates: 80,986
Cumulative Timesteps: 675,396,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 675396356...
Checkpoint 675396356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,098.05824
Policy Entropy: 1.94062
Value Function Loss: 0.09298

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15412
Policy Update Magnitude: 0.51123
Value Function Update Magnitude: 0.76492

Collected Steps per Second: 22,042.40855
Overall Steps per Second: 10,694.69701

Timestep Collection Time: 2.26981
Timestep Consumption Time: 2.40840
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.67821

Cumulative Model Updates: 80,992
Cumulative Timesteps: 675,446,388

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,152.59011
Policy Entropy: 1.95085
Value Function Loss: 0.09420

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.52444
Value Function Update Magnitude: 0.75486

Collected Steps per Second: 22,562.05524
Overall Steps per Second: 10,675.68116

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.46862
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.68579

Cumulative Model Updates: 80,998
Cumulative Timesteps: 675,496,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 675496412...
Checkpoint 675496412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,513.66075
Policy Entropy: 1.93890
Value Function Loss: 0.09289

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.55541
Value Function Update Magnitude: 0.60469

Collected Steps per Second: 22,418.65886
Overall Steps per Second: 10,598.13107

Timestep Collection Time: 2.23136
Timestep Consumption Time: 2.48872
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.72008

Cumulative Model Updates: 81,004
Cumulative Timesteps: 675,546,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,373.49122
Policy Entropy: 1.91772
Value Function Loss: 0.09727

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.56243
Value Function Update Magnitude: 0.50787

Collected Steps per Second: 22,878.57612
Overall Steps per Second: 10,638.11888

Timestep Collection Time: 2.18598
Timestep Consumption Time: 2.51523
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.70121

Cumulative Model Updates: 81,010
Cumulative Timesteps: 675,596,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 675596448...
Checkpoint 675596448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,789.21665
Policy Entropy: 1.91648
Value Function Loss: 0.10496

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.50025

Collected Steps per Second: 22,564.00123
Overall Steps per Second: 10,673.28874

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.46936
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.68590

Cumulative Model Updates: 81,016
Cumulative Timesteps: 675,646,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,342.30622
Policy Entropy: 1.92657
Value Function Loss: 0.09712

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.50627

Collected Steps per Second: 22,859.44666
Overall Steps per Second: 10,681.12906

Timestep Collection Time: 2.18868
Timestep Consumption Time: 2.49547
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.68415

Cumulative Model Updates: 81,022
Cumulative Timesteps: 675,696,494

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 675696494...
Checkpoint 675696494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,396.21144
Policy Entropy: 1.92372
Value Function Loss: 0.08490

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.55704

Collected Steps per Second: 22,397.94382
Overall Steps per Second: 10,579.06195

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.72859

Cumulative Model Updates: 81,028
Cumulative Timesteps: 675,746,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,088.07537
Policy Entropy: 1.93260
Value Function Loss: 0.08331

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.53341
Value Function Update Magnitude: 0.54320

Collected Steps per Second: 22,825.36691
Overall Steps per Second: 10,782.73190

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.44699
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.63797

Cumulative Model Updates: 81,034
Cumulative Timesteps: 675,796,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 675796528...
Checkpoint 675796528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,054.07237
Policy Entropy: 1.91416
Value Function Loss: 0.07859

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.14655
Policy Update Magnitude: 0.48991
Value Function Update Magnitude: 0.53170

Collected Steps per Second: 21,519.12397
Overall Steps per Second: 10,526.26549

Timestep Collection Time: 2.32361
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.75021

Cumulative Model Updates: 81,040
Cumulative Timesteps: 675,846,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,280.38500
Policy Entropy: 1.90826
Value Function Loss: 0.08878

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.15306
Policy Update Magnitude: 0.47099
Value Function Update Magnitude: 0.56128

Collected Steps per Second: 22,255.00438
Overall Steps per Second: 10,546.59658

Timestep Collection Time: 2.24722
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.74200

Cumulative Model Updates: 81,046
Cumulative Timesteps: 675,896,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 675896542...
Checkpoint 675896542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,897.04870
Policy Entropy: 1.92107
Value Function Loss: 0.08961

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.51701
Value Function Update Magnitude: 0.55299

Collected Steps per Second: 21,818.49715
Overall Steps per Second: 10,591.67215

Timestep Collection Time: 2.29255
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.72258

Cumulative Model Updates: 81,052
Cumulative Timesteps: 675,946,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,551.69843
Policy Entropy: 1.93950
Value Function Loss: 0.08800

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.58780

Collected Steps per Second: 22,527.44886
Overall Steps per Second: 10,559.10619

Timestep Collection Time: 2.22147
Timestep Consumption Time: 2.51795
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73942

Cumulative Model Updates: 81,058
Cumulative Timesteps: 675,996,606

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 675996606...
Checkpoint 675996606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,549.11027
Policy Entropy: 1.94684
Value Function Loss: 0.08380

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.52342
Value Function Update Magnitude: 0.55556

Collected Steps per Second: 21,723.63632
Overall Steps per Second: 10,492.43731

Timestep Collection Time: 2.30284
Timestep Consumption Time: 2.46498
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.76782

Cumulative Model Updates: 81,064
Cumulative Timesteps: 676,046,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,424.78389
Policy Entropy: 1.94217
Value Function Loss: 0.08265

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.52742
Value Function Update Magnitude: 0.53638

Collected Steps per Second: 22,784.64943
Overall Steps per Second: 10,641.90239

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.69860

Cumulative Model Updates: 81,070
Cumulative Timesteps: 676,096,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 676096634...
Checkpoint 676096634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,104.07509
Policy Entropy: 1.94363
Value Function Loss: 0.08561

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.53365

Collected Steps per Second: 22,197.08834
Overall Steps per Second: 10,536.31517

Timestep Collection Time: 2.25318
Timestep Consumption Time: 2.49364
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.74682

Cumulative Model Updates: 81,076
Cumulative Timesteps: 676,146,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,276.93226
Policy Entropy: 1.93729
Value Function Loss: 0.08499

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.52880
Value Function Update Magnitude: 0.54007

Collected Steps per Second: 22,761.66977
Overall Steps per Second: 10,679.79596

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.68286

Cumulative Model Updates: 81,082
Cumulative Timesteps: 676,196,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 676196660...
Checkpoint 676196660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,435.99702
Policy Entropy: 1.93021
Value Function Loss: 0.08208

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.52642
Value Function Update Magnitude: 0.63501

Collected Steps per Second: 22,707.41724
Overall Steps per Second: 10,792.34218

Timestep Collection Time: 2.20228
Timestep Consumption Time: 2.43138
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.63366

Cumulative Model Updates: 81,088
Cumulative Timesteps: 676,246,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,171.05209
Policy Entropy: 1.93595
Value Function Loss: 0.08561

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.53525
Value Function Update Magnitude: 0.59652

Collected Steps per Second: 22,961.06922
Overall Steps per Second: 10,742.24789

Timestep Collection Time: 2.17891
Timestep Consumption Time: 2.47841
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.65731

Cumulative Model Updates: 81,094
Cumulative Timesteps: 676,296,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 676296698...
Checkpoint 676296698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,926.66838
Policy Entropy: 1.95181
Value Function Loss: 0.08712

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.58034

Collected Steps per Second: 22,102.93179
Overall Steps per Second: 10,471.88089

Timestep Collection Time: 2.26241
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.77526

Cumulative Model Updates: 81,100
Cumulative Timesteps: 676,346,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,289.13513
Policy Entropy: 1.95665
Value Function Loss: 0.09393

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.58295

Collected Steps per Second: 22,140.26879
Overall Steps per Second: 10,488.68262

Timestep Collection Time: 2.25833
Timestep Consumption Time: 2.50871
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.76704

Cumulative Model Updates: 81,106
Cumulative Timesteps: 676,396,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 676396704...
Checkpoint 676396704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,593.43779
Policy Entropy: 1.97136
Value Function Loss: 0.10982

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.47718

Collected Steps per Second: 22,212.48305
Overall Steps per Second: 10,571.65594

Timestep Collection Time: 2.25162
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.73095

Cumulative Model Updates: 81,112
Cumulative Timesteps: 676,446,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,466.38774
Policy Entropy: 1.97209
Value Function Loss: 0.10867

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.56684
Value Function Update Magnitude: 0.42875

Collected Steps per Second: 22,604.13477
Overall Steps per Second: 10,515.79040

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.54419
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.75742

Cumulative Model Updates: 81,118
Cumulative Timesteps: 676,496,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 676496746...
Checkpoint 676496746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,857.75124
Policy Entropy: 1.99120
Value Function Loss: 0.10341

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.54202
Value Function Update Magnitude: 0.48118

Collected Steps per Second: 21,971.86966
Overall Steps per Second: 10,361.89491

Timestep Collection Time: 2.27664
Timestep Consumption Time: 2.55086
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.82750

Cumulative Model Updates: 81,124
Cumulative Timesteps: 676,546,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,110.74092
Policy Entropy: 2.00072
Value Function Loss: 0.09802

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.50174
Value Function Update Magnitude: 0.50546

Collected Steps per Second: 23,085.67755
Overall Steps per Second: 10,709.12869

Timestep Collection Time: 2.16628
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.66985

Cumulative Model Updates: 81,130
Cumulative Timesteps: 676,596,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 676596778...
Checkpoint 676596778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,020.17904
Policy Entropy: 1.99722
Value Function Loss: 0.09991

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.49587
Value Function Update Magnitude: 0.41279

Collected Steps per Second: 22,560.00292
Overall Steps per Second: 10,642.24697

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.48314
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.70051

Cumulative Model Updates: 81,136
Cumulative Timesteps: 676,646,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,337.25734
Policy Entropy: 1.97888
Value Function Loss: 0.10020

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.50544
Value Function Update Magnitude: 0.37681

Collected Steps per Second: 23,151.03424
Overall Steps per Second: 10,874.04558

Timestep Collection Time: 2.16154
Timestep Consumption Time: 2.44042
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.60197

Cumulative Model Updates: 81,142
Cumulative Timesteps: 676,696,844

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 676696844...
Checkpoint 676696844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,002.71561
Policy Entropy: 1.95568
Value Function Loss: 0.08555

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.58887

Collected Steps per Second: 21,332.18356
Overall Steps per Second: 10,631.10906

Timestep Collection Time: 2.34435
Timestep Consumption Time: 2.35977
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.70412

Cumulative Model Updates: 81,148
Cumulative Timesteps: 676,746,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,812.69296
Policy Entropy: 1.96194
Value Function Loss: 0.08539

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.64202

Collected Steps per Second: 22,027.07790
Overall Steps per Second: 10,687.52302

Timestep Collection Time: 2.27021
Timestep Consumption Time: 2.40871
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.67891

Cumulative Model Updates: 81,154
Cumulative Timesteps: 676,796,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 676796860...
Checkpoint 676796860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,092.62079
Policy Entropy: 1.97056
Value Function Loss: 0.09005

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.61767

Collected Steps per Second: 21,659.21038
Overall Steps per Second: 10,545.62318

Timestep Collection Time: 2.30886
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.74206

Cumulative Model Updates: 81,160
Cumulative Timesteps: 676,846,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,581.74872
Policy Entropy: 1.96972
Value Function Loss: 0.09690

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.55000
Value Function Update Magnitude: 0.62017

Collected Steps per Second: 21,699.16670
Overall Steps per Second: 10,623.86929

Timestep Collection Time: 2.30590
Timestep Consumption Time: 2.40388
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.70977

Cumulative Model Updates: 81,166
Cumulative Timesteps: 676,896,904

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 676896904...
Checkpoint 676896904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,916.00698
Policy Entropy: 1.96094
Value Function Loss: 0.09386

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.67714

Collected Steps per Second: 21,432.01116
Overall Steps per Second: 10,406.03124

Timestep Collection Time: 2.33324
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.80548

Cumulative Model Updates: 81,172
Cumulative Timesteps: 676,946,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,160.45658
Policy Entropy: 1.94598
Value Function Loss: 0.08913

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.71275

Collected Steps per Second: 22,215.98722
Overall Steps per Second: 10,838.63370

Timestep Collection Time: 2.25180
Timestep Consumption Time: 2.36372
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.61553

Cumulative Model Updates: 81,178
Cumulative Timesteps: 676,996,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 676996936...
Checkpoint 676996936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,020.09449
Policy Entropy: 1.93373
Value Function Loss: 0.08690

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.56306
Value Function Update Magnitude: 0.75869

Collected Steps per Second: 21,533.39379
Overall Steps per Second: 10,648.23590

Timestep Collection Time: 2.32244
Timestep Consumption Time: 2.37411
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.69655

Cumulative Model Updates: 81,184
Cumulative Timesteps: 677,046,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,692.78561
Policy Entropy: 1.94650
Value Function Loss: 0.08607

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.73663

Collected Steps per Second: 22,044.51293
Overall Steps per Second: 10,682.42525

Timestep Collection Time: 2.26986
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.68414

Cumulative Model Updates: 81,190
Cumulative Timesteps: 677,096,984

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 677096984...
Checkpoint 677096984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,680.81888
Policy Entropy: 1.95348
Value Function Loss: 0.08359

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.63427

Collected Steps per Second: 21,674.03554
Overall Steps per Second: 10,630.88008

Timestep Collection Time: 2.30700
Timestep Consumption Time: 2.39647
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.70347

Cumulative Model Updates: 81,196
Cumulative Timesteps: 677,146,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,952.98782
Policy Entropy: 1.95549
Value Function Loss: 0.08485

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.65422

Collected Steps per Second: 21,813.77577
Overall Steps per Second: 10,761.18727

Timestep Collection Time: 2.29305
Timestep Consumption Time: 2.35514
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.64819

Cumulative Model Updates: 81,202
Cumulative Timesteps: 677,197,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 677197006...
Checkpoint 677197006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,949.73752
Policy Entropy: 1.94346
Value Function Loss: 0.08511

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.54161
Value Function Update Magnitude: 0.64454

Collected Steps per Second: 21,771.60220
Overall Steps per Second: 10,604.17323

Timestep Collection Time: 2.29685
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.71569

Cumulative Model Updates: 81,208
Cumulative Timesteps: 677,247,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,936.06633
Policy Entropy: 1.94226
Value Function Loss: 0.08760

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.63168

Collected Steps per Second: 21,932.11781
Overall Steps per Second: 10,648.46285

Timestep Collection Time: 2.27976
Timestep Consumption Time: 2.41575
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69551

Cumulative Model Updates: 81,214
Cumulative Timesteps: 677,297,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 677297012...
Checkpoint 677297012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,806.52759
Policy Entropy: 1.93647
Value Function Loss: 0.08374

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.68818

Collected Steps per Second: 21,208.25211
Overall Steps per Second: 10,472.42084

Timestep Collection Time: 2.35823
Timestep Consumption Time: 2.41755
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.77578

Cumulative Model Updates: 81,220
Cumulative Timesteps: 677,347,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,943.91994
Policy Entropy: 1.92917
Value Function Loss: 0.07822

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.73426

Collected Steps per Second: 22,693.64209
Overall Steps per Second: 10,818.46226

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62191

Cumulative Model Updates: 81,226
Cumulative Timesteps: 677,397,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 677397028...
Checkpoint 677397028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,258.48820
Policy Entropy: 1.91550
Value Function Loss: 0.08211

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.53846
Value Function Update Magnitude: 0.72917

Collected Steps per Second: 22,466.05504
Overall Steps per Second: 10,677.47104

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.45728
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.68294

Cumulative Model Updates: 81,232
Cumulative Timesteps: 677,447,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,552.30463
Policy Entropy: 1.89903
Value Function Loss: 0.08163

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.54335
Value Function Update Magnitude: 0.68940

Collected Steps per Second: 22,719.79960
Overall Steps per Second: 10,848.69648

Timestep Collection Time: 2.20213
Timestep Consumption Time: 2.40967
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.61180

Cumulative Model Updates: 81,238
Cumulative Timesteps: 677,497,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 677497062...
Checkpoint 677497062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,996.66402
Policy Entropy: 1.91918
Value Function Loss: 0.08635

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.52612
Value Function Update Magnitude: 0.61375

Collected Steps per Second: 22,520.61393
Overall Steps per Second: 10,734.86779

Timestep Collection Time: 2.22205
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.66163

Cumulative Model Updates: 81,244
Cumulative Timesteps: 677,547,104

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,949.61021
Policy Entropy: 1.91331
Value Function Loss: 0.07970

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.52384
Value Function Update Magnitude: 0.68860

Collected Steps per Second: 22,842.94173
Overall Steps per Second: 10,876.17265

Timestep Collection Time: 2.18912
Timestep Consumption Time: 2.40863
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.59776

Cumulative Model Updates: 81,250
Cumulative Timesteps: 677,597,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 677597110...
Checkpoint 677597110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,772.93979
Policy Entropy: 1.90405
Value Function Loss: 0.08368

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.53764
Value Function Update Magnitude: 0.75075

Collected Steps per Second: 22,029.31646
Overall Steps per Second: 10,631.85173

Timestep Collection Time: 2.27079
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.70511

Cumulative Model Updates: 81,256
Cumulative Timesteps: 677,647,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,000.68681
Policy Entropy: 1.89000
Value Function Loss: 0.08433

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.72286

Collected Steps per Second: 22,231.09527
Overall Steps per Second: 10,472.76275

Timestep Collection Time: 2.25126
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.77887

Cumulative Model Updates: 81,262
Cumulative Timesteps: 677,697,182

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 677697182...
Checkpoint 677697182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,057.72026
Policy Entropy: 1.89645
Value Function Loss: 0.08519

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.68635

Collected Steps per Second: 22,048.83994
Overall Steps per Second: 10,581.94922

Timestep Collection Time: 2.26769
Timestep Consumption Time: 2.45733
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72503

Cumulative Model Updates: 81,268
Cumulative Timesteps: 677,747,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,293.03344
Policy Entropy: 1.92123
Value Function Loss: 0.08421

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.55725
Value Function Update Magnitude: 0.68872

Collected Steps per Second: 22,365.42383
Overall Steps per Second: 10,502.99074

Timestep Collection Time: 2.23720
Timestep Consumption Time: 2.52677
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.76398

Cumulative Model Updates: 81,274
Cumulative Timesteps: 677,797,218

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 677797218...
Checkpoint 677797218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,639.73431
Policy Entropy: 1.92690
Value Function Loss: 0.08010

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.72894

Collected Steps per Second: 22,186.46573
Overall Steps per Second: 10,572.53560

Timestep Collection Time: 2.25507
Timestep Consumption Time: 2.47719
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.73226

Cumulative Model Updates: 81,280
Cumulative Timesteps: 677,847,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,746.93130
Policy Entropy: 1.93028
Value Function Loss: 0.08419

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.77453

Collected Steps per Second: 23,184.66901
Overall Steps per Second: 10,949.48931

Timestep Collection Time: 2.15763
Timestep Consumption Time: 2.41098
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.56861

Cumulative Model Updates: 81,286
Cumulative Timesteps: 677,897,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 677897274...
Checkpoint 677897274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,632.21462
Policy Entropy: 1.92106
Value Function Loss: 0.08488

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.80958

Collected Steps per Second: 22,632.05087
Overall Steps per Second: 10,677.02644

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.47488
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68520

Cumulative Model Updates: 81,292
Cumulative Timesteps: 677,947,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,929.93619
Policy Entropy: 1.91886
Value Function Loss: 0.08572

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.74965

Collected Steps per Second: 22,613.27704
Overall Steps per Second: 10,551.44197

Timestep Collection Time: 2.21330
Timestep Consumption Time: 2.53013
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.74343

Cumulative Model Updates: 81,298
Cumulative Timesteps: 677,997,348

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 677997348...
Checkpoint 677997348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,990.82591
Policy Entropy: 1.90909
Value Function Loss: 0.08334

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.66336

Collected Steps per Second: 22,389.18014
Overall Steps per Second: 10,518.79648

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.52098
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.75492

Cumulative Model Updates: 81,304
Cumulative Timesteps: 678,047,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,426.28921
Policy Entropy: 1.90366
Value Function Loss: 0.08608

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.49021

Collected Steps per Second: 22,548.82600
Overall Steps per Second: 10,587.36331

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.72488

Cumulative Model Updates: 81,310
Cumulative Timesteps: 678,097,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 678097388...
Checkpoint 678097388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,838.96606
Policy Entropy: 1.90245
Value Function Loss: 0.09139

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.38435

Collected Steps per Second: 22,445.26980
Overall Steps per Second: 10,561.16025

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.73584

Cumulative Model Updates: 81,316
Cumulative Timesteps: 678,147,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,551.68230
Policy Entropy: 1.89936
Value Function Loss: 0.10365

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.37943

Collected Steps per Second: 22,124.00732
Overall Steps per Second: 10,444.12396

Timestep Collection Time: 2.26080
Timestep Consumption Time: 2.52830
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.78910

Cumulative Model Updates: 81,322
Cumulative Timesteps: 678,197,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 678197422...
Checkpoint 678197422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,181.78889
Policy Entropy: 1.89998
Value Function Loss: 0.10327

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.36779

Collected Steps per Second: 21,821.84591
Overall Steps per Second: 10,592.69158

Timestep Collection Time: 2.29311
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.72401

Cumulative Model Updates: 81,328
Cumulative Timesteps: 678,247,462

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,047.74122
Policy Entropy: 1.89646
Value Function Loss: 0.10438

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.53796
Value Function Update Magnitude: 0.32006

Collected Steps per Second: 22,276.45295
Overall Steps per Second: 10,543.87486

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.49917
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.74512

Cumulative Model Updates: 81,334
Cumulative Timesteps: 678,297,494

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 678297494...
Checkpoint 678297494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,574.91531
Policy Entropy: 1.89602
Value Function Loss: 0.08782

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.28875

Collected Steps per Second: 22,071.55841
Overall Steps per Second: 10,619.24606

Timestep Collection Time: 2.26636
Timestep Consumption Time: 2.44415
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71050

Cumulative Model Updates: 81,340
Cumulative Timesteps: 678,347,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,632.42212
Policy Entropy: 1.89499
Value Function Loss: 0.09577

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.54860
Value Function Update Magnitude: 0.30500

Collected Steps per Second: 23,046.04098
Overall Steps per Second: 10,639.63510

Timestep Collection Time: 2.17026
Timestep Consumption Time: 2.53065
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.70091

Cumulative Model Updates: 81,346
Cumulative Timesteps: 678,397,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 678397532...
Checkpoint 678397532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,805.01196
Policy Entropy: 1.89584
Value Function Loss: 0.09297

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.37842

Collected Steps per Second: 22,658.42379
Overall Steps per Second: 10,775.24267

Timestep Collection Time: 2.20730
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.64157

Cumulative Model Updates: 81,352
Cumulative Timesteps: 678,447,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,675.09914
Policy Entropy: 1.89547
Value Function Loss: 0.09042

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.54666
Value Function Update Magnitude: 0.48713

Collected Steps per Second: 22,512.99216
Overall Steps per Second: 10,574.48687

Timestep Collection Time: 2.22192
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.73044

Cumulative Model Updates: 81,358
Cumulative Timesteps: 678,497,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 678497568...
Checkpoint 678497568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,478.15545
Policy Entropy: 1.90292
Value Function Loss: 0.08506

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.53380
Value Function Update Magnitude: 0.49490

Collected Steps per Second: 22,802.94147
Overall Steps per Second: 10,655.13876

Timestep Collection Time: 2.19410
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.69557

Cumulative Model Updates: 81,364
Cumulative Timesteps: 678,547,600

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,629.09508
Policy Entropy: 1.90077
Value Function Loss: 0.08622

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.52423
Value Function Update Magnitude: 0.38897

Collected Steps per Second: 22,492.36139
Overall Steps per Second: 10,608.87678

Timestep Collection Time: 2.22387
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.71492

Cumulative Model Updates: 81,370
Cumulative Timesteps: 678,597,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 678597620...
Checkpoint 678597620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,222.48866
Policy Entropy: 1.90980
Value Function Loss: 0.09521

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.51557
Value Function Update Magnitude: 0.34504

Collected Steps per Second: 22,630.53117
Overall Steps per Second: 10,642.96687

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.69963

Cumulative Model Updates: 81,376
Cumulative Timesteps: 678,647,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,037.76694
Policy Entropy: 1.91319
Value Function Loss: 0.08947

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.48709
Value Function Update Magnitude: 0.31998

Collected Steps per Second: 22,684.21955
Overall Steps per Second: 10,748.20448

Timestep Collection Time: 2.20647
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.65678

Cumulative Model Updates: 81,382
Cumulative Timesteps: 678,697,690

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 678697690...
Checkpoint 678697690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,695.44016
Policy Entropy: 1.90956
Value Function Loss: 0.08496

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.48752
Value Function Update Magnitude: 0.39224

Collected Steps per Second: 21,773.44600
Overall Steps per Second: 10,571.13422

Timestep Collection Time: 2.29849
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.73421

Cumulative Model Updates: 81,388
Cumulative Timesteps: 678,747,736

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,315.31684
Policy Entropy: 1.91770
Value Function Loss: 0.07769

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.51512
Value Function Update Magnitude: 0.45145

Collected Steps per Second: 22,039.19351
Overall Steps per Second: 10,586.33496

Timestep Collection Time: 2.27068
Timestep Consumption Time: 2.45654
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.72723

Cumulative Model Updates: 81,394
Cumulative Timesteps: 678,797,780

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 678797780...
Checkpoint 678797780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,798.69580
Policy Entropy: 1.90657
Value Function Loss: 0.07861

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.52651
Value Function Update Magnitude: 0.42874

Collected Steps per Second: 22,394.93554
Overall Steps per Second: 10,533.37498

Timestep Collection Time: 2.23354
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.74872

Cumulative Model Updates: 81,400
Cumulative Timesteps: 678,847,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,292.08553
Policy Entropy: 1.91562
Value Function Loss: 0.08044

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.43317

Collected Steps per Second: 22,815.91349
Overall Steps per Second: 10,648.98777

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.50433
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.69622

Cumulative Model Updates: 81,406
Cumulative Timesteps: 678,897,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 678897810...
Checkpoint 678897810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,795.21966
Policy Entropy: 1.91585
Value Function Loss: 0.08067

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.53327
Value Function Update Magnitude: 0.44293

Collected Steps per Second: 22,750.42928
Overall Steps per Second: 10,713.16903

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.66846

Cumulative Model Updates: 81,412
Cumulative Timesteps: 678,947,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,092.83977
Policy Entropy: 1.91894
Value Function Loss: 0.07763

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.47827

Collected Steps per Second: 22,911.94145
Overall Steps per Second: 10,670.91142

Timestep Collection Time: 2.18270
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.68657

Cumulative Model Updates: 81,418
Cumulative Timesteps: 678,997,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 678997834...
Checkpoint 678997834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,356.24505
Policy Entropy: 1.90313
Value Function Loss: 0.07792

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.54928

Collected Steps per Second: 21,992.93239
Overall Steps per Second: 10,624.92190

Timestep Collection Time: 2.27409
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.70723

Cumulative Model Updates: 81,424
Cumulative Timesteps: 679,047,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,581.61753
Policy Entropy: 1.87281
Value Function Loss: 0.08271

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.59324

Collected Steps per Second: 20,995.14891
Overall Steps per Second: 10,395.27003

Timestep Collection Time: 2.38274
Timestep Consumption Time: 2.42964
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.81238

Cumulative Model Updates: 81,430
Cumulative Timesteps: 679,097,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 679097874...
Checkpoint 679097874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,731.09227
Policy Entropy: 1.86130
Value Function Loss: 0.09069

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.62816

Collected Steps per Second: 22,157.49970
Overall Steps per Second: 10,692.99186

Timestep Collection Time: 2.25729
Timestep Consumption Time: 2.42016
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.67746

Cumulative Model Updates: 81,436
Cumulative Timesteps: 679,147,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,878.65931
Policy Entropy: 1.87286
Value Function Loss: 0.09000

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.56576
Value Function Update Magnitude: 0.73539

Collected Steps per Second: 21,633.54740
Overall Steps per Second: 10,527.60438

Timestep Collection Time: 2.31160
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.75018

Cumulative Model Updates: 81,442
Cumulative Timesteps: 679,197,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 679197898...
Checkpoint 679197898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,876.63364
Policy Entropy: 1.89225
Value Function Loss: 0.08672

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.76016

Collected Steps per Second: 22,105.72039
Overall Steps per Second: 10,606.85750

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71450

Cumulative Model Updates: 81,448
Cumulative Timesteps: 679,247,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,069.89958
Policy Entropy: 1.90407
Value Function Loss: 0.08355

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.55544
Value Function Update Magnitude: 0.74220

Collected Steps per Second: 21,839.64969
Overall Steps per Second: 10,590.50615

Timestep Collection Time: 2.29024
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.72291

Cumulative Model Updates: 81,454
Cumulative Timesteps: 679,297,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 679297922...
Checkpoint 679297922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,680.29699
Policy Entropy: 1.88034
Value Function Loss: 0.08677

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.62891

Collected Steps per Second: 22,088.43688
Overall Steps per Second: 10,862.58727

Timestep Collection Time: 2.26381
Timestep Consumption Time: 2.33951
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60332

Cumulative Model Updates: 81,460
Cumulative Timesteps: 679,347,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,295.82710
Policy Entropy: 1.87362
Value Function Loss: 0.08776

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.54910

Collected Steps per Second: 21,934.05230
Overall Steps per Second: 10,591.89937

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.44122
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.72097

Cumulative Model Updates: 81,466
Cumulative Timesteps: 679,397,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 679397930...
Checkpoint 679397930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,872.46182
Policy Entropy: 1.87477
Value Function Loss: 0.08782

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.55223
Value Function Update Magnitude: 0.48647

Collected Steps per Second: 21,724.06021
Overall Steps per Second: 10,559.06358

Timestep Collection Time: 2.30169
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.73546

Cumulative Model Updates: 81,472
Cumulative Timesteps: 679,447,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,296.12319
Policy Entropy: 1.87683
Value Function Loss: 0.07903

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.53068
Value Function Update Magnitude: 0.59917

Collected Steps per Second: 22,492.68873
Overall Steps per Second: 10,969.96936

Timestep Collection Time: 2.22366
Timestep Consumption Time: 2.33570
PPO Batch Consumption Time: 0.27619
Total Iteration Time: 4.55936

Cumulative Model Updates: 81,478
Cumulative Timesteps: 679,497,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 679497948...
Checkpoint 679497948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,412.97572
Policy Entropy: 1.85497
Value Function Loss: 0.07518

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.49962
Value Function Update Magnitude: 0.70481

Collected Steps per Second: 21,422.70292
Overall Steps per Second: 10,538.72914

Timestep Collection Time: 2.33425
Timestep Consumption Time: 2.41072
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.74497

Cumulative Model Updates: 81,484
Cumulative Timesteps: 679,547,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,120.08278
Policy Entropy: 1.83817
Value Function Loss: 0.07276

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.52578
Value Function Update Magnitude: 0.63392

Collected Steps per Second: 22,355.85793
Overall Steps per Second: 10,591.02668

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.48512
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.72230

Cumulative Model Updates: 81,490
Cumulative Timesteps: 679,597,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 679597968...
Checkpoint 679597968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,325.14643
Policy Entropy: 1.84335
Value Function Loss: 0.08402

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.54054
Value Function Update Magnitude: 0.46489

Collected Steps per Second: 22,239.50855
Overall Steps per Second: 10,546.56356

Timestep Collection Time: 2.24969
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.74391

Cumulative Model Updates: 81,496
Cumulative Timesteps: 679,648,000

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,708.91779
Policy Entropy: 1.85127
Value Function Loss: 0.08778

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.43591

Collected Steps per Second: 21,276.79121
Overall Steps per Second: 10,514.32794

Timestep Collection Time: 2.35120
Timestep Consumption Time: 2.40669
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.75789

Cumulative Model Updates: 81,502
Cumulative Timesteps: 679,698,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 679698026...
Checkpoint 679698026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,143.49453
Policy Entropy: 1.84570
Value Function Loss: 0.08502

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.15249
Policy Update Magnitude: 0.49035
Value Function Update Magnitude: 0.44687

Collected Steps per Second: 22,280.49238
Overall Steps per Second: 10,600.14273

Timestep Collection Time: 2.24456
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.71786

Cumulative Model Updates: 81,508
Cumulative Timesteps: 679,748,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,688.63753
Policy Entropy: 1.84612
Value Function Loss: 0.08314

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.49977
Value Function Update Magnitude: 0.55466

Collected Steps per Second: 22,833.01459
Overall Steps per Second: 10,791.75251

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.63539

Cumulative Model Updates: 81,514
Cumulative Timesteps: 679,798,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 679798060...
Checkpoint 679798060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,211.02497
Policy Entropy: 1.84469
Value Function Loss: 0.08516

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.50416
Value Function Update Magnitude: 0.62243

Collected Steps per Second: 22,341.08495
Overall Steps per Second: 10,745.67903

Timestep Collection Time: 2.23812
Timestep Consumption Time: 2.41510
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.65322

Cumulative Model Updates: 81,520
Cumulative Timesteps: 679,848,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,683.19684
Policy Entropy: 1.86350
Value Function Loss: 0.08488

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.16138
Policy Update Magnitude: 0.50743
Value Function Update Magnitude: 0.56782

Collected Steps per Second: 22,735.46687
Overall Steps per Second: 10,793.46247

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.63707

Cumulative Model Updates: 81,526
Cumulative Timesteps: 679,898,112

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 679898112...
Checkpoint 679898112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,711.53040
Policy Entropy: 1.84996
Value Function Loss: 0.08266

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.51459
Value Function Update Magnitude: 0.60020

Collected Steps per Second: 22,204.32623
Overall Steps per Second: 10,709.99009

Timestep Collection Time: 2.25289
Timestep Consumption Time: 2.41788
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.67078

Cumulative Model Updates: 81,532
Cumulative Timesteps: 679,948,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,407.94237
Policy Entropy: 1.85521
Value Function Loss: 0.07787

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.53236
Value Function Update Magnitude: 0.64064

Collected Steps per Second: 22,758.20776
Overall Steps per Second: 10,629.60413

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.50714
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.70441

Cumulative Model Updates: 81,538
Cumulative Timesteps: 679,998,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 679998142...
Checkpoint 679998142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,362.90179
Policy Entropy: 1.84224
Value Function Loss: 0.08622

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.53441
Value Function Update Magnitude: 0.65529

Collected Steps per Second: 22,450.19824
Overall Steps per Second: 10,547.08896

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.74235

Cumulative Model Updates: 81,544
Cumulative Timesteps: 680,048,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,421.02762
Policy Entropy: 1.85130
Value Function Loss: 0.08480

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.54599
Value Function Update Magnitude: 0.69661

Collected Steps per Second: 22,436.25821
Overall Steps per Second: 10,597.12231

Timestep Collection Time: 2.22898
Timestep Consumption Time: 2.49022
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.71921

Cumulative Model Updates: 81,550
Cumulative Timesteps: 680,098,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 680098170...
Checkpoint 680098170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,023.39962
Policy Entropy: 1.83852
Value Function Loss: 0.08680

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.72036

Collected Steps per Second: 22,203.26245
Overall Steps per Second: 10,525.45199

Timestep Collection Time: 2.25237
Timestep Consumption Time: 2.49897
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.75134

Cumulative Model Updates: 81,556
Cumulative Timesteps: 680,148,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,187.74623
Policy Entropy: 1.84330
Value Function Loss: 0.08364

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.72549

Collected Steps per Second: 22,299.18482
Overall Steps per Second: 10,566.91680

Timestep Collection Time: 2.24250
Timestep Consumption Time: 2.48981
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.73232

Cumulative Model Updates: 81,562
Cumulative Timesteps: 680,198,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 680198186...
Checkpoint 680198186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,144.19206
Policy Entropy: 1.83928
Value Function Loss: 0.08001

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.52337
Value Function Update Magnitude: 0.73045

Collected Steps per Second: 20,407.06746
Overall Steps per Second: 10,014.37785

Timestep Collection Time: 2.45092
Timestep Consumption Time: 2.54350
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.99442

Cumulative Model Updates: 81,568
Cumulative Timesteps: 680,248,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,450.68748
Policy Entropy: 1.85890
Value Function Loss: 0.08020

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.49387
Value Function Update Magnitude: 0.65720

Collected Steps per Second: 21,002.94498
Overall Steps per Second: 10,156.51977

Timestep Collection Time: 2.38243
Timestep Consumption Time: 2.54426
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.92669

Cumulative Model Updates: 81,574
Cumulative Timesteps: 680,298,240

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 680298240...
Checkpoint 680298240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,499.88515
Policy Entropy: 1.84764
Value Function Loss: 0.07868

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.60111

Collected Steps per Second: 20,801.28869
Overall Steps per Second: 10,077.83266

Timestep Collection Time: 2.40504
Timestep Consumption Time: 2.55912
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.96416

Cumulative Model Updates: 81,580
Cumulative Timesteps: 680,348,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,833.15384
Policy Entropy: 1.84805
Value Function Loss: 0.08270

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.53837
Value Function Update Magnitude: 0.63955

Collected Steps per Second: 21,761.18694
Overall Steps per Second: 10,384.46809

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.51742
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.81527

Cumulative Model Updates: 81,586
Cumulative Timesteps: 680,398,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 680398272...
Checkpoint 680398272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,491.96786
Policy Entropy: 1.85524
Value Function Loss: 0.08416

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.60486

Collected Steps per Second: 20,635.99898
Overall Steps per Second: 9,979.65183

Timestep Collection Time: 2.42508
Timestep Consumption Time: 2.58952
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 5.01460

Cumulative Model Updates: 81,592
Cumulative Timesteps: 680,448,316

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,460.85786
Policy Entropy: 1.84603
Value Function Loss: 0.08488

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.54186
Value Function Update Magnitude: 0.61635

Collected Steps per Second: 21,374.32994
Overall Steps per Second: 10,315.38653

Timestep Collection Time: 2.34056
Timestep Consumption Time: 2.50928
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.84984

Cumulative Model Updates: 81,598
Cumulative Timesteps: 680,498,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 680498344...
Checkpoint 680498344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,729.41691
Policy Entropy: 1.83633
Value Function Loss: 0.08216

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.66623

Collected Steps per Second: 20,951.33806
Overall Steps per Second: 10,282.18412

Timestep Collection Time: 2.38677
Timestep Consumption Time: 2.47659
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.86336

Cumulative Model Updates: 81,604
Cumulative Timesteps: 680,548,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,266.58343
Policy Entropy: 1.81742
Value Function Loss: 0.08146

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.62697

Collected Steps per Second: 21,368.87252
Overall Steps per Second: 10,336.21786

Timestep Collection Time: 2.34051
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.83871

Cumulative Model Updates: 81,610
Cumulative Timesteps: 680,598,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 680598364...
Checkpoint 680598364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,244.81007
Policy Entropy: 1.81599
Value Function Loss: 0.08228

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.16092
Policy Update Magnitude: 0.50403
Value Function Update Magnitude: 0.59766

Collected Steps per Second: 20,943.03429
Overall Steps per Second: 10,264.66429

Timestep Collection Time: 2.38896
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.87420

Cumulative Model Updates: 81,616
Cumulative Timesteps: 680,648,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,829.58786
Policy Entropy: 1.83172
Value Function Loss: 0.08930

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.16353
Policy Update Magnitude: 0.48666
Value Function Update Magnitude: 0.57111

Collected Steps per Second: 21,439.12759
Overall Steps per Second: 10,404.02585

Timestep Collection Time: 2.33256
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.80660

Cumulative Model Updates: 81,622
Cumulative Timesteps: 680,698,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 680698404...
Checkpoint 680698404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,831.85648
Policy Entropy: 1.84368
Value Function Loss: 0.08346

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.15336
Policy Update Magnitude: 0.51614
Value Function Update Magnitude: 0.49834

Collected Steps per Second: 19,406.91327
Overall Steps per Second: 9,845.34376

Timestep Collection Time: 2.57681
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 5.07936

Cumulative Model Updates: 81,628
Cumulative Timesteps: 680,748,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,307.88141
Policy Entropy: 1.85180
Value Function Loss: 0.08288

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.52031
Value Function Update Magnitude: 0.48651

Collected Steps per Second: 21,114.27868
Overall Steps per Second: 10,102.38629

Timestep Collection Time: 2.36873
Timestep Consumption Time: 2.58198
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.95071

Cumulative Model Updates: 81,634
Cumulative Timesteps: 680,798,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 680798426...
Checkpoint 680798426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,097.83259
Policy Entropy: 1.85805
Value Function Loss: 0.08609

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.51294
Value Function Update Magnitude: 0.44122

Collected Steps per Second: 21,206.91481
Overall Steps per Second: 10,200.41182

Timestep Collection Time: 2.35829
Timestep Consumption Time: 2.54465
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.90294

Cumulative Model Updates: 81,640
Cumulative Timesteps: 680,848,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,019.34288
Policy Entropy: 1.85681
Value Function Loss: 0.09097

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.39356

Collected Steps per Second: 20,658.35334
Overall Steps per Second: 10,056.26946

Timestep Collection Time: 2.42081
Timestep Consumption Time: 2.55220
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.97302

Cumulative Model Updates: 81,646
Cumulative Timesteps: 680,898,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 680898448...
Checkpoint 680898448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,386.66306
Policy Entropy: 1.85667
Value Function Loss: 0.09156

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.49689

Collected Steps per Second: 20,788.84413
Overall Steps per Second: 10,361.94673

Timestep Collection Time: 2.40648
Timestep Consumption Time: 2.42157
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.82805

Cumulative Model Updates: 81,652
Cumulative Timesteps: 680,948,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,759.69468
Policy Entropy: 1.83704
Value Function Loss: 0.09446

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.55716
Value Function Update Magnitude: 0.45202

Collected Steps per Second: 21,442.65077
Overall Steps per Second: 10,652.06627

Timestep Collection Time: 2.33199
Timestep Consumption Time: 2.36231
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.69430

Cumulative Model Updates: 81,658
Cumulative Timesteps: 680,998,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 680998480...
Checkpoint 680998480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,335.21064
Policy Entropy: 1.83958
Value Function Loss: 0.09899

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.45338

Collected Steps per Second: 21,697.82582
Overall Steps per Second: 10,714.70467

Timestep Collection Time: 2.30641
Timestep Consumption Time: 2.36418
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.67059

Cumulative Model Updates: 81,664
Cumulative Timesteps: 681,048,524

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,292.10537
Policy Entropy: 1.84593
Value Function Loss: 0.09312

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.56896

Collected Steps per Second: 22,045.62976
Overall Steps per Second: 10,692.35031

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.40908
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.67792

Cumulative Model Updates: 81,670
Cumulative Timesteps: 681,098,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 681098542...
Checkpoint 681098542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,738.81594
Policy Entropy: 1.87027
Value Function Loss: 0.08595

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.54491
Value Function Update Magnitude: 0.72322

Collected Steps per Second: 22,233.85596
Overall Steps per Second: 10,872.32915

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.35001
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59883

Cumulative Model Updates: 81,676
Cumulative Timesteps: 681,148,542

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,371.74178
Policy Entropy: 1.89159
Value Function Loss: 0.08496

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.51932
Value Function Update Magnitude: 0.66740

Collected Steps per Second: 21,971.48381
Overall Steps per Second: 10,607.36293

Timestep Collection Time: 2.27641
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.71522

Cumulative Model Updates: 81,682
Cumulative Timesteps: 681,198,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 681198558...
Checkpoint 681198558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,732.46121
Policy Entropy: 1.89422
Value Function Loss: 0.08126

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.47358
Value Function Update Magnitude: 0.63386

Collected Steps per Second: 21,837.32464
Overall Steps per Second: 10,631.68900

Timestep Collection Time: 2.29012
Timestep Consumption Time: 2.41375
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.70386

Cumulative Model Updates: 81,688
Cumulative Timesteps: 681,248,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,688.03487
Policy Entropy: 1.87876
Value Function Loss: 0.08512

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.48334
Value Function Update Magnitude: 0.64822

Collected Steps per Second: 22,258.25485
Overall Steps per Second: 10,789.27416

Timestep Collection Time: 2.24735
Timestep Consumption Time: 2.38893
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.63627

Cumulative Model Updates: 81,694
Cumulative Timesteps: 681,298,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 681298590...
Checkpoint 681298590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,637.24357
Policy Entropy: 1.88001
Value Function Loss: 0.08200

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.51527
Value Function Update Magnitude: 0.68701

Collected Steps per Second: 21,607.45517
Overall Steps per Second: 10,586.45201

Timestep Collection Time: 2.31411
Timestep Consumption Time: 2.40910
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.72321

Cumulative Model Updates: 81,700
Cumulative Timesteps: 681,348,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,975.71777
Policy Entropy: 1.88232
Value Function Loss: 0.07902

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.51381
Value Function Update Magnitude: 0.63875

Collected Steps per Second: 21,776.74203
Overall Steps per Second: 10,496.14941

Timestep Collection Time: 2.29722
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.76613

Cumulative Model Updates: 81,706
Cumulative Timesteps: 681,398,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 681398618...
Checkpoint 681398618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,021.56467
Policy Entropy: 1.89184
Value Function Loss: 0.07343

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.51106
Value Function Update Magnitude: 0.62358

Collected Steps per Second: 21,937.97878
Overall Steps per Second: 10,669.96564

Timestep Collection Time: 2.27979
Timestep Consumption Time: 2.40757
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.68736

Cumulative Model Updates: 81,712
Cumulative Timesteps: 681,448,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,421.83058
Policy Entropy: 1.88779
Value Function Loss: 0.07793

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.52336
Value Function Update Magnitude: 0.68922

Collected Steps per Second: 22,063.32679
Overall Steps per Second: 10,525.11793

Timestep Collection Time: 2.26747
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.75320

Cumulative Model Updates: 81,718
Cumulative Timesteps: 681,498,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 681498660...
Checkpoint 681498660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,049.95906
Policy Entropy: 1.89647
Value Function Loss: 0.07545

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.51544
Value Function Update Magnitude: 0.68434

Collected Steps per Second: 22,228.94130
Overall Steps per Second: 10,543.03235

Timestep Collection Time: 2.25031
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74456

Cumulative Model Updates: 81,724
Cumulative Timesteps: 681,548,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,162.74013
Policy Entropy: 1.88009
Value Function Loss: 0.07938

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.50444
Value Function Update Magnitude: 0.67553

Collected Steps per Second: 22,538.09617
Overall Steps per Second: 10,464.48193

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.56093
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.78055

Cumulative Model Updates: 81,730
Cumulative Timesteps: 681,598,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 681598708...
Checkpoint 681598708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,473.61784
Policy Entropy: 1.88575
Value Function Loss: 0.07307

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.50384
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 22,491.32793
Overall Steps per Second: 10,578.26987

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.72705

Cumulative Model Updates: 81,736
Cumulative Timesteps: 681,648,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,366.39678
Policy Entropy: 1.87539
Value Function Loss: 0.07636

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.50767
Value Function Update Magnitude: 0.55564

Collected Steps per Second: 22,938.78068
Overall Steps per Second: 10,706.34651

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.49051
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.67031

Cumulative Model Updates: 81,742
Cumulative Timesteps: 681,698,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 681698714...
Checkpoint 681698714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,727.08425
Policy Entropy: 1.88649
Value Function Loss: 0.07925

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.51014
Value Function Update Magnitude: 0.47731

Collected Steps per Second: 22,862.06466
Overall Steps per Second: 10,926.37474

Timestep Collection Time: 2.18782
Timestep Consumption Time: 2.38991
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.57773

Cumulative Model Updates: 81,748
Cumulative Timesteps: 681,748,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,099.16105
Policy Entropy: 1.88299
Value Function Loss: 0.08690

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.52312
Value Function Update Magnitude: 0.51209

Collected Steps per Second: 23,024.85036
Overall Steps per Second: 10,818.24447

Timestep Collection Time: 2.17244
Timestep Consumption Time: 2.45124
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.62367

Cumulative Model Updates: 81,754
Cumulative Timesteps: 681,798,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 681798752...
Checkpoint 681798752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,168.97058
Policy Entropy: 1.87527
Value Function Loss: 0.08222

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.56184

Collected Steps per Second: 22,271.15749
Overall Steps per Second: 10,693.11406

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.43124
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.67665

Cumulative Model Updates: 81,760
Cumulative Timesteps: 681,848,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,506.67113
Policy Entropy: 1.87320
Value Function Loss: 0.07795

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.68090

Collected Steps per Second: 22,029.66798
Overall Steps per Second: 10,484.48889

Timestep Collection Time: 2.26985
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.76933

Cumulative Model Updates: 81,766
Cumulative Timesteps: 681,898,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 681898764...
Checkpoint 681898764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,237.76959
Policy Entropy: 1.89340
Value Function Loss: 0.07607

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.53322
Value Function Update Magnitude: 0.70909

Collected Steps per Second: 21,945.27647
Overall Steps per Second: 10,595.26288

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.44226
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72211

Cumulative Model Updates: 81,772
Cumulative Timesteps: 681,948,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,829.57956
Policy Entropy: 1.90736
Value Function Loss: 0.07967

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12250
Policy Update Magnitude: 0.53644
Value Function Update Magnitude: 0.74082

Collected Steps per Second: 22,469.40869
Overall Steps per Second: 10,555.31825

Timestep Collection Time: 2.22525
Timestep Consumption Time: 2.51170
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.73695

Cumulative Model Updates: 81,778
Cumulative Timesteps: 681,998,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 681998796...
Checkpoint 681998796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,726.63319
Policy Entropy: 1.91439
Value Function Loss: 0.07659

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.53516
Value Function Update Magnitude: 0.73180

Collected Steps per Second: 22,055.00670
Overall Steps per Second: 10,621.24874

Timestep Collection Time: 2.26724
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.70792

Cumulative Model Updates: 81,784
Cumulative Timesteps: 682,048,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,548.37122
Policy Entropy: 1.89182
Value Function Loss: 0.07670

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.52686
Value Function Update Magnitude: 0.71280

Collected Steps per Second: 22,951.93018
Overall Steps per Second: 10,749.42254

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.47443
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.65420

Cumulative Model Updates: 81,790
Cumulative Timesteps: 682,098,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 682098830...
Checkpoint 682098830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,100.27870
Policy Entropy: 1.88800
Value Function Loss: 0.07396

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.51904
Value Function Update Magnitude: 0.71094

Collected Steps per Second: 22,567.60977
Overall Steps per Second: 10,745.49261

Timestep Collection Time: 2.21627
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.65460

Cumulative Model Updates: 81,796
Cumulative Timesteps: 682,148,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,351.64333
Policy Entropy: 1.86772
Value Function Loss: 0.07456

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.49381
Value Function Update Magnitude: 0.71539

Collected Steps per Second: 22,552.65871
Overall Steps per Second: 10,619.57769

Timestep Collection Time: 2.21801
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.71036

Cumulative Model Updates: 81,802
Cumulative Timesteps: 682,198,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 682198868...
Checkpoint 682198868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,501.40206
Policy Entropy: 1.88679
Value Function Loss: 0.07933

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.51185
Value Function Update Magnitude: 0.69923

Collected Steps per Second: 22,296.63749
Overall Steps per Second: 10,520.60124

Timestep Collection Time: 2.24276
Timestep Consumption Time: 2.51039
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.75315

Cumulative Model Updates: 81,808
Cumulative Timesteps: 682,248,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,621.16406
Policy Entropy: 1.87619
Value Function Loss: 0.07312

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.52103
Value Function Update Magnitude: 0.67439

Collected Steps per Second: 23,016.81464
Overall Steps per Second: 10,852.94038

Timestep Collection Time: 2.17380
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61018

Cumulative Model Updates: 81,814
Cumulative Timesteps: 682,298,908

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 682298908...
Checkpoint 682298908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,737.31184
Policy Entropy: 1.88840
Value Function Loss: 0.07977

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.52761
Value Function Update Magnitude: 0.61522

Collected Steps per Second: 22,346.00022
Overall Steps per Second: 10,647.91988

Timestep Collection Time: 2.23772
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.69613

Cumulative Model Updates: 81,820
Cumulative Timesteps: 682,348,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,131.89471
Policy Entropy: 1.88022
Value Function Loss: 0.08106

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.66102

Collected Steps per Second: 22,316.29389
Overall Steps per Second: 10,618.08032

Timestep Collection Time: 2.24141
Timestep Consumption Time: 2.46942
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.71083

Cumulative Model Updates: 81,826
Cumulative Timesteps: 682,398,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 682398932...
Checkpoint 682398932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,948.33725
Policy Entropy: 1.88695
Value Function Loss: 0.07963

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.67871

Collected Steps per Second: 21,934.29485
Overall Steps per Second: 10,471.59221

Timestep Collection Time: 2.28163
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.77922

Cumulative Model Updates: 81,832
Cumulative Timesteps: 682,448,978

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,822.48665
Policy Entropy: 1.89179
Value Function Loss: 0.07394

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.53984
Value Function Update Magnitude: 0.72390

Collected Steps per Second: 22,208.46231
Overall Steps per Second: 10,487.38846

Timestep Collection Time: 2.25211
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.76916

Cumulative Model Updates: 81,838
Cumulative Timesteps: 682,498,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 682498994...
Checkpoint 682498994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,998.25274
Policy Entropy: 1.91477
Value Function Loss: 0.07136

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.70854

Collected Steps per Second: 21,825.71571
Overall Steps per Second: 10,671.09327

Timestep Collection Time: 2.29161
Timestep Consumption Time: 2.39545
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.68705

Cumulative Model Updates: 81,844
Cumulative Timesteps: 682,549,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,627.50316
Policy Entropy: 1.91224
Value Function Loss: 0.07554

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.53192
Value Function Update Magnitude: 0.68467

Collected Steps per Second: 23,005.66904
Overall Steps per Second: 10,767.41998

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.64550

Cumulative Model Updates: 81,850
Cumulative Timesteps: 682,599,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 682599030...
Checkpoint 682599030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,674.20585
Policy Entropy: 1.90732
Value Function Loss: 0.07739

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.63509

Collected Steps per Second: 21,256.05113
Overall Steps per Second: 10,275.54022

Timestep Collection Time: 2.35274
Timestep Consumption Time: 2.51416
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.86690

Cumulative Model Updates: 81,856
Cumulative Timesteps: 682,649,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,838.99972
Policy Entropy: 1.89047
Value Function Loss: 0.08173

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.50515
Value Function Update Magnitude: 0.61948

Collected Steps per Second: 22,944.18994
Overall Steps per Second: 10,845.10917

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61111

Cumulative Model Updates: 81,862
Cumulative Timesteps: 682,699,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 682699048...
Checkpoint 682699048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,303.13948
Policy Entropy: 1.88729
Value Function Loss: 0.08067

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.50577
Value Function Update Magnitude: 0.67040

Collected Steps per Second: 21,955.74872
Overall Steps per Second: 10,631.71300

Timestep Collection Time: 2.27731
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.70291

Cumulative Model Updates: 81,868
Cumulative Timesteps: 682,749,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,094.07812
Policy Entropy: 1.88997
Value Function Loss: 0.08295

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.53887
Value Function Update Magnitude: 0.65658

Collected Steps per Second: 22,548.07076
Overall Steps per Second: 10,520.96476

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.53736
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.75698

Cumulative Model Updates: 81,874
Cumulative Timesteps: 682,799,096

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 682799096...
Checkpoint 682799096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,841.83130
Policy Entropy: 1.89617
Value Function Loss: 0.08057

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.72548

Collected Steps per Second: 22,158.96197
Overall Steps per Second: 10,688.67091

Timestep Collection Time: 2.25660
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.67822

Cumulative Model Updates: 81,880
Cumulative Timesteps: 682,849,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,407.11081
Policy Entropy: 1.90677
Value Function Loss: 0.08116

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.72419

Collected Steps per Second: 22,820.96567
Overall Steps per Second: 10,825.77149

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.62119

Cumulative Model Updates: 81,886
Cumulative Timesteps: 682,899,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 682899128...
Checkpoint 682899128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,181.62833
Policy Entropy: 1.92720
Value Function Loss: 0.07934

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.70655

Collected Steps per Second: 21,782.14803
Overall Steps per Second: 10,611.67946

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.41672
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.71254

Cumulative Model Updates: 81,892
Cumulative Timesteps: 682,949,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,189.45435
Policy Entropy: 1.92091
Value Function Loss: 0.08580

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.67857

Collected Steps per Second: 22,171.30744
Overall Steps per Second: 10,562.45317

Timestep Collection Time: 2.25571
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.73488

Cumulative Model Updates: 81,898
Cumulative Timesteps: 682,999,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 682999148...
Checkpoint 682999148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,098.92838
Policy Entropy: 1.91550
Value Function Loss: 0.08292

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.55518
Value Function Update Magnitude: 0.61862

Collected Steps per Second: 21,767.90448
Overall Steps per Second: 10,519.63134

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.45665
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.75416

Cumulative Model Updates: 81,904
Cumulative Timesteps: 683,049,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,746.55506
Policy Entropy: 1.90197
Value Function Loss: 0.08173

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.67994

Collected Steps per Second: 22,478.39925
Overall Steps per Second: 10,505.07980

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.53595
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.76093

Cumulative Model Updates: 81,910
Cumulative Timesteps: 683,099,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 683099174...
Checkpoint 683099174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,217.66523
Policy Entropy: 1.90030
Value Function Loss: 0.07534

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.75442

Collected Steps per Second: 22,111.50892
Overall Steps per Second: 10,584.49252

Timestep Collection Time: 2.26136
Timestep Consumption Time: 2.46272
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.72408

Cumulative Model Updates: 81,916
Cumulative Timesteps: 683,149,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,702.87185
Policy Entropy: 1.89822
Value Function Loss: 0.07359

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.74229

Collected Steps per Second: 22,953.59858
Overall Steps per Second: 10,671.74336

Timestep Collection Time: 2.17918
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.68714

Cumulative Model Updates: 81,922
Cumulative Timesteps: 683,199,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 683199196...
Checkpoint 683199196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,246.28226
Policy Entropy: 1.88419
Value Function Loss: 0.07718

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.62537

Collected Steps per Second: 22,262.43844
Overall Steps per Second: 10,490.60752

Timestep Collection Time: 2.24746
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.76941

Cumulative Model Updates: 81,928
Cumulative Timesteps: 683,249,230

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,864.61343
Policy Entropy: 1.86222
Value Function Loss: 0.07800

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.60435

Collected Steps per Second: 22,846.84456
Overall Steps per Second: 10,841.09293

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61337

Cumulative Model Updates: 81,934
Cumulative Timesteps: 683,299,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 683299244...
Checkpoint 683299244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,965.59699
Policy Entropy: 1.86431
Value Function Loss: 0.08141

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.54511
Value Function Update Magnitude: 0.57818

Collected Steps per Second: 22,160.64764
Overall Steps per Second: 10,682.95004

Timestep Collection Time: 2.25670
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.68129

Cumulative Model Updates: 81,940
Cumulative Timesteps: 683,349,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,662.24904
Policy Entropy: 1.87417
Value Function Loss: 0.08424

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.55777
Value Function Update Magnitude: 0.55041

Collected Steps per Second: 23,054.21070
Overall Steps per Second: 10,847.65697

Timestep Collection Time: 2.17062
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61316

Cumulative Model Updates: 81,946
Cumulative Timesteps: 683,399,296

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 683399296...
Checkpoint 683399296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,622.54870
Policy Entropy: 1.90526
Value Function Loss: 0.08854

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.56861

Collected Steps per Second: 21,918.65128
Overall Steps per Second: 10,672.68369

Timestep Collection Time: 2.28262
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.68786

Cumulative Model Updates: 81,952
Cumulative Timesteps: 683,449,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,953.79679
Policy Entropy: 1.90179
Value Function Loss: 0.08626

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.55207
Value Function Update Magnitude: 0.61650

Collected Steps per Second: 22,558.40975
Overall Steps per Second: 10,591.23880

Timestep Collection Time: 2.21753
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.72315

Cumulative Model Updates: 81,958
Cumulative Timesteps: 683,499,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 683499352...
Checkpoint 683499352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,151.95830
Policy Entropy: 1.90675
Value Function Loss: 0.08716

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.68843

Collected Steps per Second: 21,794.39312
Overall Steps per Second: 10,563.39159

Timestep Collection Time: 2.29426
Timestep Consumption Time: 2.43926
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.73352

Cumulative Model Updates: 81,964
Cumulative Timesteps: 683,549,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,015.46507
Policy Entropy: 1.91170
Value Function Loss: 0.07934

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.52703
Value Function Update Magnitude: 0.69788

Collected Steps per Second: 22,822.63880
Overall Steps per Second: 10,637.97653

Timestep Collection Time: 2.19125
Timestep Consumption Time: 2.50984
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.70108

Cumulative Model Updates: 81,970
Cumulative Timesteps: 683,599,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 683599364...
Checkpoint 683599364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,057.63768
Policy Entropy: 1.92195
Value Function Loss: 0.08346

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.52340
Value Function Update Magnitude: 0.70560

Collected Steps per Second: 22,380.47050
Overall Steps per Second: 10,518.15687

Timestep Collection Time: 2.23472
Timestep Consumption Time: 2.52030
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.75502

Cumulative Model Updates: 81,976
Cumulative Timesteps: 683,649,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,798.48424
Policy Entropy: 1.91126
Value Function Loss: 0.08172

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.71276

Collected Steps per Second: 22,988.49518
Overall Steps per Second: 10,822.06143

Timestep Collection Time: 2.17561
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62149

Cumulative Model Updates: 81,982
Cumulative Timesteps: 683,699,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 683699392...
Checkpoint 683699392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,609.73243
Policy Entropy: 1.90210
Value Function Loss: 0.08558

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.52413
Value Function Update Magnitude: 0.74136

Collected Steps per Second: 22,115.57111
Overall Steps per Second: 10,636.34689

Timestep Collection Time: 2.26085
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.70086

Cumulative Model Updates: 81,988
Cumulative Timesteps: 683,749,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,580.23303
Policy Entropy: 1.90403
Value Function Loss: 0.08342

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.54414
Value Function Update Magnitude: 0.73102

Collected Steps per Second: 22,654.66048
Overall Steps per Second: 10,622.13098

Timestep Collection Time: 2.20899
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71130

Cumulative Model Updates: 81,994
Cumulative Timesteps: 683,799,436

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 683799436...
Checkpoint 683799436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,581.16394
Policy Entropy: 1.91869
Value Function Loss: 0.08374

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.54325
Value Function Update Magnitude: 0.73363

Collected Steps per Second: 22,314.98098
Overall Steps per Second: 10,589.86649

Timestep Collection Time: 2.24163
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.72357

Cumulative Model Updates: 82,000
Cumulative Timesteps: 683,849,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,740.05655
Policy Entropy: 1.92498
Value Function Loss: 0.07735

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.51938
Value Function Update Magnitude: 0.70815

Collected Steps per Second: 22,906.06781
Overall Steps per Second: 10,847.40300

Timestep Collection Time: 2.18396
Timestep Consumption Time: 2.42783
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.61180

Cumulative Model Updates: 82,006
Cumulative Timesteps: 683,899,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 683899484...
Checkpoint 683899484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,156.00464
Policy Entropy: 1.92395
Value Function Loss: 0.07293

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.50193
Value Function Update Magnitude: 0.69537

Collected Steps per Second: 21,687.23930
Overall Steps per Second: 10,552.42854

Timestep Collection Time: 2.30679
Timestep Consumption Time: 2.43410
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.74090

Cumulative Model Updates: 82,012
Cumulative Timesteps: 683,949,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,429.21360
Policy Entropy: 1.92077
Value Function Loss: 0.07009

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.50266
Value Function Update Magnitude: 0.66486

Collected Steps per Second: 22,375.05042
Overall Steps per Second: 10,507.80978

Timestep Collection Time: 2.23606
Timestep Consumption Time: 2.52535
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76141

Cumulative Model Updates: 82,018
Cumulative Timesteps: 683,999,544

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 683999544...
Checkpoint 683999544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,940.09223
Policy Entropy: 1.94016
Value Function Loss: 0.07288

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.50356
Value Function Update Magnitude: 0.66649

Collected Steps per Second: 21,988.07135
Overall Steps per Second: 10,612.07951

Timestep Collection Time: 2.27623
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.71632

Cumulative Model Updates: 82,024
Cumulative Timesteps: 684,049,594

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,944.23334
Policy Entropy: 1.93942
Value Function Loss: 0.07009

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.51308
Value Function Update Magnitude: 0.68173

Collected Steps per Second: 22,408.48067
Overall Steps per Second: 10,545.22810

Timestep Collection Time: 2.23201
Timestep Consumption Time: 2.51099
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.74300

Cumulative Model Updates: 82,030
Cumulative Timesteps: 684,099,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 684099610...
Checkpoint 684099610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,874.07650
Policy Entropy: 1.94636
Value Function Loss: 0.07186

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.52016
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 22,197.77295
Overall Steps per Second: 10,668.49407

Timestep Collection Time: 2.25410
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.69007

Cumulative Model Updates: 82,036
Cumulative Timesteps: 684,149,646

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,754.42680
Policy Entropy: 1.93307
Value Function Loss: 0.07943

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.50889
Value Function Update Magnitude: 0.61960

Collected Steps per Second: 22,958.49111
Overall Steps per Second: 10,763.46188

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.46770
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.64572

Cumulative Model Updates: 82,042
Cumulative Timesteps: 684,199,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 684199650...
Checkpoint 684199650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,032.13289
Policy Entropy: 1.91512
Value Function Loss: 0.07485

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.47273
Value Function Update Magnitude: 0.69651

Collected Steps per Second: 22,434.20049
Overall Steps per Second: 10,314.75134

Timestep Collection Time: 2.22874
Timestep Consumption Time: 2.61869
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.84743

Cumulative Model Updates: 82,048
Cumulative Timesteps: 684,249,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,072.38352
Policy Entropy: 1.90650
Value Function Loss: 0.07419

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.49712
Value Function Update Magnitude: 0.73253

Collected Steps per Second: 22,789.85869
Overall Steps per Second: 10,789.68268

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.63591

Cumulative Model Updates: 82,054
Cumulative Timesteps: 684,299,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 684299670...
Checkpoint 684299670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,666.52455
Policy Entropy: 1.91346
Value Function Loss: 0.07582

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.52942
Value Function Update Magnitude: 0.73243

Collected Steps per Second: 22,194.31281
Overall Steps per Second: 10,733.50565

Timestep Collection Time: 2.25364
Timestep Consumption Time: 2.40635
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.65999

Cumulative Model Updates: 82,060
Cumulative Timesteps: 684,349,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,757.72795
Policy Entropy: 1.92629
Value Function Loss: 0.07565

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.53747
Value Function Update Magnitude: 0.74371

Collected Steps per Second: 23,113.86907
Overall Steps per Second: 10,844.63203

Timestep Collection Time: 2.16476
Timestep Consumption Time: 2.44913
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.61390

Cumulative Model Updates: 82,066
Cumulative Timesteps: 684,399,724

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 684399724...
Checkpoint 684399724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,292.99466
Policy Entropy: 1.91140
Value Function Loss: 0.07750

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.73843

Collected Steps per Second: 22,145.12693
Overall Steps per Second: 10,632.28907

Timestep Collection Time: 2.25801
Timestep Consumption Time: 2.44502
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.70303

Cumulative Model Updates: 82,072
Cumulative Timesteps: 684,449,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,920.88822
Policy Entropy: 1.89937
Value Function Loss: 0.07555

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.53874
Value Function Update Magnitude: 0.71677

Collected Steps per Second: 22,372.03112
Overall Steps per Second: 10,532.70014

Timestep Collection Time: 2.23556
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.74845

Cumulative Model Updates: 82,078
Cumulative Timesteps: 684,499,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 684499742...
Checkpoint 684499742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,193.68199
Policy Entropy: 1.90237
Value Function Loss: 0.07278

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.51993
Value Function Update Magnitude: 0.70195

Collected Steps per Second: 20,962.68856
Overall Steps per Second: 10,164.50807

Timestep Collection Time: 2.38729
Timestep Consumption Time: 2.53612
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.92341

Cumulative Model Updates: 82,084
Cumulative Timesteps: 684,549,786

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,174.24878
Policy Entropy: 1.90074
Value Function Loss: 0.07939

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.52224
Value Function Update Magnitude: 0.72611

Collected Steps per Second: 21,262.20917
Overall Steps per Second: 10,309.14509

Timestep Collection Time: 2.35178
Timestep Consumption Time: 2.49867
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.85045

Cumulative Model Updates: 82,090
Cumulative Timesteps: 684,599,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 684599790...
Checkpoint 684599790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,611.17079
Policy Entropy: 1.91119
Value Function Loss: 0.07718

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.52595
Value Function Update Magnitude: 0.73454

Collected Steps per Second: 19,494.03364
Overall Steps per Second: 9,849.38530

Timestep Collection Time: 2.56571
Timestep Consumption Time: 2.51238
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 5.07808

Cumulative Model Updates: 82,096
Cumulative Timesteps: 684,649,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,123.60626
Policy Entropy: 1.90375
Value Function Loss: 0.08134

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.53620
Value Function Update Magnitude: 0.69932

Collected Steps per Second: 20,081.04466
Overall Steps per Second: 9,844.71315

Timestep Collection Time: 2.49001
Timestep Consumption Time: 2.58906
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 5.07907

Cumulative Model Updates: 82,102
Cumulative Timesteps: 684,699,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 684699808...
Checkpoint 684699808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,620.08285
Policy Entropy: 1.92135
Value Function Loss: 0.08057

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.64277

Collected Steps per Second: 21,967.61867
Overall Steps per Second: 10,523.56547

Timestep Collection Time: 2.27717
Timestep Consumption Time: 2.47635
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.75352

Cumulative Model Updates: 82,108
Cumulative Timesteps: 684,749,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,324.37392
Policy Entropy: 1.91580
Value Function Loss: 0.08213

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.14774
Policy Update Magnitude: 0.53041
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 22,622.38965
Overall Steps per Second: 10,433.82924

Timestep Collection Time: 2.21073
Timestep Consumption Time: 2.58252
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.79325

Cumulative Model Updates: 82,114
Cumulative Timesteps: 684,799,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 684799844...
Checkpoint 684799844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,052.72124
Policy Entropy: 1.90975
Value Function Loss: 0.08560

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.15483
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.56201

Collected Steps per Second: 22,398.36449
Overall Steps per Second: 10,668.86751

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.68766

Cumulative Model Updates: 82,120
Cumulative Timesteps: 684,849,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,627.61191
Policy Entropy: 1.90395
Value Function Loss: 0.08221

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.15288
Policy Update Magnitude: 0.52399
Value Function Update Magnitude: 0.70134

Collected Steps per Second: 22,520.57511
Overall Steps per Second: 10,521.87051

Timestep Collection Time: 2.22055
Timestep Consumption Time: 2.53222
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.75277

Cumulative Model Updates: 82,126
Cumulative Timesteps: 684,899,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 684899864...
Checkpoint 684899864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,674.17487
Policy Entropy: 1.89230
Value Function Loss: 0.08178

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.52828
Value Function Update Magnitude: 0.74497

Collected Steps per Second: 22,412.60190
Overall Steps per Second: 10,660.22900

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.69089

Cumulative Model Updates: 82,132
Cumulative Timesteps: 684,949,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,153.88328
Policy Entropy: 1.90361
Value Function Loss: 0.08170

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.53628
Value Function Update Magnitude: 0.68251

Collected Steps per Second: 22,838.13613
Overall Steps per Second: 10,815.47880

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.62448

Cumulative Model Updates: 82,138
Cumulative Timesteps: 684,999,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 684999886...
Checkpoint 684999886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,489.39639
Policy Entropy: 1.89280
Value Function Loss: 0.07666

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.61005

Collected Steps per Second: 22,381.73771
Overall Steps per Second: 10,682.23300

Timestep Collection Time: 2.23432
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.68142

Cumulative Model Updates: 82,144
Cumulative Timesteps: 685,049,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,840.51750
Policy Entropy: 1.90740
Value Function Loss: 0.07275

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.63403

Collected Steps per Second: 22,467.99988
Overall Steps per Second: 10,568.15796

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.73328

Cumulative Model Updates: 82,150
Cumulative Timesteps: 685,099,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 685099916...
Checkpoint 685099916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,252.63765
Policy Entropy: 1.90931
Value Function Loss: 0.07442

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.53111
Value Function Update Magnitude: 0.58321

Collected Steps per Second: 22,094.84972
Overall Steps per Second: 10,577.91560

Timestep Collection Time: 2.26388
Timestep Consumption Time: 2.46484
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.72872

Cumulative Model Updates: 82,156
Cumulative Timesteps: 685,149,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,824.27816
Policy Entropy: 1.91409
Value Function Loss: 0.08038

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.56413

Collected Steps per Second: 22,220.23169
Overall Steps per Second: 10,607.57275

Timestep Collection Time: 2.25065
Timestep Consumption Time: 2.46390
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.71456

Cumulative Model Updates: 82,162
Cumulative Timesteps: 685,199,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 685199946...
Checkpoint 685199946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,766.72896
Policy Entropy: 1.91813
Value Function Loss: 0.08261

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.52731
Value Function Update Magnitude: 0.48790

Collected Steps per Second: 22,392.08398
Overall Steps per Second: 10,670.53892

Timestep Collection Time: 2.23365
Timestep Consumption Time: 2.45365
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68730

Cumulative Model Updates: 82,168
Cumulative Timesteps: 685,249,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,071.33041
Policy Entropy: 1.91893
Value Function Loss: 0.08557

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.51830
Value Function Update Magnitude: 0.49507

Collected Steps per Second: 22,471.73038
Overall Steps per Second: 10,676.94778

Timestep Collection Time: 2.22555
Timestep Consumption Time: 2.45856
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.68411

Cumulative Model Updates: 82,174
Cumulative Timesteps: 685,299,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 685299974...
Checkpoint 685299974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,055.47831
Policy Entropy: 1.92133
Value Function Loss: 0.07909

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.50513
Value Function Update Magnitude: 0.64753

Collected Steps per Second: 22,527.39889
Overall Steps per Second: 10,668.35338

Timestep Collection Time: 2.22067
Timestep Consumption Time: 2.46852
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.68920

Cumulative Model Updates: 82,180
Cumulative Timesteps: 685,350,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,442.79163
Policy Entropy: 1.91156
Value Function Loss: 0.07771

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.48406
Value Function Update Magnitude: 0.64677

Collected Steps per Second: 22,867.63510
Overall Steps per Second: 10,782.84266

Timestep Collection Time: 2.18676
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.63755

Cumulative Model Updates: 82,186
Cumulative Timesteps: 685,400,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 685400006...
Checkpoint 685400006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,139.28992
Policy Entropy: 1.90218
Value Function Loss: 0.08151

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.14958
Policy Update Magnitude: 0.51041
Value Function Update Magnitude: 0.64332

Collected Steps per Second: 22,319.14776
Overall Steps per Second: 10,666.76466

Timestep Collection Time: 2.24211
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.69139

Cumulative Model Updates: 82,192
Cumulative Timesteps: 685,450,048

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,347.67570
Policy Entropy: 1.89224
Value Function Loss: 0.07905

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.53783
Value Function Update Magnitude: 0.55623

Collected Steps per Second: 22,770.10936
Overall Steps per Second: 10,631.21348

Timestep Collection Time: 2.19735
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.70633

Cumulative Model Updates: 82,198
Cumulative Timesteps: 685,500,082

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 685500082...
Checkpoint 685500082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,157.31012
Policy Entropy: 1.90030
Value Function Loss: 0.07326

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.53025
Value Function Update Magnitude: 0.62087

Collected Steps per Second: 22,219.92387
Overall Steps per Second: 10,541.38778

Timestep Collection Time: 2.25185
Timestep Consumption Time: 2.49477
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.74662

Cumulative Model Updates: 82,204
Cumulative Timesteps: 685,550,118

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,550.07727
Policy Entropy: 1.90806
Value Function Loss: 0.08345

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.52994
Value Function Update Magnitude: 0.60150

Collected Steps per Second: 23,020.10827
Overall Steps per Second: 10,826.07505

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.44803
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.62143

Cumulative Model Updates: 82,210
Cumulative Timesteps: 685,600,150

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 685600150...
Checkpoint 685600150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,154.93367
Policy Entropy: 1.92096
Value Function Loss: 0.08173

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.66427

Collected Steps per Second: 22,502.08300
Overall Steps per Second: 10,718.26059

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.66699

Cumulative Model Updates: 82,216
Cumulative Timesteps: 685,650,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,378.98706
Policy Entropy: 1.92579
Value Function Loss: 0.08078

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.69815

Collected Steps per Second: 22,202.73804
Overall Steps per Second: 10,507.11947

Timestep Collection Time: 2.25242
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.75963

Cumulative Model Updates: 82,222
Cumulative Timesteps: 685,700,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 685700182...
Checkpoint 685700182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,645.04514
Policy Entropy: 1.93370
Value Function Loss: 0.07424

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.52077
Value Function Update Magnitude: 0.63278

Collected Steps per Second: 22,194.83533
Overall Steps per Second: 10,612.66033

Timestep Collection Time: 2.25323
Timestep Consumption Time: 2.45907
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.71230

Cumulative Model Updates: 82,228
Cumulative Timesteps: 685,750,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,102.58804
Policy Entropy: 1.91857
Value Function Loss: 0.07075

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.52075
Value Function Update Magnitude: 0.59003

Collected Steps per Second: 22,133.90927
Overall Steps per Second: 10,478.05366

Timestep Collection Time: 2.25934
Timestep Consumption Time: 2.51330
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.77264

Cumulative Model Updates: 82,234
Cumulative Timesteps: 685,800,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 685800200...
Checkpoint 685800200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,620.52275
Policy Entropy: 1.91541
Value Function Loss: 0.06970

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.52505
Value Function Update Magnitude: 0.57530

Collected Steps per Second: 22,060.72166
Overall Steps per Second: 10,647.90533

Timestep Collection Time: 2.26810
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.69914

Cumulative Model Updates: 82,240
Cumulative Timesteps: 685,850,236

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,175.60898
Policy Entropy: 1.91976
Value Function Loss: 0.07147

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.52234
Value Function Update Magnitude: 0.56700

Collected Steps per Second: 22,625.71771
Overall Steps per Second: 10,557.94207

Timestep Collection Time: 2.21076
Timestep Consumption Time: 2.52691
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.73767

Cumulative Model Updates: 82,246
Cumulative Timesteps: 685,900,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 685900256...
Checkpoint 685900256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,483.36455
Policy Entropy: 1.93439
Value Function Loss: 0.07377

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.52307
Value Function Update Magnitude: 0.57800

Collected Steps per Second: 22,272.15918
Overall Steps per Second: 10,522.49415

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.75382

Cumulative Model Updates: 82,252
Cumulative Timesteps: 685,950,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,231.47663
Policy Entropy: 1.93266
Value Function Loss: 0.07678

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.52276
Value Function Update Magnitude: 0.66272

Collected Steps per Second: 22,861.44554
Overall Steps per Second: 10,811.65874

Timestep Collection Time: 2.18814
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.62686

Cumulative Model Updates: 82,258
Cumulative Timesteps: 686,000,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 686000302...
Checkpoint 686000302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,597.69100
Policy Entropy: 1.92003
Value Function Loss: 0.07507

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.52076
Value Function Update Magnitude: 0.66263

Collected Steps per Second: 22,164.88571
Overall Steps per Second: 10,641.32434

Timestep Collection Time: 2.25681
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.70073

Cumulative Model Updates: 82,264
Cumulative Timesteps: 686,050,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,882.84533
Policy Entropy: 1.93281
Value Function Loss: 0.07836

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.52968
Value Function Update Magnitude: 0.62594

Collected Steps per Second: 22,754.97070
Overall Steps per Second: 10,873.04335

Timestep Collection Time: 2.19855
Timestep Consumption Time: 2.40255
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60110

Cumulative Model Updates: 82,270
Cumulative Timesteps: 686,100,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 686100352...
Checkpoint 686100352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,450.06434
Policy Entropy: 1.92722
Value Function Loss: 0.07979

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.53500
Value Function Update Magnitude: 0.65242

Collected Steps per Second: 22,280.28889
Overall Steps per Second: 10,694.68993

Timestep Collection Time: 2.24458
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.67615

Cumulative Model Updates: 82,276
Cumulative Timesteps: 686,150,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,606.90818
Policy Entropy: 1.92257
Value Function Loss: 0.07992

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.53747
Value Function Update Magnitude: 0.71861

Collected Steps per Second: 22,340.04489
Overall Steps per Second: 10,506.41915

Timestep Collection Time: 2.23894
Timestep Consumption Time: 2.52177
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.76071

Cumulative Model Updates: 82,282
Cumulative Timesteps: 686,200,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 686200380...
Checkpoint 686200380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,034.76537
Policy Entropy: 1.90741
Value Function Loss: 0.08030

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.70007

Collected Steps per Second: 21,869.80110
Overall Steps per Second: 10,583.01290

Timestep Collection Time: 2.28726
Timestep Consumption Time: 2.43937
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.72663

Cumulative Model Updates: 82,288
Cumulative Timesteps: 686,250,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,986.59949
Policy Entropy: 1.89149
Value Function Loss: 0.08248

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.61346

Collected Steps per Second: 22,518.56744
Overall Steps per Second: 10,601.22446

Timestep Collection Time: 2.22146
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.71870

Cumulative Model Updates: 82,294
Cumulative Timesteps: 686,300,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 686300426...
Checkpoint 686300426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,874.85597
Policy Entropy: 1.89157
Value Function Loss: 0.08403

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.55203
Value Function Update Magnitude: 0.52228

Collected Steps per Second: 21,726.39935
Overall Steps per Second: 10,524.85977

Timestep Collection Time: 2.30162
Timestep Consumption Time: 2.44960
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.75123

Cumulative Model Updates: 82,300
Cumulative Timesteps: 686,350,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,808.84424
Policy Entropy: 1.89316
Value Function Loss: 0.08709

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.55190

Collected Steps per Second: 22,732.46978
Overall Steps per Second: 10,851.80813

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.40822
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.60790

Cumulative Model Updates: 82,306
Cumulative Timesteps: 686,400,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 686400436...
Checkpoint 686400436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,129.68178
Policy Entropy: 1.91689
Value Function Loss: 0.07912

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.50316

Collected Steps per Second: 21,549.75219
Overall Steps per Second: 10,362.21134

Timestep Collection Time: 2.32244
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.82986

Cumulative Model Updates: 82,312
Cumulative Timesteps: 686,450,484

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,073.63339
Policy Entropy: 1.91018
Value Function Loss: 0.08057

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.44428

Collected Steps per Second: 22,668.56362
Overall Steps per Second: 10,754.68861

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.44393
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.65006

Cumulative Model Updates: 82,318
Cumulative Timesteps: 686,500,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 686500494...
Checkpoint 686500494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,955.51213
Policy Entropy: 1.89113
Value Function Loss: 0.08101

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.40037

Collected Steps per Second: 22,496.73354
Overall Steps per Second: 10,763.38200

Timestep Collection Time: 2.22343
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.64724

Cumulative Model Updates: 82,324
Cumulative Timesteps: 686,550,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,610.07135
Policy Entropy: 1.87380
Value Function Loss: 0.08877

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.38695

Collected Steps per Second: 22,906.78437
Overall Steps per Second: 10,818.10134

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.43961
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.62281

Cumulative Model Updates: 82,330
Cumulative Timesteps: 686,600,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 686600524...
Checkpoint 686600524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,772.67726
Policy Entropy: 1.89900
Value Function Loss: 0.08401

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.55690
Value Function Update Magnitude: 0.37804

Collected Steps per Second: 22,353.16209
Overall Steps per Second: 10,664.52947

Timestep Collection Time: 2.23780
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.69050

Cumulative Model Updates: 82,336
Cumulative Timesteps: 686,650,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,115.44174
Policy Entropy: 1.89284
Value Function Loss: 0.08577

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.35615

Collected Steps per Second: 21,725.23956
Overall Steps per Second: 10,429.94870

Timestep Collection Time: 2.30258
Timestep Consumption Time: 2.49361
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.79619

Cumulative Model Updates: 82,342
Cumulative Timesteps: 686,700,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 686700570...
Checkpoint 686700570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,541.06795
Policy Entropy: 1.89670
Value Function Loss: 0.08659

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.48313

Collected Steps per Second: 22,171.64681
Overall Steps per Second: 10,681.48958

Timestep Collection Time: 2.25612
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.68305

Cumulative Model Updates: 82,348
Cumulative Timesteps: 686,750,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,162.87953
Policy Entropy: 1.89402
Value Function Loss: 0.08452

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.55780
Value Function Update Magnitude: 0.66071

Collected Steps per Second: 22,415.12989
Overall Steps per Second: 10,566.29799

Timestep Collection Time: 2.23206
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.73505

Cumulative Model Updates: 82,354
Cumulative Timesteps: 686,800,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 686800624...
Checkpoint 686800624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,574.45260
Policy Entropy: 1.89958
Value Function Loss: 0.07991

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.70763

Collected Steps per Second: 21,991.74057
Overall Steps per Second: 10,501.41198

Timestep Collection Time: 2.27413
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.76241

Cumulative Model Updates: 82,360
Cumulative Timesteps: 686,850,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,485.96223
Policy Entropy: 1.91262
Value Function Loss: 0.08843

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.66815

Collected Steps per Second: 22,442.27283
Overall Steps per Second: 10,474.14549

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.54725
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.77652

Cumulative Model Updates: 82,366
Cumulative Timesteps: 686,900,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 686900666...
Checkpoint 686900666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,384.77931
Policy Entropy: 1.90760
Value Function Loss: 0.09197

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.68608

Collected Steps per Second: 22,422.14075
Overall Steps per Second: 10,649.93064

Timestep Collection Time: 2.23092
Timestep Consumption Time: 2.46601
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.69693

Cumulative Model Updates: 82,372
Cumulative Timesteps: 686,950,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,528.17522
Policy Entropy: 1.91803
Value Function Loss: 0.09226

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15708
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.69711

Collected Steps per Second: 22,841.58193
Overall Steps per Second: 10,805.06178

Timestep Collection Time: 2.18995
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62950

Cumulative Model Updates: 82,378
Cumulative Timesteps: 687,000,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 687000710...
Checkpoint 687000710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,578.45823
Policy Entropy: 1.90461
Value Function Loss: 0.08567

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.17074
Policy Update Magnitude: 0.51026
Value Function Update Magnitude: 0.67665

Collected Steps per Second: 22,440.56762
Overall Steps per Second: 10,721.23346

Timestep Collection Time: 2.22909
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.66569

Cumulative Model Updates: 82,384
Cumulative Timesteps: 687,050,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,134.00596
Policy Entropy: 1.90038
Value Function Loss: 0.07930

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.45951
Value Function Update Magnitude: 0.54753

Collected Steps per Second: 22,591.88211
Overall Steps per Second: 10,635.82491

Timestep Collection Time: 2.21398
Timestep Consumption Time: 2.48880
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.70279

Cumulative Model Updates: 82,390
Cumulative Timesteps: 687,100,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 687100750...
Checkpoint 687100750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,450.93311
Policy Entropy: 1.91073
Value Function Loss: 0.08089

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.47099
Value Function Update Magnitude: 0.54414

Collected Steps per Second: 22,824.78190
Overall Steps per Second: 10,842.00565

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.42216
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.61372

Cumulative Model Updates: 82,396
Cumulative Timesteps: 687,150,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,037.56022
Policy Entropy: 1.90366
Value Function Loss: 0.08362

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.49365
Value Function Update Magnitude: 0.53680

Collected Steps per Second: 22,380.87345
Overall Steps per Second: 10,543.04256

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.50982
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.74512

Cumulative Model Updates: 82,402
Cumulative Timesteps: 687,200,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 687200800...
Checkpoint 687200800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,547.02434
Policy Entropy: 1.89733
Value Function Loss: 0.08696

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.47741
Value Function Update Magnitude: 0.57791

Collected Steps per Second: 21,929.76589
Overall Steps per Second: 10,598.67124

Timestep Collection Time: 2.28001
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.71757

Cumulative Model Updates: 82,408
Cumulative Timesteps: 687,250,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,757.93285
Policy Entropy: 1.88059
Value Function Loss: 0.08676

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.51847
Value Function Update Magnitude: 0.66742

Collected Steps per Second: 21,825.90624
Overall Steps per Second: 10,483.05669

Timestep Collection Time: 2.29214
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.77227

Cumulative Model Updates: 82,414
Cumulative Timesteps: 687,300,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 687300828...
Checkpoint 687300828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,996.75470
Policy Entropy: 1.88581
Value Function Loss: 0.08424

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.77207

Collected Steps per Second: 22,496.50168
Overall Steps per Second: 10,684.60733

Timestep Collection Time: 2.22292
Timestep Consumption Time: 2.45745
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.68038

Cumulative Model Updates: 82,420
Cumulative Timesteps: 687,350,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,195.17058
Policy Entropy: 1.89142
Value Function Loss: 0.08211

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.75341

Collected Steps per Second: 22,637.03645
Overall Steps per Second: 10,763.22506

Timestep Collection Time: 2.20983
Timestep Consumption Time: 2.43785
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.64768

Cumulative Model Updates: 82,426
Cumulative Timesteps: 687,400,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 687400860...
Checkpoint 687400860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,367.39303
Policy Entropy: 1.88466
Value Function Loss: 0.09045

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.56241
Value Function Update Magnitude: 0.65718

Collected Steps per Second: 22,325.68438
Overall Steps per Second: 10,677.62070

Timestep Collection Time: 2.24011
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.68382

Cumulative Model Updates: 82,432
Cumulative Timesteps: 687,450,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,097.55548
Policy Entropy: 1.87498
Value Function Loss: 0.09007

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.56154
Value Function Update Magnitude: 0.71388

Collected Steps per Second: 22,713.89397
Overall Steps per Second: 10,711.07253

Timestep Collection Time: 2.20244
Timestep Consumption Time: 2.46805
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.67049

Cumulative Model Updates: 82,438
Cumulative Timesteps: 687,500,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 687500898...
Checkpoint 687500898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,654.90161
Policy Entropy: 1.87702
Value Function Loss: 0.08766

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.74753

Collected Steps per Second: 22,806.51208
Overall Steps per Second: 10,819.70442

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62379

Cumulative Model Updates: 82,444
Cumulative Timesteps: 687,550,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,814.79802
Policy Entropy: 1.88545
Value Function Loss: 0.07618

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.74016

Collected Steps per Second: 22,763.48737
Overall Steps per Second: 10,730.43171

Timestep Collection Time: 2.19694
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.66058

Cumulative Model Updates: 82,450
Cumulative Timesteps: 687,600,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 687600936...
Checkpoint 687600936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,901.65481
Policy Entropy: 1.89533
Value Function Loss: 0.07433

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.53492
Value Function Update Magnitude: 0.68257

Collected Steps per Second: 22,203.84903
Overall Steps per Second: 10,510.60318

Timestep Collection Time: 2.25195
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.75729

Cumulative Model Updates: 82,456
Cumulative Timesteps: 687,650,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,606.52353
Policy Entropy: 1.88828
Value Function Loss: 0.07385

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.53052
Value Function Update Magnitude: 0.65378

Collected Steps per Second: 22,302.18724
Overall Steps per Second: 10,570.39901

Timestep Collection Time: 2.24301
Timestep Consumption Time: 2.48945
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.73246

Cumulative Model Updates: 82,462
Cumulative Timesteps: 687,700,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 687700962...
Checkpoint 687700962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,958.72741
Policy Entropy: 1.88409
Value Function Loss: 0.07980

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.60869

Collected Steps per Second: 21,714.43173
Overall Steps per Second: 10,456.93099

Timestep Collection Time: 2.30271
Timestep Consumption Time: 2.47900
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.78171

Cumulative Model Updates: 82,468
Cumulative Timesteps: 687,750,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,228.70145
Policy Entropy: 1.87947
Value Function Loss: 0.07964

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.55303
Value Function Update Magnitude: 0.60764

Collected Steps per Second: 22,357.99055
Overall Steps per Second: 10,544.73987

Timestep Collection Time: 2.23678
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.74265

Cumulative Model Updates: 82,474
Cumulative Timesteps: 687,800,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 687800974...
Checkpoint 687800974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,249.77153
Policy Entropy: 1.86727
Value Function Loss: 0.08568

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.55612
Value Function Update Magnitude: 0.66184

Collected Steps per Second: 21,498.06914
Overall Steps per Second: 10,492.43475

Timestep Collection Time: 2.32588
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.76553

Cumulative Model Updates: 82,480
Cumulative Timesteps: 687,850,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,051.91329
Policy Entropy: 1.86614
Value Function Loss: 0.08330

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.55608
Value Function Update Magnitude: 0.66851

Collected Steps per Second: 22,883.51915
Overall Steps per Second: 10,578.25072

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.54363
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.73027

Cumulative Model Updates: 82,486
Cumulative Timesteps: 687,901,014

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 687901014...
Checkpoint 687901014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,033.16285
Policy Entropy: 1.86995
Value Function Loss: 0.08142

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.69308

Collected Steps per Second: 22,497.62813
Overall Steps per Second: 10,562.30045

Timestep Collection Time: 2.22272
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.73439

Cumulative Model Updates: 82,492
Cumulative Timesteps: 687,951,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,807.78563
Policy Entropy: 1.87285
Value Function Loss: 0.07769

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.68432

Collected Steps per Second: 22,800.83225
Overall Steps per Second: 10,797.92328

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.43937
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.63385

Cumulative Model Updates: 82,498
Cumulative Timesteps: 688,001,056

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 688001056...
Checkpoint 688001056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,801.74446
Policy Entropy: 1.86075
Value Function Loss: 0.07623

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.68501

Collected Steps per Second: 22,246.50663
Overall Steps per Second: 10,662.23356

Timestep Collection Time: 2.24817
Timestep Consumption Time: 2.44259
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.69076

Cumulative Model Updates: 82,504
Cumulative Timesteps: 688,051,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,127.51222
Policy Entropy: 1.85721
Value Function Loss: 0.07863

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.55489
Value Function Update Magnitude: 0.64697

Collected Steps per Second: 22,622.09634
Overall Steps per Second: 10,581.41289

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.72716

Cumulative Model Updates: 82,510
Cumulative Timesteps: 688,101,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 688101090...
Checkpoint 688101090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,941.43641
Policy Entropy: 1.84181
Value Function Loss: 0.08542

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.57635

Collected Steps per Second: 22,570.77672
Overall Steps per Second: 10,602.51770

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.50111
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71680

Cumulative Model Updates: 82,516
Cumulative Timesteps: 688,151,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,080.41751
Policy Entropy: 1.84942
Value Function Loss: 0.09391

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14982
Policy Update Magnitude: 0.53351
Value Function Update Magnitude: 0.51933

Collected Steps per Second: 22,406.80799
Overall Steps per Second: 10,561.46358

Timestep Collection Time: 2.23352
Timestep Consumption Time: 2.50503
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.73855

Cumulative Model Updates: 82,522
Cumulative Timesteps: 688,201,146

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 688201146...
Checkpoint 688201146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,332.03438
Policy Entropy: 1.86744
Value Function Loss: 0.10151

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.16200
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.60902

Collected Steps per Second: 21,947.79265
Overall Steps per Second: 10,595.63915

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.72024

Cumulative Model Updates: 82,528
Cumulative Timesteps: 688,251,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,795.74308
Policy Entropy: 1.85910
Value Function Loss: 0.09557

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16371
Policy Update Magnitude: 0.56298
Value Function Update Magnitude: 0.54741

Collected Steps per Second: 22,218.87605
Overall Steps per Second: 10,527.91910

Timestep Collection Time: 2.25133
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.75137

Cumulative Model Updates: 82,534
Cumulative Timesteps: 688,301,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 688301182...
Checkpoint 688301182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,323.41336
Policy Entropy: 1.84982
Value Function Loss: 0.09405

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.56319
Value Function Update Magnitude: 0.58300

Collected Steps per Second: 21,292.22864
Overall Steps per Second: 10,245.39264

Timestep Collection Time: 2.34884
Timestep Consumption Time: 2.53258
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.88141

Cumulative Model Updates: 82,540
Cumulative Timesteps: 688,351,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,613.65238
Policy Entropy: 1.84262
Value Function Loss: 0.07936

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.64345

Collected Steps per Second: 22,845.20964
Overall Steps per Second: 10,754.93864

Timestep Collection Time: 2.18952
Timestep Consumption Time: 2.46137
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.65089

Cumulative Model Updates: 82,546
Cumulative Timesteps: 688,401,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 688401214...
Checkpoint 688401214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,878.33941
Policy Entropy: 1.84986
Value Function Loss: 0.08244

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.55221
Value Function Update Magnitude: 0.62795

Collected Steps per Second: 22,544.27616
Overall Steps per Second: 10,624.82759

Timestep Collection Time: 2.21875
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.70784

Cumulative Model Updates: 82,552
Cumulative Timesteps: 688,451,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,081.72273
Policy Entropy: 1.85572
Value Function Loss: 0.08381

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.60338

Collected Steps per Second: 22,967.01562
Overall Steps per Second: 10,756.53824

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.47150
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.64871

Cumulative Model Updates: 82,558
Cumulative Timesteps: 688,501,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 688501238...
Checkpoint 688501238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,374.64437
Policy Entropy: 1.84186
Value Function Loss: 0.08459

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.68466

Collected Steps per Second: 22,259.14970
Overall Steps per Second: 10,534.36810

Timestep Collection Time: 2.24681
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.74751

Cumulative Model Updates: 82,564
Cumulative Timesteps: 688,551,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,114.63283
Policy Entropy: 1.84252
Value Function Loss: 0.08178

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.72045

Collected Steps per Second: 22,866.58657
Overall Steps per Second: 10,724.16644

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.47627
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.66330

Cumulative Model Updates: 82,570
Cumulative Timesteps: 688,601,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 688601260...
Checkpoint 688601260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,393.19367
Policy Entropy: 1.83850
Value Function Loss: 0.08703

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.15776
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.69169

Collected Steps per Second: 22,440.36350
Overall Steps per Second: 10,641.70788

Timestep Collection Time: 2.22848
Timestep Consumption Time: 2.47076
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.69925

Cumulative Model Updates: 82,576
Cumulative Timesteps: 688,651,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,563.71744
Policy Entropy: 1.83658
Value Function Loss: 0.08334

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.50211
Value Function Update Magnitude: 0.65315

Collected Steps per Second: 22,229.51761
Overall Steps per Second: 10,527.59905

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.75189

Cumulative Model Updates: 82,582
Cumulative Timesteps: 688,701,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 688701294...
Checkpoint 688701294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,301.48500
Policy Entropy: 1.82369
Value Function Loss: 0.08333

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.51260
Value Function Update Magnitude: 0.57424

Collected Steps per Second: 21,812.26339
Overall Steps per Second: 10,583.01745

Timestep Collection Time: 2.29311
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.72625

Cumulative Model Updates: 82,588
Cumulative Timesteps: 688,751,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,679.83152
Policy Entropy: 1.81723
Value Function Loss: 0.08110

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.55714

Collected Steps per Second: 22,219.76254
Overall Steps per Second: 10,503.09678

Timestep Collection Time: 2.25052
Timestep Consumption Time: 2.51055
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.76107

Cumulative Model Updates: 82,594
Cumulative Timesteps: 688,801,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 688801318...
Checkpoint 688801318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,531.04602
Policy Entropy: 1.81890
Value Function Loss: 0.08202

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.60279

Collected Steps per Second: 21,797.54313
Overall Steps per Second: 10,594.33297

Timestep Collection Time: 2.29521
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.72234

Cumulative Model Updates: 82,600
Cumulative Timesteps: 688,851,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,441.94957
Policy Entropy: 1.82644
Value Function Loss: 0.07547

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.56038
Value Function Update Magnitude: 0.64877

Collected Steps per Second: 22,932.09638
Overall Steps per Second: 10,787.78524

Timestep Collection Time: 2.18122
Timestep Consumption Time: 2.45550
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63673

Cumulative Model Updates: 82,606
Cumulative Timesteps: 688,901,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 688901368...
Checkpoint 688901368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,832.67323
Policy Entropy: 1.83397
Value Function Loss: 0.07137

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.53413
Value Function Update Magnitude: 0.63451

Collected Steps per Second: 22,322.38302
Overall Steps per Second: 10,648.89959

Timestep Collection Time: 2.24044
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.69645

Cumulative Model Updates: 82,612
Cumulative Timesteps: 688,951,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,518.25643
Policy Entropy: 1.83316
Value Function Loss: 0.07365

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.53019
Value Function Update Magnitude: 0.62067

Collected Steps per Second: 22,829.12602
Overall Steps per Second: 10,696.63989

Timestep Collection Time: 2.19150
Timestep Consumption Time: 2.48567
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.67717

Cumulative Model Updates: 82,618
Cumulative Timesteps: 689,001,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 689001410...
Checkpoint 689001410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,598.12215
Policy Entropy: 1.83323
Value Function Loss: 0.08129

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.59233

Collected Steps per Second: 22,470.77712
Overall Steps per Second: 10,619.58322

Timestep Collection Time: 2.22538
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70885

Cumulative Model Updates: 82,624
Cumulative Timesteps: 689,051,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,336.07826
Policy Entropy: 1.83256
Value Function Loss: 0.08207

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.69076

Collected Steps per Second: 22,753.63373
Overall Steps per Second: 10,786.75501

Timestep Collection Time: 2.19798
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.63643

Cumulative Model Updates: 82,630
Cumulative Timesteps: 689,101,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 689101428...
Checkpoint 689101428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,866.61532
Policy Entropy: 1.83538
Value Function Loss: 0.08052

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.73300

Collected Steps per Second: 22,372.17316
Overall Steps per Second: 10,599.21572

Timestep Collection Time: 2.23572
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71903

Cumulative Model Updates: 82,636
Cumulative Timesteps: 689,151,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,234.61629
Policy Entropy: 1.82779
Value Function Loss: 0.07686

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.52737
Value Function Update Magnitude: 0.68870

Collected Steps per Second: 22,240.57616
Overall Steps per Second: 10,527.45324

Timestep Collection Time: 2.24850
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.75025

Cumulative Model Updates: 82,642
Cumulative Timesteps: 689,201,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 689201454...
Checkpoint 689201454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,119.81917
Policy Entropy: 1.83365
Value Function Loss: 0.08227

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.54621
Value Function Update Magnitude: 0.64338

Collected Steps per Second: 22,312.54916
Overall Steps per Second: 10,539.39312

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.74506

Cumulative Model Updates: 82,648
Cumulative Timesteps: 689,251,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,348.60197
Policy Entropy: 1.84065
Value Function Loss: 0.08208

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.73632

Collected Steps per Second: 21,129.06486
Overall Steps per Second: 10,413.81418

Timestep Collection Time: 2.36698
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.80247

Cumulative Model Updates: 82,654
Cumulative Timesteps: 689,301,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 689301476...
Checkpoint 689301476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,124.47560
Policy Entropy: 1.84431
Value Function Loss: 0.07961

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.74655

Collected Steps per Second: 20,820.11366
Overall Steps per Second: 10,371.29200

Timestep Collection Time: 2.40220
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.82235

Cumulative Model Updates: 82,660
Cumulative Timesteps: 689,351,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,635.10473
Policy Entropy: 1.83765
Value Function Loss: 0.07562

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.53454
Value Function Update Magnitude: 0.71636

Collected Steps per Second: 21,706.65105
Overall Steps per Second: 10,714.65401

Timestep Collection Time: 2.30427
Timestep Consumption Time: 2.36392
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.66819

Cumulative Model Updates: 82,666
Cumulative Timesteps: 689,401,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 689401508...
Checkpoint 689401508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,344.52064
Policy Entropy: 1.83271
Value Function Loss: 0.07792

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.63118

Collected Steps per Second: 21,365.11926
Overall Steps per Second: 10,618.92142

Timestep Collection Time: 2.34214
Timestep Consumption Time: 2.37021
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71234

Cumulative Model Updates: 82,672
Cumulative Timesteps: 689,451,548

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,446.35237
Policy Entropy: 1.82966
Value Function Loss: 0.09014

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.55623
Value Function Update Magnitude: 0.69215

Collected Steps per Second: 22,388.02529
Overall Steps per Second: 10,745.62869

Timestep Collection Time: 2.23343
Timestep Consumption Time: 2.41981
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.65324

Cumulative Model Updates: 82,678
Cumulative Timesteps: 689,501,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 689501550...
Checkpoint 689501550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,618.26208
Policy Entropy: 1.83065
Value Function Loss: 0.09897

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.57136

Collected Steps per Second: 21,825.78047
Overall Steps per Second: 10,640.88165

Timestep Collection Time: 2.29160
Timestep Consumption Time: 2.40876
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.70036

Cumulative Model Updates: 82,684
Cumulative Timesteps: 689,551,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,380.19745
Policy Entropy: 1.85481
Value Function Loss: 0.09991

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.49539

Collected Steps per Second: 22,325.17985
Overall Steps per Second: 10,670.83513

Timestep Collection Time: 2.23971
Timestep Consumption Time: 2.44614
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.68586

Cumulative Model Updates: 82,690
Cumulative Timesteps: 689,601,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 689601568...
Checkpoint 689601568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,351.55032
Policy Entropy: 1.86461
Value Function Loss: 0.09387

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.17589
Policy Update Magnitude: 0.50162
Value Function Update Magnitude: 0.49800

Collected Steps per Second: 21,371.48871
Overall Steps per Second: 10,630.38294

Timestep Collection Time: 2.34069
Timestep Consumption Time: 2.36507
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.70576

Cumulative Model Updates: 82,696
Cumulative Timesteps: 689,651,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,473.90415
Policy Entropy: 1.87550
Value Function Loss: 0.08594

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.17116
Policy Update Magnitude: 0.48118
Value Function Update Magnitude: 0.54321

Collected Steps per Second: 22,041.62988
Overall Steps per Second: 10,625.73637

Timestep Collection Time: 2.26871
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.70612

Cumulative Model Updates: 82,702
Cumulative Timesteps: 689,701,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 689701598...
Checkpoint 689701598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,552.32336
Policy Entropy: 1.85167
Value Function Loss: 0.08542

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15424
Policy Update Magnitude: 0.49627
Value Function Update Magnitude: 0.54151

Collected Steps per Second: 21,677.85130
Overall Steps per Second: 10,604.24771

Timestep Collection Time: 2.30733
Timestep Consumption Time: 2.40946
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.71679

Cumulative Model Updates: 82,708
Cumulative Timesteps: 689,751,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,704.05965
Policy Entropy: 1.83950
Value Function Loss: 0.08844

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.58918

Collected Steps per Second: 21,914.72707
Overall Steps per Second: 10,758.88736

Timestep Collection Time: 2.28166
Timestep Consumption Time: 2.36584
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.64751

Cumulative Model Updates: 82,714
Cumulative Timesteps: 689,801,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 689801618...
Checkpoint 689801618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,956.92236
Policy Entropy: 1.84938
Value Function Loss: 0.08917

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.56349
Value Function Update Magnitude: 0.58656

Collected Steps per Second: 21,311.23668
Overall Steps per Second: 10,638.59812

Timestep Collection Time: 2.34712
Timestep Consumption Time: 2.35463
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.70175

Cumulative Model Updates: 82,720
Cumulative Timesteps: 689,851,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,215.36173
Policy Entropy: 1.85872
Value Function Loss: 0.08744

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.62571

Collected Steps per Second: 22,069.77572
Overall Steps per Second: 10,519.51350

Timestep Collection Time: 2.26627
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.75459

Cumulative Model Updates: 82,726
Cumulative Timesteps: 689,901,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 689901654...
Checkpoint 689901654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,127.62959
Policy Entropy: 1.84839
Value Function Loss: 0.07925

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.73805

Collected Steps per Second: 21,857.40179
Overall Steps per Second: 10,557.49686

Timestep Collection Time: 2.28755
Timestep Consumption Time: 2.44842
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.73597

Cumulative Model Updates: 82,732
Cumulative Timesteps: 689,951,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,997.27768
Policy Entropy: 1.84311
Value Function Loss: 0.07991

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.52599
Value Function Update Magnitude: 0.65556

Collected Steps per Second: 22,761.73849
Overall Steps per Second: 10,647.86812

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.69841

Cumulative Model Updates: 82,738
Cumulative Timesteps: 690,001,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 690001682...
Checkpoint 690001682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,109.08798
Policy Entropy: 1.84301
Value Function Loss: 0.08850

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.57684

Collected Steps per Second: 22,480.99434
Overall Steps per Second: 10,784.76391

Timestep Collection Time: 2.22561
Timestep Consumption Time: 2.41371
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.63932

Cumulative Model Updates: 82,744
Cumulative Timesteps: 690,051,716

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,289.15736
Policy Entropy: 1.84624
Value Function Loss: 0.08348

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.61873

Collected Steps per Second: 22,792.19628
Overall Steps per Second: 10,718.24594

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66532

Cumulative Model Updates: 82,750
Cumulative Timesteps: 690,101,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 690101720...
Checkpoint 690101720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,370.29704
Policy Entropy: 1.85139
Value Function Loss: 0.08477

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.57718

Collected Steps per Second: 22,377.68222
Overall Steps per Second: 10,543.29692

Timestep Collection Time: 2.23446
Timestep Consumption Time: 2.50808
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.74254

Cumulative Model Updates: 82,756
Cumulative Timesteps: 690,151,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,256.99220
Policy Entropy: 1.83481
Value Function Loss: 0.08760

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 22,910.65326
Overall Steps per Second: 10,818.15059

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62390

Cumulative Model Updates: 82,762
Cumulative Timesteps: 690,201,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 690201744...
Checkpoint 690201744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,716.38097
Policy Entropy: 1.84348
Value Function Loss: 0.08562

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.67317

Collected Steps per Second: 21,936.61023
Overall Steps per Second: 10,335.27614

Timestep Collection Time: 2.28002
Timestep Consumption Time: 2.55932
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.83935

Cumulative Model Updates: 82,768
Cumulative Timesteps: 690,251,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,657.62712
Policy Entropy: 1.82622
Value Function Loss: 0.08777

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.54362
Value Function Update Magnitude: 0.61349

Collected Steps per Second: 22,481.49728
Overall Steps per Second: 10,739.46419

Timestep Collection Time: 2.22512
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.65796

Cumulative Model Updates: 82,774
Cumulative Timesteps: 690,301,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 690301784...
Checkpoint 690301784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,234.40013
Policy Entropy: 1.82676
Value Function Loss: 0.08449

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.52021
Value Function Update Magnitude: 0.61359

Collected Steps per Second: 21,324.37269
Overall Steps per Second: 10,301.39752

Timestep Collection Time: 2.34614
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.85662

Cumulative Model Updates: 82,780
Cumulative Timesteps: 690,351,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,413.54686
Policy Entropy: 1.83255
Value Function Loss: 0.07870

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.51277
Value Function Update Magnitude: 0.51934

Collected Steps per Second: 22,325.08911
Overall Steps per Second: 10,539.99788

Timestep Collection Time: 2.24035
Timestep Consumption Time: 2.50500
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.74535

Cumulative Model Updates: 82,786
Cumulative Timesteps: 690,401,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 690401830...
Checkpoint 690401830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,567.46128
Policy Entropy: 1.84424
Value Function Loss: 0.08396

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.52190
Value Function Update Magnitude: 0.48347

Collected Steps per Second: 21,511.86839
Overall Steps per Second: 10,457.67980

Timestep Collection Time: 2.32476
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.78213

Cumulative Model Updates: 82,792
Cumulative Timesteps: 690,451,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,047.33485
Policy Entropy: 1.85171
Value Function Loss: 0.08197

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.53187

Collected Steps per Second: 22,565.49078
Overall Steps per Second: 9,735.76269

Timestep Collection Time: 2.21586
Timestep Consumption Time: 2.92005
PPO Batch Consumption Time: 0.36253
Total Iteration Time: 5.13591

Cumulative Model Updates: 82,798
Cumulative Timesteps: 690,501,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 690501842...
Checkpoint 690501842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,459.94290
Policy Entropy: 1.86077
Value Function Loss: 0.08921

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 9,786.56730
Overall Steps per Second: 6,329.07587

Timestep Collection Time: 5.10904
Timestep Consumption Time: 2.79100
PPO Batch Consumption Time: 0.32480
Total Iteration Time: 7.90005

Cumulative Model Updates: 82,804
Cumulative Timesteps: 690,551,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,901.18081
Policy Entropy: 1.85392
Value Function Loss: 0.07975

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.69459

Collected Steps per Second: 21,686.08933
Overall Steps per Second: 10,318.33140

Timestep Collection Time: 2.30646
Timestep Consumption Time: 2.54103
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.84749

Cumulative Model Updates: 82,810
Cumulative Timesteps: 690,601,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 690601860...
Checkpoint 690601860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,210.98989
Policy Entropy: 1.85445
Value Function Loss: 0.08597

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.53658
Value Function Update Magnitude: 0.67201

Collected Steps per Second: 21,729.04019
Overall Steps per Second: 10,356.34229

Timestep Collection Time: 2.30162
Timestep Consumption Time: 2.52750
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.82912

Cumulative Model Updates: 82,816
Cumulative Timesteps: 690,651,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,231.66226
Policy Entropy: 1.85926
Value Function Loss: 0.08804

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.64798

Collected Steps per Second: 22,601.60407
Overall Steps per Second: 10,772.62015

Timestep Collection Time: 2.21276
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.64251

Cumulative Model Updates: 82,822
Cumulative Timesteps: 690,701,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 690701884...
Checkpoint 690701884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,128.56838
Policy Entropy: 1.85072
Value Function Loss: 0.09161

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.61501

Collected Steps per Second: 21,820.38907
Overall Steps per Second: 10,441.70847

Timestep Collection Time: 2.29327
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.79232

Cumulative Model Updates: 82,828
Cumulative Timesteps: 690,751,924

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,097.05364
Policy Entropy: 1.84283
Value Function Loss: 0.08830

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.56047
Value Function Update Magnitude: 0.51019

Collected Steps per Second: 22,458.74996
Overall Steps per Second: 10,697.90345

Timestep Collection Time: 2.22702
Timestep Consumption Time: 2.44829
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.67531

Cumulative Model Updates: 82,834
Cumulative Timesteps: 690,801,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 690801940...
Checkpoint 690801940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,587.45888
Policy Entropy: 1.83675
Value Function Loss: 0.08758

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.60654

Collected Steps per Second: 21,772.49471
Overall Steps per Second: 10,375.84420

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.52332
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.82062

Cumulative Model Updates: 82,840
Cumulative Timesteps: 690,851,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,856.27388
Policy Entropy: 1.83934
Value Function Loss: 0.08583

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.55178
Value Function Update Magnitude: 0.61459

Collected Steps per Second: 22,727.40286
Overall Steps per Second: 10,858.16050

Timestep Collection Time: 2.20060
Timestep Consumption Time: 2.40552
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.60612

Cumulative Model Updates: 82,846
Cumulative Timesteps: 690,901,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 690901972...
Checkpoint 690901972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,860.27904
Policy Entropy: 1.82959
Value Function Loss: 0.08521

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.55355
Value Function Update Magnitude: 0.59347

Collected Steps per Second: 22,243.56706
Overall Steps per Second: 10,618.72136

Timestep Collection Time: 2.24910
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.71130

Cumulative Model Updates: 82,852
Cumulative Timesteps: 690,952,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,024.45700
Policy Entropy: 1.84400
Value Function Loss: 0.08230

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.15602
Policy Update Magnitude: 0.55169
Value Function Update Magnitude: 0.57917

Collected Steps per Second: 22,526.76151
Overall Steps per Second: 10,588.55789

Timestep Collection Time: 2.21985
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.72265

Cumulative Model Updates: 82,858
Cumulative Timesteps: 691,002,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 691002006...
Checkpoint 691002006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,736.23942
Policy Entropy: 1.83979
Value Function Loss: 0.08405

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 21,970.34140
Overall Steps per Second: 10,468.28530

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.50144
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.77805

Cumulative Model Updates: 82,864
Cumulative Timesteps: 691,052,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,015.10853
Policy Entropy: 1.85390
Value Function Loss: 0.08225

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.16363
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.62786

Collected Steps per Second: 22,710.15160
Overall Steps per Second: 10,674.05349

Timestep Collection Time: 2.20368
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.68857

Cumulative Model Updates: 82,870
Cumulative Timesteps: 691,102,070

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 691102070...
Checkpoint 691102070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,599.53136
Policy Entropy: 1.84690
Value Function Loss: 0.08780

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.16689
Policy Update Magnitude: 0.48595
Value Function Update Magnitude: 0.52085

Collected Steps per Second: 22,160.13693
Overall Steps per Second: 10,575.30532

Timestep Collection Time: 2.25639
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.72819

Cumulative Model Updates: 82,876
Cumulative Timesteps: 691,152,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,262.92850
Policy Entropy: 1.85281
Value Function Loss: 0.09256

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.16178
Policy Update Magnitude: 0.50944
Value Function Update Magnitude: 0.43789

Collected Steps per Second: 22,540.68429
Overall Steps per Second: 10,781.70439

Timestep Collection Time: 2.21954
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.64027

Cumulative Model Updates: 82,882
Cumulative Timesteps: 691,202,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 691202102...
Checkpoint 691202102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,286.20200
Policy Entropy: 1.86197
Value Function Loss: 0.09119

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.16303
Policy Update Magnitude: 0.52788
Value Function Update Magnitude: 0.57482

Collected Steps per Second: 22,084.01652
Overall Steps per Second: 10,657.29211

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.69162

Cumulative Model Updates: 82,888
Cumulative Timesteps: 691,252,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,782.18322
Policy Entropy: 1.87128
Value Function Loss: 0.08321

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.53975
Value Function Update Magnitude: 0.53745

Collected Steps per Second: 22,755.82985
Overall Steps per Second: 10,822.01164

Timestep Collection Time: 2.19926
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62446

Cumulative Model Updates: 82,894
Cumulative Timesteps: 691,302,148

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 691302148...
Checkpoint 691302148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,249.06446
Policy Entropy: 1.86351
Value Function Loss: 0.08020

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.44448

Collected Steps per Second: 22,002.00757
Overall Steps per Second: 10,404.60506

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.53335
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.80614

Cumulative Model Updates: 82,900
Cumulative Timesteps: 691,352,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,182.27113
Policy Entropy: 1.85599
Value Function Loss: 0.07732

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.52133
Value Function Update Magnitude: 0.40619

Collected Steps per Second: 22,683.02008
Overall Steps per Second: 10,752.30138

Timestep Collection Time: 2.20464
Timestep Consumption Time: 2.44627
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.65091

Cumulative Model Updates: 82,906
Cumulative Timesteps: 691,402,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 691402162...
Checkpoint 691402162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,687.74822
Policy Entropy: 1.85513
Value Function Loss: 0.08087

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.42558

Collected Steps per Second: 19,289.19505
Overall Steps per Second: 9,315.77275

Timestep Collection Time: 2.59389
Timestep Consumption Time: 2.77700
PPO Batch Consumption Time: 0.34227
Total Iteration Time: 5.37089

Cumulative Model Updates: 82,912
Cumulative Timesteps: 691,452,196

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,113.93317
Policy Entropy: 1.86271
Value Function Loss: 0.07938

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.53426
Value Function Update Magnitude: 0.48405

Collected Steps per Second: 20,704.72679
Overall Steps per Second: 10,212.56723

Timestep Collection Time: 2.41491
Timestep Consumption Time: 2.48102
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.89593

Cumulative Model Updates: 82,918
Cumulative Timesteps: 691,502,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 691502196...
Checkpoint 691502196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,405.51601
Policy Entropy: 1.87109
Value Function Loss: 0.08265

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.52854
Value Function Update Magnitude: 0.64074

Collected Steps per Second: 21,910.71282
Overall Steps per Second: 10,585.73056

Timestep Collection Time: 2.28263
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.72466

Cumulative Model Updates: 82,924
Cumulative Timesteps: 691,552,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,151.32326
Policy Entropy: 1.87059
Value Function Loss: 0.07704

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.52038
Value Function Update Magnitude: 0.69603

Collected Steps per Second: 22,412.45758
Overall Steps per Second: 10,099.08774

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.72167
PPO Batch Consumption Time: 0.32395
Total Iteration Time: 4.95391

Cumulative Model Updates: 82,930
Cumulative Timesteps: 691,602,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 691602240...
Checkpoint 691602240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,365.41395
Policy Entropy: 1.86720
Value Function Loss: 0.07804

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.70306

Collected Steps per Second: 20,278.46130
Overall Steps per Second: 10,064.80058

Timestep Collection Time: 2.46636
Timestep Consumption Time: 2.50284
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.96920

Cumulative Model Updates: 82,936
Cumulative Timesteps: 691,652,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,128.06362
Policy Entropy: 1.87749
Value Function Loss: 0.07248

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.53447
Value Function Update Magnitude: 0.68985

Collected Steps per Second: 20,169.04472
Overall Steps per Second: 10,010.46669

Timestep Collection Time: 2.47934
Timestep Consumption Time: 2.51603
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.99537

Cumulative Model Updates: 82,942
Cumulative Timesteps: 691,702,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 691702260...
Checkpoint 691702260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,645.19491
Policy Entropy: 1.88091
Value Function Loss: 0.07779

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.53768
Value Function Update Magnitude: 0.69298

Collected Steps per Second: 20,093.26779
Overall Steps per Second: 9,661.47091

Timestep Collection Time: 2.48939
Timestep Consumption Time: 2.68787
PPO Batch Consumption Time: 0.30664
Total Iteration Time: 5.17727

Cumulative Model Updates: 82,948
Cumulative Timesteps: 691,752,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,232.80671
Policy Entropy: 1.87814
Value Function Loss: 0.07721

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.54762
Value Function Update Magnitude: 0.67893

Collected Steps per Second: 20,842.04321
Overall Steps per Second: 10,204.24958

Timestep Collection Time: 2.40053
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.90306

Cumulative Model Updates: 82,954
Cumulative Timesteps: 691,802,312

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 691802312...
Checkpoint 691802312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,321.69067
Policy Entropy: 1.85754
Value Function Loss: 0.07852

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.52345
Value Function Update Magnitude: 0.69654

Collected Steps per Second: 20,557.74253
Overall Steps per Second: 9,924.02338

Timestep Collection Time: 2.43266
Timestep Consumption Time: 2.60663
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 5.03929

Cumulative Model Updates: 82,960
Cumulative Timesteps: 691,852,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,258.39980
Policy Entropy: 1.86235
Value Function Loss: 0.07880

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15830
Policy Update Magnitude: 0.44766
Value Function Update Magnitude: 0.70655

Collected Steps per Second: 15,024.03630
Overall Steps per Second: 8,639.80680

Timestep Collection Time: 3.32946
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 5.78971

Cumulative Model Updates: 82,966
Cumulative Timesteps: 691,902,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 691902344...
Checkpoint 691902344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,124.16663
Policy Entropy: 1.86469
Value Function Loss: 0.08274

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.48819
Value Function Update Magnitude: 0.66159

Collected Steps per Second: 13,825.98435
Overall Steps per Second: 6,352.33883

Timestep Collection Time: 3.61811
Timestep Consumption Time: 4.25678
PPO Batch Consumption Time: 0.56115
Total Iteration Time: 7.87489

Cumulative Model Updates: 82,972
Cumulative Timesteps: 691,952,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,247.74461
Policy Entropy: 1.89526
Value Function Loss: 0.08199

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.69657

Collected Steps per Second: 15,135.04046
Overall Steps per Second: 7,342.93092

Timestep Collection Time: 3.30452
Timestep Consumption Time: 3.50666
PPO Batch Consumption Time: 0.44827
Total Iteration Time: 6.81118

Cumulative Model Updates: 82,978
Cumulative Timesteps: 692,002,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 692002382...
Checkpoint 692002382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,983.39278
Policy Entropy: 1.90118
Value Function Loss: 0.07744

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.55178
Value Function Update Magnitude: 0.71862

Collected Steps per Second: 15,375.08719
Overall Steps per Second: 7,508.28335

Timestep Collection Time: 3.25253
Timestep Consumption Time: 3.40784
PPO Batch Consumption Time: 0.44324
Total Iteration Time: 6.66038

Cumulative Model Updates: 82,984
Cumulative Timesteps: 692,052,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,596.80756
Policy Entropy: 1.90567
Value Function Loss: 0.07838

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 15,838.73919
Overall Steps per Second: 7,032.16244

Timestep Collection Time: 3.15972
Timestep Consumption Time: 3.95701
PPO Batch Consumption Time: 0.52945
Total Iteration Time: 7.11673

Cumulative Model Updates: 82,990
Cumulative Timesteps: 692,102,436

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 692102436...
Checkpoint 692102436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,179.87418
Policy Entropy: 1.90391
Value Function Loss: 0.08040

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.54435

Collected Steps per Second: 14,698.41300
Overall Steps per Second: 6,908.80562

Timestep Collection Time: 3.40214
Timestep Consumption Time: 3.83587
PPO Batch Consumption Time: 0.50655
Total Iteration Time: 7.23801

Cumulative Model Updates: 82,996
Cumulative Timesteps: 692,152,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,571.64568
Policy Entropy: 1.88868
Value Function Loss: 0.08219

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.53484
Value Function Update Magnitude: 0.46293

Collected Steps per Second: 14,958.54413
Overall Steps per Second: 6,967.06918

Timestep Collection Time: 3.34351
Timestep Consumption Time: 3.83512
PPO Batch Consumption Time: 0.50613
Total Iteration Time: 7.17863

Cumulative Model Updates: 83,002
Cumulative Timesteps: 692,202,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 692202456...
Checkpoint 692202456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,884.64772
Policy Entropy: 1.88980
Value Function Loss: 0.07888

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.46509

Collected Steps per Second: 14,974.25856
Overall Steps per Second: 7,270.55950

Timestep Collection Time: 3.34080
Timestep Consumption Time: 3.53983
PPO Batch Consumption Time: 0.46365
Total Iteration Time: 6.88063

Cumulative Model Updates: 83,008
Cumulative Timesteps: 692,252,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,225.73994
Policy Entropy: 1.88997
Value Function Loss: 0.07512

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.57554

Collected Steps per Second: 15,840.38393
Overall Steps per Second: 7,546.41296

Timestep Collection Time: 3.15914
Timestep Consumption Time: 3.47209
PPO Batch Consumption Time: 0.44855
Total Iteration Time: 6.63123

Cumulative Model Updates: 83,014
Cumulative Timesteps: 692,302,524

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 692302524...
Checkpoint 692302524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,512.10440
Policy Entropy: 1.89734
Value Function Loss: 0.06995

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.62762

Collected Steps per Second: 15,684.71404
Overall Steps per Second: 7,662.51732

Timestep Collection Time: 3.18858
Timestep Consumption Time: 3.33825
PPO Batch Consumption Time: 0.43651
Total Iteration Time: 6.52684

Cumulative Model Updates: 83,020
Cumulative Timesteps: 692,352,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,634.33641
Policy Entropy: 1.89222
Value Function Loss: 0.07147

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.52753
Value Function Update Magnitude: 0.63781

Collected Steps per Second: 15,730.97071
Overall Steps per Second: 7,262.49777

Timestep Collection Time: 3.17946
Timestep Consumption Time: 3.70743
PPO Batch Consumption Time: 0.48944
Total Iteration Time: 6.88689

Cumulative Model Updates: 83,026
Cumulative Timesteps: 692,402,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 692402552...
Checkpoint 692402552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,395.43047
Policy Entropy: 1.88859
Value Function Loss: 0.08678

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 14,394.70068
Overall Steps per Second: 7,060.42397

Timestep Collection Time: 3.47350
Timestep Consumption Time: 3.60823
PPO Batch Consumption Time: 0.47698
Total Iteration Time: 7.08173

Cumulative Model Updates: 83,032
Cumulative Timesteps: 692,452,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,508.04255
Policy Entropy: 1.88504
Value Function Loss: 0.09371

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.50399

Collected Steps per Second: 15,076.29753
Overall Steps per Second: 7,438.81041

Timestep Collection Time: 3.31753
Timestep Consumption Time: 3.40613
PPO Batch Consumption Time: 0.44425
Total Iteration Time: 6.72366

Cumulative Model Updates: 83,038
Cumulative Timesteps: 692,502,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 692502568...
Checkpoint 692502568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,566.70777
Policy Entropy: 1.89387
Value Function Loss: 0.09310

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.52168
Value Function Update Magnitude: 0.56795

Collected Steps per Second: 14,943.25105
Overall Steps per Second: 7,100.49564

Timestep Collection Time: 3.34666
Timestep Consumption Time: 3.69651
PPO Batch Consumption Time: 0.48691
Total Iteration Time: 7.04317

Cumulative Model Updates: 83,044
Cumulative Timesteps: 692,552,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,352.34749
Policy Entropy: 1.90693
Value Function Loss: 0.08640

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.52401
Value Function Update Magnitude: 0.51809

Collected Steps per Second: 15,453.44334
Overall Steps per Second: 7,457.46191

Timestep Collection Time: 3.23643
Timestep Consumption Time: 3.47014
PPO Batch Consumption Time: 0.45224
Total Iteration Time: 6.70657

Cumulative Model Updates: 83,050
Cumulative Timesteps: 692,602,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 692602592...
Checkpoint 692602592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,160.51220
Policy Entropy: 1.90342
Value Function Loss: 0.08487

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.42693

Collected Steps per Second: 15,380.52076
Overall Steps per Second: 7,185.71782

Timestep Collection Time: 3.25230
Timestep Consumption Time: 3.70901
PPO Batch Consumption Time: 0.48507
Total Iteration Time: 6.96131

Cumulative Model Updates: 83,056
Cumulative Timesteps: 692,652,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,441.51221
Policy Entropy: 1.88976
Value Function Loss: 0.08668

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.57321

Collected Steps per Second: 15,838.39269
Overall Steps per Second: 7,634.56015

Timestep Collection Time: 3.15941
Timestep Consumption Time: 3.39499
PPO Batch Consumption Time: 0.43995
Total Iteration Time: 6.55441

Cumulative Model Updates: 83,062
Cumulative Timesteps: 692,702,654

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 692702654...
Checkpoint 692702654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,970.99948
Policy Entropy: 1.88386
Value Function Loss: 0.08134

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.54592
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 15,624.13108
Overall Steps per Second: 7,526.08769

Timestep Collection Time: 3.20082
Timestep Consumption Time: 3.44407
PPO Batch Consumption Time: 0.44145
Total Iteration Time: 6.64489

Cumulative Model Updates: 83,068
Cumulative Timesteps: 692,752,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,522.13874
Policy Entropy: 1.90548
Value Function Loss: 0.07701

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.51163
Value Function Update Magnitude: 0.68851

Collected Steps per Second: 15,184.68001
Overall Steps per Second: 6,998.12796

Timestep Collection Time: 3.29424
Timestep Consumption Time: 3.85367
PPO Batch Consumption Time: 0.51092
Total Iteration Time: 7.14791

Cumulative Model Updates: 83,074
Cumulative Timesteps: 692,802,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 692802686...
Checkpoint 692802686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,025.89363
Policy Entropy: 1.90558
Value Function Loss: 0.07525

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15562
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.66376

Collected Steps per Second: 14,805.00350
Overall Steps per Second: 6,933.60861

Timestep Collection Time: 3.38007
Timestep Consumption Time: 3.83724
PPO Batch Consumption Time: 0.50724
Total Iteration Time: 7.21731

Cumulative Model Updates: 83,080
Cumulative Timesteps: 692,852,728

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,584.07445
Policy Entropy: 1.90868
Value Function Loss: 0.07623

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.48473
Value Function Update Magnitude: 0.60245

Collected Steps per Second: 15,753.72417
Overall Steps per Second: 8,861.41095

Timestep Collection Time: 3.17385
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 5.64244

Cumulative Model Updates: 83,086
Cumulative Timesteps: 692,902,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 692902728...
Checkpoint 692902728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,083.36402
Policy Entropy: 1.91069
Value Function Loss: 0.07865

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15499
Policy Update Magnitude: 0.50078
Value Function Update Magnitude: 0.61389

Collected Steps per Second: 17,425.12368
Overall Steps per Second: 8,920.88827

Timestep Collection Time: 2.86988
Timestep Consumption Time: 2.73584
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 5.60572

Cumulative Model Updates: 83,092
Cumulative Timesteps: 692,952,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,191.90222
Policy Entropy: 1.91857
Value Function Loss: 0.07553

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.52010
Value Function Update Magnitude: 0.66488

Collected Steps per Second: 19,296.89369
Overall Steps per Second: 9,711.25642

Timestep Collection Time: 2.59202
Timestep Consumption Time: 2.55849
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 5.15052

Cumulative Model Updates: 83,098
Cumulative Timesteps: 693,002,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 693002754...
Checkpoint 693002754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,693.52776
Policy Entropy: 1.91515
Value Function Loss: 0.08395

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.53652
Value Function Update Magnitude: 0.71920

Collected Steps per Second: 21,461.52975
Overall Steps per Second: 10,203.45602

Timestep Collection Time: 2.33022
Timestep Consumption Time: 2.57106
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.90128

Cumulative Model Updates: 83,104
Cumulative Timesteps: 693,052,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,041.59772
Policy Entropy: 1.92283
Value Function Loss: 0.08801

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.71623

Collected Steps per Second: 21,219.37328
Overall Steps per Second: 9,974.19093

Timestep Collection Time: 2.35728
Timestep Consumption Time: 2.65766
PPO Batch Consumption Time: 0.31194
Total Iteration Time: 5.01494

Cumulative Model Updates: 83,110
Cumulative Timesteps: 693,102,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 693102784...
Checkpoint 693102784 saved!
