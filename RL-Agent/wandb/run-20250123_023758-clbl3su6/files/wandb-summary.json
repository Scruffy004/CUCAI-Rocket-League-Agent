{"Total Iteration Time":5.33626809999987,"x_vel":-2.3527527759428764,"Policy Entropy":3.1230096419652305,"y_vel":57.48715990844354,"SB3 Clip Fraction":0.07127999824782212,"_step":125340,"z_vel":4.7373829021486875,"_timestamp":1.7376513873192823e+09,"Mean KL Divergence":0.00819533954684933,"Policy Reward":13310.587557754961,"Overall Steps per Second":9376.59035534613,"Value Function Update Magnitude":0.3161916434764862,"Timestep Collection Time":2.7502516000022297,"Cumulative Timesteps":3134790732,"Policy Update Magnitude":0.30349868535995483,"_runtime":315662.5249101,"Cumulative Model Updates":375844,"_wandb":{"runtime":315662},"Timesteps Collected":50036,"PPO Batch Consumption Time":0.291978398958842,"Collected Steps per Second":18193.244574408913,"Timestep Consumption Time":2.5860164999976405,"Value Function Loss":0.009140698239207268}