Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.61326
Policy Entropy: 3.25592
Value Function Loss: 0.00494

Mean KL Divergence: 0.00073
SB3 Clip Fraction: 0.00535
Policy Update Magnitude: 0.19955
Value Function Update Magnitude: 0.18093

Collected Steps per Second: 5,313.27886
Overall Steps per Second: 2,969.39622

Timestep Collection Time: 9.41641
Timestep Consumption Time: 7.43281
PPO Batch Consumption Time: 3.11144
Total Iteration Time: 16.84922

Cumulative Model Updates: 125,738
Cumulative Timesteps: 1,048,728,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.44505
Policy Entropy: 3.25066
Value Function Loss: 0.00625

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06091
Policy Update Magnitude: 0.42215
Value Function Update Magnitude: 0.38899

Collected Steps per Second: 20,441.04508
Overall Steps per Second: 11,204.82797

Timestep Collection Time: 2.44655
Timestep Consumption Time: 2.01671
PPO Batch Consumption Time: 0.30578
Total Iteration Time: 4.46325

Cumulative Model Updates: 125,742
Cumulative Timesteps: 1,048,778,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1048778352...
Checkpoint 1048778352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.52247
Policy Entropy: 3.23570
Value Function Loss: 0.00501

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.61876
Value Function Update Magnitude: 0.58904

Collected Steps per Second: 20,290.99549
Overall Steps per Second: 9,791.49819

Timestep Collection Time: 2.46592
Timestep Consumption Time: 2.64423
PPO Batch Consumption Time: 0.30866
Total Iteration Time: 5.11015

Cumulative Model Updates: 125,748
Cumulative Timesteps: 1,048,828,388

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.31170
Policy Entropy: 3.22644
Value Function Loss: 0.00436

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.59396
Value Function Update Magnitude: 0.57882

Collected Steps per Second: 20,423.66030
Overall Steps per Second: 9,730.23571

Timestep Collection Time: 2.44932
Timestep Consumption Time: 2.69177
PPO Batch Consumption Time: 0.31346
Total Iteration Time: 5.14109

Cumulative Model Updates: 125,754
Cumulative Timesteps: 1,048,878,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1048878412...
Checkpoint 1048878412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.57951
Policy Entropy: 3.21567
Value Function Loss: 0.00443

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.60502
Value Function Update Magnitude: 0.56536

Collected Steps per Second: 20,880.99411
Overall Steps per Second: 9,977.16155

Timestep Collection Time: 2.39558
Timestep Consumption Time: 2.61807
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 5.01365

Cumulative Model Updates: 125,760
Cumulative Timesteps: 1,048,928,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.39194
Policy Entropy: 3.22013
Value Function Loss: 0.00433

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.60124
Value Function Update Magnitude: 0.55922

Collected Steps per Second: 21,413.34498
Overall Steps per Second: 9,964.72685

Timestep Collection Time: 2.33611
Timestep Consumption Time: 2.68399
PPO Batch Consumption Time: 0.31834
Total Iteration Time: 5.02011

Cumulative Model Updates: 125,766
Cumulative Timesteps: 1,048,978,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1048978458...
Checkpoint 1048978458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.07686
Policy Entropy: 3.21203
Value Function Loss: 0.00434

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.60442
Value Function Update Magnitude: 0.56246

Collected Steps per Second: 20,831.12368
Overall Steps per Second: 10,094.81564

Timestep Collection Time: 2.40045
Timestep Consumption Time: 2.55299
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.95343

Cumulative Model Updates: 125,772
Cumulative Timesteps: 1,049,028,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,352.53847
Policy Entropy: 3.22875
Value Function Loss: 0.00406

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.58917
Value Function Update Magnitude: 0.55791

Collected Steps per Second: 22,800.82196
Overall Steps per Second: 10,524.94622

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.55771
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.75062

Cumulative Model Updates: 125,778
Cumulative Timesteps: 1,049,078,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1049078462...
Checkpoint 1049078462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.00228
Policy Entropy: 3.22725
Value Function Loss: 0.00419

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.56128

Collected Steps per Second: 21,299.19918
Overall Steps per Second: 10,018.25875

Timestep Collection Time: 2.34760
Timestep Consumption Time: 2.64349
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.99109

Cumulative Model Updates: 125,784
Cumulative Timesteps: 1,049,128,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.42191
Policy Entropy: 3.22904
Value Function Loss: 0.00416

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.54755

Collected Steps per Second: 21,552.24983
Overall Steps per Second: 10,055.96473

Timestep Collection Time: 2.32041
Timestep Consumption Time: 2.65276
PPO Batch Consumption Time: 0.31228
Total Iteration Time: 4.97317

Cumulative Model Updates: 125,790
Cumulative Timesteps: 1,049,178,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1049178474...
Checkpoint 1049178474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671.98347
Policy Entropy: 3.22778
Value Function Loss: 0.00413

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.56100
Value Function Update Magnitude: 0.54850

Collected Steps per Second: 22,088.98692
Overall Steps per Second: 10,436.32239

Timestep Collection Time: 2.26475
Timestep Consumption Time: 2.52870
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.79345

Cumulative Model Updates: 125,796
Cumulative Timesteps: 1,049,228,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.30353
Policy Entropy: 3.23185
Value Function Loss: 0.00396

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.53989

Collected Steps per Second: 22,801.91566
Overall Steps per Second: 10,720.85201

Timestep Collection Time: 2.19341
Timestep Consumption Time: 2.47170
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.66511

Cumulative Model Updates: 125,802
Cumulative Timesteps: 1,049,278,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1049278514...
Checkpoint 1049278514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.58727
Policy Entropy: 3.23302
Value Function Loss: 0.00400

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.52834

Collected Steps per Second: 22,256.38697
Overall Steps per Second: 10,598.37391

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.71884

Cumulative Model Updates: 125,808
Cumulative Timesteps: 1,049,328,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.43467
Policy Entropy: 3.23420
Value Function Loss: 0.00386

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.55616
Value Function Update Magnitude: 0.51424

Collected Steps per Second: 22,923.08789
Overall Steps per Second: 10,538.34414

Timestep Collection Time: 2.18173
Timestep Consumption Time: 2.56399
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.74572

Cumulative Model Updates: 125,814
Cumulative Timesteps: 1,049,378,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1049378538...
Checkpoint 1049378538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,442.98047
Policy Entropy: 3.22142
Value Function Loss: 0.00376

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.50927

Collected Steps per Second: 22,466.75503
Overall Steps per Second: 10,699.54185

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.67553

Cumulative Model Updates: 125,820
Cumulative Timesteps: 1,049,428,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.95771
Policy Entropy: 3.22318
Value Function Loss: 0.00389

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.56823
Value Function Update Magnitude: 0.52725

Collected Steps per Second: 22,491.49004
Overall Steps per Second: 10,460.95431

Timestep Collection Time: 2.22413
Timestep Consumption Time: 2.55784
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.78197

Cumulative Model Updates: 125,826
Cumulative Timesteps: 1,049,478,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1049478588...
Checkpoint 1049478588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.88294
Policy Entropy: 3.21229
Value Function Loss: 0.00403

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.57627
Value Function Update Magnitude: 0.55215

Collected Steps per Second: 22,431.73856
Overall Steps per Second: 10,591.42693

Timestep Collection Time: 2.23032
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.72363

Cumulative Model Updates: 125,832
Cumulative Timesteps: 1,049,528,618

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.82610
Policy Entropy: 3.20224
Value Function Loss: 0.00407

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.58231
Value Function Update Magnitude: 0.56213

Collected Steps per Second: 22,834.51482
Overall Steps per Second: 10,574.96180

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.53940
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.72985

Cumulative Model Updates: 125,838
Cumulative Timesteps: 1,049,578,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1049578636...
Checkpoint 1049578636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.01724
Policy Entropy: 3.20265
Value Function Loss: 0.00409

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.58172
Value Function Update Magnitude: 0.56710

Collected Steps per Second: 22,756.87839
Overall Steps per Second: 10,524.20209

Timestep Collection Time: 2.19714
Timestep Consumption Time: 2.55382
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.75095

Cumulative Model Updates: 125,844
Cumulative Timesteps: 1,049,628,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.02508
Policy Entropy: 3.22379
Value Function Loss: 0.00387

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.57855
Value Function Update Magnitude: 0.56195

Collected Steps per Second: 22,903.73279
Overall Steps per Second: 10,646.54515

Timestep Collection Time: 2.18357
Timestep Consumption Time: 2.51391
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.69749

Cumulative Model Updates: 125,850
Cumulative Timesteps: 1,049,678,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1049678648...
Checkpoint 1049678648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.75710
Policy Entropy: 3.23161
Value Function Loss: 0.00397

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.57345
Value Function Update Magnitude: 0.53958

Collected Steps per Second: 22,415.98577
Overall Steps per Second: 10,460.17557

Timestep Collection Time: 2.23126
Timestep Consumption Time: 2.55030
PPO Batch Consumption Time: 0.30145
Total Iteration Time: 4.78156

Cumulative Model Updates: 125,856
Cumulative Timesteps: 1,049,728,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,451.56537
Policy Entropy: 3.23997
Value Function Loss: 0.00387

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.57291
Value Function Update Magnitude: 0.53402

Collected Steps per Second: 22,558.61412
Overall Steps per Second: 10,503.60453

Timestep Collection Time: 2.21796
Timestep Consumption Time: 2.54555
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.76351

Cumulative Model Updates: 125,862
Cumulative Timesteps: 1,049,778,698

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1049778698...
Checkpoint 1049778698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.93378
Policy Entropy: 3.21570
Value Function Loss: 0.00398

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.53558

Collected Steps per Second: 22,194.33701
Overall Steps per Second: 10,537.42954

Timestep Collection Time: 2.25472
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.74898

Cumulative Model Updates: 125,868
Cumulative Timesteps: 1,049,828,740

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.04233
Policy Entropy: 3.22694
Value Function Loss: 0.00369

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.54880

Collected Steps per Second: 21,971.68478
Overall Steps per Second: 10,513.84709

Timestep Collection Time: 2.27611
Timestep Consumption Time: 2.48047
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.75658

Cumulative Model Updates: 125,874
Cumulative Timesteps: 1,049,878,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1049878750...
Checkpoint 1049878750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,809.87279
Policy Entropy: 3.21224
Value Function Loss: 0.00354

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.53317

Collected Steps per Second: 21,562.67441
Overall Steps per Second: 10,631.50520

Timestep Collection Time: 2.31966
Timestep Consumption Time: 2.38504
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.70470

Cumulative Model Updates: 125,880
Cumulative Timesteps: 1,049,928,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.97978
Policy Entropy: 3.21765
Value Function Loss: 0.00382

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.51546

Collected Steps per Second: 22,759.76611
Overall Steps per Second: 10,578.98955

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.53040
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.72805

Cumulative Model Updates: 125,886
Cumulative Timesteps: 1,049,978,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1049978786...
Checkpoint 1049978786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.02156
Policy Entropy: 3.21543
Value Function Loss: 0.00388

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.55292
Value Function Update Magnitude: 0.52863

Collected Steps per Second: 21,684.63647
Overall Steps per Second: 10,374.04041

Timestep Collection Time: 2.30652
Timestep Consumption Time: 2.51475
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.82127

Cumulative Model Updates: 125,892
Cumulative Timesteps: 1,050,028,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.23927
Policy Entropy: 3.21818
Value Function Loss: 0.00409

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.55124
Value Function Update Magnitude: 0.51391

Collected Steps per Second: 22,677.06707
Overall Steps per Second: 10,444.77177

Timestep Collection Time: 2.20602
Timestep Consumption Time: 2.58356
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.78957

Cumulative Model Updates: 125,898
Cumulative Timesteps: 1,050,078,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1050078828...
Checkpoint 1050078828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.85835
Policy Entropy: 3.23333
Value Function Loss: 0.00406

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.55916
Value Function Update Magnitude: 0.50986

Collected Steps per Second: 22,236.04170
Overall Steps per Second: 10,537.49882

Timestep Collection Time: 2.24932
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.74648

Cumulative Model Updates: 125,904
Cumulative Timesteps: 1,050,128,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.23134
Policy Entropy: 3.23430
Value Function Loss: 0.00408

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.51639

Collected Steps per Second: 22,716.24753
Overall Steps per Second: 10,586.77926

Timestep Collection Time: 2.20116
Timestep Consumption Time: 2.52190
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.72306

Cumulative Model Updates: 125,910
Cumulative Timesteps: 1,050,178,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1050178846...
Checkpoint 1050178846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.77276
Policy Entropy: 3.23378
Value Function Loss: 0.00388

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.52168

Collected Steps per Second: 22,207.88545
Overall Steps per Second: 10,563.97599

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.48241
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.73458

Cumulative Model Updates: 125,916
Cumulative Timesteps: 1,050,228,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.00355
Policy Entropy: 3.24175
Value Function Loss: 0.00363

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.55407
Value Function Update Magnitude: 0.51060

Collected Steps per Second: 22,570.25045
Overall Steps per Second: 10,535.16738

Timestep Collection Time: 2.21601
Timestep Consumption Time: 2.53151
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.74753

Cumulative Model Updates: 125,922
Cumulative Timesteps: 1,050,278,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1050278878...
Checkpoint 1050278878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.40518
Policy Entropy: 3.23420
Value Function Loss: 0.00363

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.55558
Value Function Update Magnitude: 0.51709

Collected Steps per Second: 22,225.85282
Overall Steps per Second: 10,564.82353

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.48415
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.73477

Cumulative Model Updates: 125,928
Cumulative Timesteps: 1,050,328,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.69917
Policy Entropy: 3.22604
Value Function Loss: 0.00382

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.53440

Collected Steps per Second: 22,954.39244
Overall Steps per Second: 10,580.50458

Timestep Collection Time: 2.17841
Timestep Consumption Time: 2.54764
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.72605

Cumulative Model Updates: 125,934
Cumulative Timesteps: 1,050,378,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1050378904...
Checkpoint 1050378904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.63202
Policy Entropy: 3.21192
Value Function Loss: 0.00386

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.56846
Value Function Update Magnitude: 0.56103

Collected Steps per Second: 21,692.13200
Overall Steps per Second: 10,583.80079

Timestep Collection Time: 2.30609
Timestep Consumption Time: 2.42038
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.72647

Cumulative Model Updates: 125,940
Cumulative Timesteps: 1,050,428,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.09918
Policy Entropy: 3.21242
Value Function Loss: 0.00387

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.55945
Value Function Update Magnitude: 0.56032

Collected Steps per Second: 22,137.30824
Overall Steps per Second: 10,499.20213

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.76303

Cumulative Model Updates: 125,946
Cumulative Timesteps: 1,050,478,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1050478936...
Checkpoint 1050478936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906.53288
Policy Entropy: 3.21222
Value Function Loss: 0.00409

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.56118
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 21,269.96782
Overall Steps per Second: 10,583.30322

Timestep Collection Time: 2.35111
Timestep Consumption Time: 2.37407
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.72518

Cumulative Model Updates: 125,952
Cumulative Timesteps: 1,050,528,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.19573
Policy Entropy: 3.21126
Value Function Loss: 0.00396

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.57140
Value Function Update Magnitude: 0.54881

Collected Steps per Second: 21,867.37020
Overall Steps per Second: 10,503.34111

Timestep Collection Time: 2.28651
Timestep Consumption Time: 2.47388
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.76039

Cumulative Model Updates: 125,958
Cumulative Timesteps: 1,050,578,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1050578944...
Checkpoint 1050578944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.60489
Policy Entropy: 3.20922
Value Function Loss: 0.00395

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.54672

Collected Steps per Second: 22,500.44845
Overall Steps per Second: 10,584.88223

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.72712

Cumulative Model Updates: 125,964
Cumulative Timesteps: 1,050,628,980

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188.67136
Policy Entropy: 3.23194
Value Function Loss: 0.00348

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.52351

Collected Steps per Second: 21,652.38410
Overall Steps per Second: 10,466.89266

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.46785
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.77716

Cumulative Model Updates: 125,970
Cumulative Timesteps: 1,050,678,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1050678982...
Checkpoint 1050678982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.02764
Policy Entropy: 3.23753
Value Function Loss: 0.00355

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.55914
Value Function Update Magnitude: 0.49607

Collected Steps per Second: 21,790.87619
Overall Steps per Second: 10,655.24016

Timestep Collection Time: 2.29454
Timestep Consumption Time: 2.39799
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.69253

Cumulative Model Updates: 125,976
Cumulative Timesteps: 1,050,728,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.87211
Policy Entropy: 3.24662
Value Function Loss: 0.00371

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.49076

Collected Steps per Second: 21,824.35595
Overall Steps per Second: 10,552.03322

Timestep Collection Time: 2.29203
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.74051

Cumulative Model Updates: 125,982
Cumulative Timesteps: 1,050,779,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1050779004...
Checkpoint 1050779004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.48750
Policy Entropy: 3.23487
Value Function Loss: 0.00383

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.54271
Value Function Update Magnitude: 0.50351

Collected Steps per Second: 21,764.03960
Overall Steps per Second: 10,490.69585

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.46925
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.76708

Cumulative Model Updates: 125,988
Cumulative Timesteps: 1,050,829,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,580.30016
Policy Entropy: 3.22370
Value Function Loss: 0.00362

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.54569
Value Function Update Magnitude: 0.49642

Collected Steps per Second: 21,927.38207
Overall Steps per Second: 10,520.21258

Timestep Collection Time: 2.28053
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.75333

Cumulative Model Updates: 125,994
Cumulative Timesteps: 1,050,879,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1050879020...
Checkpoint 1050879020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.24443
Policy Entropy: 3.21472
Value Function Loss: 0.00361

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.48510

Collected Steps per Second: 21,771.94096
Overall Steps per Second: 10,597.68111

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.42167
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.71839

Cumulative Model Updates: 126,000
Cumulative Timesteps: 1,050,929,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.67630
Policy Entropy: 3.22687
Value Function Loss: 0.00412

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.49222

Collected Steps per Second: 22,841.70443
Overall Steps per Second: 10,603.96459

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.52674
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.71616

Cumulative Model Updates: 126,006
Cumulative Timesteps: 1,050,979,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1050979034...
Checkpoint 1050979034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.34068
Policy Entropy: 3.22026
Value Function Loss: 0.00414

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.51460

Collected Steps per Second: 22,403.14296
Overall Steps per Second: 10,515.82400

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.52331
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.75550

Cumulative Model Updates: 126,012
Cumulative Timesteps: 1,051,029,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.02907
Policy Entropy: 3.21231
Value Function Loss: 0.00421

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.56534
Value Function Update Magnitude: 0.52167

Collected Steps per Second: 21,645.30923
Overall Steps per Second: 10,430.01443

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.30092
Total Iteration Time: 4.79520

Cumulative Model Updates: 126,018
Cumulative Timesteps: 1,051,079,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1051079056...
Checkpoint 1051079056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.81588
Policy Entropy: 3.20156
Value Function Loss: 0.00400

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.51667

Collected Steps per Second: 21,769.08558
Overall Steps per Second: 10,525.41939

Timestep Collection Time: 2.29720
Timestep Consumption Time: 2.45396
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.75116

Cumulative Model Updates: 126,024
Cumulative Timesteps: 1,051,129,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.93154
Policy Entropy: 3.20024
Value Function Loss: 0.00416

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.56526
Value Function Update Magnitude: 0.53650

Collected Steps per Second: 21,800.23845
Overall Steps per Second: 10,571.64461

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.73190

Cumulative Model Updates: 126,030
Cumulative Timesteps: 1,051,179,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1051179088...
Checkpoint 1051179088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.16336
Policy Entropy: 3.21287
Value Function Loss: 0.00421

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.58153
Value Function Update Magnitude: 0.55478

Collected Steps per Second: 21,835.62803
Overall Steps per Second: 10,590.67969

Timestep Collection Time: 2.29084
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.72321

Cumulative Model Updates: 126,036
Cumulative Timesteps: 1,051,229,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.32778
Policy Entropy: 3.20824
Value Function Loss: 0.00390

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.57809
Value Function Update Magnitude: 0.56596

Collected Steps per Second: 21,769.04024
Overall Steps per Second: 10,524.30930

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.45515
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.75300

Cumulative Model Updates: 126,042
Cumulative Timesteps: 1,051,279,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1051279132...
Checkpoint 1051279132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913.57131
Policy Entropy: 3.21651
Value Function Loss: 0.00373

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.54771

Collected Steps per Second: 21,776.03290
Overall Steps per Second: 10,651.90343

Timestep Collection Time: 2.29665
Timestep Consumption Time: 2.39847
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.69512

Cumulative Model Updates: 126,048
Cumulative Timesteps: 1,051,329,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.40764
Policy Entropy: 3.21492
Value Function Loss: 0.00379

Mean KL Divergence: 0.02549
SB3 Clip Fraction: 0.16027
Policy Update Magnitude: 0.64534
Value Function Update Magnitude: 0.54293

Collected Steps per Second: 21,748.46020
Overall Steps per Second: 10,575.23042

Timestep Collection Time: 2.30002
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.73011

Cumulative Model Updates: 126,054
Cumulative Timesteps: 1,051,379,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1051379166...
Checkpoint 1051379166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.45544
Policy Entropy: 3.21355
Value Function Loss: 0.00435

Mean KL Divergence: 0.03130
SB3 Clip Fraction: 0.21827
Policy Update Magnitude: 0.64193
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 21,837.48266
Overall Steps per Second: 10,618.57737

Timestep Collection Time: 2.28964
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.70873

Cumulative Model Updates: 126,060
Cumulative Timesteps: 1,051,429,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.97121
Policy Entropy: 3.21484
Value Function Loss: 0.00449

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.16768
Policy Update Magnitude: 0.60238
Value Function Update Magnitude: 0.55508

Collected Steps per Second: 22,647.39179
Overall Steps per Second: 10,486.09652

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.56097
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.76917

Cumulative Model Updates: 126,066
Cumulative Timesteps: 1,051,479,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1051479176...
Checkpoint 1051479176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.97971
Policy Entropy: 3.21368
Value Function Loss: 0.00415

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.57988
Value Function Update Magnitude: 0.53285

Collected Steps per Second: 21,633.04909
Overall Steps per Second: 10,656.70910

Timestep Collection Time: 2.31193
Timestep Consumption Time: 2.38127
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.69319

Cumulative Model Updates: 126,072
Cumulative Timesteps: 1,051,529,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.60987
Policy Entropy: 3.22558
Value Function Loss: 0.00370

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.51248

Collected Steps per Second: 22,002.21087
Overall Steps per Second: 10,573.73484

Timestep Collection Time: 2.27323
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73021

Cumulative Model Updates: 126,078
Cumulative Timesteps: 1,051,579,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1051579206...
Checkpoint 1051579206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.57962
Policy Entropy: 3.22452
Value Function Loss: 0.00373

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.55466
Value Function Update Magnitude: 0.50324

Collected Steps per Second: 21,850.60704
Overall Steps per Second: 10,534.19446

Timestep Collection Time: 2.28872
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.74740

Cumulative Model Updates: 126,084
Cumulative Timesteps: 1,051,629,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.84795
Policy Entropy: 3.21567
Value Function Loss: 0.00391

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.56706
Value Function Update Magnitude: 0.51187

Collected Steps per Second: 22,099.43189
Overall Steps per Second: 10,335.79601

Timestep Collection Time: 2.26359
Timestep Consumption Time: 2.57629
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.83988

Cumulative Model Updates: 126,090
Cumulative Timesteps: 1,051,679,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1051679240...
Checkpoint 1051679240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.04567
Policy Entropy: 3.20285
Value Function Loss: 0.00397

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.51031

Collected Steps per Second: 19,351.90091
Overall Steps per Second: 9,716.94842

Timestep Collection Time: 2.58455
Timestep Consumption Time: 2.56274
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 5.14729

Cumulative Model Updates: 126,096
Cumulative Timesteps: 1,051,729,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.25692
Policy Entropy: 3.20107
Value Function Loss: 0.00402

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.57829
Value Function Update Magnitude: 0.53255

Collected Steps per Second: 18,946.50023
Overall Steps per Second: 9,578.78019

Timestep Collection Time: 2.64144
Timestep Consumption Time: 2.58324
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 5.22467

Cumulative Model Updates: 126,102
Cumulative Timesteps: 1,051,779,302

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1051779302...
Checkpoint 1051779302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.34284
Policy Entropy: 3.20823
Value Function Loss: 0.00398

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.58458
Value Function Update Magnitude: 0.55229

Collected Steps per Second: 19,963.05725
Overall Steps per Second: 9,977.94585

Timestep Collection Time: 2.50523
Timestep Consumption Time: 2.50703
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 5.01225

Cumulative Model Updates: 126,108
Cumulative Timesteps: 1,051,829,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.35162
Policy Entropy: 3.22081
Value Function Loss: 0.00429

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.58251
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 22,628.82377
Overall Steps per Second: 10,550.95637

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.53004
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.74023

Cumulative Model Updates: 126,114
Cumulative Timesteps: 1,051,879,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1051879328...
Checkpoint 1051879328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.53896
Policy Entropy: 3.21434
Value Function Loss: 0.00432

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.58427
Value Function Update Magnitude: 0.56891

Collected Steps per Second: 22,589.93088
Overall Steps per Second: 10,661.81848

Timestep Collection Time: 2.21408
Timestep Consumption Time: 2.47705
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.69113

Cumulative Model Updates: 126,120
Cumulative Timesteps: 1,051,929,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.54658
Policy Entropy: 3.20095
Value Function Loss: 0.00429

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.58747
Value Function Update Magnitude: 0.55859

Collected Steps per Second: 22,646.15026
Overall Steps per Second: 10,553.88499

Timestep Collection Time: 2.20797
Timestep Consumption Time: 2.52981
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.73778

Cumulative Model Updates: 126,126
Cumulative Timesteps: 1,051,979,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1051979346...
Checkpoint 1051979346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.91145
Policy Entropy: 3.19758
Value Function Loss: 0.00395

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.55867

Collected Steps per Second: 20,932.01401
Overall Steps per Second: 9,868.28808

Timestep Collection Time: 2.38974
Timestep Consumption Time: 2.67923
PPO Batch Consumption Time: 0.30594
Total Iteration Time: 5.06896

Cumulative Model Updates: 126,132
Cumulative Timesteps: 1,052,029,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.94448
Policy Entropy: 3.20141
Value Function Loss: 0.00401

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.58706
Value Function Update Magnitude: 0.55762

Collected Steps per Second: 20,674.65706
Overall Steps per Second: 10,039.02536

Timestep Collection Time: 2.42026
Timestep Consumption Time: 2.56409
PPO Batch Consumption Time: 0.29879
Total Iteration Time: 4.98435

Cumulative Model Updates: 126,138
Cumulative Timesteps: 1,052,079,406

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1052079406...
Checkpoint 1052079406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.83844
Policy Entropy: 3.21325
Value Function Loss: 0.00403

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.58450
Value Function Update Magnitude: 0.56116

Collected Steps per Second: 20,517.85618
Overall Steps per Second: 10,092.21460

Timestep Collection Time: 2.43758
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.95570

Cumulative Model Updates: 126,144
Cumulative Timesteps: 1,052,129,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.58495
Policy Entropy: 3.23498
Value Function Loss: 0.00409

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.58545
Value Function Update Magnitude: 0.54413

Collected Steps per Second: 22,907.32770
Overall Steps per Second: 10,644.10924

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.70025

Cumulative Model Updates: 126,150
Cumulative Timesteps: 1,052,179,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1052179450...
Checkpoint 1052179450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.48086
Policy Entropy: 3.23354
Value Function Loss: 0.00406

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.58600
Value Function Update Magnitude: 0.55539

Collected Steps per Second: 22,538.57893
Overall Steps per Second: 10,516.66027

Timestep Collection Time: 2.21895
Timestep Consumption Time: 2.53655
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.75550

Cumulative Model Updates: 126,156
Cumulative Timesteps: 1,052,229,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.70369
Policy Entropy: 3.22480
Value Function Loss: 0.00422

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.59422
Value Function Update Magnitude: 0.58205

Collected Steps per Second: 22,093.87649
Overall Steps per Second: 10,461.76461

Timestep Collection Time: 2.26389
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 4.78103

Cumulative Model Updates: 126,162
Cumulative Timesteps: 1,052,279,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1052279480...
Checkpoint 1052279480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.32609
Policy Entropy: 3.22083
Value Function Loss: 0.00413

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.59499
Value Function Update Magnitude: 0.59378

Collected Steps per Second: 22,358.20666
Overall Steps per Second: 10,523.50958

Timestep Collection Time: 2.23748
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.75374

Cumulative Model Updates: 126,168
Cumulative Timesteps: 1,052,329,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,222.81372
Policy Entropy: 3.22035
Value Function Loss: 0.00403

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.58601
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 23,045.75215
Overall Steps per Second: 10,629.04429

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.53531
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.70560

Cumulative Model Updates: 126,174
Cumulative Timesteps: 1,052,379,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1052379522...
Checkpoint 1052379522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,943.85268
Policy Entropy: 3.20696
Value Function Loss: 0.00386

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.52840

Collected Steps per Second: 22,225.32796
Overall Steps per Second: 10,489.61682

Timestep Collection Time: 2.25032
Timestep Consumption Time: 2.51764
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.76795

Cumulative Model Updates: 126,180
Cumulative Timesteps: 1,052,429,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.69719
Policy Entropy: 3.20300
Value Function Loss: 0.00388

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.57284
Value Function Update Magnitude: 0.52258

Collected Steps per Second: 21,918.10984
Overall Steps per Second: 10,577.13552

Timestep Collection Time: 2.28177
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.72831

Cumulative Model Updates: 126,186
Cumulative Timesteps: 1,052,479,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1052479548...
Checkpoint 1052479548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052.46453
Policy Entropy: 3.20546
Value Function Loss: 0.00367

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.56586
Value Function Update Magnitude: 0.51642

Collected Steps per Second: 20,753.95098
Overall Steps per Second: 10,409.65028

Timestep Collection Time: 2.41072
Timestep Consumption Time: 2.39559
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.80631

Cumulative Model Updates: 126,192
Cumulative Timesteps: 1,052,529,580

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.88190
Policy Entropy: 3.21434
Value Function Loss: 0.00372

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.49796

Collected Steps per Second: 16,869.07022
Overall Steps per Second: 8,977.15808

Timestep Collection Time: 2.96578
Timestep Consumption Time: 2.60725
PPO Batch Consumption Time: 0.31189
Total Iteration Time: 5.57303

Cumulative Model Updates: 126,198
Cumulative Timesteps: 1,052,579,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1052579610...
Checkpoint 1052579610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.38220
Policy Entropy: 3.22168
Value Function Loss: 0.00373

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.56634
Value Function Update Magnitude: 0.51587

Collected Steps per Second: 20,434.19770
Overall Steps per Second: 10,268.13928

Timestep Collection Time: 2.44825
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.87216

Cumulative Model Updates: 126,204
Cumulative Timesteps: 1,052,629,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,515.75132
Policy Entropy: 3.21636
Value Function Loss: 0.00372

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.51568

Collected Steps per Second: 20,980.62982
Overall Steps per Second: 10,426.49194

Timestep Collection Time: 2.38325
Timestep Consumption Time: 2.41242
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.79567

Cumulative Model Updates: 126,210
Cumulative Timesteps: 1,052,679,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1052679640...
Checkpoint 1052679640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.16998
Policy Entropy: 3.23171
Value Function Loss: 0.00404

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.57939
Value Function Update Magnitude: 0.52410

Collected Steps per Second: 21,712.42892
Overall Steps per Second: 10,400.67252

Timestep Collection Time: 2.30357
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.80892

Cumulative Model Updates: 126,216
Cumulative Timesteps: 1,052,729,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.10862
Policy Entropy: 3.23397
Value Function Loss: 0.00396

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.54817

Collected Steps per Second: 22,652.52600
Overall Steps per Second: 10,587.82723

Timestep Collection Time: 2.20779
Timestep Consumption Time: 2.51575
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.72354

Cumulative Model Updates: 126,222
Cumulative Timesteps: 1,052,779,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1052779668...
Checkpoint 1052779668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.10220
Policy Entropy: 3.23553
Value Function Loss: 0.00382

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.54062

Collected Steps per Second: 21,642.05008
Overall Steps per Second: 10,436.11629

Timestep Collection Time: 2.31050
Timestep Consumption Time: 2.48094
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.79144

Cumulative Model Updates: 126,228
Cumulative Timesteps: 1,052,829,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.69789
Policy Entropy: 3.22830
Value Function Loss: 0.00385

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.51326

Collected Steps per Second: 22,538.32360
Overall Steps per Second: 10,483.01239

Timestep Collection Time: 2.21889
Timestep Consumption Time: 2.55169
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.77058

Cumulative Model Updates: 126,234
Cumulative Timesteps: 1,052,879,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1052879682...
Checkpoint 1052879682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.99771
Policy Entropy: 3.21739
Value Function Loss: 0.00389

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.54205

Collected Steps per Second: 22,509.00016
Overall Steps per Second: 10,645.94578

Timestep Collection Time: 2.22204
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.69813

Cumulative Model Updates: 126,240
Cumulative Timesteps: 1,052,929,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.87746
Policy Entropy: 3.22350
Value Function Loss: 0.00395

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.58894
Value Function Update Magnitude: 0.57446

Collected Steps per Second: 22,734.96689
Overall Steps per Second: 10,492.34991

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.56735
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.76766

Cumulative Model Updates: 126,246
Cumulative Timesteps: 1,052,979,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1052979722...
Checkpoint 1052979722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.73380
Policy Entropy: 3.24487
Value Function Loss: 0.00381

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.57504
Value Function Update Magnitude: 0.56587

Collected Steps per Second: 22,363.98210
Overall Steps per Second: 10,570.10783

Timestep Collection Time: 2.23636
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.73165

Cumulative Model Updates: 126,252
Cumulative Timesteps: 1,053,029,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.50340
Policy Entropy: 3.25634
Value Function Loss: 0.00386

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.56211
Value Function Update Magnitude: 0.54261

Collected Steps per Second: 21,695.98371
Overall Steps per Second: 10,468.74972

Timestep Collection Time: 2.30513
Timestep Consumption Time: 2.47214
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.77727

Cumulative Model Updates: 126,258
Cumulative Timesteps: 1,053,079,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1053079748...
Checkpoint 1053079748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.56228
Policy Entropy: 3.25194
Value Function Loss: 0.00381

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.53775

Collected Steps per Second: 21,583.56293
Overall Steps per Second: 10,343.20626

Timestep Collection Time: 2.31676
Timestep Consumption Time: 2.51771
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.83448

Cumulative Model Updates: 126,264
Cumulative Timesteps: 1,053,129,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.95896
Policy Entropy: 3.24754
Value Function Loss: 0.00381

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.51562

Collected Steps per Second: 22,800.24275
Overall Steps per Second: 10,715.10686

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.66724

Cumulative Model Updates: 126,270
Cumulative Timesteps: 1,053,179,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1053179762...
Checkpoint 1053179762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.53893
Policy Entropy: 3.23971
Value Function Loss: 0.00433

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.56311
Value Function Update Magnitude: 0.51762

Collected Steps per Second: 21,707.67946
Overall Steps per Second: 10,586.95243

Timestep Collection Time: 2.30462
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.72544

Cumulative Model Updates: 126,276
Cumulative Timesteps: 1,053,229,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.65646
Policy Entropy: 3.24409
Value Function Loss: 0.00437

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.53610

Collected Steps per Second: 22,851.99868
Overall Steps per Second: 10,608.50398

Timestep Collection Time: 2.18922
Timestep Consumption Time: 2.52662
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.71584

Cumulative Model Updates: 126,282
Cumulative Timesteps: 1,053,279,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1053279818...
Checkpoint 1053279818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.12182
Policy Entropy: 3.24502
Value Function Loss: 0.00431

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.56847
Value Function Update Magnitude: 0.55752

Collected Steps per Second: 21,697.41769
Overall Steps per Second: 10,571.95060

Timestep Collection Time: 2.30479
Timestep Consumption Time: 2.42546
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.73025

Cumulative Model Updates: 126,288
Cumulative Timesteps: 1,053,329,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.56619
Policy Entropy: 3.24234
Value Function Loss: 0.00402

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.56217
Value Function Update Magnitude: 0.56194

Collected Steps per Second: 22,908.81992
Overall Steps per Second: 10,630.49328

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.70345

Cumulative Model Updates: 126,294
Cumulative Timesteps: 1,053,379,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1053379826...
Checkpoint 1053379826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,409.58273
Policy Entropy: 3.25541
Value Function Loss: 0.00385

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.56681

Collected Steps per Second: 22,463.60172
Overall Steps per Second: 10,466.55482

Timestep Collection Time: 2.22707
Timestep Consumption Time: 2.55273
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.77980

Cumulative Model Updates: 126,300
Cumulative Timesteps: 1,053,429,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.21827
Policy Entropy: 3.24637
Value Function Loss: 0.00380

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.55455

Collected Steps per Second: 22,776.31946
Overall Steps per Second: 10,537.19705

Timestep Collection Time: 2.19526
Timestep Consumption Time: 2.54983
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.74509

Cumulative Model Updates: 126,306
Cumulative Timesteps: 1,053,479,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1053479854...
Checkpoint 1053479854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.96827
Policy Entropy: 3.24036
Value Function Loss: 0.00395

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.56132

Collected Steps per Second: 22,167.92583
Overall Steps per Second: 10,580.36055

Timestep Collection Time: 2.25650
Timestep Consumption Time: 2.47131
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.72782

Cumulative Model Updates: 126,312
Cumulative Timesteps: 1,053,529,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.32162
Policy Entropy: 3.22946
Value Function Loss: 0.00377

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.55572

Collected Steps per Second: 22,556.98412
Overall Steps per Second: 10,466.15470

Timestep Collection Time: 2.21705
Timestep Consumption Time: 2.56121
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 4.77826

Cumulative Model Updates: 126,318
Cumulative Timesteps: 1,053,579,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1053579886...
Checkpoint 1053579886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.77196
Policy Entropy: 3.23835
Value Function Loss: 0.00357

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.55210
Value Function Update Magnitude: 0.52366

Collected Steps per Second: 22,257.53908
Overall Steps per Second: 10,643.53508

Timestep Collection Time: 2.24715
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.69919

Cumulative Model Updates: 126,324
Cumulative Timesteps: 1,053,629,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.84901
Policy Entropy: 3.24078
Value Function Loss: 0.00363

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.52383

Collected Steps per Second: 22,597.87540
Overall Steps per Second: 10,538.02310

Timestep Collection Time: 2.21295
Timestep Consumption Time: 2.53253
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.74548

Cumulative Model Updates: 126,330
Cumulative Timesteps: 1,053,679,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1053679910...
Checkpoint 1053679910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.57305
Policy Entropy: 3.22945
Value Function Loss: 0.00378

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.52397

Collected Steps per Second: 22,754.53554
Overall Steps per Second: 10,378.31994

Timestep Collection Time: 2.19772
Timestep Consumption Time: 2.62079
PPO Batch Consumption Time: 0.30749
Total Iteration Time: 4.81851

Cumulative Model Updates: 126,336
Cumulative Timesteps: 1,053,729,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.15829
Policy Entropy: 3.22400
Value Function Loss: 0.00413

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.54058

Collected Steps per Second: 21,650.39654
Overall Steps per Second: 10,443.93251

Timestep Collection Time: 2.30952
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.78766

Cumulative Model Updates: 126,342
Cumulative Timesteps: 1,053,779,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1053779920...
Checkpoint 1053779920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.59952
Policy Entropy: 3.21215
Value Function Loss: 0.00422

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.57153
Value Function Update Magnitude: 0.54189

Collected Steps per Second: 22,077.57950
Overall Steps per Second: 10,384.74349

Timestep Collection Time: 2.26583
Timestep Consumption Time: 2.55124
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.81707

Cumulative Model Updates: 126,348
Cumulative Timesteps: 1,053,829,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.17245
Policy Entropy: 3.21516
Value Function Loss: 0.00404

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.56567
Value Function Update Magnitude: 0.54899

Collected Steps per Second: 22,598.01526
Overall Steps per Second: 10,528.96013

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.53653
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.74938

Cumulative Model Updates: 126,354
Cumulative Timesteps: 1,053,879,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1053879950...
Checkpoint 1053879950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.08523
Policy Entropy: 3.21831
Value Function Loss: 0.00393

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.56233
Value Function Update Magnitude: 0.57193

Collected Steps per Second: 22,725.70006
Overall Steps per Second: 10,520.53932

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.55337
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.75432

Cumulative Model Updates: 126,360
Cumulative Timesteps: 1,053,929,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.60030
Policy Entropy: 3.22199
Value Function Loss: 0.00383

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.56800
Value Function Update Magnitude: 0.55163

Collected Steps per Second: 23,022.20447
Overall Steps per Second: 10,571.75263

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.55869
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.73129

Cumulative Model Updates: 126,366
Cumulative Timesteps: 1,053,979,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1053979986...
Checkpoint 1053979986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.81432
Policy Entropy: 3.24362
Value Function Loss: 0.00386

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.53722

Collected Steps per Second: 22,411.55158
Overall Steps per Second: 10,572.10341

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.49983
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.73208

Cumulative Model Updates: 126,372
Cumulative Timesteps: 1,054,030,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.63430
Policy Entropy: 3.23009
Value Function Loss: 0.00414

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.57486
Value Function Update Magnitude: 0.52591

Collected Steps per Second: 22,746.18467
Overall Steps per Second: 10,528.45478

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.55107
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.74941

Cumulative Model Updates: 126,378
Cumulative Timesteps: 1,054,080,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1054080018...
Checkpoint 1054080018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.94688
Policy Entropy: 3.23249
Value Function Loss: 0.00424

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.58836
Value Function Update Magnitude: 0.55394

Collected Steps per Second: 22,337.10024
Overall Steps per Second: 10,604.03119

Timestep Collection Time: 2.24031
Timestep Consumption Time: 2.47884
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.71915

Cumulative Model Updates: 126,384
Cumulative Timesteps: 1,054,130,060

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.46942
Policy Entropy: 3.21455
Value Function Loss: 0.00438

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11156
Policy Update Magnitude: 0.59414
Value Function Update Magnitude: 0.58741

Collected Steps per Second: 22,277.00925
Overall Steps per Second: 10,421.82017

Timestep Collection Time: 2.24554
Timestep Consumption Time: 2.55439
PPO Batch Consumption Time: 0.29912
Total Iteration Time: 4.79993

Cumulative Model Updates: 126,390
Cumulative Timesteps: 1,054,180,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1054180084...
Checkpoint 1054180084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.26028
Policy Entropy: 3.22164
Value Function Loss: 0.00436

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.59971
Value Function Update Magnitude: 0.60164

Collected Steps per Second: 22,401.65382
Overall Steps per Second: 10,594.73589

Timestep Collection Time: 2.23269
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.72083

Cumulative Model Updates: 126,396
Cumulative Timesteps: 1,054,230,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.25392
Policy Entropy: 3.23078
Value Function Loss: 0.00419

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.59161
Value Function Update Magnitude: 0.58874

Collected Steps per Second: 22,601.26001
Overall Steps per Second: 10,559.89500

Timestep Collection Time: 2.21359
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73774

Cumulative Model Updates: 126,402
Cumulative Timesteps: 1,054,280,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1054280130...
Checkpoint 1054280130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.98445
Policy Entropy: 3.24643
Value Function Loss: 0.00385

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.57934
Value Function Update Magnitude: 0.56698

Collected Steps per Second: 22,738.16387
Overall Steps per Second: 10,638.13966

Timestep Collection Time: 2.19903
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70026

Cumulative Model Updates: 126,408
Cumulative Timesteps: 1,054,330,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,249.32139
Policy Entropy: 3.24637
Value Function Loss: 0.00374

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.55072

Collected Steps per Second: 22,284.40405
Overall Steps per Second: 10,398.68825

Timestep Collection Time: 2.24435
Timestep Consumption Time: 2.56530
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.80965

Cumulative Model Updates: 126,414
Cumulative Timesteps: 1,054,380,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1054380146...
Checkpoint 1054380146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.43516
Policy Entropy: 3.23788
Value Function Loss: 0.00372

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.53944

Collected Steps per Second: 22,138.90472
Overall Steps per Second: 10,584.87129

Timestep Collection Time: 2.25883
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.72448

Cumulative Model Updates: 126,420
Cumulative Timesteps: 1,054,430,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.31347
Policy Entropy: 3.21932
Value Function Loss: 0.00404

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.57066
Value Function Update Magnitude: 0.52987

Collected Steps per Second: 22,481.86340
Overall Steps per Second: 10,527.38644

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.52611
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.75066

Cumulative Model Updates: 126,426
Cumulative Timesteps: 1,054,480,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1054480166...
Checkpoint 1054480166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.18603
Policy Entropy: 3.22608
Value Function Loss: 0.00391

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.54975

Collected Steps per Second: 22,331.56289
Overall Steps per Second: 10,583.43514

Timestep Collection Time: 2.23934
Timestep Consumption Time: 2.48578
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.72512

Cumulative Model Updates: 126,432
Cumulative Timesteps: 1,054,530,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.88342
Policy Entropy: 3.22556
Value Function Loss: 0.00380

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.56013

Collected Steps per Second: 22,668.54968
Overall Steps per Second: 10,529.59819

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.54313
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.74909

Cumulative Model Updates: 126,438
Cumulative Timesteps: 1,054,580,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1054580180...
Checkpoint 1054580180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.71122
Policy Entropy: 3.22858
Value Function Loss: 0.00396

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.55446

Collected Steps per Second: 22,315.74318
Overall Steps per Second: 10,645.99747

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.45652
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.69754

Cumulative Model Updates: 126,444
Cumulative Timesteps: 1,054,630,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.19143
Policy Entropy: 3.22979
Value Function Loss: 0.00401

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.56180

Collected Steps per Second: 22,463.59130
Overall Steps per Second: 10,432.07291

Timestep Collection Time: 2.22698
Timestep Consumption Time: 2.56842
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.79540

Cumulative Model Updates: 126,450
Cumulative Timesteps: 1,054,680,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1054680216...
Checkpoint 1054680216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.86032
Policy Entropy: 3.20749
Value Function Loss: 0.00414

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.55236

Collected Steps per Second: 22,483.38569
Overall Steps per Second: 10,651.55285

Timestep Collection Time: 2.22475
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.69603

Cumulative Model Updates: 126,456
Cumulative Timesteps: 1,054,730,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.06172
Policy Entropy: 3.21337
Value Function Loss: 0.00375

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.52855

Collected Steps per Second: 22,363.67057
Overall Steps per Second: 10,475.09732

Timestep Collection Time: 2.23595
Timestep Consumption Time: 2.53766
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.77361

Cumulative Model Updates: 126,462
Cumulative Timesteps: 1,054,780,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1054780240...
Checkpoint 1054780240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.40975
Policy Entropy: 3.20967
Value Function Loss: 0.00404

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.55864
Value Function Update Magnitude: 0.52737

Collected Steps per Second: 22,588.01072
Overall Steps per Second: 10,693.39825

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.46320
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.67765

Cumulative Model Updates: 126,468
Cumulative Timesteps: 1,054,830,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.50447
Policy Entropy: 3.22616
Value Function Loss: 0.00410

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.57701
Value Function Update Magnitude: 0.55783

Collected Steps per Second: 21,941.57102
Overall Steps per Second: 10,560.16274

Timestep Collection Time: 2.27896
Timestep Consumption Time: 2.45619
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.73515

Cumulative Model Updates: 126,474
Cumulative Timesteps: 1,054,880,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1054880264...
Checkpoint 1054880264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.08360
Policy Entropy: 3.21891
Value Function Loss: 0.00443

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.58086
Value Function Update Magnitude: 0.56582

Collected Steps per Second: 22,480.84331
Overall Steps per Second: 10,459.34486

Timestep Collection Time: 2.22501
Timestep Consumption Time: 2.55732
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 4.78233

Cumulative Model Updates: 126,480
Cumulative Timesteps: 1,054,930,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.79931
Policy Entropy: 3.21437
Value Function Loss: 0.00449

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.59167
Value Function Update Magnitude: 0.57489

Collected Steps per Second: 22,683.06021
Overall Steps per Second: 10,519.18891

Timestep Collection Time: 2.20526
Timestep Consumption Time: 2.55005
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.75531

Cumulative Model Updates: 126,486
Cumulative Timesteps: 1,054,980,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1054980306...
Checkpoint 1054980306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.43510
Policy Entropy: 3.21469
Value Function Loss: 0.00449

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.59575
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,335.56369
Overall Steps per Second: 10,474.51448

Timestep Collection Time: 2.23939
Timestep Consumption Time: 2.53582
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.77521

Cumulative Model Updates: 126,492
Cumulative Timesteps: 1,055,030,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.98398
Policy Entropy: 3.22349
Value Function Loss: 0.00453

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.61131

Collected Steps per Second: 23,079.20994
Overall Steps per Second: 10,591.02977

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.55544
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.72268

Cumulative Model Updates: 126,498
Cumulative Timesteps: 1,055,080,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1055080342...
Checkpoint 1055080342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.24472
Policy Entropy: 3.22653
Value Function Loss: 0.00435

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.58097
Value Function Update Magnitude: 0.59173

Collected Steps per Second: 22,369.74820
Overall Steps per Second: 10,647.43174

Timestep Collection Time: 2.23650
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.69879

Cumulative Model Updates: 126,504
Cumulative Timesteps: 1,055,130,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.22181
Policy Entropy: 3.22630
Value Function Loss: 0.00438

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.58195
Value Function Update Magnitude: 0.58070

Collected Steps per Second: 22,184.16323
Overall Steps per Second: 10,531.38444

Timestep Collection Time: 2.25521
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.75056

Cumulative Model Updates: 126,510
Cumulative Timesteps: 1,055,180,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1055180402...
Checkpoint 1055180402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.40667
Policy Entropy: 3.22296
Value Function Loss: 0.00464

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.59126
Value Function Update Magnitude: 0.60621

Collected Steps per Second: 20,781.56281
Overall Steps per Second: 10,231.99562

Timestep Collection Time: 2.40617
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.88702

Cumulative Model Updates: 126,516
Cumulative Timesteps: 1,055,230,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.33731
Policy Entropy: 3.21167
Value Function Loss: 0.00440

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.59018
Value Function Update Magnitude: 0.61554

Collected Steps per Second: 22,258.21865
Overall Steps per Second: 10,098.44102

Timestep Collection Time: 2.24726
Timestep Consumption Time: 2.70598
PPO Batch Consumption Time: 0.31395
Total Iteration Time: 4.95324

Cumulative Model Updates: 126,522
Cumulative Timesteps: 1,055,280,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1055280426...
Checkpoint 1055280426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.03665
Policy Entropy: 3.19937
Value Function Loss: 0.00422

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.58518

Collected Steps per Second: 22,401.27877
Overall Steps per Second: 10,414.14606

Timestep Collection Time: 2.23264
Timestep Consumption Time: 2.56987
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.80251

Cumulative Model Updates: 126,528
Cumulative Timesteps: 1,055,330,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.21385
Policy Entropy: 3.18284
Value Function Loss: 0.00405

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.58228
Value Function Update Magnitude: 0.56820

Collected Steps per Second: 21,430.81733
Overall Steps per Second: 10,292.08356

Timestep Collection Time: 2.33346
Timestep Consumption Time: 2.52542
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.85888

Cumulative Model Updates: 126,534
Cumulative Timesteps: 1,055,380,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1055380448...
Checkpoint 1055380448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.94022
Policy Entropy: 3.18924
Value Function Loss: 0.00433

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.57411

Collected Steps per Second: 21,809.52990
Overall Steps per Second: 10,439.64768

Timestep Collection Time: 2.29322
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.79077

Cumulative Model Updates: 126,540
Cumulative Timesteps: 1,055,430,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.76444
Policy Entropy: 3.19389
Value Function Loss: 0.00431

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.58464
Value Function Update Magnitude: 0.59164

Collected Steps per Second: 22,532.36368
Overall Steps per Second: 10,525.99469

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.53111
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.75014

Cumulative Model Updates: 126,546
Cumulative Timesteps: 1,055,480,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1055480462...
Checkpoint 1055480462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.48859
Policy Entropy: 3.20991
Value Function Loss: 0.00408

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.59725

Collected Steps per Second: 22,395.93831
Overall Steps per Second: 10,629.01881

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.47284
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.70655

Cumulative Model Updates: 126,552
Cumulative Timesteps: 1,055,530,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.93711
Policy Entropy: 3.21262
Value Function Loss: 0.00406

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.58267
Value Function Update Magnitude: 0.57425

Collected Steps per Second: 22,738.31086
Overall Steps per Second: 10,529.87058

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.55048
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.75030

Cumulative Model Updates: 126,558
Cumulative Timesteps: 1,055,580,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1055580508...
Checkpoint 1055580508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.57711
Policy Entropy: 3.21042
Value Function Loss: 0.00419

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.56959

Collected Steps per Second: 22,586.21972
Overall Steps per Second: 10,603.80937

Timestep Collection Time: 2.21392
Timestep Consumption Time: 2.50175
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.71566

Cumulative Model Updates: 126,564
Cumulative Timesteps: 1,055,630,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.81369
Policy Entropy: 3.20152
Value Function Loss: 0.00423

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.58609
Value Function Update Magnitude: 0.55239

Collected Steps per Second: 22,538.96820
Overall Steps per Second: 10,304.25517

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.63409
PPO Batch Consumption Time: 0.31046
Total Iteration Time: 4.85256

Cumulative Model Updates: 126,570
Cumulative Timesteps: 1,055,680,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1055680514...
Checkpoint 1055680514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.72106
Policy Entropy: 3.21053
Value Function Loss: 0.00410

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.58262
Value Function Update Magnitude: 0.52435

Collected Steps per Second: 22,393.16885
Overall Steps per Second: 10,525.17837

Timestep Collection Time: 2.23363
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.75222

Cumulative Model Updates: 126,576
Cumulative Timesteps: 1,055,730,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.99925
Policy Entropy: 3.20650
Value Function Loss: 0.00417

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.52372

Collected Steps per Second: 22,703.53094
Overall Steps per Second: 10,674.14134

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.48202
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.68440

Cumulative Model Updates: 126,582
Cumulative Timesteps: 1,055,780,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1055780534...
Checkpoint 1055780534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.92216
Policy Entropy: 3.20208
Value Function Loss: 0.00384

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.58303
Value Function Update Magnitude: 0.52162

Collected Steps per Second: 22,714.57525
Overall Steps per Second: 10,690.22609

Timestep Collection Time: 2.20158
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.67792

Cumulative Model Updates: 126,588
Cumulative Timesteps: 1,055,830,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.99273
Policy Entropy: 3.20296
Value Function Loss: 0.00404

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.58434
Value Function Update Magnitude: 0.52179

Collected Steps per Second: 22,722.14804
Overall Steps per Second: 10,597.65324

Timestep Collection Time: 2.20146
Timestep Consumption Time: 2.51864
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.72010

Cumulative Model Updates: 126,594
Cumulative Timesteps: 1,055,880,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1055880564...
Checkpoint 1055880564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.73133
Policy Entropy: 3.20826
Value Function Loss: 0.00395

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.58069
Value Function Update Magnitude: 0.51739

Collected Steps per Second: 21,809.75433
Overall Steps per Second: 10,440.53518

Timestep Collection Time: 2.29310
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 4.79018

Cumulative Model Updates: 126,600
Cumulative Timesteps: 1,055,930,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.23003
Policy Entropy: 3.22447
Value Function Loss: 0.00420

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.58400
Value Function Update Magnitude: 0.53427

Collected Steps per Second: 19,732.76538
Overall Steps per Second: 10,007.59443

Timestep Collection Time: 2.53477
Timestep Consumption Time: 2.46324
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.99800

Cumulative Model Updates: 126,606
Cumulative Timesteps: 1,055,980,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1055980594...
Checkpoint 1055980594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.89843
Policy Entropy: 3.21840
Value Function Loss: 0.00370

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.54719

Collected Steps per Second: 21,538.23995
Overall Steps per Second: 10,486.06240

Timestep Collection Time: 2.32312
Timestep Consumption Time: 2.44854
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.77167

Cumulative Model Updates: 126,612
Cumulative Timesteps: 1,056,030,630

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.66997
Policy Entropy: 3.22107
Value Function Loss: 0.00395

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.57808
Value Function Update Magnitude: 0.56113

Collected Steps per Second: 20,157.13877
Overall Steps per Second: 10,027.29581

Timestep Collection Time: 2.48061
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.98659

Cumulative Model Updates: 126,618
Cumulative Timesteps: 1,056,080,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1056080632...
Checkpoint 1056080632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.71237
Policy Entropy: 3.22330
Value Function Loss: 0.00385

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.57950
Value Function Update Magnitude: 0.55843

Collected Steps per Second: 20,034.04635
Overall Steps per Second: 10,090.19579

Timestep Collection Time: 2.49795
Timestep Consumption Time: 2.46172
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.95967

Cumulative Model Updates: 126,624
Cumulative Timesteps: 1,056,130,676

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.19210
Policy Entropy: 3.23343
Value Function Loss: 0.00355

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.54802

Collected Steps per Second: 20,409.70330
Overall Steps per Second: 10,133.69445

Timestep Collection Time: 2.45158
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 4.93759

Cumulative Model Updates: 126,630
Cumulative Timesteps: 1,056,180,712

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1056180712...
Checkpoint 1056180712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.57830
Policy Entropy: 3.23041
Value Function Loss: 0.00343

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.52979

Collected Steps per Second: 20,658.56873
Overall Steps per Second: 10,245.43325

Timestep Collection Time: 2.42030
Timestep Consumption Time: 2.45992
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.88022

Cumulative Model Updates: 126,636
Cumulative Timesteps: 1,056,230,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,501.70510
Policy Entropy: 3.23698
Value Function Loss: 0.00328

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.49207

Collected Steps per Second: 22,055.73103
Overall Steps per Second: 10,691.68108

Timestep Collection Time: 2.26735
Timestep Consumption Time: 2.40993
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.67728

Cumulative Model Updates: 126,642
Cumulative Timesteps: 1,056,280,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1056280720...
Checkpoint 1056280720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275.12102
Policy Entropy: 3.22750
Value Function Loss: 0.00362

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.47303

Collected Steps per Second: 21,245.61204
Overall Steps per Second: 10,253.81335

Timestep Collection Time: 2.35409
Timestep Consumption Time: 2.52351
PPO Batch Consumption Time: 0.30512
Total Iteration Time: 4.87760

Cumulative Model Updates: 126,648
Cumulative Timesteps: 1,056,330,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.30393
Policy Entropy: 3.23307
Value Function Loss: 0.00359

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.47699

Collected Steps per Second: 21,206.74199
Overall Steps per Second: 10,504.31068

Timestep Collection Time: 2.35812
Timestep Consumption Time: 2.40259
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.76071

Cumulative Model Updates: 126,654
Cumulative Timesteps: 1,056,380,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1056380742...
Checkpoint 1056380742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.49560
Policy Entropy: 3.23145
Value Function Loss: 0.00365

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.49865

Collected Steps per Second: 20,393.93281
Overall Steps per Second: 10,145.02620

Timestep Collection Time: 2.45220
Timestep Consumption Time: 2.47731
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.92951

Cumulative Model Updates: 126,660
Cumulative Timesteps: 1,056,430,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,192.98083
Policy Entropy: 3.23514
Value Function Loss: 0.00335

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.48800

Collected Steps per Second: 21,805.43510
Overall Steps per Second: 10,501.45365

Timestep Collection Time: 2.29392
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.76315

Cumulative Model Updates: 126,666
Cumulative Timesteps: 1,056,480,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1056480772...
Checkpoint 1056480772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.25524
Policy Entropy: 3.22601
Value Function Loss: 0.00349

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.49105

Collected Steps per Second: 21,772.32148
Overall Steps per Second: 10,631.40267

Timestep Collection Time: 2.29659
Timestep Consumption Time: 2.40665
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.70324

Cumulative Model Updates: 126,672
Cumulative Timesteps: 1,056,530,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.85337
Policy Entropy: 3.22874
Value Function Loss: 0.00355

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.50669

Collected Steps per Second: 22,131.39799
Overall Steps per Second: 10,612.94591

Timestep Collection Time: 2.25950
Timestep Consumption Time: 2.45229
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.71179

Cumulative Model Updates: 126,678
Cumulative Timesteps: 1,056,580,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1056580780...
Checkpoint 1056580780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.93025
Policy Entropy: 3.23102
Value Function Loss: 0.00384

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.56062
Value Function Update Magnitude: 0.51454

Collected Steps per Second: 21,636.71111
Overall Steps per Second: 10,478.56368

Timestep Collection Time: 2.31126
Timestep Consumption Time: 2.46115
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.77241

Cumulative Model Updates: 126,684
Cumulative Timesteps: 1,056,630,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.20418
Policy Entropy: 3.21962
Value Function Loss: 0.00385

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.52670

Collected Steps per Second: 21,944.70687
Overall Steps per Second: 10,509.18943

Timestep Collection Time: 2.27973
Timestep Consumption Time: 2.48068
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.76041

Cumulative Model Updates: 126,690
Cumulative Timesteps: 1,056,680,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1056680816...
Checkpoint 1056680816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,486.78433
Policy Entropy: 3.21967
Value Function Loss: 0.00347

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.51615

Collected Steps per Second: 21,508.86803
Overall Steps per Second: 10,612.35373

Timestep Collection Time: 2.32565
Timestep Consumption Time: 2.38792
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.71356

Cumulative Model Updates: 126,696
Cumulative Timesteps: 1,056,730,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.08548
Policy Entropy: 3.21205
Value Function Loss: 0.00373

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.49231

Collected Steps per Second: 21,996.16857
Overall Steps per Second: 10,546.00038

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.46821
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.74151

Cumulative Model Updates: 126,702
Cumulative Timesteps: 1,056,780,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1056780842...
Checkpoint 1056780842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.86597
Policy Entropy: 3.21662
Value Function Loss: 0.00370

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.54494
Value Function Update Magnitude: 0.50764

Collected Steps per Second: 21,202.91432
Overall Steps per Second: 10,253.39088

Timestep Collection Time: 2.35854
Timestep Consumption Time: 2.51867
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.87722

Cumulative Model Updates: 126,708
Cumulative Timesteps: 1,056,830,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.20570
Policy Entropy: 3.20851
Value Function Loss: 0.00378

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.54631
Value Function Update Magnitude: 0.50164

Collected Steps per Second: 21,686.40230
Overall Steps per Second: 10,619.57466

Timestep Collection Time: 2.30559
Timestep Consumption Time: 2.40269
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.70829

Cumulative Model Updates: 126,714
Cumulative Timesteps: 1,056,880,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1056880850...
Checkpoint 1056880850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.26900
Policy Entropy: 3.20739
Value Function Loss: 0.00361

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.49289

Collected Steps per Second: 19,541.13954
Overall Steps per Second: 9,981.83468

Timestep Collection Time: 2.55952
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 5.01070

Cumulative Model Updates: 126,720
Cumulative Timesteps: 1,056,930,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.56892
Policy Entropy: 3.21085
Value Function Loss: 0.00364

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.56039
Value Function Update Magnitude: 0.49588

Collected Steps per Second: 21,817.01720
Overall Steps per Second: 10,573.73816

Timestep Collection Time: 2.29307
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.73134

Cumulative Model Updates: 126,726
Cumulative Timesteps: 1,056,980,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1056980894...
Checkpoint 1056980894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.86969
Policy Entropy: 3.21945
Value Function Loss: 0.00379

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.50534

Collected Steps per Second: 21,501.51763
Overall Steps per Second: 10,425.77899

Timestep Collection Time: 2.32625
Timestep Consumption Time: 2.47128
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.79753

Cumulative Model Updates: 126,732
Cumulative Timesteps: 1,057,030,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.10075
Policy Entropy: 3.21817
Value Function Loss: 0.00376

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.57080
Value Function Update Magnitude: 0.50755

Collected Steps per Second: 21,671.21838
Overall Steps per Second: 10,297.10935

Timestep Collection Time: 2.30730
Timestep Consumption Time: 2.54863
PPO Batch Consumption Time: 0.30541
Total Iteration Time: 4.85593

Cumulative Model Updates: 126,738
Cumulative Timesteps: 1,057,080,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1057080914...
Checkpoint 1057080914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.76919
Policy Entropy: 3.22953
Value Function Loss: 0.00417

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.50692

Collected Steps per Second: 21,692.31369
Overall Steps per Second: 10,531.29057

Timestep Collection Time: 2.30506
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.74795

Cumulative Model Updates: 126,744
Cumulative Timesteps: 1,057,130,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.69913
Policy Entropy: 3.21872
Value Function Loss: 0.00412

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.55938
Value Function Update Magnitude: 0.51637

Collected Steps per Second: 22,426.42674
Overall Steps per Second: 10,732.60892

Timestep Collection Time: 2.23023
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.66019

Cumulative Model Updates: 126,750
Cumulative Timesteps: 1,057,180,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1057180932...
Checkpoint 1057180932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,476.91761
Policy Entropy: 3.20743
Value Function Loss: 0.00411

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.57199
Value Function Update Magnitude: 0.53324

Collected Steps per Second: 21,819.97071
Overall Steps per Second: 10,648.14329

Timestep Collection Time: 2.29212
Timestep Consumption Time: 2.40485
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.69697

Cumulative Model Updates: 126,756
Cumulative Timesteps: 1,057,230,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.58410
Policy Entropy: 3.20517
Value Function Loss: 0.00397

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.56512
Value Function Update Magnitude: 0.53201

Collected Steps per Second: 21,976.44339
Overall Steps per Second: 10,525.71270

Timestep Collection Time: 2.27635
Timestep Consumption Time: 2.47640
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.75274

Cumulative Model Updates: 126,762
Cumulative Timesteps: 1,057,280,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1057280972...
Checkpoint 1057280972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.41239
Policy Entropy: 3.20572
Value Function Loss: 0.00408

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.50959

Collected Steps per Second: 21,925.30403
Overall Steps per Second: 10,541.52989

Timestep Collection Time: 2.28102
Timestep Consumption Time: 2.46327
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.74428

Cumulative Model Updates: 126,768
Cumulative Timesteps: 1,057,330,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.29918
Policy Entropy: 3.21016
Value Function Loss: 0.00406

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.55681
Value Function Update Magnitude: 0.50441

Collected Steps per Second: 21,969.62633
Overall Steps per Second: 10,533.36662

Timestep Collection Time: 2.27669
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.74853

Cumulative Model Updates: 126,774
Cumulative Timesteps: 1,057,381,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1057381002...
Checkpoint 1057381002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.89305
Policy Entropy: 3.20728
Value Function Loss: 0.00395

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.51590

Collected Steps per Second: 21,988.17226
Overall Steps per Second: 10,588.20994

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.72450

Cumulative Model Updates: 126,780
Cumulative Timesteps: 1,057,431,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.43229
Policy Entropy: 3.20416
Value Function Loss: 0.00390

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.51413

Collected Steps per Second: 21,815.88491
Overall Steps per Second: 10,505.69774

Timestep Collection Time: 2.29209
Timestep Consumption Time: 2.46761
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.75970

Cumulative Model Updates: 126,786
Cumulative Timesteps: 1,057,481,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1057481030...
Checkpoint 1057481030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.37016
Policy Entropy: 3.20596
Value Function Loss: 0.00379

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.51819

Collected Steps per Second: 21,481.81387
Overall Steps per Second: 10,546.14425

Timestep Collection Time: 2.32792
Timestep Consumption Time: 2.41391
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.74183

Cumulative Model Updates: 126,792
Cumulative Timesteps: 1,057,531,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.79379
Policy Entropy: 3.19016
Value Function Loss: 0.00398

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.56298
Value Function Update Magnitude: 0.50851

Collected Steps per Second: 22,906.34064
Overall Steps per Second: 10,580.10700

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.54447
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.72850

Cumulative Model Updates: 126,798
Cumulative Timesteps: 1,057,581,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1057581066...
Checkpoint 1057581066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.11686
Policy Entropy: 3.18435
Value Function Loss: 0.00431

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.57237
Value Function Update Magnitude: 0.51234

Collected Steps per Second: 22,124.46745
Overall Steps per Second: 10,421.41017

Timestep Collection Time: 2.26003
Timestep Consumption Time: 2.53798
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.79801

Cumulative Model Updates: 126,804
Cumulative Timesteps: 1,057,631,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.79539
Policy Entropy: 3.19384
Value Function Loss: 0.00416

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.57334
Value Function Update Magnitude: 0.52415

Collected Steps per Second: 22,568.98824
Overall Steps per Second: 10,592.22419

Timestep Collection Time: 2.21596
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.72158

Cumulative Model Updates: 126,810
Cumulative Timesteps: 1,057,681,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1057681080...
Checkpoint 1057681080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.24030
Policy Entropy: 3.19853
Value Function Loss: 0.00417

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.57004
Value Function Update Magnitude: 0.51431

Collected Steps per Second: 22,325.25476
Overall Steps per Second: 10,616.31239

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.70973

Cumulative Model Updates: 126,816
Cumulative Timesteps: 1,057,731,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.14724
Policy Entropy: 3.21440
Value Function Loss: 0.00434

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.56850
Value Function Update Magnitude: 0.50945

Collected Steps per Second: 22,597.14005
Overall Steps per Second: 10,426.34762

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.58308
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.79593

Cumulative Model Updates: 126,822
Cumulative Timesteps: 1,057,781,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1057781084...
Checkpoint 1057781084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.47631
Policy Entropy: 3.21109
Value Function Loss: 0.00461

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.57960
Value Function Update Magnitude: 0.54009

Collected Steps per Second: 21,701.16077
Overall Steps per Second: 10,080.62039

Timestep Collection Time: 2.30596
Timestep Consumption Time: 2.65822
PPO Batch Consumption Time: 0.30623
Total Iteration Time: 4.96418

Cumulative Model Updates: 126,828
Cumulative Timesteps: 1,057,831,126

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.32597
Policy Entropy: 3.20669
Value Function Loss: 0.00474

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.53982

Collected Steps per Second: 22,273.57420
Overall Steps per Second: 10,570.81827

Timestep Collection Time: 2.24481
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.73000

Cumulative Model Updates: 126,834
Cumulative Timesteps: 1,057,881,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1057881126...
Checkpoint 1057881126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.32511
Policy Entropy: 3.19920
Value Function Loss: 0.00420

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.58203
Value Function Update Magnitude: 0.52330

Collected Steps per Second: 22,553.31922
Overall Steps per Second: 10,666.16747

Timestep Collection Time: 2.21812
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.69016

Cumulative Model Updates: 126,840
Cumulative Timesteps: 1,057,931,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,082.97464
Policy Entropy: 3.20610
Value Function Loss: 0.00430

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.57462
Value Function Update Magnitude: 0.51214

Collected Steps per Second: 22,312.33612
Overall Steps per Second: 10,533.14278

Timestep Collection Time: 2.24136
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.74787

Cumulative Model Updates: 126,846
Cumulative Timesteps: 1,057,981,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1057981162...
Checkpoint 1057981162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.23705
Policy Entropy: 3.22113
Value Function Loss: 0.00437

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.58309
Value Function Update Magnitude: 0.52437

Collected Steps per Second: 22,301.82722
Overall Steps per Second: 10,577.46002

Timestep Collection Time: 2.24224
Timestep Consumption Time: 2.48536
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.72760

Cumulative Model Updates: 126,852
Cumulative Timesteps: 1,058,031,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.28156
Policy Entropy: 3.22547
Value Function Loss: 0.00451

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.58874
Value Function Update Magnitude: 0.54001

Collected Steps per Second: 22,407.20888
Overall Steps per Second: 10,479.57126

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.54007
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.77176

Cumulative Model Updates: 126,858
Cumulative Timesteps: 1,058,081,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1058081174...
Checkpoint 1058081174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.38846
Policy Entropy: 3.22492
Value Function Loss: 0.00412

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.57301
Value Function Update Magnitude: 0.52868

Collected Steps per Second: 22,438.98512
Overall Steps per Second: 10,639.62709

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.69960

Cumulative Model Updates: 126,864
Cumulative Timesteps: 1,058,131,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.58426
Policy Entropy: 3.22335
Value Function Loss: 0.00379

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.49405

Collected Steps per Second: 22,699.18528
Overall Steps per Second: 10,511.79601

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.55466
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.75808

Cumulative Model Updates: 126,870
Cumulative Timesteps: 1,058,181,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1058181192...
Checkpoint 1058181192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.86012
Policy Entropy: 3.22257
Value Function Loss: 0.00394

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.56387
Value Function Update Magnitude: 0.49004

Collected Steps per Second: 22,450.86265
Overall Steps per Second: 10,637.54282

Timestep Collection Time: 2.22771
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.70165

Cumulative Model Updates: 126,876
Cumulative Timesteps: 1,058,231,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.66971
Policy Entropy: 3.22069
Value Function Loss: 0.00408

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.57084
Value Function Update Magnitude: 0.51961

Collected Steps per Second: 21,308.95155
Overall Steps per Second: 9,770.67709

Timestep Collection Time: 2.34671
Timestep Consumption Time: 2.77125
PPO Batch Consumption Time: 0.32976
Total Iteration Time: 5.11797

Cumulative Model Updates: 126,882
Cumulative Timesteps: 1,058,281,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1058281212...
Checkpoint 1058281212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.94959
Policy Entropy: 3.22094
Value Function Loss: 0.00437

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.57656
Value Function Update Magnitude: 0.53760

Collected Steps per Second: 21,933.46108
Overall Steps per Second: 10,454.16234

Timestep Collection Time: 2.28072
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.78508

Cumulative Model Updates: 126,888
Cumulative Timesteps: 1,058,331,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.12777
Policy Entropy: 3.23816
Value Function Loss: 0.00432

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 22,505.41777
Overall Steps per Second: 10,446.12516

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.56529
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.78742

Cumulative Model Updates: 126,894
Cumulative Timesteps: 1,058,381,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1058381246...
Checkpoint 1058381246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.98720
Policy Entropy: 3.25665
Value Function Loss: 0.00434

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.56627

Collected Steps per Second: 22,771.42719
Overall Steps per Second: 10,639.30281

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.50472
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70125

Cumulative Model Updates: 126,900
Cumulative Timesteps: 1,058,431,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.29880
Policy Entropy: 3.25993
Value Function Loss: 0.00461

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.57942
Value Function Update Magnitude: 0.54085

Collected Steps per Second: 22,423.97465
Overall Steps per Second: 10,501.32316

Timestep Collection Time: 2.23118
Timestep Consumption Time: 2.53317
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.76435

Cumulative Model Updates: 126,906
Cumulative Timesteps: 1,058,481,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1058481296...
Checkpoint 1058481296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.81244
Policy Entropy: 3.25531
Value Function Loss: 0.00463

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.57771
Value Function Update Magnitude: 0.56468

Collected Steps per Second: 22,487.44391
Overall Steps per Second: 10,602.65059

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.49383
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.71863

Cumulative Model Updates: 126,912
Cumulative Timesteps: 1,058,531,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.61684
Policy Entropy: 3.24538
Value Function Loss: 0.00410

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.53738

Collected Steps per Second: 20,898.76473
Overall Steps per Second: 10,418.47174

Timestep Collection Time: 2.39296
Timestep Consumption Time: 2.40716
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.80013

Cumulative Model Updates: 126,918
Cumulative Timesteps: 1,058,581,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1058581336...
Checkpoint 1058581336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.29066
Policy Entropy: 3.25159
Value Function Loss: 0.00375

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.50593

Collected Steps per Second: 21,695.97211
Overall Steps per Second: 10,622.74741

Timestep Collection Time: 2.30476
Timestep Consumption Time: 2.40250
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.70726

Cumulative Model Updates: 126,924
Cumulative Timesteps: 1,058,631,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.47584
Policy Entropy: 3.24991
Value Function Loss: 0.00380

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.55919
Value Function Update Magnitude: 0.53761

Collected Steps per Second: 22,134.19616
Overall Steps per Second: 10,511.75010

Timestep Collection Time: 2.25913
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 4.75696

Cumulative Model Updates: 126,930
Cumulative Timesteps: 1,058,681,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1058681344...
Checkpoint 1058681344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.81784
Policy Entropy: 3.23882
Value Function Loss: 0.00396

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.55745
Value Function Update Magnitude: 0.56150

Collected Steps per Second: 21,828.32611
Overall Steps per Second: 10,672.21628

Timestep Collection Time: 2.29152
Timestep Consumption Time: 2.39542
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.68694

Cumulative Model Updates: 126,936
Cumulative Timesteps: 1,058,731,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.35469
Policy Entropy: 3.23628
Value Function Loss: 0.00401

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.56146
Value Function Update Magnitude: 0.56949

Collected Steps per Second: 22,747.57878
Overall Steps per Second: 10,351.22966

Timestep Collection Time: 2.19874
Timestep Consumption Time: 2.63315
PPO Batch Consumption Time: 0.31126
Total Iteration Time: 4.83189

Cumulative Model Updates: 126,942
Cumulative Timesteps: 1,058,781,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1058781380...
Checkpoint 1058781380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.41093
Policy Entropy: 3.24450
Value Function Loss: 0.00390

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.56381

Collected Steps per Second: 22,627.45040
Overall Steps per Second: 10,710.23857

Timestep Collection Time: 2.21068
Timestep Consumption Time: 2.45981
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.67048

Cumulative Model Updates: 126,948
Cumulative Timesteps: 1,058,831,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.23032
Policy Entropy: 3.25598
Value Function Loss: 0.00407

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.54200

Collected Steps per Second: 20,932.59766
Overall Steps per Second: 10,121.54619

Timestep Collection Time: 2.38910
Timestep Consumption Time: 2.55185
PPO Batch Consumption Time: 0.31030
Total Iteration Time: 4.94094

Cumulative Model Updates: 126,954
Cumulative Timesteps: 1,058,881,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1058881412...
Checkpoint 1058881412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.33823
Policy Entropy: 3.24945
Value Function Loss: 0.00404

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.55796
Value Function Update Magnitude: 0.54392

Collected Steps per Second: 21,513.66991
Overall Steps per Second: 10,403.90521

Timestep Collection Time: 2.32438
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.80646

Cumulative Model Updates: 126,960
Cumulative Timesteps: 1,058,931,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.57149
Policy Entropy: 3.23614
Value Function Loss: 0.00410

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11102
Policy Update Magnitude: 0.57539
Value Function Update Magnitude: 0.55085

Collected Steps per Second: 22,372.26705
Overall Steps per Second: 10,558.76638

Timestep Collection Time: 2.23616
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.73805

Cumulative Model Updates: 126,966
Cumulative Timesteps: 1,058,981,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1058981446...
Checkpoint 1058981446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.73374
Policy Entropy: 3.22589
Value Function Loss: 0.00440

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.58233
Value Function Update Magnitude: 0.56965

Collected Steps per Second: 20,519.85464
Overall Steps per Second: 10,258.57563

Timestep Collection Time: 2.43735
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.87534

Cumulative Model Updates: 126,972
Cumulative Timesteps: 1,059,031,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.56253
Policy Entropy: 3.23544
Value Function Loss: 0.00449

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.58679
Value Function Update Magnitude: 0.59419

Collected Steps per Second: 19,191.31639
Overall Steps per Second: 9,886.54490

Timestep Collection Time: 2.60618
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 5.05900

Cumulative Model Updates: 126,978
Cumulative Timesteps: 1,059,081,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1059081476...
Checkpoint 1059081476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.50862
Policy Entropy: 3.24741
Value Function Loss: 0.00453

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.57881
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 22,520.18623
Overall Steps per Second: 10,519.77798

Timestep Collection Time: 2.22112
Timestep Consumption Time: 2.53373
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.75485

Cumulative Model Updates: 126,984
Cumulative Timesteps: 1,059,131,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.86615
Policy Entropy: 3.24566
Value Function Loss: 0.00479

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.57775
Value Function Update Magnitude: 0.60276

Collected Steps per Second: 23,059.45853
Overall Steps per Second: 10,740.71289

Timestep Collection Time: 2.16848
Timestep Consumption Time: 2.48708
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.65556

Cumulative Model Updates: 126,990
Cumulative Timesteps: 1,059,181,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1059181500...
Checkpoint 1059181500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.36767
Policy Entropy: 3.24702
Value Function Loss: 0.00467

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.59365

Collected Steps per Second: 22,285.79464
Overall Steps per Second: 10,625.14634

Timestep Collection Time: 2.24430
Timestep Consumption Time: 2.46302
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.70732

Cumulative Model Updates: 126,996
Cumulative Timesteps: 1,059,231,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.77497
Policy Entropy: 3.24504
Value Function Loss: 0.00442

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.56108

Collected Steps per Second: 22,624.34538
Overall Steps per Second: 10,439.78758

Timestep Collection Time: 2.21133
Timestep Consumption Time: 2.58091
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.79224

Cumulative Model Updates: 127,002
Cumulative Timesteps: 1,059,281,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1059281546...
Checkpoint 1059281546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.34612
Policy Entropy: 3.25705
Value Function Loss: 0.00395

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.55108

Collected Steps per Second: 22,083.08833
Overall Steps per Second: 10,590.19839

Timestep Collection Time: 2.26490
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.72286

Cumulative Model Updates: 127,008
Cumulative Timesteps: 1,059,331,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.01119
Policy Entropy: 3.25640
Value Function Loss: 0.00352

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.55144
Value Function Update Magnitude: 0.54459

Collected Steps per Second: 22,667.36862
Overall Steps per Second: 10,564.70527

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.52804
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.73482

Cumulative Model Updates: 127,014
Cumulative Timesteps: 1,059,381,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1059381584...
Checkpoint 1059381584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.01054
Policy Entropy: 3.26060
Value Function Loss: 0.00361

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.51611

Collected Steps per Second: 22,198.02130
Overall Steps per Second: 10,539.98077

Timestep Collection Time: 2.25317
Timestep Consumption Time: 2.49219
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.74536

Cumulative Model Updates: 127,020
Cumulative Timesteps: 1,059,431,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.08643
Policy Entropy: 3.25034
Value Function Loss: 0.00399

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.55057
Value Function Update Magnitude: 0.52309

Collected Steps per Second: 22,441.83112
Overall Steps per Second: 10,567.90880

Timestep Collection Time: 2.22896
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.73339

Cumulative Model Updates: 127,026
Cumulative Timesteps: 1,059,481,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1059481622...
Checkpoint 1059481622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.67046
Policy Entropy: 3.24927
Value Function Loss: 0.00425

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.56131

Collected Steps per Second: 21,747.47301
Overall Steps per Second: 10,346.16321

Timestep Collection Time: 2.30041
Timestep Consumption Time: 2.53501
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.83542

Cumulative Model Updates: 127,032
Cumulative Timesteps: 1,059,531,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.52632
Policy Entropy: 3.23939
Value Function Loss: 0.00434

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.57931
Value Function Update Magnitude: 0.58093

Collected Steps per Second: 22,539.69960
Overall Steps per Second: 10,690.43485

Timestep Collection Time: 2.21946
Timestep Consumption Time: 2.46005
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.67951

Cumulative Model Updates: 127,038
Cumulative Timesteps: 1,059,581,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1059581676...
Checkpoint 1059581676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.71604
Policy Entropy: 3.24274
Value Function Loss: 0.00414

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.57784
Value Function Update Magnitude: 0.57039

Collected Steps per Second: 22,226.91354
Overall Steps per Second: 10,445.99178

Timestep Collection Time: 2.25096
Timestep Consumption Time: 2.53862
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.78959

Cumulative Model Updates: 127,044
Cumulative Timesteps: 1,059,631,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.55840
Policy Entropy: 3.24759
Value Function Loss: 0.00440

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.56452
Value Function Update Magnitude: 0.55004

Collected Steps per Second: 22,939.97977
Overall Steps per Second: 10,712.53086

Timestep Collection Time: 2.18056
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.66948

Cumulative Model Updates: 127,050
Cumulative Timesteps: 1,059,681,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1059681730...
Checkpoint 1059681730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928.84813
Policy Entropy: 3.25142
Value Function Loss: 0.00428

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.52852

Collected Steps per Second: 22,220.55433
Overall Steps per Second: 10,561.69397

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.48412
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.73447

Cumulative Model Updates: 127,056
Cumulative Timesteps: 1,059,731,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.21467
Policy Entropy: 3.25030
Value Function Loss: 0.00445

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.54324

Collected Steps per Second: 22,798.57500
Overall Steps per Second: 10,501.44935

Timestep Collection Time: 2.19373
Timestep Consumption Time: 2.56885
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.76258

Cumulative Model Updates: 127,062
Cumulative Timesteps: 1,059,781,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1059781748...
Checkpoint 1059781748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.95355
Policy Entropy: 3.25116
Value Function Loss: 0.00422

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.55760

Collected Steps per Second: 21,905.78489
Overall Steps per Second: 10,390.53331

Timestep Collection Time: 2.28323
Timestep Consumption Time: 2.53038
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.81361

Cumulative Model Updates: 127,068
Cumulative Timesteps: 1,059,831,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.74441
Policy Entropy: 3.24641
Value Function Loss: 0.00409

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.56184
Value Function Update Magnitude: 0.53521

Collected Steps per Second: 22,765.62692
Overall Steps per Second: 10,552.71701

Timestep Collection Time: 2.19787
Timestep Consumption Time: 2.54365
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.74153

Cumulative Model Updates: 127,074
Cumulative Timesteps: 1,059,881,800

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1059881800...
Checkpoint 1059881800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.55941
Policy Entropy: 3.24581
Value Function Loss: 0.00396

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.55186
Value Function Update Magnitude: 0.52489

Collected Steps per Second: 22,255.56389
Overall Steps per Second: 10,441.71690

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.54277
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.79021

Cumulative Model Updates: 127,080
Cumulative Timesteps: 1,059,931,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.20652
Policy Entropy: 3.23258
Value Function Loss: 0.00407

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.55529
Value Function Update Magnitude: 0.52263

Collected Steps per Second: 22,719.79115
Overall Steps per Second: 10,582.26831

Timestep Collection Time: 2.20116
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.72583

Cumulative Model Updates: 127,086
Cumulative Timesteps: 1,059,981,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1059981828...
Checkpoint 1059981828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.95435
Policy Entropy: 3.23471
Value Function Loss: 0.00398

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.52639

Collected Steps per Second: 21,953.48442
Overall Steps per Second: 10,460.84301

Timestep Collection Time: 2.27845
Timestep Consumption Time: 2.50319
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.78164

Cumulative Model Updates: 127,092
Cumulative Timesteps: 1,060,031,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.04963
Policy Entropy: 3.23770
Value Function Loss: 0.00378

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.53139

Collected Steps per Second: 21,448.75917
Overall Steps per Second: 10,373.96813

Timestep Collection Time: 2.33179
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.82111

Cumulative Model Updates: 127,098
Cumulative Timesteps: 1,060,081,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1060081862...
Checkpoint 1060081862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.83504
Policy Entropy: 3.25588
Value Function Loss: 0.00357

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.54262

Collected Steps per Second: 22,030.18319
Overall Steps per Second: 10,422.79975

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.52787
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.79775

Cumulative Model Updates: 127,104
Cumulative Timesteps: 1,060,131,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.98940
Policy Entropy: 3.26670
Value Function Loss: 0.00371

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.55770
Value Function Update Magnitude: 0.54883

Collected Steps per Second: 21,872.57193
Overall Steps per Second: 10,653.79133

Timestep Collection Time: 2.28615
Timestep Consumption Time: 2.40739
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.69354

Cumulative Model Updates: 127,110
Cumulative Timesteps: 1,060,181,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1060181872...
Checkpoint 1060181872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.40901
Policy Entropy: 3.25318
Value Function Loss: 0.00412

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.55925
Value Function Update Magnitude: 0.53875

Collected Steps per Second: 21,396.59115
Overall Steps per Second: 10,432.22942

Timestep Collection Time: 2.33832
Timestep Consumption Time: 2.45759
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.79591

Cumulative Model Updates: 127,116
Cumulative Timesteps: 1,060,231,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.00125
Policy Entropy: 3.24117
Value Function Loss: 0.00419

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.53751

Collected Steps per Second: 22,007.76271
Overall Steps per Second: 10,476.23587

Timestep Collection Time: 2.27202
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 4.77290

Cumulative Model Updates: 127,122
Cumulative Timesteps: 1,060,281,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1060281906...
Checkpoint 1060281906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.49286
Policy Entropy: 3.22451
Value Function Loss: 0.00415

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.55964

Collected Steps per Second: 21,118.64841
Overall Steps per Second: 10,441.51313

Timestep Collection Time: 2.36890
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.79126

Cumulative Model Updates: 127,128
Cumulative Timesteps: 1,060,331,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.10448
Policy Entropy: 3.22127
Value Function Loss: 0.00384

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.56073
Value Function Update Magnitude: 0.55689

Collected Steps per Second: 22,049.39869
Overall Steps per Second: 10,487.54286

Timestep Collection Time: 2.26872
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.76985

Cumulative Model Updates: 127,134
Cumulative Timesteps: 1,060,381,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1060381958...
Checkpoint 1060381958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.97908
Policy Entropy: 3.22561
Value Function Loss: 0.00407

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.56993
Value Function Update Magnitude: 0.53078

Collected Steps per Second: 22,102.92244
Overall Steps per Second: 10,456.52668

Timestep Collection Time: 2.26278
Timestep Consumption Time: 2.52026
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.78304

Cumulative Model Updates: 127,140
Cumulative Timesteps: 1,060,431,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.62856
Policy Entropy: 3.24448
Value Function Loss: 0.00418

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.56768
Value Function Update Magnitude: 0.53162

Collected Steps per Second: 22,501.64322
Overall Steps per Second: 10,383.42051

Timestep Collection Time: 2.22277
Timestep Consumption Time: 2.59414
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 4.81691

Cumulative Model Updates: 127,146
Cumulative Timesteps: 1,060,481,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1060481988...
Checkpoint 1060481988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.33315
Policy Entropy: 3.25720
Value Function Loss: 0.00412

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.55894
Value Function Update Magnitude: 0.53198

Collected Steps per Second: 19,935.64235
Overall Steps per Second: 9,859.14935

Timestep Collection Time: 2.50817
Timestep Consumption Time: 2.56346
PPO Batch Consumption Time: 0.31139
Total Iteration Time: 5.07163

Cumulative Model Updates: 127,152
Cumulative Timesteps: 1,060,531,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.85571
Policy Entropy: 3.24488
Value Function Loss: 0.00442

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.56664
Value Function Update Magnitude: 0.55366

Collected Steps per Second: 20,107.02596
Overall Steps per Second: 9,915.36820

Timestep Collection Time: 2.48689
Timestep Consumption Time: 2.55619
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 5.04308

Cumulative Model Updates: 127,158
Cumulative Timesteps: 1,060,581,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1060581994...
Checkpoint 1060581994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.71366
Policy Entropy: 3.22428
Value Function Loss: 0.00439

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.58000

Collected Steps per Second: 22,150.99927
Overall Steps per Second: 10,551.36261

Timestep Collection Time: 2.25732
Timestep Consumption Time: 2.48159
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.73891

Cumulative Model Updates: 127,164
Cumulative Timesteps: 1,060,631,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 872.42429
Policy Entropy: 3.20648
Value Function Loss: 0.00404

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.57448
Value Function Update Magnitude: 0.56496

Collected Steps per Second: 22,532.25207
Overall Steps per Second: 10,486.36411

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.54957
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.76905

Cumulative Model Updates: 127,170
Cumulative Timesteps: 1,060,682,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1060682006...
Checkpoint 1060682006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.39267
Policy Entropy: 3.21419
Value Function Loss: 0.00393

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.57099
Value Function Update Magnitude: 0.52628

Collected Steps per Second: 22,662.90082
Overall Steps per Second: 10,614.39840

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.71171

Cumulative Model Updates: 127,176
Cumulative Timesteps: 1,060,732,018

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,231.06639
Policy Entropy: 3.21898
Value Function Loss: 0.00375

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09196
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.50532

Collected Steps per Second: 21,602.58803
Overall Steps per Second: 10,462.40387

Timestep Collection Time: 2.31602
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.78208

Cumulative Model Updates: 127,182
Cumulative Timesteps: 1,060,782,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1060782050...
Checkpoint 1060782050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.41304
Policy Entropy: 3.22391
Value Function Loss: 0.00378

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.55661
Value Function Update Magnitude: 0.49958

Collected Steps per Second: 21,571.50385
Overall Steps per Second: 10,629.11592

Timestep Collection Time: 2.31908
Timestep Consumption Time: 2.38743
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.70651

Cumulative Model Updates: 127,188
Cumulative Timesteps: 1,060,832,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.15114
Policy Entropy: 3.22602
Value Function Loss: 0.00371

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.51007

Collected Steps per Second: 21,917.15618
Overall Steps per Second: 10,454.34805

Timestep Collection Time: 2.28241
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.78499

Cumulative Model Updates: 127,194
Cumulative Timesteps: 1,060,882,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1060882100...
Checkpoint 1060882100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.51589
Policy Entropy: 3.21797
Value Function Loss: 0.00391

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.56501
Value Function Update Magnitude: 0.51931

Collected Steps per Second: 21,917.59351
Overall Steps per Second: 10,343.60348

Timestep Collection Time: 2.28155
Timestep Consumption Time: 2.55294
PPO Batch Consumption Time: 0.31209
Total Iteration Time: 4.83449

Cumulative Model Updates: 127,200
Cumulative Timesteps: 1,060,932,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.85854
Policy Entropy: 3.21988
Value Function Loss: 0.00378

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.55901
Value Function Update Magnitude: 0.50824

Collected Steps per Second: 20,704.67670
Overall Steps per Second: 10,267.49931

Timestep Collection Time: 2.41607
Timestep Consumption Time: 2.45600
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.87207

Cumulative Model Updates: 127,206
Cumulative Timesteps: 1,060,982,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1060982130...
Checkpoint 1060982130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.27641
Policy Entropy: 3.20331
Value Function Loss: 0.00392

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.49597

Collected Steps per Second: 22,482.53421
Overall Steps per Second: 10,582.20043

Timestep Collection Time: 2.22475
Timestep Consumption Time: 2.50187
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.72662

Cumulative Model Updates: 127,212
Cumulative Timesteps: 1,061,032,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.44675
Policy Entropy: 3.20426
Value Function Loss: 0.00441

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.55777
Value Function Update Magnitude: 0.49551

Collected Steps per Second: 21,642.22157
Overall Steps per Second: 10,583.49072

Timestep Collection Time: 2.31132
Timestep Consumption Time: 2.41510
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.72642

Cumulative Model Updates: 127,218
Cumulative Timesteps: 1,061,082,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1061082170...
Checkpoint 1061082170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,390.75363
Policy Entropy: 3.19608
Value Function Loss: 0.00425

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.52826

Collected Steps per Second: 21,512.88731
Overall Steps per Second: 10,555.46722

Timestep Collection Time: 2.32549
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.73953

Cumulative Model Updates: 127,224
Cumulative Timesteps: 1,061,132,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.62952
Policy Entropy: 3.20707
Value Function Loss: 0.00378

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.53139

Collected Steps per Second: 21,896.25702
Overall Steps per Second: 10,457.91377

Timestep Collection Time: 2.28350
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.30110
Total Iteration Time: 4.78107

Cumulative Model Updates: 127,230
Cumulative Timesteps: 1,061,182,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1061182198...
Checkpoint 1061182198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.38949
Policy Entropy: 3.19671
Value Function Loss: 0.00412

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.57440
Value Function Update Magnitude: 0.53158

Collected Steps per Second: 20,846.03862
Overall Steps per Second: 10,129.40865

Timestep Collection Time: 2.39959
Timestep Consumption Time: 2.53870
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.93829

Cumulative Model Updates: 127,236
Cumulative Timesteps: 1,061,232,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.97325
Policy Entropy: 3.19253
Value Function Loss: 0.00428

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.59504
Value Function Update Magnitude: 0.56877

Collected Steps per Second: 22,281.43603
Overall Steps per Second: 10,551.78702

Timestep Collection Time: 2.24456
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.73967

Cumulative Model Updates: 127,242
Cumulative Timesteps: 1,061,282,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1061282232...
Checkpoint 1061282232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.31428
Policy Entropy: 3.18330
Value Function Loss: 0.00425

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.60538
Value Function Update Magnitude: 0.58363

Collected Steps per Second: 22,012.95361
Overall Steps per Second: 10,470.80055

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.77595

Cumulative Model Updates: 127,248
Cumulative Timesteps: 1,061,332,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.00837
Policy Entropy: 3.18873
Value Function Loss: 0.00408

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.59016
Value Function Update Magnitude: 0.57046

Collected Steps per Second: 21,618.45243
Overall Steps per Second: 10,086.33035

Timestep Collection Time: 2.31349
Timestep Consumption Time: 2.64511
PPO Batch Consumption Time: 0.30901
Total Iteration Time: 4.95859

Cumulative Model Updates: 127,254
Cumulative Timesteps: 1,061,382,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1061382254...
Checkpoint 1061382254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.62371
Policy Entropy: 3.19683
Value Function Loss: 0.00393

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.57700
Value Function Update Magnitude: 0.54429

Collected Steps per Second: 22,028.48608
Overall Steps per Second: 10,131.55200

Timestep Collection Time: 2.27088
Timestep Consumption Time: 2.66657
PPO Batch Consumption Time: 0.31952
Total Iteration Time: 4.93745

Cumulative Model Updates: 127,260
Cumulative Timesteps: 1,061,432,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.64851
Policy Entropy: 3.20128
Value Function Loss: 0.00422

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.58137
Value Function Update Magnitude: 0.51968

Collected Steps per Second: 22,124.78218
Overall Steps per Second: 10,264.90239

Timestep Collection Time: 2.26127
Timestep Consumption Time: 2.61262
PPO Batch Consumption Time: 0.30569
Total Iteration Time: 4.87389

Cumulative Model Updates: 127,266
Cumulative Timesteps: 1,061,482,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1061482308...
Checkpoint 1061482308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.04646
Policy Entropy: 3.19015
Value Function Loss: 0.00457

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.58915
Value Function Update Magnitude: 0.52957

Collected Steps per Second: 21,317.49628
Overall Steps per Second: 10,097.96072

Timestep Collection Time: 2.34643
Timestep Consumption Time: 2.60705
PPO Batch Consumption Time: 0.30583
Total Iteration Time: 4.95348

Cumulative Model Updates: 127,272
Cumulative Timesteps: 1,061,532,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.63274
Policy Entropy: 3.19439
Value Function Loss: 0.00479

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.59073
Value Function Update Magnitude: 0.56135

Collected Steps per Second: 21,491.69516
Overall Steps per Second: 10,229.88529

Timestep Collection Time: 2.32750
Timestep Consumption Time: 2.56229
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.88979

Cumulative Model Updates: 127,278
Cumulative Timesteps: 1,061,582,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1061582350...
Checkpoint 1061582350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.18941
Policy Entropy: 3.18530
Value Function Loss: 0.00443

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.56231

Collected Steps per Second: 22,212.05491
Overall Steps per Second: 10,616.24809

Timestep Collection Time: 2.25319
Timestep Consumption Time: 2.46109
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.71428

Cumulative Model Updates: 127,284
Cumulative Timesteps: 1,061,632,398

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.74591
Policy Entropy: 3.19760
Value Function Loss: 0.00439

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10700
Policy Update Magnitude: 0.57721
Value Function Update Magnitude: 0.53332

Collected Steps per Second: 22,314.43778
Overall Steps per Second: 10,441.15498

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.54855
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.78970

Cumulative Model Updates: 127,290
Cumulative Timesteps: 1,061,682,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1061682408...
Checkpoint 1061682408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.27030
Policy Entropy: 3.19415
Value Function Loss: 0.00439

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.55117

Collected Steps per Second: 22,394.66482
Overall Steps per Second: 10,594.73420

Timestep Collection Time: 2.23357
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.72121

Cumulative Model Updates: 127,296
Cumulative Timesteps: 1,061,732,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.87869
Policy Entropy: 3.18916
Value Function Loss: 0.00421

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.55242

Collected Steps per Second: 22,681.07958
Overall Steps per Second: 10,537.90517

Timestep Collection Time: 2.20492
Timestep Consumption Time: 2.54080
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.74572

Cumulative Model Updates: 127,302
Cumulative Timesteps: 1,061,782,438

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1061782438...
Checkpoint 1061782438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.38938
Policy Entropy: 3.19299
Value Function Loss: 0.00435

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.58937
Value Function Update Magnitude: 0.55419

Collected Steps per Second: 22,381.37489
Overall Steps per Second: 10,687.66698

Timestep Collection Time: 2.23463
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.67960

Cumulative Model Updates: 127,308
Cumulative Timesteps: 1,061,832,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.32181
Policy Entropy: 3.18933
Value Function Loss: 0.00473

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.56267

Collected Steps per Second: 22,269.04682
Overall Steps per Second: 10,378.78325

Timestep Collection Time: 2.24545
Timestep Consumption Time: 2.57246
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.81791

Cumulative Model Updates: 127,314
Cumulative Timesteps: 1,061,882,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1061882456...
Checkpoint 1061882456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.53990
Policy Entropy: 3.19971
Value Function Loss: 0.00467

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.58942
Value Function Update Magnitude: 0.58512

Collected Steps per Second: 22,576.67218
Overall Steps per Second: 10,691.77919

Timestep Collection Time: 2.21521
Timestep Consumption Time: 2.46241
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.67761

Cumulative Model Updates: 127,320
Cumulative Timesteps: 1,061,932,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.08812
Policy Entropy: 3.19964
Value Function Loss: 0.00485

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.59002
Value Function Update Magnitude: 0.56572

Collected Steps per Second: 22,416.21562
Overall Steps per Second: 10,437.38800

Timestep Collection Time: 2.23115
Timestep Consumption Time: 2.56066
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.79181

Cumulative Model Updates: 127,326
Cumulative Timesteps: 1,061,982,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1061982482...
Checkpoint 1061982482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.59089
Policy Entropy: 3.20889
Value Function Loss: 0.00447

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.58459
Value Function Update Magnitude: 0.58891

Collected Steps per Second: 22,184.29762
Overall Steps per Second: 10,558.23573

Timestep Collection Time: 2.25430
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.73659

Cumulative Model Updates: 127,332
Cumulative Timesteps: 1,062,032,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.01795
Policy Entropy: 3.20756
Value Function Loss: 0.00410

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.58909

Collected Steps per Second: 22,619.63859
Overall Steps per Second: 10,602.25287

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.71636

Cumulative Model Updates: 127,338
Cumulative Timesteps: 1,062,082,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1062082496...
Checkpoint 1062082496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.28568
Policy Entropy: 3.22590
Value Function Loss: 0.00376

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.54644

Collected Steps per Second: 22,403.23567
Overall Steps per Second: 10,599.83248

Timestep Collection Time: 2.23271
Timestep Consumption Time: 2.48623
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.71894

Cumulative Model Updates: 127,344
Cumulative Timesteps: 1,062,132,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.23279
Policy Entropy: 3.21899
Value Function Loss: 0.00394

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.52625

Collected Steps per Second: 22,207.08244
Overall Steps per Second: 10,340.35731

Timestep Collection Time: 2.25234
Timestep Consumption Time: 2.58482
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.83716

Cumulative Model Updates: 127,350
Cumulative Timesteps: 1,062,182,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1062182534...
Checkpoint 1062182534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.63868
Policy Entropy: 3.21466
Value Function Loss: 0.00422

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.56861
Value Function Update Magnitude: 0.54245

Collected Steps per Second: 21,769.62369
Overall Steps per Second: 10,240.60593

Timestep Collection Time: 2.29816
Timestep Consumption Time: 2.58730
PPO Batch Consumption Time: 0.30497
Total Iteration Time: 4.88545

Cumulative Model Updates: 127,356
Cumulative Timesteps: 1,062,232,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.64628
Policy Entropy: 3.19993
Value Function Loss: 0.00455

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.58979
Value Function Update Magnitude: 0.58310

Collected Steps per Second: 22,297.19894
Overall Steps per Second: 10,528.24157

Timestep Collection Time: 2.24360
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.75160

Cumulative Model Updates: 127,362
Cumulative Timesteps: 1,062,282,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1062282590...
Checkpoint 1062282590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.93826
Policy Entropy: 3.20374
Value Function Loss: 0.00445

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.59631
Value Function Update Magnitude: 0.58829

Collected Steps per Second: 22,002.89723
Overall Steps per Second: 10,583.88649

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.72492

Cumulative Model Updates: 127,368
Cumulative Timesteps: 1,062,332,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.84689
Policy Entropy: 3.19775
Value Function Loss: 0.00425

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.58669
Value Function Update Magnitude: 0.58361

Collected Steps per Second: 22,536.58038
Overall Steps per Second: 10,505.35478

Timestep Collection Time: 2.21959
Timestep Consumption Time: 2.54198
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.76157

Cumulative Model Updates: 127,374
Cumulative Timesteps: 1,062,382,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1062382620...
Checkpoint 1062382620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.24161
Policy Entropy: 3.20003
Value Function Loss: 0.00412

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.55402

Collected Steps per Second: 22,264.51491
Overall Steps per Second: 10,671.44588

Timestep Collection Time: 2.24573
Timestep Consumption Time: 2.43967
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.68540

Cumulative Model Updates: 127,380
Cumulative Timesteps: 1,062,432,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.98143
Policy Entropy: 3.18783
Value Function Loss: 0.00414

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.57820
Value Function Update Magnitude: 0.53930

Collected Steps per Second: 22,710.50360
Overall Steps per Second: 10,610.57653

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.71416

Cumulative Model Updates: 127,386
Cumulative Timesteps: 1,062,482,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1062482640...
Checkpoint 1062482640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.07306
Policy Entropy: 3.19353
Value Function Loss: 0.00400

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.58826
Value Function Update Magnitude: 0.54951

Collected Steps per Second: 22,439.93717
Overall Steps per Second: 10,480.39736

Timestep Collection Time: 2.22906
Timestep Consumption Time: 2.54366
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.77272

Cumulative Model Updates: 127,392
Cumulative Timesteps: 1,062,532,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.44041
Policy Entropy: 3.20129
Value Function Loss: 0.00383

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.57617
Value Function Update Magnitude: 0.53074

Collected Steps per Second: 22,354.99024
Overall Steps per Second: 10,700.46269

Timestep Collection Time: 2.23735
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.67419

Cumulative Model Updates: 127,398
Cumulative Timesteps: 1,062,582,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1062582676...
Checkpoint 1062582676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.38334
Policy Entropy: 3.19733
Value Function Loss: 0.00372

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.53296

Collected Steps per Second: 21,674.81119
Overall Steps per Second: 10,474.75585

Timestep Collection Time: 2.30775
Timestep Consumption Time: 2.46754
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.77529

Cumulative Model Updates: 127,404
Cumulative Timesteps: 1,062,632,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.56747
Policy Entropy: 3.19555
Value Function Loss: 0.00417

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.54696

Collected Steps per Second: 21,997.42301
Overall Steps per Second: 10,620.10134

Timestep Collection Time: 2.27381
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.70975

Cumulative Model Updates: 127,410
Cumulative Timesteps: 1,062,682,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1062682714...
Checkpoint 1062682714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.56395
Policy Entropy: 3.19143
Value Function Loss: 0.00441

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.58683
Value Function Update Magnitude: 0.56659

Collected Steps per Second: 21,746.51196
Overall Steps per Second: 10,479.92524

Timestep Collection Time: 2.29922
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.77103

Cumulative Model Updates: 127,416
Cumulative Timesteps: 1,062,732,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.19372
Policy Entropy: 3.19792
Value Function Loss: 0.00449

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.56898

Collected Steps per Second: 22,369.64083
Overall Steps per Second: 10,784.57433

Timestep Collection Time: 2.23607
Timestep Consumption Time: 2.40204
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.63811

Cumulative Model Updates: 127,422
Cumulative Timesteps: 1,062,782,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1062782734...
Checkpoint 1062782734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.93656
Policy Entropy: 3.20300
Value Function Loss: 0.00412

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.56084

Collected Steps per Second: 21,725.77853
Overall Steps per Second: 10,611.71147

Timestep Collection Time: 2.30141
Timestep Consumption Time: 2.41036
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.71178

Cumulative Model Updates: 127,428
Cumulative Timesteps: 1,062,832,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.95919
Policy Entropy: 3.20970
Value Function Loss: 0.00416

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.57713
Value Function Update Magnitude: 0.53513

Collected Steps per Second: 22,221.26865
Overall Steps per Second: 10,410.29732

Timestep Collection Time: 2.25118
Timestep Consumption Time: 2.55407
PPO Batch Consumption Time: 0.31100
Total Iteration Time: 4.80524

Cumulative Model Updates: 127,434
Cumulative Timesteps: 1,062,882,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1062882758...
Checkpoint 1062882758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.44870
Policy Entropy: 3.20199
Value Function Loss: 0.00419

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.54166

Collected Steps per Second: 21,370.38445
Overall Steps per Second: 10,396.90886

Timestep Collection Time: 2.33969
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.80912

Cumulative Model Updates: 127,440
Cumulative Timesteps: 1,062,932,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.13914
Policy Entropy: 3.20303
Value Function Loss: 0.00410

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.59005
Value Function Update Magnitude: 0.53293

Collected Steps per Second: 22,706.14401
Overall Steps per Second: 10,572.96405

Timestep Collection Time: 2.20284
Timestep Consumption Time: 2.52791
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.73075

Cumulative Model Updates: 127,446
Cumulative Timesteps: 1,062,982,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1062982776...
Checkpoint 1062982776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.43306
Policy Entropy: 3.20472
Value Function Loss: 0.00414

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.58654
Value Function Update Magnitude: 0.51860

Collected Steps per Second: 22,843.02660
Overall Steps per Second: 10,624.17529

Timestep Collection Time: 2.18981
Timestep Consumption Time: 2.51850
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.70832

Cumulative Model Updates: 127,452
Cumulative Timesteps: 1,063,032,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.66693
Policy Entropy: 3.20035
Value Function Loss: 0.00446

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.57188
Value Function Update Magnitude: 0.51726

Collected Steps per Second: 22,981.56034
Overall Steps per Second: 10,684.63932

Timestep Collection Time: 2.17592
Timestep Consumption Time: 2.50426
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.68018

Cumulative Model Updates: 127,458
Cumulative Timesteps: 1,063,082,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1063082804...
Checkpoint 1063082804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.47773
Policy Entropy: 3.18295
Value Function Loss: 0.00469

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.58353
Value Function Update Magnitude: 0.53008

Collected Steps per Second: 22,169.64569
Overall Steps per Second: 10,557.21032

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.48225
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.73894

Cumulative Model Updates: 127,464
Cumulative Timesteps: 1,063,132,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 856.67517
Policy Entropy: 3.18281
Value Function Loss: 0.00472

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.59608
Value Function Update Magnitude: 0.55647

Collected Steps per Second: 22,389.97468
Overall Steps per Second: 10,665.47133

Timestep Collection Time: 2.23377
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.68934

Cumulative Model Updates: 127,470
Cumulative Timesteps: 1,063,182,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1063182848...
Checkpoint 1063182848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.49371
Policy Entropy: 3.18117
Value Function Loss: 0.00449

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.59912
Value Function Update Magnitude: 0.57944

Collected Steps per Second: 22,438.94391
Overall Steps per Second: 10,566.60376

Timestep Collection Time: 2.22925
Timestep Consumption Time: 2.50472
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.73397

Cumulative Model Updates: 127,476
Cumulative Timesteps: 1,063,232,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.71223
Policy Entropy: 3.19037
Value Function Loss: 0.00425

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.59536
Value Function Update Magnitude: 0.57329

Collected Steps per Second: 22,581.24879
Overall Steps per Second: 10,495.54402

Timestep Collection Time: 2.21458
Timestep Consumption Time: 2.55011
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.76469

Cumulative Model Updates: 127,482
Cumulative Timesteps: 1,063,282,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1063282878...
Checkpoint 1063282878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.12255
Policy Entropy: 3.19026
Value Function Loss: 0.00417

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.59145
Value Function Update Magnitude: 0.57048

Collected Steps per Second: 22,495.13299
Overall Steps per Second: 10,586.02562

Timestep Collection Time: 2.22359
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.72510

Cumulative Model Updates: 127,488
Cumulative Timesteps: 1,063,332,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.41874
Policy Entropy: 3.19261
Value Function Loss: 0.00428

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11410
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.55881

Collected Steps per Second: 22,662.96502
Overall Steps per Second: 10,513.02100

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.54987
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.75620

Cumulative Model Updates: 127,494
Cumulative Timesteps: 1,063,382,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1063382900...
Checkpoint 1063382900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.73908
Policy Entropy: 3.20303
Value Function Loss: 0.00433

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.54009

Collected Steps per Second: 22,488.18880
Overall Steps per Second: 10,619.66298

Timestep Collection Time: 2.22446
Timestep Consumption Time: 2.48605
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.71051

Cumulative Model Updates: 127,500
Cumulative Timesteps: 1,063,432,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,147.02022
Policy Entropy: 3.21192
Value Function Loss: 0.00436

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.56424

Collected Steps per Second: 22,765.60594
Overall Steps per Second: 10,441.84205

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.59255
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 4.78919

Cumulative Model Updates: 127,506
Cumulative Timesteps: 1,063,482,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1063482932...
Checkpoint 1063482932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.67288
Policy Entropy: 3.21917
Value Function Loss: 0.00457

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.57457
Value Function Update Magnitude: 0.57769

Collected Steps per Second: 22,307.76013
Overall Steps per Second: 10,506.99430

Timestep Collection Time: 2.24236
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.76083

Cumulative Model Updates: 127,512
Cumulative Timesteps: 1,063,532,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.48751
Policy Entropy: 3.22184
Value Function Loss: 0.00440

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.59125
Value Function Update Magnitude: 0.62093

Collected Steps per Second: 22,388.98801
Overall Steps per Second: 10,484.59528

Timestep Collection Time: 2.23404
Timestep Consumption Time: 2.53657
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.77062

Cumulative Model Updates: 127,518
Cumulative Timesteps: 1,063,582,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1063582972...
Checkpoint 1063582972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.97962
Policy Entropy: 3.21772
Value Function Loss: 0.00439

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.59508
Value Function Update Magnitude: 0.63764

Collected Steps per Second: 22,556.02570
Overall Steps per Second: 10,647.11139

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.69649

Cumulative Model Updates: 127,524
Cumulative Timesteps: 1,063,632,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.19702
Policy Entropy: 3.22283
Value Function Loss: 0.00408

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.58202
Value Function Update Magnitude: 0.60403

Collected Steps per Second: 22,614.33175
Overall Steps per Second: 10,540.82751

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.53379
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.74593

Cumulative Model Updates: 127,530
Cumulative Timesteps: 1,063,683,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1063683002...
Checkpoint 1063683002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,681.37558
Policy Entropy: 3.22778
Value Function Loss: 0.00450

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.58195
Value Function Update Magnitude: 0.57428

Collected Steps per Second: 21,764.84578
Overall Steps per Second: 10,616.43166

Timestep Collection Time: 2.29866
Timestep Consumption Time: 2.41385
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.71251

Cumulative Model Updates: 127,536
Cumulative Timesteps: 1,063,733,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.85372
Policy Entropy: 3.22915
Value Function Loss: 0.00437

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.59303
Value Function Update Magnitude: 0.58051

Collected Steps per Second: 21,769.68695
Overall Steps per Second: 10,493.13936

Timestep Collection Time: 2.29696
Timestep Consumption Time: 2.46844
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.76540

Cumulative Model Updates: 127,542
Cumulative Timesteps: 1,063,783,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1063783036...
Checkpoint 1063783036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.14718
Policy Entropy: 3.22841
Value Function Loss: 0.00414

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.58240
Value Function Update Magnitude: 0.59999

Collected Steps per Second: 21,639.31340
Overall Steps per Second: 10,603.39328

Timestep Collection Time: 2.31153
Timestep Consumption Time: 2.40582
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.71736

Cumulative Model Updates: 127,548
Cumulative Timesteps: 1,063,833,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.39255
Policy Entropy: 3.23435
Value Function Loss: 0.00407

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.60058

Collected Steps per Second: 22,849.01858
Overall Steps per Second: 10,583.74855

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.53726
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.72668

Cumulative Model Updates: 127,554
Cumulative Timesteps: 1,063,883,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1063883082...
Checkpoint 1063883082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.90098
Policy Entropy: 3.24332
Value Function Loss: 0.00389

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.57540
Value Function Update Magnitude: 0.58473

Collected Steps per Second: 21,507.94322
Overall Steps per Second: 10,547.80898

Timestep Collection Time: 2.32575
Timestep Consumption Time: 2.41666
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.74241

Cumulative Model Updates: 127,560
Cumulative Timesteps: 1,063,933,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.52800
Policy Entropy: 3.23815
Value Function Loss: 0.00387

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.56707

Collected Steps per Second: 22,172.77112
Overall Steps per Second: 10,629.51726

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.70633

Cumulative Model Updates: 127,566
Cumulative Timesteps: 1,063,983,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1063983130...
Checkpoint 1063983130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,289.90986
Policy Entropy: 3.22345
Value Function Loss: 0.00366

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.54871

Collected Steps per Second: 21,819.07915
Overall Steps per Second: 10,555.00445

Timestep Collection Time: 2.29286
Timestep Consumption Time: 2.44689
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.73974

Cumulative Model Updates: 127,572
Cumulative Timesteps: 1,064,033,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.01211
Policy Entropy: 3.22696
Value Function Loss: 0.00389

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.54271

Collected Steps per Second: 21,888.49147
Overall Steps per Second: 10,544.61890

Timestep Collection Time: 2.28540
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.74403

Cumulative Model Updates: 127,578
Cumulative Timesteps: 1,064,083,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1064083182...
Checkpoint 1064083182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.92410
Policy Entropy: 3.22759
Value Function Loss: 0.00394

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.57289
Value Function Update Magnitude: 0.55816

Collected Steps per Second: 21,801.47052
Overall Steps per Second: 10,474.98371

Timestep Collection Time: 2.29397
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.77442

Cumulative Model Updates: 127,584
Cumulative Timesteps: 1,064,133,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.71952
Policy Entropy: 3.21698
Value Function Loss: 0.00402

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.57120
Value Function Update Magnitude: 0.55396

Collected Steps per Second: 21,883.22133
Overall Steps per Second: 10,487.95932

Timestep Collection Time: 2.28586
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.76947

Cumulative Model Updates: 127,590
Cumulative Timesteps: 1,064,183,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1064183216...
Checkpoint 1064183216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.88584
Policy Entropy: 3.20878
Value Function Loss: 0.00393

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.56966

Collected Steps per Second: 21,661.48481
Overall Steps per Second: 10,449.84701

Timestep Collection Time: 2.30963
Timestep Consumption Time: 2.47800
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.78763

Cumulative Model Updates: 127,596
Cumulative Timesteps: 1,064,233,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.12235
Policy Entropy: 3.20640
Value Function Loss: 0.00379

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.57080
Value Function Update Magnitude: 0.57471

Collected Steps per Second: 22,185.95599
Overall Steps per Second: 10,615.69458

Timestep Collection Time: 2.25395
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.71057

Cumulative Model Updates: 127,602
Cumulative Timesteps: 1,064,283,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1064283252...
Checkpoint 1064283252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.02553
Policy Entropy: 3.20897
Value Function Loss: 0.00373

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.56495
Value Function Update Magnitude: 0.56128

Collected Steps per Second: 21,591.02986
Overall Steps per Second: 10,591.94842

Timestep Collection Time: 2.31661
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.72227

Cumulative Model Updates: 127,608
Cumulative Timesteps: 1,064,333,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.78009
Policy Entropy: 3.21010
Value Function Loss: 0.00374

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.56820
Value Function Update Magnitude: 0.56865

Collected Steps per Second: 21,880.73877
Overall Steps per Second: 10,495.83346

Timestep Collection Time: 2.28511
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.76380

Cumulative Model Updates: 127,614
Cumulative Timesteps: 1,064,383,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1064383270...
Checkpoint 1064383270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.91882
Policy Entropy: 3.19565
Value Function Loss: 0.00403

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.56408

Collected Steps per Second: 22,476.89083
Overall Steps per Second: 10,614.66836

Timestep Collection Time: 2.22566
Timestep Consumption Time: 2.48725
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.71291

Cumulative Model Updates: 127,620
Cumulative Timesteps: 1,064,433,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.70712
Policy Entropy: 3.19662
Value Function Loss: 0.00402

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.58020
Value Function Update Magnitude: 0.56120

Collected Steps per Second: 21,852.96347
Overall Steps per Second: 10,427.41038

Timestep Collection Time: 2.28802
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.30265
Total Iteration Time: 4.79505

Cumulative Model Updates: 127,626
Cumulative Timesteps: 1,064,483,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1064483296...
Checkpoint 1064483296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.55461
Policy Entropy: 3.18254
Value Function Loss: 0.00427

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.57695
Value Function Update Magnitude: 0.56882

Collected Steps per Second: 21,645.24464
Overall Steps per Second: 10,345.00479

Timestep Collection Time: 2.31016
Timestep Consumption Time: 2.52348
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.83364

Cumulative Model Updates: 127,632
Cumulative Timesteps: 1,064,533,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.32213
Policy Entropy: 3.20101
Value Function Loss: 0.00419

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.58292
Value Function Update Magnitude: 0.56998

Collected Steps per Second: 22,186.71937
Overall Steps per Second: 10,413.34996

Timestep Collection Time: 2.25459
Timestep Consumption Time: 2.54905
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.80364

Cumulative Model Updates: 127,638
Cumulative Timesteps: 1,064,583,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1064583322...
Checkpoint 1064583322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.12257
Policy Entropy: 3.18939
Value Function Loss: 0.00435

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.56372

Collected Steps per Second: 22,377.73628
Overall Steps per Second: 10,575.94244

Timestep Collection Time: 2.23481
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.72866

Cumulative Model Updates: 127,644
Cumulative Timesteps: 1,064,633,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.69419
Policy Entropy: 3.20167
Value Function Loss: 0.00416

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.56361

Collected Steps per Second: 22,085.49994
Overall Steps per Second: 10,416.95454

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.53695
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.80179

Cumulative Model Updates: 127,650
Cumulative Timesteps: 1,064,683,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1064683352...
Checkpoint 1064683352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.25783
Policy Entropy: 3.20128
Value Function Loss: 0.00411

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.53835

Collected Steps per Second: 22,474.39787
Overall Steps per Second: 10,600.16466

Timestep Collection Time: 2.22573
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.71898

Cumulative Model Updates: 127,656
Cumulative Timesteps: 1,064,733,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.06990
Policy Entropy: 3.20023
Value Function Loss: 0.00403

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.51610

Collected Steps per Second: 22,584.18552
Overall Steps per Second: 10,590.53823

Timestep Collection Time: 2.21456
Timestep Consumption Time: 2.50796
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.72252

Cumulative Model Updates: 127,662
Cumulative Timesteps: 1,064,783,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1064783388...
Checkpoint 1064783388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.56482
Policy Entropy: 3.19808
Value Function Loss: 0.00423

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.55967
Value Function Update Magnitude: 0.52126

Collected Steps per Second: 22,641.60920
Overall Steps per Second: 10,595.30455

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.72020

Cumulative Model Updates: 127,668
Cumulative Timesteps: 1,064,833,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.91037
Policy Entropy: 3.17644
Value Function Loss: 0.00423

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.53604

Collected Steps per Second: 21,975.23003
Overall Steps per Second: 10,366.03556

Timestep Collection Time: 2.27656
Timestep Consumption Time: 2.54958
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.82615

Cumulative Model Updates: 127,674
Cumulative Timesteps: 1,064,883,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1064883428...
Checkpoint 1064883428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.99755
Policy Entropy: 3.18975
Value Function Loss: 0.00415

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.53247

Collected Steps per Second: 22,428.44648
Overall Steps per Second: 10,500.38384

Timestep Collection Time: 2.22958
Timestep Consumption Time: 2.53272
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.76230

Cumulative Model Updates: 127,680
Cumulative Timesteps: 1,064,933,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.97962
Policy Entropy: 3.19607
Value Function Loss: 0.00401

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.57219
Value Function Update Magnitude: 0.52663

Collected Steps per Second: 22,969.92356
Overall Steps per Second: 10,581.21271

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.54870
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.72555

Cumulative Model Updates: 127,686
Cumulative Timesteps: 1,064,983,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1064983436...
Checkpoint 1064983436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.11289
Policy Entropy: 3.19767
Value Function Loss: 0.00383

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.57740
Value Function Update Magnitude: 0.52447

Collected Steps per Second: 21,284.21909
Overall Steps per Second: 10,348.59505

Timestep Collection Time: 2.35000
Timestep Consumption Time: 2.48331
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.83331

Cumulative Model Updates: 127,692
Cumulative Timesteps: 1,065,033,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.58672
Policy Entropy: 3.19742
Value Function Loss: 0.00390

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.52835

Collected Steps per Second: 22,721.10076
Overall Steps per Second: 10,521.21563

Timestep Collection Time: 2.20130
Timestep Consumption Time: 2.55252
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.75382

Cumulative Model Updates: 127,698
Cumulative Timesteps: 1,065,083,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1065083470...
Checkpoint 1065083470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.03314
Policy Entropy: 3.19232
Value Function Loss: 0.00420

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.58019
Value Function Update Magnitude: 0.54893

Collected Steps per Second: 22,631.80911
Overall Steps per Second: 10,548.89573

Timestep Collection Time: 2.20946
Timestep Consumption Time: 2.53076
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.74021

Cumulative Model Updates: 127,704
Cumulative Timesteps: 1,065,133,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,503.05075
Policy Entropy: 3.20670
Value Function Loss: 0.00433

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.57900
Value Function Update Magnitude: 0.56111

Collected Steps per Second: 22,743.77369
Overall Steps per Second: 10,525.84844

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.55303
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.75249

Cumulative Model Updates: 127,710
Cumulative Timesteps: 1,065,183,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1065183498...
Checkpoint 1065183498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.62563
Policy Entropy: 3.19492
Value Function Loss: 0.00452

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.54869

Collected Steps per Second: 22,763.75050
Overall Steps per Second: 10,412.84343

Timestep Collection Time: 2.19735
Timestep Consumption Time: 2.60633
PPO Batch Consumption Time: 0.30785
Total Iteration Time: 4.80368

Cumulative Model Updates: 127,716
Cumulative Timesteps: 1,065,233,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.06868
Policy Entropy: 3.20212
Value Function Loss: 0.00448

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.54080

Collected Steps per Second: 20,957.00850
Overall Steps per Second: 10,170.32477

Timestep Collection Time: 2.38612
Timestep Consumption Time: 2.53073
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.91685

Cumulative Model Updates: 127,722
Cumulative Timesteps: 1,065,283,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1065283524...
Checkpoint 1065283524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.00576
Policy Entropy: 3.20390
Value Function Loss: 0.00458

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.57329
Value Function Update Magnitude: 0.53811

Collected Steps per Second: 21,103.88460
Overall Steps per Second: 10,208.81568

Timestep Collection Time: 2.37065
Timestep Consumption Time: 2.53001
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.90067

Cumulative Model Updates: 127,728
Cumulative Timesteps: 1,065,333,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.03039
Policy Entropy: 3.21132
Value Function Loss: 0.00409

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.57151
Value Function Update Magnitude: 0.54094

Collected Steps per Second: 22,825.57828
Overall Steps per Second: 10,589.33878

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.53262
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.72437

Cumulative Model Updates: 127,734
Cumulative Timesteps: 1,065,383,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1065383582...
Checkpoint 1065383582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.03624
Policy Entropy: 3.20598
Value Function Loss: 0.00380

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.55745
Value Function Update Magnitude: 0.53535

Collected Steps per Second: 22,512.91233
Overall Steps per Second: 10,485.10985

Timestep Collection Time: 2.22104
Timestep Consumption Time: 2.54782
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 4.76886

Cumulative Model Updates: 127,740
Cumulative Timesteps: 1,065,433,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.28105
Policy Entropy: 3.21245
Value Function Loss: 0.00380

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.51756

Collected Steps per Second: 22,534.88540
Overall Steps per Second: 10,459.94483

Timestep Collection Time: 2.21985
Timestep Consumption Time: 2.56259
PPO Batch Consumption Time: 0.29936
Total Iteration Time: 4.78243

Cumulative Model Updates: 127,746
Cumulative Timesteps: 1,065,483,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1065483608...
Checkpoint 1065483608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.54825
Policy Entropy: 3.21372
Value Function Loss: 0.00418

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.56866
Value Function Update Magnitude: 0.54560

Collected Steps per Second: 22,487.99378
Overall Steps per Second: 10,627.39636

Timestep Collection Time: 2.22376
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.70557

Cumulative Model Updates: 127,752
Cumulative Timesteps: 1,065,533,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,079.49265
Policy Entropy: 3.21975
Value Function Loss: 0.00432

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.52941

Collected Steps per Second: 22,592.94654
Overall Steps per Second: 10,234.21641

Timestep Collection Time: 2.21467
Timestep Consumption Time: 2.67442
PPO Batch Consumption Time: 0.31302
Total Iteration Time: 4.88909

Cumulative Model Updates: 127,758
Cumulative Timesteps: 1,065,583,652

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1065583652...
Checkpoint 1065583652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,048.96582
Policy Entropy: 3.22390
Value Function Loss: 0.00403

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.52181

Collected Steps per Second: 20,606.72264
Overall Steps per Second: 10,194.66726

Timestep Collection Time: 2.42668
Timestep Consumption Time: 2.47843
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.90511

Cumulative Model Updates: 127,764
Cumulative Timesteps: 1,065,633,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,050.72860
Policy Entropy: 3.21651
Value Function Loss: 0.00379

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.54540
Value Function Update Magnitude: 0.49944

Collected Steps per Second: 20,784.63903
Overall Steps per Second: 10,295.62302

Timestep Collection Time: 2.40668
Timestep Consumption Time: 2.45189
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.85857

Cumulative Model Updates: 127,770
Cumulative Timesteps: 1,065,683,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1065683680...
Checkpoint 1065683680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.68704
Policy Entropy: 3.20207
Value Function Loss: 0.00368

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.49860

Collected Steps per Second: 21,769.55372
Overall Steps per Second: 10,398.47939

Timestep Collection Time: 2.29715
Timestep Consumption Time: 2.51201
PPO Batch Consumption Time: 0.30226
Total Iteration Time: 4.80916

Cumulative Model Updates: 127,776
Cumulative Timesteps: 1,065,733,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.27784
Policy Entropy: 3.18627
Value Function Loss: 0.00388

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.55709
Value Function Update Magnitude: 0.51363

Collected Steps per Second: 21,488.93974
Overall Steps per Second: 10,614.88670

Timestep Collection Time: 2.32827
Timestep Consumption Time: 2.38511
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.71338

Cumulative Model Updates: 127,782
Cumulative Timesteps: 1,065,783,720

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1065783720...
Checkpoint 1065783720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.79605
Policy Entropy: 3.17568
Value Function Loss: 0.00426

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.51103

Collected Steps per Second: 22,397.67034
Overall Steps per Second: 10,599.71110

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.48533
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.71824

Cumulative Model Updates: 127,788
Cumulative Timesteps: 1,065,833,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,147.86065
Policy Entropy: 3.18819
Value Function Loss: 0.00422

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.57066
Value Function Update Magnitude: 0.50992

Collected Steps per Second: 22,225.96792
Overall Steps per Second: 10,458.36522

Timestep Collection Time: 2.25088
Timestep Consumption Time: 2.53266
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.78354

Cumulative Model Updates: 127,794
Cumulative Timesteps: 1,065,883,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1065883760...
Checkpoint 1065883760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.30043
Policy Entropy: 3.19345
Value Function Loss: 0.00428

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.55655

Collected Steps per Second: 20,781.95557
Overall Steps per Second: 10,184.76257

Timestep Collection Time: 2.40632
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.30131
Total Iteration Time: 4.91008

Cumulative Model Updates: 127,800
Cumulative Timesteps: 1,065,933,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.78268
Policy Entropy: 3.18683
Value Function Loss: 0.00446

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.58750
Value Function Update Magnitude: 0.57762

Collected Steps per Second: 22,084.67499
Overall Steps per Second: 10,313.86012

Timestep Collection Time: 2.26492
Timestep Consumption Time: 2.58487
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.84978

Cumulative Model Updates: 127,806
Cumulative Timesteps: 1,065,983,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1065983788...
Checkpoint 1065983788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.73524
Policy Entropy: 3.16355
Value Function Loss: 0.00503

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.58932
Value Function Update Magnitude: 0.57275

Collected Steps per Second: 22,065.78746
Overall Steps per Second: 10,461.20878

Timestep Collection Time: 2.26640
Timestep Consumption Time: 2.51411
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.78052

Cumulative Model Updates: 127,812
Cumulative Timesteps: 1,066,033,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.94642
Policy Entropy: 3.16755
Value Function Loss: 0.00517

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.58540
Value Function Update Magnitude: 0.56637

Collected Steps per Second: 21,192.28984
Overall Steps per Second: 10,117.58716

Timestep Collection Time: 2.35982
Timestep Consumption Time: 2.58306
PPO Batch Consumption Time: 0.30484
Total Iteration Time: 4.94288

Cumulative Model Updates: 127,818
Cumulative Timesteps: 1,066,083,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1066083808...
Checkpoint 1066083808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.70690
Policy Entropy: 3.18009
Value Function Loss: 0.00448

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.57592
Value Function Update Magnitude: 0.56749

Collected Steps per Second: 21,685.36966
Overall Steps per Second: 10,292.81942

Timestep Collection Time: 2.30672
Timestep Consumption Time: 2.55318
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.85989

Cumulative Model Updates: 127,824
Cumulative Timesteps: 1,066,133,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.91883
Policy Entropy: 3.20201
Value Function Loss: 0.00416

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.56269

Collected Steps per Second: 21,957.03726
Overall Steps per Second: 10,332.58536

Timestep Collection Time: 2.27827
Timestep Consumption Time: 2.56312
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.84138

Cumulative Model Updates: 127,830
Cumulative Timesteps: 1,066,183,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1066183854...
Checkpoint 1066183854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.84916
Policy Entropy: 3.20226
Value Function Loss: 0.00395

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.57103
Value Function Update Magnitude: 0.57405

Collected Steps per Second: 22,829.73507
Overall Steps per Second: 10,645.45023

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.50752
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.69835

Cumulative Model Updates: 127,836
Cumulative Timesteps: 1,066,233,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.31520
Policy Entropy: 3.20979
Value Function Loss: 0.00380

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.57638
Value Function Update Magnitude: 0.55921

Collected Steps per Second: 21,400.01811
Overall Steps per Second: 10,406.47933

Timestep Collection Time: 2.33738
Timestep Consumption Time: 2.46924
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.80662

Cumulative Model Updates: 127,842
Cumulative Timesteps: 1,066,283,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1066283890...
Checkpoint 1066283890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.84050
Policy Entropy: 3.20804
Value Function Loss: 0.00381

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.56987
Value Function Update Magnitude: 0.55863

Collected Steps per Second: 21,521.10869
Overall Steps per Second: 10,572.03345

Timestep Collection Time: 2.32423
Timestep Consumption Time: 2.40712
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.73135

Cumulative Model Updates: 127,848
Cumulative Timesteps: 1,066,333,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.94459
Policy Entropy: 3.19533
Value Function Loss: 0.00410

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.56510
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 22,590.20293
Overall Steps per Second: 10,564.02890

Timestep Collection Time: 2.21370
Timestep Consumption Time: 2.52010
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.73380

Cumulative Model Updates: 127,854
Cumulative Timesteps: 1,066,383,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1066383918...
Checkpoint 1066383918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.96559
Policy Entropy: 3.19576
Value Function Loss: 0.00412

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.57173
Value Function Update Magnitude: 0.55740

Collected Steps per Second: 21,605.75376
Overall Steps per Second: 10,563.12567

Timestep Collection Time: 2.31438
Timestep Consumption Time: 2.41944
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.73383

Cumulative Model Updates: 127,860
Cumulative Timesteps: 1,066,433,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.89090
Policy Entropy: 3.20326
Value Function Loss: 0.00413

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.57323
Value Function Update Magnitude: 0.55926

Collected Steps per Second: 22,021.63003
Overall Steps per Second: 10,527.98750

Timestep Collection Time: 2.27068
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.74963

Cumulative Model Updates: 127,866
Cumulative Timesteps: 1,066,483,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1066483926...
Checkpoint 1066483926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,604.27981
Policy Entropy: 3.22361
Value Function Loss: 0.00361

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.57203

Collected Steps per Second: 20,065.60205
Overall Steps per Second: 10,055.39537

Timestep Collection Time: 2.49203
Timestep Consumption Time: 2.48083
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.97285

Cumulative Model Updates: 127,872
Cumulative Timesteps: 1,066,533,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411.20387
Policy Entropy: 3.21877
Value Function Loss: 0.00326

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.57448

Collected Steps per Second: 22,390.77144
Overall Steps per Second: 10,618.33113

Timestep Collection Time: 2.23324
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.70921

Cumulative Model Updates: 127,878
Cumulative Timesteps: 1,066,583,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1066583934...
Checkpoint 1066583934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.61524
Policy Entropy: 3.22360
Value Function Loss: 0.00319

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.54041
Value Function Update Magnitude: 0.54266

Collected Steps per Second: 21,413.07725
Overall Steps per Second: 10,577.86036

Timestep Collection Time: 2.33521
Timestep Consumption Time: 2.39202
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.72723

Cumulative Model Updates: 127,884
Cumulative Timesteps: 1,066,633,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.30539
Policy Entropy: 3.20687
Value Function Loss: 0.00340

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.53968
Value Function Update Magnitude: 0.54029

Collected Steps per Second: 21,814.79380
Overall Steps per Second: 10,498.56057

Timestep Collection Time: 2.29386
Timestep Consumption Time: 2.47251
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.76637

Cumulative Model Updates: 127,890
Cumulative Timesteps: 1,066,683,978

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1066683978...
Checkpoint 1066683978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.79023
Policy Entropy: 3.21422
Value Function Loss: 0.00344

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.52200

Collected Steps per Second: 21,612.14093
Overall Steps per Second: 10,568.56550

Timestep Collection Time: 2.31435
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.73271

Cumulative Model Updates: 127,896
Cumulative Timesteps: 1,066,733,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.22714
Policy Entropy: 3.20674
Value Function Loss: 0.00381

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.55370

Collected Steps per Second: 21,837.63612
Overall Steps per Second: 10,301.49054

Timestep Collection Time: 2.29091
Timestep Consumption Time: 2.56548
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.85638

Cumulative Model Updates: 127,902
Cumulative Timesteps: 1,066,784,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1066784024...
Checkpoint 1066784024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.24242
Policy Entropy: 3.20830
Value Function Loss: 0.00384

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.57316

Collected Steps per Second: 21,873.21947
Overall Steps per Second: 10,487.75417

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.29991
Total Iteration Time: 4.76880

Cumulative Model Updates: 127,908
Cumulative Timesteps: 1,066,834,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.54195
Policy Entropy: 3.20307
Value Function Loss: 0.00397

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.55432

Collected Steps per Second: 21,770.24106
Overall Steps per Second: 10,505.05489

Timestep Collection Time: 2.29671
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.75961

Cumulative Model Updates: 127,914
Cumulative Timesteps: 1,066,884,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1066884038...
Checkpoint 1066884038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.96571
Policy Entropy: 3.20372
Value Function Loss: 0.00417

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.56339
Value Function Update Magnitude: 0.54795

Collected Steps per Second: 21,304.32631
Overall Steps per Second: 10,556.08619

Timestep Collection Time: 2.34797
Timestep Consumption Time: 2.39071
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.73869

Cumulative Model Updates: 127,920
Cumulative Timesteps: 1,066,934,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.97713
Policy Entropy: 3.20478
Value Function Loss: 0.00420

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.56088
Value Function Update Magnitude: 0.53303

Collected Steps per Second: 21,876.40170
Overall Steps per Second: 10,479.11953

Timestep Collection Time: 2.28584
Timestep Consumption Time: 2.48612
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 4.77197

Cumulative Model Updates: 127,926
Cumulative Timesteps: 1,066,984,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1066984066...
Checkpoint 1066984066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.17526
Policy Entropy: 3.19010
Value Function Loss: 0.00433

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.57085
Value Function Update Magnitude: 0.53410

Collected Steps per Second: 21,420.22847
Overall Steps per Second: 10,434.08406

Timestep Collection Time: 2.33499
Timestep Consumption Time: 2.45853
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.79352

Cumulative Model Updates: 127,932
Cumulative Timesteps: 1,067,034,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.71966
Policy Entropy: 3.18734
Value Function Loss: 0.00403

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.54784

Collected Steps per Second: 20,503.75058
Overall Steps per Second: 10,071.68257

Timestep Collection Time: 2.43985
Timestep Consumption Time: 2.52715
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.96700

Cumulative Model Updates: 127,938
Cumulative Timesteps: 1,067,084,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1067084108...
Checkpoint 1067084108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.39495
Policy Entropy: 3.19263
Value Function Loss: 0.00405

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.52314

Collected Steps per Second: 21,523.99243
Overall Steps per Second: 10,480.36734

Timestep Collection Time: 2.32485
Timestep Consumption Time: 2.44979
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.77464

Cumulative Model Updates: 127,944
Cumulative Timesteps: 1,067,134,148

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.72299
Policy Entropy: 3.19323
Value Function Loss: 0.00382

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.57021
Value Function Update Magnitude: 0.52091

Collected Steps per Second: 22,077.37882
Overall Steps per Second: 10,689.01911

Timestep Collection Time: 2.26485
Timestep Consumption Time: 2.41303
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.67788

Cumulative Model Updates: 127,950
Cumulative Timesteps: 1,067,184,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1067184150...
Checkpoint 1067184150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.53012
Policy Entropy: 3.18600
Value Function Loss: 0.00397

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.57015
Value Function Update Magnitude: 0.54469

Collected Steps per Second: 21,666.66775
Overall Steps per Second: 10,644.06441

Timestep Collection Time: 2.30898
Timestep Consumption Time: 2.39110
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.70008

Cumulative Model Updates: 127,956
Cumulative Timesteps: 1,067,234,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.17971
Policy Entropy: 3.18291
Value Function Loss: 0.00386

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.57730
Value Function Update Magnitude: 0.55821

Collected Steps per Second: 21,776.45918
Overall Steps per Second: 10,550.16995

Timestep Collection Time: 2.29652
Timestep Consumption Time: 2.44369
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.74021

Cumulative Model Updates: 127,962
Cumulative Timesteps: 1,067,284,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1067284188...
Checkpoint 1067284188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.43074
Policy Entropy: 3.17584
Value Function Loss: 0.00420

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.56550

Collected Steps per Second: 22,703.83870
Overall Steps per Second: 10,628.49261

Timestep Collection Time: 2.20280
Timestep Consumption Time: 2.50267
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.70547

Cumulative Model Updates: 127,968
Cumulative Timesteps: 1,067,334,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.25507
Policy Entropy: 3.18875
Value Function Loss: 0.00430

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.58985
Value Function Update Magnitude: 0.56972

Collected Steps per Second: 22,733.58371
Overall Steps per Second: 10,558.44085

Timestep Collection Time: 2.20071
Timestep Consumption Time: 2.53768
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.73839

Cumulative Model Updates: 127,974
Cumulative Timesteps: 1,067,384,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1067384230...
Checkpoint 1067384230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.29953
Policy Entropy: 3.18953
Value Function Loss: 0.00459

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.59360
Value Function Update Magnitude: 0.56749

Collected Steps per Second: 22,372.67756
Overall Steps per Second: 10,562.82145

Timestep Collection Time: 2.23558
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.73510

Cumulative Model Updates: 127,980
Cumulative Timesteps: 1,067,434,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.15705
Policy Entropy: 3.19992
Value Function Loss: 0.00428

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.59042
Value Function Update Magnitude: 0.56797

Collected Steps per Second: 23,042.54985
Overall Steps per Second: 10,653.56474

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.52448
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.69533

Cumulative Model Updates: 127,986
Cumulative Timesteps: 1,067,484,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1067484268...
Checkpoint 1067484268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611.34279
Policy Entropy: 3.21324
Value Function Loss: 0.00426

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.57515
Value Function Update Magnitude: 0.56775

Collected Steps per Second: 21,883.17958
Overall Steps per Second: 10,510.72568

Timestep Collection Time: 2.28523
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.75781

Cumulative Model Updates: 127,992
Cumulative Timesteps: 1,067,534,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.49648
Policy Entropy: 3.21127
Value Function Loss: 0.00391

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.55020

Collected Steps per Second: 22,008.60851
Overall Steps per Second: 10,592.74113

Timestep Collection Time: 2.27257
Timestep Consumption Time: 2.44916
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.72172

Cumulative Model Updates: 127,998
Cumulative Timesteps: 1,067,584,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1067584292...
Checkpoint 1067584292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.26202
Policy Entropy: 3.20591
Value Function Loss: 0.00394

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.57695
Value Function Update Magnitude: 0.54217

Collected Steps per Second: 20,542.59583
Overall Steps per Second: 10,235.20000

Timestep Collection Time: 2.43416
Timestep Consumption Time: 2.45133
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.88549

Cumulative Model Updates: 128,004
Cumulative Timesteps: 1,067,634,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.28045
Policy Entropy: 3.19501
Value Function Loss: 0.00409

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.58690
Value Function Update Magnitude: 0.54603

Collected Steps per Second: 20,413.82877
Overall Steps per Second: 10,149.95752

Timestep Collection Time: 2.45020
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.92790

Cumulative Model Updates: 128,010
Cumulative Timesteps: 1,067,684,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1067684314...
Checkpoint 1067684314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.19243
Policy Entropy: 3.20426
Value Function Loss: 0.00403

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.57987
Value Function Update Magnitude: 0.55933

Collected Steps per Second: 20,654.33048
Overall Steps per Second: 10,268.75746

Timestep Collection Time: 2.42157
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.87070

Cumulative Model Updates: 128,016
Cumulative Timesteps: 1,067,734,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,862.79618
Policy Entropy: 3.20178
Value Function Loss: 0.00428

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.55620

Collected Steps per Second: 21,894.29649
Overall Steps per Second: 10,495.10389

Timestep Collection Time: 2.28489
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.76660

Cumulative Model Updates: 128,022
Cumulative Timesteps: 1,067,784,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1067784356...
Checkpoint 1067784356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,081.85892
Policy Entropy: 3.20431
Value Function Loss: 0.00427

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.58724

Collected Steps per Second: 21,621.84310
Overall Steps per Second: 10,581.55285

Timestep Collection Time: 2.31368
Timestep Consumption Time: 2.41398
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.72766

Cumulative Model Updates: 128,028
Cumulative Timesteps: 1,067,834,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.71677
Policy Entropy: 3.19129
Value Function Loss: 0.00421

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 22,582.66722
Overall Steps per Second: 10,515.88857

Timestep Collection Time: 2.21444
Timestep Consumption Time: 2.54103
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.75547

Cumulative Model Updates: 128,034
Cumulative Timesteps: 1,067,884,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1067884390...
Checkpoint 1067884390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.37196
Policy Entropy: 3.18564
Value Function Loss: 0.00410

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.59035
Value Function Update Magnitude: 0.62195

Collected Steps per Second: 21,624.71446
Overall Steps per Second: 10,585.82906

Timestep Collection Time: 2.31328
Timestep Consumption Time: 2.41228
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.72556

Cumulative Model Updates: 128,040
Cumulative Timesteps: 1,067,934,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.54908
Policy Entropy: 3.19130
Value Function Loss: 0.00413

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.59190
Value Function Update Magnitude: 0.58564

Collected Steps per Second: 22,462.90159
Overall Steps per Second: 10,525.73185

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.52518
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.75178

Cumulative Model Updates: 128,046
Cumulative Timesteps: 1,067,984,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1067984430...
Checkpoint 1067984430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.35944
Policy Entropy: 3.20065
Value Function Loss: 0.00415

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.55017

Collected Steps per Second: 21,640.33197
Overall Steps per Second: 10,538.15180

Timestep Collection Time: 2.31189
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.74751

Cumulative Model Updates: 128,052
Cumulative Timesteps: 1,068,034,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.73865
Policy Entropy: 3.19729
Value Function Loss: 0.00402

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.56842
Value Function Update Magnitude: 0.52482

Collected Steps per Second: 22,456.84715
Overall Steps per Second: 10,468.00912

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.55078
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.77799

Cumulative Model Updates: 128,058
Cumulative Timesteps: 1,068,084,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1068084476...
Checkpoint 1068084476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.05798
Policy Entropy: 3.20724
Value Function Loss: 0.00390

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.50388

Collected Steps per Second: 21,776.19520
Overall Steps per Second: 10,640.26432

Timestep Collection Time: 2.29710
Timestep Consumption Time: 2.40410
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.70120

Cumulative Model Updates: 128,064
Cumulative Timesteps: 1,068,134,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.18234
Policy Entropy: 3.20086
Value Function Loss: 0.00394

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.50943

Collected Steps per Second: 22,076.50482
Overall Steps per Second: 10,516.86401

Timestep Collection Time: 2.26594
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.75655

Cumulative Model Updates: 128,070
Cumulative Timesteps: 1,068,184,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1068184522...
Checkpoint 1068184522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.41469
Policy Entropy: 3.20377
Value Function Loss: 0.00399

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.56403
Value Function Update Magnitude: 0.53494

Collected Steps per Second: 21,451.16791
Overall Steps per Second: 10,574.41510

Timestep Collection Time: 2.33162
Timestep Consumption Time: 2.39829
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.72991

Cumulative Model Updates: 128,076
Cumulative Timesteps: 1,068,234,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.14957
Policy Entropy: 3.19293
Value Function Loss: 0.00401

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.56683
Value Function Update Magnitude: 0.55750

Collected Steps per Second: 21,312.79760
Overall Steps per Second: 10,517.49680

Timestep Collection Time: 2.34695
Timestep Consumption Time: 2.40894
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.75588

Cumulative Model Updates: 128,082
Cumulative Timesteps: 1,068,284,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1068284558...
Checkpoint 1068284558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.47438
Policy Entropy: 3.19950
Value Function Loss: 0.00381

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.53688

Collected Steps per Second: 20,016.60900
Overall Steps per Second: 9,909.49315

Timestep Collection Time: 2.49853
Timestep Consumption Time: 2.54835
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 5.04688

Cumulative Model Updates: 128,088
Cumulative Timesteps: 1,068,334,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.26634
Policy Entropy: 3.20224
Value Function Loss: 0.00352

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.56498
Value Function Update Magnitude: 0.54147

Collected Steps per Second: 20,618.94170
Overall Steps per Second: 10,337.37961

Timestep Collection Time: 2.42602
Timestep Consumption Time: 2.41292
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.83894

Cumulative Model Updates: 128,094
Cumulative Timesteps: 1,068,384,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1068384592...
Checkpoint 1068384592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.68212
Policy Entropy: 3.20761
Value Function Loss: 0.00352

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.55849
Value Function Update Magnitude: 0.52716

Collected Steps per Second: 21,756.52013
Overall Steps per Second: 10,625.28051

Timestep Collection Time: 2.29871
Timestep Consumption Time: 2.40817
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.70689

Cumulative Model Updates: 128,100
Cumulative Timesteps: 1,068,434,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.19177
Policy Entropy: 3.19898
Value Function Loss: 0.00397

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.56835
Value Function Update Magnitude: 0.50487

Collected Steps per Second: 21,691.24697
Overall Steps per Second: 10,500.64463

Timestep Collection Time: 2.30646
Timestep Consumption Time: 2.45801
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.76447

Cumulative Model Updates: 128,106
Cumulative Timesteps: 1,068,484,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1068484634...
Checkpoint 1068484634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.29959
Policy Entropy: 3.19436
Value Function Loss: 0.00431

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.56895
Value Function Update Magnitude: 0.51293

Collected Steps per Second: 22,509.86022
Overall Steps per Second: 10,630.27865

Timestep Collection Time: 2.22196
Timestep Consumption Time: 2.48309
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.70505

Cumulative Model Updates: 128,112
Cumulative Timesteps: 1,068,534,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.18851
Policy Entropy: 3.19600
Value Function Loss: 0.00430

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.52955

Collected Steps per Second: 22,717.28039
Overall Steps per Second: 10,543.12929

Timestep Collection Time: 2.20123
Timestep Consumption Time: 2.54176
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.74299

Cumulative Model Updates: 128,118
Cumulative Timesteps: 1,068,584,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1068584656...
Checkpoint 1068584656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.96238
Policy Entropy: 3.20762
Value Function Loss: 0.00419

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.54566

Collected Steps per Second: 21,740.56709
Overall Steps per Second: 10,559.92746

Timestep Collection Time: 2.30003
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.73526

Cumulative Model Updates: 128,124
Cumulative Timesteps: 1,068,634,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.62214
Policy Entropy: 3.20847
Value Function Loss: 0.00417

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.58143
Value Function Update Magnitude: 0.57692

Collected Steps per Second: 22,876.48318
Overall Steps per Second: 10,599.29873

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.53306
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.71993

Cumulative Model Updates: 128,130
Cumulative Timesteps: 1,068,684,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1068684688...
Checkpoint 1068684688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.40613
Policy Entropy: 3.20888
Value Function Loss: 0.00422

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.58516

Collected Steps per Second: 21,832.63526
Overall Steps per Second: 10,499.10971

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.76364

Cumulative Model Updates: 128,136
Cumulative Timesteps: 1,068,734,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,064.26908
Policy Entropy: 3.20699
Value Function Loss: 0.00405

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.59110

Collected Steps per Second: 21,822.13187
Overall Steps per Second: 10,462.77284

Timestep Collection Time: 2.29244
Timestep Consumption Time: 2.48889
PPO Batch Consumption Time: 0.29999
Total Iteration Time: 4.78133

Cumulative Model Updates: 128,142
Cumulative Timesteps: 1,068,784,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1068784728...
Checkpoint 1068784728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.49460
Policy Entropy: 3.21692
Value Function Loss: 0.00413

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.59023

Collected Steps per Second: 22,392.18472
Overall Steps per Second: 10,624.89487

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.47350
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.70687

Cumulative Model Updates: 128,148
Cumulative Timesteps: 1,068,834,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.65615
Policy Entropy: 3.22173
Value Function Loss: 0.00413

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.58322
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 22,603.55115
Overall Steps per Second: 10,495.65347

Timestep Collection Time: 2.21302
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.76597

Cumulative Model Updates: 128,154
Cumulative Timesteps: 1,068,884,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1068884760...
Checkpoint 1068884760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.33305
Policy Entropy: 3.21243
Value Function Loss: 0.00395

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.56398

Collected Steps per Second: 21,653.55021
Overall Steps per Second: 10,326.56683

Timestep Collection Time: 2.30927
Timestep Consumption Time: 2.53299
PPO Batch Consumption Time: 0.30477
Total Iteration Time: 4.84227

Cumulative Model Updates: 128,160
Cumulative Timesteps: 1,068,934,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.49915
Policy Entropy: 3.21417
Value Function Loss: 0.00402

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.55919

Collected Steps per Second: 21,747.09238
Overall Steps per Second: 10,174.21844

Timestep Collection Time: 2.29953
Timestep Consumption Time: 2.61564
PPO Batch Consumption Time: 0.30776
Total Iteration Time: 4.91517

Cumulative Model Updates: 128,166
Cumulative Timesteps: 1,068,984,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1068984772...
Checkpoint 1068984772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.92104
Policy Entropy: 3.21721
Value Function Loss: 0.00403

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.56000

Collected Steps per Second: 22,572.20837
Overall Steps per Second: 10,655.91407

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.47831
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.69448

Cumulative Model Updates: 128,172
Cumulative Timesteps: 1,069,034,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.17504
Policy Entropy: 3.23044
Value Function Loss: 0.00416

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.57733
Value Function Update Magnitude: 0.55988

Collected Steps per Second: 22,139.91506
Overall Steps per Second: 10,539.55707

Timestep Collection Time: 2.25972
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 4.74688

Cumulative Model Updates: 128,178
Cumulative Timesteps: 1,069,084,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1069084826...
Checkpoint 1069084826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.87567
Policy Entropy: 3.22680
Value Function Loss: 0.00402

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.58226
Value Function Update Magnitude: 0.56871

Collected Steps per Second: 21,467.20467
Overall Steps per Second: 10,568.10976

Timestep Collection Time: 2.32960
Timestep Consumption Time: 2.40256
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.73216

Cumulative Model Updates: 128,184
Cumulative Timesteps: 1,069,134,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.11540
Policy Entropy: 3.22831
Value Function Loss: 0.00408

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.58317
Value Function Update Magnitude: 0.57062

Collected Steps per Second: 21,741.64868
Overall Steps per Second: 10,563.71802

Timestep Collection Time: 2.29973
Timestep Consumption Time: 2.43345
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.73318

Cumulative Model Updates: 128,190
Cumulative Timesteps: 1,069,184,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1069184836...
Checkpoint 1069184836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.11675
Policy Entropy: 3.22650
Value Function Loss: 0.00401

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.57912
Value Function Update Magnitude: 0.58577

Collected Steps per Second: 21,703.08764
Overall Steps per Second: 10,651.12824

Timestep Collection Time: 2.30511
Timestep Consumption Time: 2.39186
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.69697

Cumulative Model Updates: 128,196
Cumulative Timesteps: 1,069,234,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.76356
Policy Entropy: 3.21492
Value Function Loss: 0.00395

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.57263
Value Function Update Magnitude: 0.58315

Collected Steps per Second: 22,521.30038
Overall Steps per Second: 10,468.26917

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.55683
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 4.77749

Cumulative Model Updates: 128,202
Cumulative Timesteps: 1,069,284,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1069284876...
Checkpoint 1069284876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.64488
Policy Entropy: 3.21945
Value Function Loss: 0.00410

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.57865
Value Function Update Magnitude: 0.55717

Collected Steps per Second: 22,703.12736
Overall Steps per Second: 10,618.17532

Timestep Collection Time: 2.20313
Timestep Consumption Time: 2.50747
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.71060

Cumulative Model Updates: 128,208
Cumulative Timesteps: 1,069,334,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.46026
Policy Entropy: 3.21314
Value Function Loss: 0.00415

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.57520
Value Function Update Magnitude: 0.55546

Collected Steps per Second: 21,701.40716
Overall Steps per Second: 10,453.29744

Timestep Collection Time: 2.30437
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.78395

Cumulative Model Updates: 128,214
Cumulative Timesteps: 1,069,384,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1069384902...
Checkpoint 1069384902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.35539
Policy Entropy: 3.23074
Value Function Loss: 0.00413

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.56041

Collected Steps per Second: 21,948.39331
Overall Steps per Second: 10,595.30879

Timestep Collection Time: 2.27816
Timestep Consumption Time: 2.44110
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71926

Cumulative Model Updates: 128,220
Cumulative Timesteps: 1,069,434,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.69555
Policy Entropy: 3.22811
Value Function Loss: 0.00376

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.55366

Collected Steps per Second: 21,952.90994
Overall Steps per Second: 10,556.68485

Timestep Collection Time: 2.27797
Timestep Consumption Time: 2.45913
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.73709

Cumulative Model Updates: 128,226
Cumulative Timesteps: 1,069,484,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1069484912...
Checkpoint 1069484912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.38599
Policy Entropy: 3.20661
Value Function Loss: 0.00411

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.57338
Value Function Update Magnitude: 0.54306

Collected Steps per Second: 21,783.97711
Overall Steps per Second: 10,469.40966

Timestep Collection Time: 2.29536
Timestep Consumption Time: 2.48065
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.77601

Cumulative Model Updates: 128,232
Cumulative Timesteps: 1,069,534,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.12003
Policy Entropy: 3.20691
Value Function Loss: 0.00403

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.57138
Value Function Update Magnitude: 0.53766

Collected Steps per Second: 21,650.98830
Overall Steps per Second: 10,590.96675

Timestep Collection Time: 2.30973
Timestep Consumption Time: 2.41203
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.72176

Cumulative Model Updates: 128,238
Cumulative Timesteps: 1,069,584,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1069584922...
Checkpoint 1069584922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,877.15559
Policy Entropy: 3.20235
Value Function Loss: 0.00409

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.52660

Collected Steps per Second: 21,365.02623
Overall Steps per Second: 10,400.57517

Timestep Collection Time: 2.34130
Timestep Consumption Time: 2.46824
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.80954

Cumulative Model Updates: 128,244
Cumulative Timesteps: 1,069,634,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.56572
Policy Entropy: 3.20044
Value Function Loss: 0.00395

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.56761
Value Function Update Magnitude: 0.52615

Collected Steps per Second: 22,236.40958
Overall Steps per Second: 10,648.53259

Timestep Collection Time: 2.24973
Timestep Consumption Time: 2.44819
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.69792

Cumulative Model Updates: 128,250
Cumulative Timesteps: 1,069,684,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1069684970...
Checkpoint 1069684970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.36728
Policy Entropy: 3.19271
Value Function Loss: 0.00384

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.57242
Value Function Update Magnitude: 0.51635

Collected Steps per Second: 21,471.11167
Overall Steps per Second: 10,577.72392

Timestep Collection Time: 2.32880
Timestep Consumption Time: 2.39830
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.72710

Cumulative Model Updates: 128,256
Cumulative Timesteps: 1,069,734,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.23611
Policy Entropy: 3.19279
Value Function Loss: 0.00392

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.58164
Value Function Update Magnitude: 0.51477

Collected Steps per Second: 21,928.44159
Overall Steps per Second: 10,540.12035

Timestep Collection Time: 2.28024
Timestep Consumption Time: 2.46373
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.74397

Cumulative Model Updates: 128,262
Cumulative Timesteps: 1,069,784,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1069784974...
Checkpoint 1069784974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728.83606
Policy Entropy: 3.21188
Value Function Loss: 0.00391

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.57240
Value Function Update Magnitude: 0.51050

Collected Steps per Second: 21,447.03855
Overall Steps per Second: 10,394.16309

Timestep Collection Time: 2.33132
Timestep Consumption Time: 2.47907
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.81039

Cumulative Model Updates: 128,268
Cumulative Timesteps: 1,069,834,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.47813
Policy Entropy: 3.21250
Value Function Loss: 0.00388

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.56269
Value Function Update Magnitude: 0.51322

Collected Steps per Second: 21,084.09845
Overall Steps per Second: 10,078.76238

Timestep Collection Time: 2.37155
Timestep Consumption Time: 2.58957
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 4.96112

Cumulative Model Updates: 128,274
Cumulative Timesteps: 1,069,884,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1069884976...
Checkpoint 1069884976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.30842
Policy Entropy: 3.21129
Value Function Loss: 0.00387

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.55403
Value Function Update Magnitude: 0.50110

Collected Steps per Second: 20,655.32597
Overall Steps per Second: 9,752.81998

Timestep Collection Time: 2.42078
Timestep Consumption Time: 2.70615
PPO Batch Consumption Time: 0.31927
Total Iteration Time: 5.12693

Cumulative Model Updates: 128,280
Cumulative Timesteps: 1,069,934,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.30525
Policy Entropy: 3.21084
Value Function Loss: 0.00364

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.48400

Collected Steps per Second: 21,446.29014
Overall Steps per Second: 10,312.69756

Timestep Collection Time: 2.33280
Timestep Consumption Time: 2.51850
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.85130

Cumulative Model Updates: 128,286
Cumulative Timesteps: 1,069,985,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1069985008...
Checkpoint 1069985008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.45110
Policy Entropy: 3.21218
Value Function Loss: 0.00360

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.48737

Collected Steps per Second: 21,269.25579
Overall Steps per Second: 10,269.28008

Timestep Collection Time: 2.35203
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.30768
Total Iteration Time: 4.87142

Cumulative Model Updates: 128,292
Cumulative Timesteps: 1,070,035,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.51811
Policy Entropy: 3.21829
Value Function Loss: 0.00361

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.51913

Collected Steps per Second: 21,033.07569
Overall Steps per Second: 10,338.89876

Timestep Collection Time: 2.37721
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.83611

Cumulative Model Updates: 128,298
Cumulative Timesteps: 1,070,085,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1070085034...
Checkpoint 1070085034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.30532
Policy Entropy: 3.20302
Value Function Loss: 0.00421

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.56761
Value Function Update Magnitude: 0.57160

Collected Steps per Second: 20,902.48804
Overall Steps per Second: 10,121.41877

Timestep Collection Time: 2.39225
Timestep Consumption Time: 2.54816
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.94041

Cumulative Model Updates: 128,304
Cumulative Timesteps: 1,070,135,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.63998
Policy Entropy: 3.21565
Value Function Loss: 0.00426

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.57000
Value Function Update Magnitude: 0.58332

Collected Steps per Second: 22,192.82386
Overall Steps per Second: 10,586.08403

Timestep Collection Time: 2.25379
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.72488

Cumulative Model Updates: 128,310
Cumulative Timesteps: 1,070,185,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1070185056...
Checkpoint 1070185056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.08525
Policy Entropy: 3.21631
Value Function Loss: 0.00428

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.56481
Value Function Update Magnitude: 0.57289

Collected Steps per Second: 21,964.07173
Overall Steps per Second: 10,520.56825

Timestep Collection Time: 2.27654
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.75279

Cumulative Model Updates: 128,316
Cumulative Timesteps: 1,070,235,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.40665
Policy Entropy: 3.22462
Value Function Loss: 0.00382

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.51969

Collected Steps per Second: 22,256.91194
Overall Steps per Second: 10,399.76859

Timestep Collection Time: 2.24658
Timestep Consumption Time: 2.56141
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.80799

Cumulative Model Updates: 128,322
Cumulative Timesteps: 1,070,285,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1070285060...
Checkpoint 1070285060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.44412
Policy Entropy: 3.21801
Value Function Loss: 0.00348

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.47850

Collected Steps per Second: 21,643.66933
Overall Steps per Second: 10,509.24833

Timestep Collection Time: 2.31125
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.76000

Cumulative Model Updates: 128,328
Cumulative Timesteps: 1,070,335,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.41751
Policy Entropy: 3.21100
Value Function Loss: 0.00347

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.47821

Collected Steps per Second: 22,578.50233
Overall Steps per Second: 10,638.59644

Timestep Collection Time: 2.21609
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.70325

Cumulative Model Updates: 128,334
Cumulative Timesteps: 1,070,385,120

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1070385120...
Checkpoint 1070385120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.71530
Policy Entropy: 3.19217
Value Function Loss: 0.00382

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.56269
Value Function Update Magnitude: 0.51165

Collected Steps per Second: 22,453.58597
Overall Steps per Second: 10,639.09988

Timestep Collection Time: 2.22682
Timestep Consumption Time: 2.47283
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.69965

Cumulative Model Updates: 128,340
Cumulative Timesteps: 1,070,435,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.77944
Policy Entropy: 3.19243
Value Function Loss: 0.00424

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.58470
Value Function Update Magnitude: 0.54814

Collected Steps per Second: 22,497.51986
Overall Steps per Second: 10,621.92043

Timestep Collection Time: 2.22256
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.70744

Cumulative Model Updates: 128,346
Cumulative Timesteps: 1,070,485,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1070485122...
Checkpoint 1070485122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.70094
Policy Entropy: 3.19623
Value Function Loss: 0.00431

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.59519
Value Function Update Magnitude: 0.59910

Collected Steps per Second: 22,403.71389
Overall Steps per Second: 10,619.95562

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.70962

Cumulative Model Updates: 128,352
Cumulative Timesteps: 1,070,535,138

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.97014
Policy Entropy: 3.19889
Value Function Loss: 0.00431

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.59905
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,610.43360
Overall Steps per Second: 10,560.60128

Timestep Collection Time: 2.21190
Timestep Consumption Time: 2.52382
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.73572

Cumulative Model Updates: 128,358
Cumulative Timesteps: 1,070,585,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1070585150...
Checkpoint 1070585150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.78387
Policy Entropy: 3.20347
Value Function Loss: 0.00394

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.59349
Value Function Update Magnitude: 0.58404

Collected Steps per Second: 22,426.85390
Overall Steps per Second: 10,520.30012

Timestep Collection Time: 2.23027
Timestep Consumption Time: 2.52415
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.75443

Cumulative Model Updates: 128,364
Cumulative Timesteps: 1,070,635,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.01940
Policy Entropy: 3.20595
Value Function Loss: 0.00386

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.58173
Value Function Update Magnitude: 0.54687

Collected Steps per Second: 22,826.22993
Overall Steps per Second: 10,516.61046

Timestep Collection Time: 2.19108
Timestep Consumption Time: 2.56464
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.75571

Cumulative Model Updates: 128,370
Cumulative Timesteps: 1,070,685,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1070685182...
Checkpoint 1070685182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.14531
Policy Entropy: 3.21018
Value Function Loss: 0.00378

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.57062
Value Function Update Magnitude: 0.50669

Collected Steps per Second: 21,806.85766
Overall Steps per Second: 10,435.58045

Timestep Collection Time: 2.29405
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.79379

Cumulative Model Updates: 128,376
Cumulative Timesteps: 1,070,735,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.30707
Policy Entropy: 3.20764
Value Function Loss: 0.00402

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.48871

Collected Steps per Second: 20,920.04718
Overall Steps per Second: 10,199.66079

Timestep Collection Time: 2.39139
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.90487

Cumulative Model Updates: 128,382
Cumulative Timesteps: 1,070,785,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1070785236...
Checkpoint 1070785236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.14228
Policy Entropy: 3.20411
Value Function Loss: 0.00405

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.51173

Collected Steps per Second: 22,286.09955
Overall Steps per Second: 10,645.68228

Timestep Collection Time: 2.24364
Timestep Consumption Time: 2.45329
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.69693

Cumulative Model Updates: 128,388
Cumulative Timesteps: 1,070,835,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.21935
Policy Entropy: 3.20546
Value Function Loss: 0.00401

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.52483

Collected Steps per Second: 22,575.48636
Overall Steps per Second: 10,310.70436

Timestep Collection Time: 2.21488
Timestep Consumption Time: 2.63464
PPO Batch Consumption Time: 0.31017
Total Iteration Time: 4.84952

Cumulative Model Updates: 128,394
Cumulative Timesteps: 1,070,885,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1070885240...
Checkpoint 1070885240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.56014
Policy Entropy: 3.20003
Value Function Loss: 0.00391

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.57458
Value Function Update Magnitude: 0.52401

Collected Steps per Second: 21,454.38959
Overall Steps per Second: 10,150.57724

Timestep Collection Time: 2.33183
Timestep Consumption Time: 2.59676
PPO Batch Consumption Time: 0.30598
Total Iteration Time: 4.92859

Cumulative Model Updates: 128,400
Cumulative Timesteps: 1,070,935,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.50296
Policy Entropy: 3.20249
Value Function Loss: 0.00420

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.58232
Value Function Update Magnitude: 0.52343

Collected Steps per Second: 22,959.47800
Overall Steps per Second: 10,645.80015

Timestep Collection Time: 2.17810
Timestep Consumption Time: 2.51934
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.69744

Cumulative Model Updates: 128,406
Cumulative Timesteps: 1,070,985,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1070985276...
Checkpoint 1070985276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.10464
Policy Entropy: 3.19981
Value Function Loss: 0.00423

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.59338
Value Function Update Magnitude: 0.54723

Collected Steps per Second: 22,551.15268
Overall Steps per Second: 10,625.19026

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.70825

Cumulative Model Updates: 128,412
Cumulative Timesteps: 1,071,035,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.58200
Policy Entropy: 3.21004
Value Function Loss: 0.00413

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.58557
Value Function Update Magnitude: 0.55169

Collected Steps per Second: 22,389.11800
Overall Steps per Second: 10,434.77325

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.55926
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.79320

Cumulative Model Updates: 128,418
Cumulative Timesteps: 1,071,085,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1071085318...
Checkpoint 1071085318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.26830
Policy Entropy: 3.21844
Value Function Loss: 0.00391

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.56979
Value Function Update Magnitude: 0.54029

Collected Steps per Second: 22,487.42126
Overall Steps per Second: 10,590.85118

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.49769
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.72124

Cumulative Model Updates: 128,424
Cumulative Timesteps: 1,071,135,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.36148
Policy Entropy: 3.21880
Value Function Loss: 0.00393

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.57031
Value Function Update Magnitude: 0.52095

Collected Steps per Second: 21,908.60374
Overall Steps per Second: 10,528.94538

Timestep Collection Time: 2.28239
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.74919

Cumulative Model Updates: 128,430
Cumulative Timesteps: 1,071,185,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1071185324...
Checkpoint 1071185324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.39373
Policy Entropy: 3.21696
Value Function Loss: 0.00405

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.52793

Collected Steps per Second: 21,533.97232
Overall Steps per Second: 10,592.01263

Timestep Collection Time: 2.32201
Timestep Consumption Time: 2.39872
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.72073

Cumulative Model Updates: 128,436
Cumulative Timesteps: 1,071,235,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.76279
Policy Entropy: 3.20643
Value Function Loss: 0.00403

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.57939
Value Function Update Magnitude: 0.55954

Collected Steps per Second: 22,760.20175
Overall Steps per Second: 10,503.02994

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.56402
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.76110

Cumulative Model Updates: 128,442
Cumulative Timesteps: 1,071,285,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1071285332...
Checkpoint 1071285332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.06784
Policy Entropy: 3.21046
Value Function Loss: 0.00397

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.54869

Collected Steps per Second: 22,182.83063
Overall Steps per Second: 10,586.04850

Timestep Collection Time: 2.25463
Timestep Consumption Time: 2.46989
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.72452

Cumulative Model Updates: 128,448
Cumulative Timesteps: 1,071,335,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,442.47985
Policy Entropy: 3.21586
Value Function Loss: 0.00393

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.57288
Value Function Update Magnitude: 0.52271

Collected Steps per Second: 22,635.00006
Overall Steps per Second: 10,506.47667

Timestep Collection Time: 2.20941
Timestep Consumption Time: 2.55051
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.75992

Cumulative Model Updates: 128,454
Cumulative Timesteps: 1,071,385,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1071385356...
Checkpoint 1071385356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.60358
Policy Entropy: 3.21982
Value Function Loss: 0.00384

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.56341
Value Function Update Magnitude: 0.48698

Collected Steps per Second: 22,237.34547
Overall Steps per Second: 10,575.69925

Timestep Collection Time: 2.24937
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.72971

Cumulative Model Updates: 128,460
Cumulative Timesteps: 1,071,435,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.52197
Policy Entropy: 3.21421
Value Function Loss: 0.00411

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.50352

Collected Steps per Second: 22,381.39632
Overall Steps per Second: 10,521.26537

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.75437

Cumulative Model Updates: 128,466
Cumulative Timesteps: 1,071,485,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1071485398...
Checkpoint 1071485398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.59032
Policy Entropy: 3.21447
Value Function Loss: 0.00404

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.57339
Value Function Update Magnitude: 0.52966

Collected Steps per Second: 22,547.52509
Overall Steps per Second: 10,593.14475

Timestep Collection Time: 2.21869
Timestep Consumption Time: 2.50380
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.72249

Cumulative Model Updates: 128,472
Cumulative Timesteps: 1,071,535,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.22218
Policy Entropy: 3.21909
Value Function Loss: 0.00378

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.56040
Value Function Update Magnitude: 0.52862

Collected Steps per Second: 21,728.03730
Overall Steps per Second: 10,470.89567

Timestep Collection Time: 2.30127
Timestep Consumption Time: 2.47407
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.77533

Cumulative Model Updates: 128,478
Cumulative Timesteps: 1,071,585,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1071585426...
Checkpoint 1071585426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.49671
Policy Entropy: 3.22244
Value Function Loss: 0.00375

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.51158

Collected Steps per Second: 22,438.35172
Overall Steps per Second: 10,636.46912

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.47377
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.70325

Cumulative Model Updates: 128,484
Cumulative Timesteps: 1,071,635,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.17177
Policy Entropy: 3.22647
Value Function Loss: 0.00385

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.52005

Collected Steps per Second: 21,708.64953
Overall Steps per Second: 10,473.13332

Timestep Collection Time: 2.30415
Timestep Consumption Time: 2.47188
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.77603

Cumulative Model Updates: 128,490
Cumulative Timesteps: 1,071,685,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1071685472...
Checkpoint 1071685472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.00044
Policy Entropy: 3.21463
Value Function Loss: 0.00396

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.57375
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 21,551.27187
Overall Steps per Second: 10,564.62775

Timestep Collection Time: 2.32070
Timestep Consumption Time: 2.41340
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.73410

Cumulative Model Updates: 128,496
Cumulative Timesteps: 1,071,735,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.96847
Policy Entropy: 3.20623
Value Function Loss: 0.00394

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.57015
Value Function Update Magnitude: 0.52109

Collected Steps per Second: 22,027.89192
Overall Steps per Second: 10,513.13421

Timestep Collection Time: 2.27021
Timestep Consumption Time: 2.48650
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.75672

Cumulative Model Updates: 128,502
Cumulative Timesteps: 1,071,785,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1071785494...
Checkpoint 1071785494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.45423
Policy Entropy: 3.19271
Value Function Loss: 0.00404

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.57361
Value Function Update Magnitude: 0.50178

Collected Steps per Second: 22,496.91671
Overall Steps per Second: 10,662.96095

Timestep Collection Time: 2.22368
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.69157

Cumulative Model Updates: 128,508
Cumulative Timesteps: 1,071,835,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.92064
Policy Entropy: 3.18838
Value Function Loss: 0.00421

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.58173
Value Function Update Magnitude: 0.50924

Collected Steps per Second: 22,323.12738
Overall Steps per Second: 10,475.27107

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.53382
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.77410

Cumulative Model Updates: 128,514
Cumulative Timesteps: 1,071,885,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1071885530...
Checkpoint 1071885530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.78251
Policy Entropy: 3.19678
Value Function Loss: 0.00431

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.58615
Value Function Update Magnitude: 0.53391

Collected Steps per Second: 22,543.93279
Overall Steps per Second: 10,675.74466

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.68426

Cumulative Model Updates: 128,520
Cumulative Timesteps: 1,071,935,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.41828
Policy Entropy: 3.20473
Value Function Loss: 0.00451

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.58231
Value Function Update Magnitude: 0.53970

Collected Steps per Second: 22,826.30645
Overall Steps per Second: 10,557.24708

Timestep Collection Time: 2.19177
Timestep Consumption Time: 2.54716
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.73892

Cumulative Model Updates: 128,526
Cumulative Timesteps: 1,071,985,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1071985568...
Checkpoint 1071985568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.71982
Policy Entropy: 3.21384
Value Function Loss: 0.00442

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.58903
Value Function Update Magnitude: 0.55651

Collected Steps per Second: 22,704.19169
Overall Steps per Second: 10,510.85504

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.55587
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.75908

Cumulative Model Updates: 128,532
Cumulative Timesteps: 1,072,035,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.93215
Policy Entropy: 3.22000
Value Function Loss: 0.00397

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.54595

Collected Steps per Second: 22,518.24913
Overall Steps per Second: 10,496.10601

Timestep Collection Time: 2.22042
Timestep Consumption Time: 2.54325
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.76367

Cumulative Model Updates: 128,538
Cumulative Timesteps: 1,072,085,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1072085590...
Checkpoint 1072085590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.31067
Policy Entropy: 3.20491
Value Function Loss: 0.00392

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.56435
Value Function Update Magnitude: 0.52435

Collected Steps per Second: 22,151.15964
Overall Steps per Second: 10,540.04689

Timestep Collection Time: 2.25857
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.74666

Cumulative Model Updates: 128,544
Cumulative Timesteps: 1,072,135,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.10059
Policy Entropy: 3.20221
Value Function Loss: 0.00393

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.50454

Collected Steps per Second: 22,552.39309
Overall Steps per Second: 10,527.34366

Timestep Collection Time: 2.21715
Timestep Consumption Time: 2.53258
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.74973

Cumulative Model Updates: 128,550
Cumulative Timesteps: 1,072,185,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1072185622...
Checkpoint 1072185622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.22542
Policy Entropy: 3.20160
Value Function Loss: 0.00393

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.57485
Value Function Update Magnitude: 0.49310

Collected Steps per Second: 21,581.72177
Overall Steps per Second: 10,595.37293

Timestep Collection Time: 2.31742
Timestep Consumption Time: 2.40294
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.72036

Cumulative Model Updates: 128,556
Cumulative Timesteps: 1,072,235,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.21589
Policy Entropy: 3.21434
Value Function Loss: 0.00374

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.57570
Value Function Update Magnitude: 0.48829

Collected Steps per Second: 21,538.86404
Overall Steps per Second: 10,475.98155

Timestep Collection Time: 2.32241
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.77492

Cumulative Model Updates: 128,562
Cumulative Timesteps: 1,072,285,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1072285658...
Checkpoint 1072285658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.73512
Policy Entropy: 3.21605
Value Function Loss: 0.00378

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.51333

Collected Steps per Second: 21,649.22209
Overall Steps per Second: 10,602.75199

Timestep Collection Time: 2.31011
Timestep Consumption Time: 2.40678
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.71689

Cumulative Model Updates: 128,568
Cumulative Timesteps: 1,072,335,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,005.83073
Policy Entropy: 3.21549
Value Function Loss: 0.00362

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.57290
Value Function Update Magnitude: 0.53968

Collected Steps per Second: 21,887.93841
Overall Steps per Second: 10,490.66602

Timestep Collection Time: 2.28491
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.76729

Cumulative Model Updates: 128,574
Cumulative Timesteps: 1,072,385,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1072385682...
Checkpoint 1072385682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.47792
Policy Entropy: 3.20706
Value Function Loss: 0.00382

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.57166
Value Function Update Magnitude: 0.52730

Collected Steps per Second: 21,602.53385
Overall Steps per Second: 10,663.43800

Timestep Collection Time: 2.31556
Timestep Consumption Time: 2.37542
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.69098

Cumulative Model Updates: 128,580
Cumulative Timesteps: 1,072,435,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.87763
Policy Entropy: 3.20966
Value Function Loss: 0.00386

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.56953
Value Function Update Magnitude: 0.50331

Collected Steps per Second: 21,526.52443
Overall Steps per Second: 10,401.43624

Timestep Collection Time: 2.32299
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.80761

Cumulative Model Updates: 128,586
Cumulative Timesteps: 1,072,485,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1072485710...
Checkpoint 1072485710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.92408
Policy Entropy: 3.19912
Value Function Loss: 0.00404

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.58330
Value Function Update Magnitude: 0.50464

Collected Steps per Second: 22,562.69244
Overall Steps per Second: 10,668.93133

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.68838

Cumulative Model Updates: 128,592
Cumulative Timesteps: 1,072,535,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.23253
Policy Entropy: 3.20212
Value Function Loss: 0.00407

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.53559

Collected Steps per Second: 22,664.19107
Overall Steps per Second: 10,516.10122

Timestep Collection Time: 2.20612
Timestep Consumption Time: 2.54849
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.75461

Cumulative Model Updates: 128,598
Cumulative Timesteps: 1,072,585,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1072585730...
Checkpoint 1072585730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.45040
Policy Entropy: 3.20996
Value Function Loss: 0.00408

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.56147

Collected Steps per Second: 22,656.16371
Overall Steps per Second: 10,581.97365

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.51962
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.72785

Cumulative Model Updates: 128,604
Cumulative Timesteps: 1,072,635,760

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.47586
Policy Entropy: 3.21244
Value Function Loss: 0.00399

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.58308
Value Function Update Magnitude: 0.53024

Collected Steps per Second: 22,380.95255
Overall Steps per Second: 10,484.72092

Timestep Collection Time: 2.23529
Timestep Consumption Time: 2.53622
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.77151

Cumulative Model Updates: 128,610
Cumulative Timesteps: 1,072,685,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1072685788...
Checkpoint 1072685788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.87111
Policy Entropy: 3.21409
Value Function Loss: 0.00436

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.59363
Value Function Update Magnitude: 0.51862

Collected Steps per Second: 22,340.99119
Overall Steps per Second: 10,605.30412

Timestep Collection Time: 2.23858
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.71575

Cumulative Model Updates: 128,616
Cumulative Timesteps: 1,072,735,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.23844
Policy Entropy: 3.20447
Value Function Loss: 0.00429

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.59852
Value Function Update Magnitude: 0.53404

Collected Steps per Second: 22,598.71787
Overall Steps per Second: 10,516.05165

Timestep Collection Time: 2.21260
Timestep Consumption Time: 2.54222
PPO Batch Consumption Time: 0.30067
Total Iteration Time: 4.75483

Cumulative Model Updates: 128,622
Cumulative Timesteps: 1,072,785,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1072785802...
Checkpoint 1072785802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.24682
Policy Entropy: 3.20526
Value Function Loss: 0.00459

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.59913
Value Function Update Magnitude: 0.54949

Collected Steps per Second: 22,172.66197
Overall Steps per Second: 10,551.63440

Timestep Collection Time: 2.25566
Timestep Consumption Time: 2.48427
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.73993

Cumulative Model Updates: 128,628
Cumulative Timesteps: 1,072,835,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.31975
Policy Entropy: 3.21465
Value Function Loss: 0.00425

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.60686
Value Function Update Magnitude: 0.55962

Collected Steps per Second: 22,124.85888
Overall Steps per Second: 10,323.56714

Timestep Collection Time: 2.26035
Timestep Consumption Time: 2.58390
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.84426

Cumulative Model Updates: 128,634
Cumulative Timesteps: 1,072,885,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1072885826...
Checkpoint 1072885826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.47027
Policy Entropy: 3.23361
Value Function Loss: 0.00432

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.60197
Value Function Update Magnitude: 0.55700

Collected Steps per Second: 22,402.73774
Overall Steps per Second: 10,548.69004

Timestep Collection Time: 2.23285
Timestep Consumption Time: 2.50916
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.74201

Cumulative Model Updates: 128,640
Cumulative Timesteps: 1,072,935,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.87137
Policy Entropy: 3.22364
Value Function Loss: 0.00434

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.59901
Value Function Update Magnitude: 0.56343

Collected Steps per Second: 22,654.19892
Overall Steps per Second: 10,640.62588

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.70085

Cumulative Model Updates: 128,646
Cumulative Timesteps: 1,072,985,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1072985868...
Checkpoint 1072985868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.19842
Policy Entropy: 3.22309
Value Function Loss: 0.00421

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.59536
Value Function Update Magnitude: 0.57294

Collected Steps per Second: 22,583.56386
Overall Steps per Second: 10,656.60311

Timestep Collection Time: 2.21453
Timestep Consumption Time: 2.47852
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.69305

Cumulative Model Updates: 128,652
Cumulative Timesteps: 1,073,035,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.03154
Policy Entropy: 3.20621
Value Function Loss: 0.00437

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.56406

Collected Steps per Second: 22,271.04541
Overall Steps per Second: 10,518.41274

Timestep Collection Time: 2.24543
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.75433

Cumulative Model Updates: 128,658
Cumulative Timesteps: 1,073,085,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1073085888...
Checkpoint 1073085888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.21787
Policy Entropy: 3.21317
Value Function Loss: 0.00409

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.58457
Value Function Update Magnitude: 0.57382

Collected Steps per Second: 22,383.82251
Overall Steps per Second: 10,568.46373

Timestep Collection Time: 2.23483
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.73333

Cumulative Model Updates: 128,664
Cumulative Timesteps: 1,073,135,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.31631
Policy Entropy: 3.21596
Value Function Loss: 0.00411

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.58330
Value Function Update Magnitude: 0.56847

Collected Steps per Second: 22,586.75077
Overall Steps per Second: 10,541.31093

Timestep Collection Time: 2.21378
Timestep Consumption Time: 2.52966
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.74343

Cumulative Model Updates: 128,670
Cumulative Timesteps: 1,073,185,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1073185914...
Checkpoint 1073185914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.32995
Policy Entropy: 3.22449
Value Function Loss: 0.00413

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.55237

Collected Steps per Second: 22,542.14120
Overall Steps per Second: 10,604.47433

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.49732
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.71575

Cumulative Model Updates: 128,676
Cumulative Timesteps: 1,073,235,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.04639
Policy Entropy: 3.20442
Value Function Loss: 0.00454

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.59144
Value Function Update Magnitude: 0.54061

Collected Steps per Second: 22,445.24640
Overall Steps per Second: 10,339.88762

Timestep Collection Time: 2.22800
Timestep Consumption Time: 2.60842
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.83642

Cumulative Model Updates: 128,682
Cumulative Timesteps: 1,073,285,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1073285930...
Checkpoint 1073285930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,949.87847
Policy Entropy: 3.19834
Value Function Loss: 0.00461

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.59541
Value Function Update Magnitude: 0.54260

Collected Steps per Second: 22,157.57148
Overall Steps per Second: 10,409.58284

Timestep Collection Time: 2.25702
Timestep Consumption Time: 2.54721
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.80423

Cumulative Model Updates: 128,688
Cumulative Timesteps: 1,073,335,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.42262
Policy Entropy: 3.17980
Value Function Loss: 0.00455

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.60574
Value Function Update Magnitude: 0.54057

Collected Steps per Second: 22,706.19759
Overall Steps per Second: 10,311.78307

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.64890
PPO Batch Consumption Time: 0.30981
Total Iteration Time: 4.85270

Cumulative Model Updates: 128,694
Cumulative Timesteps: 1,073,385,980

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1073385980...
Checkpoint 1073385980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.38074
Policy Entropy: 3.18725
Value Function Loss: 0.00419

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.60792
Value Function Update Magnitude: 0.54521

Collected Steps per Second: 21,188.45367
Overall Steps per Second: 10,291.20743

Timestep Collection Time: 2.36072
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.86046

Cumulative Model Updates: 128,700
Cumulative Timesteps: 1,073,436,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.45490
Policy Entropy: 3.17704
Value Function Loss: 0.00395

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.59314
Value Function Update Magnitude: 0.55382

Collected Steps per Second: 20,414.61266
Overall Steps per Second: 9,564.36398

Timestep Collection Time: 2.45079
Timestep Consumption Time: 2.78029
PPO Batch Consumption Time: 0.32293
Total Iteration Time: 5.23108

Cumulative Model Updates: 128,706
Cumulative Timesteps: 1,073,486,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1073486032...
Checkpoint 1073486032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.15219
Policy Entropy: 3.19146
Value Function Loss: 0.00397

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.58532
Value Function Update Magnitude: 0.52728

Collected Steps per Second: 21,596.53858
Overall Steps per Second: 10,267.85070

Timestep Collection Time: 2.31611
Timestep Consumption Time: 2.55540
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.87152

Cumulative Model Updates: 128,712
Cumulative Timesteps: 1,073,536,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.66053
Policy Entropy: 3.18920
Value Function Loss: 0.00408

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.58034
Value Function Update Magnitude: 0.54706

Collected Steps per Second: 22,307.16781
Overall Steps per Second: 10,466.84596

Timestep Collection Time: 2.24376
Timestep Consumption Time: 2.53819
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.78196

Cumulative Model Updates: 128,718
Cumulative Timesteps: 1,073,586,104

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1073586104...
Checkpoint 1073586104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.49932
Policy Entropy: 3.19911
Value Function Loss: 0.00432

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.59074
Value Function Update Magnitude: 0.54951

Collected Steps per Second: 22,207.35852
Overall Steps per Second: 10,562.92261

Timestep Collection Time: 2.25277
Timestep Consumption Time: 2.48342
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.73619

Cumulative Model Updates: 128,724
Cumulative Timesteps: 1,073,636,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.45453
Policy Entropy: 3.18213
Value Function Loss: 0.00458

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.59306
Value Function Update Magnitude: 0.54542

Collected Steps per Second: 22,443.67590
Overall Steps per Second: 10,557.87937

Timestep Collection Time: 2.22887
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.73807

Cumulative Model Updates: 128,730
Cumulative Timesteps: 1,073,686,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1073686156...
Checkpoint 1073686156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.49439
Policy Entropy: 3.18067
Value Function Loss: 0.00460

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.58462
Value Function Update Magnitude: 0.54353

Collected Steps per Second: 22,344.66605
Overall Steps per Second: 10,575.02340

Timestep Collection Time: 2.23901
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.73096

Cumulative Model Updates: 128,736
Cumulative Timesteps: 1,073,736,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.83504
Policy Entropy: 3.16447
Value Function Loss: 0.00480

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.59048
Value Function Update Magnitude: 0.52241

Collected Steps per Second: 22,837.06904
Overall Steps per Second: 10,560.55605

Timestep Collection Time: 2.18986
Timestep Consumption Time: 2.54569
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.73555

Cumulative Model Updates: 128,742
Cumulative Timesteps: 1,073,786,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1073786196...
Checkpoint 1073786196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.76388
Policy Entropy: 3.18218
Value Function Loss: 0.00469

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.60503
Value Function Update Magnitude: 0.50211

Collected Steps per Second: 21,937.15593
Overall Steps per Second: 10,493.16337

Timestep Collection Time: 2.28051
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.76768

Cumulative Model Updates: 128,748
Cumulative Timesteps: 1,073,836,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,284.06209
Policy Entropy: 3.18272
Value Function Loss: 0.00468

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.59132
Value Function Update Magnitude: 0.51696

Collected Steps per Second: 22,478.08582
Overall Steps per Second: 10,538.99980

Timestep Collection Time: 2.22510
Timestep Consumption Time: 2.52070
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.74580

Cumulative Model Updates: 128,754
Cumulative Timesteps: 1,073,886,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1073886240...
Checkpoint 1073886240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.15978
Policy Entropy: 3.20371
Value Function Loss: 0.00433

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.52571

Collected Steps per Second: 22,208.43128
Overall Steps per Second: 10,575.25137

Timestep Collection Time: 2.25140
Timestep Consumption Time: 2.47662
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.72802

Cumulative Model Updates: 128,760
Cumulative Timesteps: 1,073,936,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.51831
Policy Entropy: 3.19535
Value Function Loss: 0.00426

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.51399

Collected Steps per Second: 22,805.08573
Overall Steps per Second: 10,545.90915

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.54950
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.74269

Cumulative Model Updates: 128,766
Cumulative Timesteps: 1,073,986,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1073986256...
Checkpoint 1073986256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.89581
Policy Entropy: 3.19169
Value Function Loss: 0.00430

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.57879
Value Function Update Magnitude: 0.50567

Collected Steps per Second: 21,910.11726
Overall Steps per Second: 10,427.86527

Timestep Collection Time: 2.28242
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.79561

Cumulative Model Updates: 128,772
Cumulative Timesteps: 1,074,036,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.51209
Policy Entropy: 3.18527
Value Function Loss: 0.00412

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.58454
Value Function Update Magnitude: 0.51180

Collected Steps per Second: 22,764.23371
Overall Steps per Second: 10,610.20385

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.51622
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.71282

Cumulative Model Updates: 128,778
Cumulative Timesteps: 1,074,086,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1074086268...
Checkpoint 1074086268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.45931
Policy Entropy: 3.18919
Value Function Loss: 0.00418

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.58640
Value Function Update Magnitude: 0.52129

Collected Steps per Second: 22,528.96557
Overall Steps per Second: 10,618.27415

Timestep Collection Time: 2.22008
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.71037

Cumulative Model Updates: 128,784
Cumulative Timesteps: 1,074,136,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.45039
Policy Entropy: 3.18844
Value Function Loss: 0.00416

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.58486
Value Function Update Magnitude: 0.53057

Collected Steps per Second: 22,825.58629
Overall Steps per Second: 10,528.51876

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.55879
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.74958

Cumulative Model Updates: 128,790
Cumulative Timesteps: 1,074,186,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1074186290...
Checkpoint 1074186290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.53588
Policy Entropy: 3.19081
Value Function Loss: 0.00402

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.51711

Collected Steps per Second: 22,130.52195
Overall Steps per Second: 10,552.46424

Timestep Collection Time: 2.26041
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.74050

Cumulative Model Updates: 128,796
Cumulative Timesteps: 1,074,236,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.67245
Policy Entropy: 3.19497
Value Function Loss: 0.00396

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.50725

Collected Steps per Second: 22,587.34130
Overall Steps per Second: 10,565.76535

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.52025
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.73529

Cumulative Model Updates: 128,802
Cumulative Timesteps: 1,074,286,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1074286346...
Checkpoint 1074286346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.89793
Policy Entropy: 3.20691
Value Function Loss: 0.00404

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.56321
Value Function Update Magnitude: 0.50446

Collected Steps per Second: 22,171.08698
Overall Steps per Second: 10,531.19722

Timestep Collection Time: 2.25537
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.74818

Cumulative Model Updates: 128,808
Cumulative Timesteps: 1,074,336,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.38313
Policy Entropy: 3.20371
Value Function Loss: 0.00418

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.57425
Value Function Update Magnitude: 0.49696

Collected Steps per Second: 22,467.02183
Overall Steps per Second: 10,525.01896

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.52611
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.75249

Cumulative Model Updates: 128,814
Cumulative Timesteps: 1,074,386,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1074386370...
Checkpoint 1074386370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.73317
Policy Entropy: 3.19497
Value Function Loss: 0.00445

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.51549

Collected Steps per Second: 21,962.53214
Overall Steps per Second: 10,418.59949

Timestep Collection Time: 2.27742
Timestep Consumption Time: 2.52341
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.80084

Cumulative Model Updates: 128,820
Cumulative Timesteps: 1,074,436,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.56755
Policy Entropy: 3.18728
Value Function Loss: 0.00449

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.57882
Value Function Update Magnitude: 0.54918

Collected Steps per Second: 23,307.13439
Overall Steps per Second: 10,724.16934

Timestep Collection Time: 2.14630
Timestep Consumption Time: 2.51831
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.66460

Cumulative Model Updates: 128,826
Cumulative Timesteps: 1,074,486,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1074486412...
Checkpoint 1074486412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.55322
Policy Entropy: 3.19947
Value Function Loss: 0.00425

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.54175

Collected Steps per Second: 22,157.07566
Overall Steps per Second: 10,570.84485

Timestep Collection Time: 2.25734
Timestep Consumption Time: 2.47417
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.73150

Cumulative Model Updates: 128,832
Cumulative Timesteps: 1,074,536,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.59508
Policy Entropy: 3.20049
Value Function Loss: 0.00397

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.52386

Collected Steps per Second: 22,666.47474
Overall Steps per Second: 10,207.30880

Timestep Collection Time: 2.20705
Timestep Consumption Time: 2.69395
PPO Batch Consumption Time: 0.32196
Total Iteration Time: 4.90100

Cumulative Model Updates: 128,838
Cumulative Timesteps: 1,074,586,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1074586454...
Checkpoint 1074586454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.01436
Policy Entropy: 3.21603
Value Function Loss: 0.00414

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.58314
Value Function Update Magnitude: 0.51442

Collected Steps per Second: 22,081.92300
Overall Steps per Second: 10,506.36889

Timestep Collection Time: 2.26574
Timestep Consumption Time: 2.49632
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.76206

Cumulative Model Updates: 128,844
Cumulative Timesteps: 1,074,636,486

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.77373
Policy Entropy: 3.21297
Value Function Loss: 0.00397

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.58998
Value Function Update Magnitude: 0.51714

Collected Steps per Second: 22,588.25289
Overall Steps per Second: 10,516.86540

Timestep Collection Time: 2.21451
Timestep Consumption Time: 2.54185
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.75636

Cumulative Model Updates: 128,850
Cumulative Timesteps: 1,074,686,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1074686508...
Checkpoint 1074686508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.65592
Policy Entropy: 3.20625
Value Function Loss: 0.00424

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.51648

Collected Steps per Second: 20,339.64118
Overall Steps per Second: 9,904.63693

Timestep Collection Time: 2.45894
Timestep Consumption Time: 2.59061
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 5.04955

Cumulative Model Updates: 128,856
Cumulative Timesteps: 1,074,736,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.35985
Policy Entropy: 3.20528
Value Function Loss: 0.00454

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.52484

Collected Steps per Second: 22,091.89537
Overall Steps per Second: 10,433.75318

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.52907
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.79252

Cumulative Model Updates: 128,862
Cumulative Timesteps: 1,074,786,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1074786526...
Checkpoint 1074786526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.24160
Policy Entropy: 3.20485
Value Function Loss: 0.00420

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.57819
Value Function Update Magnitude: 0.51452

Collected Steps per Second: 22,291.71877
Overall Steps per Second: 10,547.44107

Timestep Collection Time: 2.24478
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.74428

Cumulative Model Updates: 128,868
Cumulative Timesteps: 1,074,836,566

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,431.20298
Policy Entropy: 3.21029
Value Function Loss: 0.00425

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.57019
Value Function Update Magnitude: 0.51113

Collected Steps per Second: 21,550.44189
Overall Steps per Second: 10,330.99306

Timestep Collection Time: 2.32116
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.84194

Cumulative Model Updates: 128,874
Cumulative Timesteps: 1,074,886,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1074886588...
Checkpoint 1074886588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.85819
Policy Entropy: 3.20219
Value Function Loss: 0.00436

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.55480

Collected Steps per Second: 21,859.69492
Overall Steps per Second: 10,330.68351

Timestep Collection Time: 2.28768
Timestep Consumption Time: 2.55304
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.84073

Cumulative Model Updates: 128,880
Cumulative Timesteps: 1,074,936,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 872.73754
Policy Entropy: 3.20681
Value Function Loss: 0.00446

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.58196
Value Function Update Magnitude: 0.58281

Collected Steps per Second: 22,043.51298
Overall Steps per Second: 10,418.07168

Timestep Collection Time: 2.26915
Timestep Consumption Time: 2.53212
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.80127

Cumulative Model Updates: 128,886
Cumulative Timesteps: 1,074,986,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1074986616...
Checkpoint 1074986616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.29151
Policy Entropy: 3.22503
Value Function Loss: 0.00437

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.58200
Value Function Update Magnitude: 0.56702

Collected Steps per Second: 21,757.90169
Overall Steps per Second: 10,354.24506

Timestep Collection Time: 2.29884
Timestep Consumption Time: 2.53183
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.83068

Cumulative Model Updates: 128,892
Cumulative Timesteps: 1,075,036,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.23224
Policy Entropy: 3.22259
Value Function Loss: 0.00412

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.57438
Value Function Update Magnitude: 0.55672

Collected Steps per Second: 21,482.82971
Overall Steps per Second: 10,397.73357

Timestep Collection Time: 2.32865
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.81124

Cumulative Model Updates: 128,898
Cumulative Timesteps: 1,075,086,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1075086660...
Checkpoint 1075086660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.66952
Policy Entropy: 3.21519
Value Function Loss: 0.00425

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.55506

Collected Steps per Second: 22,694.56314
Overall Steps per Second: 10,329.75214

Timestep Collection Time: 2.20432
Timestep Consumption Time: 2.63859
PPO Batch Consumption Time: 0.31476
Total Iteration Time: 4.84290

Cumulative Model Updates: 128,904
Cumulative Timesteps: 1,075,136,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.53859
Policy Entropy: 3.19521
Value Function Loss: 0.00419

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.58298
Value Function Update Magnitude: 0.55510

Collected Steps per Second: 21,818.43823
Overall Steps per Second: 10,156.77348

Timestep Collection Time: 2.29173
Timestep Consumption Time: 2.63129
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 4.92302

Cumulative Model Updates: 128,910
Cumulative Timesteps: 1,075,186,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1075186688...
Checkpoint 1075186688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.04791
Policy Entropy: 3.19633
Value Function Loss: 0.00447

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.56022

Collected Steps per Second: 20,075.19929
Overall Steps per Second: 9,910.45252

Timestep Collection Time: 2.49064
Timestep Consumption Time: 2.55454
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 5.04518

Cumulative Model Updates: 128,916
Cumulative Timesteps: 1,075,236,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.26000
Policy Entropy: 3.22442
Value Function Loss: 0.00397

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.55727

Collected Steps per Second: 21,498.77361
Overall Steps per Second: 10,478.84251

Timestep Collection Time: 2.32683
Timestep Consumption Time: 2.44698
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.77381

Cumulative Model Updates: 128,922
Cumulative Timesteps: 1,075,286,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1075286712...
Checkpoint 1075286712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,030.37072
Policy Entropy: 3.23115
Value Function Loss: 0.00394

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.57103
Value Function Update Magnitude: 0.54229

Collected Steps per Second: 20,833.81411
Overall Steps per Second: 10,133.17587

Timestep Collection Time: 2.40062
Timestep Consumption Time: 2.53505
PPO Batch Consumption Time: 0.31087
Total Iteration Time: 4.93567

Cumulative Model Updates: 128,928
Cumulative Timesteps: 1,075,336,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.04080
Policy Entropy: 3.24790
Value Function Loss: 0.00357

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.56374
Value Function Update Magnitude: 0.52919

Collected Steps per Second: 20,705.71981
Overall Steps per Second: 10,301.45577

Timestep Collection Time: 2.41576
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.85562

Cumulative Model Updates: 128,934
Cumulative Timesteps: 1,075,386,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1075386746...
Checkpoint 1075386746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.36710
Policy Entropy: 3.23329
Value Function Loss: 0.00401

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.56240
Value Function Update Magnitude: 0.51148

Collected Steps per Second: 20,473.99061
Overall Steps per Second: 10,279.68014

Timestep Collection Time: 2.44300
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.86572

Cumulative Model Updates: 128,940
Cumulative Timesteps: 1,075,436,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.42232
Policy Entropy: 3.24053
Value Function Loss: 0.00407

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.55690
Value Function Update Magnitude: 0.52554

Collected Steps per Second: 22,350.39883
Overall Steps per Second: 10,353.08945

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.59331
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.83121

Cumulative Model Updates: 128,946
Cumulative Timesteps: 1,075,486,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1075486782...
Checkpoint 1075486782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.05765
Policy Entropy: 3.21394
Value Function Loss: 0.00419

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.56483
Value Function Update Magnitude: 0.54011

Collected Steps per Second: 20,719.83096
Overall Steps per Second: 9,868.19097

Timestep Collection Time: 2.41315
Timestep Consumption Time: 2.65364
PPO Batch Consumption Time: 0.31253
Total Iteration Time: 5.06678

Cumulative Model Updates: 128,952
Cumulative Timesteps: 1,075,536,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.80464
Policy Entropy: 3.21524
Value Function Loss: 0.00410

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.57262
Value Function Update Magnitude: 0.54213

Collected Steps per Second: 22,508.62840
Overall Steps per Second: 10,602.25250

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.71749

Cumulative Model Updates: 128,958
Cumulative Timesteps: 1,075,586,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1075586798...
Checkpoint 1075586798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.45611
Policy Entropy: 3.20960
Value Function Loss: 0.00410

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.57853
Value Function Update Magnitude: 0.55844

Collected Steps per Second: 22,707.68891
Overall Steps per Second: 10,675.37138

Timestep Collection Time: 2.20207
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.68405

Cumulative Model Updates: 128,964
Cumulative Timesteps: 1,075,636,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.00877
Policy Entropy: 3.22459
Value Function Loss: 0.00393

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.57277
Value Function Update Magnitude: 0.57665

Collected Steps per Second: 22,431.38686
Overall Steps per Second: 10,490.69707

Timestep Collection Time: 2.22938
Timestep Consumption Time: 2.53751
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.76689

Cumulative Model Updates: 128,970
Cumulative Timesteps: 1,075,686,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1075686810...
Checkpoint 1075686810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.29460
Policy Entropy: 3.22270
Value Function Loss: 0.00381

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.56491

Collected Steps per Second: 21,916.18571
Overall Steps per Second: 10,604.88973

Timestep Collection Time: 2.28160
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.71518

Cumulative Model Updates: 128,976
Cumulative Timesteps: 1,075,736,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,540.01354
Policy Entropy: 3.22629
Value Function Loss: 0.00414

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.53719

Collected Steps per Second: 22,555.21363
Overall Steps per Second: 10,469.91251

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.56014
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.77807

Cumulative Model Updates: 128,982
Cumulative Timesteps: 1,075,786,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1075786840...
Checkpoint 1075786840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.87566
Policy Entropy: 3.22129
Value Function Loss: 0.00394

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.52000

Collected Steps per Second: 22,245.66066
Overall Steps per Second: 10,560.81995

Timestep Collection Time: 2.24835
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.73600

Cumulative Model Updates: 128,988
Cumulative Timesteps: 1,075,836,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.20044
Policy Entropy: 3.21572
Value Function Loss: 0.00425

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.52054

Collected Steps per Second: 22,484.43220
Overall Steps per Second: 10,497.29679

Timestep Collection Time: 2.22438
Timestep Consumption Time: 2.54008
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76446

Cumulative Model Updates: 128,994
Cumulative Timesteps: 1,075,886,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1075886870...
Checkpoint 1075886870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.61639
Policy Entropy: 3.20404
Value Function Loss: 0.00421

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.53471

Collected Steps per Second: 21,700.04353
Overall Steps per Second: 10,611.31754

Timestep Collection Time: 2.30506
Timestep Consumption Time: 2.40877
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.71384

Cumulative Model Updates: 129,000
Cumulative Timesteps: 1,075,936,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.34470
Policy Entropy: 3.19763
Value Function Loss: 0.00430

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.52621

Collected Steps per Second: 21,862.21446
Overall Steps per Second: 10,487.83005

Timestep Collection Time: 2.28769
Timestep Consumption Time: 2.48107
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.76877

Cumulative Model Updates: 129,006
Cumulative Timesteps: 1,075,986,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1075986904...
Checkpoint 1075986904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.47629
Policy Entropy: 3.19487
Value Function Loss: 0.00448

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.59836
Value Function Update Magnitude: 0.53112

Collected Steps per Second: 21,709.40135
Overall Steps per Second: 10,664.26844

Timestep Collection Time: 2.30370
Timestep Consumption Time: 2.38598
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.68968

Cumulative Model Updates: 129,012
Cumulative Timesteps: 1,076,036,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.21697
Policy Entropy: 3.18643
Value Function Loss: 0.00484

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.61848
Value Function Update Magnitude: 0.56946

Collected Steps per Second: 21,585.19910
Overall Steps per Second: 10,436.61655

Timestep Collection Time: 2.31677
Timestep Consumption Time: 2.47482
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.79159

Cumulative Model Updates: 129,018
Cumulative Timesteps: 1,076,086,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1076086924...
Checkpoint 1076086924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.44350
Policy Entropy: 3.18870
Value Function Loss: 0.00483

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.62246
Value Function Update Magnitude: 0.59699

Collected Steps per Second: 22,425.20173
Overall Steps per Second: 10,594.21652

Timestep Collection Time: 2.23053
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.72144

Cumulative Model Updates: 129,024
Cumulative Timesteps: 1,076,136,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.06488
Policy Entropy: 3.18598
Value Function Loss: 0.00464

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.61032
Value Function Update Magnitude: 0.58864

Collected Steps per Second: 21,406.18621
Overall Steps per Second: 10,578.97320

Timestep Collection Time: 2.33643
Timestep Consumption Time: 2.39125
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.72768

Cumulative Model Updates: 129,030
Cumulative Timesteps: 1,076,186,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1076186958...
Checkpoint 1076186958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,021.99389
Policy Entropy: 3.19302
Value Function Loss: 0.00420

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.59415
Value Function Update Magnitude: 0.57088

Collected Steps per Second: 21,822.92396
Overall Steps per Second: 10,583.94911

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.72621

Cumulative Model Updates: 129,036
Cumulative Timesteps: 1,076,236,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.42697
Policy Entropy: 3.18012
Value Function Loss: 0.00436

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.59405
Value Function Update Magnitude: 0.53841

Collected Steps per Second: 21,929.38814
Overall Steps per Second: 10,556.77893

Timestep Collection Time: 2.28132
Timestep Consumption Time: 2.45762
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.73895

Cumulative Model Updates: 129,042
Cumulative Timesteps: 1,076,287,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1076287008...
Checkpoint 1076287008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.34268
Policy Entropy: 3.18174
Value Function Loss: 0.00427

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.59722
Value Function Update Magnitude: 0.53700

Collected Steps per Second: 21,784.39175
Overall Steps per Second: 10,503.68621

Timestep Collection Time: 2.29623
Timestep Consumption Time: 2.46610
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.76233

Cumulative Model Updates: 129,048
Cumulative Timesteps: 1,076,337,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.43493
Policy Entropy: 3.19468
Value Function Loss: 0.00428

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.58772
Value Function Update Magnitude: 0.53799

Collected Steps per Second: 21,789.14272
Overall Steps per Second: 10,474.18345

Timestep Collection Time: 2.29591
Timestep Consumption Time: 2.48021
PPO Batch Consumption Time: 0.29943
Total Iteration Time: 4.77612

Cumulative Model Updates: 129,054
Cumulative Timesteps: 1,076,387,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1076387056...
Checkpoint 1076387056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,940.35806
Policy Entropy: 3.20606
Value Function Loss: 0.00384

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.56384
Value Function Update Magnitude: 0.52815

Collected Steps per Second: 21,481.24762
Overall Steps per Second: 10,586.54146

Timestep Collection Time: 2.32873
Timestep Consumption Time: 2.39652
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.72524

Cumulative Model Updates: 129,060
Cumulative Timesteps: 1,076,437,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.78200
Policy Entropy: 3.21263
Value Function Loss: 0.00386

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.51255

Collected Steps per Second: 22,725.84307
Overall Steps per Second: 10,504.12952

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.55989
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.76003

Cumulative Model Updates: 129,066
Cumulative Timesteps: 1,076,487,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1076487080...
Checkpoint 1076487080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,289.30813
Policy Entropy: 3.20820
Value Function Loss: 0.00375

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.56126
Value Function Update Magnitude: 0.50573

Collected Steps per Second: 21,532.30101
Overall Steps per Second: 10,597.78899

Timestep Collection Time: 2.32293
Timestep Consumption Time: 2.39674
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.71966

Cumulative Model Updates: 129,072
Cumulative Timesteps: 1,076,537,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.67015
Policy Entropy: 3.21100
Value Function Loss: 0.00383

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.50849

Collected Steps per Second: 21,567.02686
Overall Steps per Second: 10,510.70943

Timestep Collection Time: 2.31900
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.75838

Cumulative Model Updates: 129,078
Cumulative Timesteps: 1,076,587,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1076587112...
Checkpoint 1076587112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.69036
Policy Entropy: 3.20880
Value Function Loss: 0.00381

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.56952
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 22,626.92437
Overall Steps per Second: 10,608.45876

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.50346
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.71322

Cumulative Model Updates: 129,084
Cumulative Timesteps: 1,076,637,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.89708
Policy Entropy: 3.22045
Value Function Loss: 0.00378

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.52505

Collected Steps per Second: 22,889.80753
Overall Steps per Second: 10,543.50477

Timestep Collection Time: 2.18455
Timestep Consumption Time: 2.55808
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.74264

Cumulative Model Updates: 129,090
Cumulative Timesteps: 1,076,687,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1076687116...
Checkpoint 1076687116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.35224
Policy Entropy: 3.21910
Value Function Loss: 0.00379

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.57455
Value Function Update Magnitude: 0.54445

Collected Steps per Second: 21,639.45266
Overall Steps per Second: 10,619.35975

Timestep Collection Time: 2.31143
Timestep Consumption Time: 2.39865
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.71008

Cumulative Model Updates: 129,096
Cumulative Timesteps: 1,076,737,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.25604
Policy Entropy: 3.21414
Value Function Loss: 0.00395

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.58239
Value Function Update Magnitude: 0.54126

Collected Steps per Second: 22,840.08751
Overall Steps per Second: 10,564.29841

Timestep Collection Time: 2.18931
Timestep Consumption Time: 2.54399
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.73330

Cumulative Model Updates: 129,102
Cumulative Timesteps: 1,076,787,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1076787138...
Checkpoint 1076787138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.63570
Policy Entropy: 3.21336
Value Function Loss: 0.00384

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.52198

Collected Steps per Second: 22,120.11901
Overall Steps per Second: 10,535.48781

Timestep Collection Time: 2.26057
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.74624

Cumulative Model Updates: 129,108
Cumulative Timesteps: 1,076,837,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,205.19835
Policy Entropy: 3.21303
Value Function Loss: 0.00386

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.50902

Collected Steps per Second: 22,076.65465
Overall Steps per Second: 10,625.46818

Timestep Collection Time: 2.26484
Timestep Consumption Time: 2.44084
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.70567

Cumulative Model Updates: 129,114
Cumulative Timesteps: 1,076,887,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1076887142...
Checkpoint 1076887142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.39725
Policy Entropy: 3.21976
Value Function Loss: 0.00412

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.52684

Collected Steps per Second: 21,355.33314
Overall Steps per Second: 10,410.60034

Timestep Collection Time: 2.34218
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.80453

Cumulative Model Updates: 129,120
Cumulative Timesteps: 1,076,937,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.18927
Policy Entropy: 3.21676
Value Function Loss: 0.00406

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.56625
Value Function Update Magnitude: 0.53371

Collected Steps per Second: 22,078.92560
Overall Steps per Second: 10,530.87345

Timestep Collection Time: 2.26487
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.74851

Cumulative Model Updates: 129,126
Cumulative Timesteps: 1,076,987,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1076987166...
Checkpoint 1076987166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950.76498
Policy Entropy: 3.21772
Value Function Loss: 0.00406

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.52609

Collected Steps per Second: 21,582.89398
Overall Steps per Second: 10,596.91775

Timestep Collection Time: 2.31767
Timestep Consumption Time: 2.40276
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.72043

Cumulative Model Updates: 129,132
Cumulative Timesteps: 1,077,037,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.81260
Policy Entropy: 3.22096
Value Function Loss: 0.00380

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.55358
Value Function Update Magnitude: 0.49721

Collected Steps per Second: 22,155.60227
Overall Steps per Second: 10,558.39903

Timestep Collection Time: 2.25785
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.73784

Cumulative Model Updates: 129,138
Cumulative Timesteps: 1,077,087,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1077087212...
Checkpoint 1077087212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.84469
Policy Entropy: 3.21543
Value Function Loss: 0.00385

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.55558
Value Function Update Magnitude: 0.49914

Collected Steps per Second: 21,469.59516
Overall Steps per Second: 10,584.91024

Timestep Collection Time: 2.32999
Timestep Consumption Time: 2.39598
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.72597

Cumulative Model Updates: 129,144
Cumulative Timesteps: 1,077,137,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.47578
Policy Entropy: 3.20785
Value Function Loss: 0.00361

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.51183

Collected Steps per Second: 21,935.63760
Overall Steps per Second: 10,517.74141

Timestep Collection Time: 2.28049
Timestep Consumption Time: 2.47566
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.75615

Cumulative Model Updates: 129,150
Cumulative Timesteps: 1,077,187,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1077187260...
Checkpoint 1077187260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.53740
Policy Entropy: 3.21103
Value Function Loss: 0.00362

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.55875
Value Function Update Magnitude: 0.49924

Collected Steps per Second: 22,057.45029
Overall Steps per Second: 10,538.38001

Timestep Collection Time: 2.26708
Timestep Consumption Time: 2.47805
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.74513

Cumulative Model Updates: 129,156
Cumulative Timesteps: 1,077,237,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.51641
Policy Entropy: 3.22351
Value Function Loss: 0.00354

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.49717

Collected Steps per Second: 22,006.26803
Overall Steps per Second: 10,561.64065

Timestep Collection Time: 2.27226
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.73449

Cumulative Model Updates: 129,162
Cumulative Timesteps: 1,077,287,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1077287270...
Checkpoint 1077287270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.73853
Policy Entropy: 3.21406
Value Function Loss: 0.00364

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.49003

Collected Steps per Second: 21,620.54835
Overall Steps per Second: 10,519.04310

Timestep Collection Time: 2.31271
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.75347

Cumulative Model Updates: 129,168
Cumulative Timesteps: 1,077,337,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.61277
Policy Entropy: 3.21798
Value Function Loss: 0.00357

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.54499
Value Function Update Magnitude: 0.48999

Collected Steps per Second: 22,062.18669
Overall Steps per Second: 10,595.77426

Timestep Collection Time: 2.26677
Timestep Consumption Time: 2.45303
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.71981

Cumulative Model Updates: 129,174
Cumulative Timesteps: 1,077,387,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1077387282...
Checkpoint 1077387282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,420.32367
Policy Entropy: 3.22242
Value Function Loss: 0.00356

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.53848
Value Function Update Magnitude: 0.48876

Collected Steps per Second: 21,416.51854
Overall Steps per Second: 10,418.90504

Timestep Collection Time: 2.33595
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.80166

Cumulative Model Updates: 129,180
Cumulative Timesteps: 1,077,437,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.49396
Policy Entropy: 3.22334
Value Function Loss: 0.00366

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.54101
Value Function Update Magnitude: 0.49472

Collected Steps per Second: 21,533.89455
Overall Steps per Second: 10,553.95298

Timestep Collection Time: 2.32276
Timestep Consumption Time: 2.41651
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.73927

Cumulative Model Updates: 129,186
Cumulative Timesteps: 1,077,487,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1077487328...
Checkpoint 1077487328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.50838
Policy Entropy: 3.22959
Value Function Loss: 0.00385

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.55120
Value Function Update Magnitude: 0.52879

Collected Steps per Second: 21,115.28160
Overall Steps per Second: 10,382.17059

Timestep Collection Time: 2.36918
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.81845

Cumulative Model Updates: 129,192
Cumulative Timesteps: 1,077,537,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.34363
Policy Entropy: 3.22047
Value Function Loss: 0.00392

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.54739

Collected Steps per Second: 22,078.89359
Overall Steps per Second: 10,671.83336

Timestep Collection Time: 2.26479
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.68561

Cumulative Model Updates: 129,198
Cumulative Timesteps: 1,077,587,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1077587358...
Checkpoint 1077587358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.40306
Policy Entropy: 3.23164
Value Function Loss: 0.00375

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.55487
Value Function Update Magnitude: 0.54153

Collected Steps per Second: 21,522.93277
Overall Steps per Second: 10,556.36096

Timestep Collection Time: 2.32357
Timestep Consumption Time: 2.41386
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.73743

Cumulative Model Updates: 129,204
Cumulative Timesteps: 1,077,637,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.81042
Policy Entropy: 3.23463
Value Function Loss: 0.00357

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.52950

Collected Steps per Second: 21,297.46406
Overall Steps per Second: 10,474.79130

Timestep Collection Time: 2.34826
Timestep Consumption Time: 2.42625
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.77451

Cumulative Model Updates: 129,210
Cumulative Timesteps: 1,077,687,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1077687380...
Checkpoint 1077687380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,084.39879
Policy Entropy: 3.21451
Value Function Loss: 0.00398

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.56171
Value Function Update Magnitude: 0.53946

Collected Steps per Second: 21,214.64039
Overall Steps per Second: 10,400.75170

Timestep Collection Time: 2.35743
Timestep Consumption Time: 2.45107
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.80850

Cumulative Model Updates: 129,216
Cumulative Timesteps: 1,077,737,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.08489
Policy Entropy: 3.19364
Value Function Loss: 0.00418

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.58768
Value Function Update Magnitude: 0.57365

Collected Steps per Second: 21,579.57575
Overall Steps per Second: 10,416.58834

Timestep Collection Time: 2.31747
Timestep Consumption Time: 2.48353
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.80100

Cumulative Model Updates: 129,222
Cumulative Timesteps: 1,077,787,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1077787402...
Checkpoint 1077787402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.77974
Policy Entropy: 3.19452
Value Function Loss: 0.00472

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.60136
Value Function Update Magnitude: 0.58511

Collected Steps per Second: 21,882.81478
Overall Steps per Second: 10,596.54730

Timestep Collection Time: 2.28517
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.71908

Cumulative Model Updates: 129,228
Cumulative Timesteps: 1,077,837,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.15776
Policy Entropy: 3.21300
Value Function Loss: 0.00424

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.58826
Value Function Update Magnitude: 0.57720

Collected Steps per Second: 21,924.85867
Overall Steps per Second: 10,556.35703

Timestep Collection Time: 2.28179
Timestep Consumption Time: 2.45734
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.73913

Cumulative Model Updates: 129,234
Cumulative Timesteps: 1,077,887,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1077887436...
Checkpoint 1077887436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,030.84148
Policy Entropy: 3.22767
Value Function Loss: 0.00376

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.52274

Collected Steps per Second: 21,549.54410
Overall Steps per Second: 10,522.85255

Timestep Collection Time: 2.32023
Timestep Consumption Time: 2.43133
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.75156

Cumulative Model Updates: 129,240
Cumulative Timesteps: 1,077,937,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,836.71982
Policy Entropy: 3.22251
Value Function Loss: 0.00381

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.55116
Value Function Update Magnitude: 0.49745

Collected Steps per Second: 21,833.01571
Overall Steps per Second: 10,507.66393

Timestep Collection Time: 2.29112
Timestep Consumption Time: 2.46941
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.76053

Cumulative Model Updates: 129,246
Cumulative Timesteps: 1,077,987,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1077987458...
Checkpoint 1077987458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.89639
Policy Entropy: 3.22298
Value Function Loss: 0.00366

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.55022
Value Function Update Magnitude: 0.49266

Collected Steps per Second: 21,664.60591
Overall Steps per Second: 10,609.86236

Timestep Collection Time: 2.30837
Timestep Consumption Time: 2.40517
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.71354

Cumulative Model Updates: 129,252
Cumulative Timesteps: 1,078,037,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.70914
Policy Entropy: 3.20584
Value Function Loss: 0.00376

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.48428

Collected Steps per Second: 22,279.80512
Overall Steps per Second: 10,605.72386

Timestep Collection Time: 2.24418
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.71444

Cumulative Model Updates: 129,258
Cumulative Timesteps: 1,078,087,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1078087468...
Checkpoint 1078087468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.50007
Policy Entropy: 3.20437
Value Function Loss: 0.00386

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.48832

Collected Steps per Second: 21,652.12097
Overall Steps per Second: 10,506.20057

Timestep Collection Time: 2.31044
Timestep Consumption Time: 2.45113
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.76157

Cumulative Model Updates: 129,264
Cumulative Timesteps: 1,078,137,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.54182
Policy Entropy: 3.19334
Value Function Loss: 0.00411

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.56907
Value Function Update Magnitude: 0.50196

Collected Steps per Second: 22,492.05936
Overall Steps per Second: 10,471.70262

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.55197
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.77515

Cumulative Model Updates: 129,270
Cumulative Timesteps: 1,078,187,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1078187498...
Checkpoint 1078187498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.67537
Policy Entropy: 3.19296
Value Function Loss: 0.00430

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.57468
Value Function Update Magnitude: 0.52782

Collected Steps per Second: 21,749.79369
Overall Steps per Second: 10,609.19001

Timestep Collection Time: 2.29924
Timestep Consumption Time: 2.41441
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.71365

Cumulative Model Updates: 129,276
Cumulative Timesteps: 1,078,237,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.62819
Policy Entropy: 3.19110
Value Function Loss: 0.00413

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.54415

Collected Steps per Second: 21,688.50746
Overall Steps per Second: 10,412.34029

Timestep Collection Time: 2.30592
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.80315

Cumulative Model Updates: 129,282
Cumulative Timesteps: 1,078,287,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1078287518...
Checkpoint 1078287518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740.85409
Policy Entropy: 3.19285
Value Function Loss: 0.00429

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.58216
Value Function Update Magnitude: 0.54052

Collected Steps per Second: 21,464.49660
Overall Steps per Second: 10,570.34983

Timestep Collection Time: 2.33036
Timestep Consumption Time: 2.40174
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.73210

Cumulative Model Updates: 129,288
Cumulative Timesteps: 1,078,337,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.00384
Policy Entropy: 3.18911
Value Function Loss: 0.00428

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.58236
Value Function Update Magnitude: 0.56797

Collected Steps per Second: 21,730.27157
Overall Steps per Second: 10,577.45227

Timestep Collection Time: 2.30204
Timestep Consumption Time: 2.42726
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.72931

Cumulative Model Updates: 129,294
Cumulative Timesteps: 1,078,387,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1078387562...
Checkpoint 1078387562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.01639
Policy Entropy: 3.19780
Value Function Loss: 0.00434

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.58117
Value Function Update Magnitude: 0.55589

Collected Steps per Second: 22,228.83132
Overall Steps per Second: 10,599.22909

Timestep Collection Time: 2.25077
Timestep Consumption Time: 2.46957
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.72034

Cumulative Model Updates: 129,300
Cumulative Timesteps: 1,078,437,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.42318
Policy Entropy: 3.19648
Value Function Loss: 0.00421

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.57705
Value Function Update Magnitude: 0.53747

Collected Steps per Second: 22,641.95098
Overall Steps per Second: 10,517.95645

Timestep Collection Time: 2.20838
Timestep Consumption Time: 2.54559
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.75397

Cumulative Model Updates: 129,306
Cumulative Timesteps: 1,078,487,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1078487596...
Checkpoint 1078487596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.67316
Policy Entropy: 3.20483
Value Function Loss: 0.00417

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.53244

Collected Steps per Second: 22,349.94256
Overall Steps per Second: 10,595.03118

Timestep Collection Time: 2.23848
Timestep Consumption Time: 2.48354
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.72202

Cumulative Model Updates: 129,312
Cumulative Timesteps: 1,078,537,626

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.36682
Policy Entropy: 3.19976
Value Function Loss: 0.00414

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.53674

Collected Steps per Second: 22,824.18806
Overall Steps per Second: 10,588.06132

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.53306
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.72494

Cumulative Model Updates: 129,318
Cumulative Timesteps: 1,078,587,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1078587654...
Checkpoint 1078587654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.30208
Policy Entropy: 3.20135
Value Function Loss: 0.00414

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.57731
Value Function Update Magnitude: 0.52432

Collected Steps per Second: 21,583.46231
Overall Steps per Second: 10,532.78528

Timestep Collection Time: 2.31677
Timestep Consumption Time: 2.43069
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.74746

Cumulative Model Updates: 129,324
Cumulative Timesteps: 1,078,637,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.06874
Policy Entropy: 3.20822
Value Function Loss: 0.00393

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.51622

Collected Steps per Second: 21,945.81391
Overall Steps per Second: 10,523.26863

Timestep Collection Time: 2.27961
Timestep Consumption Time: 2.47442
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.75404

Cumulative Model Updates: 129,330
Cumulative Timesteps: 1,078,687,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1078687686...
Checkpoint 1078687686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.91137
Policy Entropy: 3.19433
Value Function Loss: 0.00407

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.50902

Collected Steps per Second: 22,146.01542
Overall Steps per Second: 10,527.74285

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.49171
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.74955

Cumulative Model Updates: 129,336
Cumulative Timesteps: 1,078,737,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.82680
Policy Entropy: 3.19236
Value Function Loss: 0.00444

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.51075

Collected Steps per Second: 22,520.17949
Overall Steps per Second: 10,459.14684

Timestep Collection Time: 2.22050
Timestep Consumption Time: 2.56058
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.78108

Cumulative Model Updates: 129,342
Cumulative Timesteps: 1,078,787,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1078787694...
Checkpoint 1078787694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.06662
Policy Entropy: 3.18928
Value Function Loss: 0.00513

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.59381
Value Function Update Magnitude: 0.54722

Collected Steps per Second: 21,689.32420
Overall Steps per Second: 10,583.22345

Timestep Collection Time: 2.30528
Timestep Consumption Time: 2.41918
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.72446

Cumulative Model Updates: 129,348
Cumulative Timesteps: 1,078,837,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.81507
Policy Entropy: 3.21826
Value Function Loss: 0.00466

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.61098
Value Function Update Magnitude: 0.58978

Collected Steps per Second: 22,650.10074
Overall Steps per Second: 10,516.48119

Timestep Collection Time: 2.20794
Timestep Consumption Time: 2.54746
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.75539

Cumulative Model Updates: 129,354
Cumulative Timesteps: 1,078,887,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1078887704...
Checkpoint 1078887704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.86999
Policy Entropy: 3.20985
Value Function Loss: 0.00443

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.59983
Value Function Update Magnitude: 0.59223

Collected Steps per Second: 21,769.97677
Overall Steps per Second: 10,553.79461

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.73877

Cumulative Model Updates: 129,360
Cumulative Timesteps: 1,078,937,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.93402
Policy Entropy: 3.20239
Value Function Loss: 0.00434

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.58526
Value Function Update Magnitude: 0.57908

Collected Steps per Second: 22,151.11964
Overall Steps per Second: 10,603.45598

Timestep Collection Time: 2.25758
Timestep Consumption Time: 2.45861
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.71620

Cumulative Model Updates: 129,366
Cumulative Timesteps: 1,078,987,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1078987724...
Checkpoint 1078987724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.27084
Policy Entropy: 3.19467
Value Function Loss: 0.00415

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.57580
Value Function Update Magnitude: 0.56066

Collected Steps per Second: 21,282.78314
Overall Steps per Second: 10,490.83505

Timestep Collection Time: 2.35035
Timestep Consumption Time: 2.41781
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.76816

Cumulative Model Updates: 129,372
Cumulative Timesteps: 1,079,037,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.25463
Policy Entropy: 3.20329
Value Function Loss: 0.00412

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.56685
Value Function Update Magnitude: 0.53971

Collected Steps per Second: 21,754.13024
Overall Steps per Second: 10,526.65974

Timestep Collection Time: 2.29989
Timestep Consumption Time: 2.45300
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.75288

Cumulative Model Updates: 129,378
Cumulative Timesteps: 1,079,087,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1079087778...
Checkpoint 1079087778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.15212
Policy Entropy: 3.20444
Value Function Loss: 0.00400

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.56578
Value Function Update Magnitude: 0.54040

Collected Steps per Second: 21,720.67825
Overall Steps per Second: 10,529.72520

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74846

Cumulative Model Updates: 129,384
Cumulative Timesteps: 1,079,137,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.82858
Policy Entropy: 3.19825
Value Function Loss: 0.00429

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.56041

Collected Steps per Second: 21,736.22498
Overall Steps per Second: 10,442.34993

Timestep Collection Time: 2.30077
Timestep Consumption Time: 2.48838
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.78915

Cumulative Model Updates: 129,390
Cumulative Timesteps: 1,079,187,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1079187788...
Checkpoint 1079187788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.98781
Policy Entropy: 3.19792
Value Function Loss: 0.00392

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.57034
Value Function Update Magnitude: 0.57297

Collected Steps per Second: 21,875.08722
Overall Steps per Second: 10,693.17075

Timestep Collection Time: 2.28580
Timestep Consumption Time: 2.39027
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.67607

Cumulative Model Updates: 129,396
Cumulative Timesteps: 1,079,237,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823.05641
Policy Entropy: 3.18422
Value Function Loss: 0.00403

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.56777
Value Function Update Magnitude: 0.56137

Collected Steps per Second: 21,560.32762
Overall Steps per Second: 10,325.36268

Timestep Collection Time: 2.31963
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.30480
Total Iteration Time: 4.84361

Cumulative Model Updates: 129,402
Cumulative Timesteps: 1,079,287,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1079287802...
Checkpoint 1079287802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.66347
Policy Entropy: 3.18225
Value Function Loss: 0.00400

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.58147
Value Function Update Magnitude: 0.57701

Collected Steps per Second: 21,099.62038
Overall Steps per Second: 10,078.13182

Timestep Collection Time: 2.37037
Timestep Consumption Time: 2.59225
PPO Batch Consumption Time: 0.31497
Total Iteration Time: 4.96263

Cumulative Model Updates: 129,408
Cumulative Timesteps: 1,079,337,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.13395
Policy Entropy: 3.18150
Value Function Loss: 0.00405

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.58871
Value Function Update Magnitude: 0.59193

Collected Steps per Second: 21,027.72225
Overall Steps per Second: 10,366.64691

Timestep Collection Time: 2.37848
Timestep Consumption Time: 2.44603
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.82451

Cumulative Model Updates: 129,414
Cumulative Timesteps: 1,079,387,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1079387830...
Checkpoint 1079387830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,008.52751
Policy Entropy: 3.18850
Value Function Loss: 0.00406

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.58312
Value Function Update Magnitude: 0.55904

Collected Steps per Second: 22,003.48590
Overall Steps per Second: 10,609.86527

Timestep Collection Time: 2.27264
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.71316

Cumulative Model Updates: 129,420
Cumulative Timesteps: 1,079,437,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302.98096
Policy Entropy: 3.19090
Value Function Loss: 0.00396

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.58374
Value Function Update Magnitude: 0.55162

Collected Steps per Second: 21,713.56067
Overall Steps per Second: 10,522.40983

Timestep Collection Time: 2.30308
Timestep Consumption Time: 2.44945
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.75252

Cumulative Model Updates: 129,426
Cumulative Timesteps: 1,079,487,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1079487844...
Checkpoint 1079487844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.44779
Policy Entropy: 3.19235
Value Function Loss: 0.00415

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.58149
Value Function Update Magnitude: 0.54553

Collected Steps per Second: 21,628.12658
Overall Steps per Second: 10,548.53634

Timestep Collection Time: 2.31208
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.74056

Cumulative Model Updates: 129,432
Cumulative Timesteps: 1,079,537,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.09175
Policy Entropy: 3.17930
Value Function Loss: 0.00455

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.58183
Value Function Update Magnitude: 0.54624

Collected Steps per Second: 22,729.51334
Overall Steps per Second: 10,526.10783

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.75294

Cumulative Model Updates: 129,438
Cumulative Timesteps: 1,079,587,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1079587880...
Checkpoint 1079587880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,694.94319
Policy Entropy: 3.17633
Value Function Loss: 0.00455

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.58649
Value Function Update Magnitude: 0.56441

Collected Steps per Second: 21,618.99525
Overall Steps per Second: 10,580.79582

Timestep Collection Time: 2.31334
Timestep Consumption Time: 2.41334
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.72668

Cumulative Model Updates: 129,444
Cumulative Timesteps: 1,079,637,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.32665
Policy Entropy: 3.17003
Value Function Loss: 0.00461

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.59191
Value Function Update Magnitude: 0.57814

Collected Steps per Second: 21,930.00050
Overall Steps per Second: 10,449.24440

Timestep Collection Time: 2.28098
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.78714

Cumulative Model Updates: 129,450
Cumulative Timesteps: 1,079,687,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1079687914...
Checkpoint 1079687914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.05359
Policy Entropy: 3.18774
Value Function Loss: 0.00434

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.58691
Value Function Update Magnitude: 0.56715

Collected Steps per Second: 21,537.48897
Overall Steps per Second: 10,593.75923

Timestep Collection Time: 2.32153
Timestep Consumption Time: 2.39823
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.71976

Cumulative Model Updates: 129,456
Cumulative Timesteps: 1,079,737,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.13352
Policy Entropy: 3.17876
Value Function Loss: 0.00414

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.57351
Value Function Update Magnitude: 0.54376

Collected Steps per Second: 22,383.72135
Overall Steps per Second: 10,572.53006

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.73151

Cumulative Model Updates: 129,462
Cumulative Timesteps: 1,079,787,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1079787938...
Checkpoint 1079787938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.52583
Policy Entropy: 3.17637
Value Function Loss: 0.00398

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.51834

Collected Steps per Second: 22,178.82110
Overall Steps per Second: 10,595.50792

Timestep Collection Time: 2.25539
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.72106

Cumulative Model Updates: 129,468
Cumulative Timesteps: 1,079,837,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.51559
Policy Entropy: 3.17871
Value Function Loss: 0.00397

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.50938

Collected Steps per Second: 21,728.58600
Overall Steps per Second: 10,455.09798

Timestep Collection Time: 2.30185
Timestep Consumption Time: 2.48203
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.78389

Cumulative Model Updates: 129,474
Cumulative Timesteps: 1,079,887,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1079887976...
Checkpoint 1079887976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,407.99414
Policy Entropy: 3.19088
Value Function Loss: 0.00385

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.49645

Collected Steps per Second: 22,572.39257
Overall Steps per Second: 10,614.86774

Timestep Collection Time: 2.21580
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.71188

Cumulative Model Updates: 129,480
Cumulative Timesteps: 1,079,937,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.98448
Policy Entropy: 3.19491
Value Function Loss: 0.00403

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.50926

Collected Steps per Second: 22,572.61917
Overall Steps per Second: 10,508.55917

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.54529
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.76240

Cumulative Model Updates: 129,486
Cumulative Timesteps: 1,079,988,038

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1079988038...
Checkpoint 1079988038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.94565
Policy Entropy: 3.20726
Value Function Loss: 0.00401

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.57549
Value Function Update Magnitude: 0.54318

Collected Steps per Second: 22,646.96359
Overall Steps per Second: 10,652.26567

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.48693
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.69553

Cumulative Model Updates: 129,492
Cumulative Timesteps: 1,080,038,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.81110
Policy Entropy: 3.21802
Value Function Loss: 0.00411

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.54662

Collected Steps per Second: 22,137.24294
Overall Steps per Second: 10,458.39088

Timestep Collection Time: 2.26026
Timestep Consumption Time: 2.52403
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.78429

Cumulative Model Updates: 129,498
Cumulative Timesteps: 1,080,088,092

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1080088092...
Checkpoint 1080088092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.04961
Policy Entropy: 3.21546
Value Function Loss: 0.00408

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08721
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.52575

Collected Steps per Second: 22,452.21018
Overall Steps per Second: 10,643.11612

Timestep Collection Time: 2.22838
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.70088

Cumulative Model Updates: 129,504
Cumulative Timesteps: 1,080,138,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.89458
Policy Entropy: 3.20295
Value Function Loss: 0.00422

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.56478
Value Function Update Magnitude: 0.51235

Collected Steps per Second: 22,203.19754
Overall Steps per Second: 10,640.41667

Timestep Collection Time: 2.25193
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.69906

Cumulative Model Updates: 129,510
Cumulative Timesteps: 1,080,188,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1080188124...
Checkpoint 1080188124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.02249
Policy Entropy: 3.18651
Value Function Loss: 0.00463

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.52695

Collected Steps per Second: 21,833.25175
Overall Steps per Second: 10,514.36645

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.46551
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.75578

Cumulative Model Updates: 129,516
Cumulative Timesteps: 1,080,238,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.56101
Policy Entropy: 3.18620
Value Function Loss: 0.00419

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.56621
Value Function Update Magnitude: 0.52974

Collected Steps per Second: 21,924.94186
Overall Steps per Second: 10,543.36752

Timestep Collection Time: 2.28115
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.74365

Cumulative Model Updates: 129,522
Cumulative Timesteps: 1,080,288,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1080288142...
Checkpoint 1080288142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.37853
Policy Entropy: 3.18009
Value Function Loss: 0.00457

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.57715
Value Function Update Magnitude: 0.51552

Collected Steps per Second: 22,406.77237
Overall Steps per Second: 10,478.58770

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.54017
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.77164

Cumulative Model Updates: 129,528
Cumulative Timesteps: 1,080,338,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,260.77790
Policy Entropy: 3.18000
Value Function Loss: 0.00478

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.59462
Value Function Update Magnitude: 0.55381

Collected Steps per Second: 21,728.38656
Overall Steps per Second: 10,416.79491

Timestep Collection Time: 2.30141
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.30120
Total Iteration Time: 4.80052

Cumulative Model Updates: 129,534
Cumulative Timesteps: 1,080,388,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1080388148...
Checkpoint 1080388148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,402.39994
Policy Entropy: 3.19200
Value Function Loss: 0.00471

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.59729
Value Function Update Magnitude: 0.59376

Collected Steps per Second: 21,727.43487
Overall Steps per Second: 10,530.43238

Timestep Collection Time: 2.30262
Timestep Consumption Time: 2.44837
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.75099

Cumulative Model Updates: 129,540
Cumulative Timesteps: 1,080,438,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.36939
Policy Entropy: 3.19983
Value Function Loss: 0.00422

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.58899
Value Function Update Magnitude: 0.57667

Collected Steps per Second: 21,769.58175
Overall Steps per Second: 10,651.51353

Timestep Collection Time: 2.29697
Timestep Consumption Time: 2.39758
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.69454

Cumulative Model Updates: 129,546
Cumulative Timesteps: 1,080,488,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1080488182...
Checkpoint 1080488182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.10628
Policy Entropy: 3.20079
Value Function Loss: 0.00385

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.54263

Collected Steps per Second: 21,746.65087
Overall Steps per Second: 10,638.35692

Timestep Collection Time: 2.30040
Timestep Consumption Time: 2.40202
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.70242

Cumulative Model Updates: 129,552
Cumulative Timesteps: 1,080,538,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.52191
Policy Entropy: 3.19079
Value Function Loss: 0.00363

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.52093

Collected Steps per Second: 21,470.57232
Overall Steps per Second: 10,448.78517

Timestep Collection Time: 2.32886
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.78544

Cumulative Model Updates: 129,558
Cumulative Timesteps: 1,080,588,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1080588210...
Checkpoint 1080588210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.84419
Policy Entropy: 3.19553
Value Function Loss: 0.00396

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.55793
Value Function Update Magnitude: 0.51077

Collected Steps per Second: 18,444.47330
Overall Steps per Second: 9,707.34330

Timestep Collection Time: 2.71138
Timestep Consumption Time: 2.44039
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 5.15177

Cumulative Model Updates: 129,564
Cumulative Timesteps: 1,080,638,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.29027
Policy Entropy: 3.21193
Value Function Loss: 0.00400

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.51796

Collected Steps per Second: 21,834.88304
Overall Steps per Second: 10,535.54715

Timestep Collection Time: 2.28991
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.74584

Cumulative Model Updates: 129,570
Cumulative Timesteps: 1,080,688,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1080688220...
Checkpoint 1080688220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.48148
Policy Entropy: 3.21564
Value Function Loss: 0.00419

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.53769

Collected Steps per Second: 21,623.48698
Overall Steps per Second: 10,542.83193

Timestep Collection Time: 2.31360
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.74521

Cumulative Model Updates: 129,576
Cumulative Timesteps: 1,080,738,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.94399
Policy Entropy: 3.20331
Value Function Loss: 0.00408

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.57184
Value Function Update Magnitude: 0.56770

Collected Steps per Second: 20,396.04647
Overall Steps per Second: 10,152.70931

Timestep Collection Time: 2.45283
Timestep Consumption Time: 2.47472
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.92755

Cumulative Model Updates: 129,582
Cumulative Timesteps: 1,080,788,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1080788276...
Checkpoint 1080788276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.09575
Policy Entropy: 3.18707
Value Function Loss: 0.00413

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.55532

Collected Steps per Second: 21,417.17701
Overall Steps per Second: 10,585.23297

Timestep Collection Time: 2.33523
Timestep Consumption Time: 2.38966
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.72488

Cumulative Model Updates: 129,588
Cumulative Timesteps: 1,080,838,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.22925
Policy Entropy: 3.18065
Value Function Loss: 0.00410

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.54764

Collected Steps per Second: 21,585.17936
Overall Steps per Second: 10,460.29698

Timestep Collection Time: 2.31724
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.78170

Cumulative Model Updates: 129,594
Cumulative Timesteps: 1,080,888,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1080888308...
Checkpoint 1080888308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.02766
Policy Entropy: 3.18159
Value Function Loss: 0.00384

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.56592
Value Function Update Magnitude: 0.52321

Collected Steps per Second: 21,762.49592
Overall Steps per Second: 10,625.58628

Timestep Collection Time: 2.29863
Timestep Consumption Time: 2.40925
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.70788

Cumulative Model Updates: 129,600
Cumulative Timesteps: 1,080,938,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.72338
Policy Entropy: 3.18898
Value Function Loss: 0.00405

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.52098

Collected Steps per Second: 21,847.96449
Overall Steps per Second: 10,526.90253

Timestep Collection Time: 2.28982
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75240

Cumulative Model Updates: 129,606
Cumulative Timesteps: 1,080,988,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1080988360...
Checkpoint 1080988360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.92137
Policy Entropy: 3.18937
Value Function Loss: 0.00405

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10614
Policy Update Magnitude: 0.56330
Value Function Update Magnitude: 0.53213

Collected Steps per Second: 21,686.56705
Overall Steps per Second: 10,578.69233

Timestep Collection Time: 2.30604
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.72743

Cumulative Model Updates: 129,612
Cumulative Timesteps: 1,081,038,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,243.43668
Policy Entropy: 3.18453
Value Function Loss: 0.00412

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.56389
Value Function Update Magnitude: 0.54970

Collected Steps per Second: 21,946.66526
Overall Steps per Second: 10,481.76396

Timestep Collection Time: 2.27871
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.77114

Cumulative Model Updates: 129,618
Cumulative Timesteps: 1,081,088,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1081088380...
Checkpoint 1081088380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,977.50244
Policy Entropy: 3.17815
Value Function Loss: 0.00400

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.55671
Value Function Update Magnitude: 0.56092

Collected Steps per Second: 21,363.34606
Overall Steps per Second: 10,545.09462

Timestep Collection Time: 2.34130
Timestep Consumption Time: 2.40195
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.74325

Cumulative Model Updates: 129,624
Cumulative Timesteps: 1,081,138,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.21285
Policy Entropy: 3.18883
Value Function Loss: 0.00406

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.55855
Value Function Update Magnitude: 0.56703

Collected Steps per Second: 22,045.98596
Overall Steps per Second: 10,588.70615

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.72428

Cumulative Model Updates: 129,630
Cumulative Timesteps: 1,081,188,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1081188422...
Checkpoint 1081188422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.77663
Policy Entropy: 3.20167
Value Function Loss: 0.00378

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.55171
Value Function Update Magnitude: 0.55457

Collected Steps per Second: 21,442.33723
Overall Steps per Second: 10,560.11323

Timestep Collection Time: 2.33202
Timestep Consumption Time: 2.40315
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.73518

Cumulative Model Updates: 129,636
Cumulative Timesteps: 1,081,238,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.79762
Policy Entropy: 3.21193
Value Function Loss: 0.00378

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.56416

Collected Steps per Second: 21,698.89126
Overall Steps per Second: 10,517.55962

Timestep Collection Time: 2.30583
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.75719

Cumulative Model Updates: 129,642
Cumulative Timesteps: 1,081,288,460

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1081288460...
Checkpoint 1081288460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,717.37382
Policy Entropy: 3.21394
Value Function Loss: 0.00354

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.53728

Collected Steps per Second: 21,402.23900
Overall Steps per Second: 10,581.08836

Timestep Collection Time: 2.33723
Timestep Consumption Time: 2.39026
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.72749

Cumulative Model Updates: 129,648
Cumulative Timesteps: 1,081,338,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,611.00698
Policy Entropy: 3.21220
Value Function Loss: 0.00374

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.53164

Collected Steps per Second: 22,007.23146
Overall Steps per Second: 10,530.78917

Timestep Collection Time: 2.27271
Timestep Consumption Time: 2.47679
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.74950

Cumulative Model Updates: 129,654
Cumulative Timesteps: 1,081,388,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1081388498...
Checkpoint 1081388498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,946.69032
Policy Entropy: 3.21817
Value Function Loss: 0.00343

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.54228
Value Function Update Magnitude: 0.51934

Collected Steps per Second: 21,533.13530
Overall Steps per Second: 10,558.11918

Timestep Collection Time: 2.32284
Timestep Consumption Time: 2.41456
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.73740

Cumulative Model Updates: 129,660
Cumulative Timesteps: 1,081,438,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.44910
Policy Entropy: 3.21201
Value Function Loss: 0.00342

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.50677

Collected Steps per Second: 21,012.48225
Overall Steps per Second: 10,366.76796

Timestep Collection Time: 2.37954
Timestep Consumption Time: 2.44357
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.82310

Cumulative Model Updates: 129,666
Cumulative Timesteps: 1,081,488,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1081488516...
Checkpoint 1081488516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.12873
Policy Entropy: 3.22539
Value Function Loss: 0.00357

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.52296

Collected Steps per Second: 21,421.34550
Overall Steps per Second: 10,269.98709

Timestep Collection Time: 2.33524
Timestep Consumption Time: 2.53565
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.87089

Cumulative Model Updates: 129,672
Cumulative Timesteps: 1,081,538,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.15248
Policy Entropy: 3.19180
Value Function Loss: 0.00399

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.55668

Collected Steps per Second: 21,970.44689
Overall Steps per Second: 10,499.68620

Timestep Collection Time: 2.27669
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.76395

Cumulative Model Updates: 129,678
Cumulative Timesteps: 1,081,588,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1081588560...
Checkpoint 1081588560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,752.36463
Policy Entropy: 3.18960
Value Function Loss: 0.00419

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.57882

Collected Steps per Second: 21,180.26457
Overall Steps per Second: 10,265.73170

Timestep Collection Time: 2.36182
Timestep Consumption Time: 2.51109
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.87291

Cumulative Model Updates: 129,684
Cumulative Timesteps: 1,081,638,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.39547
Policy Entropy: 3.18251
Value Function Loss: 0.00396

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.57208
Value Function Update Magnitude: 0.57323

Collected Steps per Second: 22,297.02726
Overall Steps per Second: 10,489.69681

Timestep Collection Time: 2.24245
Timestep Consumption Time: 2.52413
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.76658

Cumulative Model Updates: 129,690
Cumulative Timesteps: 1,081,688,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1081688584...
Checkpoint 1081688584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.53557
Policy Entropy: 3.20086
Value Function Loss: 0.00386

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.54881

Collected Steps per Second: 22,430.49155
Overall Steps per Second: 10,529.97337

Timestep Collection Time: 2.23018
Timestep Consumption Time: 2.52045
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.75063

Cumulative Model Updates: 129,696
Cumulative Timesteps: 1,081,738,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.59512
Policy Entropy: 3.21944
Value Function Loss: 0.00398

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.54985
Value Function Update Magnitude: 0.54035

Collected Steps per Second: 21,785.80147
Overall Steps per Second: 10,533.48371

Timestep Collection Time: 2.29562
Timestep Consumption Time: 2.45228
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.74791

Cumulative Model Updates: 129,702
Cumulative Timesteps: 1,081,788,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1081788620...
Checkpoint 1081788620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,866.83869
Policy Entropy: 3.20641
Value Function Loss: 0.00400

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.55619

Collected Steps per Second: 21,871.94630
Overall Steps per Second: 10,520.40940

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.46732
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.75400

Cumulative Model Updates: 129,708
Cumulative Timesteps: 1,081,838,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.00269
Policy Entropy: 3.19476
Value Function Loss: 0.00417

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.55409
Value Function Update Magnitude: 0.56058

Collected Steps per Second: 22,665.34631
Overall Steps per Second: 10,573.41890

Timestep Collection Time: 2.20698
Timestep Consumption Time: 2.52394
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.73092

Cumulative Model Updates: 129,714
Cumulative Timesteps: 1,081,888,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1081888656...
Checkpoint 1081888656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.15237
Policy Entropy: 3.19079
Value Function Loss: 0.00422

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.54805

Collected Steps per Second: 22,124.85967
Overall Steps per Second: 10,610.31589

Timestep Collection Time: 2.26081
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.71428

Cumulative Model Updates: 129,720
Cumulative Timesteps: 1,081,938,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.78702
Policy Entropy: 3.19922
Value Function Loss: 0.00418

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.57932
Value Function Update Magnitude: 0.55062

Collected Steps per Second: 22,702.08781
Overall Steps per Second: 10,582.64661

Timestep Collection Time: 2.20262
Timestep Consumption Time: 2.52248
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.72509

Cumulative Model Updates: 129,726
Cumulative Timesteps: 1,081,988,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1081988680...
Checkpoint 1081988680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.96345
Policy Entropy: 3.20639
Value Function Loss: 0.00435

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.57589

Collected Steps per Second: 22,446.23974
Overall Steps per Second: 10,548.06818

Timestep Collection Time: 2.22781
Timestep Consumption Time: 2.51296
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.74077

Cumulative Model Updates: 129,732
Cumulative Timesteps: 1,082,038,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.58873
Policy Entropy: 3.19241
Value Function Loss: 0.00412

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.57654
Value Function Update Magnitude: 0.57189

Collected Steps per Second: 22,428.53383
Overall Steps per Second: 10,489.18166

Timestep Collection Time: 2.22930
Timestep Consumption Time: 2.53751
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.76682

Cumulative Model Updates: 129,738
Cumulative Timesteps: 1,082,088,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1082088686...
Checkpoint 1082088686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.44870
Policy Entropy: 3.19109
Value Function Loss: 0.00436

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.56786
Value Function Update Magnitude: 0.56151

Collected Steps per Second: 22,700.68638
Overall Steps per Second: 10,564.34865

Timestep Collection Time: 2.20337
Timestep Consumption Time: 2.53123
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.73460

Cumulative Model Updates: 129,744
Cumulative Timesteps: 1,082,138,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.64341
Policy Entropy: 3.18993
Value Function Loss: 0.00443

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.57494
Value Function Update Magnitude: 0.55295

Collected Steps per Second: 22,585.62426
Overall Steps per Second: 10,553.65117

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.52572
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.74111

Cumulative Model Updates: 129,750
Cumulative Timesteps: 1,082,188,740

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1082188740...
Checkpoint 1082188740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.45065
Policy Entropy: 3.19769
Value Function Loss: 0.00445

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.58538
Value Function Update Magnitude: 0.54817

Collected Steps per Second: 22,286.54616
Overall Steps per Second: 10,557.53317

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.49295
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.73690

Cumulative Model Updates: 129,756
Cumulative Timesteps: 1,082,238,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,150.40650
Policy Entropy: 3.19091
Value Function Loss: 0.00419

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.58071
Value Function Update Magnitude: 0.56372

Collected Steps per Second: 22,609.85490
Overall Steps per Second: 10,588.48701

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.51109
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.72287

Cumulative Model Updates: 129,762
Cumulative Timesteps: 1,082,288,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1082288758...
Checkpoint 1082288758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.29024
Policy Entropy: 3.20113
Value Function Loss: 0.00388

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.56618
Value Function Update Magnitude: 0.55788

Collected Steps per Second: 22,328.06419
Overall Steps per Second: 10,538.67777

Timestep Collection Time: 2.23933
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.74443

Cumulative Model Updates: 129,768
Cumulative Timesteps: 1,082,338,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.87021
Policy Entropy: 3.19583
Value Function Loss: 0.00390

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.52307

Collected Steps per Second: 22,907.39974
Overall Steps per Second: 10,507.74450

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.57683
PPO Batch Consumption Time: 0.30608
Total Iteration Time: 4.76049

Cumulative Model Updates: 129,774
Cumulative Timesteps: 1,082,388,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1082388780...
Checkpoint 1082388780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.04577
Policy Entropy: 3.19560
Value Function Loss: 0.00410

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.52093

Collected Steps per Second: 20,142.51200
Overall Steps per Second: 10,126.43628

Timestep Collection Time: 2.48281
Timestep Consumption Time: 2.45575
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.93856

Cumulative Model Updates: 129,780
Cumulative Timesteps: 1,082,438,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.39851
Policy Entropy: 3.20046
Value Function Loss: 0.00411

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.57971
Value Function Update Magnitude: 0.55103

Collected Steps per Second: 22,363.07979
Overall Steps per Second: 10,330.48677

Timestep Collection Time: 2.23663
Timestep Consumption Time: 2.60515
PPO Batch Consumption Time: 0.30866
Total Iteration Time: 4.84179

Cumulative Model Updates: 129,786
Cumulative Timesteps: 1,082,488,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1082488808...
Checkpoint 1082488808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.80903
Policy Entropy: 3.20798
Value Function Loss: 0.00392

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.57637
Value Function Update Magnitude: 0.56473

Collected Steps per Second: 22,417.13075
Overall Steps per Second: 10,678.19726

Timestep Collection Time: 2.23097
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.68356

Cumulative Model Updates: 129,792
Cumulative Timesteps: 1,082,538,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.74649
Policy Entropy: 3.21918
Value Function Loss: 0.00364

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.54718

Collected Steps per Second: 22,281.67665
Overall Steps per Second: 10,607.89403

Timestep Collection Time: 2.24534
Timestep Consumption Time: 2.47096
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.71630

Cumulative Model Updates: 129,798
Cumulative Timesteps: 1,082,588,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1082588850...
Checkpoint 1082588850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.08506
Policy Entropy: 3.22027
Value Function Loss: 0.00362

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.50496

Collected Steps per Second: 22,472.36450
Overall Steps per Second: 10,610.60812

Timestep Collection Time: 2.22549
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.71340

Cumulative Model Updates: 129,804
Cumulative Timesteps: 1,082,638,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.07071
Policy Entropy: 3.21719
Value Function Loss: 0.00371

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.50044

Collected Steps per Second: 21,313.93899
Overall Steps per Second: 10,382.40157

Timestep Collection Time: 2.34598
Timestep Consumption Time: 2.47006
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.81603

Cumulative Model Updates: 129,810
Cumulative Timesteps: 1,082,688,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1082688864...
Checkpoint 1082688864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.69023
Policy Entropy: 3.21646
Value Function Loss: 0.00367

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.50933

Collected Steps per Second: 21,747.35122
Overall Steps per Second: 10,307.90613

Timestep Collection Time: 2.29931
Timestep Consumption Time: 2.55172
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 4.85103

Cumulative Model Updates: 129,816
Cumulative Timesteps: 1,082,738,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,880.27838
Policy Entropy: 3.22259
Value Function Loss: 0.00365

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.52339

Collected Steps per Second: 22,049.77673
Overall Steps per Second: 10,384.28670

Timestep Collection Time: 2.26859
Timestep Consumption Time: 2.54849
PPO Batch Consumption Time: 0.30168
Total Iteration Time: 4.81709

Cumulative Model Updates: 129,822
Cumulative Timesteps: 1,082,788,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1082788890...
Checkpoint 1082788890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.73674
Policy Entropy: 3.23024
Value Function Loss: 0.00381

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.53177

Collected Steps per Second: 19,295.44251
Overall Steps per Second: 9,714.61182

Timestep Collection Time: 2.59274
Timestep Consumption Time: 2.55703
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 5.14977

Cumulative Model Updates: 129,828
Cumulative Timesteps: 1,082,838,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.16638
Policy Entropy: 3.22307
Value Function Loss: 0.00418

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.52511

Collected Steps per Second: 21,828.06153
Overall Steps per Second: 10,478.31359

Timestep Collection Time: 2.29164
Timestep Consumption Time: 2.48222
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.77386

Cumulative Model Updates: 129,834
Cumulative Timesteps: 1,082,888,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1082888940...
Checkpoint 1082888940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.78805
Policy Entropy: 3.21328
Value Function Loss: 0.00433

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.52586

Collected Steps per Second: 19,499.42912
Overall Steps per Second: 9,878.92596

Timestep Collection Time: 2.56428
Timestep Consumption Time: 2.49720
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 5.06148

Cumulative Model Updates: 129,840
Cumulative Timesteps: 1,082,938,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.79948
Policy Entropy: 3.18391
Value Function Loss: 0.00468

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.56435

Collected Steps per Second: 20,852.01432
Overall Steps per Second: 10,162.12350

Timestep Collection Time: 2.40006
Timestep Consumption Time: 2.52470
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.92476

Cumulative Model Updates: 129,846
Cumulative Timesteps: 1,082,988,988

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1082988988...
Checkpoint 1082988988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.10094
Policy Entropy: 3.17853
Value Function Loss: 0.00501

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.60674
Value Function Update Magnitude: 0.58844

Collected Steps per Second: 21,918.90714
Overall Steps per Second: 10,425.28783

Timestep Collection Time: 2.28168
Timestep Consumption Time: 2.51550
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.79718

Cumulative Model Updates: 129,852
Cumulative Timesteps: 1,083,039,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.93632
Policy Entropy: 3.17631
Value Function Loss: 0.00501

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.60362
Value Function Update Magnitude: 0.59843

Collected Steps per Second: 22,525.81445
Overall Steps per Second: 10,621.77424

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.48893
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.70976

Cumulative Model Updates: 129,858
Cumulative Timesteps: 1,083,089,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1083089026...
Checkpoint 1083089026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.55920
Policy Entropy: 3.18402
Value Function Loss: 0.00471

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.58347
Value Function Update Magnitude: 0.57776

Collected Steps per Second: 22,778.10148
Overall Steps per Second: 10,610.95730

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.51823
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.71437

Cumulative Model Updates: 129,864
Cumulative Timesteps: 1,083,139,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.65632
Policy Entropy: 3.19434
Value Function Loss: 0.00403

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.56126
Value Function Update Magnitude: 0.53161

Collected Steps per Second: 22,273.39995
Overall Steps per Second: 10,472.25060

Timestep Collection Time: 2.24564
Timestep Consumption Time: 2.53060
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.77624

Cumulative Model Updates: 129,870
Cumulative Timesteps: 1,083,189,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1083189068...
Checkpoint 1083189068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.26364
Policy Entropy: 3.19438
Value Function Loss: 0.00410

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.50479

Collected Steps per Second: 22,246.29589
Overall Steps per Second: 10,038.38232

Timestep Collection Time: 2.24828
Timestep Consumption Time: 2.73419
PPO Batch Consumption Time: 0.31802
Total Iteration Time: 4.98248

Cumulative Model Updates: 129,876
Cumulative Timesteps: 1,083,239,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.85116
Policy Entropy: 3.21260
Value Function Loss: 0.00413

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.52268

Collected Steps per Second: 22,548.21929
Overall Steps per Second: 10,598.04556

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.50098
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.71898

Cumulative Model Updates: 129,882
Cumulative Timesteps: 1,083,289,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1083289096...
Checkpoint 1083289096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,260.47692
Policy Entropy: 3.21842
Value Function Loss: 0.00402

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.56341
Value Function Update Magnitude: 0.53886

Collected Steps per Second: 22,380.07693
Overall Steps per Second: 10,586.33263

Timestep Collection Time: 2.23476
Timestep Consumption Time: 2.48964
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.72439

Cumulative Model Updates: 129,888
Cumulative Timesteps: 1,083,339,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.01679
Policy Entropy: 3.21097
Value Function Loss: 0.00386

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.56035
Value Function Update Magnitude: 0.55076

Collected Steps per Second: 22,388.90413
Overall Steps per Second: 10,590.53025

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.72309

Cumulative Model Updates: 129,894
Cumulative Timesteps: 1,083,389,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1083389130...
Checkpoint 1083389130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.52840
Policy Entropy: 3.20325
Value Function Loss: 0.00407

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.54923

Collected Steps per Second: 22,416.21260
Overall Steps per Second: 10,637.15843

Timestep Collection Time: 2.23115
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70182

Cumulative Model Updates: 129,900
Cumulative Timesteps: 1,083,439,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.00351
Policy Entropy: 3.20785
Value Function Loss: 0.00405

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.54715

Collected Steps per Second: 22,455.56390
Overall Steps per Second: 10,538.27573

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.51930
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.74708

Cumulative Model Updates: 129,906
Cumulative Timesteps: 1,083,489,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1083489170...
Checkpoint 1083489170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,996.55440
Policy Entropy: 3.20471
Value Function Loss: 0.00429

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.54868

Collected Steps per Second: 22,652.52253
Overall Steps per Second: 10,560.08945

Timestep Collection Time: 2.20814
Timestep Consumption Time: 2.52856
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 4.73670

Cumulative Model Updates: 129,912
Cumulative Timesteps: 1,083,539,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.62919
Policy Entropy: 3.20871
Value Function Loss: 0.00416

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.54833

Collected Steps per Second: 22,315.46337
Overall Steps per Second: 10,496.98556

Timestep Collection Time: 2.24105
Timestep Consumption Time: 2.52318
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.76422

Cumulative Model Updates: 129,918
Cumulative Timesteps: 1,083,589,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1083589200...
Checkpoint 1083589200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,286.89314
Policy Entropy: 3.20106
Value Function Loss: 0.00439

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.57454
Value Function Update Magnitude: 0.54247

Collected Steps per Second: 22,569.30605
Overall Steps per Second: 10,541.55733

Timestep Collection Time: 2.21540
Timestep Consumption Time: 2.52773
PPO Batch Consumption Time: 0.29791
Total Iteration Time: 4.74313

Cumulative Model Updates: 129,924
Cumulative Timesteps: 1,083,639,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.78283
Policy Entropy: 3.19697
Value Function Loss: 0.00428

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.58114
Value Function Update Magnitude: 0.55590

Collected Steps per Second: 22,427.17825
Overall Steps per Second: 10,378.98418

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.58913
PPO Batch Consumption Time: 0.30848
Total Iteration Time: 4.81955

Cumulative Model Updates: 129,930
Cumulative Timesteps: 1,083,689,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1083689222...
Checkpoint 1083689222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.38576
Policy Entropy: 3.19331
Value Function Loss: 0.00402

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.58017
Value Function Update Magnitude: 0.55841

Collected Steps per Second: 22,093.89472
Overall Steps per Second: 10,481.92243

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.77241

Cumulative Model Updates: 129,936
Cumulative Timesteps: 1,083,739,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.41759
Policy Entropy: 3.20824
Value Function Loss: 0.00383

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.53016

Collected Steps per Second: 22,378.57887
Overall Steps per Second: 10,651.89853

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.45972
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.69400

Cumulative Model Updates: 129,942
Cumulative Timesteps: 1,083,789,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1083789246...
Checkpoint 1083789246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.34057
Policy Entropy: 3.23252
Value Function Loss: 0.00360

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 0.50574

Collected Steps per Second: 22,122.62827
Overall Steps per Second: 10,420.49227

Timestep Collection Time: 2.26040
Timestep Consumption Time: 2.53841
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.79881

Cumulative Model Updates: 129,948
Cumulative Timesteps: 1,083,839,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.74466
Policy Entropy: 3.24098
Value Function Loss: 0.00374

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.53540
Value Function Update Magnitude: 0.49381

Collected Steps per Second: 22,545.69898
Overall Steps per Second: 10,656.67196

Timestep Collection Time: 2.21781
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.69208

Cumulative Model Updates: 129,954
Cumulative Timesteps: 1,083,889,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1083889254...
Checkpoint 1083889254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.27703
Policy Entropy: 3.23484
Value Function Loss: 0.00357

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.49384

Collected Steps per Second: 22,393.21798
Overall Steps per Second: 10,692.26986

Timestep Collection Time: 2.23362
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.67796

Cumulative Model Updates: 129,960
Cumulative Timesteps: 1,083,939,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.11249
Policy Entropy: 3.21427
Value Function Loss: 0.00372

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.51499

Collected Steps per Second: 22,485.64239
Overall Steps per Second: 10,504.38394

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.53658
PPO Batch Consumption Time: 0.29907
Total Iteration Time: 4.76049

Cumulative Model Updates: 129,966
Cumulative Timesteps: 1,083,989,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1083989278...
Checkpoint 1083989278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.70318
Policy Entropy: 3.21194
Value Function Loss: 0.00393

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.53148

Collected Steps per Second: 22,409.81769
Overall Steps per Second: 10,604.72059

Timestep Collection Time: 2.23143
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.71545

Cumulative Model Updates: 129,972
Cumulative Timesteps: 1,084,039,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.22048
Policy Entropy: 3.21542
Value Function Loss: 0.00395

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.54256

Collected Steps per Second: 21,682.38989
Overall Steps per Second: 10,395.46531

Timestep Collection Time: 2.30611
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.80998

Cumulative Model Updates: 129,978
Cumulative Timesteps: 1,084,089,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1084089286...
Checkpoint 1084089286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.64763
Policy Entropy: 3.21712
Value Function Loss: 0.00429

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.57267
Value Function Update Magnitude: 0.57865

Collected Steps per Second: 22,335.62881
Overall Steps per Second: 10,621.02756

Timestep Collection Time: 2.23965
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.70990

Cumulative Model Updates: 129,984
Cumulative Timesteps: 1,084,139,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.49878
Policy Entropy: 3.21034
Value Function Loss: 0.00415

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.57219
Value Function Update Magnitude: 0.56947

Collected Steps per Second: 22,386.72249
Overall Steps per Second: 10,568.49008

Timestep Collection Time: 2.23454
Timestep Consumption Time: 2.49878
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.73332

Cumulative Model Updates: 129,990
Cumulative Timesteps: 1,084,189,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1084189334...
Checkpoint 1084189334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.03093
Policy Entropy: 3.20965
Value Function Loss: 0.00434

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.56914
Value Function Update Magnitude: 0.54348

Collected Steps per Second: 22,407.80777
Overall Steps per Second: 10,626.95599

Timestep Collection Time: 2.23253
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.70746

Cumulative Model Updates: 129,996
Cumulative Timesteps: 1,084,239,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.66142
Policy Entropy: 3.20582
Value Function Loss: 0.00405

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.53043

Collected Steps per Second: 22,284.20695
Overall Steps per Second: 10,479.38427

Timestep Collection Time: 2.24446
Timestep Consumption Time: 2.52834
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.77280

Cumulative Model Updates: 130,002
Cumulative Timesteps: 1,084,289,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1084289376...
Checkpoint 1084289376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.30826
Policy Entropy: 3.20443
Value Function Loss: 0.00370

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 0.50342

Collected Steps per Second: 21,841.96050
Overall Steps per Second: 10,481.70401

Timestep Collection Time: 2.28972
Timestep Consumption Time: 2.48164
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.77136

Cumulative Model Updates: 130,008
Cumulative Timesteps: 1,084,339,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.28099
Policy Entropy: 3.21814
Value Function Loss: 0.00363

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.48777

Collected Steps per Second: 22,447.42977
Overall Steps per Second: 10,608.71969

Timestep Collection Time: 2.22752
Timestep Consumption Time: 2.48578
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.71329

Cumulative Model Updates: 130,014
Cumulative Timesteps: 1,084,389,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1084389390...
Checkpoint 1084389390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.00782
Policy Entropy: 3.22905
Value Function Loss: 0.00369

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.50285

Collected Steps per Second: 22,227.89441
Overall Steps per Second: 10,542.35096

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.74391

Cumulative Model Updates: 130,020
Cumulative Timesteps: 1,084,439,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.45738
Policy Entropy: 3.21763
Value Function Loss: 0.00392

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.51140

Collected Steps per Second: 22,816.31172
Overall Steps per Second: 10,546.65507

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.55004
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.74198

Cumulative Model Updates: 130,026
Cumulative Timesteps: 1,084,489,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1084489414...
Checkpoint 1084489414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.06085
Policy Entropy: 3.20284
Value Function Loss: 0.00435

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.56207
Value Function Update Magnitude: 0.53707

Collected Steps per Second: 22,142.62265
Overall Steps per Second: 10,621.66702

Timestep Collection Time: 2.25836
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.70792

Cumulative Model Updates: 130,032
Cumulative Timesteps: 1,084,539,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.59522
Policy Entropy: 3.19816
Value Function Loss: 0.00428

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.56679

Collected Steps per Second: 22,503.32208
Overall Steps per Second: 10,446.36920

Timestep Collection Time: 2.22323
Timestep Consumption Time: 2.56600
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.78922

Cumulative Model Updates: 130,038
Cumulative Timesteps: 1,084,589,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1084589450...
Checkpoint 1084589450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837.99276
Policy Entropy: 3.19700
Value Function Loss: 0.00432

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.57463

Collected Steps per Second: 22,342.89526
Overall Steps per Second: 10,668.56542

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.68742

Cumulative Model Updates: 130,044
Cumulative Timesteps: 1,084,639,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,868.15183
Policy Entropy: 3.20328
Value Function Loss: 0.00414

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.57906
Value Function Update Magnitude: 0.56273

Collected Steps per Second: 22,540.37353
Overall Steps per Second: 10,536.59445

Timestep Collection Time: 2.21957
Timestep Consumption Time: 2.52864
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.74821

Cumulative Model Updates: 130,050
Cumulative Timesteps: 1,084,689,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1084689488...
Checkpoint 1084689488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.00982
Policy Entropy: 3.18974
Value Function Loss: 0.00429

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.58999
Value Function Update Magnitude: 0.58300

Collected Steps per Second: 22,147.13920
Overall Steps per Second: 10,552.06707

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.48217
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.74106

Cumulative Model Updates: 130,056
Cumulative Timesteps: 1,084,739,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.37103
Policy Entropy: 3.19613
Value Function Loss: 0.00413

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.58899
Value Function Update Magnitude: 0.56919

Collected Steps per Second: 22,612.73170
Overall Steps per Second: 10,610.60898

Timestep Collection Time: 2.21185
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.71377

Cumulative Model Updates: 130,062
Cumulative Timesteps: 1,084,789,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1084789532...
Checkpoint 1084789532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,757.88474
Policy Entropy: 3.19112
Value Function Loss: 0.00401

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.57594
Value Function Update Magnitude: 0.54974

Collected Steps per Second: 22,247.79409
Overall Steps per Second: 10,460.92841

Timestep Collection Time: 2.24804
Timestep Consumption Time: 2.53299
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.78103

Cumulative Model Updates: 130,068
Cumulative Timesteps: 1,084,839,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.39338
Policy Entropy: 3.19552
Value Function Loss: 0.00381

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.56739
Value Function Update Magnitude: 0.53309

Collected Steps per Second: 22,692.49958
Overall Steps per Second: 10,584.54720

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.52282
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.72821

Cumulative Model Updates: 130,074
Cumulative Timesteps: 1,084,889,592

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1084889592...
Checkpoint 1084889592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.50725
Policy Entropy: 3.20896
Value Function Loss: 0.00386

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.50600

Collected Steps per Second: 22,313.51520
Overall Steps per Second: 10,420.95155

Timestep Collection Time: 2.24106
Timestep Consumption Time: 2.55754
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.79860

Cumulative Model Updates: 130,080
Cumulative Timesteps: 1,084,939,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.18918
Policy Entropy: 3.22362
Value Function Loss: 0.00378

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.50372

Collected Steps per Second: 22,962.28958
Overall Steps per Second: 10,518.04648

Timestep Collection Time: 2.17862
Timestep Consumption Time: 2.57759
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 4.75621

Cumulative Model Updates: 130,086
Cumulative Timesteps: 1,084,989,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1084989624...
Checkpoint 1084989624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.47119
Policy Entropy: 3.22262
Value Function Loss: 0.00402

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.51377

Collected Steps per Second: 22,253.94564
Overall Steps per Second: 10,668.87307

Timestep Collection Time: 2.24769
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.68841

Cumulative Model Updates: 130,092
Cumulative Timesteps: 1,085,039,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,411.08809
Policy Entropy: 3.21540
Value Function Loss: 0.00394

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.50375

Collected Steps per Second: 21,245.65717
Overall Steps per Second: 9,913.48269

Timestep Collection Time: 2.35408
Timestep Consumption Time: 2.69097
PPO Batch Consumption Time: 0.31362
Total Iteration Time: 5.04505

Cumulative Model Updates: 130,098
Cumulative Timesteps: 1,085,089,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1085089658...
Checkpoint 1085089658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.42484
Policy Entropy: 3.21190
Value Function Loss: 0.00418

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.55620
Value Function Update Magnitude: 0.49810

Collected Steps per Second: 19,897.03754
Overall Steps per Second: 9,780.28554

Timestep Collection Time: 2.51404
Timestep Consumption Time: 2.60053
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 5.11457

Cumulative Model Updates: 130,104
Cumulative Timesteps: 1,085,139,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.82693
Policy Entropy: 3.21542
Value Function Loss: 0.00389

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.52390

Collected Steps per Second: 22,513.21993
Overall Steps per Second: 10,519.07591

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.53286
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.75422

Cumulative Model Updates: 130,110
Cumulative Timesteps: 1,085,189,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1085189690...
Checkpoint 1085189690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.70824
Policy Entropy: 3.20983
Value Function Loss: 0.00418

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.56597
Value Function Update Magnitude: 0.51542

Collected Steps per Second: 21,537.62466
Overall Steps per Second: 10,480.41801

Timestep Collection Time: 2.32217
Timestep Consumption Time: 2.44997
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.77214

Cumulative Model Updates: 130,116
Cumulative Timesteps: 1,085,239,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.40804
Policy Entropy: 3.20610
Value Function Loss: 0.00388

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.50360

Collected Steps per Second: 22,705.19972
Overall Steps per Second: 10,732.34087

Timestep Collection Time: 2.20302
Timestep Consumption Time: 2.45766
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.66068

Cumulative Model Updates: 130,122
Cumulative Timesteps: 1,085,289,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1085289724...
Checkpoint 1085289724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,285.97492
Policy Entropy: 3.19978
Value Function Loss: 0.00375

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11733
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.47972

Collected Steps per Second: 22,211.87585
Overall Steps per Second: 10,606.14629

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.46330
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.71444

Cumulative Model Updates: 130,128
Cumulative Timesteps: 1,085,339,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.13616
Policy Entropy: 3.19705
Value Function Loss: 0.00387

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.47643

Collected Steps per Second: 22,703.07030
Overall Steps per Second: 10,587.73864

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.52161
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.72528

Cumulative Model Updates: 130,134
Cumulative Timesteps: 1,085,389,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1085389756...
Checkpoint 1085389756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.30729
Policy Entropy: 3.19302
Value Function Loss: 0.00389

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.48201

Collected Steps per Second: 22,175.75985
Overall Steps per Second: 10,616.26675

Timestep Collection Time: 2.25607
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.71258

Cumulative Model Updates: 130,140
Cumulative Timesteps: 1,085,439,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.06949
Policy Entropy: 3.19738
Value Function Loss: 0.00398

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.55290
Value Function Update Magnitude: 0.48105

Collected Steps per Second: 22,996.90710
Overall Steps per Second: 10,779.19137

Timestep Collection Time: 2.17508
Timestep Consumption Time: 2.46535
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.64042

Cumulative Model Updates: 130,146
Cumulative Timesteps: 1,085,489,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1085489806...
Checkpoint 1085489806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.15265
Policy Entropy: 3.20984
Value Function Loss: 0.00390

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.48475

Collected Steps per Second: 21,895.53048
Overall Steps per Second: 10,361.63872

Timestep Collection Time: 2.28385
Timestep Consumption Time: 2.54223
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.82607

Cumulative Model Updates: 130,152
Cumulative Timesteps: 1,085,539,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.31230
Policy Entropy: 3.19846
Value Function Loss: 0.00406

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.49400

Collected Steps per Second: 22,401.34603
Overall Steps per Second: 10,261.75579

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.64225
PPO Batch Consumption Time: 0.31103
Total Iteration Time: 4.87577

Cumulative Model Updates: 130,158
Cumulative Timesteps: 1,085,589,846

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1085589846...
Checkpoint 1085589846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.97853
Policy Entropy: 3.20630
Value Function Loss: 0.00412

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.50657

Collected Steps per Second: 22,535.67462
Overall Steps per Second: 10,476.54590

Timestep Collection Time: 2.22021
Timestep Consumption Time: 2.55560
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.77581

Cumulative Model Updates: 130,164
Cumulative Timesteps: 1,085,639,880

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.71363
Policy Entropy: 3.20209
Value Function Loss: 0.00406

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.54430
Value Function Update Magnitude: 0.50603

Collected Steps per Second: 22,353.93658
Overall Steps per Second: 10,523.34023

Timestep Collection Time: 2.23674
Timestep Consumption Time: 2.51460
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.75134

Cumulative Model Updates: 130,170
Cumulative Timesteps: 1,085,689,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1085689880...
Checkpoint 1085689880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.58283
Policy Entropy: 3.19584
Value Function Loss: 0.00383

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.47776

Collected Steps per Second: 22,455.07806
Overall Steps per Second: 10,435.27140

Timestep Collection Time: 2.22756
Timestep Consumption Time: 2.56580
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.79336

Cumulative Model Updates: 130,176
Cumulative Timesteps: 1,085,739,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,131.63503
Policy Entropy: 3.18795
Value Function Loss: 0.00395

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.54574
Value Function Update Magnitude: 0.48060

Collected Steps per Second: 22,253.66157
Overall Steps per Second: 10,518.27954

Timestep Collection Time: 2.24736
Timestep Consumption Time: 2.50741
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.75477

Cumulative Model Updates: 130,182
Cumulative Timesteps: 1,085,789,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1085789912...
Checkpoint 1085789912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.29489
Policy Entropy: 3.17796
Value Function Loss: 0.00386

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.49175

Collected Steps per Second: 22,285.32740
Overall Steps per Second: 10,633.06015

Timestep Collection Time: 2.24444
Timestep Consumption Time: 2.45957
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.70401

Cumulative Model Updates: 130,188
Cumulative Timesteps: 1,085,839,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.04391
Policy Entropy: 3.18505
Value Function Loss: 0.00398

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.55868
Value Function Update Magnitude: 0.50254

Collected Steps per Second: 22,440.98405
Overall Steps per Second: 10,545.96799

Timestep Collection Time: 2.22851
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.74210

Cumulative Model Updates: 130,194
Cumulative Timesteps: 1,085,889,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1085889940...
Checkpoint 1085889940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.90706
Policy Entropy: 3.18893
Value Function Loss: 0.00377

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.50239

Collected Steps per Second: 21,927.57674
Overall Steps per Second: 10,558.75881

Timestep Collection Time: 2.28096
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.73692

Cumulative Model Updates: 130,200
Cumulative Timesteps: 1,085,939,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.26017
Policy Entropy: 3.18280
Value Function Loss: 0.00373

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.50544

Collected Steps per Second: 22,721.78135
Overall Steps per Second: 10,448.88524

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.58518
PPO Batch Consumption Time: 0.30072
Total Iteration Time: 4.78616

Cumulative Model Updates: 130,206
Cumulative Timesteps: 1,085,989,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1085989966...
Checkpoint 1085989966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.55849
Policy Entropy: 3.17411
Value Function Loss: 0.00367

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.50910

Collected Steps per Second: 22,309.37897
Overall Steps per Second: 10,601.14172

Timestep Collection Time: 2.24148
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.71704

Cumulative Model Updates: 130,212
Cumulative Timesteps: 1,086,039,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.79378
Policy Entropy: 3.17553
Value Function Loss: 0.00390

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.51810

Collected Steps per Second: 22,519.29264
Overall Steps per Second: 10,433.64071

Timestep Collection Time: 2.22165
Timestep Consumption Time: 2.57342
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.79507

Cumulative Model Updates: 130,218
Cumulative Timesteps: 1,086,090,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1086090002...
Checkpoint 1086090002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.05890
Policy Entropy: 3.19334
Value Function Loss: 0.00383

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.55749
Value Function Update Magnitude: 0.51734

Collected Steps per Second: 22,137.61528
Overall Steps per Second: 10,624.41475

Timestep Collection Time: 2.25923
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.70746

Cumulative Model Updates: 130,224
Cumulative Timesteps: 1,086,140,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.04508
Policy Entropy: 3.19423
Value Function Loss: 0.00392

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.54675
Value Function Update Magnitude: 0.50485

Collected Steps per Second: 22,574.38251
Overall Steps per Second: 10,495.87488

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.54908
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.76416

Cumulative Model Updates: 130,230
Cumulative Timesteps: 1,086,190,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1086190020...
Checkpoint 1086190020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.30212
Policy Entropy: 3.20727
Value Function Loss: 0.00363

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.48590

Collected Steps per Second: 22,304.38448
Overall Steps per Second: 10,447.79517

Timestep Collection Time: 2.24261
Timestep Consumption Time: 2.54500
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.78761

Cumulative Model Updates: 130,236
Cumulative Timesteps: 1,086,240,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.49959
Policy Entropy: 3.21122
Value Function Loss: 0.00407

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.50847

Collected Steps per Second: 22,351.18108
Overall Steps per Second: 10,441.90511

Timestep Collection Time: 2.23818
Timestep Consumption Time: 2.55271
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.79089

Cumulative Model Updates: 130,242
Cumulative Timesteps: 1,086,290,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1086290066...
Checkpoint 1086290066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.21697
Policy Entropy: 3.22662
Value Function Loss: 0.00423

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.56128
Value Function Update Magnitude: 0.53576

Collected Steps per Second: 22,486.01716
Overall Steps per Second: 10,499.79247

Timestep Collection Time: 2.22440
Timestep Consumption Time: 2.53931
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.76371

Cumulative Model Updates: 130,248
Cumulative Timesteps: 1,086,340,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.80524
Policy Entropy: 3.21597
Value Function Loss: 0.00450

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.59101

Collected Steps per Second: 22,454.96687
Overall Steps per Second: 10,588.53742

Timestep Collection Time: 2.22819
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.72530

Cumulative Model Updates: 130,254
Cumulative Timesteps: 1,086,390,118

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1086390118...
Checkpoint 1086390118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.73497
Policy Entropy: 3.19788
Value Function Loss: 0.00412

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.58701

Collected Steps per Second: 22,541.00310
Overall Steps per Second: 10,580.28348

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.72577

Cumulative Model Updates: 130,260
Cumulative Timesteps: 1,086,440,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.73648
Policy Entropy: 3.19594
Value Function Loss: 0.00354

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.54358
Value Function Update Magnitude: 0.54071

Collected Steps per Second: 22,602.91860
Overall Steps per Second: 10,687.13794

Timestep Collection Time: 2.21325
Timestep Consumption Time: 2.46770
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.68095

Cumulative Model Updates: 130,266
Cumulative Timesteps: 1,086,490,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1086490144...
Checkpoint 1086490144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.72196
Policy Entropy: 3.20063
Value Function Loss: 0.00344

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.52427

Collected Steps per Second: 22,058.59972
Overall Steps per Second: 10,505.91427

Timestep Collection Time: 2.26687
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.75960

Cumulative Model Updates: 130,272
Cumulative Timesteps: 1,086,540,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.72418
Policy Entropy: 3.21526
Value Function Loss: 0.00340

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.53330
Value Function Update Magnitude: 0.51121

Collected Steps per Second: 22,710.47715
Overall Steps per Second: 10,725.17290

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.46119
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.66361

Cumulative Model Updates: 130,278
Cumulative Timesteps: 1,086,590,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1086590166...
Checkpoint 1086590166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.19620
Policy Entropy: 3.21453
Value Function Loss: 0.00355

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.54097
Value Function Update Magnitude: 0.47721

Collected Steps per Second: 21,997.38334
Overall Steps per Second: 10,588.17001

Timestep Collection Time: 2.27427
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.72490

Cumulative Model Updates: 130,284
Cumulative Timesteps: 1,086,640,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.17147
Policy Entropy: 3.21650
Value Function Loss: 0.00376

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.54813
Value Function Update Magnitude: 0.48844

Collected Steps per Second: 22,455.37148
Overall Steps per Second: 10,443.17656

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.56159
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.78858

Cumulative Model Updates: 130,290
Cumulative Timesteps: 1,086,690,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1086690202...
Checkpoint 1086690202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.35827
Policy Entropy: 3.22145
Value Function Loss: 0.00399

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.54612

Collected Steps per Second: 22,487.14941
Overall Steps per Second: 10,702.51544

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.67255

Cumulative Model Updates: 130,296
Cumulative Timesteps: 1,086,740,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.04494
Policy Entropy: 3.21514
Value Function Loss: 0.00394

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.55303
Value Function Update Magnitude: 0.60431

Collected Steps per Second: 22,198.74661
Overall Steps per Second: 10,423.63071

Timestep Collection Time: 2.25274
Timestep Consumption Time: 2.54482
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.79756

Cumulative Model Updates: 130,302
Cumulative Timesteps: 1,086,790,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1086790218...
Checkpoint 1086790218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,268.10540
Policy Entropy: 3.20682
Value Function Loss: 0.00371

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.57898

Collected Steps per Second: 22,540.28813
Overall Steps per Second: 10,659.60391

Timestep Collection Time: 2.21896
Timestep Consumption Time: 2.47315
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69211

Cumulative Model Updates: 130,308
Cumulative Timesteps: 1,086,840,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,227.16285
Policy Entropy: 3.20143
Value Function Loss: 0.00354

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.54967

Collected Steps per Second: 22,262.93022
Overall Steps per Second: 10,446.88976

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.54094
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.78745

Cumulative Model Updates: 130,314
Cumulative Timesteps: 1,086,890,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1086890248...
Checkpoint 1086890248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.39542
Policy Entropy: 3.20458
Value Function Loss: 0.00399

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.53727

Collected Steps per Second: 22,225.13647
Overall Steps per Second: 10,455.09101

Timestep Collection Time: 2.25024
Timestep Consumption Time: 2.53326
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.78351

Cumulative Model Updates: 130,320
Cumulative Timesteps: 1,086,940,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.23569
Policy Entropy: 3.20065
Value Function Loss: 0.00421

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.56026

Collected Steps per Second: 22,724.56551
Overall Steps per Second: 10,663.94477

Timestep Collection Time: 2.20035
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.68888

Cumulative Model Updates: 130,326
Cumulative Timesteps: 1,086,990,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1086990262...
Checkpoint 1086990262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.19680
Policy Entropy: 3.18660
Value Function Loss: 0.00462

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.58452

Collected Steps per Second: 22,283.74240
Overall Steps per Second: 10,558.74677

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.73806

Cumulative Model Updates: 130,332
Cumulative Timesteps: 1,087,040,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,542.35425
Policy Entropy: 3.17494
Value Function Loss: 0.00427

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.58708

Collected Steps per Second: 22,371.66169
Overall Steps per Second: 10,482.79292

Timestep Collection Time: 2.23685
Timestep Consumption Time: 2.53688
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.77373

Cumulative Model Updates: 130,338
Cumulative Timesteps: 1,087,090,332

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1087090332...
Checkpoint 1087090332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.51844
Policy Entropy: 3.18151
Value Function Loss: 0.00390

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.57667

Collected Steps per Second: 22,244.16542
Overall Steps per Second: 10,597.38848

Timestep Collection Time: 2.24904
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.72079

Cumulative Model Updates: 130,344
Cumulative Timesteps: 1,087,140,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.79397
Policy Entropy: 3.18401
Value Function Loss: 0.00381

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.54608

Collected Steps per Second: 22,636.21028
Overall Steps per Second: 10,548.92051

Timestep Collection Time: 2.20982
Timestep Consumption Time: 2.53208
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.74191

Cumulative Model Updates: 130,350
Cumulative Timesteps: 1,087,190,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1087190382...
Checkpoint 1087190382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.63912
Policy Entropy: 3.18540
Value Function Loss: 0.00414

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.58519
Value Function Update Magnitude: 0.56898

Collected Steps per Second: 22,552.63190
Overall Steps per Second: 10,674.10177

Timestep Collection Time: 2.21819
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.68667

Cumulative Model Updates: 130,356
Cumulative Timesteps: 1,087,240,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.16782
Policy Entropy: 3.19385
Value Function Loss: 0.00388

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.57167
Value Function Update Magnitude: 0.57946

Collected Steps per Second: 22,110.48789
Overall Steps per Second: 10,389.17593

Timestep Collection Time: 2.26191
Timestep Consumption Time: 2.55194
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.81386

Cumulative Model Updates: 130,362
Cumulative Timesteps: 1,087,290,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1087290420...
Checkpoint 1087290420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968.48795
Policy Entropy: 3.21911
Value Function Loss: 0.00377

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.55994

Collected Steps per Second: 22,505.87955
Overall Steps per Second: 10,611.66460

Timestep Collection Time: 2.22262
Timestep Consumption Time: 2.49125
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.71387

Cumulative Model Updates: 130,368
Cumulative Timesteps: 1,087,340,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.32204
Policy Entropy: 3.21153
Value Function Loss: 0.00373

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.55834

Collected Steps per Second: 22,233.38099
Overall Steps per Second: 10,515.23672

Timestep Collection Time: 2.24995
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75729

Cumulative Model Updates: 130,374
Cumulative Timesteps: 1,087,390,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1087390466...
Checkpoint 1087390466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961.79907
Policy Entropy: 3.19442
Value Function Loss: 0.00385

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.56614

Collected Steps per Second: 22,428.60517
Overall Steps per Second: 10,680.35063

Timestep Collection Time: 2.23028
Timestep Consumption Time: 2.45328
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.68355

Cumulative Model Updates: 130,380
Cumulative Timesteps: 1,087,440,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.44879
Policy Entropy: 3.19430
Value Function Loss: 0.00388

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.54687
Value Function Update Magnitude: 0.55340

Collected Steps per Second: 22,246.80545
Overall Steps per Second: 10,464.87252

Timestep Collection Time: 2.24769
Timestep Consumption Time: 2.53058
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.77827

Cumulative Model Updates: 130,386
Cumulative Timesteps: 1,087,490,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1087490492...
Checkpoint 1087490492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.38486
Policy Entropy: 3.18941
Value Function Loss: 0.00365

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.55573
Value Function Update Magnitude: 0.55377

Collected Steps per Second: 22,107.59679
Overall Steps per Second: 10,507.91124

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.75832

Cumulative Model Updates: 130,392
Cumulative Timesteps: 1,087,540,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237.99162
Policy Entropy: 3.19586
Value Function Loss: 0.00357

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.56234

Collected Steps per Second: 22,089.27668
Overall Steps per Second: 10,415.96918

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.53739
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.80147

Cumulative Model Updates: 130,398
Cumulative Timesteps: 1,087,590,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1087590504...
Checkpoint 1087590504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.62753
Policy Entropy: 3.19143
Value Function Loss: 0.00365

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.56838

Collected Steps per Second: 22,240.95228
Overall Steps per Second: 10,440.29355

Timestep Collection Time: 2.24855
Timestep Consumption Time: 2.54154
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.79010

Cumulative Model Updates: 130,404
Cumulative Timesteps: 1,087,640,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.57571
Policy Entropy: 3.20052
Value Function Loss: 0.00363

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.55330

Collected Steps per Second: 22,538.42745
Overall Steps per Second: 10,429.31512

Timestep Collection Time: 2.21941
Timestep Consumption Time: 2.57688
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 4.79629

Cumulative Model Updates: 130,410
Cumulative Timesteps: 1,087,690,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1087690536...
Checkpoint 1087690536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,080.94554
Policy Entropy: 3.22200
Value Function Loss: 0.00362

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.54763

Collected Steps per Second: 22,031.90980
Overall Steps per Second: 10,523.32480

Timestep Collection Time: 2.27016
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.75287

Cumulative Model Updates: 130,416
Cumulative Timesteps: 1,087,740,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.96872
Policy Entropy: 3.22019
Value Function Loss: 0.00342

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.53597
Value Function Update Magnitude: 0.53054

Collected Steps per Second: 22,276.84186
Overall Steps per Second: 10,496.11625

Timestep Collection Time: 2.24457
Timestep Consumption Time: 2.51928
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.76386

Cumulative Model Updates: 130,422
Cumulative Timesteps: 1,087,790,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1087790554...
Checkpoint 1087790554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.89661
Policy Entropy: 3.20513
Value Function Loss: 0.00372

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.53923
Value Function Update Magnitude: 0.52233

Collected Steps per Second: 22,473.00990
Overall Steps per Second: 10,655.49900

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.69298

Cumulative Model Updates: 130,428
Cumulative Timesteps: 1,087,840,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,017.05894
Policy Entropy: 3.19513
Value Function Loss: 0.00351

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.54593
Value Function Update Magnitude: 0.53734

Collected Steps per Second: 22,068.39490
Overall Steps per Second: 10,424.24897

Timestep Collection Time: 2.26641
Timestep Consumption Time: 2.53163
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.79804

Cumulative Model Updates: 130,434
Cumulative Timesteps: 1,087,890,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1087890576...
Checkpoint 1087890576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.76166
Policy Entropy: 3.20146
Value Function Loss: 0.00353

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.53069

Collected Steps per Second: 20,876.30659
Overall Steps per Second: 10,012.81225

Timestep Collection Time: 2.39621
Timestep Consumption Time: 2.59979
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.99600

Cumulative Model Updates: 130,440
Cumulative Timesteps: 1,087,940,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.10574
Policy Entropy: 3.21927
Value Function Loss: 0.00362

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.54969

Collected Steps per Second: 22,084.32959
Overall Steps per Second: 10,606.12287

Timestep Collection Time: 2.26477
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.71577

Cumulative Model Updates: 130,446
Cumulative Timesteps: 1,087,990,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1087990616...
Checkpoint 1087990616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.57647
Policy Entropy: 3.22359
Value Function Loss: 0.00356

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.56188

Collected Steps per Second: 20,757.66085
Overall Steps per Second: 9,943.57903

Timestep Collection Time: 2.40942
Timestep Consumption Time: 2.62035
PPO Batch Consumption Time: 0.30628
Total Iteration Time: 5.02978

Cumulative Model Updates: 130,452
Cumulative Timesteps: 1,088,040,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.33085
Policy Entropy: 3.22990
Value Function Loss: 0.00331

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.54877

Collected Steps per Second: 21,908.52800
Overall Steps per Second: 10,389.04135

Timestep Collection Time: 2.28313
Timestep Consumption Time: 2.53156
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.81469

Cumulative Model Updates: 130,458
Cumulative Timesteps: 1,088,090,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1088090650...
Checkpoint 1088090650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.61487
Policy Entropy: 3.22797
Value Function Loss: 0.00330

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.52716

Collected Steps per Second: 20,907.28034
Overall Steps per Second: 10,193.43937

Timestep Collection Time: 2.39256
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.90727

Cumulative Model Updates: 130,464
Cumulative Timesteps: 1,088,140,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,936.84740
Policy Entropy: 3.22703
Value Function Loss: 0.00346

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.51507

Collected Steps per Second: 22,763.21924
Overall Steps per Second: 10,512.84519

Timestep Collection Time: 2.19714
Timestep Consumption Time: 2.56028
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.75742

Cumulative Model Updates: 130,470
Cumulative Timesteps: 1,088,190,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1088190686...
Checkpoint 1088190686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.62697
Policy Entropy: 3.22262
Value Function Loss: 0.00349

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.54260
Value Function Update Magnitude: 0.51838

Collected Steps per Second: 22,031.26657
Overall Steps per Second: 10,299.42127

Timestep Collection Time: 2.27014
Timestep Consumption Time: 2.58586
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.85600

Cumulative Model Updates: 130,476
Cumulative Timesteps: 1,088,240,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.28331
Policy Entropy: 3.20977
Value Function Loss: 0.00368

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.50746

Collected Steps per Second: 22,409.48070
Overall Steps per Second: 10,526.01404

Timestep Collection Time: 2.23173
Timestep Consumption Time: 2.51954
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.75128

Cumulative Model Updates: 130,482
Cumulative Timesteps: 1,088,290,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1088290712...
Checkpoint 1088290712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.92400
Policy Entropy: 3.21787
Value Function Loss: 0.00364

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.52846

Collected Steps per Second: 22,492.53213
Overall Steps per Second: 10,544.37569

Timestep Collection Time: 2.22376
Timestep Consumption Time: 2.51981
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.74357

Cumulative Model Updates: 130,488
Cumulative Timesteps: 1,088,340,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.66216
Policy Entropy: 3.22764
Value Function Loss: 0.00376

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.55159
Value Function Update Magnitude: 0.56878

Collected Steps per Second: 22,501.05180
Overall Steps per Second: 10,520.76393

Timestep Collection Time: 2.22239
Timestep Consumption Time: 2.53069
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.75308

Cumulative Model Updates: 130,494
Cumulative Timesteps: 1,088,390,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1088390736...
Checkpoint 1088390736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,728.06044
Policy Entropy: 3.23588
Value Function Loss: 0.00390

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.55525
Value Function Update Magnitude: 0.56768

Collected Steps per Second: 22,542.13316
Overall Steps per Second: 10,458.60502

Timestep Collection Time: 2.21807
Timestep Consumption Time: 2.56268
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.78075

Cumulative Model Updates: 130,500
Cumulative Timesteps: 1,088,440,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.83998
Policy Entropy: 3.23220
Value Function Loss: 0.00414

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.56623

Collected Steps per Second: 22,598.29306
Overall Steps per Second: 10,477.47848

Timestep Collection Time: 2.21291
Timestep Consumption Time: 2.55999
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.77290

Cumulative Model Updates: 130,506
Cumulative Timesteps: 1,088,490,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1088490744...
Checkpoint 1088490744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.71629
Policy Entropy: 3.22558
Value Function Loss: 0.00430

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.57454
Value Function Update Magnitude: 0.59219

Collected Steps per Second: 22,227.97282
Overall Steps per Second: 10,537.42755

Timestep Collection Time: 2.25059
Timestep Consumption Time: 2.49687
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.74746

Cumulative Model Updates: 130,512
Cumulative Timesteps: 1,088,540,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.51070
Policy Entropy: 3.23660
Value Function Loss: 0.00411

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.57701
Value Function Update Magnitude: 0.62634

Collected Steps per Second: 22,693.50553
Overall Steps per Second: 10,535.59974

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.54376
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.74809

Cumulative Model Updates: 130,518
Cumulative Timesteps: 1,088,590,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1088590794...
Checkpoint 1088590794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.45225
Policy Entropy: 3.22852
Value Function Loss: 0.00408

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.57308
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 22,082.14845
Overall Steps per Second: 10,581.00811

Timestep Collection Time: 2.26500
Timestep Consumption Time: 2.46196
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.72696

Cumulative Model Updates: 130,524
Cumulative Timesteps: 1,088,640,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.99370
Policy Entropy: 3.23616
Value Function Loss: 0.00421

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.56800
Value Function Update Magnitude: 0.59253

Collected Steps per Second: 22,545.98182
Overall Steps per Second: 10,503.45464

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.54306
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.76110

Cumulative Model Updates: 130,530
Cumulative Timesteps: 1,088,690,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1088690818...
Checkpoint 1088690818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.20696
Policy Entropy: 3.22433
Value Function Loss: 0.00441

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.57567

Collected Steps per Second: 21,712.35797
Overall Steps per Second: 10,295.34519

Timestep Collection Time: 2.30339
Timestep Consumption Time: 2.55434
PPO Batch Consumption Time: 0.30137
Total Iteration Time: 4.85773

Cumulative Model Updates: 130,536
Cumulative Timesteps: 1,088,740,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,028.01084
Policy Entropy: 3.22313
Value Function Loss: 0.00428

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.55814

Collected Steps per Second: 22,397.37764
Overall Steps per Second: 10,300.51774

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.62183
PPO Batch Consumption Time: 0.31111
Total Iteration Time: 4.85432

Cumulative Model Updates: 130,542
Cumulative Timesteps: 1,088,790,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1088790832...
Checkpoint 1088790832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.73740
Policy Entropy: 3.23684
Value Function Loss: 0.00407

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.54224
Value Function Update Magnitude: 0.52672

Collected Steps per Second: 20,575.98020
Overall Steps per Second: 10,220.65237

Timestep Collection Time: 2.43128
Timestep Consumption Time: 2.46332
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.89460

Cumulative Model Updates: 130,548
Cumulative Timesteps: 1,088,840,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.70457
Policy Entropy: 3.24123
Value Function Loss: 0.00387

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.52861

Collected Steps per Second: 22,078.78838
Overall Steps per Second: 10,393.39745

Timestep Collection Time: 2.26534
Timestep Consumption Time: 2.54694
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.81229

Cumulative Model Updates: 130,554
Cumulative Timesteps: 1,088,890,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1088890874...
Checkpoint 1088890874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.60113
Policy Entropy: 3.23455
Value Function Loss: 0.00392

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.54271

Collected Steps per Second: 22,404.88273
Overall Steps per Second: 10,487.55712

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.53651
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.76870

Cumulative Model Updates: 130,560
Cumulative Timesteps: 1,088,940,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.17196
Policy Entropy: 3.22653
Value Function Loss: 0.00400

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.55047

Collected Steps per Second: 22,468.54040
Overall Steps per Second: 10,643.84109

Timestep Collection Time: 2.22605
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.69906

Cumulative Model Updates: 130,566
Cumulative Timesteps: 1,088,990,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1088990902...
Checkpoint 1088990902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.04920
Policy Entropy: 3.21407
Value Function Loss: 0.00407

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.55186

Collected Steps per Second: 20,154.09939
Overall Steps per Second: 9,956.65526

Timestep Collection Time: 2.48128
Timestep Consumption Time: 2.54129
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 5.02257

Cumulative Model Updates: 130,572
Cumulative Timesteps: 1,089,040,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.67686
Policy Entropy: 3.21470
Value Function Loss: 0.00404

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.57087
Value Function Update Magnitude: 0.54468

Collected Steps per Second: 21,190.38489
Overall Steps per Second: 10,316.95890

Timestep Collection Time: 2.36079
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.84891

Cumulative Model Updates: 130,578
Cumulative Timesteps: 1,089,090,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1089090936...
Checkpoint 1089090936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.44060
Policy Entropy: 3.21368
Value Function Loss: 0.00399

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.57278
Value Function Update Magnitude: 0.55469

Collected Steps per Second: 20,872.34364
Overall Steps per Second: 10,072.72119

Timestep Collection Time: 2.39686
Timestep Consumption Time: 2.56983
PPO Batch Consumption Time: 0.30085
Total Iteration Time: 4.96668

Cumulative Model Updates: 130,584
Cumulative Timesteps: 1,089,140,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.07021
Policy Entropy: 3.22251
Value Function Loss: 0.00424

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.57655
Value Function Update Magnitude: 0.55769

Collected Steps per Second: 22,986.67735
Overall Steps per Second: 10,697.06354

Timestep Collection Time: 2.17639
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.67680

Cumulative Model Updates: 130,590
Cumulative Timesteps: 1,089,190,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1089190992...
Checkpoint 1089190992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.95412
Policy Entropy: 3.22337
Value Function Loss: 0.00421

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.57366
Value Function Update Magnitude: 0.54557

Collected Steps per Second: 21,528.29729
Overall Steps per Second: 10,102.84656

Timestep Collection Time: 2.32280
Timestep Consumption Time: 2.62689
PPO Batch Consumption Time: 0.31377
Total Iteration Time: 4.94969

Cumulative Model Updates: 130,596
Cumulative Timesteps: 1,089,240,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.96075
Policy Entropy: 3.23228
Value Function Loss: 0.00415

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.57078
Value Function Update Magnitude: 0.53837

Collected Steps per Second: 22,228.49328
Overall Steps per Second: 10,445.86631

Timestep Collection Time: 2.25161
Timestep Consumption Time: 2.53975
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.79137

Cumulative Model Updates: 130,602
Cumulative Timesteps: 1,089,291,048

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1089291048...
Checkpoint 1089291048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.31104
Policy Entropy: 3.22976
Value Function Loss: 0.00398

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.56394
Value Function Update Magnitude: 0.53707

Collected Steps per Second: 21,536.13805
Overall Steps per Second: 10,214.35966

Timestep Collection Time: 2.32316
Timestep Consumption Time: 2.57504
PPO Batch Consumption Time: 0.30377
Total Iteration Time: 4.89820

Cumulative Model Updates: 130,608
Cumulative Timesteps: 1,089,341,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790.84937
Policy Entropy: 3.21762
Value Function Loss: 0.00440

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.58012
Value Function Update Magnitude: 0.56976

Collected Steps per Second: 22,549.14841
Overall Steps per Second: 10,603.82167

Timestep Collection Time: 2.21809
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.71679

Cumulative Model Updates: 130,614
Cumulative Timesteps: 1,089,391,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1089391096...
Checkpoint 1089391096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.66752
Policy Entropy: 3.20691
Value Function Loss: 0.00455

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.60093
Value Function Update Magnitude: 0.60515

Collected Steps per Second: 21,822.69901
Overall Steps per Second: 10,514.76195

Timestep Collection Time: 2.29330
Timestep Consumption Time: 2.46629
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.75959

Cumulative Model Updates: 130,620
Cumulative Timesteps: 1,089,441,142

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.54935
Policy Entropy: 3.19208
Value Function Loss: 0.00452

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.59712
Value Function Update Magnitude: 0.60377

Collected Steps per Second: 22,405.20448
Overall Steps per Second: 10,527.45903

Timestep Collection Time: 2.23278
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.75195

Cumulative Model Updates: 130,626
Cumulative Timesteps: 1,089,491,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1089491168...
Checkpoint 1089491168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.67615
Policy Entropy: 3.21587
Value Function Loss: 0.00433

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.58225

Collected Steps per Second: 20,590.26779
Overall Steps per Second: 9,910.35928

Timestep Collection Time: 2.42979
Timestep Consumption Time: 2.61846
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 5.04825

Cumulative Model Updates: 130,632
Cumulative Timesteps: 1,089,541,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.93816
Policy Entropy: 3.23587
Value Function Loss: 0.00396

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.56809

Collected Steps per Second: 22,000.71069
Overall Steps per Second: 10,382.36752

Timestep Collection Time: 2.27329
Timestep Consumption Time: 2.54392
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.81721

Cumulative Model Updates: 130,638
Cumulative Timesteps: 1,089,591,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1089591212...
Checkpoint 1089591212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.74580
Policy Entropy: 3.24180
Value Function Loss: 0.00396

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10800
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.57248

Collected Steps per Second: 22,255.37975
Overall Steps per Second: 10,646.37229

Timestep Collection Time: 2.24692
Timestep Consumption Time: 2.45008
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.69700

Cumulative Model Updates: 130,644
Cumulative Timesteps: 1,089,641,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.99234
Policy Entropy: 3.23239
Value Function Loss: 0.00381

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.56959

Collected Steps per Second: 22,484.72228
Overall Steps per Second: 10,421.35486

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.57524
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.79995

Cumulative Model Updates: 130,650
Cumulative Timesteps: 1,089,691,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1089691240...
Checkpoint 1089691240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.15838
Policy Entropy: 3.23264
Value Function Loss: 0.00359

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.53095

Collected Steps per Second: 22,567.60537
Overall Steps per Second: 10,700.62298

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.67468

Cumulative Model Updates: 130,656
Cumulative Timesteps: 1,089,741,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.51285
Policy Entropy: 3.24593
Value Function Loss: 0.00367

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.51724

Collected Steps per Second: 22,231.79046
Overall Steps per Second: 10,401.11423

Timestep Collection Time: 2.24957
Timestep Consumption Time: 2.55876
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.80833

Cumulative Model Updates: 130,662
Cumulative Timesteps: 1,089,791,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1089791274...
Checkpoint 1089791274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.02350
Policy Entropy: 3.24225
Value Function Loss: 0.00375

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.54432

Collected Steps per Second: 22,284.78000
Overall Steps per Second: 10,608.16970

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.46986
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.71373

Cumulative Model Updates: 130,668
Cumulative Timesteps: 1,089,841,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.87258
Policy Entropy: 3.23456
Value Function Loss: 0.00425

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.57288
Value Function Update Magnitude: 0.53903

Collected Steps per Second: 21,949.93185
Overall Steps per Second: 10,500.25658

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.48388
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.76179

Cumulative Model Updates: 130,674
Cumulative Timesteps: 1,089,891,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1089891278...
Checkpoint 1089891278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.20482
Policy Entropy: 3.21011
Value Function Loss: 0.00444

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.57579
Value Function Update Magnitude: 0.54706

Collected Steps per Second: 22,520.07391
Overall Steps per Second: 10,621.31665

Timestep Collection Time: 2.22042
Timestep Consumption Time: 2.48747
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.70789

Cumulative Model Updates: 130,680
Cumulative Timesteps: 1,089,941,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.30819
Policy Entropy: 3.21672
Value Function Loss: 0.00405

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.57224
Value Function Update Magnitude: 0.53325

Collected Steps per Second: 21,853.69871
Overall Steps per Second: 10,477.28363

Timestep Collection Time: 2.28886
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.77414

Cumulative Model Updates: 130,686
Cumulative Timesteps: 1,089,991,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1089991302...
Checkpoint 1089991302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.08769
Policy Entropy: 3.20831
Value Function Loss: 0.00415

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.52288

Collected Steps per Second: 22,461.47653
Overall Steps per Second: 10,625.26321

Timestep Collection Time: 2.22639
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.70652

Cumulative Model Updates: 130,692
Cumulative Timesteps: 1,090,041,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.24308
Policy Entropy: 3.20380
Value Function Loss: 0.00412

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.53146

Collected Steps per Second: 22,343.25576
Overall Steps per Second: 10,450.04460

Timestep Collection Time: 2.23898
Timestep Consumption Time: 2.54818
PPO Batch Consumption Time: 0.30072
Total Iteration Time: 4.78716

Cumulative Model Updates: 130,698
Cumulative Timesteps: 1,090,091,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1090091336...
Checkpoint 1090091336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.59785
Policy Entropy: 3.20817
Value Function Loss: 0.00423

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.54680

Collected Steps per Second: 22,049.06870
Overall Steps per Second: 10,548.13250

Timestep Collection Time: 2.26803
Timestep Consumption Time: 2.47290
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.74093

Cumulative Model Updates: 130,704
Cumulative Timesteps: 1,090,141,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.31503
Policy Entropy: 3.21979
Value Function Loss: 0.00413

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.57762
Value Function Update Magnitude: 0.55492

Collected Steps per Second: 22,051.41276
Overall Steps per Second: 10,345.81723

Timestep Collection Time: 2.26806
Timestep Consumption Time: 2.56616
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.83422

Cumulative Model Updates: 130,710
Cumulative Timesteps: 1,090,191,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1090191358...
Checkpoint 1090191358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.19469
Policy Entropy: 3.23140
Value Function Loss: 0.00413

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.57020
Value Function Update Magnitude: 0.54824

Collected Steps per Second: 22,627.46906
Overall Steps per Second: 10,534.55772

Timestep Collection Time: 2.21050
Timestep Consumption Time: 2.53749
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.74799

Cumulative Model Updates: 130,716
Cumulative Timesteps: 1,090,241,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.20488
Policy Entropy: 3.21233
Value Function Loss: 0.00367

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.56486
Value Function Update Magnitude: 0.53954

Collected Steps per Second: 22,553.65729
Overall Steps per Second: 10,467.85496

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.55980
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 4.77691

Cumulative Model Updates: 130,722
Cumulative Timesteps: 1,090,291,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1090291380...
Checkpoint 1090291380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826.97368
Policy Entropy: 3.22032
Value Function Loss: 0.00369

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.56329
Value Function Update Magnitude: 0.54003

Collected Steps per Second: 22,652.04812
Overall Steps per Second: 10,508.13911

Timestep Collection Time: 2.20757
Timestep Consumption Time: 2.55122
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.75879

Cumulative Model Updates: 130,728
Cumulative Timesteps: 1,090,341,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.22719
Policy Entropy: 3.22536
Value Function Loss: 0.00367

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.54727

Collected Steps per Second: 22,173.06991
Overall Steps per Second: 10,468.34006

Timestep Collection Time: 2.25562
Timestep Consumption Time: 2.52202
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.77764

Cumulative Model Updates: 130,734
Cumulative Timesteps: 1,090,391,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1090391400...
Checkpoint 1090391400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.04197
Policy Entropy: 3.22158
Value Function Loss: 0.00374

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.53950

Collected Steps per Second: 22,436.41588
Overall Steps per Second: 10,626.72682

Timestep Collection Time: 2.22932
Timestep Consumption Time: 2.47749
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.70681

Cumulative Model Updates: 130,740
Cumulative Timesteps: 1,090,441,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.63511
Policy Entropy: 3.20285
Value Function Loss: 0.00363

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.52703

Collected Steps per Second: 22,279.06435
Overall Steps per Second: 10,496.46442

Timestep Collection Time: 2.24462
Timestep Consumption Time: 2.51965
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.76427

Cumulative Model Updates: 130,746
Cumulative Timesteps: 1,090,491,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1090491426...
Checkpoint 1090491426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.87741
Policy Entropy: 3.19699
Value Function Loss: 0.00386

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.53800

Collected Steps per Second: 22,454.75468
Overall Steps per Second: 10,550.65716

Timestep Collection Time: 2.22670
Timestep Consumption Time: 2.51234
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.73904

Cumulative Model Updates: 130,752
Cumulative Timesteps: 1,090,541,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,248.72559
Policy Entropy: 3.20145
Value Function Loss: 0.00388

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.55978

Collected Steps per Second: 22,369.45068
Overall Steps per Second: 10,511.93489

Timestep Collection Time: 2.23600
Timestep Consumption Time: 2.52221
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.75821

Cumulative Model Updates: 130,758
Cumulative Timesteps: 1,090,591,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1090591444...
Checkpoint 1090591444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.76234
Policy Entropy: 3.20132
Value Function Loss: 0.00413

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.56487

Collected Steps per Second: 22,480.63695
Overall Steps per Second: 10,645.81707

Timestep Collection Time: 2.22431
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69706

Cumulative Model Updates: 130,764
Cumulative Timesteps: 1,090,641,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.26733
Policy Entropy: 3.20329
Value Function Loss: 0.00432

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.58332
Value Function Update Magnitude: 0.57347

Collected Steps per Second: 22,798.38795
Overall Steps per Second: 10,568.35668

Timestep Collection Time: 2.19410
Timestep Consumption Time: 2.53908
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.73319

Cumulative Model Updates: 130,770
Cumulative Timesteps: 1,090,691,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1090691470...
Checkpoint 1090691470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.74506
Policy Entropy: 3.20598
Value Function Loss: 0.00413

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.58136
Value Function Update Magnitude: 0.56893

Collected Steps per Second: 22,434.87385
Overall Steps per Second: 10,468.21852

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.54789
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.77674

Cumulative Model Updates: 130,776
Cumulative Timesteps: 1,090,741,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.56679
Policy Entropy: 3.21515
Value Function Loss: 0.00407

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.53996

Collected Steps per Second: 21,228.86273
Overall Steps per Second: 10,366.32133

Timestep Collection Time: 2.35557
Timestep Consumption Time: 2.46832
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.82389

Cumulative Model Updates: 130,782
Cumulative Timesteps: 1,090,791,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1090791480...
Checkpoint 1090791480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.12155
Policy Entropy: 3.21033
Value Function Loss: 0.00385

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.56618
Value Function Update Magnitude: 0.53714

Collected Steps per Second: 21,914.48594
Overall Steps per Second: 10,237.03996

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.60419
PPO Batch Consumption Time: 0.30862
Total Iteration Time: 4.88715

Cumulative Model Updates: 130,788
Cumulative Timesteps: 1,090,841,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.91780
Policy Entropy: 3.19576
Value Function Loss: 0.00379

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.57049
Value Function Update Magnitude: 0.55734

Collected Steps per Second: 22,148.88671
Overall Steps per Second: 10,400.70329

Timestep Collection Time: 2.25772
Timestep Consumption Time: 2.55022
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.80794

Cumulative Model Updates: 130,794
Cumulative Timesteps: 1,090,891,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1090891516...
Checkpoint 1090891516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.05191
Policy Entropy: 3.20308
Value Function Loss: 0.00361

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.56874
Value Function Update Magnitude: 0.55973

Collected Steps per Second: 22,730.26207
Overall Steps per Second: 10,667.37925

Timestep Collection Time: 2.20024
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.68831

Cumulative Model Updates: 130,800
Cumulative Timesteps: 1,090,941,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,058.74991
Policy Entropy: 3.19755
Value Function Loss: 0.00366

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.57100
Value Function Update Magnitude: 0.52977

Collected Steps per Second: 22,768.32415
Overall Steps per Second: 10,584.41435

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.52890
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.72582

Cumulative Model Updates: 130,806
Cumulative Timesteps: 1,090,991,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1090991548...
Checkpoint 1090991548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.35738
Policy Entropy: 3.20776
Value Function Loss: 0.00370

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.52926

Collected Steps per Second: 22,379.40072
Overall Steps per Second: 10,593.80020

Timestep Collection Time: 2.23545
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.72238

Cumulative Model Updates: 130,812
Cumulative Timesteps: 1,091,041,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.36720
Policy Entropy: 3.19399
Value Function Loss: 0.00403

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.55479

Collected Steps per Second: 22,472.79432
Overall Steps per Second: 10,521.37767

Timestep Collection Time: 2.22634
Timestep Consumption Time: 2.52893
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75527

Cumulative Model Updates: 130,818
Cumulative Timesteps: 1,091,091,608

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1091091608...
Checkpoint 1091091608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.32107
Policy Entropy: 3.18916
Value Function Loss: 0.00409

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.57384
Value Function Update Magnitude: 0.56571

Collected Steps per Second: 22,076.80755
Overall Steps per Second: 10,494.22745

Timestep Collection Time: 2.26500
Timestep Consumption Time: 2.49990
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.76491

Cumulative Model Updates: 130,824
Cumulative Timesteps: 1,091,141,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.12420
Policy Entropy: 3.19337
Value Function Loss: 0.00420

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.55079

Collected Steps per Second: 22,632.29134
Overall Steps per Second: 10,491.21201

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.55727
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.76704

Cumulative Model Updates: 130,830
Cumulative Timesteps: 1,091,191,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1091191624...
Checkpoint 1091191624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.52361
Policy Entropy: 3.20348
Value Function Loss: 0.00393

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.56567
Value Function Update Magnitude: 0.54206

Collected Steps per Second: 20,716.82295
Overall Steps per Second: 10,167.74502

Timestep Collection Time: 2.41379
Timestep Consumption Time: 2.50431
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.91810

Cumulative Model Updates: 130,836
Cumulative Timesteps: 1,091,241,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,427.69611
Policy Entropy: 3.21297
Value Function Loss: 0.00389

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.54240

Collected Steps per Second: 23,059.44608
Overall Steps per Second: 10,465.53378

Timestep Collection Time: 2.16883
Timestep Consumption Time: 2.60990
PPO Batch Consumption Time: 0.30393
Total Iteration Time: 4.77873

Cumulative Model Updates: 130,842
Cumulative Timesteps: 1,091,291,642

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1091291642...
Checkpoint 1091291642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,799.13427
Policy Entropy: 3.20621
Value Function Loss: 0.00394

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.55766
Value Function Update Magnitude: 0.55075

Collected Steps per Second: 21,829.42731
Overall Steps per Second: 10,382.57862

Timestep Collection Time: 2.29186
Timestep Consumption Time: 2.52679
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.81865

Cumulative Model Updates: 130,848
Cumulative Timesteps: 1,091,341,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,215.56650
Policy Entropy: 3.20257
Value Function Loss: 0.00393

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.55874

Collected Steps per Second: 22,232.43255
Overall Steps per Second: 10,459.53394

Timestep Collection Time: 2.25023
Timestep Consumption Time: 2.53278
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.78300

Cumulative Model Updates: 130,854
Cumulative Timesteps: 1,091,391,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1091391700...
Checkpoint 1091391700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.17119
Policy Entropy: 3.20384
Value Function Loss: 0.00393

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.55504
Value Function Update Magnitude: 0.55259

Collected Steps per Second: 21,314.53738
Overall Steps per Second: 10,279.88613

Timestep Collection Time: 2.34666
Timestep Consumption Time: 2.51896
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.86562

Cumulative Model Updates: 130,860
Cumulative Timesteps: 1,091,441,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494.86018
Policy Entropy: 3.20060
Value Function Loss: 0.00402

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.56084
Value Function Update Magnitude: 0.55331

Collected Steps per Second: 22,442.54060
Overall Steps per Second: 10,440.95629

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.56307
PPO Batch Consumption Time: 0.30464
Total Iteration Time: 4.79286

Cumulative Model Updates: 130,866
Cumulative Timesteps: 1,091,491,760

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1091491760...
Checkpoint 1091491760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.69302
Policy Entropy: 3.19036
Value Function Loss: 0.00421

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.57367
Value Function Update Magnitude: 0.55753

Collected Steps per Second: 22,164.88018
Overall Steps per Second: 10,593.47280

Timestep Collection Time: 2.25609
Timestep Consumption Time: 2.46436
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.72045

Cumulative Model Updates: 130,872
Cumulative Timesteps: 1,091,541,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.30707
Policy Entropy: 3.19823
Value Function Loss: 0.00413

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.58195
Value Function Update Magnitude: 0.59240

Collected Steps per Second: 22,417.49611
Overall Steps per Second: 10,530.05722

Timestep Collection Time: 2.23183
Timestep Consumption Time: 2.51952
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.75135

Cumulative Model Updates: 130,878
Cumulative Timesteps: 1,091,591,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1091591798...
Checkpoint 1091591798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.40998
Policy Entropy: 3.20558
Value Function Loss: 0.00415

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.57905
Value Function Update Magnitude: 0.57998

Collected Steps per Second: 19,668.00749
Overall Steps per Second: 9,671.33979

Timestep Collection Time: 2.54271
Timestep Consumption Time: 2.62824
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 5.17095

Cumulative Model Updates: 130,884
Cumulative Timesteps: 1,091,641,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.53637
Policy Entropy: 3.21944
Value Function Loss: 0.00393

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.57610

Collected Steps per Second: 21,323.60606
Overall Steps per Second: 10,280.98100

Timestep Collection Time: 2.34557
Timestep Consumption Time: 2.51934
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.86491

Cumulative Model Updates: 130,890
Cumulative Timesteps: 1,091,691,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1091691824...
Checkpoint 1091691824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988.99197
Policy Entropy: 3.23425
Value Function Loss: 0.00394

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.57190

Collected Steps per Second: 22,142.63609
Overall Steps per Second: 10,443.92879

Timestep Collection Time: 2.25863
Timestep Consumption Time: 2.52999
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.78862

Cumulative Model Updates: 130,896
Cumulative Timesteps: 1,091,741,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.10015
Policy Entropy: 3.23094
Value Function Loss: 0.00383

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.55943

Collected Steps per Second: 22,448.68948
Overall Steps per Second: 10,497.22647

Timestep Collection Time: 2.22855
Timestep Consumption Time: 2.53728
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.76583

Cumulative Model Updates: 130,902
Cumulative Timesteps: 1,091,791,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1091791864...
Checkpoint 1091791864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.18035
Policy Entropy: 3.21861
Value Function Loss: 0.00386

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.54207

Collected Steps per Second: 22,377.63264
Overall Steps per Second: 10,671.32341

Timestep Collection Time: 2.23500
Timestep Consumption Time: 2.45177
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.68677

Cumulative Model Updates: 130,908
Cumulative Timesteps: 1,091,841,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.50015
Policy Entropy: 3.22026
Value Function Loss: 0.00361

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.51636

Collected Steps per Second: 22,555.37389
Overall Steps per Second: 10,554.36228

Timestep Collection Time: 2.21774
Timestep Consumption Time: 2.52172
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.73946

Cumulative Model Updates: 130,914
Cumulative Timesteps: 1,091,891,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1091891900...
Checkpoint 1091891900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.96904
Policy Entropy: 3.20401
Value Function Loss: 0.00393

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.54873
Value Function Update Magnitude: 0.52246

Collected Steps per Second: 22,411.19163
Overall Steps per Second: 10,496.26825

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.53287
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.76417

Cumulative Model Updates: 130,920
Cumulative Timesteps: 1,091,941,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.18763
Policy Entropy: 3.20950
Value Function Loss: 0.00405

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.56048
Value Function Update Magnitude: 0.52357

Collected Steps per Second: 22,358.02793
Overall Steps per Second: 10,362.59208

Timestep Collection Time: 2.23651
Timestep Consumption Time: 2.58892
PPO Batch Consumption Time: 0.30803
Total Iteration Time: 4.82543

Cumulative Model Updates: 130,926
Cumulative Timesteps: 1,091,991,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1091991910...
Checkpoint 1091991910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.33205
Policy Entropy: 3.19912
Value Function Loss: 0.00427

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.56848
Value Function Update Magnitude: 0.53404

Collected Steps per Second: 21,236.22131
Overall Steps per Second: 10,334.77015

Timestep Collection Time: 2.35550
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.84017

Cumulative Model Updates: 130,932
Cumulative Timesteps: 1,092,041,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.77691
Policy Entropy: 3.20409
Value Function Loss: 0.00421

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.56979
Value Function Update Magnitude: 0.52275

Collected Steps per Second: 22,601.51778
Overall Steps per Second: 10,605.34905

Timestep Collection Time: 2.21233
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.71479

Cumulative Model Updates: 130,938
Cumulative Timesteps: 1,092,091,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1092091934...
Checkpoint 1092091934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.98527
Policy Entropy: 3.19898
Value Function Loss: 0.00414

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.50916

Collected Steps per Second: 21,683.62446
Overall Steps per Second: 10,261.69624

Timestep Collection Time: 2.30598
Timestep Consumption Time: 2.56670
PPO Batch Consumption Time: 0.30157
Total Iteration Time: 4.87268

Cumulative Model Updates: 130,944
Cumulative Timesteps: 1,092,141,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.97480
Policy Entropy: 3.19506
Value Function Loss: 0.00428

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.52701

Collected Steps per Second: 22,853.90621
Overall Steps per Second: 10,670.28487

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.68741

Cumulative Model Updates: 130,950
Cumulative Timesteps: 1,092,191,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1092191952...
Checkpoint 1092191952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.15753
Policy Entropy: 3.21018
Value Function Loss: 0.00426

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.56306
Value Function Update Magnitude: 0.54242

Collected Steps per Second: 22,090.14643
Overall Steps per Second: 10,597.24308

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.45623
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.72104

Cumulative Model Updates: 130,956
Cumulative Timesteps: 1,092,241,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.26766
Policy Entropy: 3.21016
Value Function Loss: 0.00398

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.55668
Value Function Update Magnitude: 0.53782

Collected Steps per Second: 20,355.26203
Overall Steps per Second: 9,932.17126

Timestep Collection Time: 2.45745
Timestep Consumption Time: 2.57891
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 5.03636

Cumulative Model Updates: 130,962
Cumulative Timesteps: 1,092,292,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1092292004...
Checkpoint 1092292004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.70363
Policy Entropy: 3.20252
Value Function Loss: 0.00429

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.55562
Value Function Update Magnitude: 0.53388

Collected Steps per Second: 21,790.59959
Overall Steps per Second: 10,382.46234

Timestep Collection Time: 2.29576
Timestep Consumption Time: 2.52256
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.81832

Cumulative Model Updates: 130,968
Cumulative Timesteps: 1,092,342,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,926.68910
Policy Entropy: 3.19404
Value Function Loss: 0.00401

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.52651

Collected Steps per Second: 21,171.22984
Overall Steps per Second: 10,312.99326

Timestep Collection Time: 2.36311
Timestep Consumption Time: 2.48805
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.85116

Cumulative Model Updates: 130,974
Cumulative Timesteps: 1,092,392,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1092392060...
Checkpoint 1092392060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.24568
Policy Entropy: 3.18386
Value Function Loss: 0.00417

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.51350

Collected Steps per Second: 22,354.58158
Overall Steps per Second: 10,605.43582

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.71607

Cumulative Model Updates: 130,980
Cumulative Timesteps: 1,092,442,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,324.58471
Policy Entropy: 3.17763
Value Function Loss: 0.00429

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.57023
Value Function Update Magnitude: 0.52991

Collected Steps per Second: 21,238.68250
Overall Steps per Second: 10,263.42223

Timestep Collection Time: 2.35476
Timestep Consumption Time: 2.51808
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.87284

Cumulative Model Updates: 130,986
Cumulative Timesteps: 1,092,492,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1092492088...
Checkpoint 1092492088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.07658
Policy Entropy: 3.17438
Value Function Loss: 0.00407

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.56537

Collected Steps per Second: 22,373.40146
Overall Steps per Second: 10,545.47752

Timestep Collection Time: 2.23515
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.74213

Cumulative Model Updates: 130,992
Cumulative Timesteps: 1,092,542,096

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.03616
Policy Entropy: 3.18923
Value Function Loss: 0.00440

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.57889
Value Function Update Magnitude: 0.57566

Collected Steps per Second: 22,458.90991
Overall Steps per Second: 10,320.20845

Timestep Collection Time: 2.22762
Timestep Consumption Time: 2.62015
PPO Batch Consumption Time: 0.30325
Total Iteration Time: 4.84777

Cumulative Model Updates: 130,998
Cumulative Timesteps: 1,092,592,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1092592126...
Checkpoint 1092592126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.59170
Policy Entropy: 3.21179
Value Function Loss: 0.00435

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.56438

Collected Steps per Second: 21,148.43074
Overall Steps per Second: 9,993.12046

Timestep Collection Time: 2.36490
Timestep Consumption Time: 2.63994
PPO Batch Consumption Time: 0.30636
Total Iteration Time: 5.00484

Cumulative Model Updates: 131,004
Cumulative Timesteps: 1,092,642,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.35054
Policy Entropy: 3.20749
Value Function Loss: 0.00437

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.58072
Value Function Update Magnitude: 0.56477

Collected Steps per Second: 22,798.20896
Overall Steps per Second: 10,704.08506

Timestep Collection Time: 2.19403
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.67298

Cumulative Model Updates: 131,010
Cumulative Timesteps: 1,092,692,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1092692160...
Checkpoint 1092692160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.21470
Policy Entropy: 3.19351
Value Function Loss: 0.00429

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.57254
Value Function Update Magnitude: 0.53839

Collected Steps per Second: 22,540.03411
Overall Steps per Second: 10,679.22469

Timestep Collection Time: 2.21925
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.68405

Cumulative Model Updates: 131,016
Cumulative Timesteps: 1,092,742,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.85979
Policy Entropy: 3.18078
Value Function Loss: 0.00452

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.53948

Collected Steps per Second: 22,487.26733
Overall Steps per Second: 10,403.96582

Timestep Collection Time: 2.22375
Timestep Consumption Time: 2.58269
PPO Batch Consumption Time: 0.30595
Total Iteration Time: 4.80644

Cumulative Model Updates: 131,022
Cumulative Timesteps: 1,092,792,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1092792188...
Checkpoint 1092792188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,035.87328
Policy Entropy: 3.18651
Value Function Loss: 0.00423

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.57471
Value Function Update Magnitude: 0.53653

Collected Steps per Second: 22,498.13276
Overall Steps per Second: 10,713.78040

Timestep Collection Time: 2.22374
Timestep Consumption Time: 2.44595
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.66969

Cumulative Model Updates: 131,028
Cumulative Timesteps: 1,092,842,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.38270
Policy Entropy: 3.18830
Value Function Loss: 0.00408

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.57314
Value Function Update Magnitude: 0.53437

Collected Steps per Second: 22,595.93539
Overall Steps per Second: 10,519.56375

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.54158
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.75552

Cumulative Model Updates: 131,034
Cumulative Timesteps: 1,092,892,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1092892244...
Checkpoint 1092892244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.54382
Policy Entropy: 3.19051
Value Function Loss: 0.00381

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.54626

Collected Steps per Second: 22,631.54870
Overall Steps per Second: 10,661.59480

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.48142
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.69161

Cumulative Model Updates: 131,040
Cumulative Timesteps: 1,092,942,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.64475
Policy Entropy: 3.17984
Value Function Loss: 0.00395

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.56646
Value Function Update Magnitude: 0.54711

Collected Steps per Second: 21,718.29820
Overall Steps per Second: 9,943.88289

Timestep Collection Time: 2.30350
Timestep Consumption Time: 2.72754
PPO Batch Consumption Time: 0.31965
Total Iteration Time: 5.03103

Cumulative Model Updates: 131,046
Cumulative Timesteps: 1,092,992,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1092992292...
Checkpoint 1092992292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.54588
Policy Entropy: 3.16938
Value Function Loss: 0.00389

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.53679

Collected Steps per Second: 21,344.42481
Overall Steps per Second: 10,291.97608

Timestep Collection Time: 2.34347
Timestep Consumption Time: 2.51663
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.86010

Cumulative Model Updates: 131,052
Cumulative Timesteps: 1,093,042,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.88010
Policy Entropy: 3.18165
Value Function Loss: 0.00413

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.54143

Collected Steps per Second: 21,847.30393
Overall Steps per Second: 10,499.36111

Timestep Collection Time: 2.28880
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.76258

Cumulative Model Updates: 131,058
Cumulative Timesteps: 1,093,092,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1093092316...
Checkpoint 1093092316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.60786
Policy Entropy: 3.18735
Value Function Loss: 0.00399

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.57771
Value Function Update Magnitude: 0.55020

Collected Steps per Second: 22,052.32413
Overall Steps per Second: 10,546.57136

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.74126

Cumulative Model Updates: 131,064
Cumulative Timesteps: 1,093,142,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.87191
Policy Entropy: 3.18696
Value Function Loss: 0.00431

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.58466
Value Function Update Magnitude: 0.56544

Collected Steps per Second: 22,482.97849
Overall Steps per Second: 10,547.98252

Timestep Collection Time: 2.22417
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.74081

Cumulative Model Updates: 131,070
Cumulative Timesteps: 1,093,192,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1093192326...
Checkpoint 1093192326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.47277
Policy Entropy: 3.18994
Value Function Loss: 0.00391

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.58461
Value Function Update Magnitude: 0.55641

Collected Steps per Second: 21,848.01729
Overall Steps per Second: 10,502.74159

Timestep Collection Time: 2.28945
Timestep Consumption Time: 2.47311
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.76257

Cumulative Model Updates: 131,076
Cumulative Timesteps: 1,093,242,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.72046
Policy Entropy: 3.19289
Value Function Loss: 0.00422

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.55617

Collected Steps per Second: 22,270.94551
Overall Steps per Second: 10,610.94444

Timestep Collection Time: 2.24624
Timestep Consumption Time: 2.46832
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.71457

Cumulative Model Updates: 131,082
Cumulative Timesteps: 1,093,292,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1093292372...
Checkpoint 1093292372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.20154
Policy Entropy: 3.19773
Value Function Loss: 0.00415

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.58352
Value Function Update Magnitude: 0.58017

Collected Steps per Second: 22,225.54682
Overall Steps per Second: 10,687.86953

Timestep Collection Time: 2.25056
Timestep Consumption Time: 2.42951
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.68007

Cumulative Model Updates: 131,088
Cumulative Timesteps: 1,093,342,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.34312
Policy Entropy: 3.19700
Value Function Loss: 0.00415

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.56042

Collected Steps per Second: 22,514.31422
Overall Steps per Second: 10,559.20724

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.51480
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.73596

Cumulative Model Updates: 131,094
Cumulative Timesteps: 1,093,392,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1093392400...
Checkpoint 1093392400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.58316
Policy Entropy: 3.19491
Value Function Loss: 0.00406

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.53023

Collected Steps per Second: 22,505.49142
Overall Steps per Second: 10,408.00113

Timestep Collection Time: 2.22301
Timestep Consumption Time: 2.58387
PPO Batch Consumption Time: 0.31044
Total Iteration Time: 4.80688

Cumulative Model Updates: 131,100
Cumulative Timesteps: 1,093,442,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.65411
Policy Entropy: 3.18823
Value Function Loss: 0.00432

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.56970
Value Function Update Magnitude: 0.50952

Collected Steps per Second: 22,275.77500
Overall Steps per Second: 10,516.44910

Timestep Collection Time: 2.24468
Timestep Consumption Time: 2.50997
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75465

Cumulative Model Updates: 131,106
Cumulative Timesteps: 1,093,492,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1093492432...
Checkpoint 1093492432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.66615
Policy Entropy: 3.18788
Value Function Loss: 0.00424

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.57850
Value Function Update Magnitude: 0.54185

Collected Steps per Second: 22,180.27738
Overall Steps per Second: 10,633.42503

Timestep Collection Time: 2.25561
Timestep Consumption Time: 2.44937
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.70498

Cumulative Model Updates: 131,112
Cumulative Timesteps: 1,093,542,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.38436
Policy Entropy: 3.19994
Value Function Loss: 0.00425

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.57898
Value Function Update Magnitude: 0.55601

Collected Steps per Second: 22,362.90850
Overall Steps per Second: 10,504.41408

Timestep Collection Time: 2.23710
Timestep Consumption Time: 2.52547
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.76257

Cumulative Model Updates: 131,118
Cumulative Timesteps: 1,093,592,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1093592490...
Checkpoint 1093592490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.23141
Policy Entropy: 3.21608
Value Function Loss: 0.00407

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.57112
Value Function Update Magnitude: 0.54043

Collected Steps per Second: 22,238.64458
Overall Steps per Second: 10,564.96859

Timestep Collection Time: 2.24951
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.73508

Cumulative Model Updates: 131,124
Cumulative Timesteps: 1,093,642,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.43752
Policy Entropy: 3.21694
Value Function Loss: 0.00428

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.51949

Collected Steps per Second: 22,535.41990
Overall Steps per Second: 10,480.07049

Timestep Collection Time: 2.21971
Timestep Consumption Time: 2.55335
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.77306

Cumulative Model Updates: 131,130
Cumulative Timesteps: 1,093,692,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1093692538...
Checkpoint 1093692538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.14645
Policy Entropy: 3.21030
Value Function Loss: 0.00423

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.58391
Value Function Update Magnitude: 0.52287

Collected Steps per Second: 22,261.71332
Overall Steps per Second: 10,549.45344

Timestep Collection Time: 2.24619
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.73996

Cumulative Model Updates: 131,136
Cumulative Timesteps: 1,093,742,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,931.72322
Policy Entropy: 3.20560
Value Function Loss: 0.00417

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.58600
Value Function Update Magnitude: 0.55048

Collected Steps per Second: 22,529.49031
Overall Steps per Second: 10,550.09120

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.52149
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.74214

Cumulative Model Updates: 131,142
Cumulative Timesteps: 1,093,792,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1093792572...
Checkpoint 1093792572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.52745
Policy Entropy: 3.20682
Value Function Loss: 0.00382

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.58220
Value Function Update Magnitude: 0.55391

Collected Steps per Second: 22,123.94078
Overall Steps per Second: 10,548.57103

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.48098
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.74187

Cumulative Model Updates: 131,148
Cumulative Timesteps: 1,093,842,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.09418
Policy Entropy: 3.21240
Value Function Loss: 0.00385

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.53405

Collected Steps per Second: 22,359.83165
Overall Steps per Second: 10,562.13301

Timestep Collection Time: 2.23714
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.73598

Cumulative Model Updates: 131,154
Cumulative Timesteps: 1,093,892,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1093892614...
Checkpoint 1093892614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.80351
Policy Entropy: 3.21056
Value Function Loss: 0.00385

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.55673
Value Function Update Magnitude: 0.52771

Collected Steps per Second: 22,183.02047
Overall Steps per Second: 10,681.73737

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.68313

Cumulative Model Updates: 131,160
Cumulative Timesteps: 1,093,942,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.44574
Policy Entropy: 3.20000
Value Function Loss: 0.00374

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.52822

Collected Steps per Second: 22,504.20779
Overall Steps per Second: 10,536.01885

Timestep Collection Time: 2.22314
Timestep Consumption Time: 2.52533
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.74847

Cumulative Model Updates: 131,166
Cumulative Timesteps: 1,093,992,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1093992668...
Checkpoint 1093992668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.00701
Policy Entropy: 3.19104
Value Function Loss: 0.00385

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.53824

Collected Steps per Second: 22,805.15960
Overall Steps per Second: 10,584.77517

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.53128
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.72377

Cumulative Model Updates: 131,172
Cumulative Timesteps: 1,094,042,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.58373
Policy Entropy: 3.18587
Value Function Loss: 0.00418

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.58178
Value Function Update Magnitude: 0.54588

Collected Steps per Second: 22,033.96939
Overall Steps per Second: 10,399.05025

Timestep Collection Time: 2.26995
Timestep Consumption Time: 2.53972
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 4.80967

Cumulative Model Updates: 131,178
Cumulative Timesteps: 1,094,092,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1094092684...
Checkpoint 1094092684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,978.09910
Policy Entropy: 3.19007
Value Function Loss: 0.00419

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.58116
Value Function Update Magnitude: 0.53442

Collected Steps per Second: 22,374.11440
Overall Steps per Second: 10,666.77543

Timestep Collection Time: 2.23490
Timestep Consumption Time: 2.45292
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.68783

Cumulative Model Updates: 131,184
Cumulative Timesteps: 1,094,142,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.37857
Policy Entropy: 3.20579
Value Function Loss: 0.00452

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.58232
Value Function Update Magnitude: 0.53955

Collected Steps per Second: 22,129.23521
Overall Steps per Second: 10,448.99947

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.52660
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.78687

Cumulative Model Updates: 131,190
Cumulative Timesteps: 1,094,192,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1094192706...
Checkpoint 1094192706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.54683
Policy Entropy: 3.20778
Value Function Loss: 0.00437

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.55282

Collected Steps per Second: 22,555.94227
Overall Steps per Second: 10,619.93161

Timestep Collection Time: 2.21689
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.70850

Cumulative Model Updates: 131,196
Cumulative Timesteps: 1,094,242,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.50441
Policy Entropy: 3.20912
Value Function Loss: 0.00426

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.57173
Value Function Update Magnitude: 0.54805

Collected Steps per Second: 22,478.44628
Overall Steps per Second: 10,523.77623

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.75134

Cumulative Model Updates: 131,202
Cumulative Timesteps: 1,094,292,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1094292712...
Checkpoint 1094292712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,669.04230
Policy Entropy: 3.19476
Value Function Loss: 0.00425

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.52480

Collected Steps per Second: 22,124.53964
Overall Steps per Second: 10,627.02327

Timestep Collection Time: 2.26093
Timestep Consumption Time: 2.44613
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.70706

Cumulative Model Updates: 131,208
Cumulative Timesteps: 1,094,342,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.71724
Policy Entropy: 3.18807
Value Function Loss: 0.00411

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.53209

Collected Steps per Second: 22,763.72752
Overall Steps per Second: 10,723.91439

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.46679
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.66397

Cumulative Model Updates: 131,214
Cumulative Timesteps: 1,094,392,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1094392750...
Checkpoint 1094392750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.04417
Policy Entropy: 3.19691
Value Function Loss: 0.00398

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 22,474.18279
Overall Steps per Second: 10,504.51646

Timestep Collection Time: 2.22575
Timestep Consumption Time: 2.53620
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.76195

Cumulative Model Updates: 131,220
Cumulative Timesteps: 1,094,442,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.42042
Policy Entropy: 3.18735
Value Function Loss: 0.00378

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.56244

Collected Steps per Second: 22,150.13815
Overall Steps per Second: 10,411.08530

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.54617
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 4.80430

Cumulative Model Updates: 131,226
Cumulative Timesteps: 1,094,492,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1094492790...
Checkpoint 1094492790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,228.52663
Policy Entropy: 3.19093
Value Function Loss: 0.00403

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.58578
Value Function Update Magnitude: 0.56198

Collected Steps per Second: 22,109.09153
Overall Steps per Second: 10,517.42625

Timestep Collection Time: 2.26242
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.75592

Cumulative Model Updates: 131,232
Cumulative Timesteps: 1,094,542,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.74801
Policy Entropy: 3.18922
Value Function Loss: 0.00415

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.58971
Value Function Update Magnitude: 0.57930

Collected Steps per Second: 22,094.01443
Overall Steps per Second: 10,449.54057

Timestep Collection Time: 2.26441
Timestep Consumption Time: 2.52336
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.78777

Cumulative Model Updates: 131,238
Cumulative Timesteps: 1,094,592,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1094592840...
Checkpoint 1094592840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.15821
Policy Entropy: 3.20890
Value Function Loss: 0.00422

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.57279

Collected Steps per Second: 22,719.06387
Overall Steps per Second: 10,666.56860

Timestep Collection Time: 2.20106
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.68811

Cumulative Model Updates: 131,244
Cumulative Timesteps: 1,094,642,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.53196
Policy Entropy: 3.19137
Value Function Loss: 0.00412

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.56488
Value Function Update Magnitude: 0.57835

Collected Steps per Second: 22,493.53540
Overall Steps per Second: 10,481.66187

Timestep Collection Time: 2.22357
Timestep Consumption Time: 2.54819
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.77176

Cumulative Model Updates: 131,250
Cumulative Timesteps: 1,094,692,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1094692862...
Checkpoint 1094692862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,778.57207
Policy Entropy: 3.18327
Value Function Loss: 0.00435

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.57508
Value Function Update Magnitude: 0.58807

Collected Steps per Second: 22,453.34561
Overall Steps per Second: 10,544.52507

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.51586
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.74350

Cumulative Model Updates: 131,256
Cumulative Timesteps: 1,094,742,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.72638
Policy Entropy: 3.16868
Value Function Loss: 0.00408

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.56133

Collected Steps per Second: 22,643.88215
Overall Steps per Second: 10,449.95341

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.57774
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.78682

Cumulative Model Updates: 131,262
Cumulative Timesteps: 1,094,792,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1094792902...
Checkpoint 1094792902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.21008
Policy Entropy: 3.18087
Value Function Loss: 0.00418

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.59256
Value Function Update Magnitude: 0.55560

Collected Steps per Second: 22,129.01260
Overall Steps per Second: 10,430.75437

Timestep Collection Time: 2.26002
Timestep Consumption Time: 2.53465
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.79467

Cumulative Model Updates: 131,268
Cumulative Timesteps: 1,094,842,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.30399
Policy Entropy: 3.19518
Value Function Loss: 0.00404

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.59770
Value Function Update Magnitude: 0.55633

Collected Steps per Second: 22,364.46395
Overall Steps per Second: 10,589.60561

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.48692
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.72350

Cumulative Model Updates: 131,274
Cumulative Timesteps: 1,094,892,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1094892934...
Checkpoint 1094892934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.51473
Policy Entropy: 3.20380
Value Function Loss: 0.00382

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.59218
Value Function Update Magnitude: 0.54370

Collected Steps per Second: 22,270.42083
Overall Steps per Second: 10,503.55780

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.51607
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.76201

Cumulative Model Updates: 131,280
Cumulative Timesteps: 1,094,942,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,183.05272
Policy Entropy: 3.21310
Value Function Loss: 0.00364

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.57537
Value Function Update Magnitude: 0.51632

Collected Steps per Second: 22,654.76380
Overall Steps per Second: 10,620.33488

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.50161
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.70927

Cumulative Model Updates: 131,286
Cumulative Timesteps: 1,094,992,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1094992966...
Checkpoint 1094992966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.24558
Policy Entropy: 3.20773
Value Function Loss: 0.00400

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.57771
Value Function Update Magnitude: 0.49551

Collected Steps per Second: 22,176.54501
Overall Steps per Second: 10,641.54768

Timestep Collection Time: 2.25490
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.69913

Cumulative Model Updates: 131,292
Cumulative Timesteps: 1,095,042,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.12941
Policy Entropy: 3.19625
Value Function Loss: 0.00423

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.58686
Value Function Update Magnitude: 0.52653

Collected Steps per Second: 22,394.71008
Overall Steps per Second: 10,553.71341

Timestep Collection Time: 2.23374
Timestep Consumption Time: 2.50620
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.73994

Cumulative Model Updates: 131,298
Cumulative Timesteps: 1,095,092,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1095092996...
Checkpoint 1095092996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.60128
Policy Entropy: 3.18893
Value Function Loss: 0.00435

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.59329
Value Function Update Magnitude: 0.55100

Collected Steps per Second: 22,338.08572
Overall Steps per Second: 10,429.53980

Timestep Collection Time: 2.23949
Timestep Consumption Time: 2.55707
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.79657

Cumulative Model Updates: 131,304
Cumulative Timesteps: 1,095,143,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.95837
Policy Entropy: 3.18316
Value Function Loss: 0.00422

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.58969
Value Function Update Magnitude: 0.55624

Collected Steps per Second: 22,297.41985
Overall Steps per Second: 10,697.96236

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.67472

Cumulative Model Updates: 131,310
Cumulative Timesteps: 1,095,193,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1095193032...
Checkpoint 1095193032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.01705
Policy Entropy: 3.17572
Value Function Loss: 0.00445

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.54536

Collected Steps per Second: 22,254.17348
Overall Steps per Second: 10,594.29402

Timestep Collection Time: 2.24794
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.72198

Cumulative Model Updates: 131,316
Cumulative Timesteps: 1,095,243,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.26609
Policy Entropy: 3.16504
Value Function Loss: 0.00441

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.59971
Value Function Update Magnitude: 0.53874

Collected Steps per Second: 22,485.43382
Overall Steps per Second: 10,573.51635

Timestep Collection Time: 2.22464
Timestep Consumption Time: 2.50624
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.73088

Cumulative Model Updates: 131,322
Cumulative Timesteps: 1,095,293,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1095293080...
Checkpoint 1095293080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.15193
Policy Entropy: 3.18058
Value Function Loss: 0.00436

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.59132
Value Function Update Magnitude: 0.52209

Collected Steps per Second: 22,363.40588
Overall Steps per Second: 10,524.36734

Timestep Collection Time: 2.23580
Timestep Consumption Time: 2.51508
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.75088

Cumulative Model Updates: 131,328
Cumulative Timesteps: 1,095,343,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.77775
Policy Entropy: 3.18275
Value Function Loss: 0.00446

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.59645
Value Function Update Magnitude: 0.54290

Collected Steps per Second: 22,898.83644
Overall Steps per Second: 10,674.82065

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.68411

Cumulative Model Updates: 131,334
Cumulative Timesteps: 1,095,393,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1095393082...
Checkpoint 1095393082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.47086
Policy Entropy: 3.18717
Value Function Loss: 0.00432

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.60198
Value Function Update Magnitude: 0.56643

Collected Steps per Second: 22,284.78324
Overall Steps per Second: 10,500.33216

Timestep Collection Time: 2.24467
Timestep Consumption Time: 2.51918
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.76385

Cumulative Model Updates: 131,340
Cumulative Timesteps: 1,095,443,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.28249
Policy Entropy: 3.18999
Value Function Loss: 0.00403

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.59542
Value Function Update Magnitude: 0.56761

Collected Steps per Second: 22,602.21467
Overall Steps per Second: 10,713.13114

Timestep Collection Time: 2.21217
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.66717

Cumulative Model Updates: 131,346
Cumulative Timesteps: 1,095,493,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1095493104...
Checkpoint 1095493104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.92988
Policy Entropy: 3.19158
Value Function Loss: 0.00357

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.52050

Collected Steps per Second: 21,920.88795
Overall Steps per Second: 10,477.26564

Timestep Collection Time: 2.28093
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.77224

Cumulative Model Updates: 131,352
Cumulative Timesteps: 1,095,543,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.23542
Policy Entropy: 3.20250
Value Function Loss: 0.00380

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.51006

Collected Steps per Second: 22,627.80946
Overall Steps per Second: 10,681.73795

Timestep Collection Time: 2.21011
Timestep Consumption Time: 2.47171
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.68182

Cumulative Model Updates: 131,358
Cumulative Timesteps: 1,095,593,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1095593114...
Checkpoint 1095593114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.38205
Policy Entropy: 3.20185
Value Function Loss: 0.00395

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.58119
Value Function Update Magnitude: 0.50939

Collected Steps per Second: 22,280.65561
Overall Steps per Second: 10,618.23834

Timestep Collection Time: 2.24419
Timestep Consumption Time: 2.46488
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.70907

Cumulative Model Updates: 131,364
Cumulative Timesteps: 1,095,643,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.90441
Policy Entropy: 3.18594
Value Function Loss: 0.00453

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.59555
Value Function Update Magnitude: 0.55297

Collected Steps per Second: 22,387.96983
Overall Steps per Second: 10,518.17127

Timestep Collection Time: 2.23361
Timestep Consumption Time: 2.52064
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.75425

Cumulative Model Updates: 131,370
Cumulative Timesteps: 1,095,693,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1095693122...
Checkpoint 1095693122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.41454
Policy Entropy: 3.17839
Value Function Loss: 0.00434

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.60542
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 22,431.83771
Overall Steps per Second: 10,649.65628

Timestep Collection Time: 2.23040
Timestep Consumption Time: 2.46759
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.69799

Cumulative Model Updates: 131,376
Cumulative Timesteps: 1,095,743,154

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.30252
Policy Entropy: 3.18727
Value Function Loss: 0.00412

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.59543
Value Function Update Magnitude: 0.57105

Collected Steps per Second: 22,437.75408
Overall Steps per Second: 10,391.51989

Timestep Collection Time: 2.22883
Timestep Consumption Time: 2.58375
PPO Batch Consumption Time: 0.30827
Total Iteration Time: 4.81258

Cumulative Model Updates: 131,382
Cumulative Timesteps: 1,095,793,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1095793164...
Checkpoint 1095793164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.39705
Policy Entropy: 3.18396
Value Function Loss: 0.00410

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.59636
Value Function Update Magnitude: 0.55209

Collected Steps per Second: 22,113.85070
Overall Steps per Second: 10,484.78660

Timestep Collection Time: 2.26193
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.77072

Cumulative Model Updates: 131,388
Cumulative Timesteps: 1,095,843,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.34777
Policy Entropy: 3.18409
Value Function Loss: 0.00428

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.59656
Value Function Update Magnitude: 0.55400

Collected Steps per Second: 22,818.57477
Overall Steps per Second: 10,690.92816

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.67911

Cumulative Model Updates: 131,394
Cumulative Timesteps: 1,095,893,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1095893208...
Checkpoint 1095893208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.60499
Policy Entropy: 3.17649
Value Function Loss: 0.00443

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.59367
Value Function Update Magnitude: 0.58283

Collected Steps per Second: 22,181.84330
Overall Steps per Second: 10,632.93205

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.70294

Cumulative Model Updates: 131,400
Cumulative Timesteps: 1,095,943,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.84841
Policy Entropy: 3.17754
Value Function Loss: 0.00435

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.58716
Value Function Update Magnitude: 0.56806

Collected Steps per Second: 22,759.66693
Overall Steps per Second: 10,614.14943

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.51543
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.71371

Cumulative Model Updates: 131,406
Cumulative Timesteps: 1,095,993,246

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1095993246...
Checkpoint 1095993246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895.13405
Policy Entropy: 3.17301
Value Function Loss: 0.00462

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.59689
Value Function Update Magnitude: 0.56738

Collected Steps per Second: 22,251.69918
Overall Steps per Second: 10,520.01077

Timestep Collection Time: 2.24801
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.75494

Cumulative Model Updates: 131,412
Cumulative Timesteps: 1,096,043,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.96244
Policy Entropy: 3.16719
Value Function Loss: 0.00458

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.60866
Value Function Update Magnitude: 0.58221

Collected Steps per Second: 22,250.47312
Overall Steps per Second: 10,447.09637

Timestep Collection Time: 2.24795
Timestep Consumption Time: 2.53979
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.78774

Cumulative Model Updates: 131,418
Cumulative Timesteps: 1,096,093,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1096093286...
Checkpoint 1096093286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.05126
Policy Entropy: 3.18987
Value Function Loss: 0.00438

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.60881
Value Function Update Magnitude: 0.58695

Collected Steps per Second: 22,572.58733
Overall Steps per Second: 10,603.98522

Timestep Collection Time: 2.21632
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.71785

Cumulative Model Updates: 131,424
Cumulative Timesteps: 1,096,143,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.47654
Policy Entropy: 3.19919
Value Function Loss: 0.00434

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.60030
Value Function Update Magnitude: 0.57970

Collected Steps per Second: 22,744.44446
Overall Steps per Second: 10,581.42007

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.52804
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.72734

Cumulative Model Updates: 131,430
Cumulative Timesteps: 1,096,193,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1096193336...
Checkpoint 1096193336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.36282
Policy Entropy: 3.18998
Value Function Loss: 0.00427

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.59071
Value Function Update Magnitude: 0.56900

Collected Steps per Second: 22,168.10619
Overall Steps per Second: 10,477.93307

Timestep Collection Time: 2.25676
Timestep Consumption Time: 2.51785
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.77461

Cumulative Model Updates: 131,436
Cumulative Timesteps: 1,096,243,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,976.61293
Policy Entropy: 3.18498
Value Function Loss: 0.00416

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.58126
Value Function Update Magnitude: 0.56662

Collected Steps per Second: 22,410.41311
Overall Steps per Second: 10,508.81746

Timestep Collection Time: 2.23236
Timestep Consumption Time: 2.52822
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.76057

Cumulative Model Updates: 131,442
Cumulative Timesteps: 1,096,293,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1096293392...
Checkpoint 1096293392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.77400
Policy Entropy: 3.19018
Value Function Loss: 0.00407

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.58429
Value Function Update Magnitude: 0.53851

Collected Steps per Second: 22,272.50431
Overall Steps per Second: 10,559.44207

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.73699

Cumulative Model Updates: 131,448
Cumulative Timesteps: 1,096,343,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.30184
Policy Entropy: 3.19799
Value Function Loss: 0.00457

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.59998
Value Function Update Magnitude: 0.55023

Collected Steps per Second: 22,518.35407
Overall Steps per Second: 10,525.36265

Timestep Collection Time: 2.22121
Timestep Consumption Time: 2.53093
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.75214

Cumulative Model Updates: 131,454
Cumulative Timesteps: 1,096,393,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1096393430...
Checkpoint 1096393430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,709.81221
Policy Entropy: 3.21236
Value Function Loss: 0.00419

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.60279
Value Function Update Magnitude: 0.55720

Collected Steps per Second: 22,172.04759
Overall Steps per Second: 10,412.82200

Timestep Collection Time: 2.25563
Timestep Consumption Time: 2.54729
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.80292

Cumulative Model Updates: 131,460
Cumulative Timesteps: 1,096,443,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.93241
Policy Entropy: 3.20784
Value Function Loss: 0.00426

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.59107
Value Function Update Magnitude: 0.54216

Collected Steps per Second: 22,826.91428
Overall Steps per Second: 10,551.75552

Timestep Collection Time: 2.19040
Timestep Consumption Time: 2.54815
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.73855

Cumulative Model Updates: 131,466
Cumulative Timesteps: 1,096,493,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1096493442...
Checkpoint 1096493442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.80234
Policy Entropy: 3.20757
Value Function Loss: 0.00423

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.54204

Collected Steps per Second: 22,348.62542
Overall Steps per Second: 10,495.38472

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.52743
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.76533

Cumulative Model Updates: 131,472
Cumulative Timesteps: 1,096,543,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.69208
Policy Entropy: 3.19059
Value Function Loss: 0.00457

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.59170
Value Function Update Magnitude: 0.57239

Collected Steps per Second: 22,677.72593
Overall Steps per Second: 10,728.80653

Timestep Collection Time: 2.20604
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.66296

Cumulative Model Updates: 131,478
Cumulative Timesteps: 1,096,593,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1096593484...
Checkpoint 1096593484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.00105
Policy Entropy: 3.18784
Value Function Loss: 0.00462

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.59643
Value Function Update Magnitude: 0.57510

Collected Steps per Second: 22,039.32199
Overall Steps per Second: 10,593.56225

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.45216
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.72174

Cumulative Model Updates: 131,484
Cumulative Timesteps: 1,096,643,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.08572
Policy Entropy: 3.17149
Value Function Loss: 0.00470

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.59317
Value Function Update Magnitude: 0.58135

Collected Steps per Second: 22,419.98881
Overall Steps per Second: 10,500.00423

Timestep Collection Time: 2.23069
Timestep Consumption Time: 2.53236
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.76305

Cumulative Model Updates: 131,490
Cumulative Timesteps: 1,096,693,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1096693516...
Checkpoint 1096693516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.24414
Policy Entropy: 3.17248
Value Function Loss: 0.00443

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.59607
Value Function Update Magnitude: 0.58160

Collected Steps per Second: 22,570.60853
Overall Steps per Second: 10,632.57756

Timestep Collection Time: 2.21562
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.70328

Cumulative Model Updates: 131,496
Cumulative Timesteps: 1,096,743,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.20299
Policy Entropy: 3.17664
Value Function Loss: 0.00447

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.60200
Value Function Update Magnitude: 0.56359

Collected Steps per Second: 22,206.13039
Overall Steps per Second: 10,434.19333

Timestep Collection Time: 2.25235
Timestep Consumption Time: 2.54112
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.79347

Cumulative Model Updates: 131,502
Cumulative Timesteps: 1,096,793,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1096793540...
Checkpoint 1096793540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.00261
Policy Entropy: 3.19146
Value Function Loss: 0.00395

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.59212
Value Function Update Magnitude: 0.55391

Collected Steps per Second: 22,227.37654
Overall Steps per Second: 10,521.20215

Timestep Collection Time: 2.25011
Timestep Consumption Time: 2.50353
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.75364

Cumulative Model Updates: 131,508
Cumulative Timesteps: 1,096,843,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.67597
Policy Entropy: 3.18587
Value Function Loss: 0.00391

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.58308
Value Function Update Magnitude: 0.52144

Collected Steps per Second: 22,489.16473
Overall Steps per Second: 10,669.25803

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.68880

Cumulative Model Updates: 131,514
Cumulative Timesteps: 1,096,893,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1096893580...
Checkpoint 1096893580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.46694
Policy Entropy: 3.19111
Value Function Loss: 0.00377

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.57425
Value Function Update Magnitude: 0.51653

Collected Steps per Second: 22,313.19225
Overall Steps per Second: 10,572.11027

Timestep Collection Time: 2.24181
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.73151

Cumulative Model Updates: 131,520
Cumulative Timesteps: 1,096,943,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.87285
Policy Entropy: 3.18911
Value Function Loss: 0.00422

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.56465

Collected Steps per Second: 22,716.08698
Overall Steps per Second: 10,613.72162

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.71126

Cumulative Model Updates: 131,526
Cumulative Timesteps: 1,096,993,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1096993606...
Checkpoint 1096993606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.79560
Policy Entropy: 3.19572
Value Function Loss: 0.00404

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.59196
Value Function Update Magnitude: 0.58676

Collected Steps per Second: 22,227.43222
Overall Steps per Second: 10,486.75306

Timestep Collection Time: 2.25037
Timestep Consumption Time: 2.51945
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.76983

Cumulative Model Updates: 131,532
Cumulative Timesteps: 1,097,043,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.54639
Policy Entropy: 3.18291
Value Function Loss: 0.00410

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.58494

Collected Steps per Second: 22,948.48871
Overall Steps per Second: 10,789.96438

Timestep Collection Time: 2.18062
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.63783

Cumulative Model Updates: 131,538
Cumulative Timesteps: 1,097,093,668

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1097093668...
Checkpoint 1097093668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.38641
Policy Entropy: 3.19206
Value Function Loss: 0.00378

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.57632
Value Function Update Magnitude: 0.57101

Collected Steps per Second: 21,919.26938
Overall Steps per Second: 10,380.58737

Timestep Collection Time: 2.28228
Timestep Consumption Time: 2.53690
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.81919

Cumulative Model Updates: 131,544
Cumulative Timesteps: 1,097,143,694

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.14792
Policy Entropy: 3.18907
Value Function Loss: 0.00404

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.53999

Collected Steps per Second: 22,397.70424
Overall Steps per Second: 10,488.76931

Timestep Collection Time: 2.23326
Timestep Consumption Time: 2.53565
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.76891

Cumulative Model Updates: 131,550
Cumulative Timesteps: 1,097,193,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1097193714...
Checkpoint 1097193714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,540.17194
Policy Entropy: 3.19987
Value Function Loss: 0.00392

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.57840
Value Function Update Magnitude: 0.53201

Collected Steps per Second: 22,177.88006
Overall Steps per Second: 10,576.46851

Timestep Collection Time: 2.25459
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.72767

Cumulative Model Updates: 131,556
Cumulative Timesteps: 1,097,243,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.73938
Policy Entropy: 3.19454
Value Function Loss: 0.00394

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.57980
Value Function Update Magnitude: 0.51952

Collected Steps per Second: 22,447.59306
Overall Steps per Second: 10,446.04159

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.55909
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.78650

Cumulative Model Updates: 131,562
Cumulative Timesteps: 1,097,293,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1097293716...
Checkpoint 1097293716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.95349
Policy Entropy: 3.19679
Value Function Loss: 0.00386

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.57646
Value Function Update Magnitude: 0.51221

Collected Steps per Second: 22,630.72466
Overall Steps per Second: 10,622.43740

Timestep Collection Time: 2.20947
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.70721

Cumulative Model Updates: 131,568
Cumulative Timesteps: 1,097,343,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.98682
Policy Entropy: 3.18548
Value Function Loss: 0.00390

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.57418
Value Function Update Magnitude: 0.51779

Collected Steps per Second: 22,649.13362
Overall Steps per Second: 10,598.51682

Timestep Collection Time: 2.20856
Timestep Consumption Time: 2.51116
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.71972

Cumulative Model Updates: 131,574
Cumulative Timesteps: 1,097,393,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1097393740...
Checkpoint 1097393740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.68574
Policy Entropy: 3.17887
Value Function Loss: 0.00422

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.57986
Value Function Update Magnitude: 0.53003

Collected Steps per Second: 22,650.24540
Overall Steps per Second: 10,555.51044

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.52958
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.73724

Cumulative Model Updates: 131,580
Cumulative Timesteps: 1,097,443,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.77169
Policy Entropy: 3.17315
Value Function Loss: 0.00441

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.60103
Value Function Update Magnitude: 0.57033

Collected Steps per Second: 22,630.94302
Overall Steps per Second: 10,655.16645

Timestep Collection Time: 2.21078
Timestep Consumption Time: 2.48478
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69556

Cumulative Model Updates: 131,586
Cumulative Timesteps: 1,097,493,776

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1097493776...
Checkpoint 1097493776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.01238
Policy Entropy: 3.17487
Value Function Loss: 0.00441

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.60237
Value Function Update Magnitude: 0.57745

Collected Steps per Second: 22,537.63903
Overall Steps per Second: 10,603.34361

Timestep Collection Time: 2.21940
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.71738

Cumulative Model Updates: 131,592
Cumulative Timesteps: 1,097,543,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.68878
Policy Entropy: 3.17581
Value Function Loss: 0.00454

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.60406
Value Function Update Magnitude: 0.56866

Collected Steps per Second: 22,708.69615
Overall Steps per Second: 10,717.53312

Timestep Collection Time: 2.20206
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.66581

Cumulative Model Updates: 131,598
Cumulative Timesteps: 1,097,593,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1097593802...
Checkpoint 1097593802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.08413
Policy Entropy: 3.17457
Value Function Loss: 0.00462

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.61026
Value Function Update Magnitude: 0.58506

Collected Steps per Second: 22,474.43058
Overall Steps per Second: 10,628.09888

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.70583

Cumulative Model Updates: 131,604
Cumulative Timesteps: 1,097,643,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.48963
Policy Entropy: 3.18223
Value Function Loss: 0.00424

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.60374
Value Function Update Magnitude: 0.59191

Collected Steps per Second: 22,791.98125
Overall Steps per Second: 10,627.56421

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.70701

Cumulative Model Updates: 131,610
Cumulative Timesteps: 1,097,693,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1097693840...
Checkpoint 1097693840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.90630
Policy Entropy: 3.19330
Value Function Loss: 0.00423

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.60358
Value Function Update Magnitude: 0.58527

Collected Steps per Second: 22,348.43668
Overall Steps per Second: 10,549.43835

Timestep Collection Time: 2.23792
Timestep Consumption Time: 2.50300
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.74092

Cumulative Model Updates: 131,616
Cumulative Timesteps: 1,097,743,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.51854
Policy Entropy: 3.18344
Value Function Loss: 0.00417

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.60768
Value Function Update Magnitude: 0.59481

Collected Steps per Second: 21,883.97364
Overall Steps per Second: 10,317.60043

Timestep Collection Time: 2.28597
Timestep Consumption Time: 2.56264
PPO Batch Consumption Time: 0.30567
Total Iteration Time: 4.84861

Cumulative Model Updates: 131,622
Cumulative Timesteps: 1,097,793,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1097793880...
Checkpoint 1097793880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.95053
Policy Entropy: 3.17060
Value Function Loss: 0.00445

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.61392
Value Function Update Magnitude: 0.60196

Collected Steps per Second: 22,281.51184
Overall Steps per Second: 10,617.26236

Timestep Collection Time: 2.24401
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.70931

Cumulative Model Updates: 131,628
Cumulative Timesteps: 1,097,843,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.40464
Policy Entropy: 3.16486
Value Function Loss: 0.00437

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.61557
Value Function Update Magnitude: 0.61872

Collected Steps per Second: 22,212.06930
Overall Steps per Second: 10,549.14377

Timestep Collection Time: 2.25157
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.74086

Cumulative Model Updates: 131,634
Cumulative Timesteps: 1,097,893,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1097893892...
Checkpoint 1097893892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.38844
Policy Entropy: 3.17165
Value Function Loss: 0.00446

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.62328
Value Function Update Magnitude: 0.61830

Collected Steps per Second: 22,703.67206
Overall Steps per Second: 10,619.28666

Timestep Collection Time: 2.20352
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.71105

Cumulative Model Updates: 131,640
Cumulative Timesteps: 1,097,943,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.50684
Policy Entropy: 3.18223
Value Function Loss: 0.00440

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.62101
Value Function Update Magnitude: 0.60975

Collected Steps per Second: 22,078.04780
Overall Steps per Second: 10,491.72575

Timestep Collection Time: 2.26533
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.76699

Cumulative Model Updates: 131,646
Cumulative Timesteps: 1,097,993,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1097993934...
Checkpoint 1097993934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.80460
Policy Entropy: 3.19464
Value Function Loss: 0.00426

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.60335
Value Function Update Magnitude: 0.59051

Collected Steps per Second: 22,412.78272
Overall Steps per Second: 10,581.33726

Timestep Collection Time: 2.23114
Timestep Consumption Time: 2.49473
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.72587

Cumulative Model Updates: 131,652
Cumulative Timesteps: 1,098,043,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.26653
Policy Entropy: 3.19917
Value Function Loss: 0.00440

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.59466
Value Function Update Magnitude: 0.56555

Collected Steps per Second: 22,572.32851
Overall Steps per Second: 10,530.30801

Timestep Collection Time: 2.21608
Timestep Consumption Time: 2.53421
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.75029

Cumulative Model Updates: 131,658
Cumulative Timesteps: 1,098,093,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1098093962...
Checkpoint 1098093962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.54708
Policy Entropy: 3.17997
Value Function Loss: 0.00426

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.59146
Value Function Update Magnitude: 0.55812

Collected Steps per Second: 22,337.63353
Overall Steps per Second: 10,595.92168

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.48161
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.72106

Cumulative Model Updates: 131,664
Cumulative Timesteps: 1,098,143,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.25314
Policy Entropy: 3.17105
Value Function Loss: 0.00413

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.59336
Value Function Update Magnitude: 0.57942

Collected Steps per Second: 22,435.55787
Overall Steps per Second: 10,488.47570

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.53955
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.76904

Cumulative Model Updates: 131,670
Cumulative Timesteps: 1,098,194,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1098194006...
Checkpoint 1098194006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.35961
Policy Entropy: 3.17530
Value Function Loss: 0.00430

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.60556
Value Function Update Magnitude: 0.59342

Collected Steps per Second: 22,378.49575
Overall Steps per Second: 10,653.74781

Timestep Collection Time: 2.23554
Timestep Consumption Time: 2.46027
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.69581

Cumulative Model Updates: 131,676
Cumulative Timesteps: 1,098,244,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.54632
Policy Entropy: 3.17793
Value Function Loss: 0.00424

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.60165
Value Function Update Magnitude: 0.59434

Collected Steps per Second: 22,436.34708
Overall Steps per Second: 10,509.52874

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.53038
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.76006

Cumulative Model Updates: 131,682
Cumulative Timesteps: 1,098,294,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1098294060...
Checkpoint 1098294060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.67539
Policy Entropy: 3.17402
Value Function Loss: 0.00454

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.58858
Value Function Update Magnitude: 0.56469

Collected Steps per Second: 22,769.23178
Overall Steps per Second: 10,638.38206

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.70071

Cumulative Model Updates: 131,688
Cumulative Timesteps: 1,098,344,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.79343
Policy Entropy: 3.17314
Value Function Loss: 0.00427

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.58902
Value Function Update Magnitude: 0.52065

Collected Steps per Second: 21,827.32989
Overall Steps per Second: 10,356.98045

Timestep Collection Time: 2.29199
Timestep Consumption Time: 2.53838
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.83037

Cumulative Model Updates: 131,694
Cumulative Timesteps: 1,098,394,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1098394096...
Checkpoint 1098394096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.20700
Policy Entropy: 3.17738
Value Function Loss: 0.00413

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.59423
Value Function Update Magnitude: 0.52891

Collected Steps per Second: 22,382.01020
Overall Steps per Second: 10,649.34998

Timestep Collection Time: 2.23492
Timestep Consumption Time: 2.46227
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.69719

Cumulative Model Updates: 131,700
Cumulative Timesteps: 1,098,444,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.69634
Policy Entropy: 3.19228
Value Function Loss: 0.00369

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.54881

Collected Steps per Second: 22,087.10953
Overall Steps per Second: 10,496.89574

Timestep Collection Time: 2.26458
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.76503

Cumulative Model Updates: 131,706
Cumulative Timesteps: 1,098,494,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1098494136...
Checkpoint 1098494136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.69121
Policy Entropy: 3.20144
Value Function Loss: 0.00371

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.58606
Value Function Update Magnitude: 0.54302

Collected Steps per Second: 22,609.64916
Overall Steps per Second: 10,640.72622

Timestep Collection Time: 2.21206
Timestep Consumption Time: 2.48818
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.70024

Cumulative Model Updates: 131,712
Cumulative Timesteps: 1,098,544,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202.54129
Policy Entropy: 3.21385
Value Function Loss: 0.00402

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.59514
Value Function Update Magnitude: 0.54545

Collected Steps per Second: 22,357.79885
Overall Steps per Second: 10,430.30815

Timestep Collection Time: 2.23832
Timestep Consumption Time: 2.55962
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.79794

Cumulative Model Updates: 131,718
Cumulative Timesteps: 1,098,594,194

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1098594194...
Checkpoint 1098594194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.43881
Policy Entropy: 3.21290
Value Function Loss: 0.00431

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.59783
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 22,433.07668
Overall Steps per Second: 10,590.27129

Timestep Collection Time: 2.22992
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.72358

Cumulative Model Updates: 131,724
Cumulative Timesteps: 1,098,644,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.16441
Policy Entropy: 3.21768
Value Function Loss: 0.00422

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.55261

Collected Steps per Second: 22,720.57907
Overall Steps per Second: 10,505.01867

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.56041
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.76230

Cumulative Model Updates: 131,730
Cumulative Timesteps: 1,098,694,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1098694246...
Checkpoint 1098694246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.21376
Policy Entropy: 3.20490
Value Function Loss: 0.00391

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.53760

Collected Steps per Second: 22,188.19590
Overall Steps per Second: 10,617.55111

Timestep Collection Time: 2.25381
Timestep Consumption Time: 2.45613
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.70994

Cumulative Model Updates: 131,736
Cumulative Timesteps: 1,098,744,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.84645
Policy Entropy: 3.20739
Value Function Loss: 0.00356

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.56144
Value Function Update Magnitude: 0.50817

Collected Steps per Second: 22,481.75638
Overall Steps per Second: 10,463.35983

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.55619
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.78164

Cumulative Model Updates: 131,742
Cumulative Timesteps: 1,098,794,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1098794286...
Checkpoint 1098794286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.47247
Policy Entropy: 3.20816
Value Function Loss: 0.00371

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.49955

Collected Steps per Second: 21,959.74261
Overall Steps per Second: 10,408.30314

Timestep Collection Time: 2.27771
Timestep Consumption Time: 2.52787
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.80559

Cumulative Model Updates: 131,748
Cumulative Timesteps: 1,098,844,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.42368
Policy Entropy: 3.21014
Value Function Loss: 0.00398

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.57528
Value Function Update Magnitude: 0.51586

Collected Steps per Second: 22,751.31214
Overall Steps per Second: 10,715.93873

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.66744

Cumulative Model Updates: 131,754
Cumulative Timesteps: 1,098,894,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1098894320...
Checkpoint 1098894320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.84846
Policy Entropy: 3.21031
Value Function Loss: 0.00442

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.59481
Value Function Update Magnitude: 0.53865

Collected Steps per Second: 22,042.15790
Overall Steps per Second: 10,521.20564

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.75421

Cumulative Model Updates: 131,760
Cumulative Timesteps: 1,098,944,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.23152
Policy Entropy: 3.20377
Value Function Loss: 0.00440

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.60480
Value Function Update Magnitude: 0.56509

Collected Steps per Second: 22,339.92412
Overall Steps per Second: 10,571.11366

Timestep Collection Time: 2.23859
Timestep Consumption Time: 2.49222
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.73082

Cumulative Model Updates: 131,766
Cumulative Timesteps: 1,098,994,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1098994350...
Checkpoint 1098994350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,945.98973
Policy Entropy: 3.21331
Value Function Loss: 0.00399

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.59749
Value Function Update Magnitude: 0.54320

Collected Steps per Second: 22,464.61345
Overall Steps per Second: 10,602.15798

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.71866

Cumulative Model Updates: 131,772
Cumulative Timesteps: 1,099,044,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.78778
Policy Entropy: 3.20288
Value Function Loss: 0.00395

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.58507
Value Function Update Magnitude: 0.53938

Collected Steps per Second: 22,257.81641
Overall Steps per Second: 10,498.29850

Timestep Collection Time: 2.24712
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.76420

Cumulative Model Updates: 131,778
Cumulative Timesteps: 1,099,094,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1099094394...
Checkpoint 1099094394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.82048
Policy Entropy: 3.19332
Value Function Loss: 0.00388

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.54167

Collected Steps per Second: 21,958.16680
Overall Steps per Second: 10,511.12373

Timestep Collection Time: 2.27715
Timestep Consumption Time: 2.47991
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.75706

Cumulative Model Updates: 131,784
Cumulative Timesteps: 1,099,144,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.27864
Policy Entropy: 3.18513
Value Function Loss: 0.00417

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.59830
Value Function Update Magnitude: 0.56977

Collected Steps per Second: 22,726.78332
Overall Steps per Second: 10,527.55983

Timestep Collection Time: 2.20119
Timestep Consumption Time: 2.55072
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.75191

Cumulative Model Updates: 131,790
Cumulative Timesteps: 1,099,194,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1099194422...
Checkpoint 1099194422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.89107
Policy Entropy: 3.18973
Value Function Loss: 0.00452

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.60997
Value Function Update Magnitude: 0.59971

Collected Steps per Second: 22,264.90644
Overall Steps per Second: 10,592.00462

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.47555
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.72186

Cumulative Model Updates: 131,796
Cumulative Timesteps: 1,099,244,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.03279
Policy Entropy: 3.20391
Value Function Loss: 0.00439

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.60433
Value Function Update Magnitude: 0.59397

Collected Steps per Second: 22,495.86098
Overall Steps per Second: 10,535.79947

Timestep Collection Time: 2.22281
Timestep Consumption Time: 2.52330
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.74610

Cumulative Model Updates: 131,802
Cumulative Timesteps: 1,099,294,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1099294440...
Checkpoint 1099294440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.36297
Policy Entropy: 3.20624
Value Function Loss: 0.00454

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.59302
Value Function Update Magnitude: 0.57699

Collected Steps per Second: 21,873.52264
Overall Steps per Second: 10,544.14623

Timestep Collection Time: 2.28596
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.74216

Cumulative Model Updates: 131,808
Cumulative Timesteps: 1,099,344,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,486.16650
Policy Entropy: 3.21128
Value Function Loss: 0.00439

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.60220
Value Function Update Magnitude: 0.55109

Collected Steps per Second: 22,559.39081
Overall Steps per Second: 10,507.37350

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.54311
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.76028

Cumulative Model Updates: 131,814
Cumulative Timesteps: 1,099,394,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1099394460...
Checkpoint 1099394460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.01785
Policy Entropy: 3.20982
Value Function Loss: 0.00479

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.60292
Value Function Update Magnitude: 0.56796

Collected Steps per Second: 22,021.12603
Overall Steps per Second: 10,579.64665

Timestep Collection Time: 2.27127
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.72757

Cumulative Model Updates: 131,820
Cumulative Timesteps: 1,099,444,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.20144
Policy Entropy: 3.21466
Value Function Loss: 0.00440

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.60271
Value Function Update Magnitude: 0.56869

Collected Steps per Second: 22,467.55418
Overall Steps per Second: 10,555.49333

Timestep Collection Time: 2.22659
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.73933

Cumulative Model Updates: 131,826
Cumulative Timesteps: 1,099,494,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1099494502...
Checkpoint 1099494502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.77257
Policy Entropy: 3.20063
Value Function Loss: 0.00473

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.60889
Value Function Update Magnitude: 0.57967

Collected Steps per Second: 22,440.22049
Overall Steps per Second: 10,668.63607

Timestep Collection Time: 2.22814
Timestep Consumption Time: 2.45849
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.68663

Cumulative Model Updates: 131,832
Cumulative Timesteps: 1,099,544,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.57547
Policy Entropy: 3.18949
Value Function Loss: 0.00472

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.61848
Value Function Update Magnitude: 0.58064

Collected Steps per Second: 22,683.54765
Overall Steps per Second: 10,656.61815

Timestep Collection Time: 2.20583
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.69530

Cumulative Model Updates: 131,838
Cumulative Timesteps: 1,099,594,538

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1099594538...
Checkpoint 1099594538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.86192
Policy Entropy: 3.19322
Value Function Loss: 0.00474

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.61590
Value Function Update Magnitude: 0.57912

Collected Steps per Second: 22,641.63827
Overall Steps per Second: 10,605.44645

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.71475

Cumulative Model Updates: 131,844
Cumulative Timesteps: 1,099,644,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.08298
Policy Entropy: 3.21753
Value Function Loss: 0.00430

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.60009
Value Function Update Magnitude: 0.58448

Collected Steps per Second: 22,845.00994
Overall Steps per Second: 10,755.82013

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.46067
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.64995

Cumulative Model Updates: 131,850
Cumulative Timesteps: 1,099,694,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1099694554...
Checkpoint 1099694554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.34183
Policy Entropy: 3.23079
Value Function Loss: 0.00420

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.58557
Value Function Update Magnitude: 0.57695

Collected Steps per Second: 22,315.53244
Overall Steps per Second: 10,515.13638

Timestep Collection Time: 2.24194
Timestep Consumption Time: 2.51597
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.75790

Cumulative Model Updates: 131,856
Cumulative Timesteps: 1,099,744,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.81751
Policy Entropy: 3.21332
Value Function Loss: 0.00444

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.58991
Value Function Update Magnitude: 0.56372

Collected Steps per Second: 22,597.01489
Overall Steps per Second: 10,531.36102

Timestep Collection Time: 2.21339
Timestep Consumption Time: 2.53585
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.74924

Cumulative Model Updates: 131,862
Cumulative Timesteps: 1,099,794,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1099794600...
Checkpoint 1099794600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.45006
Policy Entropy: 3.21162
Value Function Loss: 0.00535

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.60811
Value Function Update Magnitude: 0.58873

Collected Steps per Second: 22,293.53078
Overall Steps per Second: 10,630.76443

Timestep Collection Time: 2.24352
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.70484

Cumulative Model Updates: 131,868
Cumulative Timesteps: 1,099,844,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.22707
Policy Entropy: 3.20990
Value Function Loss: 0.00507

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.60382
Value Function Update Magnitude: 0.62244

Collected Steps per Second: 22,528.17474
Overall Steps per Second: 10,544.28940

Timestep Collection Time: 2.22069
Timestep Consumption Time: 2.52387
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.74456

Cumulative Model Updates: 131,874
Cumulative Timesteps: 1,099,894,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1099894644...
Checkpoint 1099894644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.98112
Policy Entropy: 3.22675
Value Function Loss: 0.00491

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.60636
Value Function Update Magnitude: 0.62958

Collected Steps per Second: 22,061.95655
Overall Steps per Second: 10,608.10677

Timestep Collection Time: 2.26689
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.71451

Cumulative Model Updates: 131,880
Cumulative Timesteps: 1,099,944,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.37596
Policy Entropy: 3.22862
Value Function Loss: 0.00441

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.60556
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 22,380.67705
Overall Steps per Second: 10,524.10737

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.51703
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.75119

Cumulative Model Updates: 131,886
Cumulative Timesteps: 1,099,994,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1099994658...
Checkpoint 1099994658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.72768
Policy Entropy: 3.21934
Value Function Loss: 0.00452

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.60110
Value Function Update Magnitude: 0.57249

Collected Steps per Second: 22,440.39573
Overall Steps per Second: 10,498.24965

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.53579
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.76498

Cumulative Model Updates: 131,892
Cumulative Timesteps: 1,100,044,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.84080
Policy Entropy: 3.20820
Value Function Loss: 0.00457

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.60374
Value Function Update Magnitude: 0.55675

Collected Steps per Second: 22,559.95183
Overall Steps per Second: 10,582.00879

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.50909
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.72576

Cumulative Model Updates: 131,898
Cumulative Timesteps: 1,100,094,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1100094690...
Checkpoint 1100094690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.74709
Policy Entropy: 3.18791
Value Function Loss: 0.00452

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.59878
Value Function Update Magnitude: 0.54959

Collected Steps per Second: 22,385.85539
Overall Steps per Second: 10,546.42911

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.74208

Cumulative Model Updates: 131,904
Cumulative Timesteps: 1,100,144,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.91869
Policy Entropy: 3.18458
Value Function Loss: 0.00445

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.58653
Value Function Update Magnitude: 0.53716

Collected Steps per Second: 22,132.69291
Overall Steps per Second: 10,468.50592

Timestep Collection Time: 2.26064
Timestep Consumption Time: 2.51884
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.77948

Cumulative Model Updates: 131,910
Cumulative Timesteps: 1,100,194,736

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1100194736...
Checkpoint 1100194736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,323.52991
Policy Entropy: 3.18367
Value Function Loss: 0.00435

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.57966
Value Function Update Magnitude: 0.50183

Collected Steps per Second: 22,258.13874
Overall Steps per Second: 10,629.31495

Timestep Collection Time: 2.24880
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.70905

Cumulative Model Updates: 131,916
Cumulative Timesteps: 1,100,244,790

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411.97801
Policy Entropy: 3.19801
Value Function Loss: 0.00416

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.57934
Value Function Update Magnitude: 0.50270

Collected Steps per Second: 22,665.46380
Overall Steps per Second: 10,559.72185

Timestep Collection Time: 2.20618
Timestep Consumption Time: 2.52918
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.73535

Cumulative Model Updates: 131,922
Cumulative Timesteps: 1,100,294,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1100294794...
Checkpoint 1100294794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.73510
Policy Entropy: 3.20760
Value Function Loss: 0.00411

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.58072
Value Function Update Magnitude: 0.53569

Collected Steps per Second: 21,927.87868
Overall Steps per Second: 10,565.90723

Timestep Collection Time: 2.28102
Timestep Consumption Time: 2.45288
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.73390

Cumulative Model Updates: 131,928
Cumulative Timesteps: 1,100,344,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,456.69064
Policy Entropy: 3.20458
Value Function Loss: 0.00421

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.58505
Value Function Update Magnitude: 0.55773

Collected Steps per Second: 22,693.11124
Overall Steps per Second: 10,429.94348

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.59182
PPO Batch Consumption Time: 0.30901
Total Iteration Time: 4.79619

Cumulative Model Updates: 131,934
Cumulative Timesteps: 1,100,394,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1100394836...
Checkpoint 1100394836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.61822
Policy Entropy: 3.18905
Value Function Loss: 0.00413

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.58228
Value Function Update Magnitude: 0.53990

Collected Steps per Second: 22,293.70657
Overall Steps per Second: 10,619.34904

Timestep Collection Time: 2.24422
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.71140

Cumulative Model Updates: 131,940
Cumulative Timesteps: 1,100,444,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.41202
Policy Entropy: 3.18984
Value Function Loss: 0.00445

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.58976
Value Function Update Magnitude: 0.52699

Collected Steps per Second: 22,480.40349
Overall Steps per Second: 10,515.46846

Timestep Collection Time: 2.22434
Timestep Consumption Time: 2.53094
PPO Batch Consumption Time: 0.30056
Total Iteration Time: 4.75528

Cumulative Model Updates: 131,946
Cumulative Timesteps: 1,100,494,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1100494872...
Checkpoint 1100494872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.35158
Policy Entropy: 3.19603
Value Function Loss: 0.00449

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.59331
Value Function Update Magnitude: 0.51555

Collected Steps per Second: 22,476.22873
Overall Steps per Second: 10,632.51245

Timestep Collection Time: 2.22502
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70350

Cumulative Model Updates: 131,952
Cumulative Timesteps: 1,100,544,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.93498
Policy Entropy: 3.20890
Value Function Loss: 0.00435

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.50729

Collected Steps per Second: 22,610.30413
Overall Steps per Second: 10,591.60509

Timestep Collection Time: 2.21165
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.72129

Cumulative Model Updates: 131,958
Cumulative Timesteps: 1,100,594,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1100594888...
Checkpoint 1100594888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.31644
Policy Entropy: 3.19765
Value Function Loss: 0.00396

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.57520
Value Function Update Magnitude: 0.50260

Collected Steps per Second: 22,510.14227
Overall Steps per Second: 10,453.55910

Timestep Collection Time: 2.22255
Timestep Consumption Time: 2.56338
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.78593

Cumulative Model Updates: 131,964
Cumulative Timesteps: 1,100,644,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.53603
Policy Entropy: 3.19782
Value Function Loss: 0.00379

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.56901
Value Function Update Magnitude: 0.51780

Collected Steps per Second: 22,648.15832
Overall Steps per Second: 10,526.15741

Timestep Collection Time: 2.20857
Timestep Consumption Time: 2.54340
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.75197

Cumulative Model Updates: 131,970
Cumulative Timesteps: 1,100,694,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1100694938...
Checkpoint 1100694938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.27593
Policy Entropy: 3.19528
Value Function Loss: 0.00416

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.55161

Collected Steps per Second: 22,277.66775
Overall Steps per Second: 10,538.87448

Timestep Collection Time: 2.24557
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.74681

Cumulative Model Updates: 131,976
Cumulative Timesteps: 1,100,744,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.07263
Policy Entropy: 3.18497
Value Function Loss: 0.00442

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.58179
Value Function Update Magnitude: 0.55632

Collected Steps per Second: 22,538.44370
Overall Steps per Second: 10,581.63496

Timestep Collection Time: 2.21941
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.72725

Cumulative Model Updates: 131,982
Cumulative Timesteps: 1,100,794,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1100794986...
Checkpoint 1100794986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.67983
Policy Entropy: 3.18716
Value Function Loss: 0.00453

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.59780
Value Function Update Magnitude: 0.54471

Collected Steps per Second: 21,793.47198
Overall Steps per Second: 10,465.50350

Timestep Collection Time: 2.29427
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.77760

Cumulative Model Updates: 131,988
Cumulative Timesteps: 1,100,844,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775.85606
Policy Entropy: 3.19146
Value Function Loss: 0.00440

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.60624
Value Function Update Magnitude: 0.54645

Collected Steps per Second: 22,904.28432
Overall Steps per Second: 10,590.90763

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.53854
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.72197

Cumulative Model Updates: 131,994
Cumulative Timesteps: 1,100,894,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1100894996...
Checkpoint 1100894996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.09647
Policy Entropy: 3.19904
Value Function Loss: 0.00431

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.59292
Value Function Update Magnitude: 0.55327

Collected Steps per Second: 22,228.04504
Overall Steps per Second: 10,608.18447

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.46433
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.71410

Cumulative Model Updates: 132,000
Cumulative Timesteps: 1,100,945,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302.06386
Policy Entropy: 3.20060
Value Function Loss: 0.00414

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.56452

Collected Steps per Second: 22,925.22707
Overall Steps per Second: 10,634.71535

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.52139
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.70309

Cumulative Model Updates: 132,006
Cumulative Timesteps: 1,100,995,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1100995020...
Checkpoint 1100995020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.72560
Policy Entropy: 3.20483
Value Function Loss: 0.00439

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.59065
Value Function Update Magnitude: 0.58000

Collected Steps per Second: 22,328.88403
Overall Steps per Second: 10,431.33895

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.55461
PPO Batch Consumption Time: 0.30628
Total Iteration Time: 4.79440

Cumulative Model Updates: 132,012
Cumulative Timesteps: 1,101,045,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.97205
Policy Entropy: 3.21516
Value Function Loss: 0.00424

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.59214
Value Function Update Magnitude: 0.57032

Collected Steps per Second: 22,602.99928
Overall Steps per Second: 10,426.86514

Timestep Collection Time: 2.21325
Timestep Consumption Time: 2.58455
PPO Batch Consumption Time: 0.30876
Total Iteration Time: 4.79780

Cumulative Model Updates: 132,018
Cumulative Timesteps: 1,101,095,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1101095058...
Checkpoint 1101095058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.98192
Policy Entropy: 3.21181
Value Function Loss: 0.00411

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.58293
Value Function Update Magnitude: 0.56083

Collected Steps per Second: 22,466.28351
Overall Steps per Second: 10,675.14647

Timestep Collection Time: 2.22698
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.68677

Cumulative Model Updates: 132,024
Cumulative Timesteps: 1,101,145,090

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.22676
Policy Entropy: 3.20615
Value Function Loss: 0.00426

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.58890
Value Function Update Magnitude: 0.56056

Collected Steps per Second: 22,364.14113
Overall Steps per Second: 10,541.38175

Timestep Collection Time: 2.23697
Timestep Consumption Time: 2.50889
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.74587

Cumulative Model Updates: 132,030
Cumulative Timesteps: 1,101,195,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1101195118...
Checkpoint 1101195118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.37685
Policy Entropy: 3.21558
Value Function Loss: 0.00403

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.59379
Value Function Update Magnitude: 0.59047

Collected Steps per Second: 22,526.69047
Overall Steps per Second: 10,615.36917

Timestep Collection Time: 2.21986
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.71072

Cumulative Model Updates: 132,036
Cumulative Timesteps: 1,101,245,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.64608
Policy Entropy: 3.21178
Value Function Loss: 0.00366

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.57910
Value Function Update Magnitude: 0.57393

Collected Steps per Second: 22,531.52295
Overall Steps per Second: 10,491.94220

Timestep Collection Time: 2.21911
Timestep Consumption Time: 2.54645
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.76556

Cumulative Model Updates: 132,042
Cumulative Timesteps: 1,101,295,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1101295124...
Checkpoint 1101295124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.58035
Policy Entropy: 3.21208
Value Function Loss: 0.00381

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08753
Policy Update Magnitude: 0.57193
Value Function Update Magnitude: 0.57820

Collected Steps per Second: 22,132.03860
Overall Steps per Second: 10,502.97758

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.50289
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.76341

Cumulative Model Updates: 132,048
Cumulative Timesteps: 1,101,345,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.58542
Policy Entropy: 3.20189
Value Function Loss: 0.00432

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.58759
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 22,601.81825
Overall Steps per Second: 10,534.37536

Timestep Collection Time: 2.21221
Timestep Consumption Time: 2.53415
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.74637

Cumulative Model Updates: 132,054
Cumulative Timesteps: 1,101,395,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1101395154...
Checkpoint 1101395154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611.58267
Policy Entropy: 3.20681
Value Function Loss: 0.00455

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.59321
Value Function Update Magnitude: 0.58416

Collected Steps per Second: 22,194.35160
Overall Steps per Second: 10,628.13705

Timestep Collection Time: 2.25391
Timestep Consumption Time: 2.45284
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.70675

Cumulative Model Updates: 132,060
Cumulative Timesteps: 1,101,445,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.89461
Policy Entropy: 3.20790
Value Function Loss: 0.00462

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.58673
Value Function Update Magnitude: 0.57757

Collected Steps per Second: 22,788.72459
Overall Steps per Second: 10,610.07125

Timestep Collection Time: 2.19407
Timestep Consumption Time: 2.51844
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.71250

Cumulative Model Updates: 132,066
Cumulative Timesteps: 1,101,495,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1101495178...
Checkpoint 1101495178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.64204
Policy Entropy: 3.19431
Value Function Loss: 0.00434

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.59420
Value Function Update Magnitude: 0.57949

Collected Steps per Second: 22,174.52217
Overall Steps per Second: 10,589.52656

Timestep Collection Time: 2.25511
Timestep Consumption Time: 2.46710
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.72221

Cumulative Model Updates: 132,072
Cumulative Timesteps: 1,101,545,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824.42806
Policy Entropy: 3.19190
Value Function Loss: 0.00428

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.59590
Value Function Update Magnitude: 0.56092

Collected Steps per Second: 22,121.17901
Overall Steps per Second: 10,416.13553

Timestep Collection Time: 2.26064
Timestep Consumption Time: 2.54037
PPO Batch Consumption Time: 0.30190
Total Iteration Time: 4.80101

Cumulative Model Updates: 132,078
Cumulative Timesteps: 1,101,595,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1101595192...
Checkpoint 1101595192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.34887
Policy Entropy: 3.19542
Value Function Loss: 0.00420

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.58724
Value Function Update Magnitude: 0.54633

Collected Steps per Second: 22,522.29229
Overall Steps per Second: 10,626.28043

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.48599
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.70663

Cumulative Model Updates: 132,084
Cumulative Timesteps: 1,101,645,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.46094
Policy Entropy: 3.19992
Value Function Loss: 0.00410

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.58435
Value Function Update Magnitude: 0.53772

Collected Steps per Second: 22,418.10053
Overall Steps per Second: 10,455.49318

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.55326
PPO Batch Consumption Time: 0.30197
Total Iteration Time: 4.78485

Cumulative Model Updates: 132,090
Cumulative Timesteps: 1,101,695,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1101695234...
Checkpoint 1101695234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,501.28927
Policy Entropy: 3.20672
Value Function Loss: 0.00384

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.52980

Collected Steps per Second: 22,266.28436
Overall Steps per Second: 10,518.15142

Timestep Collection Time: 2.24663
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.75597

Cumulative Model Updates: 132,096
Cumulative Timesteps: 1,101,745,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144.66258
Policy Entropy: 3.19884
Value Function Loss: 0.00399

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.58147
Value Function Update Magnitude: 0.52130

Collected Steps per Second: 22,554.32233
Overall Steps per Second: 10,626.44470

Timestep Collection Time: 2.21714
Timestep Consumption Time: 2.48867
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.70581

Cumulative Model Updates: 132,102
Cumulative Timesteps: 1,101,795,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1101795264...
Checkpoint 1101795264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.24373
Policy Entropy: 3.20057
Value Function Loss: 0.00413

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.52566

Collected Steps per Second: 22,413.61520
Overall Steps per Second: 10,602.90999

Timestep Collection Time: 2.23097
Timestep Consumption Time: 2.48510
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.71606

Cumulative Model Updates: 132,108
Cumulative Timesteps: 1,101,845,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.31675
Policy Entropy: 3.19374
Value Function Loss: 0.00444

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.59048
Value Function Update Magnitude: 0.54842

Collected Steps per Second: 22,195.62050
Overall Steps per Second: 10,479.90624

Timestep Collection Time: 2.25324
Timestep Consumption Time: 2.51894
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.77218

Cumulative Model Updates: 132,114
Cumulative Timesteps: 1,101,895,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1101895280...
Checkpoint 1101895280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.18881
Policy Entropy: 3.19763
Value Function Loss: 0.00429

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.59404
Value Function Update Magnitude: 0.56784

Collected Steps per Second: 22,508.59948
Overall Steps per Second: 10,627.32992

Timestep Collection Time: 2.22200
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.70617

Cumulative Model Updates: 132,120
Cumulative Timesteps: 1,101,945,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.50540
Policy Entropy: 3.20207
Value Function Loss: 0.00463

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 0.56512

Collected Steps per Second: 22,458.97734
Overall Steps per Second: 10,514.44967

Timestep Collection Time: 2.22673
Timestep Consumption Time: 2.52959
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.75631

Cumulative Model Updates: 132,126
Cumulative Timesteps: 1,101,995,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1101995304...
Checkpoint 1101995304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.89516
Policy Entropy: 3.20345
Value Function Loss: 0.00457

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.59184
Value Function Update Magnitude: 0.54939

Collected Steps per Second: 22,421.32865
Overall Steps per Second: 10,595.93355

Timestep Collection Time: 2.23055
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.71992

Cumulative Model Updates: 132,132
Cumulative Timesteps: 1,102,045,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.22091
Policy Entropy: 3.19812
Value Function Loss: 0.00436

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.51466

Collected Steps per Second: 22,651.92997
Overall Steps per Second: 10,590.31128

Timestep Collection Time: 2.20776
Timestep Consumption Time: 2.51448
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.72224

Cumulative Model Updates: 132,138
Cumulative Timesteps: 1,102,095,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1102095326...
Checkpoint 1102095326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.97549
Policy Entropy: 3.20377
Value Function Loss: 0.00435

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.57336
Value Function Update Magnitude: 0.50132

Collected Steps per Second: 22,618.19747
Overall Steps per Second: 10,531.65371

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.53739
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.74835

Cumulative Model Updates: 132,144
Cumulative Timesteps: 1,102,145,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.28496
Policy Entropy: 3.20450
Value Function Loss: 0.00414

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.54557

Collected Steps per Second: 22,557.60579
Overall Steps per Second: 10,445.68071

Timestep Collection Time: 2.21699
Timestep Consumption Time: 2.57063
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.78762

Cumulative Model Updates: 132,150
Cumulative Timesteps: 1,102,195,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1102195344...
Checkpoint 1102195344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.61581
Policy Entropy: 3.19265
Value Function Loss: 0.00425

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.58336
Value Function Update Magnitude: 0.56799

Collected Steps per Second: 22,756.67425
Overall Steps per Second: 10,607.45539

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.71517

Cumulative Model Updates: 132,156
Cumulative Timesteps: 1,102,245,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014.07958
Policy Entropy: 3.18322
Value Function Loss: 0.00417

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.58169
Value Function Update Magnitude: 0.54427

Collected Steps per Second: 22,436.63185
Overall Steps per Second: 10,536.56487

Timestep Collection Time: 2.22966
Timestep Consumption Time: 2.51819
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.74785

Cumulative Model Updates: 132,162
Cumulative Timesteps: 1,102,295,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1102295386...
Checkpoint 1102295386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.76922
Policy Entropy: 3.18673
Value Function Loss: 0.00451

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.59009
Value Function Update Magnitude: 0.54051

Collected Steps per Second: 22,462.52365
Overall Steps per Second: 10,571.16768

Timestep Collection Time: 2.22673
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.73155

Cumulative Model Updates: 132,168
Cumulative Timesteps: 1,102,345,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.34984
Policy Entropy: 3.18373
Value Function Loss: 0.00457

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.59499
Value Function Update Magnitude: 0.52500

Collected Steps per Second: 22,319.10564
Overall Steps per Second: 10,374.61801

Timestep Collection Time: 2.24086
Timestep Consumption Time: 2.57994
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 4.82080

Cumulative Model Updates: 132,174
Cumulative Timesteps: 1,102,395,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1102395418...
Checkpoint 1102395418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.31054
Policy Entropy: 3.18422
Value Function Loss: 0.00477

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.59093
Value Function Update Magnitude: 0.51787

Collected Steps per Second: 22,374.11139
Overall Steps per Second: 10,653.87259

Timestep Collection Time: 2.23490
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.69350

Cumulative Model Updates: 132,180
Cumulative Timesteps: 1,102,445,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.02364
Policy Entropy: 3.19697
Value Function Loss: 0.00476

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.58646
Value Function Update Magnitude: 0.52320

Collected Steps per Second: 22,600.70270
Overall Steps per Second: 10,532.48218

Timestep Collection Time: 2.21347
Timestep Consumption Time: 2.53622
PPO Batch Consumption Time: 0.30099
Total Iteration Time: 4.74969

Cumulative Model Updates: 132,186
Cumulative Timesteps: 1,102,495,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1102495448...
Checkpoint 1102495448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856.72570
Policy Entropy: 3.21029
Value Function Loss: 0.00437

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.58356
Value Function Update Magnitude: 0.53050

Collected Steps per Second: 22,542.81715
Overall Steps per Second: 10,640.38724

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69908

Cumulative Model Updates: 132,192
Cumulative Timesteps: 1,102,545,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.89824
Policy Entropy: 3.20708
Value Function Loss: 0.00403

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.57707
Value Function Update Magnitude: 0.51415

Collected Steps per Second: 22,656.23754
Overall Steps per Second: 10,612.93486

Timestep Collection Time: 2.20787
Timestep Consumption Time: 2.50544
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.71331

Cumulative Model Updates: 132,198
Cumulative Timesteps: 1,102,595,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1102595470...
Checkpoint 1102595470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.45846
Policy Entropy: 3.20304
Value Function Loss: 0.00414

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.57766
Value Function Update Magnitude: 0.51233

Collected Steps per Second: 22,325.65781
Overall Steps per Second: 10,503.92743

Timestep Collection Time: 2.23993
Timestep Consumption Time: 2.52095
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.76089

Cumulative Model Updates: 132,204
Cumulative Timesteps: 1,102,645,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.20519
Policy Entropy: 3.20951
Value Function Loss: 0.00420

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.58585
Value Function Update Magnitude: 0.53871

Collected Steps per Second: 22,235.05069
Overall Steps per Second: 10,429.33353

Timestep Collection Time: 2.24951
Timestep Consumption Time: 2.54638
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 4.79590

Cumulative Model Updates: 132,210
Cumulative Timesteps: 1,102,695,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1102695496...
Checkpoint 1102695496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.41943
Policy Entropy: 3.21102
Value Function Loss: 0.00392

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.58041
Value Function Update Magnitude: 0.54690

Collected Steps per Second: 22,364.68747
Overall Steps per Second: 10,640.94144

Timestep Collection Time: 2.23674
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.70109

Cumulative Model Updates: 132,216
Cumulative Timesteps: 1,102,745,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.38857
Policy Entropy: 3.20912
Value Function Loss: 0.00413

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.57817
Value Function Update Magnitude: 0.51845

Collected Steps per Second: 22,390.93318
Overall Steps per Second: 10,496.82142

Timestep Collection Time: 2.23376
Timestep Consumption Time: 2.53111
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.76487

Cumulative Model Updates: 132,222
Cumulative Timesteps: 1,102,795,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1102795536...
Checkpoint 1102795536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.67391
Policy Entropy: 3.20943
Value Function Loss: 0.00425

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.58090
Value Function Update Magnitude: 0.52265

Collected Steps per Second: 22,273.69295
Overall Steps per Second: 10,556.80875

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.73704

Cumulative Model Updates: 132,228
Cumulative Timesteps: 1,102,845,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.86001
Policy Entropy: 3.21033
Value Function Loss: 0.00476

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.59251
Value Function Update Magnitude: 0.54362

Collected Steps per Second: 22,089.90858
Overall Steps per Second: 10,505.89410

Timestep Collection Time: 2.26348
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.75923

Cumulative Model Updates: 132,234
Cumulative Timesteps: 1,102,895,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1102895544...
Checkpoint 1102895544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.35309
Policy Entropy: 3.21398
Value Function Loss: 0.00428

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.57788
Value Function Update Magnitude: 0.52723

Collected Steps per Second: 22,032.92330
Overall Steps per Second: 10,559.19146

Timestep Collection Time: 2.26997
Timestep Consumption Time: 2.46657
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.73654

Cumulative Model Updates: 132,240
Cumulative Timesteps: 1,102,945,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.62992
Policy Entropy: 3.20352
Value Function Loss: 0.00437

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.52071

Collected Steps per Second: 22,571.83026
Overall Steps per Second: 10,514.08529

Timestep Collection Time: 2.21586
Timestep Consumption Time: 2.54119
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.75705

Cumulative Model Updates: 132,246
Cumulative Timesteps: 1,102,995,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1102995574...
Checkpoint 1102995574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.57275
Policy Entropy: 3.19589
Value Function Loss: 0.00413

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.51516

Collected Steps per Second: 21,961.28174
Overall Steps per Second: 10,536.64660

Timestep Collection Time: 2.27746
Timestep Consumption Time: 2.46940
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.74686

Cumulative Model Updates: 132,252
Cumulative Timesteps: 1,103,045,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.91177
Policy Entropy: 3.17994
Value Function Loss: 0.00452

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.58645
Value Function Update Magnitude: 0.51910

Collected Steps per Second: 21,989.12652
Overall Steps per Second: 10,552.55275

Timestep Collection Time: 2.27449
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.73952

Cumulative Model Updates: 132,258
Cumulative Timesteps: 1,103,095,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1103095604...
Checkpoint 1103095604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.33311
Policy Entropy: 3.19009
Value Function Loss: 0.00442

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.58652
Value Function Update Magnitude: 0.53353

Collected Steps per Second: 22,101.44724
Overall Steps per Second: 10,637.53185

Timestep Collection Time: 2.26329
Timestep Consumption Time: 2.43912
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.70241

Cumulative Model Updates: 132,264
Cumulative Timesteps: 1,103,145,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.55879
Policy Entropy: 3.19810
Value Function Loss: 0.00450

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.52015

Collected Steps per Second: 22,782.50484
Overall Steps per Second: 10,634.55443

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.50769
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.70297

Cumulative Model Updates: 132,270
Cumulative Timesteps: 1,103,195,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1103195640...
Checkpoint 1103195640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.91608
Policy Entropy: 3.19646
Value Function Loss: 0.00431

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.52258

Collected Steps per Second: 22,583.48799
Overall Steps per Second: 10,527.92999

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.53597
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.75060

Cumulative Model Updates: 132,276
Cumulative Timesteps: 1,103,245,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.86292
Policy Entropy: 3.18177
Value Function Loss: 0.00475

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.60348
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 22,521.12983
Overall Steps per Second: 10,574.05425

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.50872
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.72912

Cumulative Model Updates: 132,282
Cumulative Timesteps: 1,103,295,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1103295660...
Checkpoint 1103295660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.15922
Policy Entropy: 3.18210
Value Function Loss: 0.00424

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.60432
Value Function Update Magnitude: 0.59461

Collected Steps per Second: 22,576.73966
Overall Steps per Second: 10,462.30072

Timestep Collection Time: 2.21573
Timestep Consumption Time: 2.56563
PPO Batch Consumption Time: 0.30067
Total Iteration Time: 4.78136

Cumulative Model Updates: 132,288
Cumulative Timesteps: 1,103,345,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.40536
Policy Entropy: 3.17619
Value Function Loss: 0.00417

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.59123
Value Function Update Magnitude: 0.58636

Collected Steps per Second: 22,400.64583
Overall Steps per Second: 10,462.06856

Timestep Collection Time: 2.23315
Timestep Consumption Time: 2.54831
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.78146

Cumulative Model Updates: 132,294
Cumulative Timesteps: 1,103,395,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1103395708...
Checkpoint 1103395708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.66414
Policy Entropy: 3.17500
Value Function Loss: 0.00411

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.58822
Value Function Update Magnitude: 0.55935

Collected Steps per Second: 22,575.37416
Overall Steps per Second: 10,629.40742

Timestep Collection Time: 2.21498
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.70431

Cumulative Model Updates: 132,300
Cumulative Timesteps: 1,103,445,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.79321
Policy Entropy: 3.16364
Value Function Loss: 0.00460

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.59997
Value Function Update Magnitude: 0.53387

Collected Steps per Second: 22,497.72634
Overall Steps per Second: 10,570.81961

Timestep Collection Time: 2.22262
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.73038

Cumulative Model Updates: 132,306
Cumulative Timesteps: 1,103,495,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1103495716...
Checkpoint 1103495716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.14675
Policy Entropy: 3.16158
Value Function Loss: 0.00470

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.61692
Value Function Update Magnitude: 0.55962

Collected Steps per Second: 22,311.47646
Overall Steps per Second: 10,539.33129

Timestep Collection Time: 2.24154
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.74527

Cumulative Model Updates: 132,312
Cumulative Timesteps: 1,103,545,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,901.13822
Policy Entropy: 3.16809
Value Function Loss: 0.00443

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.60666
Value Function Update Magnitude: 0.57838

Collected Steps per Second: 22,794.26446
Overall Steps per Second: 10,525.42548

Timestep Collection Time: 2.19362
Timestep Consumption Time: 2.55697
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.75059

Cumulative Model Updates: 132,318
Cumulative Timesteps: 1,103,595,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1103595730...
Checkpoint 1103595730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.20306
Policy Entropy: 3.17431
Value Function Loss: 0.00403

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.59539
Value Function Update Magnitude: 0.55073

Collected Steps per Second: 22,180.68592
Overall Steps per Second: 10,580.11721

Timestep Collection Time: 2.25457
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.72660

Cumulative Model Updates: 132,324
Cumulative Timesteps: 1,103,645,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.11418
Policy Entropy: 3.17015
Value Function Loss: 0.00430

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.59230
Value Function Update Magnitude: 0.54843

Collected Steps per Second: 22,399.47075
Overall Steps per Second: 10,480.87225

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.53921
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.77212

Cumulative Model Updates: 132,330
Cumulative Timesteps: 1,103,695,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1103695754...
Checkpoint 1103695754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.09054
Policy Entropy: 3.18044
Value Function Loss: 0.00416

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.60319
Value Function Update Magnitude: 0.59442

Collected Steps per Second: 22,013.63380
Overall Steps per Second: 10,564.75798

Timestep Collection Time: 2.27150
Timestep Consumption Time: 2.46159
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.73309

Cumulative Model Updates: 132,336
Cumulative Timesteps: 1,103,745,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.46512
Policy Entropy: 3.17614
Value Function Loss: 0.00412

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.60928
Value Function Update Magnitude: 0.60743

Collected Steps per Second: 22,291.87505
Overall Steps per Second: 10,456.53746

Timestep Collection Time: 2.24351
Timestep Consumption Time: 2.53934
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 4.78285

Cumulative Model Updates: 132,342
Cumulative Timesteps: 1,103,795,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1103795770...
Checkpoint 1103795770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.55454
Policy Entropy: 3.18931
Value Function Loss: 0.00378

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.59606
Value Function Update Magnitude: 0.57183

Collected Steps per Second: 22,322.25925
Overall Steps per Second: 10,669.89020

Timestep Collection Time: 2.24108
Timestep Consumption Time: 2.44744
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.68852

Cumulative Model Updates: 132,348
Cumulative Timesteps: 1,103,845,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.40781
Policy Entropy: 3.18343
Value Function Loss: 0.00372

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.58069
Value Function Update Magnitude: 0.54103

Collected Steps per Second: 22,638.71587
Overall Steps per Second: 10,606.10464

Timestep Collection Time: 2.20993
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.71709

Cumulative Model Updates: 132,354
Cumulative Timesteps: 1,103,895,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1103895826...
Checkpoint 1103895826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.47593
Policy Entropy: 3.17528
Value Function Loss: 0.00385

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.57946
Value Function Update Magnitude: 0.54313

Collected Steps per Second: 22,255.05721
Overall Steps per Second: 10,486.49508

Timestep Collection Time: 2.24740
Timestep Consumption Time: 2.52216
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.76956

Cumulative Model Updates: 132,360
Cumulative Timesteps: 1,103,945,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.68651
Policy Entropy: 3.17262
Value Function Loss: 0.00404

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.59043
Value Function Update Magnitude: 0.56580

Collected Steps per Second: 22,721.84296
Overall Steps per Second: 10,532.49282

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.54801
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.74968

Cumulative Model Updates: 132,366
Cumulative Timesteps: 1,103,995,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1103995868...
Checkpoint 1103995868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.01590
Policy Entropy: 3.17720
Value Function Loss: 0.00426

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.59065
Value Function Update Magnitude: 0.55732

Collected Steps per Second: 22,253.88952
Overall Steps per Second: 10,568.34244

Timestep Collection Time: 2.24824
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.73414

Cumulative Model Updates: 132,372
Cumulative Timesteps: 1,104,045,900

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.65467
Policy Entropy: 3.18127
Value Function Loss: 0.00411

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.54203

Collected Steps per Second: 22,575.75255
Overall Steps per Second: 10,497.24364

Timestep Collection Time: 2.21565
Timestep Consumption Time: 2.54941
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.76506

Cumulative Model Updates: 132,378
Cumulative Timesteps: 1,104,095,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1104095920...
Checkpoint 1104095920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.89040
Policy Entropy: 3.17578
Value Function Loss: 0.00442

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.59261
Value Function Update Magnitude: 0.54473

Collected Steps per Second: 22,428.55870
Overall Steps per Second: 10,615.79735

Timestep Collection Time: 2.22939
Timestep Consumption Time: 2.48076
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.71015

Cumulative Model Updates: 132,384
Cumulative Timesteps: 1,104,145,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.61289
Policy Entropy: 3.18404
Value Function Loss: 0.00438

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.59939
Value Function Update Magnitude: 0.57008

Collected Steps per Second: 22,824.85417
Overall Steps per Second: 10,731.47631

Timestep Collection Time: 2.19059
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.65919

Cumulative Model Updates: 132,390
Cumulative Timesteps: 1,104,195,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1104195922...
Checkpoint 1104195922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.73259
Policy Entropy: 3.18376
Value Function Loss: 0.00452

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.60132
Value Function Update Magnitude: 0.56460

Collected Steps per Second: 22,222.38415
Overall Steps per Second: 10,597.83921

Timestep Collection Time: 2.25061
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71926

Cumulative Model Updates: 132,396
Cumulative Timesteps: 1,104,245,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.81471
Policy Entropy: 3.18742
Value Function Loss: 0.00425

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.60044
Value Function Update Magnitude: 0.55004

Collected Steps per Second: 22,871.63236
Overall Steps per Second: 10,683.73193

Timestep Collection Time: 2.18673
Timestep Consumption Time: 2.49460
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.68132

Cumulative Model Updates: 132,402
Cumulative Timesteps: 1,104,295,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1104295950...
Checkpoint 1104295950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.53911
Policy Entropy: 3.18814
Value Function Loss: 0.00417

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.53852

Collected Steps per Second: 22,149.41124
Overall Steps per Second: 10,489.66051

Timestep Collection Time: 2.25839
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.76870

Cumulative Model Updates: 132,408
Cumulative Timesteps: 1,104,345,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.66076
Policy Entropy: 3.19923
Value Function Loss: 0.00407

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.57290
Value Function Update Magnitude: 0.51907

Collected Steps per Second: 22,456.78705
Overall Steps per Second: 10,568.85185

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.73221

Cumulative Model Updates: 132,414
Cumulative Timesteps: 1,104,395,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1104395986...
Checkpoint 1104395986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.80490
Policy Entropy: 3.20297
Value Function Loss: 0.00411

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.57308
Value Function Update Magnitude: 0.49767

Collected Steps per Second: 22,616.21835
Overall Steps per Second: 10,634.82042

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.70417

Cumulative Model Updates: 132,420
Cumulative Timesteps: 1,104,446,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.54632
Policy Entropy: 3.19610
Value Function Loss: 0.00428

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.50933

Collected Steps per Second: 22,765.16834
Overall Steps per Second: 10,650.15693

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.49953
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.69683

Cumulative Model Updates: 132,426
Cumulative Timesteps: 1,104,496,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1104496036...
Checkpoint 1104496036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.41675
Policy Entropy: 3.18764
Value Function Loss: 0.00433

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.52465

Collected Steps per Second: 22,695.03005
Overall Steps per Second: 10,625.05124

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.50343
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.70718

Cumulative Model Updates: 132,432
Cumulative Timesteps: 1,104,546,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.73028
Policy Entropy: 3.18797
Value Function Loss: 0.00447

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.60016
Value Function Update Magnitude: 0.53898

Collected Steps per Second: 22,890.91568
Overall Steps per Second: 10,755.42553

Timestep Collection Time: 2.18488
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.65012

Cumulative Model Updates: 132,438
Cumulative Timesteps: 1,104,596,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1104596064...
Checkpoint 1104596064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.92941
Policy Entropy: 3.19066
Value Function Loss: 0.00448

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.59619
Value Function Update Magnitude: 0.52362

Collected Steps per Second: 21,931.86206
Overall Steps per Second: 10,527.68761

Timestep Collection Time: 2.28070
Timestep Consumption Time: 2.47058
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.75128

Cumulative Model Updates: 132,444
Cumulative Timesteps: 1,104,646,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.51509
Policy Entropy: 3.18324
Value Function Loss: 0.00438

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.58504
Value Function Update Magnitude: 0.50351

Collected Steps per Second: 22,806.43017
Overall Steps per Second: 10,638.93505

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.50836
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.70160

Cumulative Model Updates: 132,450
Cumulative Timesteps: 1,104,696,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1104696104...
Checkpoint 1104696104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.48974
Policy Entropy: 3.17482
Value Function Loss: 0.00429

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.51080

Collected Steps per Second: 22,361.26378
Overall Steps per Second: 10,572.54409

Timestep Collection Time: 2.23628
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.72980

Cumulative Model Updates: 132,456
Cumulative Timesteps: 1,104,746,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952.10996
Policy Entropy: 3.16822
Value Function Loss: 0.00423

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.57853
Value Function Update Magnitude: 0.53387

Collected Steps per Second: 22,741.54240
Overall Steps per Second: 10,605.14383

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.51728
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.71696

Cumulative Model Updates: 132,462
Cumulative Timesteps: 1,104,796,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1104796134...
Checkpoint 1104796134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.24773
Policy Entropy: 3.16982
Value Function Loss: 0.00448

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.59261
Value Function Update Magnitude: 0.53958

Collected Steps per Second: 21,785.99317
Overall Steps per Second: 10,540.40526

Timestep Collection Time: 2.29560
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.74479

Cumulative Model Updates: 132,468
Cumulative Timesteps: 1,104,846,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.41315
Policy Entropy: 3.17986
Value Function Loss: 0.00468

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.59468
Value Function Update Magnitude: 0.53778

Collected Steps per Second: 22,483.91940
Overall Steps per Second: 10,521.96523

Timestep Collection Time: 2.22506
Timestep Consumption Time: 2.52957
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.75463

Cumulative Model Updates: 132,474
Cumulative Timesteps: 1,104,896,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1104896174...
Checkpoint 1104896174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.89075
Policy Entropy: 3.18564
Value Function Loss: 0.00450

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.58782
Value Function Update Magnitude: 0.54653

Collected Steps per Second: 22,380.48552
Overall Steps per Second: 10,508.91670

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.52559
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.76129

Cumulative Model Updates: 132,480
Cumulative Timesteps: 1,104,946,210

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.58246
Policy Entropy: 3.17803
Value Function Loss: 0.00452

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.59843
Value Function Update Magnitude: 0.57632

Collected Steps per Second: 22,412.18299
Overall Steps per Second: 10,297.56912

Timestep Collection Time: 2.23191
Timestep Consumption Time: 2.62574
PPO Batch Consumption Time: 0.31250
Total Iteration Time: 4.85765

Cumulative Model Updates: 132,486
Cumulative Timesteps: 1,104,996,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1104996232...
Checkpoint 1104996232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.71480
Policy Entropy: 3.17124
Value Function Loss: 0.00445

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.60085
Value Function Update Magnitude: 0.58820

Collected Steps per Second: 22,599.91399
Overall Steps per Second: 10,641.47605

Timestep Collection Time: 2.21240
Timestep Consumption Time: 2.48620
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.69860

Cumulative Model Updates: 132,492
Cumulative Timesteps: 1,105,046,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.98884
Policy Entropy: 3.18758
Value Function Loss: 0.00421

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.56053

Collected Steps per Second: 22,641.40421
Overall Steps per Second: 10,660.20419

Timestep Collection Time: 2.20914
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.69203

Cumulative Model Updates: 132,498
Cumulative Timesteps: 1,105,096,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1105096250...
Checkpoint 1105096250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.16144
Policy Entropy: 3.17651
Value Function Loss: 0.00452

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.59666
Value Function Update Magnitude: 0.57148

Collected Steps per Second: 22,430.83441
Overall Steps per Second: 10,609.42955

Timestep Collection Time: 2.23041
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.71562

Cumulative Model Updates: 132,504
Cumulative Timesteps: 1,105,146,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.25849
Policy Entropy: 3.16998
Value Function Loss: 0.00432

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.60898
Value Function Update Magnitude: 0.60643

Collected Steps per Second: 22,724.88382
Overall Steps per Second: 10,643.00375

Timestep Collection Time: 2.20146
Timestep Consumption Time: 2.49909
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.70055

Cumulative Model Updates: 132,510
Cumulative Timesteps: 1,105,196,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1105196308...
Checkpoint 1105196308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,203.76072
Policy Entropy: 3.15998
Value Function Loss: 0.00426

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.60081
Value Function Update Magnitude: 0.58796

Collected Steps per Second: 22,279.35853
Overall Steps per Second: 10,481.26049

Timestep Collection Time: 2.24477
Timestep Consumption Time: 2.52680
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.77156

Cumulative Model Updates: 132,516
Cumulative Timesteps: 1,105,246,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.93663
Policy Entropy: 3.15413
Value Function Loss: 0.00416

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.58570
Value Function Update Magnitude: 0.52849

Collected Steps per Second: 22,851.77899
Overall Steps per Second: 10,691.27184

Timestep Collection Time: 2.18819
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.67709

Cumulative Model Updates: 132,522
Cumulative Timesteps: 1,105,296,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1105296324...
Checkpoint 1105296324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.01096
Policy Entropy: 3.15078
Value Function Loss: 0.00416

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.58784
Value Function Update Magnitude: 0.49491

Collected Steps per Second: 22,487.94785
Overall Steps per Second: 10,728.50502

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.43921
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.66458

Cumulative Model Updates: 132,528
Cumulative Timesteps: 1,105,346,368

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883.63840
Policy Entropy: 3.15705
Value Function Loss: 0.00419

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.59655
Value Function Update Magnitude: 0.49372

Collected Steps per Second: 22,753.67401
Overall Steps per Second: 10,547.39349

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.54408
PPO Batch Consumption Time: 0.30134
Total Iteration Time: 4.74240

Cumulative Model Updates: 132,534
Cumulative Timesteps: 1,105,396,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1105396388...
Checkpoint 1105396388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.64613
Policy Entropy: 3.15827
Value Function Loss: 0.00388

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.58882
Value Function Update Magnitude: 0.50812

Collected Steps per Second: 22,281.62881
Overall Steps per Second: 10,630.17472

Timestep Collection Time: 2.24472
Timestep Consumption Time: 2.46038
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.70510

Cumulative Model Updates: 132,540
Cumulative Timesteps: 1,105,446,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.30071
Policy Entropy: 3.15825
Value Function Loss: 0.00425

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.59441
Value Function Update Magnitude: 0.52873

Collected Steps per Second: 22,234.03861
Overall Steps per Second: 10,278.56151

Timestep Collection Time: 2.24979
Timestep Consumption Time: 2.61684
PPO Batch Consumption Time: 0.30765
Total Iteration Time: 4.86663

Cumulative Model Updates: 132,546
Cumulative Timesteps: 1,105,496,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1105496426...
Checkpoint 1105496426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.15957
Policy Entropy: 3.15704
Value Function Loss: 0.00443

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.60114
Value Function Update Magnitude: 0.55904

Collected Steps per Second: 22,631.28910
Overall Steps per Second: 10,776.80110

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.64182

Cumulative Model Updates: 132,552
Cumulative Timesteps: 1,105,546,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.56812
Policy Entropy: 3.15223
Value Function Loss: 0.00461

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.60114
Value Function Update Magnitude: 0.55753

Collected Steps per Second: 22,850.61124
Overall Steps per Second: 10,580.46807

Timestep Collection Time: 2.18891
Timestep Consumption Time: 2.53848
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.72739

Cumulative Model Updates: 132,558
Cumulative Timesteps: 1,105,596,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1105596468...
Checkpoint 1105596468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.05420
Policy Entropy: 3.16845
Value Function Loss: 0.00426

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.59317
Value Function Update Magnitude: 0.53848

Collected Steps per Second: 22,583.76570
Overall Steps per Second: 10,634.28295

Timestep Collection Time: 2.21540
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.70478

Cumulative Model Updates: 132,564
Cumulative Timesteps: 1,105,646,500

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.15071
Policy Entropy: 3.16751
Value Function Loss: 0.00400

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.59045
Value Function Update Magnitude: 0.51885

Collected Steps per Second: 21,246.38764
Overall Steps per Second: 10,401.21002

Timestep Collection Time: 2.35466
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.80983

Cumulative Model Updates: 132,570
Cumulative Timesteps: 1,105,696,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1105696528...
Checkpoint 1105696528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.58445
Policy Entropy: 3.15307
Value Function Loss: 0.00422

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.59659
Value Function Update Magnitude: 0.51233

Collected Steps per Second: 21,903.00456
Overall Steps per Second: 10,536.61550

Timestep Collection Time: 2.28407
Timestep Consumption Time: 2.46394
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.74801

Cumulative Model Updates: 132,576
Cumulative Timesteps: 1,105,746,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,108.68303
Policy Entropy: 3.14562
Value Function Loss: 0.00425

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.60786
Value Function Update Magnitude: 0.53729

Collected Steps per Second: 23,004.86698
Overall Steps per Second: 10,682.09436

Timestep Collection Time: 2.17363
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.68110

Cumulative Model Updates: 132,582
Cumulative Timesteps: 1,105,796,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1105796560...
Checkpoint 1105796560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.70822
Policy Entropy: 3.13624
Value Function Loss: 0.00460

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.61177
Value Function Update Magnitude: 0.55319

Collected Steps per Second: 22,080.08125
Overall Steps per Second: 10,674.52143

Timestep Collection Time: 2.26458
Timestep Consumption Time: 2.41966
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.68424

Cumulative Model Updates: 132,588
Cumulative Timesteps: 1,105,846,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,864.35556
Policy Entropy: 3.14450
Value Function Loss: 0.00424

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.61070
Value Function Update Magnitude: 0.56183

Collected Steps per Second: 23,066.54085
Overall Steps per Second: 10,903.19014

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.58967

Cumulative Model Updates: 132,594
Cumulative Timesteps: 1,105,896,604

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1105896604...
Checkpoint 1105896604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.07686
Policy Entropy: 3.13571
Value Function Loss: 0.00429

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.61056
Value Function Update Magnitude: 0.56713

Collected Steps per Second: 22,620.42256
Overall Steps per Second: 10,649.89444

Timestep Collection Time: 2.21066
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.69545

Cumulative Model Updates: 132,600
Cumulative Timesteps: 1,105,946,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.58674
Policy Entropy: 3.15211
Value Function Loss: 0.00417

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.60629
Value Function Update Magnitude: 0.56652

Collected Steps per Second: 22,978.40789
Overall Steps per Second: 10,859.99923

Timestep Collection Time: 2.17709
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.60645

Cumulative Model Updates: 132,606
Cumulative Timesteps: 1,105,996,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1105996636...
Checkpoint 1105996636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.74853
Policy Entropy: 3.14323
Value Function Loss: 0.00427

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.59152
Value Function Update Magnitude: 0.54737

Collected Steps per Second: 22,716.80979
Overall Steps per Second: 10,631.51533

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.50229
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.70356

Cumulative Model Updates: 132,612
Cumulative Timesteps: 1,106,046,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.20603
Policy Entropy: 3.15484
Value Function Loss: 0.00406

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.57510
Value Function Update Magnitude: 0.54079

Collected Steps per Second: 22,755.62524
Overall Steps per Second: 10,804.12964

Timestep Collection Time: 2.19814
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.62971

Cumulative Model Updates: 132,618
Cumulative Timesteps: 1,106,096,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1106096662...
Checkpoint 1106096662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.72562
Policy Entropy: 3.14994
Value Function Loss: 0.00432

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.53942

Collected Steps per Second: 22,736.86373
Overall Steps per Second: 10,767.44834

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.44582
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.64604

Cumulative Model Updates: 132,624
Cumulative Timesteps: 1,106,146,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.99757
Policy Entropy: 3.16413
Value Function Loss: 0.00400

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.57749
Value Function Update Magnitude: 0.54336

Collected Steps per Second: 23,178.22274
Overall Steps per Second: 10,910.22964

Timestep Collection Time: 2.15806
Timestep Consumption Time: 2.42663
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.58469

Cumulative Model Updates: 132,630
Cumulative Timesteps: 1,106,196,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1106196708...
Checkpoint 1106196708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.36585
Policy Entropy: 3.16584
Value Function Loss: 0.00413

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.57324
Value Function Update Magnitude: 0.54662

Collected Steps per Second: 22,350.64905
Overall Steps per Second: 10,621.60297

Timestep Collection Time: 2.23707
Timestep Consumption Time: 2.47032
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.70739

Cumulative Model Updates: 132,636
Cumulative Timesteps: 1,106,246,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.06536
Policy Entropy: 3.18000
Value Function Loss: 0.00399

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.57223
Value Function Update Magnitude: 0.54670

Collected Steps per Second: 22,935.52947
Overall Steps per Second: 10,677.36558

Timestep Collection Time: 2.18046
Timestep Consumption Time: 2.50328
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.68374

Cumulative Model Updates: 132,642
Cumulative Timesteps: 1,106,296,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1106296718...
Checkpoint 1106296718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.15743
Policy Entropy: 3.17473
Value Function Loss: 0.00401

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.54864

Collected Steps per Second: 23,036.10184
Overall Steps per Second: 10,815.86364

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.45273
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.62358

Cumulative Model Updates: 132,648
Cumulative Timesteps: 1,106,346,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.94989
Policy Entropy: 3.17171
Value Function Loss: 0.00433

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.54857

Collected Steps per Second: 22,952.46324
Overall Steps per Second: 10,656.07623

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.51394
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.69253

Cumulative Model Updates: 132,654
Cumulative Timesteps: 1,106,396,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1106396730...
Checkpoint 1106396730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072.18795
Policy Entropy: 3.15563
Value Function Loss: 0.00439

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.59551
Value Function Update Magnitude: 0.57528

Collected Steps per Second: 22,729.15930
Overall Steps per Second: 10,547.69140

Timestep Collection Time: 2.20096
Timestep Consumption Time: 2.54188
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.74284

Cumulative Model Updates: 132,660
Cumulative Timesteps: 1,106,446,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.00508
Policy Entropy: 3.15811
Value Function Loss: 0.00462

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.60674
Value Function Update Magnitude: 0.59209

Collected Steps per Second: 23,282.05886
Overall Steps per Second: 10,879.98836

Timestep Collection Time: 2.14775
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.59596

Cumulative Model Updates: 132,666
Cumulative Timesteps: 1,106,496,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1106496760...
Checkpoint 1106496760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.53188
Policy Entropy: 3.15039
Value Function Loss: 0.00433

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.60577
Value Function Update Magnitude: 0.59421

Collected Steps per Second: 22,640.99293
Overall Steps per Second: 10,641.75130

Timestep Collection Time: 2.20936
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.70054

Cumulative Model Updates: 132,672
Cumulative Timesteps: 1,106,546,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.56171
Policy Entropy: 3.15965
Value Function Loss: 0.00406

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.58841
Value Function Update Magnitude: 0.58192

Collected Steps per Second: 22,801.73856
Overall Steps per Second: 10,778.41433

Timestep Collection Time: 2.19457
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.64261

Cumulative Model Updates: 132,678
Cumulative Timesteps: 1,106,596,822

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1106596822...
Checkpoint 1106596822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,387.83831
Policy Entropy: 3.16440
Value Function Loss: 0.00373

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.57808
Value Function Update Magnitude: 0.55123

Collected Steps per Second: 22,548.76824
Overall Steps per Second: 10,808.05687

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.40944
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.62747

Cumulative Model Updates: 132,684
Cumulative Timesteps: 1,106,646,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.09474
Policy Entropy: 3.17013
Value Function Loss: 0.00366

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.57082
Value Function Update Magnitude: 0.53595

Collected Steps per Second: 22,907.52063
Overall Steps per Second: 10,767.28270

Timestep Collection Time: 2.18278
Timestep Consumption Time: 2.46111
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.64388

Cumulative Model Updates: 132,690
Cumulative Timesteps: 1,106,696,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1106696838...
Checkpoint 1106696838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.49248
Policy Entropy: 3.14819
Value Function Loss: 0.00382

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.56152
Value Function Update Magnitude: 0.51860

Collected Steps per Second: 22,883.77163
Overall Steps per Second: 10,757.11274

Timestep Collection Time: 2.18539
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.64902

Cumulative Model Updates: 132,696
Cumulative Timesteps: 1,106,746,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.09388
Policy Entropy: 3.14495
Value Function Loss: 0.00420

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.50443

Collected Steps per Second: 22,739.97360
Overall Steps per Second: 10,584.85190

Timestep Collection Time: 2.19956
Timestep Consumption Time: 2.52587
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.72543

Cumulative Model Updates: 132,702
Cumulative Timesteps: 1,106,796,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1106796866...
Checkpoint 1106796866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.15548
Policy Entropy: 3.14340
Value Function Loss: 0.00436

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.58465
Value Function Update Magnitude: 0.51636

Collected Steps per Second: 22,816.99225
Overall Steps per Second: 10,595.57875

Timestep Collection Time: 2.19135
Timestep Consumption Time: 2.52760
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.71895

Cumulative Model Updates: 132,708
Cumulative Timesteps: 1,106,846,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.48698
Policy Entropy: 3.17127
Value Function Loss: 0.00419

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.58613
Value Function Update Magnitude: 0.52179

Collected Steps per Second: 22,810.03611
Overall Steps per Second: 10,792.82885

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.44157
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.63437

Cumulative Model Updates: 132,714
Cumulative Timesteps: 1,106,896,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1106896884...
Checkpoint 1106896884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.91873
Policy Entropy: 3.16610
Value Function Loss: 0.00405

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.53218

Collected Steps per Second: 22,472.79846
Overall Steps per Second: 10,650.42625

Timestep Collection Time: 2.22607
Timestep Consumption Time: 2.47102
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.69709

Cumulative Model Updates: 132,720
Cumulative Timesteps: 1,106,946,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.18372
Policy Entropy: 3.15739
Value Function Loss: 0.00406

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.53023

Collected Steps per Second: 22,703.05141
Overall Steps per Second: 10,584.83342

Timestep Collection Time: 2.20270
Timestep Consumption Time: 2.52180
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.72450

Cumulative Model Updates: 132,726
Cumulative Timesteps: 1,106,996,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1106996918...
Checkpoint 1106996918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.74261
Policy Entropy: 3.15789
Value Function Loss: 0.00393

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.55147

Collected Steps per Second: 22,692.53744
Overall Steps per Second: 10,547.53553

Timestep Collection Time: 2.20407
Timestep Consumption Time: 2.53789
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.74196

Cumulative Model Updates: 132,732
Cumulative Timesteps: 1,107,046,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.59785
Policy Entropy: 3.15643
Value Function Loss: 0.00394

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.54620

Collected Steps per Second: 22,932.02624
Overall Steps per Second: 10,850.83264

Timestep Collection Time: 2.18079
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.60886

Cumulative Model Updates: 132,738
Cumulative Timesteps: 1,107,096,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1107096944...
Checkpoint 1107096944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.68423
Policy Entropy: 3.16864
Value Function Loss: 0.00400

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.57873
Value Function Update Magnitude: 0.56463

Collected Steps per Second: 22,799.08032
Overall Steps per Second: 10,739.53403

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.65719

Cumulative Model Updates: 132,744
Cumulative Timesteps: 1,107,146,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.23653
Policy Entropy: 3.15676
Value Function Loss: 0.00485

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.59107
Value Function Update Magnitude: 0.59252

Collected Steps per Second: 22,820.09965
Overall Steps per Second: 10,793.16863

Timestep Collection Time: 2.19166
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.63386

Cumulative Model Updates: 132,750
Cumulative Timesteps: 1,107,196,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1107196974...
Checkpoint 1107196974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.43065
Policy Entropy: 3.15467
Value Function Loss: 0.00459

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.59949
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,548.23759
Overall Steps per Second: 10,738.38784

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.43931
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.65731

Cumulative Model Updates: 132,756
Cumulative Timesteps: 1,107,246,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.68108
Policy Entropy: 3.16175
Value Function Loss: 0.00427

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.58373
Value Function Update Magnitude: 0.58467

Collected Steps per Second: 22,922.87453
Overall Steps per Second: 10,825.81764

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.62118

Cumulative Model Updates: 132,762
Cumulative Timesteps: 1,107,297,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1107297014...
Checkpoint 1107297014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.24430
Policy Entropy: 3.16593
Value Function Loss: 0.00403

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.55919

Collected Steps per Second: 22,777.07989
Overall Steps per Second: 10,724.24130

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.46833
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.66457

Cumulative Model Updates: 132,768
Cumulative Timesteps: 1,107,347,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.82378
Policy Entropy: 3.17470
Value Function Loss: 0.00411

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.57118
Value Function Update Magnitude: 0.56474

Collected Steps per Second: 22,779.21036
Overall Steps per Second: 10,801.04915

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.62937

Cumulative Model Updates: 132,774
Cumulative Timesteps: 1,107,397,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1107397040...
Checkpoint 1107397040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,171.32269
Policy Entropy: 3.17275
Value Function Loss: 0.00430

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.57442

Collected Steps per Second: 22,640.99951
Overall Steps per Second: 10,723.85806

Timestep Collection Time: 2.20971
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.66530

Cumulative Model Updates: 132,780
Cumulative Timesteps: 1,107,447,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.71192
Policy Entropy: 3.17266
Value Function Loss: 0.00395

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.54961

Collected Steps per Second: 22,700.14571
Overall Steps per Second: 10,679.82010

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68416

Cumulative Model Updates: 132,786
Cumulative Timesteps: 1,107,497,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1107497096...
Checkpoint 1107497096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.04278
Policy Entropy: 3.17463
Value Function Loss: 0.00401

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.56534
Value Function Update Magnitude: 0.54284

Collected Steps per Second: 22,752.94328
Overall Steps per Second: 10,821.98769

Timestep Collection Time: 2.19822
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.62170

Cumulative Model Updates: 132,792
Cumulative Timesteps: 1,107,547,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.40669
Policy Entropy: 3.16145
Value Function Loss: 0.00440

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.58703
Value Function Update Magnitude: 0.56673

Collected Steps per Second: 22,532.35235
Overall Steps per Second: 10,617.25023

Timestep Collection Time: 2.21930
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.70988

Cumulative Model Updates: 132,798
Cumulative Timesteps: 1,107,597,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1107597118...
Checkpoint 1107597118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.49575
Policy Entropy: 3.16164
Value Function Loss: 0.00472

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.60196
Value Function Update Magnitude: 0.58380

Collected Steps per Second: 22,775.38084
Overall Steps per Second: 10,688.21923

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67842

Cumulative Model Updates: 132,804
Cumulative Timesteps: 1,107,647,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.91384
Policy Entropy: 3.16181
Value Function Loss: 0.00446

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.59678
Value Function Update Magnitude: 0.58384

Collected Steps per Second: 23,203.19612
Overall Steps per Second: 10,760.34023

Timestep Collection Time: 2.15574
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.64855

Cumulative Model Updates: 132,810
Cumulative Timesteps: 1,107,697,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1107697142...
Checkpoint 1107697142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.90844
Policy Entropy: 3.16664
Value Function Loss: 0.00428

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.58559
Value Function Update Magnitude: 0.56605

Collected Steps per Second: 22,705.84836
Overall Steps per Second: 10,655.88670

Timestep Collection Time: 2.20278
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.69374

Cumulative Model Updates: 132,816
Cumulative Timesteps: 1,107,747,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.80980
Policy Entropy: 3.17008
Value Function Loss: 0.00389

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.57446
Value Function Update Magnitude: 0.53803

Collected Steps per Second: 22,429.60273
Overall Steps per Second: 10,547.97522

Timestep Collection Time: 2.22964
Timestep Consumption Time: 2.51155
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.74119

Cumulative Model Updates: 132,822
Cumulative Timesteps: 1,107,797,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1107797168...
Checkpoint 1107797168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.00859
Policy Entropy: 3.15539
Value Function Loss: 0.00393

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.57094
Value Function Update Magnitude: 0.54510

Collected Steps per Second: 22,846.80135
Overall Steps per Second: 10,711.09717

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.66918

Cumulative Model Updates: 132,828
Cumulative Timesteps: 1,107,847,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.77611
Policy Entropy: 3.15702
Value Function Loss: 0.00389

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.57062
Value Function Update Magnitude: 0.54221

Collected Steps per Second: 22,446.10592
Overall Steps per Second: 10,750.74511

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.42435
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.65289

Cumulative Model Updates: 132,834
Cumulative Timesteps: 1,107,897,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1107897202...
Checkpoint 1107897202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 791.36756
Policy Entropy: 3.14227
Value Function Loss: 0.00390

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.57323
Value Function Update Magnitude: 0.52491

Collected Steps per Second: 22,984.65432
Overall Steps per Second: 10,745.86231

Timestep Collection Time: 2.17623
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.65481

Cumulative Model Updates: 132,840
Cumulative Timesteps: 1,107,947,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.35921
Policy Entropy: 3.15742
Value Function Loss: 0.00397

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.56983
Value Function Update Magnitude: 0.52038

Collected Steps per Second: 22,697.57174
Overall Steps per Second: 10,805.81286

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.42542
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.62936

Cumulative Model Updates: 132,846
Cumulative Timesteps: 1,107,997,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1107997246...
Checkpoint 1107997246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.81358
Policy Entropy: 3.15069
Value Function Loss: 0.00415

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.57611
Value Function Update Magnitude: 0.53410

Collected Steps per Second: 23,053.40007
Overall Steps per Second: 10,796.66579

Timestep Collection Time: 2.16940
Timestep Consumption Time: 2.46277
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.63217

Cumulative Model Updates: 132,852
Cumulative Timesteps: 1,108,047,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106.68227
Policy Entropy: 3.14726
Value Function Loss: 0.00420

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.59078
Value Function Update Magnitude: 0.57188

Collected Steps per Second: 22,898.14633
Overall Steps per Second: 10,756.34942

Timestep Collection Time: 2.18446
Timestep Consumption Time: 2.46582
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.65028

Cumulative Model Updates: 132,858
Cumulative Timesteps: 1,108,097,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1108097278...
Checkpoint 1108097278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.80518
Policy Entropy: 3.14185
Value Function Loss: 0.00419

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.59823
Value Function Update Magnitude: 0.59143

Collected Steps per Second: 22,819.54169
Overall Steps per Second: 10,603.01988

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.52504
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.71658

Cumulative Model Updates: 132,864
Cumulative Timesteps: 1,108,147,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.63141
Policy Entropy: 3.15251
Value Function Loss: 0.00400

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.59052
Value Function Update Magnitude: 0.57952

Collected Steps per Second: 22,636.70763
Overall Steps per Second: 10,784.60200

Timestep Collection Time: 2.20986
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.63847

Cumulative Model Updates: 132,870
Cumulative Timesteps: 1,108,197,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1108197312...
Checkpoint 1108197312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.29466
Policy Entropy: 3.16256
Value Function Loss: 0.00453

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.58726
Value Function Update Magnitude: 0.56655

Collected Steps per Second: 22,744.19630
Overall Steps per Second: 10,771.34852

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.64454

Cumulative Model Updates: 132,876
Cumulative Timesteps: 1,108,247,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.06995
Policy Entropy: 3.16783
Value Function Loss: 0.00506

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.61047
Value Function Update Magnitude: 0.58159

Collected Steps per Second: 23,354.78368
Overall Steps per Second: 10,941.95772

Timestep Collection Time: 2.14132
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.57048

Cumulative Model Updates: 132,882
Cumulative Timesteps: 1,108,297,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1108297350...
Checkpoint 1108297350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.55137
Policy Entropy: 3.15616
Value Function Loss: 0.00555

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.62106
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 22,726.75001
Overall Steps per Second: 10,656.90710

Timestep Collection Time: 2.20005
Timestep Consumption Time: 2.49174
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.69179

Cumulative Model Updates: 132,888
Cumulative Timesteps: 1,108,347,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,039.26745
Policy Entropy: 3.16193
Value Function Loss: 0.00496

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.62441
Value Function Update Magnitude: 0.62338

Collected Steps per Second: 22,887.26933
Overall Steps per Second: 10,798.63488

Timestep Collection Time: 2.18576
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.63262

Cumulative Model Updates: 132,894
Cumulative Timesteps: 1,108,397,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1108397376...
Checkpoint 1108397376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.37768
Policy Entropy: 3.16195
Value Function Loss: 0.00431

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.61693
Value Function Update Magnitude: 0.60153

Collected Steps per Second: 22,717.09444
Overall Steps per Second: 10,699.39025

Timestep Collection Time: 2.20099
Timestep Consumption Time: 2.47218
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.67316

Cumulative Model Updates: 132,900
Cumulative Timesteps: 1,108,447,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060.62475
Policy Entropy: 3.16536
Value Function Loss: 0.00423

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.60191
Value Function Update Magnitude: 0.57769

Collected Steps per Second: 22,903.47605
Overall Steps per Second: 10,811.20879

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.62612

Cumulative Model Updates: 132,906
Cumulative Timesteps: 1,108,497,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1108497390...
Checkpoint 1108497390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.27852
Policy Entropy: 3.17595
Value Function Loss: 0.00438

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.60129
Value Function Update Magnitude: 0.58046

Collected Steps per Second: 22,671.32420
Overall Steps per Second: 10,726.28320

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.45612
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.66163

Cumulative Model Updates: 132,912
Cumulative Timesteps: 1,108,547,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.27760
Policy Entropy: 3.17337
Value Function Loss: 0.00441

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.59935
Value Function Update Magnitude: 0.57513

Collected Steps per Second: 22,859.47352
Overall Steps per Second: 10,795.41692

Timestep Collection Time: 2.18798
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.63308

Cumulative Model Updates: 132,918
Cumulative Timesteps: 1,108,597,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1108597408...
Checkpoint 1108597408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.48162
Policy Entropy: 3.17327
Value Function Loss: 0.00443

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.59080
Value Function Update Magnitude: 0.55538

Collected Steps per Second: 22,796.40212
Overall Steps per Second: 10,757.88513

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.64850

Cumulative Model Updates: 132,924
Cumulative Timesteps: 1,108,647,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.16957
Policy Entropy: 3.16246
Value Function Loss: 0.00472

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.60045
Value Function Update Magnitude: 0.57201

Collected Steps per Second: 22,505.48128
Overall Steps per Second: 10,670.78094

Timestep Collection Time: 2.22275
Timestep Consumption Time: 2.46519
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68794

Cumulative Model Updates: 132,930
Cumulative Timesteps: 1,108,697,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1108697440...
Checkpoint 1108697440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.83351
Policy Entropy: 3.15785
Value Function Loss: 0.00472

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.60837
Value Function Update Magnitude: 0.58308

Collected Steps per Second: 22,887.89842
Overall Steps per Second: 10,838.81747

Timestep Collection Time: 2.18631
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.61674

Cumulative Model Updates: 132,936
Cumulative Timesteps: 1,108,747,480

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.62529
Policy Entropy: 3.16910
Value Function Loss: 0.00477

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.61784
Value Function Update Magnitude: 0.57782

Collected Steps per Second: 22,417.06491
Overall Steps per Second: 10,561.27319

Timestep Collection Time: 2.23071
Timestep Consumption Time: 2.50413
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.73485

Cumulative Model Updates: 132,942
Cumulative Timesteps: 1,108,797,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1108797486...
Checkpoint 1108797486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.80131
Policy Entropy: 3.18427
Value Function Loss: 0.00462

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.60059
Value Function Update Magnitude: 0.58766

Collected Steps per Second: 22,310.35307
Overall Steps per Second: 10,527.97300

Timestep Collection Time: 2.24111
Timestep Consumption Time: 2.50814
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.74925

Cumulative Model Updates: 132,948
Cumulative Timesteps: 1,108,847,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,192.34484
Policy Entropy: 3.19781
Value Function Loss: 0.00422

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.58203

Collected Steps per Second: 22,876.82423
Overall Steps per Second: 10,813.67592

Timestep Collection Time: 2.18614
Timestep Consumption Time: 2.43874
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.62488

Cumulative Model Updates: 132,954
Cumulative Timesteps: 1,108,897,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1108897498...
Checkpoint 1108897498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.85681
Policy Entropy: 3.19579
Value Function Loss: 0.00402

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.57725
Value Function Update Magnitude: 0.54394

Collected Steps per Second: 22,723.45847
Overall Steps per Second: 10,775.19835

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.64177

Cumulative Model Updates: 132,960
Cumulative Timesteps: 1,108,947,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.88218
Policy Entropy: 3.19458
Value Function Loss: 0.00392

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.51932

Collected Steps per Second: 22,802.21840
Overall Steps per Second: 10,639.71833

Timestep Collection Time: 2.19356
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.70106

Cumulative Model Updates: 132,966
Cumulative Timesteps: 1,108,997,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1108997532...
Checkpoint 1108997532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.37393
Policy Entropy: 3.18945
Value Function Loss: 0.00407

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.56280
Value Function Update Magnitude: 0.52973

Collected Steps per Second: 22,954.48412
Overall Steps per Second: 10,866.80007

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.60154

Cumulative Model Updates: 132,972
Cumulative Timesteps: 1,109,047,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.56598
Policy Entropy: 3.17604
Value Function Loss: 0.00451

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.58318
Value Function Update Magnitude: 0.55742

Collected Steps per Second: 22,817.04904
Overall Steps per Second: 10,724.91406

Timestep Collection Time: 2.19143
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.66223

Cumulative Model Updates: 132,978
Cumulative Timesteps: 1,109,097,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1109097538...
Checkpoint 1109097538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.61888
Policy Entropy: 3.17556
Value Function Loss: 0.00436

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.59002
Value Function Update Magnitude: 0.56600

Collected Steps per Second: 22,695.21315
Overall Steps per Second: 10,809.57313

Timestep Collection Time: 2.20328
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.62590

Cumulative Model Updates: 132,984
Cumulative Timesteps: 1,109,147,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.08820
Policy Entropy: 3.18580
Value Function Loss: 0.00464

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.58744
Value Function Update Magnitude: 0.55505

Collected Steps per Second: 22,648.02596
Overall Steps per Second: 10,600.73809

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.50986
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.71835

Cumulative Model Updates: 132,990
Cumulative Timesteps: 1,109,197,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1109197560...
Checkpoint 1109197560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.25876
Policy Entropy: 3.19327
Value Function Loss: 0.00427

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.58192
Value Function Update Magnitude: 0.54957

Collected Steps per Second: 23,051.44746
Overall Steps per Second: 10,856.44335

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.43699
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.60648

Cumulative Model Updates: 132,996
Cumulative Timesteps: 1,109,247,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.25234
Policy Entropy: 3.18076
Value Function Loss: 0.00450

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.59592
Value Function Update Magnitude: 0.56148

Collected Steps per Second: 22,569.85615
Overall Steps per Second: 10,610.98674

Timestep Collection Time: 2.21596
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.71342

Cumulative Model Updates: 133,002
Cumulative Timesteps: 1,109,297,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1109297584...
Checkpoint 1109297584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.68577
Policy Entropy: 3.17413
Value Function Loss: 0.00475

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.62053
Value Function Update Magnitude: 0.59087

Collected Steps per Second: 22,834.04838
Overall Steps per Second: 10,665.11941

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.69062

Cumulative Model Updates: 133,008
Cumulative Timesteps: 1,109,347,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.86976
Policy Entropy: 3.16484
Value Function Loss: 0.00463

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.61239
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 22,813.95122
Overall Steps per Second: 10,853.39767

Timestep Collection Time: 2.19164
Timestep Consumption Time: 2.41521
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.60685

Cumulative Model Updates: 133,014
Cumulative Timesteps: 1,109,397,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1109397610...
Checkpoint 1109397610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.81121
Policy Entropy: 3.17158
Value Function Loss: 0.00449

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.60244
Value Function Update Magnitude: 0.58193

Collected Steps per Second: 22,111.78172
Overall Steps per Second: 10,643.53341

Timestep Collection Time: 2.26151
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.69825

Cumulative Model Updates: 133,020
Cumulative Timesteps: 1,109,447,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.05409
Policy Entropy: 3.18665
Value Function Loss: 0.00408

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.58694
Value Function Update Magnitude: 0.55020

Collected Steps per Second: 23,040.34848
Overall Steps per Second: 10,856.71309

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.43612
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.60692

Cumulative Model Updates: 133,026
Cumulative Timesteps: 1,109,497,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1109497632...
Checkpoint 1109497632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.74617
Policy Entropy: 3.19104
Value Function Loss: 0.00401

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.57684
Value Function Update Magnitude: 0.54333

Collected Steps per Second: 22,607.13806
Overall Steps per Second: 10,704.86237

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.45918
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.67096

Cumulative Model Updates: 133,032
Cumulative Timesteps: 1,109,547,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.34213
Policy Entropy: 3.17567
Value Function Loss: 0.00408

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.56191

Collected Steps per Second: 22,836.37888
Overall Steps per Second: 10,809.54918

Timestep Collection Time: 2.19028
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.62721

Cumulative Model Updates: 133,038
Cumulative Timesteps: 1,109,597,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1109597652...
Checkpoint 1109597652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.27486
Policy Entropy: 3.16538
Value Function Loss: 0.00394

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.57683

Collected Steps per Second: 22,696.45155
Overall Steps per Second: 10,746.20448

Timestep Collection Time: 2.20325
Timestep Consumption Time: 2.45011
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.65336

Cumulative Model Updates: 133,044
Cumulative Timesteps: 1,109,647,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,695.87331
Policy Entropy: 3.14887
Value Function Loss: 0.00404

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.57531
Value Function Update Magnitude: 0.54725

Collected Steps per Second: 23,003.36010
Overall Steps per Second: 10,826.66315

Timestep Collection Time: 2.17360
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.61823

Cumulative Model Updates: 133,050
Cumulative Timesteps: 1,109,697,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1109697658...
Checkpoint 1109697658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.10744
Policy Entropy: 3.14993
Value Function Loss: 0.00426

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.59002
Value Function Update Magnitude: 0.53783

Collected Steps per Second: 22,761.58624
Overall Steps per Second: 10,699.99719

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.47730
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.67495

Cumulative Model Updates: 133,056
Cumulative Timesteps: 1,109,747,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.88409
Policy Entropy: 3.15119
Value Function Loss: 0.00447

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.59180
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 22,397.40373
Overall Steps per Second: 10,629.61518

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.47154
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.70403

Cumulative Model Updates: 133,062
Cumulative Timesteps: 1,109,797,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1109797682...
Checkpoint 1109797682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.67548
Policy Entropy: 3.15108
Value Function Loss: 0.00435

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.60902

Collected Steps per Second: 23,041.67099
Overall Steps per Second: 10,845.58678

Timestep Collection Time: 2.17111
Timestep Consumption Time: 2.44146
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.61257

Cumulative Model Updates: 133,068
Cumulative Timesteps: 1,109,847,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.00252
Policy Entropy: 3.14611
Value Function Loss: 0.00425

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.58470
Value Function Update Magnitude: 0.57427

Collected Steps per Second: 22,783.69929
Overall Steps per Second: 10,715.75610

Timestep Collection Time: 2.19473
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.66640

Cumulative Model Updates: 133,074
Cumulative Timesteps: 1,109,897,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1109897712...
Checkpoint 1109897712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.27232
Policy Entropy: 3.14054
Value Function Loss: 0.00429

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.58768
Value Function Update Magnitude: 0.57241

Collected Steps per Second: 23,103.03319
Overall Steps per Second: 10,906.93883

Timestep Collection Time: 2.16474
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.58534

Cumulative Model Updates: 133,080
Cumulative Timesteps: 1,109,947,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.97324
Policy Entropy: 3.14274
Value Function Loss: 0.00397

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.58782
Value Function Update Magnitude: 0.57408

Collected Steps per Second: 22,580.68682
Overall Steps per Second: 10,668.74434

Timestep Collection Time: 2.21437
Timestep Consumption Time: 2.47240
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.68677

Cumulative Model Updates: 133,086
Cumulative Timesteps: 1,109,997,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1109997726...
Checkpoint 1109997726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,590.40132
Policy Entropy: 3.14076
Value Function Loss: 0.00401

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.58553
Value Function Update Magnitude: 0.53879

Collected Steps per Second: 22,655.02115
Overall Steps per Second: 10,796.96038

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.42421
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.63149

Cumulative Model Updates: 133,092
Cumulative Timesteps: 1,110,047,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.86633
Policy Entropy: 3.13394
Value Function Loss: 0.00405

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.58401
Value Function Update Magnitude: 0.50754

Collected Steps per Second: 22,987.01292
Overall Steps per Second: 10,856.18295

Timestep Collection Time: 2.17592
Timestep Consumption Time: 2.43140
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.60733

Cumulative Model Updates: 133,098
Cumulative Timesteps: 1,110,097,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1110097750...
Checkpoint 1110097750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.11487
Policy Entropy: 3.12681
Value Function Loss: 0.00425

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.58689
Value Function Update Magnitude: 0.50636

Collected Steps per Second: 22,754.85430
Overall Steps per Second: 10,763.03024

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.44879
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.64665

Cumulative Model Updates: 133,104
Cumulative Timesteps: 1,110,147,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.28542
Policy Entropy: 3.13051
Value Function Loss: 0.00408

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.58684
Value Function Update Magnitude: 0.52125

Collected Steps per Second: 23,061.66792
Overall Steps per Second: 10,860.14437

Timestep Collection Time: 2.16845
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.60473

Cumulative Model Updates: 133,110
Cumulative Timesteps: 1,110,197,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1110197770...
Checkpoint 1110197770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.89554
Policy Entropy: 3.13548
Value Function Loss: 0.00405

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.52215

Collected Steps per Second: 22,890.49308
Overall Steps per Second: 10,668.63103

Timestep Collection Time: 2.18536
Timestep Consumption Time: 2.50353
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.68889

Cumulative Model Updates: 133,116
Cumulative Timesteps: 1,110,247,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.39043
Policy Entropy: 3.13440
Value Function Loss: 0.00400

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.50638

Collected Steps per Second: 23,020.27563
Overall Steps per Second: 10,807.44273

Timestep Collection Time: 2.17252
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.62755

Cumulative Model Updates: 133,122
Cumulative Timesteps: 1,110,297,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1110297806...
Checkpoint 1110297806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.74958
Policy Entropy: 3.13416
Value Function Loss: 0.00421

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.58019
Value Function Update Magnitude: 0.50948

Collected Steps per Second: 22,671.98944
Overall Steps per Second: 10,770.74591

Timestep Collection Time: 2.20554
Timestep Consumption Time: 2.43703
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.64258

Cumulative Model Updates: 133,128
Cumulative Timesteps: 1,110,347,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.95701
Policy Entropy: 3.13214
Value Function Loss: 0.00409

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.51894

Collected Steps per Second: 22,936.03537
Overall Steps per Second: 10,840.33181

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.61443

Cumulative Model Updates: 133,134
Cumulative Timesteps: 1,110,397,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1110397832...
Checkpoint 1110397832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.67480
Policy Entropy: 3.13071
Value Function Loss: 0.00373

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.51461

Collected Steps per Second: 22,438.07689
Overall Steps per Second: 10,710.15516

Timestep Collection Time: 2.22871
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.66921

Cumulative Model Updates: 133,140
Cumulative Timesteps: 1,110,447,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.21885
Policy Entropy: 3.12934
Value Function Loss: 0.00400

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.49952

Collected Steps per Second: 22,598.69747
Overall Steps per Second: 10,772.47708

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.42943
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.64239

Cumulative Model Updates: 133,146
Cumulative Timesteps: 1,110,497,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1110497850...
Checkpoint 1110497850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.15552
Policy Entropy: 3.12737
Value Function Loss: 0.00439

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.51094

Collected Steps per Second: 22,892.45129
Overall Steps per Second: 10,751.88618

Timestep Collection Time: 2.18509
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.65239

Cumulative Model Updates: 133,152
Cumulative Timesteps: 1,110,547,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.96360
Policy Entropy: 3.12860
Value Function Loss: 0.00439

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.57949
Value Function Update Magnitude: 0.52062

Collected Steps per Second: 22,331.44979
Overall Steps per Second: 10,598.29157

Timestep Collection Time: 2.23989
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.71963

Cumulative Model Updates: 133,158
Cumulative Timesteps: 1,110,597,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1110597892...
Checkpoint 1110597892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.35326
Policy Entropy: 3.14006
Value Function Loss: 0.00400

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.57546
Value Function Update Magnitude: 0.51539

Collected Steps per Second: 22,862.48954
Overall Steps per Second: 10,842.08344

Timestep Collection Time: 2.18795
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.61369

Cumulative Model Updates: 133,164
Cumulative Timesteps: 1,110,647,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.68853
Policy Entropy: 3.13437
Value Function Loss: 0.00417

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.57989
Value Function Update Magnitude: 0.51846

Collected Steps per Second: 22,982.04007
Overall Steps per Second: 10,770.77230

Timestep Collection Time: 2.17666
Timestep Consumption Time: 2.46776
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.64442

Cumulative Model Updates: 133,170
Cumulative Timesteps: 1,110,697,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1110697938...
Checkpoint 1110697938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,279.20847
Policy Entropy: 3.13911
Value Function Loss: 0.00382

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.58298
Value Function Update Magnitude: 0.52681

Collected Steps per Second: 23,039.24080
Overall Steps per Second: 10,860.38559

Timestep Collection Time: 2.17021
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.60389

Cumulative Model Updates: 133,176
Cumulative Timesteps: 1,110,747,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.06858
Policy Entropy: 3.11431
Value Function Loss: 0.00412

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.58317
Value Function Update Magnitude: 0.51152

Collected Steps per Second: 22,846.09415
Overall Steps per Second: 10,822.44059

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.62262

Cumulative Model Updates: 133,182
Cumulative Timesteps: 1,110,797,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1110797966...
Checkpoint 1110797966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.97370
Policy Entropy: 3.11274
Value Function Loss: 0.00402

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.58796
Value Function Update Magnitude: 0.52052

Collected Steps per Second: 22,713.34383
Overall Steps per Second: 10,790.32021

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.43380
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.63638

Cumulative Model Updates: 133,188
Cumulative Timesteps: 1,110,847,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.07726
Policy Entropy: 3.11118
Value Function Loss: 0.00419

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.59179
Value Function Update Magnitude: 0.53586

Collected Steps per Second: 23,062.24704
Overall Steps per Second: 10,788.44041

Timestep Collection Time: 2.16900
Timestep Consumption Time: 2.46763
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.63663

Cumulative Model Updates: 133,194
Cumulative Timesteps: 1,110,898,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1110898016...
Checkpoint 1110898016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.35245
Policy Entropy: 3.10866
Value Function Loss: 0.00429

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.59091
Value Function Update Magnitude: 0.54858

Collected Steps per Second: 22,864.94183
Overall Steps per Second: 10,732.40108

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.66047

Cumulative Model Updates: 133,200
Cumulative Timesteps: 1,110,948,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,399.40107
Policy Entropy: 3.11061
Value Function Loss: 0.00436

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.54127

Collected Steps per Second: 22,675.58183
Overall Steps per Second: 10,795.00878

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.63622

Cumulative Model Updates: 133,206
Cumulative Timesteps: 1,110,998,082

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1110998082...
Checkpoint 1110998082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.61376
Policy Entropy: 3.13169
Value Function Loss: 0.00440

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.58510
Value Function Update Magnitude: 0.55494

Collected Steps per Second: 22,866.02930
Overall Steps per Second: 10,747.83551

Timestep Collection Time: 2.18709
Timestep Consumption Time: 2.46594
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.65303

Cumulative Model Updates: 133,212
Cumulative Timesteps: 1,111,048,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.23246
Policy Entropy: 3.14966
Value Function Loss: 0.00424

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.57958
Value Function Update Magnitude: 0.57895

Collected Steps per Second: 22,592.73872
Overall Steps per Second: 10,640.92913

Timestep Collection Time: 2.21443
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70166

Cumulative Model Updates: 133,218
Cumulative Timesteps: 1,111,098,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1111098122...
Checkpoint 1111098122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.11417
Policy Entropy: 3.15556
Value Function Loss: 0.00414

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.60169

Collected Steps per Second: 23,209.94225
Overall Steps per Second: 10,931.92568

Timestep Collection Time: 2.15459
Timestep Consumption Time: 2.41990
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.57449

Cumulative Model Updates: 133,224
Cumulative Timesteps: 1,111,148,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.43123
Policy Entropy: 3.16841
Value Function Loss: 0.00418

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.58636

Collected Steps per Second: 22,740.67510
Overall Steps per Second: 10,835.29731

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.41662
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.61602

Cumulative Model Updates: 133,230
Cumulative Timesteps: 1,111,198,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1111198146...
Checkpoint 1111198146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.38679
Policy Entropy: 3.16136
Value Function Loss: 0.00419

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.58567
Value Function Update Magnitude: 0.58183

Collected Steps per Second: 22,861.68289
Overall Steps per Second: 10,667.90053

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.68902

Cumulative Model Updates: 133,236
Cumulative Timesteps: 1,111,248,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.44782
Policy Entropy: 3.16620
Value Function Loss: 0.00428

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.57633

Collected Steps per Second: 22,979.94242
Overall Steps per Second: 10,858.42495

Timestep Collection Time: 2.17581
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.60472

Cumulative Model Updates: 133,242
Cumulative Timesteps: 1,111,298,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1111298168...
Checkpoint 1111298168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.23280
Policy Entropy: 3.15838
Value Function Loss: 0.00419

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.56187

Collected Steps per Second: 22,649.01060
Overall Steps per Second: 10,740.33671

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.44892
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.65758

Cumulative Model Updates: 133,248
Cumulative Timesteps: 1,111,348,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.42259
Policy Entropy: 3.17352
Value Function Loss: 0.00403

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.56128
Value Function Update Magnitude: 0.53413

Collected Steps per Second: 22,886.98839
Overall Steps per Second: 10,762.42813

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.64598

Cumulative Model Updates: 133,254
Cumulative Timesteps: 1,111,398,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1111398194...
Checkpoint 1111398194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,268.97705
Policy Entropy: 3.17926
Value Function Loss: 0.00398

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.55191

Collected Steps per Second: 22,410.03353
Overall Steps per Second: 10,670.84766

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.45501
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.68660

Cumulative Model Updates: 133,260
Cumulative Timesteps: 1,111,448,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,420.93527
Policy Entropy: 3.17940
Value Function Loss: 0.00385

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.57445
Value Function Update Magnitude: 0.57814

Collected Steps per Second: 23,130.80874
Overall Steps per Second: 10,684.57559

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.51913
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.68170

Cumulative Model Updates: 133,266
Cumulative Timesteps: 1,111,498,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1111498226...
Checkpoint 1111498226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.00050
Policy Entropy: 3.16546
Value Function Loss: 0.00386

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.58379

Collected Steps per Second: 22,626.56438
Overall Steps per Second: 10,546.26329

Timestep Collection Time: 2.21041
Timestep Consumption Time: 2.53193
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.74234

Cumulative Model Updates: 133,272
Cumulative Timesteps: 1,111,548,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.90729
Policy Entropy: 3.16084
Value Function Loss: 0.00381

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.57398
Value Function Update Magnitude: 0.56770

Collected Steps per Second: 22,998.15631
Overall Steps per Second: 10,868.27645

Timestep Collection Time: 2.17461
Timestep Consumption Time: 2.42704
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.60165

Cumulative Model Updates: 133,278
Cumulative Timesteps: 1,111,598,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1111598252...
Checkpoint 1111598252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.66807
Policy Entropy: 3.16464
Value Function Loss: 0.00357

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.56820
Value Function Update Magnitude: 0.54858

Collected Steps per Second: 22,910.30731
Overall Steps per Second: 10,656.91135

Timestep Collection Time: 2.18251
Timestep Consumption Time: 2.50947
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.69198

Cumulative Model Updates: 133,284
Cumulative Timesteps: 1,111,648,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.97054
Policy Entropy: 3.17092
Value Function Loss: 0.00366

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.51825

Collected Steps per Second: 22,791.61241
Overall Steps per Second: 10,758.05540

Timestep Collection Time: 2.19379
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.64768

Cumulative Model Updates: 133,290
Cumulative Timesteps: 1,111,698,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1111698254...
Checkpoint 1111698254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,084.68459
Policy Entropy: 3.16733
Value Function Loss: 0.00348

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.50457

Collected Steps per Second: 22,537.94774
Overall Steps per Second: 10,777.34684

Timestep Collection Time: 2.21937
Timestep Consumption Time: 2.42185
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.64122

Cumulative Model Updates: 133,296
Cumulative Timesteps: 1,111,748,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.61741
Policy Entropy: 3.17574
Value Function Loss: 0.00372

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.53265

Collected Steps per Second: 22,877.50351
Overall Steps per Second: 10,883.26568

Timestep Collection Time: 2.18573
Timestep Consumption Time: 2.40885
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.59458

Cumulative Model Updates: 133,302
Cumulative Timesteps: 1,111,798,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1111798278...
Checkpoint 1111798278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.96901
Policy Entropy: 3.16698
Value Function Loss: 0.00382

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.57651
Value Function Update Magnitude: 0.52281

Collected Steps per Second: 22,405.20232
Overall Steps per Second: 10,633.04331

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.70270

Cumulative Model Updates: 133,308
Cumulative Timesteps: 1,111,848,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.94107
Policy Entropy: 3.15812
Value Function Loss: 0.00410

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.54260

Collected Steps per Second: 22,941.48961
Overall Steps per Second: 10,860.91610

Timestep Collection Time: 2.17998
Timestep Consumption Time: 2.42479
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.60477

Cumulative Model Updates: 133,314
Cumulative Timesteps: 1,111,898,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1111898294...
Checkpoint 1111898294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,122.20842
Policy Entropy: 3.15304
Value Function Loss: 0.00401

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 22,647.89683
Overall Steps per Second: 10,661.81114

Timestep Collection Time: 2.20859
Timestep Consumption Time: 2.48292
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.69151

Cumulative Model Updates: 133,320
Cumulative Timesteps: 1,111,948,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.01617
Policy Entropy: 3.16781
Value Function Loss: 0.00352

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.55489
Value Function Update Magnitude: 0.55142

Collected Steps per Second: 22,725.36395
Overall Steps per Second: 10,613.77231

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.71124

Cumulative Model Updates: 133,326
Cumulative Timesteps: 1,111,998,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1111998318...
Checkpoint 1111998318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.53992
Policy Entropy: 3.16565
Value Function Loss: 0.00404

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.52538

Collected Steps per Second: 22,526.58753
Overall Steps per Second: 10,495.30302

Timestep Collection Time: 2.22066
Timestep Consumption Time: 2.54566
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.76632

Cumulative Model Updates: 133,332
Cumulative Timesteps: 1,112,048,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.18855
Policy Entropy: 3.14291
Value Function Loss: 0.00444

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.57256
Value Function Update Magnitude: 0.54762

Collected Steps per Second: 22,925.46575
Overall Steps per Second: 10,806.82663

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.62967

Cumulative Model Updates: 133,338
Cumulative Timesteps: 1,112,098,374

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1112098374...
Checkpoint 1112098374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.35963
Policy Entropy: 3.14090
Value Function Loss: 0.00447

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.55674

Collected Steps per Second: 22,729.89265
Overall Steps per Second: 10,771.35077

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.44239
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.64231

Cumulative Model Updates: 133,344
Cumulative Timesteps: 1,112,148,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.59594
Policy Entropy: 3.13919
Value Function Loss: 0.00402

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.58498
Value Function Update Magnitude: 0.59205

Collected Steps per Second: 22,612.36480
Overall Steps per Second: 10,780.26687

Timestep Collection Time: 2.21153
Timestep Consumption Time: 2.42731
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.63885

Cumulative Model Updates: 133,350
Cumulative Timesteps: 1,112,198,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1112198386...
Checkpoint 1112198386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.72290
Policy Entropy: 3.14786
Value Function Loss: 0.00372

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.56516

Collected Steps per Second: 22,975.66045
Overall Steps per Second: 10,724.37896

Timestep Collection Time: 2.17656
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.66302

Cumulative Model Updates: 133,356
Cumulative Timesteps: 1,112,248,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.08900
Policy Entropy: 3.14989
Value Function Loss: 0.00389

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.53934

Collected Steps per Second: 22,903.23662
Overall Steps per Second: 10,824.36124

Timestep Collection Time: 2.18397
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.62106

Cumulative Model Updates: 133,362
Cumulative Timesteps: 1,112,298,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1112298414...
Checkpoint 1112298414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.75259
Policy Entropy: 3.15850
Value Function Loss: 0.00387

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.53349

Collected Steps per Second: 22,707.50580
Overall Steps per Second: 10,742.54325

Timestep Collection Time: 2.20306
Timestep Consumption Time: 2.45375
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.65681

Cumulative Model Updates: 133,368
Cumulative Timesteps: 1,112,348,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.47708
Policy Entropy: 3.14992
Value Function Loss: 0.00377

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 22,640.88518
Overall Steps per Second: 10,560.82388

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.52659
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.73543

Cumulative Model Updates: 133,374
Cumulative Timesteps: 1,112,398,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1112398450...
Checkpoint 1112398450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.79853
Policy Entropy: 3.15798
Value Function Loss: 0.00387

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.56205
Value Function Update Magnitude: 0.54249

Collected Steps per Second: 22,954.76466
Overall Steps per Second: 10,883.53906

Timestep Collection Time: 2.17907
Timestep Consumption Time: 2.41686
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.59593

Cumulative Model Updates: 133,380
Cumulative Timesteps: 1,112,448,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.61179
Policy Entropy: 3.14498
Value Function Loss: 0.00405

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.56370

Collected Steps per Second: 23,008.36010
Overall Steps per Second: 10,699.59867

Timestep Collection Time: 2.17399
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.67494

Cumulative Model Updates: 133,386
Cumulative Timesteps: 1,112,498,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1112498490...
Checkpoint 1112498490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.05428
Policy Entropy: 3.15430
Value Function Loss: 0.00405

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.58761

Collected Steps per Second: 22,824.90063
Overall Steps per Second: 10,625.32847

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.51625
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.70781

Cumulative Model Updates: 133,392
Cumulative Timesteps: 1,112,548,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.60537
Policy Entropy: 3.15063
Value Function Loss: 0.00405

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.58133
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 22,761.05930
Overall Steps per Second: 10,772.55067

Timestep Collection Time: 2.19735
Timestep Consumption Time: 2.44538
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.64273

Cumulative Model Updates: 133,398
Cumulative Timesteps: 1,112,598,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1112598526...
Checkpoint 1112598526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.40796
Policy Entropy: 3.14490
Value Function Loss: 0.00394

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.56035

Collected Steps per Second: 22,732.36089
Overall Steps per Second: 10,621.37124

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.71013

Cumulative Model Updates: 133,404
Cumulative Timesteps: 1,112,648,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.84312
Policy Entropy: 3.14349
Value Function Loss: 0.00399

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.56892
Value Function Update Magnitude: 0.53621

Collected Steps per Second: 22,954.06456
Overall Steps per Second: 10,653.00315

Timestep Collection Time: 2.17896
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.69501

Cumulative Model Updates: 133,410
Cumulative Timesteps: 1,112,698,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1112698570...
Checkpoint 1112698570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.62441
Policy Entropy: 3.12935
Value Function Loss: 0.00438

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.58353
Value Function Update Magnitude: 0.53321

Collected Steps per Second: 22,778.91356
Overall Steps per Second: 10,822.34591

Timestep Collection Time: 2.19501
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.62007

Cumulative Model Updates: 133,416
Cumulative Timesteps: 1,112,748,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.84936
Policy Entropy: 3.12634
Value Function Loss: 0.00438

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10608
Policy Update Magnitude: 0.59904
Value Function Update Magnitude: 0.57834

Collected Steps per Second: 22,879.62784
Overall Steps per Second: 10,615.72274

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.71226

Cumulative Model Updates: 133,422
Cumulative Timesteps: 1,112,798,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1112798594...
Checkpoint 1112798594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.41338
Policy Entropy: 3.12516
Value Function Loss: 0.00426

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.59851
Value Function Update Magnitude: 0.59869

Collected Steps per Second: 22,862.63231
Overall Steps per Second: 10,738.86786

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.65747

Cumulative Model Updates: 133,428
Cumulative Timesteps: 1,112,848,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.90158
Policy Entropy: 3.14496
Value Function Loss: 0.00391

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.58245
Value Function Update Magnitude: 0.57556

Collected Steps per Second: 23,131.87671
Overall Steps per Second: 10,723.12301

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.66562

Cumulative Model Updates: 133,434
Cumulative Timesteps: 1,112,898,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1112898640...
Checkpoint 1112898640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.64087
Policy Entropy: 3.14685
Value Function Loss: 0.00399

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.57997
Value Function Update Magnitude: 0.55107

Collected Steps per Second: 22,810.43304
Overall Steps per Second: 10,632.92857

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.70444

Cumulative Model Updates: 133,440
Cumulative Timesteps: 1,112,948,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.87536
Policy Entropy: 3.14680
Value Function Loss: 0.00414

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.58695
Value Function Update Magnitude: 0.55144

Collected Steps per Second: 22,927.08116
Overall Steps per Second: 10,876.37873

Timestep Collection Time: 2.18214
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.59988

Cumulative Model Updates: 133,446
Cumulative Timesteps: 1,112,998,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1112998692...
Checkpoint 1112998692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.50632
Policy Entropy: 3.14634
Value Function Loss: 0.00398

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.58502
Value Function Update Magnitude: 0.58007

Collected Steps per Second: 22,629.10021
Overall Steps per Second: 10,721.14088

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.45483
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.66499

Cumulative Model Updates: 133,452
Cumulative Timesteps: 1,113,048,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.16482
Policy Entropy: 3.14348
Value Function Loss: 0.00392

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.57807
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 22,975.14585
Overall Steps per Second: 10,792.73858

Timestep Collection Time: 2.17653
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.63330

Cumulative Model Updates: 133,458
Cumulative Timesteps: 1,113,098,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1113098712...
Checkpoint 1113098712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.85256
Policy Entropy: 3.14326
Value Function Loss: 0.00424

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.58521
Value Function Update Magnitude: 0.55377

Collected Steps per Second: 22,439.49078
Overall Steps per Second: 10,753.67750

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.65180

Cumulative Model Updates: 133,464
Cumulative Timesteps: 1,113,148,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161.41607
Policy Entropy: 3.15286
Value Function Loss: 0.00433

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.58758
Value Function Update Magnitude: 0.55003

Collected Steps per Second: 23,063.86092
Overall Steps per Second: 10,869.67674

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.60050

Cumulative Model Updates: 133,470
Cumulative Timesteps: 1,113,198,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1113198742...
Checkpoint 1113198742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.95427
Policy Entropy: 3.15162
Value Function Loss: 0.00443

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.53549

Collected Steps per Second: 22,489.53596
Overall Steps per Second: 10,680.01232

Timestep Collection Time: 2.22388
Timestep Consumption Time: 2.45907
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.68295

Cumulative Model Updates: 133,476
Cumulative Timesteps: 1,113,248,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.10632
Policy Entropy: 3.16810
Value Function Loss: 0.00426

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.51032

Collected Steps per Second: 23,402.27293
Overall Steps per Second: 10,886.08288

Timestep Collection Time: 2.13723
Timestep Consumption Time: 2.45726
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.59449

Cumulative Model Updates: 133,482
Cumulative Timesteps: 1,113,298,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1113298772...
Checkpoint 1113298772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.22930
Policy Entropy: 3.15004
Value Function Loss: 0.00445

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.57718
Value Function Update Magnitude: 0.51310

Collected Steps per Second: 22,332.97290
Overall Steps per Second: 10,648.16994

Timestep Collection Time: 2.24001
Timestep Consumption Time: 2.45808
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.69808

Cumulative Model Updates: 133,488
Cumulative Timesteps: 1,113,348,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.88892
Policy Entropy: 3.16871
Value Function Loss: 0.00420

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.57396
Value Function Update Magnitude: 0.52720

Collected Steps per Second: 22,932.84776
Overall Steps per Second: 10,685.09983

Timestep Collection Time: 2.18089
Timestep Consumption Time: 2.49983
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.68072

Cumulative Model Updates: 133,494
Cumulative Timesteps: 1,113,398,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1113398812...
Checkpoint 1113398812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875.02869
Policy Entropy: 3.17933
Value Function Loss: 0.00409

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.13716
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.52076

Collected Steps per Second: 22,570.03120
Overall Steps per Second: 10,610.44739

Timestep Collection Time: 2.21586
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.71347

Cumulative Model Updates: 133,500
Cumulative Timesteps: 1,113,448,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.10394
Policy Entropy: 3.18932
Value Function Loss: 0.00376

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.52857

Collected Steps per Second: 22,660.95077
Overall Steps per Second: 10,709.48565

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.66988

Cumulative Model Updates: 133,506
Cumulative Timesteps: 1,113,498,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1113498836...
Checkpoint 1113498836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,284.20113
Policy Entropy: 3.18478
Value Function Loss: 0.00368

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.51286

Collected Steps per Second: 22,791.20556
Overall Steps per Second: 10,632.76855

Timestep Collection Time: 2.19488
Timestep Consumption Time: 2.50982
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.70470

Cumulative Model Updates: 133,512
Cumulative Timesteps: 1,113,548,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.61475
Policy Entropy: 3.17770
Value Function Loss: 0.00373

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.52294

Collected Steps per Second: 22,892.98375
Overall Steps per Second: 10,851.58067

Timestep Collection Time: 2.18451
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.60855

Cumulative Model Updates: 133,518
Cumulative Timesteps: 1,113,598,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1113598870...
Checkpoint 1113598870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302.73728
Policy Entropy: 3.16332
Value Function Loss: 0.00421

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.58233
Value Function Update Magnitude: 0.51977

Collected Steps per Second: 22,799.25088
Overall Steps per Second: 10,699.87665

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.67538

Cumulative Model Updates: 133,524
Cumulative Timesteps: 1,113,648,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.56802
Policy Entropy: 3.16359
Value Function Loss: 0.00419

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.57929
Value Function Update Magnitude: 0.52635

Collected Steps per Second: 23,044.85226
Overall Steps per Second: 10,887.61613

Timestep Collection Time: 2.17003
Timestep Consumption Time: 2.42308
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.59311

Cumulative Model Updates: 133,530
Cumulative Timesteps: 1,113,698,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1113698904...
Checkpoint 1113698904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.17118
Policy Entropy: 3.16249
Value Function Loss: 0.00407

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.54099

Collected Steps per Second: 22,523.29331
Overall Steps per Second: 10,628.96922

Timestep Collection Time: 2.22072
Timestep Consumption Time: 2.48510
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.70582

Cumulative Model Updates: 133,536
Cumulative Timesteps: 1,113,748,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,055.10383
Policy Entropy: 3.16761
Value Function Loss: 0.00414

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.57619
Value Function Update Magnitude: 0.55317

Collected Steps per Second: 22,818.43542
Overall Steps per Second: 10,659.83591

Timestep Collection Time: 2.19156
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.69125

Cumulative Model Updates: 133,542
Cumulative Timesteps: 1,113,798,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1113798930...
Checkpoint 1113798930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.71922
Policy Entropy: 3.18177
Value Function Loss: 0.00416

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.57840
Value Function Update Magnitude: 0.56182

Collected Steps per Second: 22,827.24469
Overall Steps per Second: 10,667.64402

Timestep Collection Time: 2.19159
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68970

Cumulative Model Updates: 133,548
Cumulative Timesteps: 1,113,848,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.88925
Policy Entropy: 3.17664
Value Function Loss: 0.00418

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.55072

Collected Steps per Second: 23,175.46730
Overall Steps per Second: 10,697.30146

Timestep Collection Time: 2.15745
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.67408

Cumulative Model Updates: 133,554
Cumulative Timesteps: 1,113,898,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1113898958...
Checkpoint 1113898958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,566.53726
Policy Entropy: 3.17981
Value Function Loss: 0.00406

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.57043
Value Function Update Magnitude: 0.54021

Collected Steps per Second: 22,539.98447
Overall Steps per Second: 10,650.56215

Timestep Collection Time: 2.21872
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.69553

Cumulative Model Updates: 133,560
Cumulative Timesteps: 1,113,948,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101.01486
Policy Entropy: 3.16119
Value Function Loss: 0.00411

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.57986
Value Function Update Magnitude: 0.54155

Collected Steps per Second: 22,716.46625
Overall Steps per Second: 10,584.76196

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.52353
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.72528

Cumulative Model Updates: 133,566
Cumulative Timesteps: 1,113,998,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1113998984...
Checkpoint 1113998984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.51179
Policy Entropy: 3.16268
Value Function Loss: 0.00382

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.54552

Collected Steps per Second: 22,804.91934
Overall Steps per Second: 10,620.62859

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.51551
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.70820

Cumulative Model Updates: 133,572
Cumulative Timesteps: 1,114,048,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.26706
Policy Entropy: 3.16400
Value Function Loss: 0.00387

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.57457
Value Function Update Magnitude: 0.51935

Collected Steps per Second: 23,086.04703
Overall Steps per Second: 10,790.35149

Timestep Collection Time: 2.16590
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.63395

Cumulative Model Updates: 133,578
Cumulative Timesteps: 1,114,098,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1114098990...
Checkpoint 1114098990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.23762
Policy Entropy: 3.16372
Value Function Loss: 0.00390

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.57518
Value Function Update Magnitude: 0.51396

Collected Steps per Second: 22,673.52303
Overall Steps per Second: 10,614.36758

Timestep Collection Time: 2.20619
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.71267

Cumulative Model Updates: 133,584
Cumulative Timesteps: 1,114,149,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.96244
Policy Entropy: 3.15485
Value Function Loss: 0.00404

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.54918

Collected Steps per Second: 22,637.64036
Overall Steps per Second: 10,636.96001

Timestep Collection Time: 2.20968
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.70266

Cumulative Model Updates: 133,590
Cumulative Timesteps: 1,114,199,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1114199034...
Checkpoint 1114199034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.09119
Policy Entropy: 3.15769
Value Function Loss: 0.00413

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.57512
Value Function Update Magnitude: 0.54748

Collected Steps per Second: 22,784.22023
Overall Steps per Second: 10,610.78186

Timestep Collection Time: 2.19520
Timestep Consumption Time: 2.51849
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.71370

Cumulative Model Updates: 133,596
Cumulative Timesteps: 1,114,249,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.58812
Policy Entropy: 3.15084
Value Function Loss: 0.00424

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.54081

Collected Steps per Second: 22,939.63320
Overall Steps per Second: 10,811.99094

Timestep Collection Time: 2.18085
Timestep Consumption Time: 2.44623
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.62708

Cumulative Model Updates: 133,602
Cumulative Timesteps: 1,114,299,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1114299078...
Checkpoint 1114299078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.99752
Policy Entropy: 3.15205
Value Function Loss: 0.00427

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.52911

Collected Steps per Second: 22,629.23542
Overall Steps per Second: 10,635.60089

Timestep Collection Time: 2.21059
Timestep Consumption Time: 2.49286
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.70345

Cumulative Model Updates: 133,608
Cumulative Timesteps: 1,114,349,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.12699
Policy Entropy: 3.14857
Value Function Loss: 0.00392

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.57096
Value Function Update Magnitude: 0.52829

Collected Steps per Second: 23,073.60801
Overall Steps per Second: 10,920.68959

Timestep Collection Time: 2.16888
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.58249

Cumulative Model Updates: 133,614
Cumulative Timesteps: 1,114,399,146

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1114399146...
Checkpoint 1114399146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.22710
Policy Entropy: 3.15066
Value Function Loss: 0.00365

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.55513
Value Function Update Magnitude: 0.49745

Collected Steps per Second: 22,545.09470
Overall Steps per Second: 10,643.98379

Timestep Collection Time: 2.21831
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69862

Cumulative Model Updates: 133,620
Cumulative Timesteps: 1,114,449,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.97097
Policy Entropy: 3.14733
Value Function Loss: 0.00375

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.55160
Value Function Update Magnitude: 0.46840

Collected Steps per Second: 23,167.06452
Overall Steps per Second: 10,903.21448

Timestep Collection Time: 2.15936
Timestep Consumption Time: 2.42883
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.58819

Cumulative Model Updates: 133,626
Cumulative Timesteps: 1,114,499,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1114499184...
Checkpoint 1114499184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.56558
Policy Entropy: 3.14762
Value Function Loss: 0.00397

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.47682

Collected Steps per Second: 22,335.31245
Overall Steps per Second: 10,653.76563

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.45614
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.69618

Cumulative Model Updates: 133,632
Cumulative Timesteps: 1,114,549,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.53837
Policy Entropy: 3.14799
Value Function Loss: 0.00401

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.48996

Collected Steps per Second: 23,012.49359
Overall Steps per Second: 10,826.04207

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.44664
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.62016

Cumulative Model Updates: 133,638
Cumulative Timesteps: 1,114,599,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1114599234...
Checkpoint 1114599234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.23914
Policy Entropy: 3.14703
Value Function Loss: 0.00374

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.56011
Value Function Update Magnitude: 0.49050

Collected Steps per Second: 22,803.65438
Overall Steps per Second: 10,684.34318

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.68255

Cumulative Model Updates: 133,644
Cumulative Timesteps: 1,114,649,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.10520
Policy Entropy: 3.14637
Value Function Loss: 0.00383

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.57350
Value Function Update Magnitude: 0.52787

Collected Steps per Second: 23,199.35047
Overall Steps per Second: 10,866.90997

Timestep Collection Time: 2.15566
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.60204

Cumulative Model Updates: 133,650
Cumulative Timesteps: 1,114,699,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1114699274...
Checkpoint 1114699274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,904.77819
Policy Entropy: 3.16452
Value Function Loss: 0.00386

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.53079

Collected Steps per Second: 22,589.00904
Overall Steps per Second: 10,656.28189

Timestep Collection Time: 2.21382
Timestep Consumption Time: 2.47900
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.69282

Cumulative Model Updates: 133,656
Cumulative Timesteps: 1,114,749,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.64132
Policy Entropy: 3.17970
Value Function Loss: 0.00379

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.52787

Collected Steps per Second: 22,885.59149
Overall Steps per Second: 10,841.80407

Timestep Collection Time: 2.18539
Timestep Consumption Time: 2.42768
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.61307

Cumulative Model Updates: 133,662
Cumulative Timesteps: 1,114,799,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1114799296...
Checkpoint 1114799296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.37639
Policy Entropy: 3.17920
Value Function Loss: 0.00411

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.57834
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 22,771.68844
Overall Steps per Second: 10,765.47712

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.64615

Cumulative Model Updates: 133,668
Cumulative Timesteps: 1,114,849,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.00303
Policy Entropy: 3.16030
Value Function Loss: 0.00419

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.58787
Value Function Update Magnitude: 0.55269

Collected Steps per Second: 23,148.54877
Overall Steps per Second: 10,889.19778

Timestep Collection Time: 2.16100
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.59391

Cumulative Model Updates: 133,674
Cumulative Timesteps: 1,114,899,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1114899338...
Checkpoint 1114899338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,330.91090
Policy Entropy: 3.15271
Value Function Loss: 0.00465

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.59883
Value Function Update Magnitude: 0.58401

Collected Steps per Second: 22,501.31660
Overall Steps per Second: 10,608.82828

Timestep Collection Time: 2.22316
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.71532

Cumulative Model Updates: 133,680
Cumulative Timesteps: 1,114,949,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.82227
Policy Entropy: 3.15837
Value Function Loss: 0.00456

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.59243
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 23,278.84013
Overall Steps per Second: 10,891.82565

Timestep Collection Time: 2.14882
Timestep Consumption Time: 2.44380
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.59262

Cumulative Model Updates: 133,686
Cumulative Timesteps: 1,114,999,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1114999384...
Checkpoint 1114999384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.54058
Policy Entropy: 3.16966
Value Function Loss: 0.00486

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.59388
Value Function Update Magnitude: 0.57219

Collected Steps per Second: 22,425.80333
Overall Steps per Second: 10,729.72701

Timestep Collection Time: 2.22975
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.66032

Cumulative Model Updates: 133,692
Cumulative Timesteps: 1,115,049,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.39185
Policy Entropy: 3.15913
Value Function Loss: 0.00460

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.60194
Value Function Update Magnitude: 0.58433

Collected Steps per Second: 23,397.68515
Overall Steps per Second: 10,881.15849

Timestep Collection Time: 2.13790
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.59712

Cumulative Model Updates: 133,698
Cumulative Timesteps: 1,115,099,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1115099410...
Checkpoint 1115099410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.22713
Policy Entropy: 3.16051
Value Function Loss: 0.00451

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.60247
Value Function Update Magnitude: 0.58025

Collected Steps per Second: 22,234.49369
Overall Steps per Second: 10,660.51052

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.69021

Cumulative Model Updates: 133,704
Cumulative Timesteps: 1,115,149,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.69560
Policy Entropy: 3.15866
Value Function Loss: 0.00424

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.59560
Value Function Update Magnitude: 0.56905

Collected Steps per Second: 22,862.97417
Overall Steps per Second: 10,784.84428

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.63836

Cumulative Model Updates: 133,710
Cumulative Timesteps: 1,115,199,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1115199434...
Checkpoint 1115199434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.61679
Policy Entropy: 3.14993
Value Function Loss: 0.00410

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.58955
Value Function Update Magnitude: 0.56043

Collected Steps per Second: 22,647.12833
Overall Steps per Second: 10,748.26673

Timestep Collection Time: 2.20832
Timestep Consumption Time: 2.44471
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.65303

Cumulative Model Updates: 133,716
Cumulative Timesteps: 1,115,249,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.49064
Policy Entropy: 3.14039
Value Function Loss: 0.00403

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.58969
Value Function Update Magnitude: 0.53258

Collected Steps per Second: 22,989.57111
Overall Steps per Second: 10,839.63937

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.43800
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.61307

Cumulative Model Updates: 133,722
Cumulative Timesteps: 1,115,299,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1115299450...
Checkpoint 1115299450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.42220
Policy Entropy: 3.13879
Value Function Loss: 0.00381

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.57699
Value Function Update Magnitude: 0.50751

Collected Steps per Second: 22,727.01977
Overall Steps per Second: 10,749.02700

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.45293
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.65419

Cumulative Model Updates: 133,728
Cumulative Timesteps: 1,115,349,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.64160
Policy Entropy: 3.13436
Value Function Loss: 0.00422

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.51096

Collected Steps per Second: 23,092.13334
Overall Steps per Second: 10,829.34992

Timestep Collection Time: 2.16585
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.61838

Cumulative Model Updates: 133,734
Cumulative Timesteps: 1,115,399,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115399492...
Checkpoint 1115399492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.89145
Policy Entropy: 3.14240
Value Function Loss: 0.00435

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.58749
Value Function Update Magnitude: 0.55958

Collected Steps per Second: 22,787.69603
Overall Steps per Second: 10,719.88188

Timestep Collection Time: 2.19531
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.66666

Cumulative Model Updates: 133,740
Cumulative Timesteps: 1,115,449,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.36467
Policy Entropy: 3.13082
Value Function Loss: 0.00448

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.60123
Value Function Update Magnitude: 0.56966

Collected Steps per Second: 22,684.66680
Overall Steps per Second: 10,678.87145

Timestep Collection Time: 2.20413
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.68214

Cumulative Model Updates: 133,746
Cumulative Timesteps: 1,115,499,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1115499518...
Checkpoint 1115499518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.54641
Policy Entropy: 3.14018
Value Function Loss: 0.00449

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.59144
Value Function Update Magnitude: 0.57074

Collected Steps per Second: 22,705.18544
Overall Steps per Second: 10,765.20835

Timestep Collection Time: 2.20293
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.64626

Cumulative Model Updates: 133,752
Cumulative Timesteps: 1,115,549,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.26636
Policy Entropy: 3.13266
Value Function Loss: 0.00431

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.58493
Value Function Update Magnitude: 0.55769

Collected Steps per Second: 22,532.19812
Overall Steps per Second: 10,593.58987

Timestep Collection Time: 2.21976
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.72135

Cumulative Model Updates: 133,758
Cumulative Timesteps: 1,115,599,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1115599552...
Checkpoint 1115599552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.86270
Policy Entropy: 3.12531
Value Function Loss: 0.00464

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.58835
Value Function Update Magnitude: 0.55051

Collected Steps per Second: 22,536.48905
Overall Steps per Second: 10,610.84986

Timestep Collection Time: 2.21862
Timestep Consumption Time: 2.49353
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.71216

Cumulative Model Updates: 133,764
Cumulative Timesteps: 1,115,649,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.86399
Policy Entropy: 3.12379
Value Function Loss: 0.00438

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.55218

Collected Steps per Second: 23,125.03163
Overall Steps per Second: 10,857.61532

Timestep Collection Time: 2.16346
Timestep Consumption Time: 2.44437
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.60783

Cumulative Model Updates: 133,770
Cumulative Timesteps: 1,115,699,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1115699582...
Checkpoint 1115699582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.12596
Policy Entropy: 3.12432
Value Function Loss: 0.00437

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.58509
Value Function Update Magnitude: 0.55103

Collected Steps per Second: 22,527.07316
Overall Steps per Second: 10,674.03286

Timestep Collection Time: 2.22026
Timestep Consumption Time: 2.46550
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.68576

Cumulative Model Updates: 133,776
Cumulative Timesteps: 1,115,749,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.49709
Policy Entropy: 3.14401
Value Function Loss: 0.00403

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.57118
Value Function Update Magnitude: 0.53318

Collected Steps per Second: 22,922.75900
Overall Steps per Second: 10,851.90444

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.60970

Cumulative Model Updates: 133,782
Cumulative Timesteps: 1,115,799,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1115799622...
Checkpoint 1115799622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,236.71263
Policy Entropy: 3.15118
Value Function Loss: 0.00417

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.57864
Value Function Update Magnitude: 0.53169

Collected Steps per Second: 22,633.40822
Overall Steps per Second: 10,767.92351

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.64695

Cumulative Model Updates: 133,788
Cumulative Timesteps: 1,115,849,660

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.67715
Policy Entropy: 3.14132
Value Function Loss: 0.00438

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.58225
Value Function Update Magnitude: 0.56356

Collected Steps per Second: 22,939.56589
Overall Steps per Second: 10,821.09441

Timestep Collection Time: 2.18025
Timestep Consumption Time: 2.44165
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.62190

Cumulative Model Updates: 133,794
Cumulative Timesteps: 1,115,899,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115899674...
Checkpoint 1115899674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.79362
Policy Entropy: 3.13253
Value Function Loss: 0.00424

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.59205
Value Function Update Magnitude: 0.59826

Collected Steps per Second: 22,453.06866
Overall Steps per Second: 10,675.94077

Timestep Collection Time: 2.22829
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.68643

Cumulative Model Updates: 133,800
Cumulative Timesteps: 1,115,949,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.83086
Policy Entropy: 3.13860
Value Function Loss: 0.00408

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.59060
Value Function Update Magnitude: 0.57035

Collected Steps per Second: 22,581.67198
Overall Steps per Second: 10,538.54395

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.53101
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.74582

Cumulative Model Updates: 133,806
Cumulative Timesteps: 1,115,999,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115999720...
Checkpoint 1115999720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.88532
Policy Entropy: 3.15959
Value Function Loss: 0.00416

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.58780
Value Function Update Magnitude: 0.54755

Collected Steps per Second: 22,808.91303
Overall Steps per Second: 10,602.22499

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.52457
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.71731

Cumulative Model Updates: 133,812
Cumulative Timesteps: 1,116,049,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.19129
Policy Entropy: 3.16385
Value Function Loss: 0.00435

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.59694
Value Function Update Magnitude: 0.56385

Collected Steps per Second: 23,109.79727
Overall Steps per Second: 10,818.04333

Timestep Collection Time: 2.16471
Timestep Consumption Time: 2.45960
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.62431

Cumulative Model Updates: 133,818
Cumulative Timesteps: 1,116,099,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1116099760...
Checkpoint 1116099760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.07941
Policy Entropy: 3.15216
Value Function Loss: 0.00454

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.59725
Value Function Update Magnitude: 0.59941

Collected Steps per Second: 22,545.12360
Overall Steps per Second: 10,665.12809

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.69005

Cumulative Model Updates: 133,824
Cumulative Timesteps: 1,116,149,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.71871
Policy Entropy: 3.13773
Value Function Loss: 0.00416

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.60374

Collected Steps per Second: 23,081.80289
Overall Steps per Second: 10,696.62372

Timestep Collection Time: 2.16638
Timestep Consumption Time: 2.50836
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.67475

Cumulative Model Updates: 133,830
Cumulative Timesteps: 1,116,199,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1116199784...
Checkpoint 1116199784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,057.94844
Policy Entropy: 3.14916
Value Function Loss: 0.00380

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.58143
Value Function Update Magnitude: 0.56452

Collected Steps per Second: 22,556.37335
Overall Steps per Second: 10,567.31621

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.51611
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.73384

Cumulative Model Updates: 133,836
Cumulative Timesteps: 1,116,249,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.01177
Policy Entropy: 3.15270
Value Function Loss: 0.00360

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.50800

Collected Steps per Second: 23,236.66753
Overall Steps per Second: 10,728.95516

Timestep Collection Time: 2.15220
Timestep Consumption Time: 2.50902
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.66122

Cumulative Model Updates: 133,842
Cumulative Timesteps: 1,116,299,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1116299818...
Checkpoint 1116299818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.35537
Policy Entropy: 3.15213
Value Function Loss: 0.00381

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.56416
Value Function Update Magnitude: 0.48859

Collected Steps per Second: 22,540.84345
Overall Steps per Second: 10,766.95647

Timestep Collection Time: 2.21944
Timestep Consumption Time: 2.42700
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.64644

Cumulative Model Updates: 133,848
Cumulative Timesteps: 1,116,349,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.04905
Policy Entropy: 3.14499
Value Function Loss: 0.00419

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.51069

Collected Steps per Second: 23,013.59772
Overall Steps per Second: 10,812.36818

Timestep Collection Time: 2.17306
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.62526

Cumulative Model Updates: 133,854
Cumulative Timesteps: 1,116,399,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1116399856...
Checkpoint 1116399856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.32933
Policy Entropy: 3.12386
Value Function Loss: 0.00430

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.53057

Collected Steps per Second: 22,737.28333
Overall Steps per Second: 10,665.93012

Timestep Collection Time: 2.19903
Timestep Consumption Time: 2.48879
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.68782

Cumulative Model Updates: 133,860
Cumulative Timesteps: 1,116,449,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.87538
Policy Entropy: 3.13076
Value Function Loss: 0.00418

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.58046
Value Function Update Magnitude: 0.55177

Collected Steps per Second: 23,140.03566
Overall Steps per Second: 10,857.63578

Timestep Collection Time: 2.16145
Timestep Consumption Time: 2.44508
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.60653

Cumulative Model Updates: 133,866
Cumulative Timesteps: 1,116,499,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1116499872...
Checkpoint 1116499872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.56112
Policy Entropy: 3.13467
Value Function Loss: 0.00405

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.57103
Value Function Update Magnitude: 0.54632

Collected Steps per Second: 22,801.71892
Overall Steps per Second: 10,680.18422

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.68250

Cumulative Model Updates: 133,872
Cumulative Timesteps: 1,116,549,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.00553
Policy Entropy: 3.15510
Value Function Loss: 0.00392

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.56515
Value Function Update Magnitude: 0.52807

Collected Steps per Second: 22,642.76375
Overall Steps per Second: 10,578.16031

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.72804

Cumulative Model Updates: 133,878
Cumulative Timesteps: 1,116,599,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1116599896...
Checkpoint 1116599896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.15890
Policy Entropy: 3.15135
Value Function Loss: 0.00405

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.56677
Value Function Update Magnitude: 0.51975

Collected Steps per Second: 22,818.33694
Overall Steps per Second: 10,745.78133

Timestep Collection Time: 2.19218
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65504

Cumulative Model Updates: 133,884
Cumulative Timesteps: 1,116,649,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.64948
Policy Entropy: 3.14946
Value Function Loss: 0.00420

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.54944

Collected Steps per Second: 23,311.00403
Overall Steps per Second: 10,785.96117

Timestep Collection Time: 2.14628
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.63862

Cumulative Model Updates: 133,890
Cumulative Timesteps: 1,116,699,950

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1116699950...
Checkpoint 1116699950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.82874
Policy Entropy: 3.15257
Value Function Loss: 0.00437

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.58400
Value Function Update Magnitude: 0.57462

Collected Steps per Second: 22,703.76140
Overall Steps per Second: 10,666.18166

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.48603
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.68884

Cumulative Model Updates: 133,896
Cumulative Timesteps: 1,116,749,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,901.61063
Policy Entropy: 3.15911
Value Function Loss: 0.00440

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.58670
Value Function Update Magnitude: 0.57204

Collected Steps per Second: 22,883.23762
Overall Steps per Second: 10,768.61663

Timestep Collection Time: 2.18597
Timestep Consumption Time: 2.45920
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.64516

Cumulative Model Updates: 133,902
Cumulative Timesteps: 1,116,799,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1116799984...
Checkpoint 1116799984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.56984
Policy Entropy: 3.15593
Value Function Loss: 0.00430

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.58194
Value Function Update Magnitude: 0.57937

Collected Steps per Second: 22,540.54048
Overall Steps per Second: 10,672.16069

Timestep Collection Time: 2.21876
Timestep Consumption Time: 2.46745
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.68621

Cumulative Model Updates: 133,908
Cumulative Timesteps: 1,116,849,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.28420
Policy Entropy: 3.15736
Value Function Loss: 0.00423

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.57015

Collected Steps per Second: 23,021.95162
Overall Steps per Second: 10,840.79798

Timestep Collection Time: 2.17184
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.61221

Cumulative Model Updates: 133,914
Cumulative Timesteps: 1,116,899,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1116899996...
Checkpoint 1116899996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.46116
Policy Entropy: 3.15457
Value Function Loss: 0.00423

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.57804
Value Function Update Magnitude: 0.54870

Collected Steps per Second: 22,220.59034
Overall Steps per Second: 10,661.85868

Timestep Collection Time: 2.25098
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.69130

Cumulative Model Updates: 133,920
Cumulative Timesteps: 1,116,950,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.20171
Policy Entropy: 3.16342
Value Function Loss: 0.00413

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.57951
Value Function Update Magnitude: 0.54963

Collected Steps per Second: 22,900.23613
Overall Steps per Second: 10,835.10159

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.43125
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.61463

Cumulative Model Updates: 133,926
Cumulative Timesteps: 1,117,000,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1117000014...
Checkpoint 1117000014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.68433
Policy Entropy: 3.15841
Value Function Loss: 0.00394

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.57313
Value Function Update Magnitude: 0.53327

Collected Steps per Second: 22,467.40080
Overall Steps per Second: 10,805.42888

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.40311
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.62971

Cumulative Model Updates: 133,932
Cumulative Timesteps: 1,117,050,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.88093
Policy Entropy: 3.16833
Value Function Loss: 0.00382

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.51593

Collected Steps per Second: 22,954.40254
Overall Steps per Second: 10,816.80786

Timestep Collection Time: 2.17858
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.62318

Cumulative Model Updates: 133,938
Cumulative Timesteps: 1,117,100,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1117100048...
Checkpoint 1117100048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.47913
Policy Entropy: 3.15776
Value Function Loss: 0.00395

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.57271
Value Function Update Magnitude: 0.51541

Collected Steps per Second: 22,592.80597
Overall Steps per Second: 10,662.43751

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.68973

Cumulative Model Updates: 133,944
Cumulative Timesteps: 1,117,150,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.68255
Policy Entropy: 3.14365
Value Function Loss: 0.00402

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.52112

Collected Steps per Second: 23,142.26232
Overall Steps per Second: 10,893.20515

Timestep Collection Time: 2.16150
Timestep Consumption Time: 2.43054
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.59204

Cumulative Model Updates: 133,950
Cumulative Timesteps: 1,117,200,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1117200074...
Checkpoint 1117200074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.71038
Policy Entropy: 3.14002
Value Function Loss: 0.00389

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.53696

Collected Steps per Second: 22,797.67429
Overall Steps per Second: 10,647.17931

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.69758

Cumulative Model Updates: 133,956
Cumulative Timesteps: 1,117,250,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.78660
Policy Entropy: 3.13715
Value Function Loss: 0.00386

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.57198
Value Function Update Magnitude: 0.52962

Collected Steps per Second: 23,025.07465
Overall Steps per Second: 10,884.51301

Timestep Collection Time: 2.17250
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.59570

Cumulative Model Updates: 133,962
Cumulative Timesteps: 1,117,300,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1117300112...
Checkpoint 1117300112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.95726
Policy Entropy: 3.15278
Value Function Loss: 0.00399

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.53448

Collected Steps per Second: 22,656.11405
Overall Steps per Second: 10,663.53260

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.68963

Cumulative Model Updates: 133,968
Cumulative Timesteps: 1,117,350,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.57481
Policy Entropy: 3.14419
Value Function Loss: 0.00432

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.58489
Value Function Update Magnitude: 0.55266

Collected Steps per Second: 22,901.12340
Overall Steps per Second: 10,856.51056

Timestep Collection Time: 2.18382
Timestep Consumption Time: 2.42281
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.60664

Cumulative Model Updates: 133,974
Cumulative Timesteps: 1,117,400,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1117400132...
Checkpoint 1117400132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.29489
Policy Entropy: 3.14489
Value Function Loss: 0.00433

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.59406
Value Function Update Magnitude: 0.57328

Collected Steps per Second: 22,420.70448
Overall Steps per Second: 10,644.58344

Timestep Collection Time: 2.23071
Timestep Consumption Time: 2.46783
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.69854

Cumulative Model Updates: 133,980
Cumulative Timesteps: 1,117,450,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076.70090
Policy Entropy: 3.15621
Value Function Loss: 0.00416

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.59515
Value Function Update Magnitude: 0.59027

Collected Steps per Second: 22,748.30262
Overall Steps per Second: 10,572.89927

Timestep Collection Time: 2.19849
Timestep Consumption Time: 2.53171
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.73021

Cumulative Model Updates: 133,986
Cumulative Timesteps: 1,117,500,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1117500158...
Checkpoint 1117500158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.55605
Policy Entropy: 3.16413
Value Function Loss: 0.00410

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.58318
Value Function Update Magnitude: 0.56957

Collected Steps per Second: 22,396.80773
Overall Steps per Second: 10,600.03911

Timestep Collection Time: 2.23300
Timestep Consumption Time: 2.48510
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.71810

Cumulative Model Updates: 133,992
Cumulative Timesteps: 1,117,550,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.41389
Policy Entropy: 3.17479
Value Function Loss: 0.00430

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.58287
Value Function Update Magnitude: 0.53641

Collected Steps per Second: 23,020.27881
Overall Steps per Second: 10,843.04208

Timestep Collection Time: 2.17208
Timestep Consumption Time: 2.43935
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.61144

Cumulative Model Updates: 133,998
Cumulative Timesteps: 1,117,600,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1117600172...
Checkpoint 1117600172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.27905
Policy Entropy: 3.15796
Value Function Loss: 0.00436

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.57880
Value Function Update Magnitude: 0.53614

Collected Steps per Second: 22,576.85262
Overall Steps per Second: 10,705.41325

Timestep Collection Time: 2.21581
Timestep Consumption Time: 2.45715
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.67296

Cumulative Model Updates: 134,004
Cumulative Timesteps: 1,117,650,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.87575
Policy Entropy: 3.15200
Value Function Loss: 0.00410

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.53907

Collected Steps per Second: 22,895.80518
Overall Steps per Second: 10,673.78076

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.68494

Cumulative Model Updates: 134,010
Cumulative Timesteps: 1,117,700,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1117700204...
Checkpoint 1117700204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.08227
Policy Entropy: 3.14264
Value Function Loss: 0.00391

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.57659
Value Function Update Magnitude: 0.52442

Collected Steps per Second: 22,793.96531
Overall Steps per Second: 10,773.65531

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.44866
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.64336

Cumulative Model Updates: 134,016
Cumulative Timesteps: 1,117,750,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.88243
Policy Entropy: 3.14281
Value Function Loss: 0.00398

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.58225
Value Function Update Magnitude: 0.52333

Collected Steps per Second: 22,962.52589
Overall Steps per Second: 10,683.95770

Timestep Collection Time: 2.17746
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.67991

Cumulative Model Updates: 134,022
Cumulative Timesteps: 1,117,800,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1117800230...
Checkpoint 1117800230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.68057
Policy Entropy: 3.14104
Value Function Loss: 0.00421

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.53350

Collected Steps per Second: 22,999.98938
Overall Steps per Second: 10,840.49654

Timestep Collection Time: 2.17461
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.61381

Cumulative Model Updates: 134,028
Cumulative Timesteps: 1,117,850,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.33978
Policy Entropy: 3.14587
Value Function Loss: 0.00419

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.60218
Value Function Update Magnitude: 0.56625

Collected Steps per Second: 22,849.42189
Overall Steps per Second: 10,728.41846

Timestep Collection Time: 2.18833
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.66071

Cumulative Model Updates: 134,034
Cumulative Timesteps: 1,117,900,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1117900248...
Checkpoint 1117900248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.75851
Policy Entropy: 3.14933
Value Function Loss: 0.00412

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.56684

Collected Steps per Second: 22,606.38268
Overall Steps per Second: 10,554.82558

Timestep Collection Time: 2.21247
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.73869

Cumulative Model Updates: 134,040
Cumulative Timesteps: 1,117,950,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.99644
Policy Entropy: 3.14524
Value Function Loss: 0.00414

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.59036
Value Function Update Magnitude: 0.54598

Collected Steps per Second: 23,000.84273
Overall Steps per Second: 10,797.61100

Timestep Collection Time: 2.17401
Timestep Consumption Time: 2.45702
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.63102

Cumulative Model Updates: 134,046
Cumulative Timesteps: 1,118,000,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1118000268...
Checkpoint 1118000268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.71421
Policy Entropy: 3.14068
Value Function Loss: 0.00439

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.59214
Value Function Update Magnitude: 0.52746

Collected Steps per Second: 22,693.14488
Overall Steps per Second: 10,705.99925

Timestep Collection Time: 2.20428
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.67233

Cumulative Model Updates: 134,052
Cumulative Timesteps: 1,118,050,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.13303
Policy Entropy: 3.13424
Value Function Loss: 0.00432

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.59577
Value Function Update Magnitude: 0.51885

Collected Steps per Second: 23,167.90556
Overall Steps per Second: 10,916.54395

Timestep Collection Time: 2.15859
Timestep Consumption Time: 2.42253
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.58112

Cumulative Model Updates: 134,058
Cumulative Timesteps: 1,118,100,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1118100300...
Checkpoint 1118100300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094.89149
Policy Entropy: 3.13128
Value Function Loss: 0.00408

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.59323
Value Function Update Magnitude: 0.51267

Collected Steps per Second: 22,647.20012
Overall Steps per Second: 10,640.09811

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.49202
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.70033

Cumulative Model Updates: 134,064
Cumulative Timesteps: 1,118,150,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.41163
Policy Entropy: 3.14362
Value Function Loss: 0.00401

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.58610
Value Function Update Magnitude: 0.50759

Collected Steps per Second: 23,095.92175
Overall Steps per Second: 10,839.20632

Timestep Collection Time: 2.16618
Timestep Consumption Time: 2.44947
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.61565

Cumulative Model Updates: 134,070
Cumulative Timesteps: 1,118,200,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1118200342...
Checkpoint 1118200342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.44017
Policy Entropy: 3.14059
Value Function Loss: 0.00403

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.57641
Value Function Update Magnitude: 0.50656

Collected Steps per Second: 22,554.89441
Overall Steps per Second: 10,706.10369

Timestep Collection Time: 2.21761
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.67191

Cumulative Model Updates: 134,076
Cumulative Timesteps: 1,118,250,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.51571
Policy Entropy: 3.13800
Value Function Loss: 0.00470

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.58462
Value Function Update Magnitude: 0.51086

Collected Steps per Second: 22,561.33629
Overall Steps per Second: 10,653.03355

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.47861
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.69594

Cumulative Model Updates: 134,082
Cumulative Timesteps: 1,118,300,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1118300386...
Checkpoint 1118300386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,091.82578
Policy Entropy: 3.13859
Value Function Loss: 0.00437

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.59026
Value Function Update Magnitude: 0.53383

Collected Steps per Second: 22,996.62936
Overall Steps per Second: 10,905.00249

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.41169
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.58670

Cumulative Model Updates: 134,088
Cumulative Timesteps: 1,118,350,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.85738
Policy Entropy: 3.14306
Value Function Loss: 0.00425

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.58589
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 22,933.07540
Overall Steps per Second: 10,801.14287

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.44908
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.62951

Cumulative Model Updates: 134,094
Cumulative Timesteps: 1,118,400,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1118400408...
Checkpoint 1118400408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773.56733
Policy Entropy: 3.17036
Value Function Loss: 0.00393

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.53814

Collected Steps per Second: 22,809.46524
Overall Steps per Second: 10,684.95808

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.67985

Cumulative Model Updates: 134,100
Cumulative Timesteps: 1,118,450,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,165.24857
Policy Entropy: 3.18915
Value Function Loss: 0.00374

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.52674

Collected Steps per Second: 22,425.24798
Overall Steps per Second: 10,480.42371

Timestep Collection Time: 2.23052
Timestep Consumption Time: 2.54219
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.77271

Cumulative Model Updates: 134,106
Cumulative Timesteps: 1,118,500,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1118500432...
Checkpoint 1118500432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.93513
Policy Entropy: 3.19402
Value Function Loss: 0.00348

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.50727

Collected Steps per Second: 22,897.94796
Overall Steps per Second: 10,679.42950

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.68452

Cumulative Model Updates: 134,112
Cumulative Timesteps: 1,118,550,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.03466
Policy Entropy: 3.17956
Value Function Loss: 0.00357

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.48555

Collected Steps per Second: 22,940.32695
Overall Steps per Second: 10,850.55633

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.61009

Cumulative Model Updates: 134,118
Cumulative Timesteps: 1,118,600,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1118600482...
Checkpoint 1118600482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.50149
Policy Entropy: 3.17125
Value Function Loss: 0.00349

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.48401

Collected Steps per Second: 22,943.79220
Overall Steps per Second: 10,709.23642

Timestep Collection Time: 2.18011
Timestep Consumption Time: 2.49062
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.67073

Cumulative Model Updates: 134,124
Cumulative Timesteps: 1,118,650,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,887.22726
Policy Entropy: 3.16140
Value Function Loss: 0.00396

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.55403
Value Function Update Magnitude: 0.47797

Collected Steps per Second: 23,189.08905
Overall Steps per Second: 10,841.30255

Timestep Collection Time: 2.15679
Timestep Consumption Time: 2.45649
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.61328

Cumulative Model Updates: 134,130
Cumulative Timesteps: 1,118,700,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1118700516...
Checkpoint 1118700516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234.74712
Policy Entropy: 3.15034
Value Function Loss: 0.00407

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.56574
Value Function Update Magnitude: 0.49737

Collected Steps per Second: 22,722.72909
Overall Steps per Second: 10,667.98229

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.68786

Cumulative Model Updates: 134,136
Cumulative Timesteps: 1,118,750,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,085.04129
Policy Entropy: 3.14104
Value Function Loss: 0.00403

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.57043
Value Function Update Magnitude: 0.50594

Collected Steps per Second: 22,958.31914
Overall Steps per Second: 10,760.92632

Timestep Collection Time: 2.17795
Timestep Consumption Time: 2.46868
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.64663

Cumulative Model Updates: 134,142
Cumulative Timesteps: 1,118,800,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1118800528...
Checkpoint 1118800528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.00997
Policy Entropy: 3.12863
Value Function Loss: 0.00425

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.57224
Value Function Update Magnitude: 0.49791

Collected Steps per Second: 22,674.98854
Overall Steps per Second: 10,732.67054

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.65998

Cumulative Model Updates: 134,148
Cumulative Timesteps: 1,118,850,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,787.58149
Policy Entropy: 3.12871
Value Function Loss: 0.00410

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.49722

Collected Steps per Second: 22,816.72580
Overall Steps per Second: 10,564.40956

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.54170
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.73325

Cumulative Model Updates: 134,154
Cumulative Timesteps: 1,118,900,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1118900546...
Checkpoint 1118900546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.76917
Policy Entropy: 3.13375
Value Function Loss: 0.00396

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.49588

Collected Steps per Second: 22,706.65177
Overall Steps per Second: 10,562.88511

Timestep Collection Time: 2.20341
Timestep Consumption Time: 2.53318
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.73658

Cumulative Model Updates: 134,160
Cumulative Timesteps: 1,118,950,578

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.32861
Policy Entropy: 3.13321
Value Function Loss: 0.00403

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.55905
Value Function Update Magnitude: 0.49325

Collected Steps per Second: 22,868.05584
Overall Steps per Second: 10,817.48818

Timestep Collection Time: 2.18707
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.62344

Cumulative Model Updates: 134,166
Cumulative Timesteps: 1,119,000,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1119000592...
Checkpoint 1119000592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.43561
Policy Entropy: 3.12653
Value Function Loss: 0.00437

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.48220

Collected Steps per Second: 22,624.19487
Overall Steps per Second: 10,727.30419

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.66156

Cumulative Model Updates: 134,172
Cumulative Timesteps: 1,119,050,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.65589
Policy Entropy: 3.13123
Value Function Loss: 0.00457

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.58691
Value Function Update Magnitude: 0.51806

Collected Steps per Second: 22,681.71911
Overall Steps per Second: 10,674.73008

Timestep Collection Time: 2.20459
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.68433

Cumulative Model Updates: 134,178
Cumulative Timesteps: 1,119,100,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1119100602...
Checkpoint 1119100602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.73650
Policy Entropy: 3.12237
Value Function Loss: 0.00448

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.59292
Value Function Update Magnitude: 0.54012

Collected Steps per Second: 22,641.89016
Overall Steps per Second: 10,816.57529

Timestep Collection Time: 2.20830
Timestep Consumption Time: 2.41424
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.62254

Cumulative Model Updates: 134,184
Cumulative Timesteps: 1,119,150,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.15771
Policy Entropy: 3.12100
Value Function Loss: 0.00437

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.60168
Value Function Update Magnitude: 0.55100

Collected Steps per Second: 22,175.14757
Overall Steps per Second: 10,524.63626

Timestep Collection Time: 2.25505
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.75133

Cumulative Model Updates: 134,190
Cumulative Timesteps: 1,119,200,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1119200608...
Checkpoint 1119200608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,953.22556
Policy Entropy: 3.11510
Value Function Loss: 0.00456

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.60390
Value Function Update Magnitude: 0.54889

Collected Steps per Second: 22,785.16062
Overall Steps per Second: 10,649.58713

Timestep Collection Time: 2.19511
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.69652

Cumulative Model Updates: 134,196
Cumulative Timesteps: 1,119,250,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.86813
Policy Entropy: 3.12835
Value Function Loss: 0.00415

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.58892
Value Function Update Magnitude: 0.51991

Collected Steps per Second: 23,002.33248
Overall Steps per Second: 10,867.09882

Timestep Collection Time: 2.17387
Timestep Consumption Time: 2.42755
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.60141

Cumulative Model Updates: 134,202
Cumulative Timesteps: 1,119,300,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1119300628...
Checkpoint 1119300628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.22231
Policy Entropy: 3.13741
Value Function Loss: 0.00413

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.57738
Value Function Update Magnitude: 0.53505

Collected Steps per Second: 22,708.24643
Overall Steps per Second: 10,684.19768

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68187

Cumulative Model Updates: 134,208
Cumulative Timesteps: 1,119,350,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.27919
Policy Entropy: 3.13837
Value Function Loss: 0.00413

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.58249
Value Function Update Magnitude: 0.55722

Collected Steps per Second: 22,994.65853
Overall Steps per Second: 10,852.19657

Timestep Collection Time: 2.17564
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.60994

Cumulative Model Updates: 134,214
Cumulative Timesteps: 1,119,400,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1119400678...
Checkpoint 1119400678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.39932
Policy Entropy: 3.13200
Value Function Loss: 0.00447

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.59381
Value Function Update Magnitude: 0.54956

Collected Steps per Second: 22,696.74291
Overall Steps per Second: 10,657.32173

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.48995
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.69405

Cumulative Model Updates: 134,220
Cumulative Timesteps: 1,119,450,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.80908
Policy Entropy: 3.13593
Value Function Loss: 0.00467

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.60176
Value Function Update Magnitude: 0.54693

Collected Steps per Second: 22,709.21951
Overall Steps per Second: 10,778.24274

Timestep Collection Time: 2.20245
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.64046

Cumulative Model Updates: 134,226
Cumulative Timesteps: 1,119,500,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1119500720...
Checkpoint 1119500720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.14467
Policy Entropy: 3.13539
Value Function Loss: 0.00459

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.60217
Value Function Update Magnitude: 0.54971

Collected Steps per Second: 22,695.89905
Overall Steps per Second: 10,645.02165

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.69816

Cumulative Model Updates: 134,232
Cumulative Timesteps: 1,119,550,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.16993
Policy Entropy: 3.14341
Value Function Loss: 0.00446

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.59864
Value Function Update Magnitude: 0.54861

Collected Steps per Second: 22,789.42363
Overall Steps per Second: 10,814.24501

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.62723

Cumulative Model Updates: 134,238
Cumulative Timesteps: 1,119,600,772

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1119600772...
Checkpoint 1119600772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.90093
Policy Entropy: 3.13425
Value Function Loss: 0.00444

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.58921
Value Function Update Magnitude: 0.54857

Collected Steps per Second: 22,815.06524
Overall Steps per Second: 10,735.59194

Timestep Collection Time: 2.19241
Timestep Consumption Time: 2.46686
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.65927

Cumulative Model Updates: 134,244
Cumulative Timesteps: 1,119,650,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,139.79466
Policy Entropy: 3.12185
Value Function Loss: 0.00418

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.59253
Value Function Update Magnitude: 0.56633

Collected Steps per Second: 22,787.45552
Overall Steps per Second: 10,812.79848

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.62581

Cumulative Model Updates: 134,250
Cumulative Timesteps: 1,119,700,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1119700810...
Checkpoint 1119700810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.27852
Policy Entropy: 3.12152
Value Function Loss: 0.00419

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.60361
Value Function Update Magnitude: 0.56789

Collected Steps per Second: 22,768.80109
Overall Steps per Second: 10,730.69223

Timestep Collection Time: 2.19713
Timestep Consumption Time: 2.46483
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.66195

Cumulative Model Updates: 134,256
Cumulative Timesteps: 1,119,750,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.82510
Policy Entropy: 3.11042
Value Function Loss: 0.00453

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.61211
Value Function Update Magnitude: 0.57068

Collected Steps per Second: 22,559.24599
Overall Steps per Second: 10,917.77184

Timestep Collection Time: 2.21665
Timestep Consumption Time: 2.36359
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.58024

Cumulative Model Updates: 134,262
Cumulative Timesteps: 1,119,800,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1119800842...
Checkpoint 1119800842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.54662
Policy Entropy: 3.11345
Value Function Loss: 0.00467

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.62011
Value Function Update Magnitude: 0.59164

Collected Steps per Second: 21,896.92067
Overall Steps per Second: 10,622.74646

Timestep Collection Time: 2.28443
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.70895

Cumulative Model Updates: 134,268
Cumulative Timesteps: 1,119,850,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.62726
Policy Entropy: 3.11247
Value Function Loss: 0.00476

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.61840
Value Function Update Magnitude: 0.61421

Collected Steps per Second: 22,288.89077
Overall Steps per Second: 10,522.82531

Timestep Collection Time: 2.24327
Timestep Consumption Time: 2.50831
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.75158

Cumulative Model Updates: 134,274
Cumulative Timesteps: 1,119,900,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1119900864...
Checkpoint 1119900864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.32485
Policy Entropy: 3.12509
Value Function Loss: 0.00498

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.62982
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 22,676.31593
Overall Steps per Second: 10,632.64606

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.49765
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.70269

Cumulative Model Updates: 134,280
Cumulative Timesteps: 1,119,950,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.93343
Policy Entropy: 3.15055
Value Function Loss: 0.00504

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.62642
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 23,072.89623
Overall Steps per Second: 10,863.09260

Timestep Collection Time: 2.16756
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.60385

Cumulative Model Updates: 134,286
Cumulative Timesteps: 1,120,000,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1120000878...
Checkpoint 1120000878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.36057
Policy Entropy: 3.16454
Value Function Loss: 0.00459

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.60430
Value Function Update Magnitude: 0.62311

Collected Steps per Second: 22,901.12034
Overall Steps per Second: 10,709.54116

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.66873

Cumulative Model Updates: 134,292
Cumulative Timesteps: 1,120,050,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.05625
Policy Entropy: 3.15790
Value Function Loss: 0.00448

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.59617
Value Function Update Magnitude: 0.60610

Collected Steps per Second: 22,857.29749
Overall Steps per Second: 10,828.44888

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.61784

Cumulative Model Updates: 134,298
Cumulative Timesteps: 1,120,100,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1120100882...
Checkpoint 1120100882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.19411
Policy Entropy: 3.13573
Value Function Loss: 0.00430

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.60723
Value Function Update Magnitude: 0.60857

Collected Steps per Second: 22,712.47203
Overall Steps per Second: 10,643.87212

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.69904

Cumulative Model Updates: 134,304
Cumulative Timesteps: 1,120,150,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.34908
Policy Entropy: 3.15211
Value Function Loss: 0.00425

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.60958
Value Function Update Magnitude: 0.62979

Collected Steps per Second: 22,902.07937
Overall Steps per Second: 10,819.64453

Timestep Collection Time: 2.18391
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.62270

Cumulative Model Updates: 134,310
Cumulative Timesteps: 1,120,200,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1120200914...
Checkpoint 1120200914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.70490
Policy Entropy: 3.14078
Value Function Loss: 0.00452

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.61209
Value Function Update Magnitude: 0.62129

Collected Steps per Second: 22,954.30179
Overall Steps per Second: 10,657.77411

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.51438
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.69366

Cumulative Model Updates: 134,316
Cumulative Timesteps: 1,120,250,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.53806
Policy Entropy: 3.13715
Value Function Loss: 0.00469

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.61985
Value Function Update Magnitude: 0.62060

Collected Steps per Second: 22,902.37910
Overall Steps per Second: 10,848.89137

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.61079

Cumulative Model Updates: 134,322
Cumulative Timesteps: 1,120,300,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1120300960...
Checkpoint 1120300960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.41063
Policy Entropy: 3.12647
Value Function Loss: 0.00488

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.62411
Value Function Update Magnitude: 0.63182

Collected Steps per Second: 22,605.02585
Overall Steps per Second: 10,788.08054

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.63623

Cumulative Model Updates: 134,328
Cumulative Timesteps: 1,120,350,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.94811
Policy Entropy: 3.15576
Value Function Loss: 0.00439

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.61657
Value Function Update Magnitude: 0.64050

Collected Steps per Second: 22,804.17046
Overall Steps per Second: 10,812.51510

Timestep Collection Time: 2.19258
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.62427

Cumulative Model Updates: 134,334
Cumulative Timesteps: 1,120,400,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1120400976...
Checkpoint 1120400976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.27514
Policy Entropy: 3.16450
Value Function Loss: 0.00453

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.60344
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,520.79337
Overall Steps per Second: 10,677.76114

Timestep Collection Time: 2.22079
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.68394

Cumulative Model Updates: 134,340
Cumulative Timesteps: 1,120,450,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.63474
Policy Entropy: 3.17593
Value Function Loss: 0.00428

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.59525
Value Function Update Magnitude: 0.59237

Collected Steps per Second: 22,888.11725
Overall Steps per Second: 10,856.60097

Timestep Collection Time: 2.18533
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.60715

Cumulative Model Updates: 134,346
Cumulative Timesteps: 1,120,501,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1120501008...
Checkpoint 1120501008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,161.51697
Policy Entropy: 3.17802
Value Function Loss: 0.00414

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.59493

Collected Steps per Second: 22,360.89648
Overall Steps per Second: 10,742.00299

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.65593

Cumulative Model Updates: 134,352
Cumulative Timesteps: 1,120,551,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.51221
Policy Entropy: 3.18973
Value Function Loss: 0.00396

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.56993
Value Function Update Magnitude: 0.58929

Collected Steps per Second: 23,065.69476
Overall Steps per Second: 10,757.48209

Timestep Collection Time: 2.16876
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.65016

Cumulative Model Updates: 134,358
Cumulative Timesteps: 1,120,601,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1120601046...
Checkpoint 1120601046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.43781
Policy Entropy: 3.19332
Value Function Loss: 0.00377

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.57477

Collected Steps per Second: 22,287.38606
Overall Steps per Second: 10,667.04254

Timestep Collection Time: 2.24378
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.68808

Cumulative Model Updates: 134,364
Cumulative Timesteps: 1,120,651,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,353.19673
Policy Entropy: 3.19204
Value Function Loss: 0.00368

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.56162

Collected Steps per Second: 23,091.94889
Overall Steps per Second: 10,892.63907

Timestep Collection Time: 2.16586
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.59154

Cumulative Model Updates: 134,370
Cumulative Timesteps: 1,120,701,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1120701068...
Checkpoint 1120701068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.63142
Policy Entropy: 3.17689
Value Function Loss: 0.00381

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.57479

Collected Steps per Second: 22,635.72499
Overall Steps per Second: 10,806.82041

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.62948

Cumulative Model Updates: 134,376
Cumulative Timesteps: 1,120,751,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.76487
Policy Entropy: 3.17496
Value Function Loss: 0.00393

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.56834
Value Function Update Magnitude: 0.59652

Collected Steps per Second: 22,989.13882
Overall Steps per Second: 10,769.92400

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.64293

Cumulative Model Updates: 134,382
Cumulative Timesteps: 1,120,801,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1120801102...
Checkpoint 1120801102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.68593
Policy Entropy: 3.18321
Value Function Loss: 0.00395

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.61530

Collected Steps per Second: 22,732.21595
Overall Steps per Second: 10,697.22547

Timestep Collection Time: 2.19952
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.67411

Cumulative Model Updates: 134,388
Cumulative Timesteps: 1,120,851,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657.07685
Policy Entropy: 3.19545
Value Function Loss: 0.00391

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.59284

Collected Steps per Second: 22,784.89141
Overall Steps per Second: 10,829.71136

Timestep Collection Time: 2.19567
Timestep Consumption Time: 2.42385
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.61951

Cumulative Model Updates: 134,394
Cumulative Timesteps: 1,120,901,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1120901130...
Checkpoint 1120901130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.82972
Policy Entropy: 3.19780
Value Function Loss: 0.00378

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.56146
Value Function Update Magnitude: 0.58494

Collected Steps per Second: 22,598.59842
Overall Steps per Second: 10,694.41686

Timestep Collection Time: 2.21297
Timestep Consumption Time: 2.46330
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.67627

Cumulative Model Updates: 134,400
Cumulative Timesteps: 1,120,951,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,066.37049
Policy Entropy: 3.20359
Value Function Loss: 0.00433

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.57751
Value Function Update Magnitude: 0.60854

Collected Steps per Second: 22,713.41118
Overall Steps per Second: 10,578.42260

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.52617
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72830

Cumulative Model Updates: 134,406
Cumulative Timesteps: 1,121,001,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1121001158...
Checkpoint 1121001158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.51018
Policy Entropy: 3.20243
Value Function Loss: 0.00450

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.58490
Value Function Update Magnitude: 0.63181

Collected Steps per Second: 22,766.75628
Overall Steps per Second: 10,566.20435

Timestep Collection Time: 2.19689
Timestep Consumption Time: 2.53670
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.73358

Cumulative Model Updates: 134,412
Cumulative Timesteps: 1,121,051,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.49725
Policy Entropy: 3.20607
Value Function Loss: 0.00447

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.58279
Value Function Update Magnitude: 0.61784

Collected Steps per Second: 22,993.17508
Overall Steps per Second: 10,873.43265

Timestep Collection Time: 2.17560
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.60057

Cumulative Model Updates: 134,418
Cumulative Timesteps: 1,121,101,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1121101198...
Checkpoint 1121101198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.63152
Policy Entropy: 3.19645
Value Function Loss: 0.00427

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.57958
Value Function Update Magnitude: 0.58818

Collected Steps per Second: 22,733.35834
Overall Steps per Second: 10,666.42458

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.68817

Cumulative Model Updates: 134,424
Cumulative Timesteps: 1,121,151,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.92736
Policy Entropy: 3.19475
Value Function Loss: 0.00420

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.58905

Collected Steps per Second: 23,077.34696
Overall Steps per Second: 10,856.94055

Timestep Collection Time: 2.16680
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.60572

Cumulative Model Updates: 134,430
Cumulative Timesteps: 1,121,201,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1121201208...
Checkpoint 1121201208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.61572
Policy Entropy: 3.21206
Value Function Loss: 0.00400

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.57102
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 22,689.61288
Overall Steps per Second: 10,699.92398

Timestep Collection Time: 2.20418
Timestep Consumption Time: 2.46987
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.67405

Cumulative Model Updates: 134,436
Cumulative Timesteps: 1,121,251,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.14217
Policy Entropy: 3.22581
Value Function Loss: 0.00424

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.57825
Value Function Update Magnitude: 0.57712

Collected Steps per Second: 22,631.97113
Overall Steps per Second: 10,780.71118

Timestep Collection Time: 2.21059
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.64070

Cumulative Model Updates: 134,442
Cumulative Timesteps: 1,121,301,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1121301250...
Checkpoint 1121301250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.26027
Policy Entropy: 3.20693
Value Function Loss: 0.00430

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.58831
Value Function Update Magnitude: 0.59337

Collected Steps per Second: 22,739.33043
Overall Steps per Second: 10,766.98664

Timestep Collection Time: 2.20059
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.64754

Cumulative Model Updates: 134,448
Cumulative Timesteps: 1,121,351,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.58071
Policy Entropy: 3.18929
Value Function Loss: 0.00443

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.60371

Collected Steps per Second: 22,680.84195
Overall Steps per Second: 10,768.60811

Timestep Collection Time: 2.20450
Timestep Consumption Time: 2.43862
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.64313

Cumulative Model Updates: 134,454
Cumulative Timesteps: 1,121,401,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1121401290...
Checkpoint 1121401290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.80822
Policy Entropy: 3.17458
Value Function Loss: 0.00431

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.58480
Value Function Update Magnitude: 0.57123

Collected Steps per Second: 22,948.75649
Overall Steps per Second: 10,757.33204

Timestep Collection Time: 2.17999
Timestep Consumption Time: 2.47061
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.65060

Cumulative Model Updates: 134,460
Cumulative Timesteps: 1,121,451,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.57701
Policy Entropy: 3.17549
Value Function Loss: 0.00416

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.57819
Value Function Update Magnitude: 0.55156

Collected Steps per Second: 22,770.41300
Overall Steps per Second: 10,780.84130

Timestep Collection Time: 2.19601
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.63823

Cumulative Model Updates: 134,466
Cumulative Timesteps: 1,121,501,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1121501322...
Checkpoint 1121501322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.07094
Policy Entropy: 3.16252
Value Function Loss: 0.00404

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.57184
Value Function Update Magnitude: 0.52992

Collected Steps per Second: 22,905.17249
Overall Steps per Second: 10,775.04398

Timestep Collection Time: 2.18422
Timestep Consumption Time: 2.45891
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.64314

Cumulative Model Updates: 134,472
Cumulative Timesteps: 1,121,551,352

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.30342
Policy Entropy: 3.15291
Value Function Loss: 0.00428

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.57930
Value Function Update Magnitude: 0.53369

Collected Steps per Second: 22,923.99394
Overall Steps per Second: 10,794.94143

Timestep Collection Time: 2.18112
Timestep Consumption Time: 2.45068
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.63180

Cumulative Model Updates: 134,478
Cumulative Timesteps: 1,121,601,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1121601352...
Checkpoint 1121601352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.81823
Policy Entropy: 3.15596
Value Function Loss: 0.00421

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.53520

Collected Steps per Second: 22,767.49681
Overall Steps per Second: 10,716.94828

Timestep Collection Time: 2.19673
Timestep Consumption Time: 2.47009
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.66681

Cumulative Model Updates: 134,484
Cumulative Timesteps: 1,121,651,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.00175
Policy Entropy: 3.16710
Value Function Loss: 0.00409

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.57423
Value Function Update Magnitude: 0.52440

Collected Steps per Second: 22,588.71312
Overall Steps per Second: 10,548.48895

Timestep Collection Time: 2.21473
Timestep Consumption Time: 2.52794
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.74267

Cumulative Model Updates: 134,490
Cumulative Timesteps: 1,121,701,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1121701394...
Checkpoint 1121701394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.48166
Policy Entropy: 3.16889
Value Function Loss: 0.00418

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.57065
Value Function Update Magnitude: 0.50710

Collected Steps per Second: 22,929.60385
Overall Steps per Second: 10,636.24758

Timestep Collection Time: 2.18181
Timestep Consumption Time: 2.52173
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.70354

Cumulative Model Updates: 134,496
Cumulative Timesteps: 1,121,751,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.03197
Policy Entropy: 3.16458
Value Function Loss: 0.00436

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.58262
Value Function Update Magnitude: 0.53155

Collected Steps per Second: 23,098.77797
Overall Steps per Second: 10,772.20559

Timestep Collection Time: 2.16505
Timestep Consumption Time: 2.47745
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.64250

Cumulative Model Updates: 134,502
Cumulative Timesteps: 1,121,801,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1121801432...
Checkpoint 1121801432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.39595
Policy Entropy: 3.16551
Value Function Loss: 0.00419

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.53910

Collected Steps per Second: 22,645.67454
Overall Steps per Second: 10,676.44927

Timestep Collection Time: 2.20810
Timestep Consumption Time: 2.47548
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.68358

Cumulative Model Updates: 134,508
Cumulative Timesteps: 1,121,851,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.59541
Policy Entropy: 3.16945
Value Function Loss: 0.00402

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.56711
Value Function Update Magnitude: 0.52136

Collected Steps per Second: 22,640.46648
Overall Steps per Second: 10,550.44202

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.53080
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.73933

Cumulative Model Updates: 134,514
Cumulative Timesteps: 1,121,901,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1121901438...
Checkpoint 1121901438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.21868
Policy Entropy: 3.18113
Value Function Loss: 0.00381

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.50783

Collected Steps per Second: 22,280.34469
Overall Steps per Second: 10,621.14483

Timestep Collection Time: 2.24530
Timestep Consumption Time: 2.46474
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.71004

Cumulative Model Updates: 134,520
Cumulative Timesteps: 1,121,951,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.60137
Policy Entropy: 3.18583
Value Function Loss: 0.00384

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.54167
Value Function Update Magnitude: 0.49724

Collected Steps per Second: 22,985.34338
Overall Steps per Second: 10,752.81880

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.65087

Cumulative Model Updates: 134,526
Cumulative Timesteps: 1,122,001,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1122001474...
Checkpoint 1122001474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.85141
Policy Entropy: 3.19000
Value Function Loss: 0.00379

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.48074

Collected Steps per Second: 22,643.09738
Overall Steps per Second: 10,797.89444

Timestep Collection Time: 2.20862
Timestep Consumption Time: 2.42284
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.63146

Cumulative Model Updates: 134,532
Cumulative Timesteps: 1,122,051,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.72128
Policy Entropy: 3.18245
Value Function Loss: 0.00402

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.49028

Collected Steps per Second: 22,585.55467
Overall Steps per Second: 10,737.58598

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.65766

Cumulative Model Updates: 134,538
Cumulative Timesteps: 1,122,101,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1122101496...
Checkpoint 1122101496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960.27363
Policy Entropy: 3.17794
Value Function Loss: 0.00399

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.55519
Value Function Update Magnitude: 0.54161

Collected Steps per Second: 22,634.06923
Overall Steps per Second: 10,825.92208

Timestep Collection Time: 2.20941
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.61928

Cumulative Model Updates: 134,544
Cumulative Timesteps: 1,122,151,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.39560
Policy Entropy: 3.17578
Value Function Loss: 0.00411

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.56096

Collected Steps per Second: 22,985.56454
Overall Steps per Second: 10,857.50851

Timestep Collection Time: 2.17597
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.60658

Cumulative Model Updates: 134,550
Cumulative Timesteps: 1,122,201,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1122201520...
Checkpoint 1122201520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.81697
Policy Entropy: 3.18651
Value Function Loss: 0.00400

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.56273
Value Function Update Magnitude: 0.54961

Collected Steps per Second: 12,340.68731
Overall Steps per Second: 6,438.02103

Timestep Collection Time: 4.05488
Timestep Consumption Time: 3.71770
PPO Batch Consumption Time: 0.34839
Total Iteration Time: 7.77257

Cumulative Model Updates: 134,556
Cumulative Timesteps: 1,122,251,560

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.93008
Policy Entropy: 3.19029
Value Function Loss: 0.00437

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.57402
Value Function Update Magnitude: 0.57391

Collected Steps per Second: 13,545.74570
Overall Steps per Second: 7,885.14162

Timestep Collection Time: 3.69297
Timestep Consumption Time: 2.65112
PPO Batch Consumption Time: 0.31193
Total Iteration Time: 6.34408

Cumulative Model Updates: 134,562
Cumulative Timesteps: 1,122,301,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1122301584...
Checkpoint 1122301584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.36814
Policy Entropy: 3.19081
Value Function Loss: 0.00414

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.56917

Collected Steps per Second: 20,168.69661
Overall Steps per Second: 9,922.60471

Timestep Collection Time: 2.48127
Timestep Consumption Time: 2.56216
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 5.04343

Cumulative Model Updates: 134,568
Cumulative Timesteps: 1,122,351,628

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.35344
Policy Entropy: 3.17180
Value Function Loss: 0.00438

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.57639
Value Function Update Magnitude: 0.54036

Collected Steps per Second: 20,907.58074
Overall Steps per Second: 10,269.09449

Timestep Collection Time: 2.39282
Timestep Consumption Time: 2.47889
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.87171

Cumulative Model Updates: 134,574
Cumulative Timesteps: 1,122,401,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1122401656...
Checkpoint 1122401656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.57624
Policy Entropy: 3.15769
Value Function Loss: 0.00416

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.57942
Value Function Update Magnitude: 0.52764

Collected Steps per Second: 19,957.74963
Overall Steps per Second: 9,988.31640

Timestep Collection Time: 2.50549
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 5.00625

Cumulative Model Updates: 134,580
Cumulative Timesteps: 1,122,451,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.89249
Policy Entropy: 3.17122
Value Function Loss: 0.00399

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.57716
Value Function Update Magnitude: 0.53953

Collected Steps per Second: 21,692.09722
Overall Steps per Second: 10,304.69734

Timestep Collection Time: 2.30563
Timestep Consumption Time: 2.54788
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.85351

Cumulative Model Updates: 134,586
Cumulative Timesteps: 1,122,501,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1122501674...
Checkpoint 1122501674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.87771
Policy Entropy: 3.18090
Value Function Loss: 0.00379

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.57092
Value Function Update Magnitude: 0.53311

Collected Steps per Second: 21,670.37578
Overall Steps per Second: 10,288.58652

Timestep Collection Time: 2.30868
Timestep Consumption Time: 2.55399
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 4.86267

Cumulative Model Updates: 134,592
Cumulative Timesteps: 1,122,551,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.30272
Policy Entropy: 3.19299
Value Function Loss: 0.00397

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.53422

Collected Steps per Second: 20,868.61793
Overall Steps per Second: 10,026.14806

Timestep Collection Time: 2.39623
Timestep Consumption Time: 2.59133
PPO Batch Consumption Time: 0.30644
Total Iteration Time: 4.98756

Cumulative Model Updates: 134,598
Cumulative Timesteps: 1,122,601,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1122601710...
Checkpoint 1122601710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.56236
Policy Entropy: 3.19068
Value Function Loss: 0.00393

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.56395
Value Function Update Magnitude: 0.52864

Collected Steps per Second: 20,446.51355
Overall Steps per Second: 9,956.33922

Timestep Collection Time: 2.44550
Timestep Consumption Time: 2.57662
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 5.02213

Cumulative Model Updates: 134,604
Cumulative Timesteps: 1,122,651,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.20832
Policy Entropy: 3.17217
Value Function Loss: 0.00429

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.56076
Value Function Update Magnitude: 0.51306

Collected Steps per Second: 20,654.35835
Overall Steps per Second: 10,235.17218

Timestep Collection Time: 2.42147
Timestep Consumption Time: 2.46501
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.88648

Cumulative Model Updates: 134,610
Cumulative Timesteps: 1,122,701,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1122701726...
Checkpoint 1122701726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.37338
Policy Entropy: 3.18187
Value Function Loss: 0.00418

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.55751
Value Function Update Magnitude: 0.50925

Collected Steps per Second: 20,932.73512
Overall Steps per Second: 10,126.47115

Timestep Collection Time: 2.38927
Timestep Consumption Time: 2.54966
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.93894

Cumulative Model Updates: 134,616
Cumulative Timesteps: 1,122,751,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.69100
Policy Entropy: 3.16698
Value Function Loss: 0.00473

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.51514

Collected Steps per Second: 21,318.93412
Overall Steps per Second: 10,158.59700

Timestep Collection Time: 2.34665
Timestep Consumption Time: 2.57805
PPO Batch Consumption Time: 0.30387
Total Iteration Time: 4.92470

Cumulative Model Updates: 134,622
Cumulative Timesteps: 1,122,801,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1122801768...
Checkpoint 1122801768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.51548
Policy Entropy: 3.17277
Value Function Loss: 0.00461

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.57838
Value Function Update Magnitude: 0.54547

Collected Steps per Second: 20,981.75657
Overall Steps per Second: 10,107.57830

Timestep Collection Time: 2.38350
Timestep Consumption Time: 2.56427
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.94777

Cumulative Model Updates: 134,628
Cumulative Timesteps: 1,122,851,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.20069
Policy Entropy: 3.15732
Value Function Loss: 0.00487

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.58552
Value Function Update Magnitude: 0.56906

Collected Steps per Second: 21,732.21141
Overall Steps per Second: 10,391.59544

Timestep Collection Time: 2.30147
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.81312

Cumulative Model Updates: 134,634
Cumulative Timesteps: 1,122,901,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1122901794...
Checkpoint 1122901794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.21486
Policy Entropy: 3.16337
Value Function Loss: 0.00429

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.58592
Value Function Update Magnitude: 0.55269

Collected Steps per Second: 21,486.73424
Overall Steps per Second: 10,360.09512

Timestep Collection Time: 2.32795
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.82814

Cumulative Model Updates: 134,640
Cumulative Timesteps: 1,122,951,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,289.20999
Policy Entropy: 3.16784
Value Function Loss: 0.00425

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.57384
Value Function Update Magnitude: 0.52592

Collected Steps per Second: 21,156.35127
Overall Steps per Second: 10,078.19414

Timestep Collection Time: 2.36477
Timestep Consumption Time: 2.59941
PPO Batch Consumption Time: 0.30963
Total Iteration Time: 4.96418

Cumulative Model Updates: 134,646
Cumulative Timesteps: 1,123,001,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1123001844...
Checkpoint 1123001844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974.67135
Policy Entropy: 3.16754
Value Function Loss: 0.00448

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.51761

Collected Steps per Second: 22,165.67665
Overall Steps per Second: 10,426.00388

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.54118
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 4.79800

Cumulative Model Updates: 134,652
Cumulative Timesteps: 1,123,051,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.34896
Policy Entropy: 3.17668
Value Function Loss: 0.00454

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.57547
Value Function Update Magnitude: 0.52427

Collected Steps per Second: 21,225.75420
Overall Steps per Second: 10,094.60890

Timestep Collection Time: 2.35638
Timestep Consumption Time: 2.59834
PPO Batch Consumption Time: 0.30304
Total Iteration Time: 4.95472

Cumulative Model Updates: 134,658
Cumulative Timesteps: 1,123,101,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1123101884...
Checkpoint 1123101884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.12536
Policy Entropy: 3.16218
Value Function Loss: 0.00411

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.51869

Collected Steps per Second: 21,111.63424
Overall Steps per Second: 10,165.34161

Timestep Collection Time: 2.36846
Timestep Consumption Time: 2.55041
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.91887

Cumulative Model Updates: 134,664
Cumulative Timesteps: 1,123,151,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.26765
Policy Entropy: 3.17344
Value Function Loss: 0.00360

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.54589
Value Function Update Magnitude: 0.48457

Collected Steps per Second: 20,926.93789
Overall Steps per Second: 10,069.07544

Timestep Collection Time: 2.38955
Timestep Consumption Time: 2.57674
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.96630

Cumulative Model Updates: 134,670
Cumulative Timesteps: 1,123,201,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1123201892...
Checkpoint 1123201892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.91961
Policy Entropy: 3.17234
Value Function Loss: 0.00338

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.53608
Value Function Update Magnitude: 0.44722

Collected Steps per Second: 21,644.64512
Overall Steps per Second: 10,234.78289

Timestep Collection Time: 2.31096
Timestep Consumption Time: 2.57629
PPO Batch Consumption Time: 0.30585
Total Iteration Time: 4.88726

Cumulative Model Updates: 134,676
Cumulative Timesteps: 1,123,251,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.03976
Policy Entropy: 3.15961
Value Function Loss: 0.00377

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.53936
Value Function Update Magnitude: 0.44923

Collected Steps per Second: 21,461.13833
Overall Steps per Second: 10,401.64758

Timestep Collection Time: 2.33138
Timestep Consumption Time: 2.47882
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.81020

Cumulative Model Updates: 134,682
Cumulative Timesteps: 1,123,301,946

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1123301946...
Checkpoint 1123301946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.57556
Policy Entropy: 3.16161
Value Function Loss: 0.00406

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.45924

Collected Steps per Second: 22,178.81347
Overall Steps per Second: 10,437.46304

Timestep Collection Time: 2.25531
Timestep Consumption Time: 2.53705
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.79235

Cumulative Model Updates: 134,688
Cumulative Timesteps: 1,123,351,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.19287
Policy Entropy: 3.15255
Value Function Loss: 0.00454

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14826
Policy Update Magnitude: 0.56952
Value Function Update Magnitude: 0.47825

Collected Steps per Second: 22,023.16602
Overall Steps per Second: 10,413.41685

Timestep Collection Time: 2.27097
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.29952
Total Iteration Time: 4.80284

Cumulative Model Updates: 134,694
Cumulative Timesteps: 1,123,401,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1123401980...
Checkpoint 1123401980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.01375
Policy Entropy: 3.16589
Value Function Loss: 0.00426

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.57351
Value Function Update Magnitude: 0.50121

Collected Steps per Second: 20,598.75245
Overall Steps per Second: 9,941.32670

Timestep Collection Time: 2.42830
Timestep Consumption Time: 2.60322
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 5.03152

Cumulative Model Updates: 134,700
Cumulative Timesteps: 1,123,452,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.64567
Policy Entropy: 3.16550
Value Function Loss: 0.00389

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.51806

Collected Steps per Second: 22,188.21929
Overall Steps per Second: 10,290.18880

Timestep Collection Time: 2.25399
Timestep Consumption Time: 2.60617
PPO Batch Consumption Time: 0.30951
Total Iteration Time: 4.86016

Cumulative Model Updates: 134,706
Cumulative Timesteps: 1,123,502,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1123502012...
Checkpoint 1123502012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.24245
Policy Entropy: 3.18077
Value Function Loss: 0.00368

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.51423

Collected Steps per Second: 21,030.94961
Overall Steps per Second: 10,281.05419

Timestep Collection Time: 2.37830
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.86507

Cumulative Model Updates: 134,712
Cumulative Timesteps: 1,123,552,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,412.27601
Policy Entropy: 3.16820
Value Function Loss: 0.00400

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.57036
Value Function Update Magnitude: 0.50336

Collected Steps per Second: 20,616.90611
Overall Steps per Second: 9,997.16919

Timestep Collection Time: 2.42587
Timestep Consumption Time: 2.57694
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 5.00282

Cumulative Model Updates: 134,718
Cumulative Timesteps: 1,123,602,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1123602044...
Checkpoint 1123602044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.94237
Policy Entropy: 3.16336
Value Function Loss: 0.00418

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.49895

Collected Steps per Second: 21,800.79787
Overall Steps per Second: 10,278.31717

Timestep Collection Time: 2.29386
Timestep Consumption Time: 2.57153
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.86539

Cumulative Model Updates: 134,724
Cumulative Timesteps: 1,123,652,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.48312
Policy Entropy: 3.15867
Value Function Loss: 0.00448

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.57134
Value Function Update Magnitude: 0.50173

Collected Steps per Second: 21,505.45309
Overall Steps per Second: 10,423.47053

Timestep Collection Time: 2.32583
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.79859

Cumulative Model Updates: 134,730
Cumulative Timesteps: 1,123,702,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1123702070...
Checkpoint 1123702070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.87588
Policy Entropy: 3.15378
Value Function Loss: 0.00451

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.57334
Value Function Update Magnitude: 0.52305

Collected Steps per Second: 20,869.71763
Overall Steps per Second: 10,179.91602

Timestep Collection Time: 2.39629
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.91261

Cumulative Model Updates: 134,736
Cumulative Timesteps: 1,123,752,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.77877
Policy Entropy: 3.14401
Value Function Loss: 0.00424

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.54834

Collected Steps per Second: 20,793.86997
Overall Steps per Second: 10,127.69744

Timestep Collection Time: 2.40513
Timestep Consumption Time: 2.53301
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.93814

Cumulative Model Updates: 134,742
Cumulative Timesteps: 1,123,802,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1123802092...
Checkpoint 1123802092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,062.19225
Policy Entropy: 3.13079
Value Function Loss: 0.00430

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.56511

Collected Steps per Second: 22,077.29278
Overall Steps per Second: 10,142.87257

Timestep Collection Time: 2.26513
Timestep Consumption Time: 2.66523
PPO Batch Consumption Time: 0.31642
Total Iteration Time: 4.93036

Cumulative Model Updates: 134,748
Cumulative Timesteps: 1,123,852,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.53654
Policy Entropy: 3.13100
Value Function Loss: 0.00455

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.60914
Value Function Update Magnitude: 0.59320

Collected Steps per Second: 21,949.29627
Overall Steps per Second: 10,455.43712

Timestep Collection Time: 2.27816
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.78258

Cumulative Model Updates: 134,754
Cumulative Timesteps: 1,123,902,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1123902104...
Checkpoint 1123902104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.47898
Policy Entropy: 3.14351
Value Function Loss: 0.00428

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.60580
Value Function Update Magnitude: 0.60359

Collected Steps per Second: 20,317.71273
Overall Steps per Second: 10,133.06158

Timestep Collection Time: 2.46110
Timestep Consumption Time: 2.47363
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.93474

Cumulative Model Updates: 134,760
Cumulative Timesteps: 1,123,952,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,731.22443
Policy Entropy: 3.14398
Value Function Loss: 0.00476

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.59779
Value Function Update Magnitude: 0.58090

Collected Steps per Second: 21,904.96458
Overall Steps per Second: 10,434.86672

Timestep Collection Time: 2.28323
Timestep Consumption Time: 2.50974
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.79297

Cumulative Model Updates: 134,766
Cumulative Timesteps: 1,124,002,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1124002122...
Checkpoint 1124002122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.60525
Policy Entropy: 3.13483
Value Function Loss: 0.00441

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.58923
Value Function Update Magnitude: 0.55786

Collected Steps per Second: 21,924.97320
Overall Steps per Second: 10,401.61959

Timestep Collection Time: 2.28142
Timestep Consumption Time: 2.52745
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.80887

Cumulative Model Updates: 134,772
Cumulative Timesteps: 1,124,052,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023.41608
Policy Entropy: 3.11583
Value Function Loss: 0.00431

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.57936
Value Function Update Magnitude: 0.51964

Collected Steps per Second: 22,211.94097
Overall Steps per Second: 10,355.60531

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.57860
PPO Batch Consumption Time: 0.30056
Total Iteration Time: 4.83081

Cumulative Model Updates: 134,778
Cumulative Timesteps: 1,124,102,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1124102168...
Checkpoint 1124102168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.87127
Policy Entropy: 3.12054
Value Function Loss: 0.00400

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.58452
Value Function Update Magnitude: 0.52624

Collected Steps per Second: 21,934.56784
Overall Steps per Second: 10,468.33098

Timestep Collection Time: 2.28024
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.77784

Cumulative Model Updates: 134,784
Cumulative Timesteps: 1,124,152,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.00582
Policy Entropy: 3.12600
Value Function Loss: 0.00407

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.59043
Value Function Update Magnitude: 0.54192

Collected Steps per Second: 21,545.53073
Overall Steps per Second: 10,384.83951

Timestep Collection Time: 2.32067
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.81471

Cumulative Model Updates: 134,790
Cumulative Timesteps: 1,124,202,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1124202184...
Checkpoint 1124202184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.16707
Policy Entropy: 3.13378
Value Function Loss: 0.00412

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.54274

Collected Steps per Second: 22,189.04762
Overall Steps per Second: 10,440.57664

Timestep Collection Time: 2.25454
Timestep Consumption Time: 2.53696
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.79150

Cumulative Model Updates: 134,796
Cumulative Timesteps: 1,124,252,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.13624
Policy Entropy: 3.13359
Value Function Loss: 0.00443

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.58366
Value Function Update Magnitude: 0.55103

Collected Steps per Second: 22,207.26069
Overall Steps per Second: 10,452.48645

Timestep Collection Time: 2.25215
Timestep Consumption Time: 2.53274
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.78489

Cumulative Model Updates: 134,802
Cumulative Timesteps: 1,124,302,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1124302224...
Checkpoint 1124302224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.29089
Policy Entropy: 3.13217
Value Function Loss: 0.00450

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.58406
Value Function Update Magnitude: 0.56291

Collected Steps per Second: 22,105.17610
Overall Steps per Second: 10,519.37848

Timestep Collection Time: 2.26219
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.75370

Cumulative Model Updates: 134,808
Cumulative Timesteps: 1,124,352,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.45357
Policy Entropy: 3.13722
Value Function Loss: 0.00430

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.56087

Collected Steps per Second: 21,503.12612
Overall Steps per Second: 10,072.32562

Timestep Collection Time: 2.32617
Timestep Consumption Time: 2.63991
PPO Batch Consumption Time: 0.30912
Total Iteration Time: 4.96608

Cumulative Model Updates: 134,814
Cumulative Timesteps: 1,124,402,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1124402250...
Checkpoint 1124402250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.66986
Policy Entropy: 3.13291
Value Function Loss: 0.00458

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.53971

Collected Steps per Second: 21,287.67998
Overall Steps per Second: 10,278.07501

Timestep Collection Time: 2.35028
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.86784

Cumulative Model Updates: 134,820
Cumulative Timesteps: 1,124,452,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.19812
Policy Entropy: 3.13502
Value Function Loss: 0.00434

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.57834
Value Function Update Magnitude: 0.54336

Collected Steps per Second: 22,271.43823
Overall Steps per Second: 10,450.32554

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.54032
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.78607

Cumulative Model Updates: 134,826
Cumulative Timesteps: 1,124,502,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1124502298...
Checkpoint 1124502298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.93648
Policy Entropy: 3.12900
Value Function Loss: 0.00463

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.57535
Value Function Update Magnitude: 0.56017

Collected Steps per Second: 21,979.25832
Overall Steps per Second: 10,422.32246

Timestep Collection Time: 2.27542
Timestep Consumption Time: 2.52313
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.79855

Cumulative Model Updates: 134,832
Cumulative Timesteps: 1,124,552,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.86395
Policy Entropy: 3.13352
Value Function Loss: 0.00444

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.56154

Collected Steps per Second: 22,135.91336
Overall Steps per Second: 10,547.99769

Timestep Collection Time: 2.25922
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.74118

Cumulative Model Updates: 134,838
Cumulative Timesteps: 1,124,602,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1124602320...
Checkpoint 1124602320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,192.34927
Policy Entropy: 3.13619
Value Function Loss: 0.00438

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.54332

Collected Steps per Second: 22,360.74449
Overall Steps per Second: 10,437.17293

Timestep Collection Time: 2.23731
Timestep Consumption Time: 2.55594
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.79325

Cumulative Model Updates: 134,844
Cumulative Timesteps: 1,124,652,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.63144
Policy Entropy: 3.14760
Value Function Loss: 0.00419

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.57723
Value Function Update Magnitude: 0.53825

Collected Steps per Second: 20,446.69678
Overall Steps per Second: 10,176.68735

Timestep Collection Time: 2.44558
Timestep Consumption Time: 2.46800
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.91358

Cumulative Model Updates: 134,850
Cumulative Timesteps: 1,124,702,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1124702352...
Checkpoint 1124702352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,779.90422
Policy Entropy: 3.15543
Value Function Loss: 0.00426

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.58903
Value Function Update Magnitude: 0.54591

Collected Steps per Second: 21,658.32369
Overall Steps per Second: 10,409.10140

Timestep Collection Time: 2.30997
Timestep Consumption Time: 2.49640
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.80637

Cumulative Model Updates: 134,856
Cumulative Timesteps: 1,124,752,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.25983
Policy Entropy: 3.14611
Value Function Loss: 0.00417

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.59742
Value Function Update Magnitude: 0.55398

Collected Steps per Second: 22,104.39438
Overall Steps per Second: 10,464.32645

Timestep Collection Time: 2.26272
Timestep Consumption Time: 2.51695
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.77967

Cumulative Model Updates: 134,862
Cumulative Timesteps: 1,124,802,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1124802398...
Checkpoint 1124802398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.52695
Policy Entropy: 3.14412
Value Function Loss: 0.00404

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.59041
Value Function Update Magnitude: 0.53694

Collected Steps per Second: 21,711.97315
Overall Steps per Second: 10,364.81295

Timestep Collection Time: 2.30389
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.82614

Cumulative Model Updates: 134,868
Cumulative Timesteps: 1,124,852,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.31737
Policy Entropy: 3.14304
Value Function Loss: 0.00400

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.57788
Value Function Update Magnitude: 0.52016

Collected Steps per Second: 22,536.12581
Overall Steps per Second: 10,666.04123

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.46941
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.68834

Cumulative Model Updates: 134,874
Cumulative Timesteps: 1,124,902,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1124902426...
Checkpoint 1124902426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.01874
Policy Entropy: 3.13395
Value Function Loss: 0.00434

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.58375
Value Function Update Magnitude: 0.55298

Collected Steps per Second: 21,230.19652
Overall Steps per Second: 10,261.26896

Timestep Collection Time: 2.35523
Timestep Consumption Time: 2.51766
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.87289

Cumulative Model Updates: 134,880
Cumulative Timesteps: 1,124,952,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.88551
Policy Entropy: 3.14825
Value Function Loss: 0.00395

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.58895
Value Function Update Magnitude: 0.58194

Collected Steps per Second: 22,315.49855
Overall Steps per Second: 10,456.13778

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.54322
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 4.78551

Cumulative Model Updates: 134,886
Cumulative Timesteps: 1,125,002,466

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1125002466...
Checkpoint 1125002466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.48565
Policy Entropy: 3.15081
Value Function Loss: 0.00402

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.58522
Value Function Update Magnitude: 0.58374

Collected Steps per Second: 21,970.23522
Overall Steps per Second: 10,586.85603

Timestep Collection Time: 2.27690
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.72510

Cumulative Model Updates: 134,892
Cumulative Timesteps: 1,125,052,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.36320
Policy Entropy: 3.15694
Value Function Loss: 0.00387

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.58810
Value Function Update Magnitude: 0.57521

Collected Steps per Second: 22,175.75539
Overall Steps per Second: 10,506.00765

Timestep Collection Time: 2.25571
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.76128

Cumulative Model Updates: 134,898
Cumulative Timesteps: 1,125,102,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1125102512...
Checkpoint 1125102512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.57617
Policy Entropy: 3.13624
Value Function Loss: 0.00410

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.54666

Collected Steps per Second: 22,047.30574
Overall Steps per Second: 10,551.85412

Timestep Collection Time: 2.26849
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.73983

Cumulative Model Updates: 134,904
Cumulative Timesteps: 1,125,152,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.02320
Policy Entropy: 3.11343
Value Function Loss: 0.00415

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.57881
Value Function Update Magnitude: 0.53097

Collected Steps per Second: 22,220.89823
Overall Steps per Second: 10,567.57496

Timestep Collection Time: 2.25076
Timestep Consumption Time: 2.48202
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.73278

Cumulative Model Updates: 134,910
Cumulative Timesteps: 1,125,202,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1125202540...
Checkpoint 1125202540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.69257
Policy Entropy: 3.12180
Value Function Loss: 0.00438

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.58115
Value Function Update Magnitude: 0.52218

Collected Steps per Second: 22,155.82011
Overall Steps per Second: 10,542.84858

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.48700
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.74483

Cumulative Model Updates: 134,916
Cumulative Timesteps: 1,125,252,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.55678
Policy Entropy: 3.13393
Value Function Loss: 0.00430

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.58378
Value Function Update Magnitude: 0.52988

Collected Steps per Second: 22,192.85321
Overall Steps per Second: 10,591.84205

Timestep Collection Time: 2.25370
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.72212

Cumulative Model Updates: 134,922
Cumulative Timesteps: 1,125,302,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1125302580...
Checkpoint 1125302580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,978.26112
Policy Entropy: 3.16430
Value Function Loss: 0.00409

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.58231
Value Function Update Magnitude: 0.53498

Collected Steps per Second: 21,874.67677
Overall Steps per Second: 10,445.27888

Timestep Collection Time: 2.28648
Timestep Consumption Time: 2.50190
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.78838

Cumulative Model Updates: 134,928
Cumulative Timesteps: 1,125,352,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.78048
Policy Entropy: 3.15690
Value Function Loss: 0.00397

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.55265

Collected Steps per Second: 22,586.63984
Overall Steps per Second: 10,559.30412

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.52267
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.73743

Cumulative Model Updates: 134,934
Cumulative Timesteps: 1,125,402,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1125402620...
Checkpoint 1125402620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,122.58201
Policy Entropy: 3.15738
Value Function Loss: 0.00394

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.58428
Value Function Update Magnitude: 0.55423

Collected Steps per Second: 21,970.64017
Overall Steps per Second: 10,172.53698

Timestep Collection Time: 2.27795
Timestep Consumption Time: 2.64196
PPO Batch Consumption Time: 0.31276
Total Iteration Time: 4.91991

Cumulative Model Updates: 134,940
Cumulative Timesteps: 1,125,452,668

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.82192
Policy Entropy: 3.14109
Value Function Loss: 0.00409

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.58270
Value Function Update Magnitude: 0.56513

Collected Steps per Second: 20,263.78728
Overall Steps per Second: 9,841.36653

Timestep Collection Time: 2.46894
Timestep Consumption Time: 2.61471
PPO Batch Consumption Time: 0.30416
Total Iteration Time: 5.08364

Cumulative Model Updates: 134,946
Cumulative Timesteps: 1,125,502,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1125502698...
Checkpoint 1125502698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.66633
Policy Entropy: 3.11876
Value Function Loss: 0.00397

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.58176
Value Function Update Magnitude: 0.56692

Collected Steps per Second: 21,310.18025
Overall Steps per Second: 10,427.10736

Timestep Collection Time: 2.34695
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.79654

Cumulative Model Updates: 134,952
Cumulative Timesteps: 1,125,552,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.65373
Policy Entropy: 3.11008
Value Function Loss: 0.00392

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.58192
Value Function Update Magnitude: 0.54910

Collected Steps per Second: 22,329.43926
Overall Steps per Second: 10,538.18489

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.74465

Cumulative Model Updates: 134,958
Cumulative Timesteps: 1,125,602,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1125602712...
Checkpoint 1125602712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,815.77496
Policy Entropy: 3.09771
Value Function Loss: 0.00406

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.53650

Collected Steps per Second: 22,056.85557
Overall Steps per Second: 10,531.34323

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.75077

Cumulative Model Updates: 134,964
Cumulative Timesteps: 1,125,652,744

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.63373
Policy Entropy: 3.10568
Value Function Loss: 0.00419

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.59806
Value Function Update Magnitude: 0.53163

Collected Steps per Second: 22,160.55875
Overall Steps per Second: 10,615.76376

Timestep Collection Time: 2.25644
Timestep Consumption Time: 2.45391
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.71035

Cumulative Model Updates: 134,970
Cumulative Timesteps: 1,125,702,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1125702748...
Checkpoint 1125702748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.66767
Policy Entropy: 3.10336
Value Function Loss: 0.00407

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.58798
Value Function Update Magnitude: 0.53298

Collected Steps per Second: 22,075.81246
Overall Steps per Second: 10,549.29857

Timestep Collection Time: 2.26501
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.73984

Cumulative Model Updates: 134,976
Cumulative Timesteps: 1,125,752,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,655.58563
Policy Entropy: 3.10446
Value Function Loss: 0.00396

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.50915

Collected Steps per Second: 22,299.62248
Overall Steps per Second: 10,510.65550

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.51509
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.75746

Cumulative Model Updates: 134,982
Cumulative Timesteps: 1,125,802,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1125802754...
Checkpoint 1125802754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.76957
Policy Entropy: 3.10191
Value Function Loss: 0.00397

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.58696
Value Function Update Magnitude: 0.50451

Collected Steps per Second: 22,218.26216
Overall Steps per Second: 10,590.53168

Timestep Collection Time: 2.25193
Timestep Consumption Time: 2.47248
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.72441

Cumulative Model Updates: 134,988
Cumulative Timesteps: 1,125,852,788

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.53423
Policy Entropy: 3.11293
Value Function Loss: 0.00389

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.58178
Value Function Update Magnitude: 0.50612

Collected Steps per Second: 22,344.00528
Overall Steps per Second: 10,508.22501

Timestep Collection Time: 2.23801
Timestep Consumption Time: 2.52074
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.75875

Cumulative Model Updates: 134,994
Cumulative Timesteps: 1,125,902,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1125902794...
Checkpoint 1125902794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.18186
Policy Entropy: 3.13554
Value Function Loss: 0.00403

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.50060

Collected Steps per Second: 22,000.51236
Overall Steps per Second: 10,410.44105

Timestep Collection Time: 2.27340
Timestep Consumption Time: 2.53101
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.80441

Cumulative Model Updates: 135,000
Cumulative Timesteps: 1,125,952,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,316.87239
Policy Entropy: 3.14454
Value Function Loss: 0.00430

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.58356
Value Function Update Magnitude: 0.50829

Collected Steps per Second: 22,297.64223
Overall Steps per Second: 10,553.70272

Timestep Collection Time: 2.24347
Timestep Consumption Time: 2.49648
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.73995

Cumulative Model Updates: 135,006
Cumulative Timesteps: 1,126,002,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1126002834...
Checkpoint 1126002834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.91341
Policy Entropy: 3.14081
Value Function Loss: 0.00452

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.58512
Value Function Update Magnitude: 0.51779

Collected Steps per Second: 21,622.30466
Overall Steps per Second: 10,397.18843

Timestep Collection Time: 2.31400
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.81226

Cumulative Model Updates: 135,012
Cumulative Timesteps: 1,126,052,868

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.71602
Policy Entropy: 3.13995
Value Function Loss: 0.00433

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.58198
Value Function Update Magnitude: 0.52037

Collected Steps per Second: 22,316.25482
Overall Steps per Second: 10,440.65633

Timestep Collection Time: 2.24088
Timestep Consumption Time: 2.54886
PPO Batch Consumption Time: 0.30157
Total Iteration Time: 4.78974

Cumulative Model Updates: 135,018
Cumulative Timesteps: 1,126,102,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1126102876...
Checkpoint 1126102876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.81419
Policy Entropy: 3.12390
Value Function Loss: 0.00407

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.49762

Collected Steps per Second: 21,773.58959
Overall Steps per Second: 10,298.87477

Timestep Collection Time: 2.29654
Timestep Consumption Time: 2.55874
PPO Batch Consumption Time: 0.30203
Total Iteration Time: 4.85529

Cumulative Model Updates: 135,024
Cumulative Timesteps: 1,126,152,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.63807
Policy Entropy: 3.13030
Value Function Loss: 0.00403

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.47856

Collected Steps per Second: 22,210.20876
Overall Steps per Second: 10,508.03885

Timestep Collection Time: 2.25266
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.76131

Cumulative Model Updates: 135,030
Cumulative Timesteps: 1,126,202,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1126202912...
Checkpoint 1126202912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.19978
Policy Entropy: 3.12954
Value Function Loss: 0.00397

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.57568
Value Function Update Magnitude: 0.48354

Collected Steps per Second: 22,229.13238
Overall Steps per Second: 10,458.46922

Timestep Collection Time: 2.25047
Timestep Consumption Time: 2.53283
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.78330

Cumulative Model Updates: 135,036
Cumulative Timesteps: 1,126,252,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.52139
Policy Entropy: 3.14126
Value Function Loss: 0.00390

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.48282

Collected Steps per Second: 22,177.08576
Overall Steps per Second: 10,510.04699

Timestep Collection Time: 2.25548
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.75926

Cumulative Model Updates: 135,042
Cumulative Timesteps: 1,126,302,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1126302958...
Checkpoint 1126302958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.62375
Policy Entropy: 3.14183
Value Function Loss: 0.00383

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.47885

Collected Steps per Second: 21,822.61031
Overall Steps per Second: 10,484.48570

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.47854
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.77048

Cumulative Model Updates: 135,048
Cumulative Timesteps: 1,126,352,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,241.49857
Policy Entropy: 3.13038
Value Function Loss: 0.00399

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.58574
Value Function Update Magnitude: 0.48887

Collected Steps per Second: 22,407.91282
Overall Steps per Second: 10,566.38172

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.73294

Cumulative Model Updates: 135,054
Cumulative Timesteps: 1,126,402,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1126402984...
Checkpoint 1126402984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,088.49272
Policy Entropy: 3.13527
Value Function Loss: 0.00406

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.59768
Value Function Update Magnitude: 0.51309

Collected Steps per Second: 21,887.53162
Overall Steps per Second: 10,547.58065

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.45730
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.74289

Cumulative Model Updates: 135,060
Cumulative Timesteps: 1,126,453,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.90286
Policy Entropy: 3.13893
Value Function Loss: 0.00401

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.59349
Value Function Update Magnitude: 0.53242

Collected Steps per Second: 22,472.05247
Overall Steps per Second: 10,571.23003

Timestep Collection Time: 2.22570
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.73133

Cumulative Model Updates: 135,066
Cumulative Timesteps: 1,126,503,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1126503026...
Checkpoint 1126503026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,488.73385
Policy Entropy: 3.14242
Value Function Loss: 0.00405

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.59140
Value Function Update Magnitude: 0.56370

Collected Steps per Second: 21,966.32039
Overall Steps per Second: 10,598.06504

Timestep Collection Time: 2.27658
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.71860

Cumulative Model Updates: 135,072
Cumulative Timesteps: 1,126,553,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.08632
Policy Entropy: 3.13559
Value Function Loss: 0.00403

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.58789
Value Function Update Magnitude: 0.54430

Collected Steps per Second: 22,170.28132
Overall Steps per Second: 10,470.72622

Timestep Collection Time: 2.25662
Timestep Consumption Time: 2.52146
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.77808

Cumulative Model Updates: 135,078
Cumulative Timesteps: 1,126,603,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1126603064...
Checkpoint 1126603064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.28279
Policy Entropy: 3.12456
Value Function Loss: 0.00437

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.54075

Collected Steps per Second: 21,808.14423
Overall Steps per Second: 10,682.21601

Timestep Collection Time: 2.29327
Timestep Consumption Time: 2.38853
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.68180

Cumulative Model Updates: 135,084
Cumulative Timesteps: 1,126,653,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.10289
Policy Entropy: 3.11967
Value Function Loss: 0.00476

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.59772
Value Function Update Magnitude: 0.55696

Collected Steps per Second: 21,872.78521
Overall Steps per Second: 10,126.04835

Timestep Collection Time: 2.28732
Timestep Consumption Time: 2.65341
PPO Batch Consumption Time: 0.31429
Total Iteration Time: 4.94072

Cumulative Model Updates: 135,090
Cumulative Timesteps: 1,126,703,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1126703106...
Checkpoint 1126703106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.35187
Policy Entropy: 3.12358
Value Function Loss: 0.00468

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.59880
Value Function Update Magnitude: 0.56699

Collected Steps per Second: 18,392.31056
Overall Steps per Second: 8,589.76613

Timestep Collection Time: 2.71961
Timestep Consumption Time: 3.10359
PPO Batch Consumption Time: 0.36997
Total Iteration Time: 5.82321

Cumulative Model Updates: 135,096
Cumulative Timesteps: 1,126,753,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.69084
Policy Entropy: 3.11789
Value Function Loss: 0.00460

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.59948
Value Function Update Magnitude: 0.56704

Collected Steps per Second: 20,890.02483
Overall Steps per Second: 9,603.68459

Timestep Collection Time: 2.39406
Timestep Consumption Time: 2.81352
PPO Batch Consumption Time: 0.33549
Total Iteration Time: 5.20758

Cumulative Model Updates: 135,102
Cumulative Timesteps: 1,126,803,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1126803138...
Checkpoint 1126803138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.11312
Policy Entropy: 3.11835
Value Function Loss: 0.00464

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.61186
Value Function Update Magnitude: 0.58318

Collected Steps per Second: 21,342.77942
Overall Steps per Second: 9,291.62123

Timestep Collection Time: 2.34402
Timestep Consumption Time: 3.04018
PPO Batch Consumption Time: 0.36932
Total Iteration Time: 5.38421

Cumulative Model Updates: 135,108
Cumulative Timesteps: 1,126,853,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.96347
Policy Entropy: 3.12006
Value Function Loss: 0.00427

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.61279
Value Function Update Magnitude: 0.60811

Collected Steps per Second: 17,770.18224
Overall Steps per Second: 8,491.17643

Timestep Collection Time: 2.81381
Timestep Consumption Time: 3.07489
PPO Batch Consumption Time: 0.36301
Total Iteration Time: 5.88870

Cumulative Model Updates: 135,114
Cumulative Timesteps: 1,126,903,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1126903168...
Checkpoint 1126903168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.05176
Policy Entropy: 3.13033
Value Function Loss: 0.00450

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.60838
Value Function Update Magnitude: 0.60825

Collected Steps per Second: 17,923.66526
Overall Steps per Second: 8,569.96595

Timestep Collection Time: 2.78961
Timestep Consumption Time: 3.04472
PPO Batch Consumption Time: 0.36891
Total Iteration Time: 5.83433

Cumulative Model Updates: 135,120
Cumulative Timesteps: 1,126,953,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.02240
Policy Entropy: 3.11395
Value Function Loss: 0.00460

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.61892
Value Function Update Magnitude: 0.62510

Collected Steps per Second: 17,765.12737
Overall Steps per Second: 8,512.24287

Timestep Collection Time: 2.81540
Timestep Consumption Time: 3.06037
PPO Batch Consumption Time: 0.36747
Total Iteration Time: 5.87577

Cumulative Model Updates: 135,126
Cumulative Timesteps: 1,127,003,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1127003184...
Checkpoint 1127003184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.66924
Policy Entropy: 3.11121
Value Function Loss: 0.00482

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.62466
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 19,106.37386
Overall Steps per Second: 9,610.64219

Timestep Collection Time: 2.61808
Timestep Consumption Time: 2.58678
PPO Batch Consumption Time: 0.30827
Total Iteration Time: 5.20486

Cumulative Model Updates: 135,132
Cumulative Timesteps: 1,127,053,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.67715
Policy Entropy: 3.10583
Value Function Loss: 0.00458

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.61838
Value Function Update Magnitude: 0.63348

Collected Steps per Second: 22,684.99458
Overall Steps per Second: 10,609.11585

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.71425

Cumulative Model Updates: 135,138
Cumulative Timesteps: 1,127,103,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1127103220...
Checkpoint 1127103220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.83239
Policy Entropy: 3.11397
Value Function Loss: 0.00468

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.61772
Value Function Update Magnitude: 0.58627

Collected Steps per Second: 20,413.78243
Overall Steps per Second: 10,120.31032

Timestep Collection Time: 2.45080
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.94352

Cumulative Model Updates: 135,144
Cumulative Timesteps: 1,127,153,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.89932
Policy Entropy: 3.12031
Value Function Loss: 0.00438

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.61385
Value Function Update Magnitude: 0.59036

Collected Steps per Second: 22,100.41210
Overall Steps per Second: 10,528.86334

Timestep Collection Time: 2.26358
Timestep Consumption Time: 2.48774
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.75132

Cumulative Model Updates: 135,150
Cumulative Timesteps: 1,127,203,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1127203276...
Checkpoint 1127203276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.10732
Policy Entropy: 3.11027
Value Function Loss: 0.00454

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.62314
Value Function Update Magnitude: 0.61078

Collected Steps per Second: 21,533.70172
Overall Steps per Second: 10,352.20812

Timestep Collection Time: 2.32278
Timestep Consumption Time: 2.50885
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.83163

Cumulative Model Updates: 135,156
Cumulative Timesteps: 1,127,253,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.56151
Policy Entropy: 3.11897
Value Function Loss: 0.00463

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.62916
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 22,403.14189
Overall Steps per Second: 10,637.33539

Timestep Collection Time: 2.23254
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.70193

Cumulative Model Updates: 135,162
Cumulative Timesteps: 1,127,303,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1127303310...
Checkpoint 1127303310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,128.05532
Policy Entropy: 3.11055
Value Function Loss: 0.00453

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.62006
Value Function Update Magnitude: 0.63760

Collected Steps per Second: 22,076.77838
Overall Steps per Second: 10,368.29326

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.55911
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 4.82529

Cumulative Model Updates: 135,168
Cumulative Timesteps: 1,127,353,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.77089
Policy Entropy: 3.11472
Value Function Loss: 0.00442

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.61570
Value Function Update Magnitude: 0.61132

Collected Steps per Second: 22,016.22427
Overall Steps per Second: 10,304.27529

Timestep Collection Time: 2.27160
Timestep Consumption Time: 2.58192
PPO Batch Consumption Time: 0.30667
Total Iteration Time: 4.85352

Cumulative Model Updates: 135,174
Cumulative Timesteps: 1,127,403,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1127403352...
Checkpoint 1127403352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.71774
Policy Entropy: 3.11923
Value Function Loss: 0.00444

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.61285
Value Function Update Magnitude: 0.58205

Collected Steps per Second: 21,986.97434
Overall Steps per Second: 10,332.32612

Timestep Collection Time: 2.27480
Timestep Consumption Time: 2.56593
PPO Batch Consumption Time: 0.30207
Total Iteration Time: 4.84073

Cumulative Model Updates: 135,180
Cumulative Timesteps: 1,127,453,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.68928
Policy Entropy: 3.14709
Value Function Loss: 0.00407

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.59928
Value Function Update Magnitude: 0.55412

Collected Steps per Second: 21,462.57921
Overall Steps per Second: 10,382.90496

Timestep Collection Time: 2.33047
Timestep Consumption Time: 2.48687
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.81734

Cumulative Model Updates: 135,186
Cumulative Timesteps: 1,127,503,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1127503386...
Checkpoint 1127503386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.33914
Policy Entropy: 3.16311
Value Function Loss: 0.00385

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.53638

Collected Steps per Second: 21,795.34775
Overall Steps per Second: 10,258.94460

Timestep Collection Time: 2.29443
Timestep Consumption Time: 2.58014
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.87458

Cumulative Model Updates: 135,192
Cumulative Timesteps: 1,127,553,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,046.92851
Policy Entropy: 3.16703
Value Function Loss: 0.00398

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.57592
Value Function Update Magnitude: 0.53149

Collected Steps per Second: 22,375.22523
Overall Steps per Second: 10,486.02968

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.53414
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.76920

Cumulative Model Updates: 135,198
Cumulative Timesteps: 1,127,603,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1127603404...
Checkpoint 1127603404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,165.32750
Policy Entropy: 3.14465
Value Function Loss: 0.00444

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.59241
Value Function Update Magnitude: 0.57039

Collected Steps per Second: 21,781.91304
Overall Steps per Second: 10,333.81579

Timestep Collection Time: 2.29695
Timestep Consumption Time: 2.54463
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.84158

Cumulative Model Updates: 135,204
Cumulative Timesteps: 1,127,653,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.57507
Policy Entropy: 3.13162
Value Function Loss: 0.00435

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.59155
Value Function Update Magnitude: 0.56966

Collected Steps per Second: 22,480.99781
Overall Steps per Second: 10,661.73720

Timestep Collection Time: 2.22526
Timestep Consumption Time: 2.46685
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.69211

Cumulative Model Updates: 135,210
Cumulative Timesteps: 1,127,703,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1127703462...
Checkpoint 1127703462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.13236
Policy Entropy: 3.13193
Value Function Loss: 0.00416

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.58557
Value Function Update Magnitude: 0.55714

Collected Steps per Second: 21,780.51626
Overall Steps per Second: 10,305.74139

Timestep Collection Time: 2.29600
Timestep Consumption Time: 2.55644
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.85244

Cumulative Model Updates: 135,216
Cumulative Timesteps: 1,127,753,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.68087
Policy Entropy: 3.16522
Value Function Loss: 0.00380

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.57562
Value Function Update Magnitude: 0.54312

Collected Steps per Second: 22,028.84014
Overall Steps per Second: 10,443.04783

Timestep Collection Time: 2.26993
Timestep Consumption Time: 2.51832
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.78826

Cumulative Model Updates: 135,222
Cumulative Timesteps: 1,127,803,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1127803474...
Checkpoint 1127803474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.76975
Policy Entropy: 3.16924
Value Function Loss: 0.00389

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.57699
Value Function Update Magnitude: 0.51493

Collected Steps per Second: 18,030.66590
Overall Steps per Second: 8,722.77472

Timestep Collection Time: 2.77438
Timestep Consumption Time: 2.96049
PPO Batch Consumption Time: 0.36215
Total Iteration Time: 5.73487

Cumulative Model Updates: 135,228
Cumulative Timesteps: 1,127,853,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076.45515
Policy Entropy: 3.16446
Value Function Loss: 0.00386

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.58327
Value Function Update Magnitude: 0.50895

Collected Steps per Second: 19,489.53960
Overall Steps per Second: 9,768.98577

Timestep Collection Time: 2.56620
Timestep Consumption Time: 2.55347
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 5.11967

Cumulative Model Updates: 135,234
Cumulative Timesteps: 1,127,903,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1127903512...
Checkpoint 1127903512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.84032
Policy Entropy: 3.14329
Value Function Loss: 0.00396

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.58822
Value Function Update Magnitude: 0.50718

Collected Steps per Second: 21,385.19169
Overall Steps per Second: 10,068.96587

Timestep Collection Time: 2.33853
Timestep Consumption Time: 2.62821
PPO Batch Consumption Time: 0.31567
Total Iteration Time: 4.96675

Cumulative Model Updates: 135,240
Cumulative Timesteps: 1,127,953,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.21192
Policy Entropy: 3.14116
Value Function Loss: 0.00399

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.58580
Value Function Update Magnitude: 0.49614

Collected Steps per Second: 21,501.96237
Overall Steps per Second: 9,745.62022

Timestep Collection Time: 2.32630
Timestep Consumption Time: 2.80626
PPO Batch Consumption Time: 0.33519
Total Iteration Time: 5.13256

Cumulative Model Updates: 135,246
Cumulative Timesteps: 1,128,003,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1128003542...
Checkpoint 1128003542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904.87609
Policy Entropy: 3.13853
Value Function Loss: 0.00417

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.58739
Value Function Update Magnitude: 0.51520

Collected Steps per Second: 21,726.87885
Overall Steps per Second: 10,453.59819

Timestep Collection Time: 2.30139
Timestep Consumption Time: 2.48184
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.78323

Cumulative Model Updates: 135,252
Cumulative Timesteps: 1,128,053,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.20081
Policy Entropy: 3.13221
Value Function Loss: 0.00425

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.59335
Value Function Update Magnitude: 0.54836

Collected Steps per Second: 18,870.12611
Overall Steps per Second: 9,607.66222

Timestep Collection Time: 2.65075
Timestep Consumption Time: 2.55551
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 5.20626

Cumulative Model Updates: 135,258
Cumulative Timesteps: 1,128,103,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1128103564...
Checkpoint 1128103564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.67594
Policy Entropy: 3.12410
Value Function Loss: 0.00410

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.59421
Value Function Update Magnitude: 0.56463

Collected Steps per Second: 21,533.75639
Overall Steps per Second: 10,307.35895

Timestep Collection Time: 2.32361
Timestep Consumption Time: 2.53079
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.85440

Cumulative Model Updates: 135,264
Cumulative Timesteps: 1,128,153,600

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.88269
Policy Entropy: 3.12250
Value Function Loss: 0.00398

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.54310

Collected Steps per Second: 21,555.23109
Overall Steps per Second: 10,171.17374

Timestep Collection Time: 2.31990
Timestep Consumption Time: 2.59654
PPO Batch Consumption Time: 0.30741
Total Iteration Time: 4.91644

Cumulative Model Updates: 135,270
Cumulative Timesteps: 1,128,203,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1128203606...
Checkpoint 1128203606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792.56880
Policy Entropy: 3.11900
Value Function Loss: 0.00438

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.59373
Value Function Update Magnitude: 0.54426

Collected Steps per Second: 21,204.41411
Overall Steps per Second: 10,059.59991

Timestep Collection Time: 2.35800
Timestep Consumption Time: 2.61238
PPO Batch Consumption Time: 0.31027
Total Iteration Time: 4.97038

Cumulative Model Updates: 135,276
Cumulative Timesteps: 1,128,253,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.67596
Policy Entropy: 3.13555
Value Function Loss: 0.00457

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.59974
Value Function Update Magnitude: 0.57963

Collected Steps per Second: 21,326.83996
Overall Steps per Second: 10,127.93732

Timestep Collection Time: 2.34446
Timestep Consumption Time: 2.59238
PPO Batch Consumption Time: 0.30756
Total Iteration Time: 4.93684

Cumulative Model Updates: 135,282
Cumulative Timesteps: 1,128,303,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1128303606...
Checkpoint 1128303606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.26120
Policy Entropy: 3.13397
Value Function Loss: 0.00491

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.61340
Value Function Update Magnitude: 0.59043

Collected Steps per Second: 21,097.03128
Overall Steps per Second: 10,214.44513

Timestep Collection Time: 2.37019
Timestep Consumption Time: 2.52523
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.89542

Cumulative Model Updates: 135,288
Cumulative Timesteps: 1,128,353,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.99962
Policy Entropy: 3.13984
Value Function Loss: 0.00462

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.61220
Value Function Update Magnitude: 0.57071

Collected Steps per Second: 22,213.01516
Overall Steps per Second: 10,481.10945

Timestep Collection Time: 2.25165
Timestep Consumption Time: 2.52036
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.77201

Cumulative Model Updates: 135,294
Cumulative Timesteps: 1,128,403,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1128403626...
Checkpoint 1128403626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.20658
Policy Entropy: 3.13014
Value Function Loss: 0.00420

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.53526

Collected Steps per Second: 22,312.59976
Overall Steps per Second: 10,608.68997

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.47352
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.71557

Cumulative Model Updates: 135,300
Cumulative Timesteps: 1,128,453,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.48586
Policy Entropy: 3.14191
Value Function Loss: 0.00355

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.56170
Value Function Update Magnitude: 0.48845

Collected Steps per Second: 20,101.85018
Overall Steps per Second: 10,004.56657

Timestep Collection Time: 2.48783
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.99872

Cumulative Model Updates: 135,306
Cumulative Timesteps: 1,128,503,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1128503662...
Checkpoint 1128503662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.36451
Policy Entropy: 3.13798
Value Function Loss: 0.00410

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.56233
Value Function Update Magnitude: 0.48237

Collected Steps per Second: 21,930.92369
Overall Steps per Second: 9,858.66086

Timestep Collection Time: 2.28052
Timestep Consumption Time: 2.79258
PPO Batch Consumption Time: 0.34392
Total Iteration Time: 5.07310

Cumulative Model Updates: 135,312
Cumulative Timesteps: 1,128,553,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.65825
Policy Entropy: 3.13508
Value Function Loss: 0.00433

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.58341
Value Function Update Magnitude: 0.51420

Collected Steps per Second: 19,087.71497
Overall Steps per Second: 8,775.54563

Timestep Collection Time: 2.62095
Timestep Consumption Time: 3.07989
PPO Batch Consumption Time: 0.38086
Total Iteration Time: 5.70084

Cumulative Model Updates: 135,318
Cumulative Timesteps: 1,128,603,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1128603704...
Checkpoint 1128603704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.74601
Policy Entropy: 3.12174
Value Function Loss: 0.00458

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.59810
Value Function Update Magnitude: 0.54664

Collected Steps per Second: 17,434.65985
Overall Steps per Second: 8,526.95563

Timestep Collection Time: 2.86854
Timestep Consumption Time: 2.99663
PPO Batch Consumption Time: 0.35694
Total Iteration Time: 5.86516

Cumulative Model Updates: 135,324
Cumulative Timesteps: 1,128,653,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.84563
Policy Entropy: 3.12260
Value Function Loss: 0.00420

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.59563
Value Function Update Magnitude: 0.54148

Collected Steps per Second: 21,291.28570
Overall Steps per Second: 9,299.78453

Timestep Collection Time: 2.34941
Timestep Consumption Time: 3.02942
PPO Batch Consumption Time: 0.35650
Total Iteration Time: 5.37883

Cumulative Model Updates: 135,330
Cumulative Timesteps: 1,128,703,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1128703738...
Checkpoint 1128703738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.57248
Policy Entropy: 3.11647
Value Function Loss: 0.00422

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.58877
Value Function Update Magnitude: 0.53220

Collected Steps per Second: 21,195.75529
Overall Steps per Second: 10,174.76198

Timestep Collection Time: 2.35915
Timestep Consumption Time: 2.55536
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.91451

Cumulative Model Updates: 135,336
Cumulative Timesteps: 1,128,753,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.38427
Policy Entropy: 3.12521
Value Function Loss: 0.00418

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.58678
Value Function Update Magnitude: 0.53012

Collected Steps per Second: 22,606.25082
Overall Steps per Second: 10,633.94947

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.70606

Cumulative Model Updates: 135,342
Cumulative Timesteps: 1,128,803,786

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1128803786...
Checkpoint 1128803786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,005.23735
Policy Entropy: 3.11759
Value Function Loss: 0.00438

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.58833
Value Function Update Magnitude: 0.52000

Collected Steps per Second: 22,022.44745
Overall Steps per Second: 10,285.16015

Timestep Collection Time: 2.27105
Timestep Consumption Time: 2.59169
PPO Batch Consumption Time: 0.30944
Total Iteration Time: 4.86273

Cumulative Model Updates: 135,348
Cumulative Timesteps: 1,128,853,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.68345
Policy Entropy: 3.12002
Value Function Loss: 0.00441

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.59900
Value Function Update Magnitude: 0.52158

Collected Steps per Second: 22,062.16202
Overall Steps per Second: 10,464.84389

Timestep Collection Time: 2.26723
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.77981

Cumulative Model Updates: 135,354
Cumulative Timesteps: 1,128,903,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1128903820...
Checkpoint 1128903820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.58122
Policy Entropy: 3.10821
Value Function Loss: 0.00457

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.60125
Value Function Update Magnitude: 0.55327

Collected Steps per Second: 21,845.79540
Overall Steps per Second: 10,562.72302

Timestep Collection Time: 2.28904
Timestep Consumption Time: 2.44515
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.73420

Cumulative Model Updates: 135,360
Cumulative Timesteps: 1,128,953,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,639.97752
Policy Entropy: 3.11871
Value Function Loss: 0.00444

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.59154
Value Function Update Magnitude: 0.55205

Collected Steps per Second: 22,108.89051
Overall Steps per Second: 10,521.97107

Timestep Collection Time: 2.26307
Timestep Consumption Time: 2.49212
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.75519

Cumulative Model Updates: 135,366
Cumulative Timesteps: 1,129,003,860

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1129003860...
Checkpoint 1129003860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.60512
Policy Entropy: 3.11286
Value Function Loss: 0.00494

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.59733
Value Function Update Magnitude: 0.52646

Collected Steps per Second: 21,986.55776
Overall Steps per Second: 10,520.94585

Timestep Collection Time: 2.27484
Timestep Consumption Time: 2.47910
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.75395

Cumulative Model Updates: 135,372
Cumulative Timesteps: 1,129,053,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928.52416
Policy Entropy: 3.12270
Value Function Loss: 0.00463

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.59357
Value Function Update Magnitude: 0.52810

Collected Steps per Second: 22,167.50307
Overall Steps per Second: 10,642.09746

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.44414
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.70095

Cumulative Model Updates: 135,378
Cumulative Timesteps: 1,129,103,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1129103904...
Checkpoint 1129103904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.09670
Policy Entropy: 3.11861
Value Function Loss: 0.00436

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.58611
Value Function Update Magnitude: 0.52703

Collected Steps per Second: 22,060.79766
Overall Steps per Second: 10,583.85976

Timestep Collection Time: 2.26719
Timestep Consumption Time: 2.45850
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.72569

Cumulative Model Updates: 135,384
Cumulative Timesteps: 1,129,153,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.29894
Policy Entropy: 3.12843
Value Function Loss: 0.00387

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.57830
Value Function Update Magnitude: 0.52978

Collected Steps per Second: 22,251.63206
Overall Steps per Second: 10,482.49838

Timestep Collection Time: 2.24792
Timestep Consumption Time: 2.52384
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.77176

Cumulative Model Updates: 135,390
Cumulative Timesteps: 1,129,203,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1129203940...
Checkpoint 1129203940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.87719
Policy Entropy: 3.12868
Value Function Loss: 0.00417

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.58366
Value Function Update Magnitude: 0.54276

Collected Steps per Second: 22,244.59703
Overall Steps per Second: 10,413.27482

Timestep Collection Time: 2.24936
Timestep Consumption Time: 2.55567
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 4.80502

Cumulative Model Updates: 135,396
Cumulative Timesteps: 1,129,253,976

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.95383
Policy Entropy: 3.14426
Value Function Loss: 0.00437

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.59498
Value Function Update Magnitude: 0.57233

Collected Steps per Second: 22,611.17163
Overall Steps per Second: 10,566.64009

Timestep Collection Time: 2.21165
Timestep Consumption Time: 2.52098
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.73263

Cumulative Model Updates: 135,402
Cumulative Timesteps: 1,129,303,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1129303984...
Checkpoint 1129303984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.16969
Policy Entropy: 3.13403
Value Function Loss: 0.00442

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.58871
Value Function Update Magnitude: 0.58662

Collected Steps per Second: 21,658.95187
Overall Steps per Second: 10,333.53562

Timestep Collection Time: 2.30944
Timestep Consumption Time: 2.53111
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.84055

Cumulative Model Updates: 135,408
Cumulative Timesteps: 1,129,354,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.83378
Policy Entropy: 3.11403
Value Function Loss: 0.00426

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.59274
Value Function Update Magnitude: 0.56994

Collected Steps per Second: 22,448.83001
Overall Steps per Second: 10,493.48016

Timestep Collection Time: 2.22800
Timestep Consumption Time: 2.53839
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.76639

Cumulative Model Updates: 135,414
Cumulative Timesteps: 1,129,404,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1129404020...
Checkpoint 1129404020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.85707
Policy Entropy: 3.11377
Value Function Loss: 0.00416

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.59039
Value Function Update Magnitude: 0.56047

Collected Steps per Second: 22,149.22111
Overall Steps per Second: 10,614.29754

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.71195

Cumulative Model Updates: 135,420
Cumulative Timesteps: 1,129,454,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,901.23353
Policy Entropy: 3.11257
Value Function Loss: 0.00486

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.60436
Value Function Update Magnitude: 0.57697

Collected Steps per Second: 22,375.88662
Overall Steps per Second: 10,454.09470

Timestep Collection Time: 2.23517
Timestep Consumption Time: 2.54898
PPO Batch Consumption Time: 0.30090
Total Iteration Time: 4.78415

Cumulative Model Updates: 135,426
Cumulative Timesteps: 1,129,504,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1129504048...
Checkpoint 1129504048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.68617
Policy Entropy: 3.12649
Value Function Loss: 0.00470

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.61331
Value Function Update Magnitude: 0.61374

Collected Steps per Second: 21,906.15119
Overall Steps per Second: 10,547.92093

Timestep Collection Time: 2.28456
Timestep Consumption Time: 2.46007
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.74463

Cumulative Model Updates: 135,432
Cumulative Timesteps: 1,129,554,094

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.46453
Policy Entropy: 3.12957
Value Function Loss: 0.00404

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.59776
Value Function Update Magnitude: 0.60080

Collected Steps per Second: 22,081.46710
Overall Steps per Second: 10,548.43107

Timestep Collection Time: 2.26434
Timestep Consumption Time: 2.47570
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.74004

Cumulative Model Updates: 135,438
Cumulative Timesteps: 1,129,604,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1129604094...
Checkpoint 1129604094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.03146
Policy Entropy: 3.14493
Value Function Loss: 0.00370

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.56849
Value Function Update Magnitude: 0.54872

Collected Steps per Second: 22,160.19157
Overall Steps per Second: 10,549.47547

Timestep Collection Time: 2.25702
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.74109

Cumulative Model Updates: 135,444
Cumulative Timesteps: 1,129,654,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,429.45147
Policy Entropy: 3.14921
Value Function Loss: 0.00375

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.51812

Collected Steps per Second: 22,008.12070
Overall Steps per Second: 10,623.05796

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.70957

Cumulative Model Updates: 135,450
Cumulative Timesteps: 1,129,704,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1129704140...
Checkpoint 1129704140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.85444
Policy Entropy: 3.14812
Value Function Loss: 0.00418

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.57277
Value Function Update Magnitude: 0.52781

Collected Steps per Second: 21,905.10454
Overall Steps per Second: 10,526.00980

Timestep Collection Time: 2.28285
Timestep Consumption Time: 2.46786
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.75071

Cumulative Model Updates: 135,456
Cumulative Timesteps: 1,129,754,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.76613
Policy Entropy: 3.14418
Value Function Loss: 0.00418

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.56952
Value Function Update Magnitude: 0.53678

Collected Steps per Second: 22,436.35644
Overall Steps per Second: 10,547.71468

Timestep Collection Time: 2.22888
Timestep Consumption Time: 2.51224
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.74112

Cumulative Model Updates: 135,462
Cumulative Timesteps: 1,129,804,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1129804154...
Checkpoint 1129804154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981.92284
Policy Entropy: 3.14762
Value Function Loss: 0.00422

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.55868
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 21,961.88860
Overall Steps per Second: 10,362.78300

Timestep Collection Time: 2.27676
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.82515

Cumulative Model Updates: 135,468
Cumulative Timesteps: 1,129,854,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,725.03629
Policy Entropy: 3.16478
Value Function Loss: 0.00377

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.55038
Value Function Update Magnitude: 0.52206

Collected Steps per Second: 22,377.65141
Overall Steps per Second: 10,319.21481

Timestep Collection Time: 2.23509
Timestep Consumption Time: 2.61179
PPO Batch Consumption Time: 0.30668
Total Iteration Time: 4.84688

Cumulative Model Updates: 135,474
Cumulative Timesteps: 1,129,904,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1129904172...
Checkpoint 1129904172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,146.40514
Policy Entropy: 3.16567
Value Function Loss: 0.00372

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.49945

Collected Steps per Second: 21,862.62312
Overall Steps per Second: 10,288.93484

Timestep Collection Time: 2.28829
Timestep Consumption Time: 2.57402
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.86231

Cumulative Model Updates: 135,480
Cumulative Timesteps: 1,129,954,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.49501
Policy Entropy: 3.15445
Value Function Loss: 0.00400

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.50693

Collected Steps per Second: 22,176.11155
Overall Steps per Second: 10,322.84692

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.58905
PPO Batch Consumption Time: 0.30299
Total Iteration Time: 4.84382

Cumulative Model Updates: 135,486
Cumulative Timesteps: 1,130,004,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1130004202...
Checkpoint 1130004202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.79439
Policy Entropy: 3.14456
Value Function Loss: 0.00395

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.56324
Value Function Update Magnitude: 0.52406

Collected Steps per Second: 22,137.60752
Overall Steps per Second: 10,585.70869

Timestep Collection Time: 2.25986
Timestep Consumption Time: 2.46613
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.72599

Cumulative Model Updates: 135,492
Cumulative Timesteps: 1,130,054,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.76980
Policy Entropy: 3.12928
Value Function Loss: 0.00410

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.56503
Value Function Update Magnitude: 0.54846

Collected Steps per Second: 22,132.63235
Overall Steps per Second: 10,509.69544

Timestep Collection Time: 2.26010
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.75961

Cumulative Model Updates: 135,498
Cumulative Timesteps: 1,130,104,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1130104252...
Checkpoint 1130104252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.74656
Policy Entropy: 3.13412
Value Function Loss: 0.00382

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.55614

Collected Steps per Second: 22,074.84967
Overall Steps per Second: 10,575.36898

Timestep Collection Time: 2.26638
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.73080

Cumulative Model Updates: 135,504
Cumulative Timesteps: 1,130,154,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,747.62072
Policy Entropy: 3.12042
Value Function Loss: 0.00418

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.57503
Value Function Update Magnitude: 0.55083

Collected Steps per Second: 22,324.79030
Overall Steps per Second: 10,630.39650

Timestep Collection Time: 2.24029
Timestep Consumption Time: 2.46452
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.70481

Cumulative Model Updates: 135,510
Cumulative Timesteps: 1,130,204,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1130204296...
Checkpoint 1130204296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,559.73944
Policy Entropy: 3.12723
Value Function Loss: 0.00399

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.55899

Collected Steps per Second: 22,230.54728
Overall Steps per Second: 10,572.46211

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.73097

Cumulative Model Updates: 135,516
Cumulative Timesteps: 1,130,254,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.41777
Policy Entropy: 3.12155
Value Function Loss: 0.00388

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 0.53792

Collected Steps per Second: 22,220.59765
Overall Steps per Second: 10,480.31361

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.77085

Cumulative Model Updates: 135,522
Cumulative Timesteps: 1,130,304,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1130304314...
Checkpoint 1130304314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.93743
Policy Entropy: 3.12318
Value Function Loss: 0.00416

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.54784

Collected Steps per Second: 22,023.04537
Overall Steps per Second: 10,507.66005

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.75919

Cumulative Model Updates: 135,528
Cumulative Timesteps: 1,130,354,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.18355
Policy Entropy: 3.12291
Value Function Loss: 0.00426

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.57992
Value Function Update Magnitude: 0.55320

Collected Steps per Second: 22,703.57201
Overall Steps per Second: 10,565.18500

Timestep Collection Time: 2.20256
Timestep Consumption Time: 2.53053
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73309

Cumulative Model Updates: 135,534
Cumulative Timesteps: 1,130,404,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1130404328...
Checkpoint 1130404328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.37513
Policy Entropy: 3.10790
Value Function Loss: 0.00458

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.58691
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 22,223.48925
Overall Steps per Second: 10,574.74058

Timestep Collection Time: 2.25023
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.72900

Cumulative Model Updates: 135,540
Cumulative Timesteps: 1,130,454,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.32530
Policy Entropy: 3.11005
Value Function Loss: 0.00449

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.59668
Value Function Update Magnitude: 0.58351

Collected Steps per Second: 21,757.51627
Overall Steps per Second: 10,458.42775

Timestep Collection Time: 2.29879
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.78236

Cumulative Model Updates: 135,546
Cumulative Timesteps: 1,130,504,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1130504352...
Checkpoint 1130504352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,442.95123
Policy Entropy: 3.10903
Value Function Loss: 0.00412

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.59486
Value Function Update Magnitude: 0.60204

Collected Steps per Second: 22,167.01643
Overall Steps per Second: 10,577.21219

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.47233
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.72866

Cumulative Model Updates: 135,552
Cumulative Timesteps: 1,130,554,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,187.59086
Policy Entropy: 3.12691
Value Function Loss: 0.00412

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.58694

Collected Steps per Second: 22,128.31226
Overall Steps per Second: 10,344.23395

Timestep Collection Time: 2.25973
Timestep Consumption Time: 2.57427
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.83400

Cumulative Model Updates: 135,558
Cumulative Timesteps: 1,130,604,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1130604372...
Checkpoint 1130604372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040.34409
Policy Entropy: 3.12313
Value Function Loss: 0.00416

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.58937
Value Function Update Magnitude: 0.57888

Collected Steps per Second: 22,116.77953
Overall Steps per Second: 10,382.80149

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.55503
PPO Batch Consumption Time: 0.30186
Total Iteration Time: 4.81585

Cumulative Model Updates: 135,564
Cumulative Timesteps: 1,130,654,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.27582
Policy Entropy: 3.12563
Value Function Loss: 0.00393

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.57915
Value Function Update Magnitude: 0.59003

Collected Steps per Second: 22,130.70938
Overall Steps per Second: 10,530.04089

Timestep Collection Time: 2.26057
Timestep Consumption Time: 2.49041
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.75098

Cumulative Model Updates: 135,570
Cumulative Timesteps: 1,130,704,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1130704402...
Checkpoint 1130704402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.59574
Policy Entropy: 3.11311
Value Function Loss: 0.00391

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.58599

Collected Steps per Second: 21,968.61147
Overall Steps per Second: 10,571.06699

Timestep Collection Time: 2.27616
Timestep Consumption Time: 2.45411
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.73027

Cumulative Model Updates: 135,576
Cumulative Timesteps: 1,130,754,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,790.34240
Policy Entropy: 3.11751
Value Function Loss: 0.00406

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.56203

Collected Steps per Second: 22,180.66434
Overall Steps per Second: 10,596.83190

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.46487
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.71971

Cumulative Model Updates: 135,582
Cumulative Timesteps: 1,130,804,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1130804420...
Checkpoint 1130804420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.45564
Policy Entropy: 3.12306
Value Function Loss: 0.00445

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.55508

Collected Steps per Second: 22,048.29100
Overall Steps per Second: 10,553.72309

Timestep Collection Time: 2.26811
Timestep Consumption Time: 2.47031
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.73842

Cumulative Model Updates: 135,588
Cumulative Timesteps: 1,130,854,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.05128
Policy Entropy: 3.12409
Value Function Loss: 0.00470

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.59947
Value Function Update Magnitude: 0.57054

Collected Steps per Second: 22,357.76800
Overall Steps per Second: 10,521.28812

Timestep Collection Time: 2.23752
Timestep Consumption Time: 2.51722
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.75474

Cumulative Model Updates: 135,594
Cumulative Timesteps: 1,130,904,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1130904454...
Checkpoint 1130904454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.31956
Policy Entropy: 3.11890
Value Function Loss: 0.00475

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.60037
Value Function Update Magnitude: 0.59080

Collected Steps per Second: 21,776.75013
Overall Steps per Second: 10,432.47831

Timestep Collection Time: 2.29667
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.79407

Cumulative Model Updates: 135,600
Cumulative Timesteps: 1,130,954,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.79719
Policy Entropy: 3.11101
Value Function Loss: 0.00448

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.58778
Value Function Update Magnitude: 0.59056

Collected Steps per Second: 22,440.70795
Overall Steps per Second: 10,625.23697

Timestep Collection Time: 2.22809
Timestep Consumption Time: 2.47768
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.70578

Cumulative Model Updates: 135,606
Cumulative Timesteps: 1,131,004,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1131004468...
Checkpoint 1131004468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.03038
Policy Entropy: 3.11834
Value Function Loss: 0.00398

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.58485
Value Function Update Magnitude: 0.57389

Collected Steps per Second: 22,069.29248
Overall Steps per Second: 10,585.32392

Timestep Collection Time: 2.26623
Timestep Consumption Time: 2.45862
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.72484

Cumulative Model Updates: 135,612
Cumulative Timesteps: 1,131,054,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.48828
Policy Entropy: 3.12393
Value Function Loss: 0.00358

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.57504
Value Function Update Magnitude: 0.55870

Collected Steps per Second: 22,118.93938
Overall Steps per Second: 10,502.68816

Timestep Collection Time: 2.26132
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.76240

Cumulative Model Updates: 135,618
Cumulative Timesteps: 1,131,104,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1131104500...
Checkpoint 1131104500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.99212
Policy Entropy: 3.13790
Value Function Loss: 0.00394

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.56391

Collected Steps per Second: 22,110.23181
Overall Steps per Second: 10,447.08186

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.52614
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.78890

Cumulative Model Updates: 135,624
Cumulative Timesteps: 1,131,154,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.25087
Policy Entropy: 3.13709
Value Function Loss: 0.00376

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.58903
Value Function Update Magnitude: 0.56936

Collected Steps per Second: 22,096.75109
Overall Steps per Second: 10,368.58278

Timestep Collection Time: 2.26287
Timestep Consumption Time: 2.55959
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.82245

Cumulative Model Updates: 135,630
Cumulative Timesteps: 1,131,204,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1131204532...
Checkpoint 1131204532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.82176
Policy Entropy: 3.12416
Value Function Loss: 0.00390

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.59661
Value Function Update Magnitude: 0.55804

Collected Steps per Second: 21,845.75827
Overall Steps per Second: 10,454.36489

Timestep Collection Time: 2.28996
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.78518

Cumulative Model Updates: 135,636
Cumulative Timesteps: 1,131,254,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.39590
Policy Entropy: 3.11572
Value Function Loss: 0.00378

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.59505
Value Function Update Magnitude: 0.55234

Collected Steps per Second: 21,911.12473
Overall Steps per Second: 10,506.52666

Timestep Collection Time: 2.28295
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.76104

Cumulative Model Updates: 135,642
Cumulative Timesteps: 1,131,304,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1131304580...
Checkpoint 1131304580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.86358
Policy Entropy: 3.11008
Value Function Loss: 0.00393

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.59023
Value Function Update Magnitude: 0.54200

Collected Steps per Second: 22,014.53648
Overall Steps per Second: 10,368.45230

Timestep Collection Time: 2.27241
Timestep Consumption Time: 2.55242
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.82483

Cumulative Model Updates: 135,648
Cumulative Timesteps: 1,131,354,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.64277
Policy Entropy: 3.11911
Value Function Loss: 0.00400

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.58679
Value Function Update Magnitude: 0.53941

Collected Steps per Second: 22,162.18290
Overall Steps per Second: 10,350.39275

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.57546
PPO Batch Consumption Time: 0.30162
Total Iteration Time: 4.83228

Cumulative Model Updates: 135,654
Cumulative Timesteps: 1,131,404,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1131404622...
Checkpoint 1131404622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.18111
Policy Entropy: 3.11377
Value Function Loss: 0.00418

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.59223
Value Function Update Magnitude: 0.53693

Collected Steps per Second: 22,000.45651
Overall Steps per Second: 10,410.32440

Timestep Collection Time: 2.27377
Timestep Consumption Time: 2.53146
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.80523

Cumulative Model Updates: 135,660
Cumulative Timesteps: 1,131,454,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.37636
Policy Entropy: 3.10508
Value Function Loss: 0.00469

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.60779
Value Function Update Magnitude: 0.54538

Collected Steps per Second: 22,491.29332
Overall Steps per Second: 10,601.94252

Timestep Collection Time: 2.22433
Timestep Consumption Time: 2.49443
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.71876

Cumulative Model Updates: 135,666
Cumulative Timesteps: 1,131,504,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1131504674...
Checkpoint 1131504674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,366.75640
Policy Entropy: 3.10569
Value Function Loss: 0.00491

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.61511
Value Function Update Magnitude: 0.59101

Collected Steps per Second: 21,982.88371
Overall Steps per Second: 10,289.00320

Timestep Collection Time: 2.27522
Timestep Consumption Time: 2.58589
PPO Batch Consumption Time: 0.30519
Total Iteration Time: 4.86111

Cumulative Model Updates: 135,672
Cumulative Timesteps: 1,131,554,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052.11519
Policy Entropy: 3.10803
Value Function Loss: 0.00476

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.62450
Value Function Update Magnitude: 0.61006

Collected Steps per Second: 21,355.96729
Overall Steps per Second: 10,140.46005

Timestep Collection Time: 2.34202
Timestep Consumption Time: 2.59031
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.93232

Cumulative Model Updates: 135,678
Cumulative Timesteps: 1,131,604,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1131604706...
Checkpoint 1131604706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.46729
Policy Entropy: 3.11875
Value Function Loss: 0.00453

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.62046
Value Function Update Magnitude: 0.57762

Collected Steps per Second: 22,582.93059
Overall Steps per Second: 10,531.92386

Timestep Collection Time: 2.21459
Timestep Consumption Time: 2.53402
PPO Batch Consumption Time: 0.30156
Total Iteration Time: 4.74861

Cumulative Model Updates: 135,684
Cumulative Timesteps: 1,131,654,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.97288
Policy Entropy: 3.10999
Value Function Loss: 0.00441

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.60396
Value Function Update Magnitude: 0.56076

Collected Steps per Second: 22,157.60976
Overall Steps per Second: 10,472.36903

Timestep Collection Time: 2.25773
Timestep Consumption Time: 2.51922
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.77695

Cumulative Model Updates: 135,690
Cumulative Timesteps: 1,131,704,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1131704744...
Checkpoint 1131704744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.79590
Policy Entropy: 3.11550
Value Function Loss: 0.00458

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.60386
Value Function Update Magnitude: 0.56183

Collected Steps per Second: 20,955.14041
Overall Steps per Second: 9,965.06449

Timestep Collection Time: 2.38653
Timestep Consumption Time: 2.63201
PPO Batch Consumption Time: 0.31244
Total Iteration Time: 5.01853

Cumulative Model Updates: 135,696
Cumulative Timesteps: 1,131,754,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.74665
Policy Entropy: 3.11465
Value Function Loss: 0.00440

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.61261
Value Function Update Magnitude: 0.56405

Collected Steps per Second: 21,563.92728
Overall Steps per Second: 10,286.50847

Timestep Collection Time: 2.31869
Timestep Consumption Time: 2.54205
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.86074

Cumulative Model Updates: 135,702
Cumulative Timesteps: 1,131,804,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1131804754...
Checkpoint 1131804754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.42074
Policy Entropy: 3.12749
Value Function Loss: 0.00449

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.60825
Value Function Update Magnitude: 0.57474

Collected Steps per Second: 22,246.48675
Overall Steps per Second: 10,634.41820

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.45437
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.70209

Cumulative Model Updates: 135,708
Cumulative Timesteps: 1,131,854,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,797.87620
Policy Entropy: 3.11405
Value Function Loss: 0.00422

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.60191
Value Function Update Magnitude: 0.56723

Collected Steps per Second: 22,385.72170
Overall Steps per Second: 10,445.96675

Timestep Collection Time: 2.23401
Timestep Consumption Time: 2.55348
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.78749

Cumulative Model Updates: 135,714
Cumulative Timesteps: 1,131,904,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1131904768...
Checkpoint 1131904768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797.12762
Policy Entropy: 3.12110
Value Function Loss: 0.00417

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.59556
Value Function Update Magnitude: 0.57130

Collected Steps per Second: 22,168.38622
Overall Steps per Second: 10,609.61663

Timestep Collection Time: 2.25628
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.71440

Cumulative Model Updates: 135,720
Cumulative Timesteps: 1,131,954,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.70765
Policy Entropy: 3.11485
Value Function Loss: 0.00401

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.59061
Value Function Update Magnitude: 0.57610

Collected Steps per Second: 22,742.77131
Overall Steps per Second: 10,612.90379

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.71143

Cumulative Model Updates: 135,726
Cumulative Timesteps: 1,132,004,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1132004788...
Checkpoint 1132004788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.76027
Policy Entropy: 3.13085
Value Function Loss: 0.00376

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.58901
Value Function Update Magnitude: 0.54872

Collected Steps per Second: 22,176.77278
Overall Steps per Second: 10,515.52960

Timestep Collection Time: 2.25569
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.75715

Cumulative Model Updates: 135,732
Cumulative Timesteps: 1,132,054,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.98309
Policy Entropy: 3.12416
Value Function Loss: 0.00400

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.58435
Value Function Update Magnitude: 0.53458

Collected Steps per Second: 22,253.10831
Overall Steps per Second: 10,429.63668

Timestep Collection Time: 2.24769
Timestep Consumption Time: 2.54807
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.79576

Cumulative Model Updates: 135,738
Cumulative Timesteps: 1,132,104,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1132104830...
Checkpoint 1132104830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.11516
Policy Entropy: 3.10567
Value Function Loss: 0.00400

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.58518
Value Function Update Magnitude: 0.52915

Collected Steps per Second: 22,552.24560
Overall Steps per Second: 10,623.45456

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.48959
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.70676

Cumulative Model Updates: 135,744
Cumulative Timesteps: 1,132,154,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.89980
Policy Entropy: 3.09825
Value Function Loss: 0.00400

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.58938
Value Function Update Magnitude: 0.53353

Collected Steps per Second: 22,662.06345
Overall Steps per Second: 10,482.55046

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.56442
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.77155

Cumulative Model Updates: 135,750
Cumulative Timesteps: 1,132,204,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1132204850...
Checkpoint 1132204850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.94743
Policy Entropy: 3.08888
Value Function Loss: 0.00422

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.59839
Value Function Update Magnitude: 0.54987

Collected Steps per Second: 22,027.71339
Overall Steps per Second: 10,532.79275

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.47761
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.74784

Cumulative Model Updates: 135,756
Cumulative Timesteps: 1,132,254,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.52519
Policy Entropy: 3.07519
Value Function Loss: 0.00448

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.60662
Value Function Update Magnitude: 0.55743

Collected Steps per Second: 22,650.05663
Overall Steps per Second: 10,632.75345

Timestep Collection Time: 2.20759
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.70264

Cumulative Model Updates: 135,762
Cumulative Timesteps: 1,132,304,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1132304860...
Checkpoint 1132304860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.50333
Policy Entropy: 3.06944
Value Function Loss: 0.00461

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.60868
Value Function Update Magnitude: 0.53941

Collected Steps per Second: 22,305.73671
Overall Steps per Second: 10,568.05090

Timestep Collection Time: 2.24283
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.73389

Cumulative Model Updates: 135,768
Cumulative Timesteps: 1,132,354,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.30839
Policy Entropy: 3.07284
Value Function Loss: 0.00489

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.61707
Value Function Update Magnitude: 0.54863

Collected Steps per Second: 22,874.32140
Overall Steps per Second: 10,671.11093

Timestep Collection Time: 2.18638
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.68667

Cumulative Model Updates: 135,774
Cumulative Timesteps: 1,132,404,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1132404900...
Checkpoint 1132404900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.62247
Policy Entropy: 3.08756
Value Function Loss: 0.00438

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.60395
Value Function Update Magnitude: 0.56139

Collected Steps per Second: 22,331.93854
Overall Steps per Second: 10,424.53937

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.55743
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.79638

Cumulative Model Updates: 135,780
Cumulative Timesteps: 1,132,454,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.74717
Policy Entropy: 3.09783
Value Function Loss: 0.00398

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.53715

Collected Steps per Second: 22,692.44278
Overall Steps per Second: 10,499.50808

Timestep Collection Time: 2.20435
Timestep Consumption Time: 2.55988
PPO Batch Consumption Time: 0.30132
Total Iteration Time: 4.76422

Cumulative Model Updates: 135,786
Cumulative Timesteps: 1,132,504,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1132504922...
Checkpoint 1132504922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.71018
Policy Entropy: 3.11150
Value Function Loss: 0.00367

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.49286

Collected Steps per Second: 22,150.43602
Overall Steps per Second: 10,682.13286

Timestep Collection Time: 2.25738
Timestep Consumption Time: 2.42352
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.68090

Cumulative Model Updates: 135,792
Cumulative Timesteps: 1,132,554,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.24001
Policy Entropy: 3.11880
Value Function Loss: 0.00382

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.46877

Collected Steps per Second: 22,702.20327
Overall Steps per Second: 10,597.52137

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.71827

Cumulative Model Updates: 135,798
Cumulative Timesteps: 1,132,604,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1132604926...
Checkpoint 1132604926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.94299
Policy Entropy: 3.11823
Value Function Loss: 0.00396

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.44766

Collected Steps per Second: 21,864.58743
Overall Steps per Second: 10,367.79981

Timestep Collection Time: 2.28717
Timestep Consumption Time: 2.53623
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.82340

Cumulative Model Updates: 135,804
Cumulative Timesteps: 1,132,654,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.71954
Policy Entropy: 3.11174
Value Function Loss: 0.00425

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.57226
Value Function Update Magnitude: 0.45680

Collected Steps per Second: 22,458.51405
Overall Steps per Second: 10,507.24514

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.53331
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.76052

Cumulative Model Updates: 135,810
Cumulative Timesteps: 1,132,704,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1132704954...
Checkpoint 1132704954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149.64169
Policy Entropy: 3.11415
Value Function Loss: 0.00427

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.58005
Value Function Update Magnitude: 0.48721

Collected Steps per Second: 22,505.40937
Overall Steps per Second: 10,576.74984

Timestep Collection Time: 2.22249
Timestep Consumption Time: 2.50656
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.72905

Cumulative Model Updates: 135,816
Cumulative Timesteps: 1,132,754,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,445.44109
Policy Entropy: 3.11968
Value Function Loss: 0.00417

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.50176

Collected Steps per Second: 22,664.91790
Overall Steps per Second: 10,569.00371

Timestep Collection Time: 2.20720
Timestep Consumption Time: 2.52608
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.73327

Cumulative Model Updates: 135,822
Cumulative Timesteps: 1,132,804,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1132804998...
Checkpoint 1132804998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.49238
Policy Entropy: 3.11554
Value Function Loss: 0.00412

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.49749

Collected Steps per Second: 21,811.54065
Overall Steps per Second: 10,367.25007

Timestep Collection Time: 2.29291
Timestep Consumption Time: 2.53112
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.82404

Cumulative Model Updates: 135,828
Cumulative Timesteps: 1,132,855,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,153.11065
Policy Entropy: 3.10246
Value Function Loss: 0.00436

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.57196
Value Function Update Magnitude: 0.48910

Collected Steps per Second: 21,785.69638
Overall Steps per Second: 10,429.38513

Timestep Collection Time: 2.29637
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.79683

Cumulative Model Updates: 135,834
Cumulative Timesteps: 1,132,905,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1132905038...
Checkpoint 1132905038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.05440
Policy Entropy: 3.09777
Value Function Loss: 0.00417

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.49106

Collected Steps per Second: 22,378.34755
Overall Steps per Second: 10,511.47950

Timestep Collection Time: 2.23493
Timestep Consumption Time: 2.52311
PPO Batch Consumption Time: 0.30056
Total Iteration Time: 4.75804

Cumulative Model Updates: 135,840
Cumulative Timesteps: 1,132,955,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.12391
Policy Entropy: 3.10492
Value Function Loss: 0.00419

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.57847
Value Function Update Magnitude: 0.48138

Collected Steps per Second: 23,001.43000
Overall Steps per Second: 10,580.45704

Timestep Collection Time: 2.17447
Timestep Consumption Time: 2.55273
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.72721

Cumulative Model Updates: 135,846
Cumulative Timesteps: 1,133,005,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1133005068...
Checkpoint 1133005068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,995.65842
Policy Entropy: 3.12016
Value Function Loss: 0.00406

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.50422

Collected Steps per Second: 22,230.53051
Overall Steps per Second: 10,433.87887

Timestep Collection Time: 2.24916
Timestep Consumption Time: 2.54292
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.79208

Cumulative Model Updates: 135,852
Cumulative Timesteps: 1,133,055,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.88904
Policy Entropy: 3.11363
Value Function Loss: 0.00400

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.57989
Value Function Update Magnitude: 0.52075

Collected Steps per Second: 22,525.60194
Overall Steps per Second: 10,529.96494

Timestep Collection Time: 2.22050
Timestep Consumption Time: 2.52957
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 4.75006

Cumulative Model Updates: 135,858
Cumulative Timesteps: 1,133,105,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1133105086...
Checkpoint 1133105086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.39092
Policy Entropy: 3.09742
Value Function Loss: 0.00392

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.51288

Collected Steps per Second: 22,180.66119
Overall Steps per Second: 10,660.44513

Timestep Collection Time: 2.25548
Timestep Consumption Time: 2.43738
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.69286

Cumulative Model Updates: 135,864
Cumulative Timesteps: 1,133,155,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,403.29673
Policy Entropy: 3.09253
Value Function Loss: 0.00397

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.50483

Collected Steps per Second: 22,691.25900
Overall Steps per Second: 10,516.15519

Timestep Collection Time: 2.20402
Timestep Consumption Time: 2.55171
PPO Batch Consumption Time: 0.29802
Total Iteration Time: 4.75573

Cumulative Model Updates: 135,870
Cumulative Timesteps: 1,133,205,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1133205126...
Checkpoint 1133205126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.14738
Policy Entropy: 3.09914
Value Function Loss: 0.00379

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.57777
Value Function Update Magnitude: 0.49660

Collected Steps per Second: 22,513.38521
Overall Steps per Second: 10,516.42753

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.53438
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.75599

Cumulative Model Updates: 135,876
Cumulative Timesteps: 1,133,255,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,507.18254
Policy Entropy: 3.09577
Value Function Loss: 0.00382

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.50419

Collected Steps per Second: 22,356.24803
Overall Steps per Second: 10,489.00821

Timestep Collection Time: 2.23660
Timestep Consumption Time: 2.53048
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.76709

Cumulative Model Updates: 135,882
Cumulative Timesteps: 1,133,305,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1133305144...
Checkpoint 1133305144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.52754
Policy Entropy: 3.07721
Value Function Loss: 0.00403

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.59708
Value Function Update Magnitude: 0.50759

Collected Steps per Second: 22,576.83715
Overall Steps per Second: 10,638.81948

Timestep Collection Time: 2.21528
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.70109

Cumulative Model Updates: 135,888
Cumulative Timesteps: 1,133,355,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.89994
Policy Entropy: 3.07511
Value Function Loss: 0.00433

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.60297
Value Function Update Magnitude: 0.51482

Collected Steps per Second: 22,435.75306
Overall Steps per Second: 10,436.50582

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.56260
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.79145

Cumulative Model Updates: 135,894
Cumulative Timesteps: 1,133,405,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1133405164...
Checkpoint 1133405164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.06624
Policy Entropy: 3.07421
Value Function Loss: 0.00452

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.60355
Value Function Update Magnitude: 0.51388

Collected Steps per Second: 22,329.18898
Overall Steps per Second: 10,610.70175

Timestep Collection Time: 2.24065
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.71524

Cumulative Model Updates: 135,900
Cumulative Timesteps: 1,133,455,196

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.69411
Policy Entropy: 3.07791
Value Function Loss: 0.00470

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.60662
Value Function Update Magnitude: 0.54285

Collected Steps per Second: 22,698.51363
Overall Steps per Second: 10,392.37188

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.60927
PPO Batch Consumption Time: 0.31151
Total Iteration Time: 4.81276

Cumulative Model Updates: 135,906
Cumulative Timesteps: 1,133,505,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1133505212...
Checkpoint 1133505212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.78779
Policy Entropy: 3.07893
Value Function Loss: 0.00451

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.61002
Value Function Update Magnitude: 0.55364

Collected Steps per Second: 22,424.37098
Overall Steps per Second: 10,659.54104

Timestep Collection Time: 2.23088
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.69307

Cumulative Model Updates: 135,912
Cumulative Timesteps: 1,133,555,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,527.69096
Policy Entropy: 3.07807
Value Function Loss: 0.00452

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.60126
Value Function Update Magnitude: 0.52543

Collected Steps per Second: 22,695.21905
Overall Steps per Second: 10,546.50976

Timestep Collection Time: 2.20355
Timestep Consumption Time: 2.53831
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.74185

Cumulative Model Updates: 135,918
Cumulative Timesteps: 1,133,605,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1133605248...
Checkpoint 1133605248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.01560
Policy Entropy: 3.08194
Value Function Loss: 0.00463

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.59604
Value Function Update Magnitude: 0.49863

Collected Steps per Second: 22,392.28297
Overall Steps per Second: 10,716.70992

Timestep Collection Time: 2.23389
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.66766

Cumulative Model Updates: 135,924
Cumulative Timesteps: 1,133,655,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.65081
Policy Entropy: 3.08610
Value Function Loss: 0.00447

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.59045
Value Function Update Magnitude: 0.49506

Collected Steps per Second: 22,593.36662
Overall Steps per Second: 10,617.47837

Timestep Collection Time: 2.21330
Timestep Consumption Time: 2.49648
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.70978

Cumulative Model Updates: 135,930
Cumulative Timesteps: 1,133,705,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1133705276...
Checkpoint 1133705276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.13965
Policy Entropy: 3.10181
Value Function Loss: 0.00451

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.58704
Value Function Update Magnitude: 0.50820

Collected Steps per Second: 22,244.40850
Overall Steps per Second: 10,428.48511

Timestep Collection Time: 2.24794
Timestep Consumption Time: 2.54701
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.79494

Cumulative Model Updates: 135,936
Cumulative Timesteps: 1,133,755,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.30616
Policy Entropy: 3.11167
Value Function Loss: 0.00391

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.57529
Value Function Update Magnitude: 0.50487

Collected Steps per Second: 22,011.72313
Overall Steps per Second: 10,443.61961

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.51750
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.79029

Cumulative Model Updates: 135,942
Cumulative Timesteps: 1,133,805,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1133805308...
Checkpoint 1133805308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.56009
Policy Entropy: 3.12037
Value Function Loss: 0.00393

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.56128
Value Function Update Magnitude: 0.49033

Collected Steps per Second: 22,039.07083
Overall Steps per Second: 10,567.59165

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.73466

Cumulative Model Updates: 135,948
Cumulative Timesteps: 1,133,855,342

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.92717
Policy Entropy: 3.11244
Value Function Loss: 0.00405

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.49972

Collected Steps per Second: 22,294.83104
Overall Steps per Second: 10,595.63556

Timestep Collection Time: 2.24267
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.71892

Cumulative Model Updates: 135,954
Cumulative Timesteps: 1,133,905,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1133905342...
Checkpoint 1133905342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.54297
Policy Entropy: 3.10664
Value Function Loss: 0.00444

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.59196
Value Function Update Magnitude: 0.53280

Collected Steps per Second: 22,494.80455
Overall Steps per Second: 10,586.49849

Timestep Collection Time: 2.22300
Timestep Consumption Time: 2.50056
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.72356

Cumulative Model Updates: 135,960
Cumulative Timesteps: 1,133,955,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.71739
Policy Entropy: 3.09442
Value Function Loss: 0.00457

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.60956
Value Function Update Magnitude: 0.53753

Collected Steps per Second: 22,452.18509
Overall Steps per Second: 10,517.85120

Timestep Collection Time: 2.22793
Timestep Consumption Time: 2.52798
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.75591

Cumulative Model Updates: 135,966
Cumulative Timesteps: 1,134,005,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1134005370...
Checkpoint 1134005370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.76523
Policy Entropy: 3.10477
Value Function Loss: 0.00454

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.61305
Value Function Update Magnitude: 0.54063

Collected Steps per Second: 22,438.74789
Overall Steps per Second: 10,608.88737

Timestep Collection Time: 2.22963
Timestep Consumption Time: 2.48623
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.71586

Cumulative Model Updates: 135,972
Cumulative Timesteps: 1,134,055,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.29015
Policy Entropy: 3.10216
Value Function Loss: 0.00432

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.59917
Value Function Update Magnitude: 0.53406

Collected Steps per Second: 22,620.78757
Overall Steps per Second: 10,435.81388

Timestep Collection Time: 2.21044
Timestep Consumption Time: 2.58094
PPO Batch Consumption Time: 0.30064
Total Iteration Time: 4.79138

Cumulative Model Updates: 135,978
Cumulative Timesteps: 1,134,105,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1134105402...
Checkpoint 1134105402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,341.35173
Policy Entropy: 3.10659
Value Function Loss: 0.00418

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.59220
Value Function Update Magnitude: 0.53529

Collected Steps per Second: 22,134.54517
Overall Steps per Second: 10,486.08230

Timestep Collection Time: 2.26009
Timestep Consumption Time: 2.51062
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.77070

Cumulative Model Updates: 135,984
Cumulative Timesteps: 1,134,155,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.26275
Policy Entropy: 3.10886
Value Function Loss: 0.00391

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.58837
Value Function Update Magnitude: 0.53642

Collected Steps per Second: 22,466.37771
Overall Steps per Second: 10,533.58213

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.52158
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.74748

Cumulative Model Updates: 135,990
Cumulative Timesteps: 1,134,205,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1134205436...
Checkpoint 1134205436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.66328
Policy Entropy: 3.11750
Value Function Loss: 0.00394

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.59059
Value Function Update Magnitude: 0.52235

Collected Steps per Second: 22,171.37108
Overall Steps per Second: 10,653.74411

Timestep Collection Time: 2.25534
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.69356

Cumulative Model Updates: 135,996
Cumulative Timesteps: 1,134,255,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.46961
Policy Entropy: 3.12557
Value Function Loss: 0.00361

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.58136
Value Function Update Magnitude: 0.51758

Collected Steps per Second: 22,411.79623
Overall Steps per Second: 10,510.51414

Timestep Collection Time: 2.23168
Timestep Consumption Time: 2.52698
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.75866

Cumulative Model Updates: 136,002
Cumulative Timesteps: 1,134,305,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1134305456...
Checkpoint 1134305456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.12146
Policy Entropy: 3.11764
Value Function Loss: 0.00362

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.50518

Collected Steps per Second: 19,842.55688
Overall Steps per Second: 9,564.86702

Timestep Collection Time: 2.52054
Timestep Consumption Time: 2.70839
PPO Batch Consumption Time: 0.32456
Total Iteration Time: 5.22893

Cumulative Model Updates: 136,008
Cumulative Timesteps: 1,134,355,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.69663
Policy Entropy: 3.10041
Value Function Loss: 0.00385

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.57566
Value Function Update Magnitude: 0.48524

Collected Steps per Second: 22,347.68826
Overall Steps per Second: 10,659.61230

Timestep Collection Time: 2.23880
Timestep Consumption Time: 2.45480
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.69360

Cumulative Model Updates: 136,014
Cumulative Timesteps: 1,134,405,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1134405502...
Checkpoint 1134405502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.35111
Policy Entropy: 3.09263
Value Function Loss: 0.00427

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.59255
Value Function Update Magnitude: 0.48113

Collected Steps per Second: 22,402.29056
Overall Steps per Second: 10,628.25708

Timestep Collection Time: 2.23316
Timestep Consumption Time: 2.47391
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.70707

Cumulative Model Updates: 136,020
Cumulative Timesteps: 1,134,455,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.33222
Policy Entropy: 3.09203
Value Function Loss: 0.00436

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.59984
Value Function Update Magnitude: 0.49365

Collected Steps per Second: 22,449.87039
Overall Steps per Second: 10,592.30780

Timestep Collection Time: 2.22754
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.72116

Cumulative Model Updates: 136,026
Cumulative Timesteps: 1,134,505,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1134505538...
Checkpoint 1134505538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.97669
Policy Entropy: 3.09136
Value Function Loss: 0.00441

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.59967
Value Function Update Magnitude: 0.52258

Collected Steps per Second: 22,269.14722
Overall Steps per Second: 10,655.59650

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.69500

Cumulative Model Updates: 136,032
Cumulative Timesteps: 1,134,555,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.13468
Policy Entropy: 3.07800
Value Function Loss: 0.00470

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.60738
Value Function Update Magnitude: 0.53473

Collected Steps per Second: 22,560.59252
Overall Steps per Second: 10,565.96325

Timestep Collection Time: 2.21705
Timestep Consumption Time: 2.51683
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.73388

Cumulative Model Updates: 136,038
Cumulative Timesteps: 1,134,605,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1134605584...
Checkpoint 1134605584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.77383
Policy Entropy: 3.09344
Value Function Loss: 0.00447

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.60845
Value Function Update Magnitude: 0.54443

Collected Steps per Second: 22,375.40708
Overall Steps per Second: 10,534.63826

Timestep Collection Time: 2.23469
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.74644

Cumulative Model Updates: 136,044
Cumulative Timesteps: 1,134,655,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.83271
Policy Entropy: 3.10010
Value Function Loss: 0.00451

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.60593
Value Function Update Magnitude: 0.53338

Collected Steps per Second: 22,667.75934
Overall Steps per Second: 10,530.24670

Timestep Collection Time: 2.20657
Timestep Consumption Time: 2.54337
PPO Batch Consumption Time: 0.29880
Total Iteration Time: 4.74994

Cumulative Model Updates: 136,050
Cumulative Timesteps: 1,134,705,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1134705604...
Checkpoint 1134705604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.88425
Policy Entropy: 3.10529
Value Function Loss: 0.00448

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.61241
Value Function Update Magnitude: 0.54859

Collected Steps per Second: 22,270.18657
Overall Steps per Second: 10,528.17081

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.75011

Cumulative Model Updates: 136,056
Cumulative Timesteps: 1,134,755,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.27370
Policy Entropy: 3.10086
Value Function Loss: 0.00446

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.61529
Value Function Update Magnitude: 0.57100

Collected Steps per Second: 22,481.89151
Overall Steps per Second: 10,551.86877

Timestep Collection Time: 2.22481
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.74020

Cumulative Model Updates: 136,062
Cumulative Timesteps: 1,134,805,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1134805632...
Checkpoint 1134805632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.62555
Policy Entropy: 3.09229
Value Function Loss: 0.00435

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.60546
Value Function Update Magnitude: 0.57759

Collected Steps per Second: 22,792.04979
Overall Steps per Second: 10,511.84985

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.56422
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 4.75920

Cumulative Model Updates: 136,068
Cumulative Timesteps: 1,134,855,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.84877
Policy Entropy: 3.09166
Value Function Loss: 0.00409

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.54981

Collected Steps per Second: 22,215.67558
Overall Steps per Second: 10,507.35654

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.76257

Cumulative Model Updates: 136,074
Cumulative Timesteps: 1,134,905,702

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1134905702...
Checkpoint 1134905702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.65454
Policy Entropy: 3.10188
Value Function Loss: 0.00429

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.59285
Value Function Update Magnitude: 0.52983

Collected Steps per Second: 22,714.37818
Overall Steps per Second: 10,598.62638

Timestep Collection Time: 2.20195
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.71910

Cumulative Model Updates: 136,080
Cumulative Timesteps: 1,134,955,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,228.35881
Policy Entropy: 3.12780
Value Function Loss: 0.00420

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.59414
Value Function Update Magnitude: 0.54359

Collected Steps per Second: 22,044.49947
Overall Steps per Second: 10,339.55427

Timestep Collection Time: 2.26814
Timestep Consumption Time: 2.56766
PPO Batch Consumption Time: 0.30382
Total Iteration Time: 4.83580

Cumulative Model Updates: 136,086
Cumulative Timesteps: 1,135,005,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1135005718...
Checkpoint 1135005718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.32773
Policy Entropy: 3.12555
Value Function Loss: 0.00416

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.59078
Value Function Update Magnitude: 0.55085

Collected Steps per Second: 22,425.37017
Overall Steps per Second: 10,461.39661

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.55118
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.78196

Cumulative Model Updates: 136,092
Cumulative Timesteps: 1,135,055,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.28466
Policy Entropy: 3.11082
Value Function Loss: 0.00418

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.59241
Value Function Update Magnitude: 0.55591

Collected Steps per Second: 22,571.15168
Overall Steps per Second: 10,717.79135

Timestep Collection Time: 2.21575
Timestep Consumption Time: 2.45051
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.66626

Cumulative Model Updates: 136,098
Cumulative Timesteps: 1,135,105,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1135105756...
Checkpoint 1135105756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.14983
Policy Entropy: 3.09427
Value Function Loss: 0.00405

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.59402
Value Function Update Magnitude: 0.54933

Collected Steps per Second: 20,582.68999
Overall Steps per Second: 10,267.65148

Timestep Collection Time: 2.42961
Timestep Consumption Time: 2.44083
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.87044

Cumulative Model Updates: 136,104
Cumulative Timesteps: 1,135,155,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.29406
Policy Entropy: 3.10097
Value Function Loss: 0.00437

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.60049
Value Function Update Magnitude: 0.56255

Collected Steps per Second: 22,128.66245
Overall Steps per Second: 10,411.20534

Timestep Collection Time: 2.25987
Timestep Consumption Time: 2.54341
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.80329

Cumulative Model Updates: 136,110
Cumulative Timesteps: 1,135,205,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1135205772...
Checkpoint 1135205772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.75510
Policy Entropy: 3.10342
Value Function Loss: 0.00430

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.60382
Value Function Update Magnitude: 0.57302

Collected Steps per Second: 22,033.84417
Overall Steps per Second: 10,561.13371

Timestep Collection Time: 2.26996
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.73586

Cumulative Model Updates: 136,116
Cumulative Timesteps: 1,135,255,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.39961
Policy Entropy: 3.10390
Value Function Loss: 0.00451

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.59930
Value Function Update Magnitude: 0.56484

Collected Steps per Second: 22,142.71187
Overall Steps per Second: 10,550.37420

Timestep Collection Time: 2.25835
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.73974

Cumulative Model Updates: 136,122
Cumulative Timesteps: 1,135,305,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1135305794...
Checkpoint 1135305794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.05943
Policy Entropy: 3.09259
Value Function Loss: 0.00465

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.60627
Value Function Update Magnitude: 0.56917

Collected Steps per Second: 22,093.43639
Overall Steps per Second: 10,587.56609

Timestep Collection Time: 2.26321
Timestep Consumption Time: 2.45950
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.72271

Cumulative Model Updates: 136,128
Cumulative Timesteps: 1,135,355,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.01703
Policy Entropy: 3.08403
Value Function Loss: 0.00450

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.60583
Value Function Update Magnitude: 0.55460

Collected Steps per Second: 21,832.23169
Overall Steps per Second: 10,490.63999

Timestep Collection Time: 2.29028
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.76634

Cumulative Model Updates: 136,134
Cumulative Timesteps: 1,135,405,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1135405798...
Checkpoint 1135405798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.86520
Policy Entropy: 3.06880
Value Function Loss: 0.00478

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.59992
Value Function Update Magnitude: 0.54858

Collected Steps per Second: 22,002.31543
Overall Steps per Second: 10,538.58798

Timestep Collection Time: 2.27258
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.74466

Cumulative Model Updates: 136,140
Cumulative Timesteps: 1,135,455,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.02420
Policy Entropy: 3.08956
Value Function Loss: 0.00446

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.59249
Value Function Update Magnitude: 0.55633

Collected Steps per Second: 22,001.30521
Overall Steps per Second: 10,583.72692

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.72707

Cumulative Model Updates: 136,146
Cumulative Timesteps: 1,135,505,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1135505830...
Checkpoint 1135505830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.39838
Policy Entropy: 3.10837
Value Function Loss: 0.00433

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.58013
Value Function Update Magnitude: 0.54303

Collected Steps per Second: 21,874.91101
Overall Steps per Second: 10,515.90140

Timestep Collection Time: 2.28609
Timestep Consumption Time: 2.46938
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.75546

Cumulative Model Updates: 136,152
Cumulative Timesteps: 1,135,555,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.88629
Policy Entropy: 3.12503
Value Function Loss: 0.00389

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.57312
Value Function Update Magnitude: 0.52146

Collected Steps per Second: 22,237.19704
Overall Steps per Second: 10,597.97939

Timestep Collection Time: 2.24866
Timestep Consumption Time: 2.46959
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.71826

Cumulative Model Updates: 136,158
Cumulative Timesteps: 1,135,605,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1135605842...
Checkpoint 1135605842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.05238
Policy Entropy: 3.13904
Value Function Loss: 0.00401

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.57198
Value Function Update Magnitude: 0.52236

Collected Steps per Second: 21,792.48742
Overall Steps per Second: 10,397.85753

Timestep Collection Time: 2.29529
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.81061

Cumulative Model Updates: 136,164
Cumulative Timesteps: 1,135,655,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.22809
Policy Entropy: 3.13848
Value Function Loss: 0.00371

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.52599

Collected Steps per Second: 22,222.64381
Overall Steps per Second: 10,551.19677

Timestep Collection Time: 2.25077
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.74050

Cumulative Model Updates: 136,170
Cumulative Timesteps: 1,135,705,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1135705880...
Checkpoint 1135705880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.25310
Policy Entropy: 3.13140
Value Function Loss: 0.00401

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.57915
Value Function Update Magnitude: 0.54760

Collected Steps per Second: 21,954.14637
Overall Steps per Second: 10,373.42505

Timestep Collection Time: 2.27848
Timestep Consumption Time: 2.54365
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.82213

Cumulative Model Updates: 136,176
Cumulative Timesteps: 1,135,755,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.39132
Policy Entropy: 3.11156
Value Function Loss: 0.00413

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.59615
Value Function Update Magnitude: 0.56934

Collected Steps per Second: 22,294.77948
Overall Steps per Second: 10,365.82739

Timestep Collection Time: 2.24411
Timestep Consumption Time: 2.58252
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.82663

Cumulative Model Updates: 136,182
Cumulative Timesteps: 1,135,805,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1135805934...
Checkpoint 1135805934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.76267
Policy Entropy: 3.09916
Value Function Loss: 0.00423

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.60305
Value Function Update Magnitude: 0.56397

Collected Steps per Second: 22,095.50694
Overall Steps per Second: 10,615.80321

Timestep Collection Time: 2.26290
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.70996

Cumulative Model Updates: 136,188
Cumulative Timesteps: 1,135,855,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.47137
Policy Entropy: 3.09983
Value Function Loss: 0.00407

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.60446
Value Function Update Magnitude: 0.55209

Collected Steps per Second: 22,273.57147
Overall Steps per Second: 10,543.35925

Timestep Collection Time: 2.24571
Timestep Consumption Time: 2.49851
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.74422

Cumulative Model Updates: 136,194
Cumulative Timesteps: 1,135,905,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1135905954...
Checkpoint 1135905954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.82180
Policy Entropy: 3.10487
Value Function Loss: 0.00383

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.59646
Value Function Update Magnitude: 0.54393

Collected Steps per Second: 22,289.09366
Overall Steps per Second: 10,541.43356

Timestep Collection Time: 2.24361
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.74395

Cumulative Model Updates: 136,200
Cumulative Timesteps: 1,135,955,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.21307
Policy Entropy: 3.10370
Value Function Loss: 0.00381

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.59904
Value Function Update Magnitude: 0.53228

Collected Steps per Second: 22,174.03165
Overall Steps per Second: 10,553.04588

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.48308
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.73797

Cumulative Model Updates: 136,206
Cumulative Timesteps: 1,136,005,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1136005962...
Checkpoint 1136005962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,907.58136
Policy Entropy: 3.10287
Value Function Loss: 0.00397

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.60205
Value Function Update Magnitude: 0.52603

Collected Steps per Second: 22,271.14762
Overall Steps per Second: 10,611.79326

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.46727
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.71287

Cumulative Model Updates: 136,212
Cumulative Timesteps: 1,136,055,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.76150
Policy Entropy: 3.10191
Value Function Loss: 0.00403

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.59972
Value Function Update Magnitude: 0.53116

Collected Steps per Second: 22,212.61392
Overall Steps per Second: 10,478.56303

Timestep Collection Time: 2.25106
Timestep Consumption Time: 2.52077
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.77184

Cumulative Model Updates: 136,218
Cumulative Timesteps: 1,136,105,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1136105976...
Checkpoint 1136105976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.16147
Policy Entropy: 3.10781
Value Function Loss: 0.00420

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.60109
Value Function Update Magnitude: 0.52691

Collected Steps per Second: 21,931.05265
Overall Steps per Second: 10,513.90986

Timestep Collection Time: 2.28033
Timestep Consumption Time: 2.47623
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.75656

Cumulative Model Updates: 136,224
Cumulative Timesteps: 1,136,155,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.15468
Policy Entropy: 3.10606
Value Function Loss: 0.00442

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.60894
Value Function Update Magnitude: 0.54613

Collected Steps per Second: 22,160.47440
Overall Steps per Second: 10,532.02249

Timestep Collection Time: 2.25771
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.75046

Cumulative Model Updates: 136,230
Cumulative Timesteps: 1,136,206,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1136206018...
Checkpoint 1136206018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.59950
Policy Entropy: 3.11884
Value Function Loss: 0.00451

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.61247
Value Function Update Magnitude: 0.55893

Collected Steps per Second: 21,912.83833
Overall Steps per Second: 10,558.27480

Timestep Collection Time: 2.28268
Timestep Consumption Time: 2.45484
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.73752

Cumulative Model Updates: 136,236
Cumulative Timesteps: 1,136,256,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.31744
Policy Entropy: 3.11841
Value Function Loss: 0.00436

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.61539
Value Function Update Magnitude: 0.57693

Collected Steps per Second: 22,001.57419
Overall Steps per Second: 10,522.03777

Timestep Collection Time: 2.27393
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.75478

Cumulative Model Updates: 136,242
Cumulative Timesteps: 1,136,306,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1136306068...
Checkpoint 1136306068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.38066
Policy Entropy: 3.12715
Value Function Loss: 0.00431

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.61553
Value Function Update Magnitude: 0.55825

Collected Steps per Second: 21,719.86025
Overall Steps per Second: 10,421.75509

Timestep Collection Time: 2.30351
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.80073

Cumulative Model Updates: 136,248
Cumulative Timesteps: 1,136,356,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.03259
Policy Entropy: 3.12559
Value Function Loss: 0.00440

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.61067
Value Function Update Magnitude: 0.54172

Collected Steps per Second: 22,264.12435
Overall Steps per Second: 10,604.69466

Timestep Collection Time: 2.24666
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.71678

Cumulative Model Updates: 136,254
Cumulative Timesteps: 1,136,406,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1136406120...
Checkpoint 1136406120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.55656
Policy Entropy: 3.12620
Value Function Loss: 0.00425

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.59902
Value Function Update Magnitude: 0.52889

Collected Steps per Second: 22,169.08119
Overall Steps per Second: 10,514.72127

Timestep Collection Time: 2.25639
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.75733

Cumulative Model Updates: 136,260
Cumulative Timesteps: 1,136,456,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.00371
Policy Entropy: 3.13028
Value Function Loss: 0.00417

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.59423
Value Function Update Magnitude: 0.52070

Collected Steps per Second: 22,317.31381
Overall Steps per Second: 10,646.92207

Timestep Collection Time: 2.24095
Timestep Consumption Time: 2.45637
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.69732

Cumulative Model Updates: 136,266
Cumulative Timesteps: 1,136,506,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1136506154...
Checkpoint 1136506154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.62037
Policy Entropy: 3.12639
Value Function Loss: 0.00413

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.58856
Value Function Update Magnitude: 0.51037

Collected Steps per Second: 22,057.30391
Overall Steps per Second: 10,376.54111

Timestep Collection Time: 2.26691
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.81875

Cumulative Model Updates: 136,272
Cumulative Timesteps: 1,136,556,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.87067
Policy Entropy: 3.12959
Value Function Loss: 0.00422

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.58998
Value Function Update Magnitude: 0.53074

Collected Steps per Second: 22,227.92648
Overall Steps per Second: 10,413.85516

Timestep Collection Time: 2.24978
Timestep Consumption Time: 2.55228
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.80206

Cumulative Model Updates: 136,278
Cumulative Timesteps: 1,136,606,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1136606164...
Checkpoint 1136606164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.51632
Policy Entropy: 3.13554
Value Function Loss: 0.00419

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.59584
Value Function Update Magnitude: 0.54288

Collected Steps per Second: 21,737.85607
Overall Steps per Second: 10,426.37091

Timestep Collection Time: 2.30124
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.79783

Cumulative Model Updates: 136,284
Cumulative Timesteps: 1,136,656,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.71766
Policy Entropy: 3.13734
Value Function Loss: 0.00409

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.59183
Value Function Update Magnitude: 0.53915

Collected Steps per Second: 22,484.77682
Overall Steps per Second: 10,619.52410

Timestep Collection Time: 2.22506
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.71113

Cumulative Model Updates: 136,290
Cumulative Timesteps: 1,136,706,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1136706218...
Checkpoint 1136706218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.95874
Policy Entropy: 3.13363
Value Function Loss: 0.00423

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.55048

Collected Steps per Second: 21,535.01371
Overall Steps per Second: 10,338.02211

Timestep Collection Time: 2.32226
Timestep Consumption Time: 2.51522
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.83748

Cumulative Model Updates: 136,296
Cumulative Timesteps: 1,136,756,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.47962
Policy Entropy: 3.10979
Value Function Loss: 0.00446

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.60548
Value Function Update Magnitude: 0.55653

Collected Steps per Second: 22,718.05605
Overall Steps per Second: 10,694.62448

Timestep Collection Time: 2.20204
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.67768

Cumulative Model Updates: 136,302
Cumulative Timesteps: 1,136,806,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1136806254...
Checkpoint 1136806254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.75694
Policy Entropy: 3.09690
Value Function Loss: 0.00466

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.61839
Value Function Update Magnitude: 0.57174

Collected Steps per Second: 22,015.44074
Overall Steps per Second: 10,445.92595

Timestep Collection Time: 2.27159
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.78751

Cumulative Model Updates: 136,308
Cumulative Timesteps: 1,136,856,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.30889
Policy Entropy: 3.10808
Value Function Loss: 0.00457

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.61363
Value Function Update Magnitude: 0.59279

Collected Steps per Second: 21,692.87072
Overall Steps per Second: 10,532.84644

Timestep Collection Time: 2.30527
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.74781

Cumulative Model Updates: 136,314
Cumulative Timesteps: 1,136,906,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1136906272...
Checkpoint 1136906272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.72495
Policy Entropy: 3.11392
Value Function Loss: 0.00423

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.59957
Value Function Update Magnitude: 0.59973

Collected Steps per Second: 19,134.10359
Overall Steps per Second: 9,694.01734

Timestep Collection Time: 2.61428
Timestep Consumption Time: 2.54580
PPO Batch Consumption Time: 0.30102
Total Iteration Time: 5.16009

Cumulative Model Updates: 136,320
Cumulative Timesteps: 1,136,956,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,124.31816
Policy Entropy: 3.12102
Value Function Loss: 0.00411

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.59611
Value Function Update Magnitude: 0.54597

Collected Steps per Second: 21,943.88541
Overall Steps per Second: 10,385.11665

Timestep Collection Time: 2.27863
Timestep Consumption Time: 2.53614
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.81477

Cumulative Model Updates: 136,326
Cumulative Timesteps: 1,137,006,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1137006296...
Checkpoint 1137006296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.29521
Policy Entropy: 3.11154
Value Function Loss: 0.00419

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.59197
Value Function Update Magnitude: 0.51831

Collected Steps per Second: 19,066.59994
Overall Steps per Second: 9,865.05103

Timestep Collection Time: 2.62239
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 5.06840

Cumulative Model Updates: 136,332
Cumulative Timesteps: 1,137,056,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.56797
Policy Entropy: 3.11746
Value Function Loss: 0.00427

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.59266
Value Function Update Magnitude: 0.52109

Collected Steps per Second: 21,300.97683
Overall Steps per Second: 10,263.27314

Timestep Collection Time: 2.34844
Timestep Consumption Time: 2.52564
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.87408

Cumulative Model Updates: 136,338
Cumulative Timesteps: 1,137,106,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1137106320...
Checkpoint 1137106320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.85548
Policy Entropy: 3.12920
Value Function Loss: 0.00422

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.59000
Value Function Update Magnitude: 0.51915

Collected Steps per Second: 21,870.62399
Overall Steps per Second: 10,224.23466

Timestep Collection Time: 2.28690
Timestep Consumption Time: 2.60500
PPO Batch Consumption Time: 0.31372
Total Iteration Time: 4.89191

Cumulative Model Updates: 136,344
Cumulative Timesteps: 1,137,156,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.75272
Policy Entropy: 3.12401
Value Function Loss: 0.00429

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.15048
Policy Update Magnitude: 0.58553
Value Function Update Magnitude: 0.52163

Collected Steps per Second: 22,066.54529
Overall Steps per Second: 10,499.74830

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.76316

Cumulative Model Updates: 136,350
Cumulative Timesteps: 1,137,206,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1137206348...
Checkpoint 1137206348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,028.11343
Policy Entropy: 3.11945
Value Function Loss: 0.00438

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.59636
Value Function Update Magnitude: 0.53453

Collected Steps per Second: 22,019.95313
Overall Steps per Second: 10,358.54549

Timestep Collection Time: 2.27112
Timestep Consumption Time: 2.55678
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.82790

Cumulative Model Updates: 136,356
Cumulative Timesteps: 1,137,256,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.34539
Policy Entropy: 3.10852
Value Function Loss: 0.00446

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.60565
Value Function Update Magnitude: 0.54194

Collected Steps per Second: 22,645.68514
Overall Steps per Second: 10,650.62003

Timestep Collection Time: 2.20828
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.69531

Cumulative Model Updates: 136,362
Cumulative Timesteps: 1,137,306,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1137306366...
Checkpoint 1137306366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.37606
Policy Entropy: 3.10687
Value Function Loss: 0.00446

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.61148
Value Function Update Magnitude: 0.56574

Collected Steps per Second: 21,224.53975
Overall Steps per Second: 10,259.20987

Timestep Collection Time: 2.35642
Timestep Consumption Time: 2.51861
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.87503

Cumulative Model Updates: 136,368
Cumulative Timesteps: 1,137,356,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.84682
Policy Entropy: 3.11758
Value Function Loss: 0.00428

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.61232
Value Function Update Magnitude: 0.58832

Collected Steps per Second: 20,777.15149
Overall Steps per Second: 10,318.96281

Timestep Collection Time: 2.40851
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.84952

Cumulative Model Updates: 136,374
Cumulative Timesteps: 1,137,406,422

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1137406422...
Checkpoint 1137406422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.51484
Policy Entropy: 3.10898
Value Function Loss: 0.00407

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.60570
Value Function Update Magnitude: 0.57912

Collected Steps per Second: 22,144.25657
Overall Steps per Second: 10,377.42321

Timestep Collection Time: 2.25837
Timestep Consumption Time: 2.56074
PPO Batch Consumption Time: 0.29927
Total Iteration Time: 4.81912

Cumulative Model Updates: 136,380
Cumulative Timesteps: 1,137,456,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.47204
Policy Entropy: 3.11470
Value Function Loss: 0.00416

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.60964
Value Function Update Magnitude: 0.56577

Collected Steps per Second: 22,345.73055
Overall Steps per Second: 10,467.16923

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.53928
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.77684

Cumulative Model Updates: 136,386
Cumulative Timesteps: 1,137,506,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1137506432...
Checkpoint 1137506432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237.38052
Policy Entropy: 3.11598
Value Function Loss: 0.00425

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.61083
Value Function Update Magnitude: 0.55649

Collected Steps per Second: 22,369.23491
Overall Steps per Second: 10,625.71820

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.70575

Cumulative Model Updates: 136,392
Cumulative Timesteps: 1,137,556,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.45294
Policy Entropy: 3.12482
Value Function Loss: 0.00434

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.60676
Value Function Update Magnitude: 0.55551

Collected Steps per Second: 22,309.10727
Overall Steps per Second: 10,366.60294

Timestep Collection Time: 2.24133
Timestep Consumption Time: 2.58205
PPO Batch Consumption Time: 0.30831
Total Iteration Time: 4.82337

Cumulative Model Updates: 136,398
Cumulative Timesteps: 1,137,606,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1137606436...
Checkpoint 1137606436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.58153
Policy Entropy: 3.11268
Value Function Loss: 0.00489

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.61045
Value Function Update Magnitude: 0.58653

Collected Steps per Second: 22,202.39047
Overall Steps per Second: 10,599.91388

Timestep Collection Time: 2.25228
Timestep Consumption Time: 2.46531
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.71759

Cumulative Model Updates: 136,404
Cumulative Timesteps: 1,137,656,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.26371
Policy Entropy: 3.11418
Value Function Loss: 0.00478

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.61961
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 22,084.09481
Overall Steps per Second: 10,595.76334

Timestep Collection Time: 2.26425
Timestep Consumption Time: 2.45499
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.71924

Cumulative Model Updates: 136,410
Cumulative Timesteps: 1,137,706,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1137706446...
Checkpoint 1137706446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.54591
Policy Entropy: 3.11245
Value Function Loss: 0.00490

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.62172
Value Function Update Magnitude: 0.61621

Collected Steps per Second: 22,273.73477
Overall Steps per Second: 10,668.05391

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.68727

Cumulative Model Updates: 136,416
Cumulative Timesteps: 1,137,756,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906.36253
Policy Entropy: 3.10905
Value Function Loss: 0.00460

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.61821
Value Function Update Magnitude: 0.58865

Collected Steps per Second: 22,634.23756
Overall Steps per Second: 10,450.68741

Timestep Collection Time: 2.21001
Timestep Consumption Time: 2.57646
PPO Batch Consumption Time: 0.30181
Total Iteration Time: 4.78648

Cumulative Model Updates: 136,422
Cumulative Timesteps: 1,137,806,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1137806472...
Checkpoint 1137806472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348.58079
Policy Entropy: 3.10556
Value Function Loss: 0.00448

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.60652
Value Function Update Magnitude: 0.55654

Collected Steps per Second: 22,273.07479
Overall Steps per Second: 10,688.69229

Timestep Collection Time: 2.24540
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.67896

Cumulative Model Updates: 136,428
Cumulative Timesteps: 1,137,856,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944.34673
Policy Entropy: 3.10204
Value Function Loss: 0.00419

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.60069
Value Function Update Magnitude: 0.54970

Collected Steps per Second: 22,156.22673
Overall Steps per Second: 10,449.31730

Timestep Collection Time: 2.25797
Timestep Consumption Time: 2.52972
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.78768

Cumulative Model Updates: 136,434
Cumulative Timesteps: 1,137,906,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1137906512...
Checkpoint 1137906512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.20240
Policy Entropy: 3.10979
Value Function Loss: 0.00414

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.59817
Value Function Update Magnitude: 0.54689

Collected Steps per Second: 22,312.20922
Overall Steps per Second: 10,579.29523

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.72640

Cumulative Model Updates: 136,440
Cumulative Timesteps: 1,137,956,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.43036
Policy Entropy: 3.10319
Value Function Loss: 0.00451

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.60631
Value Function Update Magnitude: 0.53787

Collected Steps per Second: 22,540.64163
Overall Steps per Second: 10,546.70860

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.52341
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.74233

Cumulative Model Updates: 136,446
Cumulative Timesteps: 1,138,006,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1138006530...
Checkpoint 1138006530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.16228
Policy Entropy: 3.10370
Value Function Loss: 0.00467

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.61906
Value Function Update Magnitude: 0.55147

Collected Steps per Second: 22,605.42273
Overall Steps per Second: 10,540.79584

Timestep Collection Time: 2.21310
Timestep Consumption Time: 2.53303
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.74613

Cumulative Model Updates: 136,452
Cumulative Timesteps: 1,138,056,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.02966
Policy Entropy: 3.12731
Value Function Loss: 0.00434

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.60463
Value Function Update Magnitude: 0.53910

Collected Steps per Second: 22,191.26297
Overall Steps per Second: 10,527.38232

Timestep Collection Time: 2.25350
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.75028

Cumulative Model Updates: 136,458
Cumulative Timesteps: 1,138,106,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1138106566...
Checkpoint 1138106566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.15957
Policy Entropy: 3.13596
Value Function Loss: 0.00452

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.59296
Value Function Update Magnitude: 0.51587

Collected Steps per Second: 22,312.51403
Overall Steps per Second: 10,589.46774

Timestep Collection Time: 2.24152
Timestep Consumption Time: 2.48147
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.72299

Cumulative Model Updates: 136,464
Cumulative Timesteps: 1,138,156,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.51858
Policy Entropy: 3.13812
Value Function Loss: 0.00440

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.59801
Value Function Update Magnitude: 0.52834

Collected Steps per Second: 22,424.53804
Overall Steps per Second: 10,432.19835

Timestep Collection Time: 2.22997
Timestep Consumption Time: 2.56346
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.79343

Cumulative Model Updates: 136,470
Cumulative Timesteps: 1,138,206,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1138206586...
Checkpoint 1138206586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.03670
Policy Entropy: 3.12375
Value Function Loss: 0.00457

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.60715
Value Function Update Magnitude: 0.54040

Collected Steps per Second: 21,975.03060
Overall Steps per Second: 10,511.72897

Timestep Collection Time: 2.27540
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.75678

Cumulative Model Updates: 136,476
Cumulative Timesteps: 1,138,256,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.00479
Policy Entropy: 3.11880
Value Function Loss: 0.00430

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.60413
Value Function Update Magnitude: 0.54160

Collected Steps per Second: 22,436.06283
Overall Steps per Second: 10,593.09758

Timestep Collection Time: 2.22855
Timestep Consumption Time: 2.49150
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.72005

Cumulative Model Updates: 136,482
Cumulative Timesteps: 1,138,306,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1138306588...
Checkpoint 1138306588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.16620
Policy Entropy: 3.10222
Value Function Loss: 0.00416

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.59084
Value Function Update Magnitude: 0.52805

Collected Steps per Second: 22,308.62410
Overall Steps per Second: 10,696.56606

Timestep Collection Time: 2.24182
Timestep Consumption Time: 2.43370
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.67552

Cumulative Model Updates: 136,488
Cumulative Timesteps: 1,138,356,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,906.55279
Policy Entropy: 3.10469
Value Function Loss: 0.00402

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.57756
Value Function Update Magnitude: 0.51906

Collected Steps per Second: 22,543.61233
Overall Steps per Second: 10,537.86403

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.74631

Cumulative Model Updates: 136,494
Cumulative Timesteps: 1,138,406,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1138406616...
Checkpoint 1138406616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.89931
Policy Entropy: 3.10092
Value Function Loss: 0.00413

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.58294
Value Function Update Magnitude: 0.52345

Collected Steps per Second: 22,535.91958
Overall Steps per Second: 10,580.13161

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.50766
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 4.72678

Cumulative Model Updates: 136,500
Cumulative Timesteps: 1,138,456,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.73419
Policy Entropy: 3.10270
Value Function Loss: 0.00396

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.58315
Value Function Update Magnitude: 0.51658

Collected Steps per Second: 22,326.18167
Overall Steps per Second: 10,380.83260

Timestep Collection Time: 2.23961
Timestep Consumption Time: 2.57715
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.81676

Cumulative Model Updates: 136,506
Cumulative Timesteps: 1,138,506,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1138506628...
Checkpoint 1138506628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.76701
Policy Entropy: 3.10602
Value Function Loss: 0.00381

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.56817
Value Function Update Magnitude: 0.48818

Collected Steps per Second: 22,552.74064
Overall Steps per Second: 10,638.60923

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.48363
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.70137

Cumulative Model Updates: 136,512
Cumulative Timesteps: 1,138,556,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.62310
Policy Entropy: 3.11594
Value Function Loss: 0.00419

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.57023
Value Function Update Magnitude: 0.46991

Collected Steps per Second: 22,372.28657
Overall Steps per Second: 10,496.69809

Timestep Collection Time: 2.23491
Timestep Consumption Time: 2.52849
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.76340

Cumulative Model Updates: 136,518
Cumulative Timesteps: 1,138,606,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1138606644...
Checkpoint 1138606644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.40175
Policy Entropy: 3.10250
Value Function Loss: 0.00477

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.59117
Value Function Update Magnitude: 0.50727

Collected Steps per Second: 22,512.21808
Overall Steps per Second: 10,580.32116

Timestep Collection Time: 2.22199
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.72783

Cumulative Model Updates: 136,524
Cumulative Timesteps: 1,138,656,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.80303
Policy Entropy: 3.09561
Value Function Loss: 0.00482

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.60344
Value Function Update Magnitude: 0.54824

Collected Steps per Second: 22,113.21629
Overall Steps per Second: 10,457.30912

Timestep Collection Time: 2.26118
Timestep Consumption Time: 2.52035
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.78154

Cumulative Model Updates: 136,530
Cumulative Timesteps: 1,138,706,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1138706668...
Checkpoint 1138706668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.76480
Policy Entropy: 3.08922
Value Function Loss: 0.00461

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.59903
Value Function Update Magnitude: 0.53880

Collected Steps per Second: 22,123.02067
Overall Steps per Second: 10,591.69358

Timestep Collection Time: 2.26018
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.72087

Cumulative Model Updates: 136,536
Cumulative Timesteps: 1,138,756,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.77586
Policy Entropy: 3.08349
Value Function Loss: 0.00429

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.58997
Value Function Update Magnitude: 0.53892

Collected Steps per Second: 22,346.03728
Overall Steps per Second: 10,484.36465

Timestep Collection Time: 2.23843
Timestep Consumption Time: 2.53249
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.77091

Cumulative Model Updates: 136,542
Cumulative Timesteps: 1,138,806,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1138806690...
Checkpoint 1138806690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.20530
Policy Entropy: 3.09316
Value Function Loss: 0.00405

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.59151
Value Function Update Magnitude: 0.53446

Collected Steps per Second: 22,312.03763
Overall Steps per Second: 10,573.63022

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.73177

Cumulative Model Updates: 136,548
Cumulative Timesteps: 1,138,856,722

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,677.67307
Policy Entropy: 3.08103
Value Function Loss: 0.00393

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.52910

Collected Steps per Second: 22,206.93108
Overall Steps per Second: 10,541.43655

Timestep Collection Time: 2.25272
Timestep Consumption Time: 2.49293
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.74565

Cumulative Model Updates: 136,554
Cumulative Timesteps: 1,138,906,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1138906748...
Checkpoint 1138906748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.78940
Policy Entropy: 3.09247
Value Function Loss: 0.00393

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.59425
Value Function Update Magnitude: 0.51261

Collected Steps per Second: 21,646.04910
Overall Steps per Second: 10,450.59959

Timestep Collection Time: 2.31100
Timestep Consumption Time: 2.47571
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.78671

Cumulative Model Updates: 136,560
Cumulative Timesteps: 1,138,956,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.50317
Policy Entropy: 3.08956
Value Function Loss: 0.00423

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.59516
Value Function Update Magnitude: 0.51883

Collected Steps per Second: 22,675.47783
Overall Steps per Second: 10,639.31713

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69993

Cumulative Model Updates: 136,566
Cumulative Timesteps: 1,139,006,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1139006776...
Checkpoint 1139006776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.60347
Policy Entropy: 3.08648
Value Function Loss: 0.00438

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.60068
Value Function Update Magnitude: 0.55599

Collected Steps per Second: 22,511.72668
Overall Steps per Second: 10,650.58950

Timestep Collection Time: 2.22329
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.69927

Cumulative Model Updates: 136,572
Cumulative Timesteps: 1,139,056,826

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.08161
Policy Entropy: 3.06779
Value Function Loss: 0.00446

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.60885
Value Function Update Magnitude: 0.59347

Collected Steps per Second: 22,299.12217
Overall Steps per Second: 10,448.97647

Timestep Collection Time: 2.24251
Timestep Consumption Time: 2.54322
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.78573

Cumulative Model Updates: 136,578
Cumulative Timesteps: 1,139,106,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1139106832...
Checkpoint 1139106832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.35789
Policy Entropy: 3.07626
Value Function Loss: 0.00460

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.60603
Value Function Update Magnitude: 0.58887

Collected Steps per Second: 22,359.88404
Overall Steps per Second: 10,646.39628

Timestep Collection Time: 2.23624
Timestep Consumption Time: 2.46038
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.69661

Cumulative Model Updates: 136,584
Cumulative Timesteps: 1,139,156,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.45421
Policy Entropy: 3.08915
Value Function Loss: 0.00449

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.59160

Collected Steps per Second: 22,428.31701
Overall Steps per Second: 10,533.54492

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.51872
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.74921

Cumulative Model Updates: 136,590
Cumulative Timesteps: 1,139,206,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1139206860...
Checkpoint 1139206860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.48815
Policy Entropy: 3.09219
Value Function Loss: 0.00464

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.60385
Value Function Update Magnitude: 0.58153

Collected Steps per Second: 22,475.51283
Overall Steps per Second: 10,546.96960

Timestep Collection Time: 2.22553
Timestep Consumption Time: 2.51706
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.74259

Cumulative Model Updates: 136,596
Cumulative Timesteps: 1,139,256,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.42415
Policy Entropy: 3.10262
Value Function Loss: 0.00461

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.61320
Value Function Update Magnitude: 0.57680

Collected Steps per Second: 22,363.72793
Overall Steps per Second: 10,528.02842

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.51477
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 4.75170

Cumulative Model Updates: 136,602
Cumulative Timesteps: 1,139,306,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1139306906...
Checkpoint 1139306906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,994.95867
Policy Entropy: 3.10864
Value Function Loss: 0.00443

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.61471
Value Function Update Magnitude: 0.59016

Collected Steps per Second: 22,454.86133
Overall Steps per Second: 10,618.79488

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.48294
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.71052

Cumulative Model Updates: 136,608
Cumulative Timesteps: 1,139,356,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.50230
Policy Entropy: 3.12318
Value Function Loss: 0.00414

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.60391
Value Function Update Magnitude: 0.59159

Collected Steps per Second: 22,426.31091
Overall Steps per Second: 10,388.25290

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.58453
PPO Batch Consumption Time: 0.30174
Total Iteration Time: 4.81486

Cumulative Model Updates: 136,614
Cumulative Timesteps: 1,139,406,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1139406944...
Checkpoint 1139406944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.45457
Policy Entropy: 3.12342
Value Function Loss: 0.00392

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.59125
Value Function Update Magnitude: 0.58444

Collected Steps per Second: 22,123.77734
Overall Steps per Second: 10,628.77903

Timestep Collection Time: 2.26055
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.70534

Cumulative Model Updates: 136,620
Cumulative Timesteps: 1,139,456,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,502.73498
Policy Entropy: 3.13444
Value Function Loss: 0.00395

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.58964
Value Function Update Magnitude: 0.58636

Collected Steps per Second: 22,165.02882
Overall Steps per Second: 10,490.99246

Timestep Collection Time: 2.25644
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.76733

Cumulative Model Updates: 136,626
Cumulative Timesteps: 1,139,506,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1139506970...
Checkpoint 1139506970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.96266
Policy Entropy: 3.12020
Value Function Loss: 0.00446

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.59626
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 22,277.91503
Overall Steps per Second: 10,536.72008

Timestep Collection Time: 2.24509
Timestep Consumption Time: 2.50173
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.74683

Cumulative Model Updates: 136,632
Cumulative Timesteps: 1,139,556,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.08346
Policy Entropy: 3.13503
Value Function Loss: 0.00428

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.60002
Value Function Update Magnitude: 0.57123

Collected Steps per Second: 22,169.54456
Overall Steps per Second: 10,533.52109

Timestep Collection Time: 2.25544
Timestep Consumption Time: 2.49150
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.74694

Cumulative Model Updates: 136,638
Cumulative Timesteps: 1,139,606,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1139606988...
Checkpoint 1139606988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.52086
Policy Entropy: 3.12341
Value Function Loss: 0.00406

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.58056
Value Function Update Magnitude: 0.54377

Collected Steps per Second: 22,570.34056
Overall Steps per Second: 10,627.93405

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.49048
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.70684

Cumulative Model Updates: 136,644
Cumulative Timesteps: 1,139,657,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.74255
Policy Entropy: 3.13732
Value Function Loss: 0.00388

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.57311
Value Function Update Magnitude: 0.53234

Collected Steps per Second: 22,404.51046
Overall Steps per Second: 10,546.43564

Timestep Collection Time: 2.23303
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.74378

Cumulative Model Updates: 136,650
Cumulative Timesteps: 1,139,707,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1139707042...
Checkpoint 1139707042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.38721
Policy Entropy: 3.13079
Value Function Loss: 0.00399

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.54835

Collected Steps per Second: 22,536.11928
Overall Steps per Second: 10,594.26410

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.72237

Cumulative Model Updates: 136,656
Cumulative Timesteps: 1,139,757,072

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.64276
Policy Entropy: 3.13198
Value Function Loss: 0.00406

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.56951
Value Function Update Magnitude: 0.54952

Collected Steps per Second: 22,203.56432
Overall Steps per Second: 10,481.03727

Timestep Collection Time: 2.25189
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.77052

Cumulative Model Updates: 136,662
Cumulative Timesteps: 1,139,807,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1139807072...
Checkpoint 1139807072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.92758
Policy Entropy: 3.13562
Value Function Loss: 0.00401

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.57296
Value Function Update Magnitude: 0.55135

Collected Steps per Second: 22,315.24605
Overall Steps per Second: 10,640.78306

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.45828
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.69890

Cumulative Model Updates: 136,668
Cumulative Timesteps: 1,139,857,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.46057
Policy Entropy: 3.13238
Value Function Loss: 0.00417

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.56629
Value Function Update Magnitude: 0.56232

Collected Steps per Second: 22,711.73276
Overall Steps per Second: 10,637.74538

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.70212

Cumulative Model Updates: 136,674
Cumulative Timesteps: 1,139,907,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1139907092...
Checkpoint 1139907092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.36528
Policy Entropy: 3.12261
Value Function Loss: 0.00444

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.57001
Value Function Update Magnitude: 0.55069

Collected Steps per Second: 21,988.34512
Overall Steps per Second: 10,439.91445

Timestep Collection Time: 2.27484
Timestep Consumption Time: 2.51639
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.79123

Cumulative Model Updates: 136,680
Cumulative Timesteps: 1,139,957,112

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.96842
Policy Entropy: 3.10983
Value Function Loss: 0.00432

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.54822

Collected Steps per Second: 22,586.68612
Overall Steps per Second: 10,570.72604

Timestep Collection Time: 2.21520
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.73326

Cumulative Model Updates: 136,686
Cumulative Timesteps: 1,140,007,146

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1140007146...
Checkpoint 1140007146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.34479
Policy Entropy: 3.10526
Value Function Loss: 0.00432

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.58427
Value Function Update Magnitude: 0.56914

Collected Steps per Second: 22,047.87157
Overall Steps per Second: 10,537.66630

Timestep Collection Time: 2.26779
Timestep Consumption Time: 2.47709
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.74488

Cumulative Model Updates: 136,692
Cumulative Timesteps: 1,140,057,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.97932
Policy Entropy: 3.10962
Value Function Loss: 0.00431

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.60170
Value Function Update Magnitude: 0.58122

Collected Steps per Second: 22,480.75606
Overall Steps per Second: 10,524.32856

Timestep Collection Time: 2.22510
Timestep Consumption Time: 2.52788
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.75299

Cumulative Model Updates: 136,698
Cumulative Timesteps: 1,140,107,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1140107168...
Checkpoint 1140107168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.44891
Policy Entropy: 3.11775
Value Function Loss: 0.00403

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.59785
Value Function Update Magnitude: 0.56379

Collected Steps per Second: 22,392.89314
Overall Steps per Second: 10,525.98604

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.51891
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.75319

Cumulative Model Updates: 136,704
Cumulative Timesteps: 1,140,157,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.83488
Policy Entropy: 3.12068
Value Function Loss: 0.00434

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.59535
Value Function Update Magnitude: 0.55462

Collected Steps per Second: 22,502.87111
Overall Steps per Second: 10,411.93950

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.58158
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.80468

Cumulative Model Updates: 136,710
Cumulative Timesteps: 1,140,207,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1140207226...
Checkpoint 1140207226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598.34974
Policy Entropy: 3.12873
Value Function Loss: 0.00422

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.59234
Value Function Update Magnitude: 0.55790

Collected Steps per Second: 22,054.93869
Overall Steps per Second: 10,419.96851

Timestep Collection Time: 2.26824
Timestep Consumption Time: 2.53273
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.80097

Cumulative Model Updates: 136,716
Cumulative Timesteps: 1,140,257,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.17272
Policy Entropy: 3.12488
Value Function Loss: 0.00434

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.59328
Value Function Update Magnitude: 0.55184

Collected Steps per Second: 22,500.07975
Overall Steps per Second: 10,726.55784

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.66207

Cumulative Model Updates: 136,722
Cumulative Timesteps: 1,140,307,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1140307260...
Checkpoint 1140307260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.41010
Policy Entropy: 3.12740
Value Function Loss: 0.00429

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.59516
Value Function Update Magnitude: 0.57122

Collected Steps per Second: 22,183.30673
Overall Steps per Second: 10,612.47994

Timestep Collection Time: 2.25503
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.71370

Cumulative Model Updates: 136,728
Cumulative Timesteps: 1,140,357,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.63393
Policy Entropy: 3.12844
Value Function Loss: 0.00451

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.60274
Value Function Update Magnitude: 0.59621

Collected Steps per Second: 22,296.56491
Overall Steps per Second: 10,532.30304

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.50590
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.74939

Cumulative Model Updates: 136,734
Cumulative Timesteps: 1,140,407,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1140407306...
Checkpoint 1140407306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954.58548
Policy Entropy: 3.12068
Value Function Loss: 0.00456

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.61224
Value Function Update Magnitude: 0.60743

Collected Steps per Second: 22,031.56415
Overall Steps per Second: 10,507.51676

Timestep Collection Time: 2.26983
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.75926

Cumulative Model Updates: 136,740
Cumulative Timesteps: 1,140,457,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.83962
Policy Entropy: 3.12848
Value Function Loss: 0.00457

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.61743
Value Function Update Magnitude: 0.59945

Collected Steps per Second: 22,652.17913
Overall Steps per Second: 10,605.96325

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.50774
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71565

Cumulative Model Updates: 136,746
Cumulative Timesteps: 1,140,507,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1140507328...
Checkpoint 1140507328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.01513
Policy Entropy: 3.13387
Value Function Loss: 0.00424

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.60497
Value Function Update Magnitude: 0.59064

Collected Steps per Second: 22,321.05912
Overall Steps per Second: 10,602.89019

Timestep Collection Time: 2.24147
Timestep Consumption Time: 2.47724
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.71871

Cumulative Model Updates: 136,752
Cumulative Timesteps: 1,140,557,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,110.81509
Policy Entropy: 3.13113
Value Function Loss: 0.00425

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.58765
Value Function Update Magnitude: 0.56997

Collected Steps per Second: 22,645.12031
Overall Steps per Second: 10,472.01701

Timestep Collection Time: 2.20842
Timestep Consumption Time: 2.56716
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.77558

Cumulative Model Updates: 136,758
Cumulative Timesteps: 1,140,607,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1140607370...
Checkpoint 1140607370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.58152
Policy Entropy: 3.12558
Value Function Loss: 0.00406

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.58085
Value Function Update Magnitude: 0.54283

Collected Steps per Second: 22,083.45131
Overall Steps per Second: 10,598.83390

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.71995

Cumulative Model Updates: 136,764
Cumulative Timesteps: 1,140,657,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.96114
Policy Entropy: 3.13509
Value Function Loss: 0.00418

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.57493
Value Function Update Magnitude: 0.53252

Collected Steps per Second: 22,290.89741
Overall Steps per Second: 10,494.80191

Timestep Collection Time: 2.24441
Timestep Consumption Time: 2.52271
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.76712

Cumulative Model Updates: 136,770
Cumulative Timesteps: 1,140,707,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1140707426...
Checkpoint 1140707426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.53026
Policy Entropy: 3.14682
Value Function Loss: 0.00428

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.54694

Collected Steps per Second: 22,110.91892
Overall Steps per Second: 10,502.27187

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.76164

Cumulative Model Updates: 136,776
Cumulative Timesteps: 1,140,757,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.93857
Policy Entropy: 3.15334
Value Function Loss: 0.00385

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.58476
Value Function Update Magnitude: 0.55599

Collected Steps per Second: 22,533.68181
Overall Steps per Second: 10,679.01320

Timestep Collection Time: 2.21970
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.68377

Cumulative Model Updates: 136,782
Cumulative Timesteps: 1,140,807,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1140807452...
Checkpoint 1140807452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.03119
Policy Entropy: 3.15252
Value Function Loss: 0.00389

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.57924
Value Function Update Magnitude: 0.54481

Collected Steps per Second: 21,760.74629
Overall Steps per Second: 10,135.35686

Timestep Collection Time: 2.29863
Timestep Consumption Time: 2.63656
PPO Batch Consumption Time: 0.31061
Total Iteration Time: 4.93520

Cumulative Model Updates: 136,788
Cumulative Timesteps: 1,140,857,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.70485
Policy Entropy: 3.16366
Value Function Loss: 0.00381

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.57725
Value Function Update Magnitude: 0.55536

Collected Steps per Second: 22,515.46605
Overall Steps per Second: 10,447.89440

Timestep Collection Time: 2.22114
Timestep Consumption Time: 2.56547
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 4.78661

Cumulative Model Updates: 136,794
Cumulative Timesteps: 1,140,907,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1140907482...
Checkpoint 1140907482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.92847
Policy Entropy: 3.17149
Value Function Loss: 0.00410

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.57441
Value Function Update Magnitude: 0.57121

Collected Steps per Second: 22,288.54731
Overall Steps per Second: 10,552.38024

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.73846

Cumulative Model Updates: 136,800
Cumulative Timesteps: 1,140,957,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,135.76284
Policy Entropy: 3.16522
Value Function Loss: 0.00387

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.57184
Value Function Update Magnitude: 0.54877

Collected Steps per Second: 22,674.03614
Overall Steps per Second: 10,549.39268

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.53596
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74245

Cumulative Model Updates: 136,806
Cumulative Timesteps: 1,141,007,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1141007514...
Checkpoint 1141007514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,581.32356
Policy Entropy: 3.15071
Value Function Loss: 0.00382

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.57369
Value Function Update Magnitude: 0.52880

Collected Steps per Second: 22,188.74709
Overall Steps per Second: 10,612.20437

Timestep Collection Time: 2.25448
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.71382

Cumulative Model Updates: 136,812
Cumulative Timesteps: 1,141,057,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.66226
Policy Entropy: 3.15115
Value Function Loss: 0.00422

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.58893
Value Function Update Magnitude: 0.54520

Collected Steps per Second: 22,594.16660
Overall Steps per Second: 10,531.54890

Timestep Collection Time: 2.21402
Timestep Consumption Time: 2.53590
PPO Batch Consumption Time: 0.29922
Total Iteration Time: 4.74992

Cumulative Model Updates: 136,818
Cumulative Timesteps: 1,141,107,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1141107562...
Checkpoint 1141107562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.28059
Policy Entropy: 3.14862
Value Function Loss: 0.00462

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.59477
Value Function Update Magnitude: 0.55108

Collected Steps per Second: 22,367.98594
Overall Steps per Second: 10,636.54420

Timestep Collection Time: 2.23534
Timestep Consumption Time: 2.46544
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.70077

Cumulative Model Updates: 136,824
Cumulative Timesteps: 1,141,157,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.37152
Policy Entropy: 3.14793
Value Function Loss: 0.00449

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.58524
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 22,418.91718
Overall Steps per Second: 10,526.39043

Timestep Collection Time: 2.23142
Timestep Consumption Time: 2.52102
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 4.75244

Cumulative Model Updates: 136,830
Cumulative Timesteps: 1,141,207,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1141207588...
Checkpoint 1141207588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.36810
Policy Entropy: 3.15587
Value Function Loss: 0.00392

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.57230
Value Function Update Magnitude: 0.54585

Collected Steps per Second: 22,262.83842
Overall Steps per Second: 10,544.79088

Timestep Collection Time: 2.24787
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.74585

Cumulative Model Updates: 136,836
Cumulative Timesteps: 1,141,257,632

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.71456
Policy Entropy: 3.15710
Value Function Loss: 0.00348

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.56461
Value Function Update Magnitude: 0.51175

Collected Steps per Second: 22,438.99376
Overall Steps per Second: 10,423.65690

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.57016
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.79985

Cumulative Model Updates: 136,842
Cumulative Timesteps: 1,141,307,664

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1141307664...
Checkpoint 1141307664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,541.13819
Policy Entropy: 3.14112
Value Function Loss: 0.00365

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.48986

Collected Steps per Second: 22,520.33272
Overall Steps per Second: 10,618.67093

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.70944

Cumulative Model Updates: 136,848
Cumulative Timesteps: 1,141,357,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.59382
Policy Entropy: 3.14606
Value Function Loss: 0.00392

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.58068
Value Function Update Magnitude: 0.49946

Collected Steps per Second: 22,454.22396
Overall Steps per Second: 10,515.31632

Timestep Collection Time: 2.22684
Timestep Consumption Time: 2.52832
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.75516

Cumulative Model Updates: 136,854
Cumulative Timesteps: 1,141,407,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1141407674...
Checkpoint 1141407674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.66692
Policy Entropy: 3.14155
Value Function Loss: 0.00415

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.59223
Value Function Update Magnitude: 0.51242

Collected Steps per Second: 21,889.04028
Overall Steps per Second: 10,527.67553

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.46632
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.75167

Cumulative Model Updates: 136,860
Cumulative Timesteps: 1,141,457,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.14590
Policy Entropy: 3.13723
Value Function Loss: 0.00399

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.58345
Value Function Update Magnitude: 0.53140

Collected Steps per Second: 22,407.39413
Overall Steps per Second: 10,516.32967

Timestep Collection Time: 2.23239
Timestep Consumption Time: 2.52421
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.75660

Cumulative Model Updates: 136,866
Cumulative Timesteps: 1,141,507,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1141507720...
Checkpoint 1141507720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.28734
Policy Entropy: 3.13478
Value Function Loss: 0.00387

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.57899
Value Function Update Magnitude: 0.53267

Collected Steps per Second: 22,079.37432
Overall Steps per Second: 10,613.26638

Timestep Collection Time: 2.26519
Timestep Consumption Time: 2.44721
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.71240

Cumulative Model Updates: 136,872
Cumulative Timesteps: 1,141,557,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992.25431
Policy Entropy: 3.14234
Value Function Loss: 0.00360

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.56653
Value Function Update Magnitude: 0.51182

Collected Steps per Second: 22,714.45401
Overall Steps per Second: 10,535.72863

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.54502
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.74671

Cumulative Model Updates: 136,878
Cumulative Timesteps: 1,141,607,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1141607744...
Checkpoint 1141607744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,127.18142
Policy Entropy: 3.15623
Value Function Loss: 0.00382

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.48499

Collected Steps per Second: 22,058.25659
Overall Steps per Second: 10,562.58680

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.46736
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.73445

Cumulative Model Updates: 136,884
Cumulative Timesteps: 1,141,657,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.66135
Policy Entropy: 3.13901
Value Function Loss: 0.00391

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.47794

Collected Steps per Second: 22,429.75361
Overall Steps per Second: 10,494.51465

Timestep Collection Time: 2.22936
Timestep Consumption Time: 2.53541
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 4.76477

Cumulative Model Updates: 136,890
Cumulative Timesteps: 1,141,707,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1141707756...
Checkpoint 1141707756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.28160
Policy Entropy: 3.13726
Value Function Loss: 0.00410

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.56625
Value Function Update Magnitude: 0.47578

Collected Steps per Second: 22,348.12204
Overall Steps per Second: 10,588.48351

Timestep Collection Time: 2.23804
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.72362

Cumulative Model Updates: 136,896
Cumulative Timesteps: 1,141,757,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.87292
Policy Entropy: 3.14345
Value Function Loss: 0.00409

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.57756
Value Function Update Magnitude: 0.48675

Collected Steps per Second: 22,238.92476
Overall Steps per Second: 10,551.50753

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.73961

Cumulative Model Updates: 136,902
Cumulative Timesteps: 1,141,807,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1141807782...
Checkpoint 1141807782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923.62687
Policy Entropy: 3.14911
Value Function Loss: 0.00411

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.58312
Value Function Update Magnitude: 0.47666

Collected Steps per Second: 22,507.30738
Overall Steps per Second: 10,636.44139

Timestep Collection Time: 2.22248
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.70289

Cumulative Model Updates: 136,908
Cumulative Timesteps: 1,141,857,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.86150
Policy Entropy: 3.14330
Value Function Loss: 0.00400

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.45825

Collected Steps per Second: 22,448.76174
Overall Steps per Second: 10,546.23042

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.51424
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.74198

Cumulative Model Updates: 136,914
Cumulative Timesteps: 1,141,907,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1141907814...
Checkpoint 1141907814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,682.40528
Policy Entropy: 3.13802
Value Function Loss: 0.00396

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.56013
Value Function Update Magnitude: 0.44135

Collected Steps per Second: 22,413.29808
Overall Steps per Second: 10,499.60303

Timestep Collection Time: 2.23082
Timestep Consumption Time: 2.53127
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.76208

Cumulative Model Updates: 136,920
Cumulative Timesteps: 1,141,957,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.32343
Policy Entropy: 3.14280
Value Function Loss: 0.00417

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.57042
Value Function Update Magnitude: 0.46151

Collected Steps per Second: 22,310.12972
Overall Steps per Second: 10,506.28903

Timestep Collection Time: 2.24185
Timestep Consumption Time: 2.51873
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.76058

Cumulative Model Updates: 136,926
Cumulative Timesteps: 1,142,007,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1142007830...
Checkpoint 1142007830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.16737
Policy Entropy: 3.15018
Value Function Loss: 0.00411

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.49953

Collected Steps per Second: 22,118.44815
Overall Steps per Second: 10,523.32170

Timestep Collection Time: 2.26128
Timestep Consumption Time: 2.49159
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.75287

Cumulative Model Updates: 136,932
Cumulative Timesteps: 1,142,057,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.58915
Policy Entropy: 3.14416
Value Function Loss: 0.00408

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.49938

Collected Steps per Second: 22,550.75137
Overall Steps per Second: 10,524.81740

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.53366
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.75106

Cumulative Model Updates: 136,938
Cumulative Timesteps: 1,142,107,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1142107850...
Checkpoint 1142107850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.10299
Policy Entropy: 3.15194
Value Function Loss: 0.00369

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.48227

Collected Steps per Second: 22,223.93341
Overall Steps per Second: 10,606.76705

Timestep Collection Time: 2.25055
Timestep Consumption Time: 2.46493
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.71548

Cumulative Model Updates: 136,944
Cumulative Timesteps: 1,142,157,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.59092
Policy Entropy: 3.15025
Value Function Loss: 0.00381

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.55763
Value Function Update Magnitude: 0.46032

Collected Steps per Second: 21,909.68575
Overall Steps per Second: 10,527.88516

Timestep Collection Time: 2.28219
Timestep Consumption Time: 2.46729
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.74948

Cumulative Model Updates: 136,950
Cumulative Timesteps: 1,142,207,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1142207868...
Checkpoint 1142207868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.56223
Policy Entropy: 3.15173
Value Function Loss: 0.00389

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.44675

Collected Steps per Second: 22,040.32474
Overall Steps per Second: 10,611.21822

Timestep Collection Time: 2.27002
Timestep Consumption Time: 2.44499
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.71501

Cumulative Model Updates: 136,956
Cumulative Timesteps: 1,142,257,900

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,564.03719
Policy Entropy: 3.15031
Value Function Loss: 0.00389

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.56629
Value Function Update Magnitude: 0.45512

Collected Steps per Second: 22,429.98804
Overall Steps per Second: 10,494.95451

Timestep Collection Time: 2.22934
Timestep Consumption Time: 2.53524
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.76458

Cumulative Model Updates: 136,962
Cumulative Timesteps: 1,142,307,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1142307904...
Checkpoint 1142307904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.19809
Policy Entropy: 3.15092
Value Function Loss: 0.00391

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.46897

Collected Steps per Second: 22,651.04211
Overall Steps per Second: 10,610.49114

Timestep Collection Time: 2.20873
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.71514

Cumulative Model Updates: 136,968
Cumulative Timesteps: 1,142,357,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.82158
Policy Entropy: 3.14373
Value Function Loss: 0.00374

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.56656
Value Function Update Magnitude: 0.47155

Collected Steps per Second: 22,338.23074
Overall Steps per Second: 10,480.23777

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.53308
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.77184

Cumulative Model Updates: 136,974
Cumulative Timesteps: 1,142,407,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1142407944...
Checkpoint 1142407944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.77371
Policy Entropy: 3.15343
Value Function Loss: 0.00391

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.56503
Value Function Update Magnitude: 0.46955

Collected Steps per Second: 22,368.47196
Overall Steps per Second: 10,561.09212

Timestep Collection Time: 2.23583
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.73550

Cumulative Model Updates: 136,980
Cumulative Timesteps: 1,142,457,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.52518
Policy Entropy: 3.14992
Value Function Loss: 0.00413

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.57745
Value Function Update Magnitude: 0.47696

Collected Steps per Second: 22,221.79568
Overall Steps per Second: 10,541.47951

Timestep Collection Time: 2.25067
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.74450

Cumulative Model Updates: 136,986
Cumulative Timesteps: 1,142,507,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1142507970...
Checkpoint 1142507970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.97889
Policy Entropy: 3.14967
Value Function Loss: 0.00435

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.50523

Collected Steps per Second: 22,419.74996
Overall Steps per Second: 10,566.54126

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.50284
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.73400

Cumulative Model Updates: 136,992
Cumulative Timesteps: 1,142,557,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.27157
Policy Entropy: 3.14170
Value Function Loss: 0.00413

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.52045

Collected Steps per Second: 22,341.93958
Overall Steps per Second: 10,495.63389

Timestep Collection Time: 2.23911
Timestep Consumption Time: 2.52726
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.76636

Cumulative Model Updates: 136,998
Cumulative Timesteps: 1,142,608,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1142608018...
Checkpoint 1142608018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.93733
Policy Entropy: 3.13963
Value Function Loss: 0.00434

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.58482
Value Function Update Magnitude: 0.56106

Collected Steps per Second: 21,733.12669
Overall Steps per Second: 10,410.68116

Timestep Collection Time: 2.30146
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.80449

Cumulative Model Updates: 137,004
Cumulative Timesteps: 1,142,658,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.80874
Policy Entropy: 3.15113
Value Function Loss: 0.00404

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.57881
Value Function Update Magnitude: 0.57782

Collected Steps per Second: 22,739.49787
Overall Steps per Second: 10,747.33918

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.65287

Cumulative Model Updates: 137,010
Cumulative Timesteps: 1,142,708,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1142708042...
Checkpoint 1142708042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,028.89823
Policy Entropy: 3.15375
Value Function Loss: 0.00415

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.57517
Value Function Update Magnitude: 0.56282

Collected Steps per Second: 22,362.48176
Overall Steps per Second: 10,602.69693

Timestep Collection Time: 2.23616
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.71635

Cumulative Model Updates: 137,016
Cumulative Timesteps: 1,142,758,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.82783
Policy Entropy: 3.16670
Value Function Loss: 0.00390

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.53279

Collected Steps per Second: 22,184.37286
Overall Steps per Second: 10,435.14653

Timestep Collection Time: 2.25420
Timestep Consumption Time: 2.53807
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.79227

Cumulative Model Updates: 137,022
Cumulative Timesteps: 1,142,808,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1142808056...
Checkpoint 1142808056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.13121
Policy Entropy: 3.16228
Value Function Loss: 0.00413

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.52214

Collected Steps per Second: 21,961.84650
Overall Steps per Second: 10,459.85769

Timestep Collection Time: 2.27722
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.78133

Cumulative Model Updates: 137,028
Cumulative Timesteps: 1,142,858,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.34265
Policy Entropy: 3.16557
Value Function Loss: 0.00416

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.58061
Value Function Update Magnitude: 0.51204

Collected Steps per Second: 21,911.79419
Overall Steps per Second: 10,384.86399

Timestep Collection Time: 2.28379
Timestep Consumption Time: 2.53495
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.81874

Cumulative Model Updates: 137,034
Cumulative Timesteps: 1,142,908,110

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1142908110...
Checkpoint 1142908110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.03228
Policy Entropy: 3.15656
Value Function Loss: 0.00415

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.58204
Value Function Update Magnitude: 0.51533

Collected Steps per Second: 22,293.99733
Overall Steps per Second: 10,465.82678

Timestep Collection Time: 2.24392
Timestep Consumption Time: 2.53602
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.77994

Cumulative Model Updates: 137,040
Cumulative Timesteps: 1,142,958,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,743.18016
Policy Entropy: 3.15935
Value Function Loss: 0.00407

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.57807
Value Function Update Magnitude: 0.53058

Collected Steps per Second: 22,195.74034
Overall Steps per Second: 10,509.65703

Timestep Collection Time: 2.25404
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.76038

Cumulative Model Updates: 137,046
Cumulative Timesteps: 1,143,008,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1143008166...
Checkpoint 1143008166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.73276
Policy Entropy: 3.16250
Value Function Loss: 0.00379

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.58538
Value Function Update Magnitude: 0.54278

Collected Steps per Second: 22,388.51115
Overall Steps per Second: 10,600.19176

Timestep Collection Time: 2.23329
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.71690

Cumulative Model Updates: 137,052
Cumulative Timesteps: 1,143,058,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.90295
Policy Entropy: 3.16372
Value Function Loss: 0.00400

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.54419

Collected Steps per Second: 22,483.33369
Overall Steps per Second: 10,433.59403

Timestep Collection Time: 2.22485
Timestep Consumption Time: 2.56947
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.79432

Cumulative Model Updates: 137,058
Cumulative Timesteps: 1,143,108,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1143108188...
Checkpoint 1143108188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,750.95806
Policy Entropy: 3.16505
Value Function Loss: 0.00393

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.58820
Value Function Update Magnitude: 0.53116

Collected Steps per Second: 22,254.30218
Overall Steps per Second: 10,605.28050

Timestep Collection Time: 2.24792
Timestep Consumption Time: 2.46916
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.71708

Cumulative Model Updates: 137,064
Cumulative Timesteps: 1,143,158,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.68513
Policy Entropy: 3.17410
Value Function Loss: 0.00426

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.58852
Value Function Update Magnitude: 0.54922

Collected Steps per Second: 21,413.69342
Overall Steps per Second: 10,205.39870

Timestep Collection Time: 2.33542
Timestep Consumption Time: 2.56493
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.90035

Cumulative Model Updates: 137,070
Cumulative Timesteps: 1,143,208,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1143208224...
Checkpoint 1143208224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.94506
Policy Entropy: 3.17404
Value Function Loss: 0.00426

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.58515
Value Function Update Magnitude: 0.57718

Collected Steps per Second: 21,908.98649
Overall Steps per Second: 10,611.28676

Timestep Collection Time: 2.28253
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.71272

Cumulative Model Updates: 137,076
Cumulative Timesteps: 1,143,258,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.25613
Policy Entropy: 3.18387
Value Function Loss: 0.00417

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.58318
Value Function Update Magnitude: 0.57648

Collected Steps per Second: 22,459.39891
Overall Steps per Second: 10,443.94316

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.56256
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.78995

Cumulative Model Updates: 137,082
Cumulative Timesteps: 1,143,308,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1143308258...
Checkpoint 1143308258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.22264
Policy Entropy: 3.18424
Value Function Loss: 0.00370

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.56493
Value Function Update Magnitude: 0.52026

Collected Steps per Second: 22,392.51875
Overall Steps per Second: 10,543.37821

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.74345

Cumulative Model Updates: 137,088
Cumulative Timesteps: 1,143,358,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.26043
Policy Entropy: 3.19287
Value Function Loss: 0.00352

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.48677

Collected Steps per Second: 22,234.63901
Overall Steps per Second: 10,499.21567

Timestep Collection Time: 2.24964
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.76417

Cumulative Model Updates: 137,094
Cumulative Timesteps: 1,143,408,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1143408290...
Checkpoint 1143408290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.87259
Policy Entropy: 3.19813
Value Function Loss: 0.00363

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.56299
Value Function Update Magnitude: 0.49219

Collected Steps per Second: 22,246.17440
Overall Steps per Second: 10,630.98001

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.45713
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.70606

Cumulative Model Updates: 137,100
Cumulative Timesteps: 1,143,458,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.42270
Policy Entropy: 3.19037
Value Function Loss: 0.00397

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.57787
Value Function Update Magnitude: 0.53765

Collected Steps per Second: 22,247.65959
Overall Steps per Second: 10,467.85917

Timestep Collection Time: 2.24779
Timestep Consumption Time: 2.52950
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.77729

Cumulative Model Updates: 137,106
Cumulative Timesteps: 1,143,508,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1143508328...
Checkpoint 1143508328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.72825
Policy Entropy: 3.19081
Value Function Loss: 0.00393

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.56131

Collected Steps per Second: 22,246.14753
Overall Steps per Second: 10,629.70437

Timestep Collection Time: 2.24848
Timestep Consumption Time: 2.45720
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.70568

Cumulative Model Updates: 137,112
Cumulative Timesteps: 1,143,558,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.15009
Policy Entropy: 3.19653
Value Function Loss: 0.00409

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.57658
Value Function Update Magnitude: 0.55165

Collected Steps per Second: 22,199.54845
Overall Steps per Second: 10,443.43965

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.53621
PPO Batch Consumption Time: 0.30036
Total Iteration Time: 4.78923

Cumulative Model Updates: 137,118
Cumulative Timesteps: 1,143,608,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1143608364...
Checkpoint 1143608364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,222.50985
Policy Entropy: 3.19564
Value Function Loss: 0.00455

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.58058
Value Function Update Magnitude: 0.55367

Collected Steps per Second: 22,211.70147
Overall Steps per Second: 10,536.33776

Timestep Collection Time: 2.25206
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.74757

Cumulative Model Updates: 137,124
Cumulative Timesteps: 1,143,658,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.06374
Policy Entropy: 3.18809
Value Function Loss: 0.00454

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.59000
Value Function Update Magnitude: 0.56588

Collected Steps per Second: 22,503.60602
Overall Steps per Second: 10,573.45043

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.73128

Cumulative Model Updates: 137,130
Cumulative Timesteps: 1,143,708,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1143708412...
Checkpoint 1143708412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.10178
Policy Entropy: 3.17274
Value Function Loss: 0.00422

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.58830
Value Function Update Magnitude: 0.56429

Collected Steps per Second: 22,182.36671
Overall Steps per Second: 10,554.62194

Timestep Collection Time: 2.25503
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.73935

Cumulative Model Updates: 137,136
Cumulative Timesteps: 1,143,758,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.08938
Policy Entropy: 3.16239
Value Function Loss: 0.00449

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.59727
Value Function Update Magnitude: 0.56040

Collected Steps per Second: 22,323.45637
Overall Steps per Second: 10,581.50654

Timestep Collection Time: 2.24007
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.72579

Cumulative Model Updates: 137,142
Cumulative Timesteps: 1,143,808,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1143808440...
Checkpoint 1143808440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.88037
Policy Entropy: 3.16671
Value Function Loss: 0.00439

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.59770
Value Function Update Magnitude: 0.54894

Collected Steps per Second: 21,910.46767
Overall Steps per Second: 10,635.88259

Timestep Collection Time: 2.28284
Timestep Consumption Time: 2.41992
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.70276

Cumulative Model Updates: 137,148
Cumulative Timesteps: 1,143,858,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.37479
Policy Entropy: 3.15683
Value Function Loss: 0.00490

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.59815
Value Function Update Magnitude: 0.55611

Collected Steps per Second: 22,403.97782
Overall Steps per Second: 10,487.26664

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.53675
PPO Batch Consumption Time: 0.30003
Total Iteration Time: 4.76921

Cumulative Model Updates: 137,154
Cumulative Timesteps: 1,143,908,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1143908474...
Checkpoint 1143908474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.41481
Policy Entropy: 3.16405
Value Function Loss: 0.00438

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.60128
Value Function Update Magnitude: 0.57279

Collected Steps per Second: 22,649.15703
Overall Steps per Second: 10,580.43408

Timestep Collection Time: 2.20812
Timestep Consumption Time: 2.51872
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.72684

Cumulative Model Updates: 137,160
Cumulative Timesteps: 1,143,958,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.33909
Policy Entropy: 3.15486
Value Function Loss: 0.00445

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.60624
Value Function Update Magnitude: 0.57520

Collected Steps per Second: 22,509.72747
Overall Steps per Second: 10,446.70792

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.56493
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.78620

Cumulative Model Updates: 137,166
Cumulative Timesteps: 1,144,008,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1144008486...
Checkpoint 1144008486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.41430
Policy Entropy: 3.16273
Value Function Loss: 0.00444

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.61130
Value Function Update Magnitude: 0.57394

Collected Steps per Second: 22,300.20221
Overall Steps per Second: 10,562.42997

Timestep Collection Time: 2.24357
Timestep Consumption Time: 2.49322
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.73679

Cumulative Model Updates: 137,172
Cumulative Timesteps: 1,144,058,518

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.57627
Policy Entropy: 3.15772
Value Function Loss: 0.00450

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.61281
Value Function Update Magnitude: 0.58564

Collected Steps per Second: 22,587.49108
Overall Steps per Second: 10,570.49032

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.51744
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.73185

Cumulative Model Updates: 137,178
Cumulative Timesteps: 1,144,108,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1144108536...
Checkpoint 1144108536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.76963
Policy Entropy: 3.15087
Value Function Loss: 0.00450

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.60346
Value Function Update Magnitude: 0.57444

Collected Steps per Second: 22,261.55533
Overall Steps per Second: 10,625.79769

Timestep Collection Time: 2.24611
Timestep Consumption Time: 2.45960
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.70572

Cumulative Model Updates: 137,184
Cumulative Timesteps: 1,144,158,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.13692
Policy Entropy: 3.15098
Value Function Loss: 0.00423

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.58838
Value Function Update Magnitude: 0.55140

Collected Steps per Second: 22,706.95481
Overall Steps per Second: 10,498.92542

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.56155
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.76449

Cumulative Model Updates: 137,190
Cumulative Timesteps: 1,144,208,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1144208560...
Checkpoint 1144208560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873.61932
Policy Entropy: 3.14609
Value Function Loss: 0.00436

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.58739
Value Function Update Magnitude: 0.54175

Collected Steps per Second: 22,289.07181
Overall Steps per Second: 10,600.94477

Timestep Collection Time: 2.24361
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.71732

Cumulative Model Updates: 137,196
Cumulative Timesteps: 1,144,258,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913.62354
Policy Entropy: 3.15885
Value Function Loss: 0.00421

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.58961
Value Function Update Magnitude: 0.55512

Collected Steps per Second: 22,577.62243
Overall Steps per Second: 10,584.28401

Timestep Collection Time: 2.21547
Timestep Consumption Time: 2.51041
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.72587

Cumulative Model Updates: 137,202
Cumulative Timesteps: 1,144,308,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1144308588...
Checkpoint 1144308588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.16593
Policy Entropy: 3.14052
Value Function Loss: 0.00453

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.59942
Value Function Update Magnitude: 0.56953

Collected Steps per Second: 22,332.98803
Overall Steps per Second: 10,466.85155

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.53855
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.77775

Cumulative Model Updates: 137,208
Cumulative Timesteps: 1,144,358,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.17615
Policy Entropy: 3.14927
Value Function Loss: 0.00432

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.59423
Value Function Update Magnitude: 0.58240

Collected Steps per Second: 22,368.76693
Overall Steps per Second: 10,443.79206

Timestep Collection Time: 2.23651
Timestep Consumption Time: 2.55370
PPO Batch Consumption Time: 0.30227
Total Iteration Time: 4.79021

Cumulative Model Updates: 137,214
Cumulative Timesteps: 1,144,408,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1144408624...
Checkpoint 1144408624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,218.35762
Policy Entropy: 3.15202
Value Function Loss: 0.00434

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.59738
Value Function Update Magnitude: 0.59555

Collected Steps per Second: 22,452.68336
Overall Steps per Second: 10,564.83593

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.50628
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.73363

Cumulative Model Updates: 137,220
Cumulative Timesteps: 1,144,458,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.50479
Policy Entropy: 3.16429
Value Function Loss: 0.00414

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.58682

Collected Steps per Second: 22,372.98241
Overall Steps per Second: 10,600.51377

Timestep Collection Time: 2.23609
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.71939

Cumulative Model Updates: 137,226
Cumulative Timesteps: 1,144,508,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1144508662...
Checkpoint 1144508662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.56533
Policy Entropy: 3.15767
Value Function Loss: 0.00415

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.58670
Value Function Update Magnitude: 0.57039

Collected Steps per Second: 21,899.83427
Overall Steps per Second: 10,499.88903

Timestep Collection Time: 2.28349
Timestep Consumption Time: 2.47923
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.76272

Cumulative Model Updates: 137,232
Cumulative Timesteps: 1,144,558,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.50481
Policy Entropy: 3.15784
Value Function Loss: 0.00427

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.60098
Value Function Update Magnitude: 0.56583

Collected Steps per Second: 22,666.78048
Overall Steps per Second: 10,655.17892

Timestep Collection Time: 2.20719
Timestep Consumption Time: 2.48817
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.69537

Cumulative Model Updates: 137,238
Cumulative Timesteps: 1,144,608,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1144608700...
Checkpoint 1144608700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.36017
Policy Entropy: 3.16096
Value Function Loss: 0.00397

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.59689
Value Function Update Magnitude: 0.58228

Collected Steps per Second: 22,211.54097
Overall Steps per Second: 10,566.98976

Timestep Collection Time: 2.25171
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73304

Cumulative Model Updates: 137,244
Cumulative Timesteps: 1,144,658,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.18180
Policy Entropy: 3.16305
Value Function Loss: 0.00388

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.58798
Value Function Update Magnitude: 0.57845

Collected Steps per Second: 22,827.92787
Overall Steps per Second: 10,627.65992

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.70715

Cumulative Model Updates: 137,250
Cumulative Timesteps: 1,144,708,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1144708740...
Checkpoint 1144708740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.41062
Policy Entropy: 3.15002
Value Function Loss: 0.00404

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.53998

Collected Steps per Second: 22,214.05367
Overall Steps per Second: 10,446.88184

Timestep Collection Time: 2.25200
Timestep Consumption Time: 2.53661
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.78861

Cumulative Model Updates: 137,256
Cumulative Timesteps: 1,144,758,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.08433
Policy Entropy: 3.12615
Value Function Loss: 0.00426

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.59278
Value Function Update Magnitude: 0.54036

Collected Steps per Second: 22,924.64915
Overall Steps per Second: 10,633.52563

Timestep Collection Time: 2.18176
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.70361

Cumulative Model Updates: 137,262
Cumulative Timesteps: 1,144,808,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1144808782...
Checkpoint 1144808782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.62033
Policy Entropy: 3.12168
Value Function Loss: 0.00414

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.58894
Value Function Update Magnitude: 0.54306

Collected Steps per Second: 22,332.57345
Overall Steps per Second: 10,528.10662

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.75109

Cumulative Model Updates: 137,268
Cumulative Timesteps: 1,144,858,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.30654
Policy Entropy: 3.12496
Value Function Loss: 0.00392

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.50923

Collected Steps per Second: 22,710.49880
Overall Steps per Second: 10,623.57483

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.50579
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.70821

Cumulative Model Updates: 137,274
Cumulative Timesteps: 1,144,908,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1144908820...
Checkpoint 1144908820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.68686
Policy Entropy: 3.13991
Value Function Loss: 0.00419

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.59148
Value Function Update Magnitude: 0.51434

Collected Steps per Second: 22,144.81772
Overall Steps per Second: 10,478.01303

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.77190

Cumulative Model Updates: 137,280
Cumulative Timesteps: 1,144,958,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.25715
Policy Entropy: 3.14144
Value Function Loss: 0.00411

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.59890
Value Function Update Magnitude: 0.55221

Collected Steps per Second: 20,109.93194
Overall Steps per Second: 9,994.52134

Timestep Collection Time: 2.48703
Timestep Consumption Time: 2.51711
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 5.00414

Cumulative Model Updates: 137,286
Cumulative Timesteps: 1,145,008,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1145008834...
Checkpoint 1145008834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.46971
Policy Entropy: 3.14402
Value Function Loss: 0.00442

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.59657
Value Function Update Magnitude: 0.56305

Collected Steps per Second: 22,108.51645
Overall Steps per Second: 10,565.12590

Timestep Collection Time: 2.26284
Timestep Consumption Time: 2.47236
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.73520

Cumulative Model Updates: 137,292
Cumulative Timesteps: 1,145,058,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.81757
Policy Entropy: 3.15167
Value Function Loss: 0.00415

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.53017

Collected Steps per Second: 22,588.40537
Overall Steps per Second: 10,563.43526

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.51978
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.73331

Cumulative Model Updates: 137,298
Cumulative Timesteps: 1,145,108,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1145108862...
Checkpoint 1145108862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.74016
Policy Entropy: 3.15025
Value Function Loss: 0.00444

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.59023
Value Function Update Magnitude: 0.50878

Collected Steps per Second: 22,085.62950
Overall Steps per Second: 10,561.74321

Timestep Collection Time: 2.26464
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.73558

Cumulative Model Updates: 137,304
Cumulative Timesteps: 1,145,158,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.24424
Policy Entropy: 3.15537
Value Function Loss: 0.00412

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.59363
Value Function Update Magnitude: 0.51445

Collected Steps per Second: 22,534.35563
Overall Steps per Second: 10,555.43318

Timestep Collection Time: 2.21892
Timestep Consumption Time: 2.51816
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.73709

Cumulative Model Updates: 137,310
Cumulative Timesteps: 1,145,208,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1145208880...
Checkpoint 1145208880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.54058
Policy Entropy: 3.15136
Value Function Loss: 0.00435

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.51581

Collected Steps per Second: 20,260.70913
Overall Steps per Second: 10,067.52389

Timestep Collection Time: 2.46783
Timestep Consumption Time: 2.49863
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.96646

Cumulative Model Updates: 137,316
Cumulative Timesteps: 1,145,258,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,271.99389
Policy Entropy: 3.16662
Value Function Loss: 0.00390

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.57114
Value Function Update Magnitude: 0.52882

Collected Steps per Second: 18,097.10441
Overall Steps per Second: 9,497.81919

Timestep Collection Time: 2.76409
Timestep Consumption Time: 2.50259
PPO Batch Consumption Time: 0.30580
Total Iteration Time: 5.26668

Cumulative Model Updates: 137,322
Cumulative Timesteps: 1,145,308,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1145308902...
Checkpoint 1145308902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 836.66615
Policy Entropy: 3.16761
Value Function Loss: 0.00372

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.49105

Collected Steps per Second: 20,164.88489
Overall Steps per Second: 9,985.51426

Timestep Collection Time: 2.48134
Timestep Consumption Time: 2.52952
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 5.01086

Cumulative Model Updates: 137,328
Cumulative Timesteps: 1,145,358,938

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.90869
Policy Entropy: 3.16665
Value Function Loss: 0.00388

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.56049
Value Function Update Magnitude: 0.47086

Collected Steps per Second: 18,419.92722
Overall Steps per Second: 9,666.27659

Timestep Collection Time: 2.71619
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 5.17593

Cumulative Model Updates: 137,334
Cumulative Timesteps: 1,145,408,970

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1145408970...
Checkpoint 1145408970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.54547
Policy Entropy: 3.15927
Value Function Loss: 0.00431

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.57399
Value Function Update Magnitude: 0.47345

Collected Steps per Second: 21,997.15447
Overall Steps per Second: 10,500.61871

Timestep Collection Time: 2.27402
Timestep Consumption Time: 2.48970
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.76372

Cumulative Model Updates: 137,340
Cumulative Timesteps: 1,145,458,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,138.42725
Policy Entropy: 3.15798
Value Function Loss: 0.00468

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.59089
Value Function Update Magnitude: 0.51201

Collected Steps per Second: 22,211.16079
Overall Steps per Second: 10,368.68434

Timestep Collection Time: 2.25247
Timestep Consumption Time: 2.57263
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.82511

Cumulative Model Updates: 137,346
Cumulative Timesteps: 1,145,509,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1145509022...
Checkpoint 1145509022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.35113
Policy Entropy: 3.15230
Value Function Loss: 0.00498

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.60239
Value Function Update Magnitude: 0.54384

Collected Steps per Second: 22,579.47280
Overall Steps per Second: 10,542.88881

Timestep Collection Time: 2.21582
Timestep Consumption Time: 2.52975
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.74557

Cumulative Model Updates: 137,352
Cumulative Timesteps: 1,145,559,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.57903
Policy Entropy: 3.16606
Value Function Loss: 0.00485

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.60522
Value Function Update Magnitude: 0.56341

Collected Steps per Second: 22,603.27305
Overall Steps per Second: 10,450.50929

Timestep Collection Time: 2.21216
Timestep Consumption Time: 2.57249
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 4.78465

Cumulative Model Updates: 137,358
Cumulative Timesteps: 1,145,609,056

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1145609056...
Checkpoint 1145609056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.99068
Policy Entropy: 3.16966
Value Function Loss: 0.00443

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.59698
Value Function Update Magnitude: 0.56111

Collected Steps per Second: 22,250.47185
Overall Steps per Second: 10,568.91179

Timestep Collection Time: 2.24813
Timestep Consumption Time: 2.48481
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.73294

Cumulative Model Updates: 137,364
Cumulative Timesteps: 1,145,659,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216.32634
Policy Entropy: 3.18708
Value Function Loss: 0.00432

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.53296

Collected Steps per Second: 22,415.96635
Overall Steps per Second: 10,510.88395

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.52662
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.75735

Cumulative Model Updates: 137,370
Cumulative Timesteps: 1,145,709,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1145709082...
Checkpoint 1145709082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,264.00196
Policy Entropy: 3.18445
Value Function Loss: 0.00424

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.56824
Value Function Update Magnitude: 0.52487

Collected Steps per Second: 22,269.76212
Overall Steps per Second: 10,623.47499

Timestep Collection Time: 2.24565
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.70750

Cumulative Model Updates: 137,376
Cumulative Timesteps: 1,145,759,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.43826
Policy Entropy: 3.18197
Value Function Loss: 0.00418

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.56746
Value Function Update Magnitude: 0.54729

Collected Steps per Second: 22,158.92114
Overall Steps per Second: 10,502.00574

Timestep Collection Time: 2.25778
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.76385

Cumulative Model Updates: 137,382
Cumulative Timesteps: 1,145,809,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1145809122...
Checkpoint 1145809122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.63323
Policy Entropy: 3.18031
Value Function Loss: 0.00401

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.57268

Collected Steps per Second: 22,525.13156
Overall Steps per Second: 10,690.42095

Timestep Collection Time: 2.22028
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.67821

Cumulative Model Updates: 137,388
Cumulative Timesteps: 1,145,859,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.19492
Policy Entropy: 3.17003
Value Function Loss: 0.00411

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.57006

Collected Steps per Second: 21,654.82998
Overall Steps per Second: 10,394.26026

Timestep Collection Time: 2.30942
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.81131

Cumulative Model Updates: 137,394
Cumulative Timesteps: 1,145,909,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1145909144...
Checkpoint 1145909144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,147.15071
Policy Entropy: 3.16594
Value Function Loss: 0.00388

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.53606

Collected Steps per Second: 22,006.54715
Overall Steps per Second: 10,547.94535

Timestep Collection Time: 2.27314
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.74253

Cumulative Model Updates: 137,400
Cumulative Timesteps: 1,145,959,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.01071
Policy Entropy: 3.16750
Value Function Loss: 0.00398

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.51347

Collected Steps per Second: 22,167.49642
Overall Steps per Second: 10,566.41851

Timestep Collection Time: 2.25610
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.73311

Cumulative Model Updates: 137,406
Cumulative Timesteps: 1,146,009,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1146009180...
Checkpoint 1146009180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.83164
Policy Entropy: 3.15787
Value Function Loss: 0.00383

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.57215
Value Function Update Magnitude: 0.50874

Collected Steps per Second: 22,216.17193
Overall Steps per Second: 10,517.34951

Timestep Collection Time: 2.25223
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.75747

Cumulative Model Updates: 137,412
Cumulative Timesteps: 1,146,059,216

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,385.76424
Policy Entropy: 3.16466
Value Function Loss: 0.00369

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.49118

Collected Steps per Second: 22,297.24957
Overall Steps per Second: 10,489.07212

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.52595
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.76973

Cumulative Model Updates: 137,418
Cumulative Timesteps: 1,146,109,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1146109246...
Checkpoint 1146109246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.01838
Policy Entropy: 3.16895
Value Function Loss: 0.00406

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.57426
Value Function Update Magnitude: 0.48688

Collected Steps per Second: 22,424.43442
Overall Steps per Second: 10,614.68476

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.71272

Cumulative Model Updates: 137,424
Cumulative Timesteps: 1,146,159,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.54506
Policy Entropy: 3.17322
Value Function Loss: 0.00421

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.51493

Collected Steps per Second: 22,277.97084
Overall Steps per Second: 10,580.80457

Timestep Collection Time: 2.24536
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.72762

Cumulative Model Updates: 137,430
Cumulative Timesteps: 1,146,209,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1146209292...
Checkpoint 1146209292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.16012
Policy Entropy: 3.17911
Value Function Loss: 0.00447

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.58143
Value Function Update Magnitude: 0.52833

Collected Steps per Second: 22,315.41475
Overall Steps per Second: 10,413.74703

Timestep Collection Time: 2.24186
Timestep Consumption Time: 2.56218
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.80403

Cumulative Model Updates: 137,436
Cumulative Timesteps: 1,146,259,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.80959
Policy Entropy: 3.17629
Value Function Loss: 0.00426

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.55023

Collected Steps per Second: 22,486.47825
Overall Steps per Second: 10,534.22822

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.52429
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.74909

Cumulative Model Updates: 137,442
Cumulative Timesteps: 1,146,309,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1146309348...
Checkpoint 1146309348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.00147
Policy Entropy: 3.17824
Value Function Loss: 0.00412

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.57416
Value Function Update Magnitude: 0.54149

Collected Steps per Second: 22,156.18310
Overall Steps per Second: 10,483.83423

Timestep Collection Time: 2.25725
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.77039

Cumulative Model Updates: 137,448
Cumulative Timesteps: 1,146,359,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.08940
Policy Entropy: 3.17898
Value Function Loss: 0.00404

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.51940

Collected Steps per Second: 22,436.33128
Overall Steps per Second: 10,622.68096

Timestep Collection Time: 2.22888
Timestep Consumption Time: 2.47878
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.70766

Cumulative Model Updates: 137,454
Cumulative Timesteps: 1,146,409,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1146409368...
Checkpoint 1146409368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.37757
Policy Entropy: 3.17604
Value Function Loss: 0.00411

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.57435
Value Function Update Magnitude: 0.53095

Collected Steps per Second: 20,557.79943
Overall Steps per Second: 10,116.03652

Timestep Collection Time: 2.43314
Timestep Consumption Time: 2.51148
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.94462

Cumulative Model Updates: 137,460
Cumulative Timesteps: 1,146,459,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.14967
Policy Entropy: 3.17087
Value Function Loss: 0.00392

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.57438
Value Function Update Magnitude: 0.55039

Collected Steps per Second: 22,126.45577
Overall Steps per Second: 10,420.12913

Timestep Collection Time: 2.25992
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.79879

Cumulative Model Updates: 137,466
Cumulative Timesteps: 1,146,509,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1146509392...
Checkpoint 1146509392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.12676
Policy Entropy: 3.16955
Value Function Loss: 0.00410

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.58310
Value Function Update Magnitude: 0.56679

Collected Steps per Second: 21,924.34413
Overall Steps per Second: 10,415.36772

Timestep Collection Time: 2.28084
Timestep Consumption Time: 2.52033
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.80117

Cumulative Model Updates: 137,472
Cumulative Timesteps: 1,146,559,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.00070
Policy Entropy: 3.16212
Value Function Loss: 0.00399

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.58617
Value Function Update Magnitude: 0.56287

Collected Steps per Second: 22,033.26597
Overall Steps per Second: 10,551.04803

Timestep Collection Time: 2.27057
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.74152

Cumulative Model Updates: 137,478
Cumulative Timesteps: 1,146,609,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1146609426...
Checkpoint 1146609426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.66742
Policy Entropy: 3.15545
Value Function Loss: 0.00425

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.59365
Value Function Update Magnitude: 0.57114

Collected Steps per Second: 22,747.69379
Overall Steps per Second: 10,610.39789

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71311

Cumulative Model Updates: 137,484
Cumulative Timesteps: 1,146,659,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,507.74421
Policy Entropy: 3.15979
Value Function Loss: 0.00413

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.59612
Value Function Update Magnitude: 0.55309

Collected Steps per Second: 22,156.04453
Overall Steps per Second: 10,370.13243

Timestep Collection Time: 2.25789
Timestep Consumption Time: 2.56615
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.82405

Cumulative Model Updates: 137,490
Cumulative Timesteps: 1,146,709,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1146709460...
Checkpoint 1146709460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.89178
Policy Entropy: 3.15480
Value Function Loss: 0.00397

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.58950
Value Function Update Magnitude: 0.55623

Collected Steps per Second: 22,250.63069
Overall Steps per Second: 10,556.65641

Timestep Collection Time: 2.24722
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.73654

Cumulative Model Updates: 137,496
Cumulative Timesteps: 1,146,759,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.28184
Policy Entropy: 3.16460
Value Function Loss: 0.00386

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.58442
Value Function Update Magnitude: 0.54440

Collected Steps per Second: 22,418.64078
Overall Steps per Second: 10,605.94249

Timestep Collection Time: 2.23136
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.71660

Cumulative Model Updates: 137,502
Cumulative Timesteps: 1,146,809,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1146809486...
Checkpoint 1146809486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.84800
Policy Entropy: 3.15036
Value Function Loss: 0.00461

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.58698
Value Function Update Magnitude: 0.54395

Collected Steps per Second: 22,712.06234
Overall Steps per Second: 10,649.06614

Timestep Collection Time: 2.20244
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.69731

Cumulative Model Updates: 137,508
Cumulative Timesteps: 1,146,859,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.96284
Policy Entropy: 3.15512
Value Function Loss: 0.00467

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.56586

Collected Steps per Second: 22,627.90309
Overall Steps per Second: 10,289.83883

Timestep Collection Time: 2.21046
Timestep Consumption Time: 2.65046
PPO Batch Consumption Time: 0.31430
Total Iteration Time: 4.86091

Cumulative Model Updates: 137,514
Cumulative Timesteps: 1,146,909,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1146909526...
Checkpoint 1146909526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.69662
Policy Entropy: 3.16339
Value Function Loss: 0.00427

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.57830
Value Function Update Magnitude: 0.53777

Collected Steps per Second: 22,430.63290
Overall Steps per Second: 10,482.72256

Timestep Collection Time: 2.22954
Timestep Consumption Time: 2.54117
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.77071

Cumulative Model Updates: 137,520
Cumulative Timesteps: 1,146,959,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.15959
Policy Entropy: 3.17696
Value Function Loss: 0.00391

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.50816

Collected Steps per Second: 22,307.12470
Overall Steps per Second: 10,637.11652

Timestep Collection Time: 2.24153
Timestep Consumption Time: 2.45918
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.70071

Cumulative Model Updates: 137,526
Cumulative Timesteps: 1,147,009,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1147009538...
Checkpoint 1147009538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,741.91816
Policy Entropy: 3.17764
Value Function Loss: 0.00370

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.48872

Collected Steps per Second: 22,088.78272
Overall Steps per Second: 10,382.47953

Timestep Collection Time: 2.26386
Timestep Consumption Time: 2.55252
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.81638

Cumulative Model Updates: 137,532
Cumulative Timesteps: 1,147,059,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.61236
Policy Entropy: 3.16636
Value Function Loss: 0.00363

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.47719

Collected Steps per Second: 21,570.66018
Overall Steps per Second: 10,403.09410

Timestep Collection Time: 2.31815
Timestep Consumption Time: 2.48850
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.80665

Cumulative Model Updates: 137,538
Cumulative Timesteps: 1,147,109,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1147109548...
Checkpoint 1147109548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.54369
Policy Entropy: 3.16376
Value Function Loss: 0.00346

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.47176

Collected Steps per Second: 21,826.57363
Overall Steps per Second: 10,355.01779

Timestep Collection Time: 2.29115
Timestep Consumption Time: 2.53820
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.82935

Cumulative Model Updates: 137,544
Cumulative Timesteps: 1,147,159,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.49183
Policy Entropy: 3.17095
Value Function Loss: 0.00364

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.55635
Value Function Update Magnitude: 0.47284

Collected Steps per Second: 22,213.55520
Overall Steps per Second: 10,437.15758

Timestep Collection Time: 2.25196
Timestep Consumption Time: 2.54092
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.79288

Cumulative Model Updates: 137,550
Cumulative Timesteps: 1,147,209,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1147209580...
Checkpoint 1147209580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.92612
Policy Entropy: 3.17708
Value Function Loss: 0.00360

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.50309

Collected Steps per Second: 21,341.78084
Overall Steps per Second: 10,412.64650

Timestep Collection Time: 2.34357
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.80339

Cumulative Model Updates: 137,556
Cumulative Timesteps: 1,147,259,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,556.48930
Policy Entropy: 3.18908
Value Function Loss: 0.00408

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.56450
Value Function Update Magnitude: 0.56709

Collected Steps per Second: 22,251.31257
Overall Steps per Second: 10,539.99284

Timestep Collection Time: 2.24733
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.74441

Cumulative Model Updates: 137,562
Cumulative Timesteps: 1,147,309,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1147309602...
Checkpoint 1147309602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.87914
Policy Entropy: 3.19830
Value Function Loss: 0.00428

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.55413

Collected Steps per Second: 22,446.25381
Overall Steps per Second: 10,613.52081

Timestep Collection Time: 2.22763
Timestep Consumption Time: 2.48353
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.71116

Cumulative Model Updates: 137,568
Cumulative Timesteps: 1,147,359,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.04787
Policy Entropy: 3.19133
Value Function Loss: 0.00451

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.57549
Value Function Update Magnitude: 0.56522

Collected Steps per Second: 22,538.35573
Overall Steps per Second: 10,511.46833

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.53949
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.75899

Cumulative Model Updates: 137,574
Cumulative Timesteps: 1,147,409,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1147409628...
Checkpoint 1147409628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.99801
Policy Entropy: 3.18079
Value Function Loss: 0.00417

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.57009
Value Function Update Magnitude: 0.54802

Collected Steps per Second: 22,369.06189
Overall Steps per Second: 10,621.08349

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.47367
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.71007

Cumulative Model Updates: 137,580
Cumulative Timesteps: 1,147,459,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100.75329
Policy Entropy: 3.18693
Value Function Loss: 0.00355

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.55710
Value Function Update Magnitude: 0.49398

Collected Steps per Second: 22,334.41466
Overall Steps per Second: 10,419.82267

Timestep Collection Time: 2.23986
Timestep Consumption Time: 2.56118
PPO Batch Consumption Time: 0.29941
Total Iteration Time: 4.80104

Cumulative Model Updates: 137,586
Cumulative Timesteps: 1,147,509,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1147509680...
Checkpoint 1147509680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,293.29618
Policy Entropy: 3.19439
Value Function Loss: 0.00340

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.45957

Collected Steps per Second: 22,245.65899
Overall Steps per Second: 10,436.59223

Timestep Collection Time: 2.24889
Timestep Consumption Time: 2.54463
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.79352

Cumulative Model Updates: 137,592
Cumulative Timesteps: 1,147,559,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.39289
Policy Entropy: 3.18854
Value Function Loss: 0.00364

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.47267

Collected Steps per Second: 22,705.58118
Overall Steps per Second: 10,621.84209

Timestep Collection Time: 2.20237
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.70785

Cumulative Model Updates: 137,598
Cumulative Timesteps: 1,147,609,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1147609714...
Checkpoint 1147609714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.54013
Policy Entropy: 3.16284
Value Function Loss: 0.00357

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.56469
Value Function Update Magnitude: 0.47324

Collected Steps per Second: 22,251.67604
Overall Steps per Second: 10,609.53818

Timestep Collection Time: 2.24819
Timestep Consumption Time: 2.46700
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.71519

Cumulative Model Updates: 137,604
Cumulative Timesteps: 1,147,659,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,115.23877
Policy Entropy: 3.15076
Value Function Loss: 0.00371

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.56499
Value Function Update Magnitude: 0.47146

Collected Steps per Second: 21,637.25720
Overall Steps per Second: 10,368.23486

Timestep Collection Time: 2.31157
Timestep Consumption Time: 2.51240
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.82396

Cumulative Model Updates: 137,610
Cumulative Timesteps: 1,147,709,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1147709756...
Checkpoint 1147709756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.63793
Policy Entropy: 3.14613
Value Function Loss: 0.00412

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.57971
Value Function Update Magnitude: 0.48136

Collected Steps per Second: 21,965.47611
Overall Steps per Second: 10,353.23274

Timestep Collection Time: 2.27648
Timestep Consumption Time: 2.55331
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.82980

Cumulative Model Updates: 137,616
Cumulative Timesteps: 1,147,759,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875.84074
Policy Entropy: 3.16171
Value Function Loss: 0.00478

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.49696

Collected Steps per Second: 22,247.97433
Overall Steps per Second: 10,484.13702

Timestep Collection Time: 2.24776
Timestep Consumption Time: 2.52212
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.76987

Cumulative Model Updates: 137,622
Cumulative Timesteps: 1,147,809,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1147809768...
Checkpoint 1147809768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.78531
Policy Entropy: 3.16319
Value Function Loss: 0.00477

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.58115
Value Function Update Magnitude: 0.50621

Collected Steps per Second: 21,707.45373
Overall Steps per Second: 10,311.58400

Timestep Collection Time: 2.30474
Timestep Consumption Time: 2.54709
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.85182

Cumulative Model Updates: 137,628
Cumulative Timesteps: 1,147,859,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,761.99304
Policy Entropy: 3.16411
Value Function Loss: 0.00438

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.58674
Value Function Update Magnitude: 0.52028

Collected Steps per Second: 22,985.99367
Overall Steps per Second: 10,728.47071

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.48735
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.66441

Cumulative Model Updates: 137,634
Cumulative Timesteps: 1,147,909,840

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1147909840...
Checkpoint 1147909840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,667.39982
Policy Entropy: 3.16838
Value Function Loss: 0.00395

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.51361

Collected Steps per Second: 21,874.02340
Overall Steps per Second: 10,336.14250

Timestep Collection Time: 2.28600
Timestep Consumption Time: 2.55178
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.83778

Cumulative Model Updates: 137,640
Cumulative Timesteps: 1,147,959,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040.44249
Policy Entropy: 3.16536
Value Function Loss: 0.00395

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.59013
Value Function Update Magnitude: 0.49753

Collected Steps per Second: 22,514.00612
Overall Steps per Second: 10,445.89058

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.56737
PPO Batch Consumption Time: 0.30049
Total Iteration Time: 4.78963

Cumulative Model Updates: 137,646
Cumulative Timesteps: 1,148,009,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1148009876...
Checkpoint 1148009876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.66629
Policy Entropy: 3.17617
Value Function Loss: 0.00404

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.48900

Collected Steps per Second: 21,488.59944
Overall Steps per Second: 10,628.32535

Timestep Collection Time: 2.32719
Timestep Consumption Time: 2.37798
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.70516

Cumulative Model Updates: 137,652
Cumulative Timesteps: 1,148,059,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.57482
Policy Entropy: 3.17039
Value Function Loss: 0.00403

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.57905
Value Function Update Magnitude: 0.48998

Collected Steps per Second: 22,414.28106
Overall Steps per Second: 10,418.95659

Timestep Collection Time: 2.23206
Timestep Consumption Time: 2.56977
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.80182

Cumulative Model Updates: 137,658
Cumulative Timesteps: 1,148,109,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1148109914...
Checkpoint 1148109914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.64244
Policy Entropy: 3.17696
Value Function Loss: 0.00404

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.58010
Value Function Update Magnitude: 0.51452

Collected Steps per Second: 22,270.66373
Overall Steps per Second: 10,655.22974

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.69403

Cumulative Model Updates: 137,664
Cumulative Timesteps: 1,148,159,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,972.39513
Policy Entropy: 3.18052
Value Function Loss: 0.00382

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.58555
Value Function Update Magnitude: 0.51940

Collected Steps per Second: 22,211.76265
Overall Steps per Second: 10,505.64907

Timestep Collection Time: 2.25142
Timestep Consumption Time: 2.50869
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.76011

Cumulative Model Updates: 137,670
Cumulative Timesteps: 1,148,209,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1148209938...
Checkpoint 1148209938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.98255
Policy Entropy: 3.16880
Value Function Loss: 0.00426

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.60444
Value Function Update Magnitude: 0.52926

Collected Steps per Second: 21,936.34180
Overall Steps per Second: 10,477.57647

Timestep Collection Time: 2.28005
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.77362

Cumulative Model Updates: 137,676
Cumulative Timesteps: 1,148,259,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,623.86948
Policy Entropy: 3.16038
Value Function Loss: 0.00411

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.59797
Value Function Update Magnitude: 0.55112

Collected Steps per Second: 21,985.51768
Overall Steps per Second: 10,611.54664

Timestep Collection Time: 2.27559
Timestep Consumption Time: 2.43909
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.71468

Cumulative Model Updates: 137,682
Cumulative Timesteps: 1,148,309,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1148309984...
Checkpoint 1148309984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,324.06600
Policy Entropy: 3.17135
Value Function Loss: 0.00412

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.59274
Value Function Update Magnitude: 0.54476

Collected Steps per Second: 21,433.55433
Overall Steps per Second: 10,335.87373

Timestep Collection Time: 2.33298
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.83791

Cumulative Model Updates: 137,688
Cumulative Timesteps: 1,148,359,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.73444
Policy Entropy: 3.18067
Value Function Loss: 0.00392

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.58876
Value Function Update Magnitude: 0.56643

Collected Steps per Second: 22,504.14533
Overall Steps per Second: 10,677.41067

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.68335

Cumulative Model Updates: 137,694
Cumulative Timesteps: 1,148,409,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1148409994...
Checkpoint 1148409994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.79321
Policy Entropy: 3.18375
Value Function Loss: 0.00405

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.58617
Value Function Update Magnitude: 0.55596

Collected Steps per Second: 21,724.63798
Overall Steps per Second: 10,436.15087

Timestep Collection Time: 2.30255
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.79315

Cumulative Model Updates: 137,700
Cumulative Timesteps: 1,148,460,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,959.53818
Policy Entropy: 3.18255
Value Function Loss: 0.00396

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.53961

Collected Steps per Second: 22,546.72435
Overall Steps per Second: 10,595.14457

Timestep Collection Time: 2.21886
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.72179

Cumulative Model Updates: 137,706
Cumulative Timesteps: 1,148,510,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1148510044...
Checkpoint 1148510044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.19650
Policy Entropy: 3.16899
Value Function Loss: 0.00434

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.58441
Value Function Update Magnitude: 0.53338

Collected Steps per Second: 22,345.17873
Overall Steps per Second: 10,364.05607

Timestep Collection Time: 2.23842
Timestep Consumption Time: 2.58768
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.82610

Cumulative Model Updates: 137,712
Cumulative Timesteps: 1,148,560,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.94063
Policy Entropy: 3.16965
Value Function Loss: 0.00423

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.58794
Value Function Update Magnitude: 0.51098

Collected Steps per Second: 22,779.61375
Overall Steps per Second: 10,489.34664

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.57324
PPO Batch Consumption Time: 0.29856
Total Iteration Time: 4.76941

Cumulative Model Updates: 137,718
Cumulative Timesteps: 1,148,610,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1148610090...
Checkpoint 1148610090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.89986
Policy Entropy: 3.16899
Value Function Loss: 0.00438

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.58907
Value Function Update Magnitude: 0.50629

Collected Steps per Second: 22,420.57698
Overall Steps per Second: 10,570.04429

Timestep Collection Time: 2.23108
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.73243

Cumulative Model Updates: 137,724
Cumulative Timesteps: 1,148,660,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,839.40005
Policy Entropy: 3.18835
Value Function Loss: 0.00421

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.58657
Value Function Update Magnitude: 0.53568

Collected Steps per Second: 22,664.73835
Overall Steps per Second: 10,603.02000

Timestep Collection Time: 2.20704
Timestep Consumption Time: 2.51067
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.71771

Cumulative Model Updates: 137,730
Cumulative Timesteps: 1,148,710,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1148710134...
Checkpoint 1148710134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.80725
Policy Entropy: 3.18151
Value Function Loss: 0.00394

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.54425

Collected Steps per Second: 22,635.54291
Overall Steps per Second: 10,588.00817

Timestep Collection Time: 2.20918
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.72289

Cumulative Model Updates: 137,736
Cumulative Timesteps: 1,148,760,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776.14580
Policy Entropy: 3.18341
Value Function Loss: 0.00423

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.58173
Value Function Update Magnitude: 0.54023

Collected Steps per Second: 22,571.95057
Overall Steps per Second: 10,605.05485

Timestep Collection Time: 2.21602
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.71662

Cumulative Model Updates: 137,742
Cumulative Timesteps: 1,148,810,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1148810160...
Checkpoint 1148810160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680.74850
Policy Entropy: 3.17523
Value Function Loss: 0.00444

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.59291
Value Function Update Magnitude: 0.53246

Collected Steps per Second: 22,143.65036
Overall Steps per Second: 10,495.30946

Timestep Collection Time: 2.25925
Timestep Consumption Time: 2.50745
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.76670

Cumulative Model Updates: 137,748
Cumulative Timesteps: 1,148,860,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,057.51557
Policy Entropy: 3.18069
Value Function Loss: 0.00423

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.59812
Value Function Update Magnitude: 0.54862

Collected Steps per Second: 22,527.78278
Overall Steps per Second: 10,504.87405

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.54133
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.76179

Cumulative Model Updates: 137,754
Cumulative Timesteps: 1,148,910,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1148910210...
Checkpoint 1148910210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.66117
Policy Entropy: 3.18237
Value Function Loss: 0.00397

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.54473

Collected Steps per Second: 21,772.52492
Overall Steps per Second: 10,452.23998

Timestep Collection Time: 2.29666
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.78405

Cumulative Model Updates: 137,760
Cumulative Timesteps: 1,148,960,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.35760
Policy Entropy: 3.17507
Value Function Loss: 0.00386

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.59459
Value Function Update Magnitude: 0.51619

Collected Steps per Second: 22,438.09435
Overall Steps per Second: 10,497.23675

Timestep Collection Time: 2.22880
Timestep Consumption Time: 2.53531
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.76411

Cumulative Model Updates: 137,766
Cumulative Timesteps: 1,149,010,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1149010224...
Checkpoint 1149010224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.71659
Policy Entropy: 3.17555
Value Function Loss: 0.00420

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.59846
Value Function Update Magnitude: 0.54006

Collected Steps per Second: 20,250.69732
Overall Steps per Second: 10,151.25512

Timestep Collection Time: 2.47004
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.92747

Cumulative Model Updates: 137,772
Cumulative Timesteps: 1,149,060,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.20750
Policy Entropy: 3.18088
Value Function Loss: 0.00415

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.59598
Value Function Update Magnitude: 0.52543

Collected Steps per Second: 22,151.59634
Overall Steps per Second: 10,524.11861

Timestep Collection Time: 2.25835
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.75346

Cumulative Model Updates: 137,778
Cumulative Timesteps: 1,149,110,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1149110270...
Checkpoint 1149110270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.86571
Policy Entropy: 3.18282
Value Function Loss: 0.00403

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.58790
Value Function Update Magnitude: 0.52740

Collected Steps per Second: 22,210.20100
Overall Steps per Second: 10,368.70413

Timestep Collection Time: 2.25176
Timestep Consumption Time: 2.57160
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.82336

Cumulative Model Updates: 137,784
Cumulative Timesteps: 1,149,160,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.32867
Policy Entropy: 3.18045
Value Function Loss: 0.00405

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.58308
Value Function Update Magnitude: 0.54455

Collected Steps per Second: 22,605.96779
Overall Steps per Second: 10,642.09559

Timestep Collection Time: 2.21189
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.69851

Cumulative Model Updates: 137,790
Cumulative Timesteps: 1,149,210,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1149210284...
Checkpoint 1149210284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.56074
Policy Entropy: 3.17690
Value Function Loss: 0.00405

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.58518
Value Function Update Magnitude: 0.57435

Collected Steps per Second: 22,303.73394
Overall Steps per Second: 10,474.67257

Timestep Collection Time: 2.24178
Timestep Consumption Time: 2.53164
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.77342

Cumulative Model Updates: 137,796
Cumulative Timesteps: 1,149,260,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.10540
Policy Entropy: 3.17397
Value Function Loss: 0.00402

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.58517
Value Function Update Magnitude: 0.54703

Collected Steps per Second: 22,912.29228
Overall Steps per Second: 10,725.87486

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.47969
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.66218

Cumulative Model Updates: 137,802
Cumulative Timesteps: 1,149,310,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1149310290...
Checkpoint 1149310290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.94221
Policy Entropy: 3.18516
Value Function Loss: 0.00424

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.57689
Value Function Update Magnitude: 0.53464

Collected Steps per Second: 22,241.11100
Overall Steps per Second: 10,571.38601

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73107

Cumulative Model Updates: 137,808
Cumulative Timesteps: 1,149,360,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.83386
Policy Entropy: 3.18176
Value Function Loss: 0.00413

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.57755
Value Function Update Magnitude: 0.53098

Collected Steps per Second: 22,699.31439
Overall Steps per Second: 10,500.91684

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.55878
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.76149

Cumulative Model Updates: 137,814
Cumulative Timesteps: 1,149,410,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1149410304...
Checkpoint 1149410304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.71111
Policy Entropy: 3.16979
Value Function Loss: 0.00377

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.57138
Value Function Update Magnitude: 0.51860

Collected Steps per Second: 22,268.33441
Overall Steps per Second: 10,421.26551

Timestep Collection Time: 2.24660
Timestep Consumption Time: 2.55397
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.80057

Cumulative Model Updates: 137,820
Cumulative Timesteps: 1,149,460,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.04863
Policy Entropy: 3.15296
Value Function Loss: 0.00399

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.58297
Value Function Update Magnitude: 0.52101

Collected Steps per Second: 21,748.00752
Overall Steps per Second: 10,384.89524

Timestep Collection Time: 2.29952
Timestep Consumption Time: 2.51613
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.81565

Cumulative Model Updates: 137,826
Cumulative Timesteps: 1,149,510,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1149510342...
Checkpoint 1149510342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.07504
Policy Entropy: 3.16160
Value Function Loss: 0.00381

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.58900
Value Function Update Magnitude: 0.52868

Collected Steps per Second: 22,229.52954
Overall Steps per Second: 10,537.70709

Timestep Collection Time: 2.24980
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.74600

Cumulative Model Updates: 137,832
Cumulative Timesteps: 1,149,560,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,133.18251
Policy Entropy: 3.16085
Value Function Loss: 0.00396

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.52996

Collected Steps per Second: 21,937.45811
Overall Steps per Second: 10,362.97028

Timestep Collection Time: 2.27930
Timestep Consumption Time: 2.54577
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.82506

Cumulative Model Updates: 137,838
Cumulative Timesteps: 1,149,610,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1149610356...
Checkpoint 1149610356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.27425
Policy Entropy: 3.14895
Value Function Loss: 0.00377

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.58773
Value Function Update Magnitude: 0.51766

Collected Steps per Second: 22,177.76183
Overall Steps per Second: 10,577.17412

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.72754

Cumulative Model Updates: 137,844
Cumulative Timesteps: 1,149,660,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.11771
Policy Entropy: 3.13799
Value Function Loss: 0.00412

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.58900
Value Function Update Magnitude: 0.51078

Collected Steps per Second: 22,613.25272
Overall Steps per Second: 10,555.70196

Timestep Collection Time: 2.21233
Timestep Consumption Time: 2.52710
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.73943

Cumulative Model Updates: 137,850
Cumulative Timesteps: 1,149,710,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1149710388...
Checkpoint 1149710388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.58445
Policy Entropy: 3.15656
Value Function Loss: 0.00380

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.51366

Collected Steps per Second: 22,729.70761
Overall Steps per Second: 10,506.65279

Timestep Collection Time: 2.20003
Timestep Consumption Time: 2.55943
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.75946

Cumulative Model Updates: 137,856
Cumulative Timesteps: 1,149,760,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,925.37186
Policy Entropy: 3.15983
Value Function Loss: 0.00389

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.57507
Value Function Update Magnitude: 0.50060

Collected Steps per Second: 22,260.30133
Overall Steps per Second: 10,644.92048

Timestep Collection Time: 2.24696
Timestep Consumption Time: 2.45181
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.69877

Cumulative Model Updates: 137,862
Cumulative Timesteps: 1,149,810,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1149810412...
Checkpoint 1149810412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.45991
Policy Entropy: 3.14638
Value Function Loss: 0.00389

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.57531
Value Function Update Magnitude: 0.48192

Collected Steps per Second: 22,351.09539
Overall Steps per Second: 10,611.19972

Timestep Collection Time: 2.23810
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.71426

Cumulative Model Updates: 137,868
Cumulative Timesteps: 1,149,860,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.03292
Policy Entropy: 3.13357
Value Function Loss: 0.00423

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.49046

Collected Steps per Second: 22,482.46011
Overall Steps per Second: 10,442.03509

Timestep Collection Time: 2.22440
Timestep Consumption Time: 2.56490
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.78930

Cumulative Model Updates: 137,874
Cumulative Timesteps: 1,149,910,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1149910446...
Checkpoint 1149910446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.09582
Policy Entropy: 3.15455
Value Function Loss: 0.00408

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.59955
Value Function Update Magnitude: 0.50418

Collected Steps per Second: 22,517.16336
Overall Steps per Second: 10,629.23422

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.48457
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.70608

Cumulative Model Updates: 137,880
Cumulative Timesteps: 1,149,960,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.83384
Policy Entropy: 3.16479
Value Function Loss: 0.00461

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.60119
Value Function Update Magnitude: 0.51906

Collected Steps per Second: 22,380.60475
Overall Steps per Second: 10,480.09080

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.53840
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 4.77381

Cumulative Model Updates: 137,886
Cumulative Timesteps: 1,150,010,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1150010498...
Checkpoint 1150010498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.61835
Policy Entropy: 3.18219
Value Function Loss: 0.00434

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.54123

Collected Steps per Second: 21,925.60065
Overall Steps per Second: 10,618.24504

Timestep Collection Time: 2.28181
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.71170

Cumulative Model Updates: 137,892
Cumulative Timesteps: 1,150,060,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.17020
Policy Entropy: 3.18369
Value Function Loss: 0.00429

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.58760
Value Function Update Magnitude: 0.52447

Collected Steps per Second: 21,962.40258
Overall Steps per Second: 10,332.18598

Timestep Collection Time: 2.27753
Timestep Consumption Time: 2.56365
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.84118

Cumulative Model Updates: 137,898
Cumulative Timesteps: 1,150,110,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1150110548...
Checkpoint 1150110548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.59025
Policy Entropy: 3.19331
Value Function Loss: 0.00380

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.58260
Value Function Update Magnitude: 0.51154

Collected Steps per Second: 22,314.48337
Overall Steps per Second: 10,532.84601

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.74990

Cumulative Model Updates: 137,904
Cumulative Timesteps: 1,150,160,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.98301
Policy Entropy: 3.17477
Value Function Loss: 0.00386

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.58150
Value Function Update Magnitude: 0.50241

Collected Steps per Second: 21,939.18763
Overall Steps per Second: 10,414.56500

Timestep Collection Time: 2.27939
Timestep Consumption Time: 2.52235
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.80174

Cumulative Model Updates: 137,910
Cumulative Timesteps: 1,150,210,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1150210586...
Checkpoint 1150210586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.06422
Policy Entropy: 3.15897
Value Function Loss: 0.00420

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.59334
Value Function Update Magnitude: 0.51740

Collected Steps per Second: 21,811.03434
Overall Steps per Second: 10,543.08966

Timestep Collection Time: 2.29370
Timestep Consumption Time: 2.45140
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.74510

Cumulative Model Updates: 137,916
Cumulative Timesteps: 1,150,260,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.16341
Policy Entropy: 3.15250
Value Function Loss: 0.00428

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.59740
Value Function Update Magnitude: 0.53802

Collected Steps per Second: 22,203.22651
Overall Steps per Second: 10,425.91838

Timestep Collection Time: 2.25256
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.79708

Cumulative Model Updates: 137,922
Cumulative Timesteps: 1,150,310,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1150310628...
Checkpoint 1150310628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.11242
Policy Entropy: 3.15341
Value Function Loss: 0.00474

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.60870
Value Function Update Magnitude: 0.57177

Collected Steps per Second: 22,188.76002
Overall Steps per Second: 10,373.37448

Timestep Collection Time: 2.25375
Timestep Consumption Time: 2.56705
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.82080

Cumulative Model Updates: 137,928
Cumulative Timesteps: 1,150,360,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.58453
Policy Entropy: 3.14592
Value Function Loss: 0.00448

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.60625
Value Function Update Magnitude: 0.62244

Collected Steps per Second: 22,475.92456
Overall Steps per Second: 10,692.00671

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.45296
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.67864

Cumulative Model Updates: 137,934
Cumulative Timesteps: 1,150,410,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1150410660...
Checkpoint 1150410660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.82028
Policy Entropy: 3.14461
Value Function Loss: 0.00445

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.61000
Value Function Update Magnitude: 0.62506

Collected Steps per Second: 22,235.58574
Overall Steps per Second: 10,654.52878

Timestep Collection Time: 2.24991
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.69547

Cumulative Model Updates: 137,940
Cumulative Timesteps: 1,150,460,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,519.52938
Policy Entropy: 3.16086
Value Function Loss: 0.00388

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.59782
Value Function Update Magnitude: 0.57881

Collected Steps per Second: 22,601.56197
Overall Steps per Second: 10,462.85411

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.56740
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.78034

Cumulative Model Updates: 137,946
Cumulative Timesteps: 1,150,510,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1150510704...
Checkpoint 1150510704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.83681
Policy Entropy: 3.17653
Value Function Loss: 0.00428

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.59996
Value Function Update Magnitude: 0.55376

Collected Steps per Second: 22,704.25514
Overall Steps per Second: 10,645.71462

Timestep Collection Time: 2.20355
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.69954

Cumulative Model Updates: 137,952
Cumulative Timesteps: 1,150,560,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.95462
Policy Entropy: 3.18111
Value Function Loss: 0.00423

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.59662
Value Function Update Magnitude: 0.56175

Collected Steps per Second: 22,452.50998
Overall Steps per Second: 10,497.05232

Timestep Collection Time: 2.22737
Timestep Consumption Time: 2.53683
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.76419

Cumulative Model Updates: 137,958
Cumulative Timesteps: 1,150,610,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1150610744...
Checkpoint 1150610744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,623.47225
Policy Entropy: 3.16489
Value Function Loss: 0.00426

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.59103
Value Function Update Magnitude: 0.58003

Collected Steps per Second: 22,479.39707
Overall Steps per Second: 10,624.26779

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.70903

Cumulative Model Updates: 137,964
Cumulative Timesteps: 1,150,660,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,503.83009
Policy Entropy: 3.16405
Value Function Loss: 0.00404

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.58693
Value Function Update Magnitude: 0.57847

Collected Steps per Second: 21,999.72793
Overall Steps per Second: 10,425.06534

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.79652

Cumulative Model Updates: 137,970
Cumulative Timesteps: 1,150,710,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1150710778...
Checkpoint 1150710778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.92783
Policy Entropy: 3.16487
Value Function Loss: 0.00428

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.59784
Value Function Update Magnitude: 0.57713

Collected Steps per Second: 21,717.10815
Overall Steps per Second: 10,418.16518

Timestep Collection Time: 2.30261
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.79989

Cumulative Model Updates: 137,976
Cumulative Timesteps: 1,150,760,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.74588
Policy Entropy: 3.17383
Value Function Loss: 0.00414

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.60323
Value Function Update Magnitude: 0.55172

Collected Steps per Second: 21,918.30588
Overall Steps per Second: 10,368.87925

Timestep Collection Time: 2.28138
Timestep Consumption Time: 2.54113
PPO Batch Consumption Time: 0.29943
Total Iteration Time: 4.82251

Cumulative Model Updates: 137,982
Cumulative Timesteps: 1,150,810,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1150810788...
Checkpoint 1150810788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.15625
Policy Entropy: 3.18786
Value Function Loss: 0.00413

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.59121
Value Function Update Magnitude: 0.53258

Collected Steps per Second: 21,907.96352
Overall Steps per Second: 10,442.77112

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.50703
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.79049

Cumulative Model Updates: 137,988
Cumulative Timesteps: 1,150,860,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.10414
Policy Entropy: 3.18326
Value Function Loss: 0.00393

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.57979
Value Function Update Magnitude: 0.52360

Collected Steps per Second: 22,491.59882
Overall Steps per Second: 10,585.42108

Timestep Collection Time: 2.22314
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.72367

Cumulative Model Updates: 137,994
Cumulative Timesteps: 1,150,910,816

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1150910816...
Checkpoint 1150910816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,447.26615
Policy Entropy: 3.18217
Value Function Loss: 0.00376

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.51206

Collected Steps per Second: 21,855.49319
Overall Steps per Second: 10,430.70127

Timestep Collection Time: 2.28894
Timestep Consumption Time: 2.50709
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.79603

Cumulative Model Updates: 138,000
Cumulative Timesteps: 1,150,960,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.42210
Policy Entropy: 3.16847
Value Function Loss: 0.00370

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.50314

Collected Steps per Second: 22,408.41092
Overall Steps per Second: 10,655.81608

Timestep Collection Time: 2.23211
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.69396

Cumulative Model Updates: 138,006
Cumulative Timesteps: 1,151,010,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1151010860...
Checkpoint 1151010860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.46001
Policy Entropy: 3.16680
Value Function Loss: 0.00404

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.58594
Value Function Update Magnitude: 0.49616

Collected Steps per Second: 22,431.82510
Overall Steps per Second: 10,624.63621

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.47806
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.70793

Cumulative Model Updates: 138,012
Cumulative Timesteps: 1,151,060,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,446.58592
Policy Entropy: 3.15769
Value Function Loss: 0.00423

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.59087
Value Function Update Magnitude: 0.51411

Collected Steps per Second: 22,800.30597
Overall Steps per Second: 10,551.18640

Timestep Collection Time: 2.19330
Timestep Consumption Time: 2.54626
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.73956

Cumulative Model Updates: 138,018
Cumulative Timesteps: 1,151,110,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1151110888...
Checkpoint 1151110888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.84350
Policy Entropy: 3.16502
Value Function Loss: 0.00443

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.59537
Value Function Update Magnitude: 0.52510

Collected Steps per Second: 22,351.01854
Overall Steps per Second: 10,542.06434

Timestep Collection Time: 2.23712
Timestep Consumption Time: 2.50597
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.74309

Cumulative Model Updates: 138,024
Cumulative Timesteps: 1,151,160,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,936.52548
Policy Entropy: 3.16533
Value Function Loss: 0.00426

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.52706

Collected Steps per Second: 22,444.51320
Overall Steps per Second: 10,552.69742

Timestep Collection Time: 2.22825
Timestep Consumption Time: 2.51101
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.73926

Cumulative Model Updates: 138,030
Cumulative Timesteps: 1,151,210,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1151210902...
Checkpoint 1151210902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.36380
Policy Entropy: 3.15422
Value Function Loss: 0.00411

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.53019

Collected Steps per Second: 22,318.98491
Overall Steps per Second: 10,532.91320

Timestep Collection Time: 2.24159
Timestep Consumption Time: 2.50828
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.74987

Cumulative Model Updates: 138,036
Cumulative Timesteps: 1,151,260,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,684.20641
Policy Entropy: 3.15408
Value Function Loss: 0.00419

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.59272
Value Function Update Magnitude: 0.53495

Collected Steps per Second: 21,963.25142
Overall Steps per Second: 10,433.50195

Timestep Collection Time: 2.27762
Timestep Consumption Time: 2.51693
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.79456

Cumulative Model Updates: 138,042
Cumulative Timesteps: 1,151,310,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1151310956...
Checkpoint 1151310956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.82091
Policy Entropy: 3.14938
Value Function Loss: 0.00437

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.59291
Value Function Update Magnitude: 0.53802

Collected Steps per Second: 22,312.06746
Overall Steps per Second: 10,558.00670

Timestep Collection Time: 2.24094
Timestep Consumption Time: 2.49480
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.73574

Cumulative Model Updates: 138,048
Cumulative Timesteps: 1,151,360,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.67460
Policy Entropy: 3.14252
Value Function Loss: 0.00457

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.59130
Value Function Update Magnitude: 0.53360

Collected Steps per Second: 21,744.96187
Overall Steps per Second: 10,481.26884

Timestep Collection Time: 2.29938
Timestep Consumption Time: 2.47103
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.77041

Cumulative Model Updates: 138,054
Cumulative Timesteps: 1,151,410,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1151410956...
Checkpoint 1151410956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.94144
Policy Entropy: 3.14671
Value Function Loss: 0.00431

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.59016
Value Function Update Magnitude: 0.53000

Collected Steps per Second: 21,590.68840
Overall Steps per Second: 10,193.66039

Timestep Collection Time: 2.31711
Timestep Consumption Time: 2.59065
PPO Batch Consumption Time: 0.31105
Total Iteration Time: 4.90776

Cumulative Model Updates: 138,060
Cumulative Timesteps: 1,151,460,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.53770
Policy Entropy: 3.14602
Value Function Loss: 0.00434

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.58988
Value Function Update Magnitude: 0.51046

Collected Steps per Second: 21,733.78448
Overall Steps per Second: 10,519.38955

Timestep Collection Time: 2.30121
Timestep Consumption Time: 2.45325
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.75446

Cumulative Model Updates: 138,066
Cumulative Timesteps: 1,151,510,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1151510998...
Checkpoint 1151510998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.66504
Policy Entropy: 3.15202
Value Function Loss: 0.00419

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.58249
Value Function Update Magnitude: 0.49939

Collected Steps per Second: 22,529.11531
Overall Steps per Second: 10,557.66532

Timestep Collection Time: 2.21953
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.73627

Cumulative Model Updates: 138,072
Cumulative Timesteps: 1,151,561,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.31833
Policy Entropy: 3.14287
Value Function Loss: 0.00410

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.57755
Value Function Update Magnitude: 0.50721

Collected Steps per Second: 22,763.30171
Overall Steps per Second: 10,552.11712

Timestep Collection Time: 2.19722
Timestep Consumption Time: 2.54268
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.73990

Cumulative Model Updates: 138,078
Cumulative Timesteps: 1,151,611,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1151611018...
Checkpoint 1151611018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.75819
Policy Entropy: 3.13950
Value Function Loss: 0.00394

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.50629

Collected Steps per Second: 22,332.27750
Overall Steps per Second: 10,719.14419

Timestep Collection Time: 2.23936
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.66548

Cumulative Model Updates: 138,084
Cumulative Timesteps: 1,151,661,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.90881
Policy Entropy: 3.13608
Value Function Loss: 0.00420

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.51812

Collected Steps per Second: 22,748.35983
Overall Steps per Second: 10,540.21454

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.54710
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.74620

Cumulative Model Updates: 138,090
Cumulative Timesteps: 1,151,711,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1151711054...
Checkpoint 1151711054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.07922
Policy Entropy: 3.14431
Value Function Loss: 0.00427

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.58567
Value Function Update Magnitude: 0.54607

Collected Steps per Second: 22,332.30286
Overall Steps per Second: 10,501.72204

Timestep Collection Time: 2.23927
Timestep Consumption Time: 2.52262
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.76189

Cumulative Model Updates: 138,096
Cumulative Timesteps: 1,151,761,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.32091
Policy Entropy: 3.15650
Value Function Loss: 0.00453

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.59731
Value Function Update Magnitude: 0.55962

Collected Steps per Second: 22,727.98533
Overall Steps per Second: 10,611.23524

Timestep Collection Time: 2.20064
Timestep Consumption Time: 2.51286
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.71349

Cumulative Model Updates: 138,102
Cumulative Timesteps: 1,151,811,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1151811078...
Checkpoint 1151811078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.10785
Policy Entropy: 3.15155
Value Function Loss: 0.00460

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.60384
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 22,752.48258
Overall Steps per Second: 10,647.10479

Timestep Collection Time: 2.19791
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.69686

Cumulative Model Updates: 138,108
Cumulative Timesteps: 1,151,861,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.43999
Policy Entropy: 3.15129
Value Function Loss: 0.00467

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.61377
Value Function Update Magnitude: 0.57177

Collected Steps per Second: 22,119.66174
Overall Steps per Second: 10,535.44883

Timestep Collection Time: 2.26097
Timestep Consumption Time: 2.48605
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.74702

Cumulative Model Updates: 138,114
Cumulative Timesteps: 1,151,911,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1151911098...
Checkpoint 1151911098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.81645
Policy Entropy: 3.15357
Value Function Loss: 0.00437

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.61415
Value Function Update Magnitude: 0.58298

Collected Steps per Second: 21,768.97924
Overall Steps per Second: 10,374.94226

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.52256
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.81950

Cumulative Model Updates: 138,120
Cumulative Timesteps: 1,151,961,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.22252
Policy Entropy: 3.14445
Value Function Loss: 0.00460

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.61557
Value Function Update Magnitude: 0.59335

Collected Steps per Second: 21,734.42332
Overall Steps per Second: 10,483.28800

Timestep Collection Time: 2.30133
Timestep Consumption Time: 2.46989
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.77121

Cumulative Model Updates: 138,126
Cumulative Timesteps: 1,152,011,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1152011118...
Checkpoint 1152011118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.24290
Policy Entropy: 3.14279
Value Function Loss: 0.00462

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.62143
Value Function Update Magnitude: 0.60704

Collected Steps per Second: 21,875.39240
Overall Steps per Second: 10,507.73411

Timestep Collection Time: 2.28640
Timestep Consumption Time: 2.47352
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.75992

Cumulative Model Updates: 138,132
Cumulative Timesteps: 1,152,061,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.93408
Policy Entropy: 3.12609
Value Function Loss: 0.00504

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.63045
Value Function Update Magnitude: 0.59856

Collected Steps per Second: 22,527.36373
Overall Steps per Second: 10,427.65478

Timestep Collection Time: 2.22006
Timestep Consumption Time: 2.57604
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.79609

Cumulative Model Updates: 138,138
Cumulative Timesteps: 1,152,111,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1152111146...
Checkpoint 1152111146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.10720
Policy Entropy: 3.13068
Value Function Loss: 0.00487

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.63670
Value Function Update Magnitude: 0.60057

Collected Steps per Second: 22,036.12606
Overall Steps per Second: 10,457.95548

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.51245
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.78181

Cumulative Model Updates: 138,144
Cumulative Timesteps: 1,152,161,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,583.25619
Policy Entropy: 3.12917
Value Function Loss: 0.00454

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.62789
Value Function Update Magnitude: 0.59804

Collected Steps per Second: 22,847.29113
Overall Steps per Second: 10,760.86690

Timestep Collection Time: 2.18949
Timestep Consumption Time: 2.45920
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.64870

Cumulative Model Updates: 138,150
Cumulative Timesteps: 1,152,211,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1152211178...
Checkpoint 1152211178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.60685
Policy Entropy: 3.13441
Value Function Loss: 0.00422

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.61267
Value Function Update Magnitude: 0.57838

Collected Steps per Second: 22,140.86140
Overall Steps per Second: 10,647.55171

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.69742

Cumulative Model Updates: 138,156
Cumulative Timesteps: 1,152,261,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.95245
Policy Entropy: 3.14419
Value Function Loss: 0.00418

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.59044
Value Function Update Magnitude: 0.54921

Collected Steps per Second: 21,965.59143
Overall Steps per Second: 10,440.15528

Timestep Collection Time: 2.27656
Timestep Consumption Time: 2.51321
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.78978

Cumulative Model Updates: 138,162
Cumulative Timesteps: 1,152,311,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1152311200...
Checkpoint 1152311200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.62475
Policy Entropy: 3.13912
Value Function Loss: 0.00430

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.58589
Value Function Update Magnitude: 0.51873

Collected Steps per Second: 22,519.73054
Overall Steps per Second: 10,671.47593

Timestep Collection Time: 2.22081
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.68651

Cumulative Model Updates: 138,168
Cumulative Timesteps: 1,152,361,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.42483
Policy Entropy: 3.13190
Value Function Loss: 0.00445

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.58871
Value Function Update Magnitude: 0.50743

Collected Steps per Second: 22,452.41339
Overall Steps per Second: 10,500.27737

Timestep Collection Time: 2.22809
Timestep Consumption Time: 2.53617
PPO Batch Consumption Time: 0.30010
Total Iteration Time: 4.76426

Cumulative Model Updates: 138,174
Cumulative Timesteps: 1,152,411,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1152411238...
Checkpoint 1152411238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,336.27876
Policy Entropy: 3.12093
Value Function Loss: 0.00438

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.59086
Value Function Update Magnitude: 0.53576

Collected Steps per Second: 22,026.96615
Overall Steps per Second: 10,526.73158

Timestep Collection Time: 2.27094
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.75190

Cumulative Model Updates: 138,180
Cumulative Timesteps: 1,152,461,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052.03786
Policy Entropy: 3.12553
Value Function Loss: 0.00446

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.59490
Value Function Update Magnitude: 0.55371

Collected Steps per Second: 22,243.78153
Overall Steps per Second: 10,602.64020

Timestep Collection Time: 2.24827
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.71675

Cumulative Model Updates: 138,186
Cumulative Timesteps: 1,152,511,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1152511270...
Checkpoint 1152511270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.69351
Policy Entropy: 3.12228
Value Function Loss: 0.00425

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.58980
Value Function Update Magnitude: 0.53905

Collected Steps per Second: 21,843.51378
Overall Steps per Second: 10,476.87810

Timestep Collection Time: 2.28974
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.77394

Cumulative Model Updates: 138,192
Cumulative Timesteps: 1,152,561,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.25143
Policy Entropy: 3.12513
Value Function Loss: 0.00443

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.53406

Collected Steps per Second: 22,042.99044
Overall Steps per Second: 10,566.64522

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.46397
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.73263

Cumulative Model Updates: 138,198
Cumulative Timesteps: 1,152,611,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1152611294...
Checkpoint 1152611294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.57545
Policy Entropy: 3.12807
Value Function Loss: 0.00422

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.59647
Value Function Update Magnitude: 0.54247

Collected Steps per Second: 21,498.67222
Overall Steps per Second: 10,250.58070

Timestep Collection Time: 2.32628
Timestep Consumption Time: 2.55266
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 4.87894

Cumulative Model Updates: 138,204
Cumulative Timesteps: 1,152,661,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,522.18989
Policy Entropy: 3.13048
Value Function Loss: 0.00417

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.60260
Value Function Update Magnitude: 0.55402

Collected Steps per Second: 22,531.04434
Overall Steps per Second: 10,467.98809

Timestep Collection Time: 2.22138
Timestep Consumption Time: 2.55986
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.78124

Cumulative Model Updates: 138,210
Cumulative Timesteps: 1,152,711,356

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1152711356...
Checkpoint 1152711356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.04798
Policy Entropy: 3.11599
Value Function Loss: 0.00453

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.60721
Value Function Update Magnitude: 0.55053

Collected Steps per Second: 21,573.14551
Overall Steps per Second: 10,164.26319

Timestep Collection Time: 2.31862
Timestep Consumption Time: 2.60254
PPO Batch Consumption Time: 0.30440
Total Iteration Time: 4.92116

Cumulative Model Updates: 138,216
Cumulative Timesteps: 1,152,761,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.84743
Policy Entropy: 3.11797
Value Function Loss: 0.00478

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.61132
Value Function Update Magnitude: 0.56518

Collected Steps per Second: 22,297.82065
Overall Steps per Second: 10,370.18624

Timestep Collection Time: 2.24255
Timestep Consumption Time: 2.57935
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.82190

Cumulative Model Updates: 138,222
Cumulative Timesteps: 1,152,811,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1152811380...
Checkpoint 1152811380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.12830
Policy Entropy: 3.13590
Value Function Loss: 0.00477

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.61182
Value Function Update Magnitude: 0.55758

Collected Steps per Second: 22,321.71848
Overall Steps per Second: 10,620.47692

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.46851
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.70902

Cumulative Model Updates: 138,228
Cumulative Timesteps: 1,152,861,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.59651
Policy Entropy: 3.13097
Value Function Loss: 0.00454

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.61382
Value Function Update Magnitude: 0.55180

Collected Steps per Second: 22,572.85293
Overall Steps per Second: 10,516.02903

Timestep Collection Time: 2.21532
Timestep Consumption Time: 2.53990
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.75522

Cumulative Model Updates: 138,234
Cumulative Timesteps: 1,152,911,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1152911398...
Checkpoint 1152911398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.69958
Policy Entropy: 3.13622
Value Function Loss: 0.00405

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.60793
Value Function Update Magnitude: 0.54825

Collected Steps per Second: 22,499.13138
Overall Steps per Second: 10,597.87545

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.72076

Cumulative Model Updates: 138,240
Cumulative Timesteps: 1,152,961,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.96036
Policy Entropy: 3.11257
Value Function Loss: 0.00424

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.60370
Value Function Update Magnitude: 0.54495

Collected Steps per Second: 22,470.95196
Overall Steps per Second: 10,573.61245

Timestep Collection Time: 2.22572
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.73008

Cumulative Model Updates: 138,246
Cumulative Timesteps: 1,153,011,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1153011442...
Checkpoint 1153011442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.79885
Policy Entropy: 3.11689
Value Function Loss: 0.00434

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.60600
Value Function Update Magnitude: 0.54853

Collected Steps per Second: 21,961.17288
Overall Steps per Second: 10,510.81727

Timestep Collection Time: 2.27684
Timestep Consumption Time: 2.48036
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.75719

Cumulative Model Updates: 138,252
Cumulative Timesteps: 1,153,061,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.63482
Policy Entropy: 3.11944
Value Function Loss: 0.00453

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.60125
Value Function Update Magnitude: 0.55096

Collected Steps per Second: 21,557.11841
Overall Steps per Second: 10,334.30978

Timestep Collection Time: 2.32007
Timestep Consumption Time: 2.51954
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.83961

Cumulative Model Updates: 138,258
Cumulative Timesteps: 1,153,111,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1153111458...
Checkpoint 1153111458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.33482
Policy Entropy: 3.13797
Value Function Loss: 0.00426

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.60073
Value Function Update Magnitude: 0.54729

Collected Steps per Second: 21,386.12842
Overall Steps per Second: 10,365.34548

Timestep Collection Time: 2.33909
Timestep Consumption Time: 2.48700
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.82608

Cumulative Model Updates: 138,264
Cumulative Timesteps: 1,153,161,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.82787
Policy Entropy: 3.13862
Value Function Loss: 0.00412

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.59148
Value Function Update Magnitude: 0.52925

Collected Steps per Second: 22,062.24355
Overall Steps per Second: 10,545.43591

Timestep Collection Time: 2.26650
Timestep Consumption Time: 2.47527
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.74177

Cumulative Model Updates: 138,270
Cumulative Timesteps: 1,153,211,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1153211486...
Checkpoint 1153211486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.21089
Policy Entropy: 3.12164
Value Function Loss: 0.00434

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.59298
Value Function Update Magnitude: 0.52905

Collected Steps per Second: 21,743.55738
Overall Steps per Second: 10,569.69168

Timestep Collection Time: 2.30064
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.73278

Cumulative Model Updates: 138,276
Cumulative Timesteps: 1,153,261,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.99606
Policy Entropy: 3.10708
Value Function Loss: 0.00426

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.59768
Value Function Update Magnitude: 0.55047

Collected Steps per Second: 22,147.55171
Overall Steps per Second: 10,499.19591

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.76341

Cumulative Model Updates: 138,282
Cumulative Timesteps: 1,153,311,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1153311522...
Checkpoint 1153311522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.58992
Policy Entropy: 3.11411
Value Function Loss: 0.00407

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.55805

Collected Steps per Second: 22,071.70120
Overall Steps per Second: 10,344.48937

Timestep Collection Time: 2.26543
Timestep Consumption Time: 2.56825
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.83368

Cumulative Model Updates: 138,288
Cumulative Timesteps: 1,153,361,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.84531
Policy Entropy: 3.13383
Value Function Loss: 0.00440

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.58787
Value Function Update Magnitude: 0.53908

Collected Steps per Second: 22,282.65293
Overall Steps per Second: 10,306.43736

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.60859
PPO Batch Consumption Time: 0.30472
Total Iteration Time: 4.85347

Cumulative Model Updates: 138,294
Cumulative Timesteps: 1,153,411,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1153411546...
Checkpoint 1153411546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,668.72400
Policy Entropy: 3.13949
Value Function Loss: 0.00425

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.59434
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 22,401.78748
Overall Steps per Second: 10,601.00271

Timestep Collection Time: 2.23259
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.71786

Cumulative Model Updates: 138,300
Cumulative Timesteps: 1,153,461,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.14265
Policy Entropy: 3.13525
Value Function Loss: 0.00452

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.59587
Value Function Update Magnitude: 0.52183

Collected Steps per Second: 22,532.59808
Overall Steps per Second: 10,567.55163

Timestep Collection Time: 2.22016
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.73393

Cumulative Model Updates: 138,306
Cumulative Timesteps: 1,153,511,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1153511586...
Checkpoint 1153511586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.07326
Policy Entropy: 3.14405
Value Function Loss: 0.00420

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.59544
Value Function Update Magnitude: 0.52293

Collected Steps per Second: 22,399.46875
Overall Steps per Second: 10,573.23168

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.49753
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.73044

Cumulative Model Updates: 138,312
Cumulative Timesteps: 1,153,561,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821.23021
Policy Entropy: 3.14114
Value Function Loss: 0.00458

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.59486
Value Function Update Magnitude: 0.52954

Collected Steps per Second: 22,530.92597
Overall Steps per Second: 10,591.64136

Timestep Collection Time: 2.21997
Timestep Consumption Time: 2.50243
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.72240

Cumulative Model Updates: 138,318
Cumulative Timesteps: 1,153,611,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1153611620...
Checkpoint 1153611620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.17893
Policy Entropy: 3.12998
Value Function Loss: 0.00464

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.59958
Value Function Update Magnitude: 0.54940

Collected Steps per Second: 22,726.95371
Overall Steps per Second: 10,624.59133

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.70889

Cumulative Model Updates: 138,324
Cumulative Timesteps: 1,153,661,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.39994
Policy Entropy: 3.13587
Value Function Loss: 0.00455

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.60654
Value Function Update Magnitude: 0.57810

Collected Steps per Second: 22,718.37065
Overall Steps per Second: 10,570.05243

Timestep Collection Time: 2.20148
Timestep Consumption Time: 2.53019
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.73167

Cumulative Model Updates: 138,330
Cumulative Timesteps: 1,153,711,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1153711664...
Checkpoint 1153711664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.31336
Policy Entropy: 3.13804
Value Function Loss: 0.00394

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.58942
Value Function Update Magnitude: 0.57314

Collected Steps per Second: 22,058.39266
Overall Steps per Second: 10,426.54267

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.53016
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.79814

Cumulative Model Updates: 138,336
Cumulative Timesteps: 1,153,761,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.91758
Policy Entropy: 3.16211
Value Function Loss: 0.00375

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.57121
Value Function Update Magnitude: 0.54924

Collected Steps per Second: 22,321.44451
Overall Steps per Second: 10,465.24785

Timestep Collection Time: 2.24089
Timestep Consumption Time: 2.53873
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.77963

Cumulative Model Updates: 138,342
Cumulative Timesteps: 1,153,811,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1153811712...
Checkpoint 1153811712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.81405
Policy Entropy: 3.16163
Value Function Loss: 0.00409

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.54130

Collected Steps per Second: 21,674.40333
Overall Steps per Second: 10,378.46333

Timestep Collection Time: 2.30825
Timestep Consumption Time: 2.51231
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.82056

Cumulative Model Updates: 138,348
Cumulative Timesteps: 1,153,861,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.94510
Policy Entropy: 3.15178
Value Function Loss: 0.00424

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.54219

Collected Steps per Second: 21,722.82604
Overall Steps per Second: 10,281.90728

Timestep Collection Time: 2.30173
Timestep Consumption Time: 2.56118
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.86291

Cumulative Model Updates: 138,354
Cumulative Timesteps: 1,153,911,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1153911742...
Checkpoint 1153911742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.58786
Policy Entropy: 3.15448
Value Function Loss: 0.00431

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.57240
Value Function Update Magnitude: 0.52411

Collected Steps per Second: 22,132.55188
Overall Steps per Second: 10,528.28423

Timestep Collection Time: 2.25939
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.74968

Cumulative Model Updates: 138,360
Cumulative Timesteps: 1,153,961,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.60949
Policy Entropy: 3.16987
Value Function Loss: 0.00395

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.56378
Value Function Update Magnitude: 0.49501

Collected Steps per Second: 21,836.17508
Overall Steps per Second: 10,484.06388

Timestep Collection Time: 2.29088
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.77143

Cumulative Model Updates: 138,366
Cumulative Timesteps: 1,154,011,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1154011772...
Checkpoint 1154011772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.79397
Policy Entropy: 3.15895
Value Function Loss: 0.00413

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.47831

Collected Steps per Second: 22,425.46068
Overall Steps per Second: 10,466.02378

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.54775
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.77736

Cumulative Model Updates: 138,372
Cumulative Timesteps: 1,154,061,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,009.03611
Policy Entropy: 3.15739
Value Function Loss: 0.00392

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.57190
Value Function Update Magnitude: 0.48852

Collected Steps per Second: 22,271.74071
Overall Steps per Second: 10,481.22787

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.52574
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.77101

Cumulative Model Updates: 138,378
Cumulative Timesteps: 1,154,111,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1154111778...
Checkpoint 1154111778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.36007
Policy Entropy: 3.14607
Value Function Loss: 0.00384

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.56815
Value Function Update Magnitude: 0.50617

Collected Steps per Second: 22,543.75440
Overall Steps per Second: 10,493.33571

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.54834
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 4.76741

Cumulative Model Updates: 138,384
Cumulative Timesteps: 1,154,161,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,891.50470
Policy Entropy: 3.14859
Value Function Loss: 0.00372

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.57376
Value Function Update Magnitude: 0.52190

Collected Steps per Second: 22,549.19913
Overall Steps per Second: 10,624.71588

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.70789

Cumulative Model Updates: 138,390
Cumulative Timesteps: 1,154,211,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1154211824...
Checkpoint 1154211824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.42909
Policy Entropy: 3.13365
Value Function Loss: 0.00424

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.53754

Collected Steps per Second: 22,809.91648
Overall Steps per Second: 10,763.83271

Timestep Collection Time: 2.19282
Timestep Consumption Time: 2.45404
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.64686

Cumulative Model Updates: 138,396
Cumulative Timesteps: 1,154,261,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.66121
Policy Entropy: 3.13503
Value Function Loss: 0.00418

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.59543
Value Function Update Magnitude: 0.54975

Collected Steps per Second: 22,479.97850
Overall Steps per Second: 10,551.90830

Timestep Collection Time: 2.22536
Timestep Consumption Time: 2.51559
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.74094

Cumulative Model Updates: 138,402
Cumulative Timesteps: 1,154,311,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1154311868...
Checkpoint 1154311868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.52956
Policy Entropy: 3.13524
Value Function Loss: 0.00480

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.61070
Value Function Update Magnitude: 0.57448

Collected Steps per Second: 22,270.79143
Overall Steps per Second: 10,700.65035

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.67299

Cumulative Model Updates: 138,408
Cumulative Timesteps: 1,154,361,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.83194
Policy Entropy: 3.13735
Value Function Loss: 0.00453

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.61923
Value Function Update Magnitude: 0.59559

Collected Steps per Second: 21,830.69023
Overall Steps per Second: 10,389.42354

Timestep Collection Time: 2.29164
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.81528

Cumulative Model Updates: 138,414
Cumulative Timesteps: 1,154,411,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1154411900...
Checkpoint 1154411900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.85339
Policy Entropy: 3.12621
Value Function Loss: 0.00492

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.60998
Value Function Update Magnitude: 0.58230

Collected Steps per Second: 22,345.09902
Overall Steps per Second: 10,667.69209

Timestep Collection Time: 2.23870
Timestep Consumption Time: 2.45060
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.68930

Cumulative Model Updates: 138,420
Cumulative Timesteps: 1,154,461,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.00647
Policy Entropy: 3.13007
Value Function Loss: 0.00468

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.61048
Value Function Update Magnitude: 0.57766

Collected Steps per Second: 21,895.81674
Overall Steps per Second: 10,433.51501

Timestep Collection Time: 2.28372
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.79263

Cumulative Model Updates: 138,426
Cumulative Timesteps: 1,154,511,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1154511928...
Checkpoint 1154511928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164.97950
Policy Entropy: 3.12701
Value Function Loss: 0.00445

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.61202
Value Function Update Magnitude: 0.57050

Collected Steps per Second: 21,724.27442
Overall Steps per Second: 10,386.42374

Timestep Collection Time: 2.30341
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.81783

Cumulative Model Updates: 138,432
Cumulative Timesteps: 1,154,561,968

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.99431
Policy Entropy: 3.12250
Value Function Loss: 0.00439

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.61127
Value Function Update Magnitude: 0.56149

Collected Steps per Second: 22,591.51286
Overall Steps per Second: 10,673.35597

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.68569

Cumulative Model Updates: 138,438
Cumulative Timesteps: 1,154,611,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1154611980...
Checkpoint 1154611980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.77224
Policy Entropy: 3.13208
Value Function Loss: 0.00438

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.60206
Value Function Update Magnitude: 0.55318

Collected Steps per Second: 22,522.66348
Overall Steps per Second: 10,641.56870

Timestep Collection Time: 2.22105
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.70081

Cumulative Model Updates: 138,444
Cumulative Timesteps: 1,154,662,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.82173
Policy Entropy: 3.13593
Value Function Loss: 0.00434

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.59793
Value Function Update Magnitude: 0.54928

Collected Steps per Second: 20,691.60973
Overall Steps per Second: 10,074.53938

Timestep Collection Time: 2.41663
Timestep Consumption Time: 2.54677
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.96340

Cumulative Model Updates: 138,450
Cumulative Timesteps: 1,154,712,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1154712008...
Checkpoint 1154712008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.25834
Policy Entropy: 3.14194
Value Function Loss: 0.00430

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.59632
Value Function Update Magnitude: 0.54714

Collected Steps per Second: 22,039.69498
Overall Steps per Second: 10,565.55706

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.46451
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.73387

Cumulative Model Updates: 138,456
Cumulative Timesteps: 1,154,762,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.01919
Policy Entropy: 3.13404
Value Function Loss: 0.00405

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.55185

Collected Steps per Second: 22,637.22289
Overall Steps per Second: 10,507.55319

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.55014
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.75924

Cumulative Model Updates: 138,462
Cumulative Timesteps: 1,154,812,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1154812032...
Checkpoint 1154812032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.80807
Policy Entropy: 3.12454
Value Function Loss: 0.00394

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.57540
Value Function Update Magnitude: 0.53372

Collected Steps per Second: 22,341.79052
Overall Steps per Second: 10,724.35328

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.42433
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.66229

Cumulative Model Updates: 138,468
Cumulative Timesteps: 1,154,862,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206.84129
Policy Entropy: 3.13170
Value Function Loss: 0.00379

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.57494
Value Function Update Magnitude: 0.51217

Collected Steps per Second: 22,424.77296
Overall Steps per Second: 10,538.64948

Timestep Collection Time: 2.23021
Timestep Consumption Time: 2.51537
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.74558

Cumulative Model Updates: 138,474
Cumulative Timesteps: 1,154,912,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1154912044...
Checkpoint 1154912044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.14790
Policy Entropy: 3.13981
Value Function Loss: 0.00386

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.58128
Value Function Update Magnitude: 0.51489

Collected Steps per Second: 22,005.35825
Overall Steps per Second: 10,505.12834

Timestep Collection Time: 2.27336
Timestep Consumption Time: 2.48870
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.76206

Cumulative Model Updates: 138,480
Cumulative Timesteps: 1,154,962,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.18768
Policy Entropy: 3.14382
Value Function Loss: 0.00400

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.58916
Value Function Update Magnitude: 0.53006

Collected Steps per Second: 22,075.60951
Overall Steps per Second: 10,445.96188

Timestep Collection Time: 2.26594
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.78864

Cumulative Model Updates: 138,486
Cumulative Timesteps: 1,155,012,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1155012092...
Checkpoint 1155012092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.74212
Policy Entropy: 3.13113
Value Function Loss: 0.00426

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.59207
Value Function Update Magnitude: 0.56094

Collected Steps per Second: 22,020.40399
Overall Steps per Second: 10,556.89288

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.46572
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.73643

Cumulative Model Updates: 138,492
Cumulative Timesteps: 1,155,062,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.41539
Policy Entropy: 3.14040
Value Function Loss: 0.00423

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.59733
Value Function Update Magnitude: 0.57236

Collected Steps per Second: 21,336.81950
Overall Steps per Second: 10,461.80672

Timestep Collection Time: 2.34374
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.78005

Cumulative Model Updates: 138,498
Cumulative Timesteps: 1,155,112,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1155112102...
Checkpoint 1155112102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.88406
Policy Entropy: 3.14953
Value Function Loss: 0.00433

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.58983
Value Function Update Magnitude: 0.54647

Collected Steps per Second: 22,103.72379
Overall Steps per Second: 10,593.95728

Timestep Collection Time: 2.26251
Timestep Consumption Time: 2.45810
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.72062

Cumulative Model Updates: 138,504
Cumulative Timesteps: 1,155,162,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.05813
Policy Entropy: 3.16157
Value Function Loss: 0.00402

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.58580
Value Function Update Magnitude: 0.53641

Collected Steps per Second: 22,104.95589
Overall Steps per Second: 10,630.10659

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.44256
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.70531

Cumulative Model Updates: 138,510
Cumulative Timesteps: 1,155,212,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1155212130...
Checkpoint 1155212130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.45367
Policy Entropy: 3.13650
Value Function Loss: 0.00389

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.58417
Value Function Update Magnitude: 0.52540

Collected Steps per Second: 22,467.67140
Overall Steps per Second: 10,531.88215

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.52348
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.75015

Cumulative Model Updates: 138,516
Cumulative Timesteps: 1,155,262,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526.99894
Policy Entropy: 3.13347
Value Function Loss: 0.00358

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.58485
Value Function Update Magnitude: 0.51672

Collected Steps per Second: 22,519.72333
Overall Steps per Second: 10,365.55032

Timestep Collection Time: 2.22072
Timestep Consumption Time: 2.60392
PPO Batch Consumption Time: 0.30133
Total Iteration Time: 4.82464

Cumulative Model Updates: 138,522
Cumulative Timesteps: 1,155,312,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1155312168...
Checkpoint 1155312168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772.62617
Policy Entropy: 3.12105
Value Function Loss: 0.00367

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.58448
Value Function Update Magnitude: 0.50657

Collected Steps per Second: 22,126.75600
Overall Steps per Second: 10,481.32394

Timestep Collection Time: 2.26016
Timestep Consumption Time: 2.51118
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.77134

Cumulative Model Updates: 138,528
Cumulative Timesteps: 1,155,362,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,355.74823
Policy Entropy: 3.12564
Value Function Loss: 0.00379

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.57659
Value Function Update Magnitude: 0.50457

Collected Steps per Second: 22,291.72649
Overall Steps per Second: 10,468.66718

Timestep Collection Time: 2.24514
Timestep Consumption Time: 2.53560
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.78074

Cumulative Model Updates: 138,534
Cumulative Timesteps: 1,155,412,226

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1155412226...
Checkpoint 1155412226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.33522
Policy Entropy: 3.12016
Value Function Loss: 0.00361

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.48023

Collected Steps per Second: 22,455.32440
Overall Steps per Second: 10,469.04403

Timestep Collection Time: 2.22718
Timestep Consumption Time: 2.54995
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.77713

Cumulative Model Updates: 138,540
Cumulative Timesteps: 1,155,462,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,478.92438
Policy Entropy: 3.13108
Value Function Loss: 0.00337

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.55000
Value Function Update Magnitude: 0.46871

Collected Steps per Second: 22,519.49602
Overall Steps per Second: 10,421.33818

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.57879
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 4.80015

Cumulative Model Updates: 138,546
Cumulative Timesteps: 1,155,512,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1155512262...
Checkpoint 1155512262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,936.40006
Policy Entropy: 3.14717
Value Function Loss: 0.00333

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.45067

Collected Steps per Second: 22,617.17597
Overall Steps per Second: 10,676.09331

Timestep Collection Time: 2.21151
Timestep Consumption Time: 2.47354
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.68505

Cumulative Model Updates: 138,552
Cumulative Timesteps: 1,155,562,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,235.68970
Policy Entropy: 3.14366
Value Function Loss: 0.00357

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.54558
Value Function Update Magnitude: 0.44657

Collected Steps per Second: 21,764.71866
Overall Steps per Second: 10,484.37028

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.77015

Cumulative Model Updates: 138,558
Cumulative Timesteps: 1,155,612,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1155612292...
Checkpoint 1155612292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,268.41258
Policy Entropy: 3.13642
Value Function Loss: 0.00381

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.46059

Collected Steps per Second: 21,415.14835
Overall Steps per Second: 10,239.52102

Timestep Collection Time: 2.33564
Timestep Consumption Time: 2.54916
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 4.88480

Cumulative Model Updates: 138,564
Cumulative Timesteps: 1,155,662,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.45571
Policy Entropy: 3.12893
Value Function Loss: 0.00362

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.47581

Collected Steps per Second: 21,974.62332
Overall Steps per Second: 10,395.24766

Timestep Collection Time: 2.27562
Timestep Consumption Time: 2.53484
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.81047

Cumulative Model Updates: 138,570
Cumulative Timesteps: 1,155,712,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1155712316...
Checkpoint 1155712316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.51667
Policy Entropy: 3.13363
Value Function Loss: 0.00381

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.47369

Collected Steps per Second: 21,847.01863
Overall Steps per Second: 10,355.16228

Timestep Collection Time: 2.28965
Timestep Consumption Time: 2.54099
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.83063

Cumulative Model Updates: 138,576
Cumulative Timesteps: 1,155,762,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.96430
Policy Entropy: 3.13265
Value Function Loss: 0.00385

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.57747
Value Function Update Magnitude: 0.49416

Collected Steps per Second: 22,304.31841
Overall Steps per Second: 10,492.71578

Timestep Collection Time: 2.24217
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.76616

Cumulative Model Updates: 138,582
Cumulative Timesteps: 1,155,812,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1155812348...
Checkpoint 1155812348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.16605
Policy Entropy: 3.13608
Value Function Loss: 0.00389

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.57946
Value Function Update Magnitude: 0.51375

Collected Steps per Second: 21,692.71633
Overall Steps per Second: 10,454.20415

Timestep Collection Time: 2.30547
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.78391

Cumulative Model Updates: 138,588
Cumulative Timesteps: 1,155,862,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,301.64742
Policy Entropy: 3.13189
Value Function Loss: 0.00402

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.58492
Value Function Update Magnitude: 0.51819

Collected Steps per Second: 22,002.90193
Overall Steps per Second: 10,491.93956

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.76728

Cumulative Model Updates: 138,594
Cumulative Timesteps: 1,155,912,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1155912378...
Checkpoint 1155912378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.86788
Policy Entropy: 3.13765
Value Function Loss: 0.00436

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.59667
Value Function Update Magnitude: 0.51101

Collected Steps per Second: 22,368.88224
Overall Steps per Second: 10,553.89336

Timestep Collection Time: 2.23677
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.74081

Cumulative Model Updates: 138,600
Cumulative Timesteps: 1,155,962,412

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.37522
Policy Entropy: 3.12893
Value Function Loss: 0.00429

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.59125
Value Function Update Magnitude: 0.51198

Collected Steps per Second: 22,356.36478
Overall Steps per Second: 10,462.83373

Timestep Collection Time: 2.23686
Timestep Consumption Time: 2.54273
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.77958

Cumulative Model Updates: 138,606
Cumulative Timesteps: 1,156,012,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1156012420...
Checkpoint 1156012420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.67031
Policy Entropy: 3.13989
Value Function Loss: 0.00443

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.59860
Value Function Update Magnitude: 0.52425

Collected Steps per Second: 21,994.56693
Overall Steps per Second: 10,454.26973

Timestep Collection Time: 2.27393
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.78407

Cumulative Model Updates: 138,612
Cumulative Timesteps: 1,156,062,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.49376
Policy Entropy: 3.14110
Value Function Loss: 0.00411

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.59608
Value Function Update Magnitude: 0.54745

Collected Steps per Second: 22,639.56481
Overall Steps per Second: 10,637.91675

Timestep Collection Time: 2.20870
Timestep Consumption Time: 2.49184
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.70054

Cumulative Model Updates: 138,618
Cumulative Timesteps: 1,156,112,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1156112438...
Checkpoint 1156112438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.24634
Policy Entropy: 3.14266
Value Function Loss: 0.00397

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.53915

Collected Steps per Second: 22,344.00784
Overall Steps per Second: 10,575.61268

Timestep Collection Time: 2.23854
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.72956

Cumulative Model Updates: 138,624
Cumulative Timesteps: 1,156,162,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.22602
Policy Entropy: 3.14109
Value Function Loss: 0.00390

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.58444
Value Function Update Magnitude: 0.50626

Collected Steps per Second: 22,405.00920
Overall Steps per Second: 10,637.44323

Timestep Collection Time: 2.23218
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.70151

Cumulative Model Updates: 138,630
Cumulative Timesteps: 1,156,212,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1156212468...
Checkpoint 1156212468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.71560
Policy Entropy: 3.14460
Value Function Loss: 0.00356

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.48789

Collected Steps per Second: 22,007.47582
Overall Steps per Second: 10,513.24483

Timestep Collection Time: 2.27295
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.75800

Cumulative Model Updates: 138,636
Cumulative Timesteps: 1,156,262,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.98361
Policy Entropy: 3.15468
Value Function Loss: 0.00390

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.48284

Collected Steps per Second: 22,435.04607
Overall Steps per Second: 10,546.66026

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.51349
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.74330

Cumulative Model Updates: 138,642
Cumulative Timesteps: 1,156,312,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1156312516...
Checkpoint 1156312516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.87749
Policy Entropy: 3.16330
Value Function Loss: 0.00373

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.57252
Value Function Update Magnitude: 0.49650

Collected Steps per Second: 21,742.30234
Overall Steps per Second: 10,356.50119

Timestep Collection Time: 2.30077
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.83020

Cumulative Model Updates: 138,648
Cumulative Timesteps: 1,156,362,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.50384
Policy Entropy: 3.16641
Value Function Loss: 0.00391

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.51796

Collected Steps per Second: 22,680.88866
Overall Steps per Second: 10,671.26653

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.68698

Cumulative Model Updates: 138,654
Cumulative Timesteps: 1,156,412,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1156412556...
Checkpoint 1156412556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609.96692
Policy Entropy: 3.13937
Value Function Loss: 0.00386

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.57854
Value Function Update Magnitude: 0.52008

Collected Steps per Second: 21,829.51630
Overall Steps per Second: 10,324.87590

Timestep Collection Time: 2.29158
Timestep Consumption Time: 2.55342
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.84500

Cumulative Model Updates: 138,660
Cumulative Timesteps: 1,156,462,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,762.01612
Policy Entropy: 3.11877
Value Function Loss: 0.00409

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.52405

Collected Steps per Second: 22,481.81168
Overall Steps per Second: 10,368.56305

Timestep Collection Time: 2.22482
Timestep Consumption Time: 2.59918
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.82401

Cumulative Model Updates: 138,666
Cumulative Timesteps: 1,156,512,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1156512598...
Checkpoint 1156512598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.24943
Policy Entropy: 3.10838
Value Function Loss: 0.00420

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.59396
Value Function Update Magnitude: 0.52583

Collected Steps per Second: 22,167.44565
Overall Steps per Second: 10,535.23107

Timestep Collection Time: 2.25583
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.74655

Cumulative Model Updates: 138,672
Cumulative Timesteps: 1,156,562,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,545.31248
Policy Entropy: 3.11184
Value Function Loss: 0.00427

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.58941
Value Function Update Magnitude: 0.55723

Collected Steps per Second: 22,019.36131
Overall Steps per Second: 10,499.22917

Timestep Collection Time: 2.27136
Timestep Consumption Time: 2.49222
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.76359

Cumulative Model Updates: 138,678
Cumulative Timesteps: 1,156,612,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1156612618...
Checkpoint 1156612618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.48622
Policy Entropy: 3.11833
Value Function Loss: 0.00437

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.58998
Value Function Update Magnitude: 0.57230

Collected Steps per Second: 22,436.17350
Overall Steps per Second: 10,606.52038

Timestep Collection Time: 2.22917
Timestep Consumption Time: 2.48623
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.71540

Cumulative Model Updates: 138,684
Cumulative Timesteps: 1,156,662,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.67976
Policy Entropy: 3.12023
Value Function Loss: 0.00391

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.58014
Value Function Update Magnitude: 0.55132

Collected Steps per Second: 22,084.39162
Overall Steps per Second: 10,563.16843

Timestep Collection Time: 2.26486
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.73513

Cumulative Model Updates: 138,690
Cumulative Timesteps: 1,156,712,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1156712650...
Checkpoint 1156712650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.62031
Policy Entropy: 3.10782
Value Function Loss: 0.00418

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.57982
Value Function Update Magnitude: 0.53988

Collected Steps per Second: 22,101.56706
Overall Steps per Second: 10,535.97312

Timestep Collection Time: 2.26255
Timestep Consumption Time: 2.48366
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.74622

Cumulative Model Updates: 138,696
Cumulative Timesteps: 1,156,762,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.25778
Policy Entropy: 3.10819
Value Function Loss: 0.00451

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.60165
Value Function Update Magnitude: 0.56053

Collected Steps per Second: 22,335.04605
Overall Steps per Second: 10,576.33945

Timestep Collection Time: 2.23944
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.72924

Cumulative Model Updates: 138,702
Cumulative Timesteps: 1,156,812,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1156812674...
Checkpoint 1156812674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,784.15803
Policy Entropy: 3.10771
Value Function Loss: 0.00503

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.61982
Value Function Update Magnitude: 0.56097

Collected Steps per Second: 21,666.93451
Overall Steps per Second: 10,255.92371

Timestep Collection Time: 2.30794
Timestep Consumption Time: 2.56788
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.87582

Cumulative Model Updates: 138,708
Cumulative Timesteps: 1,156,862,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.64985
Policy Entropy: 3.12057
Value Function Loss: 0.00468

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.61605
Value Function Update Magnitude: 0.58712

Collected Steps per Second: 22,042.61508
Overall Steps per Second: 10,395.94460

Timestep Collection Time: 2.26969
Timestep Consumption Time: 2.54276
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.81245

Cumulative Model Updates: 138,714
Cumulative Timesteps: 1,156,912,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1156912710...
Checkpoint 1156912710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.24716
Policy Entropy: 3.12975
Value Function Loss: 0.00437

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.60429
Value Function Update Magnitude: 0.57592

Collected Steps per Second: 21,661.76310
Overall Steps per Second: 10,339.31986

Timestep Collection Time: 2.31015
Timestep Consumption Time: 2.52982
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.83997

Cumulative Model Updates: 138,720
Cumulative Timesteps: 1,156,962,752

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.51538
Policy Entropy: 3.12100
Value Function Loss: 0.00408

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.59438
Value Function Update Magnitude: 0.55060

Collected Steps per Second: 22,096.25483
Overall Steps per Second: 10,449.29525

Timestep Collection Time: 2.26346
Timestep Consumption Time: 2.52289
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.78635

Cumulative Model Updates: 138,726
Cumulative Timesteps: 1,157,012,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1157012766...
Checkpoint 1157012766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.88258
Policy Entropy: 3.12706
Value Function Loss: 0.00416

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.59119
Value Function Update Magnitude: 0.53845

Collected Steps per Second: 21,822.16091
Overall Steps per Second: 10,546.04177

Timestep Collection Time: 2.29125
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.74112

Cumulative Model Updates: 138,732
Cumulative Timesteps: 1,157,062,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.86024
Policy Entropy: 3.11449
Value Function Loss: 0.00420

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.60461
Value Function Update Magnitude: 0.54850

Collected Steps per Second: 22,767.06965
Overall Steps per Second: 10,519.73709

Timestep Collection Time: 2.19712
Timestep Consumption Time: 2.55794
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 4.75506

Cumulative Model Updates: 138,738
Cumulative Timesteps: 1,157,112,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1157112788...
Checkpoint 1157112788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.40474
Policy Entropy: 3.10390
Value Function Loss: 0.00458

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.62405
Value Function Update Magnitude: 0.58828

Collected Steps per Second: 22,413.33119
Overall Steps per Second: 10,501.38110

Timestep Collection Time: 2.23135
Timestep Consumption Time: 2.53107
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.76242

Cumulative Model Updates: 138,744
Cumulative Timesteps: 1,157,162,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.37424
Policy Entropy: 3.10744
Value Function Loss: 0.00459

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.61902
Value Function Update Magnitude: 0.58005

Collected Steps per Second: 22,526.77368
Overall Steps per Second: 10,531.62980

Timestep Collection Time: 2.22038
Timestep Consumption Time: 2.52893
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.74931

Cumulative Model Updates: 138,750
Cumulative Timesteps: 1,157,212,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1157212818...
Checkpoint 1157212818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.90477
Policy Entropy: 3.11788
Value Function Loss: 0.00455

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.61273
Value Function Update Magnitude: 0.54867

Collected Steps per Second: 22,302.36287
Overall Steps per Second: 10,655.61840

Timestep Collection Time: 2.24236
Timestep Consumption Time: 2.45094
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.69330

Cumulative Model Updates: 138,756
Cumulative Timesteps: 1,157,262,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490.38881
Policy Entropy: 3.13722
Value Function Loss: 0.00421

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.59709
Value Function Update Magnitude: 0.53537

Collected Steps per Second: 22,471.85256
Overall Steps per Second: 10,452.33815

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.55912
PPO Batch Consumption Time: 0.30305
Total Iteration Time: 4.78458

Cumulative Model Updates: 138,762
Cumulative Timesteps: 1,157,312,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1157312838...
Checkpoint 1157312838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.86161
Policy Entropy: 3.14484
Value Function Loss: 0.00403

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.58107
Value Function Update Magnitude: 0.52110

Collected Steps per Second: 22,176.10794
Overall Steps per Second: 10,638.18816

Timestep Collection Time: 2.25594
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.70268

Cumulative Model Updates: 138,768
Cumulative Timesteps: 1,157,362,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.28764
Policy Entropy: 3.15160
Value Function Loss: 0.00424

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.58111
Value Function Update Magnitude: 0.53706

Collected Steps per Second: 22,713.25664
Overall Steps per Second: 10,770.71523

Timestep Collection Time: 2.20250
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.64463

Cumulative Model Updates: 138,774
Cumulative Timesteps: 1,157,412,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1157412892...
Checkpoint 1157412892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,812.83692
Policy Entropy: 3.16091
Value Function Loss: 0.00406

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.57677
Value Function Update Magnitude: 0.57277

Collected Steps per Second: 21,937.00807
Overall Steps per Second: 10,486.12806

Timestep Collection Time: 2.27953
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.76878

Cumulative Model Updates: 138,780
Cumulative Timesteps: 1,157,462,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.81303
Policy Entropy: 3.14759
Value Function Loss: 0.00446

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.58783
Value Function Update Magnitude: 0.55558

Collected Steps per Second: 22,211.38752
Overall Steps per Second: 10,442.73928

Timestep Collection Time: 2.25182
Timestep Consumption Time: 2.53773
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.78955

Cumulative Model Updates: 138,786
Cumulative Timesteps: 1,157,512,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1157512914...
Checkpoint 1157512914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.04811
Policy Entropy: 3.14181
Value Function Loss: 0.00421

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.56924

Collected Steps per Second: 21,615.07446
Overall Steps per Second: 10,454.09363

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.47120
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.78588

Cumulative Model Updates: 138,792
Cumulative Timesteps: 1,157,562,946

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.13259
Policy Entropy: 3.13376
Value Function Loss: 0.00441

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.55017

Collected Steps per Second: 22,046.75013
Overall Steps per Second: 10,498.99986

Timestep Collection Time: 2.26927
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.76522

Cumulative Model Updates: 138,798
Cumulative Timesteps: 1,157,612,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1157612976...
Checkpoint 1157612976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,772.05643
Policy Entropy: 3.13714
Value Function Loss: 0.00409

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.57682
Value Function Update Magnitude: 0.52678

Collected Steps per Second: 22,109.31142
Overall Steps per Second: 10,546.18794

Timestep Collection Time: 2.26194
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.74200

Cumulative Model Updates: 138,804
Cumulative Timesteps: 1,157,662,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.43016
Policy Entropy: 3.12633
Value Function Loss: 0.00423

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.58294
Value Function Update Magnitude: 0.53167

Collected Steps per Second: 22,038.57914
Overall Steps per Second: 10,508.33956

Timestep Collection Time: 2.27002
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.76079

Cumulative Model Updates: 138,810
Cumulative Timesteps: 1,157,713,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1157713014...
Checkpoint 1157713014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,875.11438
Policy Entropy: 3.12697
Value Function Loss: 0.00407

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.58495
Value Function Update Magnitude: 0.53046

Collected Steps per Second: 22,177.35507
Overall Steps per Second: 10,293.96972

Timestep Collection Time: 2.25500
Timestep Consumption Time: 2.60318
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.85818

Cumulative Model Updates: 138,816
Cumulative Timesteps: 1,157,763,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.66273
Policy Entropy: 3.13638
Value Function Loss: 0.00409

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.58315
Value Function Update Magnitude: 0.51980

Collected Steps per Second: 22,441.54656
Overall Steps per Second: 10,439.89068

Timestep Collection Time: 2.22828
Timestep Consumption Time: 2.56162
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.78990

Cumulative Model Updates: 138,822
Cumulative Timesteps: 1,157,813,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1157813030...
Checkpoint 1157813030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.54793
Policy Entropy: 3.13087
Value Function Loss: 0.00388

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.57621
Value Function Update Magnitude: 0.51366

Collected Steps per Second: 22,021.78821
Overall Steps per Second: 10,508.84744

Timestep Collection Time: 2.27166
Timestep Consumption Time: 2.48871
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.76037

Cumulative Model Updates: 138,828
Cumulative Timesteps: 1,157,863,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,255.20327
Policy Entropy: 3.12638
Value Function Loss: 0.00376

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.50699

Collected Steps per Second: 22,502.08924
Overall Steps per Second: 10,536.70401

Timestep Collection Time: 2.22246
Timestep Consumption Time: 2.52381
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.74627

Cumulative Model Updates: 138,834
Cumulative Timesteps: 1,157,913,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1157913066...
Checkpoint 1157913066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.37270
Policy Entropy: 3.10394
Value Function Loss: 0.00381

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.50584

Collected Steps per Second: 22,504.72899
Overall Steps per Second: 10,522.99145

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.52995
PPO Batch Consumption Time: 0.29879
Total Iteration Time: 4.75188

Cumulative Model Updates: 138,840
Cumulative Timesteps: 1,157,963,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.92938
Policy Entropy: 3.11879
Value Function Loss: 0.00393

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.51040

Collected Steps per Second: 22,492.09621
Overall Steps per Second: 10,620.50358

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.48626
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.71051

Cumulative Model Updates: 138,846
Cumulative Timesteps: 1,158,013,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1158013098...
Checkpoint 1158013098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.05585
Policy Entropy: 3.11653
Value Function Loss: 0.00452

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.59045
Value Function Update Magnitude: 0.49382

Collected Steps per Second: 22,220.78794
Overall Steps per Second: 10,626.61624

Timestep Collection Time: 2.25123
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.70743

Cumulative Model Updates: 138,852
Cumulative Timesteps: 1,158,063,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.33601
Policy Entropy: 3.12482
Value Function Loss: 0.00447

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.59140
Value Function Update Magnitude: 0.50112

Collected Steps per Second: 21,814.86964
Overall Steps per Second: 10,447.31082

Timestep Collection Time: 2.29302
Timestep Consumption Time: 2.49500
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.78803

Cumulative Model Updates: 138,858
Cumulative Timesteps: 1,158,113,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1158113144...
Checkpoint 1158113144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.31327
Policy Entropy: 3.12088
Value Function Loss: 0.00449

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.59489
Value Function Update Magnitude: 0.51319

Collected Steps per Second: 21,900.86634
Overall Steps per Second: 10,390.01467

Timestep Collection Time: 2.28475
Timestep Consumption Time: 2.53122
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.81597

Cumulative Model Updates: 138,864
Cumulative Timesteps: 1,158,163,182

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.51651
Policy Entropy: 3.13302
Value Function Loss: 0.00409

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.58792
Value Function Update Magnitude: 0.51863

Collected Steps per Second: 21,729.05703
Overall Steps per Second: 10,288.92189

Timestep Collection Time: 2.30245
Timestep Consumption Time: 2.56006
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.86251

Cumulative Model Updates: 138,870
Cumulative Timesteps: 1,158,213,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1158213212...
Checkpoint 1158213212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,994.93790
Policy Entropy: 3.13279
Value Function Loss: 0.00438

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.58774
Value Function Update Magnitude: 0.52082

Collected Steps per Second: 22,169.78428
Overall Steps per Second: 10,545.85871

Timestep Collection Time: 2.25532
Timestep Consumption Time: 2.48588
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.74120

Cumulative Model Updates: 138,876
Cumulative Timesteps: 1,158,263,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.46752
Policy Entropy: 3.13047
Value Function Loss: 0.00423

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.58785
Value Function Update Magnitude: 0.53340

Collected Steps per Second: 21,823.44675
Overall Steps per Second: 10,608.20105

Timestep Collection Time: 2.29194
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.71503

Cumulative Model Updates: 138,882
Cumulative Timesteps: 1,158,313,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1158313230...
Checkpoint 1158313230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.97812
Policy Entropy: 3.11586
Value Function Loss: 0.00433

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.58796
Value Function Update Magnitude: 0.54277

Collected Steps per Second: 22,211.88508
Overall Steps per Second: 10,610.82325

Timestep Collection Time: 2.25186
Timestep Consumption Time: 2.46201
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.71387

Cumulative Model Updates: 138,888
Cumulative Timesteps: 1,158,363,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,865.66878
Policy Entropy: 3.11924
Value Function Loss: 0.00415

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.58366
Value Function Update Magnitude: 0.51692

Collected Steps per Second: 22,544.86192
Overall Steps per Second: 10,429.22533

Timestep Collection Time: 2.21904
Timestep Consumption Time: 2.57786
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.79690

Cumulative Model Updates: 138,894
Cumulative Timesteps: 1,158,413,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1158413276...
Checkpoint 1158413276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.95107
Policy Entropy: 3.10497
Value Function Loss: 0.00439

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.57964
Value Function Update Magnitude: 0.49369

Collected Steps per Second: 21,785.23687
Overall Steps per Second: 10,211.79709

Timestep Collection Time: 2.29577
Timestep Consumption Time: 2.60189
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.89767

Cumulative Model Updates: 138,900
Cumulative Timesteps: 1,158,463,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.92865
Policy Entropy: 3.11517
Value Function Loss: 0.00441

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.58436
Value Function Update Magnitude: 0.49997

Collected Steps per Second: 22,427.05009
Overall Steps per Second: 10,452.30397

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.55459
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.78440

Cumulative Model Updates: 138,906
Cumulative Timesteps: 1,158,513,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1158513298...
Checkpoint 1158513298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.57590
Policy Entropy: 3.11455
Value Function Loss: 0.00452

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.59143
Value Function Update Magnitude: 0.52256

Collected Steps per Second: 22,305.79585
Overall Steps per Second: 10,627.90552

Timestep Collection Time: 2.24175
Timestep Consumption Time: 2.46322
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.70497

Cumulative Model Updates: 138,912
Cumulative Timesteps: 1,158,563,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.13142
Policy Entropy: 3.12477
Value Function Loss: 0.00426

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.59210
Value Function Update Magnitude: 0.52902

Collected Steps per Second: 22,698.51478
Overall Steps per Second: 10,450.54472

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.58258
PPO Batch Consumption Time: 0.30748
Total Iteration Time: 4.78616

Cumulative Model Updates: 138,918
Cumulative Timesteps: 1,158,613,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1158613320...
Checkpoint 1158613320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.44426
Policy Entropy: 3.12707
Value Function Loss: 0.00392

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.58248
Value Function Update Magnitude: 0.52947

Collected Steps per Second: 22,057.86861
Overall Steps per Second: 10,577.20922

Timestep Collection Time: 2.26767
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.72904

Cumulative Model Updates: 138,924
Cumulative Timesteps: 1,158,663,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.53662
Policy Entropy: 3.13577
Value Function Loss: 0.00371

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.50529

Collected Steps per Second: 22,661.44627
Overall Steps per Second: 10,568.70923

Timestep Collection Time: 2.20780
Timestep Consumption Time: 2.52617
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.73397

Cumulative Model Updates: 138,930
Cumulative Timesteps: 1,158,713,372

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1158713372...
Checkpoint 1158713372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.17291
Policy Entropy: 3.13610
Value Function Loss: 0.00382

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.48364

Collected Steps per Second: 22,587.66379
Overall Steps per Second: 10,580.37896

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.72800

Cumulative Model Updates: 138,936
Cumulative Timesteps: 1,158,763,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.51175
Policy Entropy: 3.12756
Value Function Loss: 0.00392

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.49321

Collected Steps per Second: 21,792.48030
Overall Steps per Second: 10,459.69213

Timestep Collection Time: 2.29510
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.78179

Cumulative Model Updates: 138,942
Cumulative Timesteps: 1,158,813,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1158813412...
Checkpoint 1158813412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.51171
Policy Entropy: 3.12256
Value Function Loss: 0.00391

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.52243

Collected Steps per Second: 22,158.08610
Overall Steps per Second: 10,569.70396

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.47419
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.73088

Cumulative Model Updates: 138,948
Cumulative Timesteps: 1,158,863,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.80679
Policy Entropy: 3.12726
Value Function Loss: 0.00399

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.57680
Value Function Update Magnitude: 0.54152

Collected Steps per Second: 22,160.99670
Overall Steps per Second: 10,587.55826

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.46710
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.72404

Cumulative Model Updates: 138,954
Cumulative Timesteps: 1,158,913,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1158913432...
Checkpoint 1158913432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,638.50881
Policy Entropy: 3.12782
Value Function Loss: 0.00427

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.58332
Value Function Update Magnitude: 0.54254

Collected Steps per Second: 22,118.98281
Overall Steps per Second: 10,529.64324

Timestep Collection Time: 2.26150
Timestep Consumption Time: 2.48909
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.75059

Cumulative Model Updates: 138,960
Cumulative Timesteps: 1,158,963,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.40818
Policy Entropy: 3.12445
Value Function Loss: 0.00434

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.58583
Value Function Update Magnitude: 0.54322

Collected Steps per Second: 22,564.89539
Overall Steps per Second: 10,541.13255

Timestep Collection Time: 2.21627
Timestep Consumption Time: 2.52800
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.74427

Cumulative Model Updates: 138,966
Cumulative Timesteps: 1,159,013,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1159013464...
Checkpoint 1159013464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.27261
Policy Entropy: 3.11840
Value Function Loss: 0.00438

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.58845
Value Function Update Magnitude: 0.55320

Collected Steps per Second: 21,591.81884
Overall Steps per Second: 10,361.71826

Timestep Collection Time: 2.31569
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.82545

Cumulative Model Updates: 138,972
Cumulative Timesteps: 1,159,063,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.64933
Policy Entropy: 3.11476
Value Function Loss: 0.00419

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.59270
Value Function Update Magnitude: 0.52462

Collected Steps per Second: 22,343.65574
Overall Steps per Second: 10,612.30049

Timestep Collection Time: 2.23795
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.71189

Cumulative Model Updates: 138,978
Cumulative Timesteps: 1,159,113,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1159113468...
Checkpoint 1159113468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,184.57207
Policy Entropy: 3.12652
Value Function Loss: 0.00425

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.58710
Value Function Update Magnitude: 0.49865

Collected Steps per Second: 22,326.05701
Overall Steps per Second: 10,544.59489

Timestep Collection Time: 2.24061
Timestep Consumption Time: 2.50343
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.74404

Cumulative Model Updates: 138,984
Cumulative Timesteps: 1,159,163,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.07649
Policy Entropy: 3.13340
Value Function Loss: 0.00444

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.57835
Value Function Update Magnitude: 0.48786

Collected Steps per Second: 22,500.57527
Overall Steps per Second: 10,583.91172

Timestep Collection Time: 2.22288
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.72566

Cumulative Model Updates: 138,990
Cumulative Timesteps: 1,159,213,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1159213508...
Checkpoint 1159213508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.24098
Policy Entropy: 3.12257
Value Function Loss: 0.00442

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.48951

Collected Steps per Second: 22,271.54935
Overall Steps per Second: 10,402.86558

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.56289
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 4.80925

Cumulative Model Updates: 138,996
Cumulative Timesteps: 1,159,263,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.38571
Policy Entropy: 3.10629
Value Function Loss: 0.00441

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.48573

Collected Steps per Second: 22,874.34018
Overall Steps per Second: 10,656.45148

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.50614
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.69199

Cumulative Model Updates: 139,002
Cumulative Timesteps: 1,159,313,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1159313538...
Checkpoint 1159313538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.45962
Policy Entropy: 3.10878
Value Function Loss: 0.00442

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.49571

Collected Steps per Second: 22,228.95279
Overall Steps per Second: 10,437.61207

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.54156
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.79133

Cumulative Model Updates: 139,008
Cumulative Timesteps: 1,159,363,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.19508
Policy Entropy: 3.12019
Value Function Loss: 0.00456

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.58441
Value Function Update Magnitude: 0.51852

Collected Steps per Second: 21,941.28769
Overall Steps per Second: 10,338.88719

Timestep Collection Time: 2.27981
Timestep Consumption Time: 2.55843
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.83824

Cumulative Model Updates: 139,014
Cumulative Timesteps: 1,159,413,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1159413570...
Checkpoint 1159413570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.84608
Policy Entropy: 3.12761
Value Function Loss: 0.00444

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.58466
Value Function Update Magnitude: 0.53800

Collected Steps per Second: 21,704.10610
Overall Steps per Second: 10,290.18990

Timestep Collection Time: 2.30399
Timestep Consumption Time: 2.55559
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.85958

Cumulative Model Updates: 139,020
Cumulative Timesteps: 1,159,463,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.95087
Policy Entropy: 3.12741
Value Function Loss: 0.00452

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.58781
Value Function Update Magnitude: 0.54448

Collected Steps per Second: 22,040.27188
Overall Steps per Second: 10,352.55762

Timestep Collection Time: 2.26930
Timestep Consumption Time: 2.56197
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.83127

Cumulative Model Updates: 139,026
Cumulative Timesteps: 1,159,513,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1159513592...
Checkpoint 1159513592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.80364
Policy Entropy: 3.13834
Value Function Loss: 0.00400

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.58081
Value Function Update Magnitude: 0.55807

Collected Steps per Second: 21,732.44116
Overall Steps per Second: 10,353.93911

Timestep Collection Time: 2.30089
Timestep Consumption Time: 2.52857
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.82947

Cumulative Model Updates: 139,032
Cumulative Timesteps: 1,159,563,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,218.27605
Policy Entropy: 3.13618
Value Function Loss: 0.00409

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.57140
Value Function Update Magnitude: 0.53436

Collected Steps per Second: 21,920.95796
Overall Steps per Second: 10,334.62401

Timestep Collection Time: 2.28138
Timestep Consumption Time: 2.55769
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.83907

Cumulative Model Updates: 139,038
Cumulative Timesteps: 1,159,613,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1159613606...
Checkpoint 1159613606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.61005
Policy Entropy: 3.13884
Value Function Loss: 0.00405

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.50989

Collected Steps per Second: 21,990.53523
Overall Steps per Second: 10,577.25770

Timestep Collection Time: 2.27416
Timestep Consumption Time: 2.45391
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.72807

Cumulative Model Updates: 139,044
Cumulative Timesteps: 1,159,663,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.51264
Policy Entropy: 3.13884
Value Function Loss: 0.00408

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.56179
Value Function Update Magnitude: 0.50231

Collected Steps per Second: 22,609.22378
Overall Steps per Second: 10,476.27128

Timestep Collection Time: 2.21193
Timestep Consumption Time: 2.56172
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.77364

Cumulative Model Updates: 139,050
Cumulative Timesteps: 1,159,713,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1159713626...
Checkpoint 1159713626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,146.90558
Policy Entropy: 3.14907
Value Function Loss: 0.00394

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.56427
Value Function Update Magnitude: 0.49754

Collected Steps per Second: 22,355.82206
Overall Steps per Second: 10,518.61211

Timestep Collection Time: 2.23763
Timestep Consumption Time: 2.51813
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.75576

Cumulative Model Updates: 139,056
Cumulative Timesteps: 1,159,763,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.94199
Policy Entropy: 3.14866
Value Function Loss: 0.00379

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.49658

Collected Steps per Second: 22,792.56551
Overall Steps per Second: 10,599.70366

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.52412
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.71843

Cumulative Model Updates: 139,062
Cumulative Timesteps: 1,159,813,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1159813664...
Checkpoint 1159813664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,204.36152
Policy Entropy: 3.15147
Value Function Loss: 0.00395

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.51536

Collected Steps per Second: 22,460.90772
Overall Steps per Second: 10,634.26984

Timestep Collection Time: 2.22689
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.70347

Cumulative Model Updates: 139,068
Cumulative Timesteps: 1,159,863,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.46189
Policy Entropy: 3.15054
Value Function Loss: 0.00382

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.53726

Collected Steps per Second: 22,850.06386
Overall Steps per Second: 10,451.67090

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.59616
PPO Batch Consumption Time: 0.30504
Total Iteration Time: 4.78469

Cumulative Model Updates: 139,074
Cumulative Timesteps: 1,159,913,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1159913690...
Checkpoint 1159913690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.26001
Policy Entropy: 3.14722
Value Function Loss: 0.00383

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.56340
Value Function Update Magnitude: 0.51496

Collected Steps per Second: 22,106.25650
Overall Steps per Second: 10,396.89744

Timestep Collection Time: 2.26253
Timestep Consumption Time: 2.54814
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.81067

Cumulative Model Updates: 139,080
Cumulative Timesteps: 1,159,963,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.27263
Policy Entropy: 3.12576
Value Function Loss: 0.00396

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.51425

Collected Steps per Second: 22,825.19515
Overall Steps per Second: 10,728.67270

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.47083
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.66227

Cumulative Model Updates: 139,086
Cumulative Timesteps: 1,160,013,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1160013726...
Checkpoint 1160013726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,391.70440
Policy Entropy: 3.12674
Value Function Loss: 0.00407

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.56215
Value Function Update Magnitude: 0.51449

Collected Steps per Second: 21,451.05501
Overall Steps per Second: 10,234.55240

Timestep Collection Time: 2.33145
Timestep Consumption Time: 2.55514
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.88658

Cumulative Model Updates: 139,092
Cumulative Timesteps: 1,160,063,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.10676
Policy Entropy: 3.12170
Value Function Loss: 0.00427

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.49570

Collected Steps per Second: 22,521.05579
Overall Steps per Second: 10,475.25582

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.55331
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.77373

Cumulative Model Updates: 139,098
Cumulative Timesteps: 1,160,113,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1160113744...
Checkpoint 1160113744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.19747
Policy Entropy: 3.12183
Value Function Loss: 0.00423

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.49552

Collected Steps per Second: 21,746.97512
Overall Steps per Second: 10,554.03270

Timestep Collection Time: 2.30009
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.73942

Cumulative Model Updates: 139,104
Cumulative Timesteps: 1,160,163,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.88962
Policy Entropy: 3.12751
Value Function Loss: 0.00410

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.47939

Collected Steps per Second: 21,904.24290
Overall Steps per Second: 10,489.41448

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.48435
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.76728

Cumulative Model Updates: 139,110
Cumulative Timesteps: 1,160,213,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1160213770...
Checkpoint 1160213770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.89413
Policy Entropy: 3.13343
Value Function Loss: 0.00409

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.56084
Value Function Update Magnitude: 0.48967

Collected Steps per Second: 21,955.52015
Overall Steps per Second: 10,550.38814

Timestep Collection Time: 2.27879
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.74220

Cumulative Model Updates: 139,116
Cumulative Timesteps: 1,160,263,802

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.06594
Policy Entropy: 3.14675
Value Function Loss: 0.00405

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.56027
Value Function Update Magnitude: 0.50434

Collected Steps per Second: 22,183.36519
Overall Steps per Second: 10,474.10386

Timestep Collection Time: 2.25493
Timestep Consumption Time: 2.52085
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.77578

Cumulative Model Updates: 139,122
Cumulative Timesteps: 1,160,313,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1160313824...
Checkpoint 1160313824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.05340
Policy Entropy: 3.13334
Value Function Loss: 0.00412

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.50504

Collected Steps per Second: 21,614.82666
Overall Steps per Second: 10,271.25146

Timestep Collection Time: 2.31332
Timestep Consumption Time: 2.55483
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.86815

Cumulative Model Updates: 139,128
Cumulative Timesteps: 1,160,363,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923.35446
Policy Entropy: 3.12442
Value Function Loss: 0.00433

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.51258

Collected Steps per Second: 21,853.32388
Overall Steps per Second: 10,525.67645

Timestep Collection Time: 2.28862
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.75162

Cumulative Model Updates: 139,134
Cumulative Timesteps: 1,160,413,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1160413840...
Checkpoint 1160413840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.12039
Policy Entropy: 3.10495
Value Function Loss: 0.00438

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.59958
Value Function Update Magnitude: 0.52094

Collected Steps per Second: 21,846.21473
Overall Steps per Second: 10,477.33856

Timestep Collection Time: 2.29019
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.77526

Cumulative Model Updates: 139,140
Cumulative Timesteps: 1,160,463,872

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.91215
Policy Entropy: 3.09543
Value Function Loss: 0.00444

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.60814
Value Function Update Magnitude: 0.53873

Collected Steps per Second: 22,202.38714
Overall Steps per Second: 10,580.92471

Timestep Collection Time: 2.25291
Timestep Consumption Time: 2.47446
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.72738

Cumulative Model Updates: 139,146
Cumulative Timesteps: 1,160,513,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1160513892...
Checkpoint 1160513892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.22058
Policy Entropy: 3.09998
Value Function Loss: 0.00430

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.59241
Value Function Update Magnitude: 0.54837

Collected Steps per Second: 22,322.27628
Overall Steps per Second: 10,227.11118

Timestep Collection Time: 2.24081
Timestep Consumption Time: 2.65011
PPO Batch Consumption Time: 0.31142
Total Iteration Time: 4.89092

Cumulative Model Updates: 139,152
Cumulative Timesteps: 1,160,563,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,571.58820
Policy Entropy: 3.10591
Value Function Loss: 0.00419

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.59056
Value Function Update Magnitude: 0.55190

Collected Steps per Second: 21,427.33873
Overall Steps per Second: 10,393.00250

Timestep Collection Time: 2.33403
Timestep Consumption Time: 2.47806
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.81208

Cumulative Model Updates: 139,158
Cumulative Timesteps: 1,160,613,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1160613924...
Checkpoint 1160613924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.65421
Policy Entropy: 3.10764
Value Function Loss: 0.00432

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.59757
Value Function Update Magnitude: 0.55778

Collected Steps per Second: 22,032.17150
Overall Steps per Second: 10,635.55333

Timestep Collection Time: 2.26950
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.70140

Cumulative Model Updates: 139,164
Cumulative Timesteps: 1,160,663,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.72195
Policy Entropy: 3.11368
Value Function Loss: 0.00434

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.59097
Value Function Update Magnitude: 0.55900

Collected Steps per Second: 22,976.10021
Overall Steps per Second: 10,629.95369

Timestep Collection Time: 2.17626
Timestep Consumption Time: 2.52762
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.70388

Cumulative Model Updates: 139,170
Cumulative Timesteps: 1,160,713,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1160713928...
Checkpoint 1160713928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.63409
Policy Entropy: 3.10884
Value Function Loss: 0.00436

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.58622
Value Function Update Magnitude: 0.54927

Collected Steps per Second: 22,264.55910
Overall Steps per Second: 10,546.11248

Timestep Collection Time: 2.24590
Timestep Consumption Time: 2.49556
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.74146

Cumulative Model Updates: 139,176
Cumulative Timesteps: 1,160,763,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.76704
Policy Entropy: 3.12298
Value Function Loss: 0.00426

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.58909
Value Function Update Magnitude: 0.54252

Collected Steps per Second: 22,666.81093
Overall Steps per Second: 10,608.25744

Timestep Collection Time: 2.20710
Timestep Consumption Time: 2.50885
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.71595

Cumulative Model Updates: 139,182
Cumulative Timesteps: 1,160,813,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1160813960...
Checkpoint 1160813960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.64585
Policy Entropy: 3.12520
Value Function Loss: 0.00414

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.59096
Value Function Update Magnitude: 0.53069

Collected Steps per Second: 23,048.01467
Overall Steps per Second: 10,841.42878

Timestep Collection Time: 2.16956
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.61231

Cumulative Model Updates: 139,188
Cumulative Timesteps: 1,160,863,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.52948
Policy Entropy: 3.13831
Value Function Loss: 0.00378

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.57580
Value Function Update Magnitude: 0.51652

Collected Steps per Second: 22,048.65537
Overall Steps per Second: 10,543.63616

Timestep Collection Time: 2.26789
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.74258

Cumulative Model Updates: 139,194
Cumulative Timesteps: 1,160,913,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1160913968...
Checkpoint 1160913968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.61214
Policy Entropy: 3.13689
Value Function Loss: 0.00361

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.49415

Collected Steps per Second: 21,872.49093
Overall Steps per Second: 10,558.77508

Timestep Collection Time: 2.28671
Timestep Consumption Time: 2.45021
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.73691

Cumulative Model Updates: 139,200
Cumulative Timesteps: 1,160,963,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.71790
Policy Entropy: 3.11939
Value Function Loss: 0.00411

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.57523
Value Function Update Magnitude: 0.47934

Collected Steps per Second: 21,982.35505
Overall Steps per Second: 10,605.92400

Timestep Collection Time: 2.27537
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.71604

Cumulative Model Updates: 139,206
Cumulative Timesteps: 1,161,014,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1161014002...
Checkpoint 1161014002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.64476
Policy Entropy: 3.11946
Value Function Loss: 0.00442

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.58769
Value Function Update Magnitude: 0.48619

Collected Steps per Second: 21,989.14564
Overall Steps per Second: 10,544.28073

Timestep Collection Time: 2.27512
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.74456

Cumulative Model Updates: 139,212
Cumulative Timesteps: 1,161,064,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.74379
Policy Entropy: 3.12236
Value Function Loss: 0.00444

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.57973
Value Function Update Magnitude: 0.49717

Collected Steps per Second: 22,978.00052
Overall Steps per Second: 10,528.56176

Timestep Collection Time: 2.17626
Timestep Consumption Time: 2.57330
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.74956

Cumulative Model Updates: 139,218
Cumulative Timesteps: 1,161,114,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1161114036...
Checkpoint 1161114036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.01508
Policy Entropy: 3.13181
Value Function Loss: 0.00464

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.51427

Collected Steps per Second: 22,638.78815
Overall Steps per Second: 10,577.10354

Timestep Collection Time: 2.20984
Timestep Consumption Time: 2.52000
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.72984

Cumulative Model Updates: 139,224
Cumulative Timesteps: 1,161,164,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.43540
Policy Entropy: 3.12652
Value Function Loss: 0.00466

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.55486

Collected Steps per Second: 22,776.15738
Overall Steps per Second: 10,849.06128

Timestep Collection Time: 2.19589
Timestep Consumption Time: 2.41409
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.60998

Cumulative Model Updates: 139,230
Cumulative Timesteps: 1,161,214,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1161214078...
Checkpoint 1161214078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.82092
Policy Entropy: 3.12472
Value Function Loss: 0.00451

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.60110
Value Function Update Magnitude: 0.55645

Collected Steps per Second: 22,632.66920
Overall Steps per Second: 10,794.01416

Timestep Collection Time: 2.20920
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63220

Cumulative Model Updates: 139,236
Cumulative Timesteps: 1,161,264,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.54662
Policy Entropy: 3.11890
Value Function Loss: 0.00441

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.59612
Value Function Update Magnitude: 0.54872

Collected Steps per Second: 22,946.73802
Overall Steps per Second: 10,858.33084

Timestep Collection Time: 2.17905
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.60494

Cumulative Model Updates: 139,242
Cumulative Timesteps: 1,161,314,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1161314080...
Checkpoint 1161314080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.18490
Policy Entropy: 3.12448
Value Function Loss: 0.00448

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.59371
Value Function Update Magnitude: 0.54529

Collected Steps per Second: 22,851.77107
Overall Steps per Second: 10,683.73649

Timestep Collection Time: 2.18836
Timestep Consumption Time: 2.49240
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.68076

Cumulative Model Updates: 139,248
Cumulative Timesteps: 1,161,364,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.30644
Policy Entropy: 3.11010
Value Function Loss: 0.00473

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.60184
Value Function Update Magnitude: 0.52694

Collected Steps per Second: 22,426.65320
Overall Steps per Second: 10,598.09769

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71915

Cumulative Model Updates: 139,254
Cumulative Timesteps: 1,161,414,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1161414102...
Checkpoint 1161414102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,778.91424
Policy Entropy: 3.12424
Value Function Loss: 0.00470

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.61126
Value Function Update Magnitude: 0.52754

Collected Steps per Second: 22,587.08598
Overall Steps per Second: 10,783.35539

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.63919

Cumulative Model Updates: 139,260
Cumulative Timesteps: 1,161,464,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.70692
Policy Entropy: 3.12436
Value Function Loss: 0.00516

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.61754
Value Function Update Magnitude: 0.57074

Collected Steps per Second: 22,157.74403
Overall Steps per Second: 10,547.97051

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.48400
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.74082

Cumulative Model Updates: 139,266
Cumulative Timesteps: 1,161,514,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1161514134...
Checkpoint 1161514134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.04543
Policy Entropy: 3.13959
Value Function Loss: 0.00508

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.61523
Value Function Update Magnitude: 0.59435

Collected Steps per Second: 22,376.21640
Overall Steps per Second: 10,624.27763

Timestep Collection Time: 2.23541
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.70808

Cumulative Model Updates: 139,272
Cumulative Timesteps: 1,161,564,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.15197
Policy Entropy: 3.14295
Value Function Loss: 0.00491

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.60799
Value Function Update Magnitude: 0.59490

Collected Steps per Second: 22,621.97284
Overall Steps per Second: 10,630.98145

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70568

Cumulative Model Updates: 139,278
Cumulative Timesteps: 1,161,614,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1161614180...
Checkpoint 1161614180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,984.72301
Policy Entropy: 3.13702
Value Function Loss: 0.00460

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.59858
Value Function Update Magnitude: 0.58721

Collected Steps per Second: 22,958.76362
Overall Steps per Second: 10,587.21747

Timestep Collection Time: 2.17904
Timestep Consumption Time: 2.54628
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.72532

Cumulative Model Updates: 139,284
Cumulative Timesteps: 1,161,664,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.70099
Policy Entropy: 3.13839
Value Function Loss: 0.00434

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.59635
Value Function Update Magnitude: 0.58922

Collected Steps per Second: 23,005.46671
Overall Steps per Second: 10,775.41435

Timestep Collection Time: 2.17348
Timestep Consumption Time: 2.46689
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.64038

Cumulative Model Updates: 139,290
Cumulative Timesteps: 1,161,714,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1161714210...
Checkpoint 1161714210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.34893
Policy Entropy: 3.13161
Value Function Loss: 0.00429

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.58504
Value Function Update Magnitude: 0.59839

Collected Steps per Second: 22,554.20763
Overall Steps per Second: 10,667.97790

Timestep Collection Time: 2.21706
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.68730

Cumulative Model Updates: 139,296
Cumulative Timesteps: 1,161,764,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.05617
Policy Entropy: 3.14217
Value Function Loss: 0.00466

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.59617
Value Function Update Magnitude: 0.60471

Collected Steps per Second: 23,233.05773
Overall Steps per Second: 10,957.53433

Timestep Collection Time: 2.15305
Timestep Consumption Time: 2.41203
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.56508

Cumulative Model Updates: 139,302
Cumulative Timesteps: 1,161,814,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1161814236...
Checkpoint 1161814236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.35325
Policy Entropy: 3.14271
Value Function Loss: 0.00459

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.60017
Value Function Update Magnitude: 0.60623

Collected Steps per Second: 22,786.89971
Overall Steps per Second: 10,632.73466

Timestep Collection Time: 2.19486
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.70378

Cumulative Model Updates: 139,308
Cumulative Timesteps: 1,161,864,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,638.24167
Policy Entropy: 3.13425
Value Function Loss: 0.00453

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.60065
Value Function Update Magnitude: 0.58559

Collected Steps per Second: 22,752.05307
Overall Steps per Second: 10,727.12292

Timestep Collection Time: 2.19813
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.66220

Cumulative Model Updates: 139,314
Cumulative Timesteps: 1,161,914,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1161914262...
Checkpoint 1161914262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.16409
Policy Entropy: 3.11102
Value Function Loss: 0.00457

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.60675
Value Function Update Magnitude: 0.56435

Collected Steps per Second: 22,212.75017
Overall Steps per Second: 10,708.77635

Timestep Collection Time: 2.25177
Timestep Consumption Time: 2.41898
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.67075

Cumulative Model Updates: 139,320
Cumulative Timesteps: 1,161,964,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.51383
Policy Entropy: 3.10104
Value Function Loss: 0.00448

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.61363
Value Function Update Magnitude: 0.54740

Collected Steps per Second: 22,178.33573
Overall Steps per Second: 10,523.90725

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.75109

Cumulative Model Updates: 139,326
Cumulative Timesteps: 1,162,014,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1162014280...
Checkpoint 1162014280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.21581
Policy Entropy: 3.09933
Value Function Loss: 0.00421

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.60465
Value Function Update Magnitude: 0.52628

Collected Steps per Second: 21,875.59041
Overall Steps per Second: 10,594.89169

Timestep Collection Time: 2.28602
Timestep Consumption Time: 2.43399
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.72001

Cumulative Model Updates: 139,332
Cumulative Timesteps: 1,162,064,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.13079
Policy Entropy: 3.10866
Value Function Loss: 0.00427

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.50860

Collected Steps per Second: 22,204.60361
Overall Steps per Second: 10,520.64509

Timestep Collection Time: 2.25242
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.75389

Cumulative Model Updates: 139,338
Cumulative Timesteps: 1,162,114,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1162114302...
Checkpoint 1162114302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,457.94806
Policy Entropy: 3.09918
Value Function Loss: 0.00423

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.59622
Value Function Update Magnitude: 0.52056

Collected Steps per Second: 22,565.50215
Overall Steps per Second: 10,612.39994

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.49650
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.71298

Cumulative Model Updates: 139,344
Cumulative Timesteps: 1,162,164,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.52036
Policy Entropy: 3.09624
Value Function Loss: 0.00448

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.59702
Value Function Update Magnitude: 0.55123

Collected Steps per Second: 22,806.00200
Overall Steps per Second: 10,682.63599

Timestep Collection Time: 2.19276
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.68124

Cumulative Model Updates: 139,350
Cumulative Timesteps: 1,162,214,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1162214326...
Checkpoint 1162214326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.94950
Policy Entropy: 3.09462
Value Function Loss: 0.00442

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.60402
Value Function Update Magnitude: 0.56934

Collected Steps per Second: 21,942.50695
Overall Steps per Second: 10,439.67244

Timestep Collection Time: 2.27868
Timestep Consumption Time: 2.51074
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.78942

Cumulative Model Updates: 139,356
Cumulative Timesteps: 1,162,264,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.24214
Policy Entropy: 3.10250
Value Function Loss: 0.00465

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.60561
Value Function Update Magnitude: 0.56556

Collected Steps per Second: 22,648.05357
Overall Steps per Second: 10,779.25598

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.64002

Cumulative Model Updates: 139,362
Cumulative Timesteps: 1,162,314,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1162314342...
Checkpoint 1162314342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.73103
Policy Entropy: 3.10801
Value Function Loss: 0.00447

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.60022
Value Function Update Magnitude: 0.55106

Collected Steps per Second: 22,343.55226
Overall Steps per Second: 10,664.57519

Timestep Collection Time: 2.23904
Timestep Consumption Time: 2.45201
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.69104

Cumulative Model Updates: 139,368
Cumulative Timesteps: 1,162,364,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.50805
Policy Entropy: 3.10935
Value Function Loss: 0.00467

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.59747
Value Function Update Magnitude: 0.54487

Collected Steps per Second: 22,744.47962
Overall Steps per Second: 10,553.71950

Timestep Collection Time: 2.19851
Timestep Consumption Time: 2.53953
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.73805

Cumulative Model Updates: 139,374
Cumulative Timesteps: 1,162,414,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1162414374...
Checkpoint 1162414374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.75056
Policy Entropy: 3.10668
Value Function Loss: 0.00465

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.59890
Value Function Update Magnitude: 0.55257

Collected Steps per Second: 22,974.46515
Overall Steps per Second: 10,643.05467

Timestep Collection Time: 2.17694
Timestep Consumption Time: 2.52228
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.69921

Cumulative Model Updates: 139,380
Cumulative Timesteps: 1,162,464,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.08163
Policy Entropy: 3.11151
Value Function Loss: 0.00490

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.61524
Value Function Update Magnitude: 0.57358

Collected Steps per Second: 22,638.80447
Overall Steps per Second: 10,746.88024

Timestep Collection Time: 2.20922
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.65382

Cumulative Model Updates: 139,386
Cumulative Timesteps: 1,162,514,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1162514402...
Checkpoint 1162514402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.19538
Policy Entropy: 3.10436
Value Function Loss: 0.00460

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.61178
Value Function Update Magnitude: 0.56605

Collected Steps per Second: 22,753.43709
Overall Steps per Second: 10,784.98953

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.63644

Cumulative Model Updates: 139,392
Cumulative Timesteps: 1,162,564,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.74763
Policy Entropy: 3.11024
Value Function Loss: 0.00437

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.59739
Value Function Update Magnitude: 0.53126

Collected Steps per Second: 22,872.64699
Overall Steps per Second: 10,796.85909

Timestep Collection Time: 2.18707
Timestep Consumption Time: 2.44613
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.63320

Cumulative Model Updates: 139,398
Cumulative Timesteps: 1,162,614,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1162614430...
Checkpoint 1162614430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.13742
Policy Entropy: 3.09858
Value Function Loss: 0.00450

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.59033
Value Function Update Magnitude: 0.51687

Collected Steps per Second: 23,080.91114
Overall Steps per Second: 10,744.58902

Timestep Collection Time: 2.16647
Timestep Consumption Time: 2.48741
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.65388

Cumulative Model Updates: 139,404
Cumulative Timesteps: 1,162,664,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.45723
Policy Entropy: 3.10838
Value Function Loss: 0.00424

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.58844
Value Function Update Magnitude: 0.51569

Collected Steps per Second: 22,288.09601
Overall Steps per Second: 10,579.32237

Timestep Collection Time: 2.24443
Timestep Consumption Time: 2.48404
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.72847

Cumulative Model Updates: 139,410
Cumulative Timesteps: 1,162,714,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1162714458...
Checkpoint 1162714458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.17403
Policy Entropy: 3.10073
Value Function Loss: 0.00462

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.59631
Value Function Update Magnitude: 0.51711

Collected Steps per Second: 22,395.60728
Overall Steps per Second: 10,527.39013

Timestep Collection Time: 2.23330
Timestep Consumption Time: 2.51774
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.75104

Cumulative Model Updates: 139,416
Cumulative Timesteps: 1,162,764,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.75928
Policy Entropy: 3.11754
Value Function Loss: 0.00500

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.61805
Value Function Update Magnitude: 0.55751

Collected Steps per Second: 22,622.55091
Overall Steps per Second: 10,534.50705

Timestep Collection Time: 2.21142
Timestep Consumption Time: 2.53754
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.74896

Cumulative Model Updates: 139,422
Cumulative Timesteps: 1,162,814,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1162814502...
Checkpoint 1162814502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,331.32679
Policy Entropy: 3.13383
Value Function Loss: 0.00482

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.60871
Value Function Update Magnitude: 0.58750

Collected Steps per Second: 21,402.64267
Overall Steps per Second: 10,272.86660

Timestep Collection Time: 2.33635
Timestep Consumption Time: 2.53123
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.86758

Cumulative Model Updates: 139,428
Cumulative Timesteps: 1,162,864,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.99279
Policy Entropy: 3.13683
Value Function Loss: 0.00504

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.60249
Value Function Update Magnitude: 0.57495

Collected Steps per Second: 21,420.68447
Overall Steps per Second: 10,284.20275

Timestep Collection Time: 2.33550
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.86455

Cumulative Model Updates: 139,434
Cumulative Timesteps: 1,162,914,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1162914534...
Checkpoint 1162914534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.73665
Policy Entropy: 3.13817
Value Function Loss: 0.00474

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.59749
Value Function Update Magnitude: 0.55714

Collected Steps per Second: 21,820.18856
Overall Steps per Second: 10,438.91864

Timestep Collection Time: 2.29191
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.79073

Cumulative Model Updates: 139,440
Cumulative Timesteps: 1,162,964,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.79299
Policy Entropy: 3.12394
Value Function Loss: 0.00477

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.59157
Value Function Update Magnitude: 0.55965

Collected Steps per Second: 22,613.06976
Overall Steps per Second: 10,694.30261

Timestep Collection Time: 2.21235
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.67800

Cumulative Model Updates: 139,446
Cumulative Timesteps: 1,163,014,572

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1163014572...
Checkpoint 1163014572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.93392
Policy Entropy: 3.13977
Value Function Loss: 0.00411

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.57785
Value Function Update Magnitude: 0.53534

Collected Steps per Second: 22,674.35627
Overall Steps per Second: 10,638.05122

Timestep Collection Time: 2.20566
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.70124

Cumulative Model Updates: 139,452
Cumulative Timesteps: 1,163,064,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.72194
Policy Entropy: 3.14566
Value Function Loss: 0.00428

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.55749
Value Function Update Magnitude: 0.49327

Collected Steps per Second: 22,838.25523
Overall Steps per Second: 10,797.89699

Timestep Collection Time: 2.18931
Timestep Consumption Time: 2.44122
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.63053

Cumulative Model Updates: 139,458
Cumulative Timesteps: 1,163,114,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1163114584...
Checkpoint 1163114584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.75915
Policy Entropy: 3.14005
Value Function Loss: 0.00436

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.48751

Collected Steps per Second: 22,871.64235
Overall Steps per Second: 10,723.71481

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.47704
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.66368

Cumulative Model Updates: 139,464
Cumulative Timesteps: 1,163,164,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,702.46465
Policy Entropy: 3.14046
Value Function Loss: 0.00416

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.57457
Value Function Update Magnitude: 0.50376

Collected Steps per Second: 23,063.17540
Overall Steps per Second: 10,793.55530

Timestep Collection Time: 2.16848
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.63351

Cumulative Model Updates: 139,470
Cumulative Timesteps: 1,163,214,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1163214608...
Checkpoint 1163214608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532.02091
Policy Entropy: 3.13518
Value Function Loss: 0.00416

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.57405
Value Function Update Magnitude: 0.52428

Collected Steps per Second: 22,945.14267
Overall Steps per Second: 10,805.58922

Timestep Collection Time: 2.17946
Timestep Consumption Time: 2.44852
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.62798

Cumulative Model Updates: 139,476
Cumulative Timesteps: 1,163,264,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,781.90073
Policy Entropy: 3.14159
Value Function Loss: 0.00405

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.58108
Value Function Update Magnitude: 0.54956

Collected Steps per Second: 22,661.43177
Overall Steps per Second: 10,796.05200

Timestep Collection Time: 2.20683
Timestep Consumption Time: 2.42542
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.63225

Cumulative Model Updates: 139,482
Cumulative Timesteps: 1,163,314,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1163314626...
Checkpoint 1163314626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.81414
Policy Entropy: 3.12482
Value Function Loss: 0.00433

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.58977
Value Function Update Magnitude: 0.56548

Collected Steps per Second: 22,275.05773
Overall Steps per Second: 10,717.75255

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.66646

Cumulative Model Updates: 139,488
Cumulative Timesteps: 1,163,364,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.60650
Policy Entropy: 3.12463
Value Function Loss: 0.00402

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 22,521.95571
Overall Steps per Second: 10,668.39706

Timestep Collection Time: 2.22121
Timestep Consumption Time: 2.46797
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.68918

Cumulative Model Updates: 139,494
Cumulative Timesteps: 1,163,414,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1163414666...
Checkpoint 1163414666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671.82072
Policy Entropy: 3.12413
Value Function Loss: 0.00407

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.58401
Value Function Update Magnitude: 0.56648

Collected Steps per Second: 22,605.88928
Overall Steps per Second: 10,775.67352

Timestep Collection Time: 2.21217
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.64082

Cumulative Model Updates: 139,500
Cumulative Timesteps: 1,163,464,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.84119
Policy Entropy: 3.13770
Value Function Loss: 0.00397

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.56651

Collected Steps per Second: 22,421.50757
Overall Steps per Second: 10,522.43906

Timestep Collection Time: 2.23036
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.75251

Cumulative Model Updates: 139,506
Cumulative Timesteps: 1,163,514,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1163514682...
Checkpoint 1163514682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,682.53574
Policy Entropy: 3.13804
Value Function Loss: 0.00411

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.58345
Value Function Update Magnitude: 0.55653

Collected Steps per Second: 22,662.15954
Overall Steps per Second: 10,700.34695

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.46761
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.67499

Cumulative Model Updates: 139,512
Cumulative Timesteps: 1,163,564,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.11589
Policy Entropy: 3.14298
Value Function Loss: 0.00422

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.59055
Value Function Update Magnitude: 0.54466

Collected Steps per Second: 22,963.75300
Overall Steps per Second: 10,765.40909

Timestep Collection Time: 2.17795
Timestep Consumption Time: 2.46785
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.64581

Cumulative Model Updates: 139,518
Cumulative Timesteps: 1,163,614,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1163614720...
Checkpoint 1163614720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.19725
Policy Entropy: 3.14605
Value Function Loss: 0.00457

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.60243
Value Function Update Magnitude: 0.55095

Collected Steps per Second: 22,565.11867
Overall Steps per Second: 10,786.68275

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.42041
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.63701

Cumulative Model Updates: 139,524
Cumulative Timesteps: 1,163,664,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.17584
Policy Entropy: 3.13510
Value Function Loss: 0.00443

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.59031
Value Function Update Magnitude: 0.56475

Collected Steps per Second: 22,873.79955
Overall Steps per Second: 10,802.49357

Timestep Collection Time: 2.18599
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.62875

Cumulative Model Updates: 139,530
Cumulative Timesteps: 1,163,714,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1163714740...
Checkpoint 1163714740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.82192
Policy Entropy: 3.11429
Value Function Loss: 0.00450

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.58994
Value Function Update Magnitude: 0.53924

Collected Steps per Second: 23,093.55124
Overall Steps per Second: 10,662.00442

Timestep Collection Time: 2.16528
Timestep Consumption Time: 2.52465
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.68992

Cumulative Model Updates: 139,536
Cumulative Timesteps: 1,163,764,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.73417
Policy Entropy: 3.10075
Value Function Loss: 0.00448

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.60281
Value Function Update Magnitude: 0.54658

Collected Steps per Second: 22,830.15899
Overall Steps per Second: 10,831.59081

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.42624
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.61650

Cumulative Model Updates: 139,542
Cumulative Timesteps: 1,163,814,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1163814748...
Checkpoint 1163814748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302.37845
Policy Entropy: 3.12341
Value Function Loss: 0.00417

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.59540
Value Function Update Magnitude: 0.54662

Collected Steps per Second: 22,395.86917
Overall Steps per Second: 10,675.52152

Timestep Collection Time: 2.23389
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.68642

Cumulative Model Updates: 139,548
Cumulative Timesteps: 1,163,864,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,238.95911
Policy Entropy: 3.12896
Value Function Loss: 0.00387

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.58226
Value Function Update Magnitude: 0.51853

Collected Steps per Second: 21,674.49304
Overall Steps per Second: 10,499.04335

Timestep Collection Time: 2.30769
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.76405

Cumulative Model Updates: 139,554
Cumulative Timesteps: 1,163,914,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1163914796...
Checkpoint 1163914796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377.18591
Policy Entropy: 3.12677
Value Function Loss: 0.00393

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.58192
Value Function Update Magnitude: 0.50352

Collected Steps per Second: 22,217.33616
Overall Steps per Second: 10,692.42035

Timestep Collection Time: 2.25176
Timestep Consumption Time: 2.42707
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.67883

Cumulative Model Updates: 139,560
Cumulative Timesteps: 1,163,964,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.20762
Policy Entropy: 3.11403
Value Function Loss: 0.00407

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.58435
Value Function Update Magnitude: 0.49936

Collected Steps per Second: 22,605.02021
Overall Steps per Second: 10,782.32131

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.63833

Cumulative Model Updates: 139,566
Cumulative Timesteps: 1,164,014,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1164014836...
Checkpoint 1164014836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.57511
Policy Entropy: 3.11707
Value Function Loss: 0.00375

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.57740
Value Function Update Magnitude: 0.50417

Collected Steps per Second: 22,474.53499
Overall Steps per Second: 10,682.90353

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.45691
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.68281

Cumulative Model Updates: 139,572
Cumulative Timesteps: 1,164,064,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,311.07019
Policy Entropy: 3.12407
Value Function Loss: 0.00385

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.57376
Value Function Update Magnitude: 0.49392

Collected Steps per Second: 22,699.23446
Overall Steps per Second: 10,481.00147

Timestep Collection Time: 2.20316
Timestep Consumption Time: 2.56833
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.77149

Cumulative Model Updates: 139,578
Cumulative Timesteps: 1,164,114,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1164114872...
Checkpoint 1164114872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031.00811
Policy Entropy: 3.12924
Value Function Loss: 0.00371

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.48698

Collected Steps per Second: 21,269.90535
Overall Steps per Second: 10,185.64803

Timestep Collection Time: 2.35206
Timestep Consumption Time: 2.55956
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.91162

Cumulative Model Updates: 139,584
Cumulative Timesteps: 1,164,164,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.17323
Policy Entropy: 3.12940
Value Function Loss: 0.00385

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.57114
Value Function Update Magnitude: 0.48477

Collected Steps per Second: 22,664.69653
Overall Steps per Second: 10,534.51231

Timestep Collection Time: 2.20607
Timestep Consumption Time: 2.54023
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.74630

Cumulative Model Updates: 139,590
Cumulative Timesteps: 1,164,214,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1164214900...
Checkpoint 1164214900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.85079
Policy Entropy: 3.13137
Value Function Loss: 0.00383

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.47290

Collected Steps per Second: 23,099.45207
Overall Steps per Second: 10,774.69571

Timestep Collection Time: 2.16507
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.64162

Cumulative Model Updates: 139,596
Cumulative Timesteps: 1,164,264,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.58859
Policy Entropy: 3.11612
Value Function Loss: 0.00406

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.47533

Collected Steps per Second: 22,776.45735
Overall Steps per Second: 10,740.96672

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.46071
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.65675

Cumulative Model Updates: 139,602
Cumulative Timesteps: 1,164,314,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1164314930...
Checkpoint 1164314930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,953.06006
Policy Entropy: 3.09784
Value Function Loss: 0.00441

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.59297
Value Function Update Magnitude: 0.51873

Collected Steps per Second: 22,728.99951
Overall Steps per Second: 10,618.77246

Timestep Collection Time: 2.20062
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.71034

Cumulative Model Updates: 139,608
Cumulative Timesteps: 1,164,364,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,822.60550
Policy Entropy: 3.09657
Value Function Loss: 0.00415

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.54299

Collected Steps per Second: 22,867.63489
Overall Steps per Second: 10,630.83126

Timestep Collection Time: 2.18658
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.70349

Cumulative Model Updates: 139,614
Cumulative Timesteps: 1,164,414,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1164414950...
Checkpoint 1164414950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.48640
Policy Entropy: 3.11126
Value Function Loss: 0.00416

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.52539

Collected Steps per Second: 22,855.64407
Overall Steps per Second: 10,651.39392

Timestep Collection Time: 2.18843
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.69591

Cumulative Model Updates: 139,620
Cumulative Timesteps: 1,164,464,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,721.30484
Policy Entropy: 3.11613
Value Function Loss: 0.00413

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.58993
Value Function Update Magnitude: 0.52066

Collected Steps per Second: 22,326.63247
Overall Steps per Second: 10,667.90403

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.44748
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.68696

Cumulative Model Updates: 139,626
Cumulative Timesteps: 1,164,514,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1164514968...
Checkpoint 1164514968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.67170
Policy Entropy: 3.10310
Value Function Loss: 0.00412

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.58669
Value Function Update Magnitude: 0.51276

Collected Steps per Second: 22,092.99383
Overall Steps per Second: 10,593.15932

Timestep Collection Time: 2.26416
Timestep Consumption Time: 2.45795
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.72210

Cumulative Model Updates: 139,632
Cumulative Timesteps: 1,164,564,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.42068
Policy Entropy: 3.10180
Value Function Loss: 0.00465

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.59887
Value Function Update Magnitude: 0.51039

Collected Steps per Second: 22,462.64487
Overall Steps per Second: 10,587.77277

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.49691
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.72318

Cumulative Model Updates: 139,638
Cumulative Timesteps: 1,164,614,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1164614998...
Checkpoint 1164614998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.70894
Policy Entropy: 3.11163
Value Function Loss: 0.00442

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.60464
Value Function Update Magnitude: 0.51981

Collected Steps per Second: 22,505.65814
Overall Steps per Second: 10,641.58378

Timestep Collection Time: 2.22202
Timestep Consumption Time: 2.47728
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.69930

Cumulative Model Updates: 139,644
Cumulative Timesteps: 1,164,665,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.92054
Policy Entropy: 3.12186
Value Function Loss: 0.00461

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.60145
Value Function Update Magnitude: 0.52235

Collected Steps per Second: 22,937.25092
Overall Steps per Second: 10,531.89324

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.56916
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.75033

Cumulative Model Updates: 139,650
Cumulative Timesteps: 1,164,715,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1164715036...
Checkpoint 1164715036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.75169
Policy Entropy: 3.13355
Value Function Loss: 0.00400

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.58494
Value Function Update Magnitude: 0.51575

Collected Steps per Second: 22,745.00228
Overall Steps per Second: 10,670.83994

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.68735

Cumulative Model Updates: 139,656
Cumulative Timesteps: 1,164,765,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.96772
Policy Entropy: 3.12730
Value Function Loss: 0.00400

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.49846

Collected Steps per Second: 22,526.98375
Overall Steps per Second: 10,727.68160

Timestep Collection Time: 2.21983
Timestep Consumption Time: 2.44157
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.66140

Cumulative Model Updates: 139,662
Cumulative Timesteps: 1,164,815,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1164815060...
Checkpoint 1164815060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.99847
Policy Entropy: 3.13237
Value Function Loss: 0.00383

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.57323
Value Function Update Magnitude: 0.50390

Collected Steps per Second: 22,642.19885
Overall Steps per Second: 10,699.04941

Timestep Collection Time: 2.20915
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.67518

Cumulative Model Updates: 139,668
Cumulative Timesteps: 1,164,865,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,709.17504
Policy Entropy: 3.12696
Value Function Loss: 0.00408

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.52235

Collected Steps per Second: 22,334.54991
Overall Steps per Second: 10,432.59083

Timestep Collection Time: 2.23940
Timestep Consumption Time: 2.55481
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.79421

Cumulative Model Updates: 139,674
Cumulative Timesteps: 1,164,915,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1164915096...
Checkpoint 1164915096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.83601
Policy Entropy: 3.14281
Value Function Loss: 0.00416

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.58494
Value Function Update Magnitude: 0.53195

Collected Steps per Second: 23,011.69278
Overall Steps per Second: 10,633.18120

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.53087
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.70489

Cumulative Model Updates: 139,680
Cumulative Timesteps: 1,164,965,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.02314
Policy Entropy: 3.13364
Value Function Loss: 0.00472

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.59497
Value Function Update Magnitude: 0.54669

Collected Steps per Second: 22,812.84349
Overall Steps per Second: 10,723.62350

Timestep Collection Time: 2.19210
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.66335

Cumulative Model Updates: 139,686
Cumulative Timesteps: 1,165,015,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1165015132...
Checkpoint 1165015132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312.80840
Policy Entropy: 3.14125
Value Function Loss: 0.00454

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.59575
Value Function Update Magnitude: 0.54530

Collected Steps per Second: 22,366.00682
Overall Steps per Second: 10,606.26233

Timestep Collection Time: 2.23679
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.71684

Cumulative Model Updates: 139,692
Cumulative Timesteps: 1,165,065,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906.01781
Policy Entropy: 3.14971
Value Function Loss: 0.00430

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.58562
Value Function Update Magnitude: 0.54099

Collected Steps per Second: 21,836.05991
Overall Steps per Second: 10,611.14736

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.71391

Cumulative Model Updates: 139,698
Cumulative Timesteps: 1,165,115,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1165115180...
Checkpoint 1165115180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.06634
Policy Entropy: 3.15936
Value Function Loss: 0.00419

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.58406
Value Function Update Magnitude: 0.53317

Collected Steps per Second: 22,357.37140
Overall Steps per Second: 10,636.78555

Timestep Collection Time: 2.23694
Timestep Consumption Time: 2.46486
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.70180

Cumulative Model Updates: 139,704
Cumulative Timesteps: 1,165,165,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.54669
Policy Entropy: 3.16148
Value Function Loss: 0.00438

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.59034
Value Function Update Magnitude: 0.53002

Collected Steps per Second: 22,469.34559
Overall Steps per Second: 10,554.44654

Timestep Collection Time: 2.22570
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.73829

Cumulative Model Updates: 139,710
Cumulative Timesteps: 1,165,215,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1165215202...
Checkpoint 1165215202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.55626
Policy Entropy: 3.16019
Value Function Loss: 0.00451

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.52551

Collected Steps per Second: 22,346.67718
Overall Steps per Second: 10,595.25783

Timestep Collection Time: 2.23854
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.72136

Cumulative Model Updates: 139,716
Cumulative Timesteps: 1,165,265,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,940.84963
Policy Entropy: 3.14880
Value Function Loss: 0.00466

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.58221
Value Function Update Magnitude: 0.52394

Collected Steps per Second: 22,958.91640
Overall Steps per Second: 10,520.55331

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.57624
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.75526

Cumulative Model Updates: 139,722
Cumulative Timesteps: 1,165,315,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1165315254...
Checkpoint 1165315254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.81089
Policy Entropy: 3.14953
Value Function Loss: 0.00441

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.58231
Value Function Update Magnitude: 0.52693

Collected Steps per Second: 22,852.61834
Overall Steps per Second: 10,524.78176

Timestep Collection Time: 2.18846
Timestep Consumption Time: 2.56337
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.75183

Cumulative Model Updates: 139,728
Cumulative Timesteps: 1,165,365,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891.76654
Policy Entropy: 3.13230
Value Function Loss: 0.00429

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.58365
Value Function Update Magnitude: 0.54238

Collected Steps per Second: 22,803.63189
Overall Steps per Second: 10,700.09397

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.67342

Cumulative Model Updates: 139,734
Cumulative Timesteps: 1,165,415,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1165415272...
Checkpoint 1165415272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.51678
Policy Entropy: 3.14490
Value Function Loss: 0.00409

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.53199

Collected Steps per Second: 22,799.85835
Overall Steps per Second: 10,655.26673

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.49962
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.69270

Cumulative Model Updates: 139,740
Cumulative Timesteps: 1,165,465,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.41524
Policy Entropy: 3.15189
Value Function Loss: 0.00421

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.57661
Value Function Update Magnitude: 0.50961

Collected Steps per Second: 22,920.31529
Overall Steps per Second: 10,752.27831

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.65408

Cumulative Model Updates: 139,746
Cumulative Timesteps: 1,165,515,316

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1165515316...
Checkpoint 1165515316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.69878
Policy Entropy: 3.16232
Value Function Loss: 0.00415

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.51430

Collected Steps per Second: 22,445.57999
Overall Steps per Second: 10,639.88119

Timestep Collection Time: 2.22823
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70062

Cumulative Model Updates: 139,752
Cumulative Timesteps: 1,165,565,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.99875
Policy Entropy: 3.16198
Value Function Loss: 0.00431

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.51616

Collected Steps per Second: 22,731.66454
Overall Steps per Second: 10,836.98805

Timestep Collection Time: 2.20089
Timestep Consumption Time: 2.41570
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.61660

Cumulative Model Updates: 139,758
Cumulative Timesteps: 1,165,615,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1165615360...
Checkpoint 1165615360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.51161
Policy Entropy: 3.15991
Value Function Loss: 0.00411

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.53788

Collected Steps per Second: 21,948.39678
Overall Steps per Second: 10,441.68913

Timestep Collection Time: 2.27880
Timestep Consumption Time: 2.51123
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.79003

Cumulative Model Updates: 139,764
Cumulative Timesteps: 1,165,665,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.61930
Policy Entropy: 3.15310
Value Function Loss: 0.00409

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.55458

Collected Steps per Second: 13,003.78991
Overall Steps per Second: 6,800.81120

Timestep Collection Time: 3.84519
Timestep Consumption Time: 3.50717
PPO Batch Consumption Time: 0.34903
Total Iteration Time: 7.35236

Cumulative Model Updates: 139,770
Cumulative Timesteps: 1,165,715,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1165715378...
Checkpoint 1165715378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.74431
Policy Entropy: 3.14748
Value Function Loss: 0.00394

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.57721
Value Function Update Magnitude: 0.54822

Collected Steps per Second: 15,820.62058
Overall Steps per Second: 8,842.12418

Timestep Collection Time: 3.16056
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 5.65498

Cumulative Model Updates: 139,776
Cumulative Timesteps: 1,165,765,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.23358
Policy Entropy: 3.15061
Value Function Loss: 0.00431

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.58221
Value Function Update Magnitude: 0.52958

Collected Steps per Second: 21,991.86226
Overall Steps per Second: 10,334.20761

Timestep Collection Time: 2.27493
Timestep Consumption Time: 2.56627
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.84120

Cumulative Model Updates: 139,782
Cumulative Timesteps: 1,165,815,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1165815410...
Checkpoint 1165815410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.15373
Policy Entropy: 3.14886
Value Function Loss: 0.00430

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.58372
Value Function Update Magnitude: 0.52928

Collected Steps per Second: 21,540.83404
Overall Steps per Second: 10,249.82436

Timestep Collection Time: 2.32238
Timestep Consumption Time: 2.55829
PPO Batch Consumption Time: 0.30190
Total Iteration Time: 4.88067

Cumulative Model Updates: 139,788
Cumulative Timesteps: 1,165,865,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.50697
Policy Entropy: 3.15421
Value Function Loss: 0.00449

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.58373
Value Function Update Magnitude: 0.53193

Collected Steps per Second: 21,101.48628
Overall Steps per Second: 10,108.93915

Timestep Collection Time: 2.37159
Timestep Consumption Time: 2.57888
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.95047

Cumulative Model Updates: 139,794
Cumulative Timesteps: 1,165,915,480

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1165915480...
Checkpoint 1165915480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.53484
Policy Entropy: 3.16027
Value Function Loss: 0.00436

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.52378

Collected Steps per Second: 19,733.36747
Overall Steps per Second: 9,806.90575

Timestep Collection Time: 2.53378
Timestep Consumption Time: 2.56467
PPO Batch Consumption Time: 0.30251
Total Iteration Time: 5.09845

Cumulative Model Updates: 139,800
Cumulative Timesteps: 1,165,965,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.48240
Policy Entropy: 3.15563
Value Function Loss: 0.00467

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.51043

Collected Steps per Second: 20,521.54194
Overall Steps per Second: 10,146.69474

Timestep Collection Time: 2.43715
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.92909

Cumulative Model Updates: 139,806
Cumulative Timesteps: 1,166,015,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1166015494...
Checkpoint 1166015494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.62295
Policy Entropy: 3.17123
Value Function Loss: 0.00471

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.51627

Collected Steps per Second: 19,472.23031
Overall Steps per Second: 9,713.60365

Timestep Collection Time: 2.56899
Timestep Consumption Time: 2.58090
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 5.14989

Cumulative Model Updates: 139,812
Cumulative Timesteps: 1,166,065,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.31434
Policy Entropy: 3.16414
Value Function Loss: 0.00470

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.58047
Value Function Update Magnitude: 0.52916

Collected Steps per Second: 21,321.87528
Overall Steps per Second: 10,179.95881

Timestep Collection Time: 2.34614
Timestep Consumption Time: 2.56783
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.91397

Cumulative Model Updates: 139,818
Cumulative Timesteps: 1,166,115,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1166115542...
Checkpoint 1166115542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.34569
Policy Entropy: 3.16761
Value Function Loss: 0.00435

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.53635

Collected Steps per Second: 21,004.15694
Overall Steps per Second: 9,884.09538

Timestep Collection Time: 2.38115
Timestep Consumption Time: 2.67890
PPO Batch Consumption Time: 0.31134
Total Iteration Time: 5.06005

Cumulative Model Updates: 139,824
Cumulative Timesteps: 1,166,165,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.71658
Policy Entropy: 3.14910
Value Function Loss: 0.00446

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.59745
Value Function Update Magnitude: 0.55353

Collected Steps per Second: 20,032.58289
Overall Steps per Second: 9,946.19039

Timestep Collection Time: 2.49683
Timestep Consumption Time: 2.53203
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 5.02886

Cumulative Model Updates: 139,830
Cumulative Timesteps: 1,166,215,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1166215574...
Checkpoint 1166215574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.72891
Policy Entropy: 3.15068
Value Function Loss: 0.00432

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.59854
Value Function Update Magnitude: 0.54293

Collected Steps per Second: 21,701.04133
Overall Steps per Second: 10,253.93377

Timestep Collection Time: 2.30523
Timestep Consumption Time: 2.57348
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.87871

Cumulative Model Updates: 139,836
Cumulative Timesteps: 1,166,265,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.29768
Policy Entropy: 3.14440
Value Function Loss: 0.00436

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.60157
Value Function Update Magnitude: 0.53598

Collected Steps per Second: 17,679.30404
Overall Steps per Second: 9,222.03317

Timestep Collection Time: 2.82975
Timestep Consumption Time: 2.59508
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 5.42483

Cumulative Model Updates: 139,842
Cumulative Timesteps: 1,166,315,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1166315628...
Checkpoint 1166315628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.56426
Policy Entropy: 3.15636
Value Function Loss: 0.00408

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.59184
Value Function Update Magnitude: 0.55798

Collected Steps per Second: 14,899.51258
Overall Steps per Second: 7,325.28526

Timestep Collection Time: 3.35756
Timestep Consumption Time: 3.47166
PPO Batch Consumption Time: 0.45217
Total Iteration Time: 6.82922

Cumulative Model Updates: 139,848
Cumulative Timesteps: 1,166,365,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.57443
Policy Entropy: 3.16440
Value Function Loss: 0.00419

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.58121
Value Function Update Magnitude: 0.56360

Collected Steps per Second: 15,066.62207
Overall Steps per Second: 6,831.82824

Timestep Collection Time: 3.31952
Timestep Consumption Time: 4.00121
PPO Batch Consumption Time: 0.53352
Total Iteration Time: 7.32073

Cumulative Model Updates: 139,854
Cumulative Timesteps: 1,166,415,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1166415668...
Checkpoint 1166415668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,222.03247
Policy Entropy: 3.16987
Value Function Loss: 0.00397

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.56251
Value Function Update Magnitude: 0.52815

Collected Steps per Second: 14,883.66713
Overall Steps per Second: 7,096.67564

Timestep Collection Time: 3.36127
Timestep Consumption Time: 3.68823
PPO Batch Consumption Time: 0.48793
Total Iteration Time: 7.04950

Cumulative Model Updates: 139,860
Cumulative Timesteps: 1,166,465,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.32225
Policy Entropy: 3.16816
Value Function Loss: 0.00431

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.50959

Collected Steps per Second: 15,783.63143
Overall Steps per Second: 7,373.05245

Timestep Collection Time: 3.16974
Timestep Consumption Time: 3.61578
PPO Batch Consumption Time: 0.47413
Total Iteration Time: 6.78552

Cumulative Model Updates: 139,866
Cumulative Timesteps: 1,166,515,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1166515726...
Checkpoint 1166515726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.99714
Policy Entropy: 3.16525
Value Function Loss: 0.00435

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.58269
Value Function Update Magnitude: 0.51160

Collected Steps per Second: 15,908.23495
Overall Steps per Second: 7,324.69273

Timestep Collection Time: 3.14453
Timestep Consumption Time: 3.68497
PPO Batch Consumption Time: 0.48868
Total Iteration Time: 6.82950

Cumulative Model Updates: 139,872
Cumulative Timesteps: 1,166,565,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.15357
Policy Entropy: 3.17304
Value Function Loss: 0.00412

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.56705
Value Function Update Magnitude: 0.50657

Collected Steps per Second: 15,265.20687
Overall Steps per Second: 7,270.39177

Timestep Collection Time: 3.27647
Timestep Consumption Time: 3.60294
PPO Batch Consumption Time: 0.47732
Total Iteration Time: 6.87941

Cumulative Model Updates: 139,878
Cumulative Timesteps: 1,166,615,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1166615766...
Checkpoint 1166615766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988.05574
Policy Entropy: 3.17620
Value Function Loss: 0.00407

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.56722
Value Function Update Magnitude: 0.48940

Collected Steps per Second: 15,373.98633
Overall Steps per Second: 6,858.59966

Timestep Collection Time: 3.25277
Timestep Consumption Time: 4.03852
PPO Batch Consumption Time: 0.54686
Total Iteration Time: 7.29128

Cumulative Model Updates: 139,884
Cumulative Timesteps: 1,166,665,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.72973
Policy Entropy: 3.17309
Value Function Loss: 0.00420

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.48593

Collected Steps per Second: 15,168.78573
Overall Steps per Second: 6,927.40152

Timestep Collection Time: 3.29664
Timestep Consumption Time: 3.92194
PPO Batch Consumption Time: 0.52434
Total Iteration Time: 7.21858

Cumulative Model Updates: 139,890
Cumulative Timesteps: 1,166,715,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1166715780...
Checkpoint 1166715780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.37523
Policy Entropy: 3.16050
Value Function Loss: 0.00445

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.57268
Value Function Update Magnitude: 0.50700

Collected Steps per Second: 15,396.10202
Overall Steps per Second: 7,341.15604

Timestep Collection Time: 3.24939
Timestep Consumption Time: 3.56534
PPO Batch Consumption Time: 0.46367
Total Iteration Time: 6.81473

Cumulative Model Updates: 139,896
Cumulative Timesteps: 1,166,765,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.92877
Policy Entropy: 3.15251
Value Function Loss: 0.00421

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.50450

Collected Steps per Second: 15,732.72798
Overall Steps per Second: 7,053.72675

Timestep Collection Time: 3.17872
Timestep Consumption Time: 3.91115
PPO Batch Consumption Time: 0.51870
Total Iteration Time: 7.08987

Cumulative Model Updates: 139,902
Cumulative Timesteps: 1,166,815,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1166815818...
Checkpoint 1166815818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.19987
Policy Entropy: 3.17108
Value Function Loss: 0.00404

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.57234
Value Function Update Magnitude: 0.51392

Collected Steps per Second: 15,296.31729
Overall Steps per Second: 6,712.36364

Timestep Collection Time: 3.26968
Timestep Consumption Time: 4.18135
PPO Batch Consumption Time: 0.56355
Total Iteration Time: 7.45103

Cumulative Model Updates: 139,908
Cumulative Timesteps: 1,166,865,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.34440
Policy Entropy: 3.17416
Value Function Loss: 0.00397

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.57710
Value Function Update Magnitude: 0.53348

Collected Steps per Second: 16,328.08626
Overall Steps per Second: 7,725.12404

Timestep Collection Time: 3.06454
Timestep Consumption Time: 3.41277
PPO Batch Consumption Time: 0.44122
Total Iteration Time: 6.47731

Cumulative Model Updates: 139,914
Cumulative Timesteps: 1,166,915,870

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1166915870...
Checkpoint 1166915870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,402.04160
Policy Entropy: 3.16124
Value Function Loss: 0.00386

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.57215
Value Function Update Magnitude: 0.54935

Collected Steps per Second: 15,848.96873
Overall Steps per Second: 7,181.07875

Timestep Collection Time: 3.15617
Timestep Consumption Time: 3.80964
PPO Batch Consumption Time: 0.50080
Total Iteration Time: 6.96581

Cumulative Model Updates: 139,920
Cumulative Timesteps: 1,166,965,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.82990
Policy Entropy: 3.15250
Value Function Loss: 0.00416

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.57423
Value Function Update Magnitude: 0.52976

Collected Steps per Second: 15,037.95847
Overall Steps per Second: 6,998.16632

Timestep Collection Time: 3.32532
Timestep Consumption Time: 3.82027
PPO Batch Consumption Time: 0.50883
Total Iteration Time: 7.14559

Cumulative Model Updates: 139,926
Cumulative Timesteps: 1,167,015,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1167015898...
Checkpoint 1167015898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.77125
Policy Entropy: 3.14632
Value Function Loss: 0.00427

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.53024

Collected Steps per Second: 14,863.49046
Overall Steps per Second: 7,115.41012

Timestep Collection Time: 3.36489
Timestep Consumption Time: 3.66408
PPO Batch Consumption Time: 0.48213
Total Iteration Time: 7.02897

Cumulative Model Updates: 139,932
Cumulative Timesteps: 1,167,065,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.91569
Policy Entropy: 3.14386
Value Function Loss: 0.00419

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.57870
Value Function Update Magnitude: 0.54239

Collected Steps per Second: 15,058.19462
Overall Steps per Second: 6,936.26233

Timestep Collection Time: 3.32138
Timestep Consumption Time: 3.88913
PPO Batch Consumption Time: 0.51664
Total Iteration Time: 7.21051

Cumulative Model Updates: 139,938
Cumulative Timesteps: 1,167,115,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1167115926...
Checkpoint 1167115926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,241.87022
Policy Entropy: 3.14391
Value Function Loss: 0.00379

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.57445
Value Function Update Magnitude: 0.52246

Collected Steps per Second: 15,784.56082
Overall Steps per Second: 7,413.43966

Timestep Collection Time: 3.16816
Timestep Consumption Time: 3.57743
PPO Batch Consumption Time: 0.46598
Total Iteration Time: 6.74559

Cumulative Model Updates: 139,944
Cumulative Timesteps: 1,167,165,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.33582
Policy Entropy: 3.13800
Value Function Loss: 0.00406

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.49775

Collected Steps per Second: 15,636.69780
Overall Steps per Second: 7,186.79252

Timestep Collection Time: 3.19812
Timestep Consumption Time: 3.76020
PPO Batch Consumption Time: 0.49835
Total Iteration Time: 6.95832

Cumulative Model Updates: 139,950
Cumulative Timesteps: 1,167,215,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1167215942...
Checkpoint 1167215942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.82472
Policy Entropy: 3.14205
Value Function Loss: 0.00410

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.50085

Collected Steps per Second: 15,973.74994
Overall Steps per Second: 7,419.82533

Timestep Collection Time: 3.13039
Timestep Consumption Time: 3.60886
PPO Batch Consumption Time: 0.47475
Total Iteration Time: 6.73924

Cumulative Model Updates: 139,956
Cumulative Timesteps: 1,167,265,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.40455
Policy Entropy: 3.14469
Value Function Loss: 0.00464

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.49143

Collected Steps per Second: 15,224.76498
Overall Steps per Second: 6,909.00074

Timestep Collection Time: 3.28504
Timestep Consumption Time: 3.95392
PPO Batch Consumption Time: 0.52962
Total Iteration Time: 7.23896

Cumulative Model Updates: 139,962
Cumulative Timesteps: 1,167,315,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1167315960...
Checkpoint 1167315960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.71577
Policy Entropy: 3.14182
Value Function Loss: 0.00464

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.50967

Collected Steps per Second: 15,515.30921
Overall Steps per Second: 7,260.23942

Timestep Collection Time: 3.22275
Timestep Consumption Time: 3.66435
PPO Batch Consumption Time: 0.48066
Total Iteration Time: 6.88710

Cumulative Model Updates: 139,968
Cumulative Timesteps: 1,167,365,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,079.76161
Policy Entropy: 3.15390
Value Function Loss: 0.00446

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.57999
Value Function Update Magnitude: 0.54729

Collected Steps per Second: 15,490.14186
Overall Steps per Second: 7,393.20107

Timestep Collection Time: 3.22786
Timestep Consumption Time: 3.53511
PPO Batch Consumption Time: 0.46128
Total Iteration Time: 6.76297

Cumulative Model Updates: 139,974
Cumulative Timesteps: 1,167,415,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1167415962...
Checkpoint 1167415962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.71981
Policy Entropy: 3.16374
Value Function Loss: 0.00415

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.56987
Value Function Update Magnitude: 0.53356

Collected Steps per Second: 15,451.59544
Overall Steps per Second: 6,910.83867

Timestep Collection Time: 3.23734
Timestep Consumption Time: 4.00086
PPO Batch Consumption Time: 0.53816
Total Iteration Time: 7.23820

Cumulative Model Updates: 139,980
Cumulative Timesteps: 1,167,465,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,475.19234
Policy Entropy: 3.18007
Value Function Loss: 0.00418

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.52605

Collected Steps per Second: 15,104.62452
Overall Steps per Second: 7,246.54659

Timestep Collection Time: 3.31316
Timestep Consumption Time: 3.59275
PPO Batch Consumption Time: 0.46737
Total Iteration Time: 6.90591

Cumulative Model Updates: 139,986
Cumulative Timesteps: 1,167,516,028

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1167516028...
Checkpoint 1167516028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.64972
Policy Entropy: 3.16993
Value Function Loss: 0.00440

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.53237

Collected Steps per Second: 15,390.98722
Overall Steps per Second: 7,269.04041

Timestep Collection Time: 3.25060
Timestep Consumption Time: 3.63201
PPO Batch Consumption Time: 0.47156
Total Iteration Time: 6.88261

Cumulative Model Updates: 139,992
Cumulative Timesteps: 1,167,566,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.53856
Policy Entropy: 3.17019
Value Function Loss: 0.00426

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.53310

Collected Steps per Second: 15,870.07351
Overall Steps per Second: 7,187.25812

Timestep Collection Time: 3.15210
Timestep Consumption Time: 3.80800
PPO Batch Consumption Time: 0.50530
Total Iteration Time: 6.96010

Cumulative Model Updates: 139,998
Cumulative Timesteps: 1,167,616,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1167616082...
Checkpoint 1167616082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.10601
Policy Entropy: 3.15022
Value Function Loss: 0.00390

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.56933
Value Function Update Magnitude: 0.51767

Collected Steps per Second: 15,797.09575
Overall Steps per Second: 7,219.86245

Timestep Collection Time: 3.16615
Timestep Consumption Time: 3.76140
PPO Batch Consumption Time: 0.50046
Total Iteration Time: 6.92756

Cumulative Model Updates: 140,004
Cumulative Timesteps: 1,167,666,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.00958
Policy Entropy: 3.14986
Value Function Loss: 0.00383

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.50933

Collected Steps per Second: 15,696.63155
Overall Steps per Second: 7,392.62275

Timestep Collection Time: 3.18616
Timestep Consumption Time: 3.57896
PPO Batch Consumption Time: 0.46509
Total Iteration Time: 6.76512

Cumulative Model Updates: 140,010
Cumulative Timesteps: 1,167,716,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1167716110...
Checkpoint 1167716110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.62046
Policy Entropy: 3.14053
Value Function Loss: 0.00420

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.52480

Collected Steps per Second: 15,341.67039
Overall Steps per Second: 7,199.91869

Timestep Collection Time: 3.26027
Timestep Consumption Time: 3.68675
PPO Batch Consumption Time: 0.48537
Total Iteration Time: 6.94702

Cumulative Model Updates: 140,016
Cumulative Timesteps: 1,167,766,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,308.87106
Policy Entropy: 3.14143
Value Function Loss: 0.00427

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.58131
Value Function Update Magnitude: 0.53299

Collected Steps per Second: 15,191.40527
Overall Steps per Second: 7,303.92958

Timestep Collection Time: 3.29147
Timestep Consumption Time: 3.55444
PPO Batch Consumption Time: 0.46050
Total Iteration Time: 6.84590

Cumulative Model Updates: 140,022
Cumulative Timesteps: 1,167,816,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1167816130...
Checkpoint 1167816130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.51138
Policy Entropy: 3.12561
Value Function Loss: 0.00401

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.58049
Value Function Update Magnitude: 0.53059

Collected Steps per Second: 15,725.64732
Overall Steps per Second: 7,058.27934

Timestep Collection Time: 3.18054
Timestep Consumption Time: 3.90561
PPO Batch Consumption Time: 0.51625
Total Iteration Time: 7.08615

Cumulative Model Updates: 140,028
Cumulative Timesteps: 1,167,866,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.16974
Policy Entropy: 3.10952
Value Function Loss: 0.00389

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.58546
Value Function Update Magnitude: 0.51379

Collected Steps per Second: 15,924.07430
Overall Steps per Second: 7,508.44295

Timestep Collection Time: 3.14128
Timestep Consumption Time: 3.52082
PPO Batch Consumption Time: 0.46163
Total Iteration Time: 6.66210

Cumulative Model Updates: 140,034
Cumulative Timesteps: 1,167,916,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1167916168...
Checkpoint 1167916168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.62765
Policy Entropy: 3.11558
Value Function Loss: 0.00423

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.59369
Value Function Update Magnitude: 0.53009

Collected Steps per Second: 16,263.70732
Overall Steps per Second: 7,362.09549

Timestep Collection Time: 3.07568
Timestep Consumption Time: 3.71885
PPO Batch Consumption Time: 0.49525
Total Iteration Time: 6.79453

Cumulative Model Updates: 140,040
Cumulative Timesteps: 1,167,966,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.84733
Policy Entropy: 3.13180
Value Function Loss: 0.00432

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.59448
Value Function Update Magnitude: 0.55367

Collected Steps per Second: 15,257.61703
Overall Steps per Second: 6,791.01896

Timestep Collection Time: 3.28007
Timestep Consumption Time: 4.08937
PPO Batch Consumption Time: 0.54711
Total Iteration Time: 7.36944

Cumulative Model Updates: 140,046
Cumulative Timesteps: 1,168,016,236

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1168016236...
Checkpoint 1168016236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.58292
Policy Entropy: 3.16000
Value Function Loss: 0.00415

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.57721
Value Function Update Magnitude: 0.56298

Collected Steps per Second: 14,979.16297
Overall Steps per Second: 6,932.60785

Timestep Collection Time: 3.33850
Timestep Consumption Time: 3.87494
PPO Batch Consumption Time: 0.51165
Total Iteration Time: 7.21345

Cumulative Model Updates: 140,052
Cumulative Timesteps: 1,168,066,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.35509
Policy Entropy: 3.15997
Value Function Loss: 0.00396

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.52664

Collected Steps per Second: 15,618.76695
Overall Steps per Second: 7,113.97593

Timestep Collection Time: 3.20269
Timestep Consumption Time: 3.82883
PPO Batch Consumption Time: 0.51599
Total Iteration Time: 7.03151

Cumulative Model Updates: 140,058
Cumulative Timesteps: 1,168,116,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1168116266...
Checkpoint 1168116266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.35813
Policy Entropy: 3.14286
Value Function Loss: 0.00398

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.57289
Value Function Update Magnitude: 0.51483

Collected Steps per Second: 15,532.66129
Overall Steps per Second: 7,444.37551

Timestep Collection Time: 3.22031
Timestep Consumption Time: 3.49886
PPO Batch Consumption Time: 0.45727
Total Iteration Time: 6.71917

Cumulative Model Updates: 140,064
Cumulative Timesteps: 1,168,166,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.43276
Policy Entropy: 3.12151
Value Function Loss: 0.00441

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.59337
Value Function Update Magnitude: 0.52627

Collected Steps per Second: 15,772.80105
Overall Steps per Second: 7,081.78598

Timestep Collection Time: 3.17204
Timestep Consumption Time: 3.89284
PPO Batch Consumption Time: 0.52232
Total Iteration Time: 7.06488

Cumulative Model Updates: 140,070
Cumulative Timesteps: 1,168,216,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1168216318...
Checkpoint 1168216318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.06814
Policy Entropy: 3.12780
Value Function Loss: 0.00448

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.60748
Value Function Update Magnitude: 0.54807

Collected Steps per Second: 15,322.41278
Overall Steps per Second: 7,319.85389

Timestep Collection Time: 3.26345
Timestep Consumption Time: 3.56783
PPO Batch Consumption Time: 0.46667
Total Iteration Time: 6.83128

Cumulative Model Updates: 140,076
Cumulative Timesteps: 1,168,266,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.42786
Policy Entropy: 3.12987
Value Function Loss: 0.00483

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.60624
Value Function Update Magnitude: 0.55666

Collected Steps per Second: 15,731.15927
Overall Steps per Second: 6,996.21909

Timestep Collection Time: 3.17841
Timestep Consumption Time: 3.96831
PPO Batch Consumption Time: 0.52835
Total Iteration Time: 7.14672

Cumulative Model Updates: 140,082
Cumulative Timesteps: 1,168,316,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1168316322...
Checkpoint 1168316322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.68353
Policy Entropy: 3.13132
Value Function Loss: 0.00457

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.59441
Value Function Update Magnitude: 0.54613

Collected Steps per Second: 14,917.58767
Overall Steps per Second: 6,791.83340

Timestep Collection Time: 3.35202
Timestep Consumption Time: 4.01035
PPO Batch Consumption Time: 0.53620
Total Iteration Time: 7.36237

Cumulative Model Updates: 140,088
Cumulative Timesteps: 1,168,366,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.55680
Policy Entropy: 3.13195
Value Function Loss: 0.00439

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.53075

Collected Steps per Second: 15,772.02157
Overall Steps per Second: 7,009.74539

Timestep Collection Time: 3.17093
Timestep Consumption Time: 3.96371
PPO Batch Consumption Time: 0.53444
Total Iteration Time: 7.13464

Cumulative Model Updates: 140,094
Cumulative Timesteps: 1,168,416,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1168416338...
Checkpoint 1168416338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.24361
Policy Entropy: 3.12598
Value Function Loss: 0.00437

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.58567
Value Function Update Magnitude: 0.52006

Collected Steps per Second: 15,825.85685
Overall Steps per Second: 7,151.66262

Timestep Collection Time: 3.16040
Timestep Consumption Time: 3.83322
PPO Batch Consumption Time: 0.51121
Total Iteration Time: 6.99362

Cumulative Model Updates: 140,100
Cumulative Timesteps: 1,168,466,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.75604
Policy Entropy: 3.13421
Value Function Loss: 0.00425

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.59080
Value Function Update Magnitude: 0.53764

Collected Steps per Second: 15,684.64891
Overall Steps per Second: 7,117.53325

Timestep Collection Time: 3.18821
Timestep Consumption Time: 3.83754
PPO Batch Consumption Time: 0.50896
Total Iteration Time: 7.02575

Cumulative Model Updates: 140,106
Cumulative Timesteps: 1,168,516,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1168516360...
Checkpoint 1168516360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960.69060
Policy Entropy: 3.14645
Value Function Loss: 0.00435

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.59312
Value Function Update Magnitude: 0.56377

Collected Steps per Second: 15,671.05183
Overall Steps per Second: 7,329.13346

Timestep Collection Time: 3.19060
Timestep Consumption Time: 3.63149
PPO Batch Consumption Time: 0.48206
Total Iteration Time: 6.82209

Cumulative Model Updates: 140,112
Cumulative Timesteps: 1,168,566,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.21211
Policy Entropy: 3.15778
Value Function Loss: 0.00385

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.58718
Value Function Update Magnitude: 0.55566

Collected Steps per Second: 15,445.24546
Overall Steps per Second: 6,874.36716

Timestep Collection Time: 3.23944
Timestep Consumption Time: 4.03890
PPO Batch Consumption Time: 0.53813
Total Iteration Time: 7.27834

Cumulative Model Updates: 140,118
Cumulative Timesteps: 1,168,616,394

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1168616394...
Checkpoint 1168616394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.34582
Policy Entropy: 3.15681
Value Function Loss: 0.00414

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.57782
Value Function Update Magnitude: 0.55848

Collected Steps per Second: 14,918.65226
Overall Steps per Second: 6,927.87497

Timestep Collection Time: 3.35178
Timestep Consumption Time: 3.86602
PPO Batch Consumption Time: 0.52088
Total Iteration Time: 7.21780

Cumulative Model Updates: 140,124
Cumulative Timesteps: 1,168,666,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.09063
Policy Entropy: 3.14212
Value Function Loss: 0.00432

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.58893
Value Function Update Magnitude: 0.55497

Collected Steps per Second: 15,250.84604
Overall Steps per Second: 7,392.38880

Timestep Collection Time: 3.27903
Timestep Consumption Time: 3.48576
PPO Batch Consumption Time: 0.45673
Total Iteration Time: 6.76480

Cumulative Model Updates: 140,130
Cumulative Timesteps: 1,168,716,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1168716406...
Checkpoint 1168716406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.40138
Policy Entropy: 3.13239
Value Function Loss: 0.00532

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.59104
Value Function Update Magnitude: 0.56790

Collected Steps per Second: 15,538.77979
Overall Steps per Second: 7,075.90963

Timestep Collection Time: 3.21930
Timestep Consumption Time: 3.85032
PPO Batch Consumption Time: 0.51562
Total Iteration Time: 7.06962

Cumulative Model Updates: 140,136
Cumulative Timesteps: 1,168,766,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.41464
Policy Entropy: 3.13776
Value Function Loss: 0.00526

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.59355
Value Function Update Magnitude: 0.57180

Collected Steps per Second: 15,310.29981
Overall Steps per Second: 7,130.06174

Timestep Collection Time: 3.26591
Timestep Consumption Time: 3.74694
PPO Batch Consumption Time: 0.48907
Total Iteration Time: 7.01284

Cumulative Model Updates: 140,142
Cumulative Timesteps: 1,168,816,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1168816432...
Checkpoint 1168816432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891.19469
Policy Entropy: 3.13956
Value Function Loss: 0.00477

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.59582
Value Function Update Magnitude: 0.55967

Collected Steps per Second: 15,685.91884
Overall Steps per Second: 7,089.69134

Timestep Collection Time: 3.18872
Timestep Consumption Time: 3.86631
PPO Batch Consumption Time: 0.51870
Total Iteration Time: 7.05503

Cumulative Model Updates: 140,148
Cumulative Timesteps: 1,168,866,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.97017
Policy Entropy: 3.14621
Value Function Loss: 0.00431

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.54531

Collected Steps per Second: 14,800.99727
Overall Steps per Second: 6,843.96670

Timestep Collection Time: 3.37842
Timestep Consumption Time: 3.92787
PPO Batch Consumption Time: 0.52862
Total Iteration Time: 7.30629

Cumulative Model Updates: 140,154
Cumulative Timesteps: 1,168,916,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1168916454...
Checkpoint 1168916454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.46586
Policy Entropy: 3.14402
Value Function Loss: 0.00421

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.52773

Collected Steps per Second: 15,088.21201
Overall Steps per Second: 7,249.83587

Timestep Collection Time: 3.31491
Timestep Consumption Time: 3.58401
PPO Batch Consumption Time: 0.47291
Total Iteration Time: 6.89891

Cumulative Model Updates: 140,160
Cumulative Timesteps: 1,168,966,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.35982
Policy Entropy: 3.15600
Value Function Loss: 0.00410

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.50501

Collected Steps per Second: 15,738.73449
Overall Steps per Second: 7,494.08522

Timestep Collection Time: 3.17688
Timestep Consumption Time: 3.49505
PPO Batch Consumption Time: 0.45859
Total Iteration Time: 6.67193

Cumulative Model Updates: 140,166
Cumulative Timesteps: 1,169,016,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1169016470...
Checkpoint 1169016470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.41984
Policy Entropy: 3.14352
Value Function Loss: 0.00411

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.50473

Collected Steps per Second: 15,673.44771
Overall Steps per Second: 7,305.06263

Timestep Collection Time: 3.19075
Timestep Consumption Time: 3.65519
PPO Batch Consumption Time: 0.48268
Total Iteration Time: 6.84594

Cumulative Model Updates: 140,172
Cumulative Timesteps: 1,169,066,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902.74920
Policy Entropy: 3.13718
Value Function Loss: 0.00414

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.49774

Collected Steps per Second: 15,902.97715
Overall Steps per Second: 7,282.64812

Timestep Collection Time: 3.14570
Timestep Consumption Time: 3.72350
PPO Batch Consumption Time: 0.48999
Total Iteration Time: 6.86920

Cumulative Model Updates: 140,178
Cumulative Timesteps: 1,169,116,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1169116506...
Checkpoint 1169116506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.54453
Policy Entropy: 3.12678
Value Function Loss: 0.00433

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10608
Policy Update Magnitude: 0.58682
Value Function Update Magnitude: 0.51677

Collected Steps per Second: 15,236.90621
Overall Steps per Second: 6,913.02659

Timestep Collection Time: 3.28334
Timestep Consumption Time: 3.95343
PPO Batch Consumption Time: 0.52770
Total Iteration Time: 7.23677

Cumulative Model Updates: 140,184
Cumulative Timesteps: 1,169,166,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906.12896
Policy Entropy: 3.13356
Value Function Loss: 0.00412

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.58527
Value Function Update Magnitude: 0.53004

Collected Steps per Second: 15,817.75587
Overall Steps per Second: 7,295.73631

Timestep Collection Time: 3.16113
Timestep Consumption Time: 3.69246
PPO Batch Consumption Time: 0.48429
Total Iteration Time: 6.85359

Cumulative Model Updates: 140,190
Cumulative Timesteps: 1,169,216,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1169216536...
Checkpoint 1169216536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.02275
Policy Entropy: 3.12711
Value Function Loss: 0.00399

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.58941
Value Function Update Magnitude: 0.53974

Collected Steps per Second: 15,456.52236
Overall Steps per Second: 8,610.94748

Timestep Collection Time: 3.23540
Timestep Consumption Time: 2.57209
PPO Batch Consumption Time: 0.30813
Total Iteration Time: 5.80749

Cumulative Model Updates: 140,196
Cumulative Timesteps: 1,169,266,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.84148
Policy Entropy: 3.11701
Value Function Loss: 0.00422

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.59519
Value Function Update Magnitude: 0.54510

Collected Steps per Second: 16,962.30720
Overall Steps per Second: 9,135.90422

Timestep Collection Time: 2.94901
Timestep Consumption Time: 2.52631
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 5.47532

Cumulative Model Updates: 140,202
Cumulative Timesteps: 1,169,316,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1169316566...
Checkpoint 1169316566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.49256
Policy Entropy: 3.13465
Value Function Loss: 0.00412

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.59025
Value Function Update Magnitude: 0.55700

Collected Steps per Second: 20,966.49779
Overall Steps per Second: 10,168.41310

Timestep Collection Time: 2.38562
Timestep Consumption Time: 2.53334
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.91896

Cumulative Model Updates: 140,208
Cumulative Timesteps: 1,169,366,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.53074
Policy Entropy: 3.13137
Value Function Loss: 0.00397

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.57784
Value Function Update Magnitude: 0.55273

Collected Steps per Second: 22,150.75193
Overall Steps per Second: 10,486.59552

Timestep Collection Time: 2.25834
Timestep Consumption Time: 2.51194
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.77028

Cumulative Model Updates: 140,214
Cumulative Timesteps: 1,169,416,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1169416608...
Checkpoint 1169416608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,837.67853
Policy Entropy: 3.13624
Value Function Loss: 0.00382

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.56812
Value Function Update Magnitude: 0.52809

Collected Steps per Second: 22,108.43201
Overall Steps per Second: 10,563.93778

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.47220
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.73441

Cumulative Model Updates: 140,220
Cumulative Timesteps: 1,169,466,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.47389
Policy Entropy: 3.13423
Value Function Loss: 0.00377

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.50613

Collected Steps per Second: 22,530.22954
Overall Steps per Second: 10,554.11109

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.51956
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.73995

Cumulative Model Updates: 140,226
Cumulative Timesteps: 1,169,516,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1169516648...
Checkpoint 1169516648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.25198
Policy Entropy: 3.13694
Value Function Loss: 0.00383

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.48359

Collected Steps per Second: 21,606.42668
Overall Steps per Second: 10,422.14956

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.80016

Cumulative Model Updates: 140,232
Cumulative Timesteps: 1,169,566,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.52177
Policy Entropy: 3.13678
Value Function Loss: 0.00392

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.50952

Collected Steps per Second: 21,439.57074
Overall Steps per Second: 10,246.85224

Timestep Collection Time: 2.33307
Timestep Consumption Time: 2.54843
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.88150

Cumulative Model Updates: 140,238
Cumulative Timesteps: 1,169,616,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1169616696...
Checkpoint 1169616696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.60356
Policy Entropy: 3.12016
Value Function Loss: 0.00420

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.54070

Collected Steps per Second: 21,364.72238
Overall Steps per Second: 10,248.28681

Timestep Collection Time: 2.34059
Timestep Consumption Time: 2.53886
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.87945

Cumulative Model Updates: 140,244
Cumulative Timesteps: 1,169,666,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.08590
Policy Entropy: 3.12694
Value Function Loss: 0.00439

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.58228
Value Function Update Magnitude: 0.56507

Collected Steps per Second: 21,554.41000
Overall Steps per Second: 10,438.00028

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.47226
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.79364

Cumulative Model Updates: 140,250
Cumulative Timesteps: 1,169,716,738

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1169716738...
Checkpoint 1169716738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.35371
Policy Entropy: 3.12585
Value Function Loss: 0.00433

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.58747
Value Function Update Magnitude: 0.58985

Collected Steps per Second: 21,683.93803
Overall Steps per Second: 10,195.37862

Timestep Collection Time: 2.30742
Timestep Consumption Time: 2.60010
PPO Batch Consumption Time: 0.30132
Total Iteration Time: 4.90752

Cumulative Model Updates: 140,256
Cumulative Timesteps: 1,169,766,772

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.20240
Policy Entropy: 3.12170
Value Function Loss: 0.00447

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.58609
Value Function Update Magnitude: 0.59267

Collected Steps per Second: 22,093.72115
Overall Steps per Second: 10,445.60310

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.52402
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.78747

Cumulative Model Updates: 140,262
Cumulative Timesteps: 1,169,816,780

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1169816780...
Checkpoint 1169816780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.29475
Policy Entropy: 3.11788
Value Function Loss: 0.00445

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.59484
Value Function Update Magnitude: 0.59399

Collected Steps per Second: 22,315.60682
Overall Steps per Second: 10,528.84993

Timestep Collection Time: 2.24067
Timestep Consumption Time: 2.50837
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.74905

Cumulative Model Updates: 140,268
Cumulative Timesteps: 1,169,866,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.71959
Policy Entropy: 3.12837
Value Function Loss: 0.00429

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.59133
Value Function Update Magnitude: 0.59106

Collected Steps per Second: 22,449.51811
Overall Steps per Second: 10,551.36673

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.73872

Cumulative Model Updates: 140,274
Cumulative Timesteps: 1,169,916,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1169916782...
Checkpoint 1169916782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.09060
Policy Entropy: 3.14209
Value Function Loss: 0.00442

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.58431
Value Function Update Magnitude: 0.57288

Collected Steps per Second: 22,394.39195
Overall Steps per Second: 10,654.29119

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.46103
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.69445

Cumulative Model Updates: 140,280
Cumulative Timesteps: 1,169,966,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.48635
Policy Entropy: 3.13653
Value Function Loss: 0.00424

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.58570
Value Function Update Magnitude: 0.57323

Collected Steps per Second: 22,098.49340
Overall Steps per Second: 10,379.40580

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.55504
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.81800

Cumulative Model Updates: 140,286
Cumulative Timesteps: 1,170,016,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1170016806...
Checkpoint 1170016806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.89817
Policy Entropy: 3.13492
Value Function Loss: 0.00401

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.56149

Collected Steps per Second: 22,286.05137
Overall Steps per Second: 10,605.11050

Timestep Collection Time: 2.24481
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.71735

Cumulative Model Updates: 140,292
Cumulative Timesteps: 1,170,066,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.11903
Policy Entropy: 3.12720
Value Function Loss: 0.00435

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.59088
Value Function Update Magnitude: 0.56330

Collected Steps per Second: 21,841.34005
Overall Steps per Second: 10,512.77296

Timestep Collection Time: 2.29052
Timestep Consumption Time: 2.46826
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.75878

Cumulative Model Updates: 140,298
Cumulative Timesteps: 1,170,116,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1170116862...
Checkpoint 1170116862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.49173
Policy Entropy: 3.13245
Value Function Loss: 0.00466

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.59142
Value Function Update Magnitude: 0.58557

Collected Steps per Second: 21,931.42037
Overall Steps per Second: 10,607.75930

Timestep Collection Time: 2.28120
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.71636

Cumulative Model Updates: 140,304
Cumulative Timesteps: 1,170,166,892

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.61468
Policy Entropy: 3.11808
Value Function Loss: 0.00470

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.59583
Value Function Update Magnitude: 0.59510

Collected Steps per Second: 21,405.48658
Overall Steps per Second: 10,152.69436

Timestep Collection Time: 2.33660
Timestep Consumption Time: 2.58978
PPO Batch Consumption Time: 0.30243
Total Iteration Time: 4.92638

Cumulative Model Updates: 140,310
Cumulative Timesteps: 1,170,216,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1170216908...
Checkpoint 1170216908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.91742
Policy Entropy: 3.12582
Value Function Loss: 0.00445

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.59570
Value Function Update Magnitude: 0.59681

Collected Steps per Second: 21,372.92159
Overall Steps per Second: 10,133.19144

Timestep Collection Time: 2.34044
Timestep Consumption Time: 2.59601
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.93645

Cumulative Model Updates: 140,316
Cumulative Timesteps: 1,170,266,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.09641
Policy Entropy: 3.13528
Value Function Loss: 0.00413

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.59446
Value Function Update Magnitude: 0.58037

Collected Steps per Second: 21,598.97896
Overall Steps per Second: 10,423.64095

Timestep Collection Time: 2.31622
Timestep Consumption Time: 2.48325
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.79947

Cumulative Model Updates: 140,322
Cumulative Timesteps: 1,170,316,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1170316958...
Checkpoint 1170316958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.75616
Policy Entropy: 3.13544
Value Function Loss: 0.00412

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.58442
Value Function Update Magnitude: 0.54534

Collected Steps per Second: 21,850.90783
Overall Steps per Second: 10,312.22751

Timestep Collection Time: 2.28933
Timestep Consumption Time: 2.56161
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 4.85094

Cumulative Model Updates: 140,328
Cumulative Timesteps: 1,170,366,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,444.96191
Policy Entropy: 3.13310
Value Function Loss: 0.00420

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.54478

Collected Steps per Second: 21,932.87014
Overall Steps per Second: 10,433.39409

Timestep Collection Time: 2.28041
Timestep Consumption Time: 2.51342
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.79384

Cumulative Model Updates: 140,334
Cumulative Timesteps: 1,170,416,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1170416998...
Checkpoint 1170416998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.67192
Policy Entropy: 3.12875
Value Function Loss: 0.00415

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.55532

Collected Steps per Second: 21,822.61709
Overall Steps per Second: 10,525.21505

Timestep Collection Time: 2.29138
Timestep Consumption Time: 2.45949
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.75088

Cumulative Model Updates: 140,340
Cumulative Timesteps: 1,170,467,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.07636
Policy Entropy: 3.13099
Value Function Loss: 0.00443

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.53362

Collected Steps per Second: 22,884.08244
Overall Steps per Second: 10,568.58108

Timestep Collection Time: 2.18589
Timestep Consumption Time: 2.54720
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.73309

Cumulative Model Updates: 140,346
Cumulative Timesteps: 1,170,517,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1170517024...
Checkpoint 1170517024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.39158
Policy Entropy: 3.14000
Value Function Loss: 0.00428

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.57718
Value Function Update Magnitude: 0.53575

Collected Steps per Second: 22,189.45673
Overall Steps per Second: 10,553.23851

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.48575
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.74016

Cumulative Model Updates: 140,352
Cumulative Timesteps: 1,170,567,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.42473
Policy Entropy: 3.14645
Value Function Loss: 0.00417

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.56889
Value Function Update Magnitude: 0.56062

Collected Steps per Second: 22,211.90932
Overall Steps per Second: 10,542.73012

Timestep Collection Time: 2.25176
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.74412

Cumulative Model Updates: 140,358
Cumulative Timesteps: 1,170,617,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1170617064...
Checkpoint 1170617064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,285.77133
Policy Entropy: 3.13727
Value Function Loss: 0.00404

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.56875
Value Function Update Magnitude: 0.57444

Collected Steps per Second: 22,278.20202
Overall Steps per Second: 10,598.12767

Timestep Collection Time: 2.24533
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.71989

Cumulative Model Updates: 140,364
Cumulative Timesteps: 1,170,667,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.86212
Policy Entropy: 3.12706
Value Function Loss: 0.00403

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.56541

Collected Steps per Second: 21,163.32258
Overall Steps per Second: 10,145.28408

Timestep Collection Time: 2.36305
Timestep Consumption Time: 2.56633
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.92938

Cumulative Model Updates: 140,370
Cumulative Timesteps: 1,170,717,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1170717096...
Checkpoint 1170717096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.84342
Policy Entropy: 3.12996
Value Function Loss: 0.00415

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.57495
Value Function Update Magnitude: 0.54220

Collected Steps per Second: 21,992.17701
Overall Steps per Second: 10,462.63510

Timestep Collection Time: 2.27481
Timestep Consumption Time: 2.50678
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.78159

Cumulative Model Updates: 140,376
Cumulative Timesteps: 1,170,767,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.85225
Policy Entropy: 3.13574
Value Function Loss: 0.00409

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.57395
Value Function Update Magnitude: 0.53893

Collected Steps per Second: 22,534.70815
Overall Steps per Second: 10,571.97192

Timestep Collection Time: 2.21942
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.73081

Cumulative Model Updates: 140,382
Cumulative Timesteps: 1,170,817,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1170817138...
Checkpoint 1170817138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.23625
Policy Entropy: 3.14968
Value Function Loss: 0.00401

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.57269
Value Function Update Magnitude: 0.54512

Collected Steps per Second: 22,426.28591
Overall Steps per Second: 10,515.61439

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.52561
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.75540

Cumulative Model Updates: 140,388
Cumulative Timesteps: 1,170,867,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,042.84708
Policy Entropy: 3.14490
Value Function Loss: 0.00387

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.53254

Collected Steps per Second: 21,679.49649
Overall Steps per Second: 10,482.05867

Timestep Collection Time: 2.30854
Timestep Consumption Time: 2.46609
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.77463

Cumulative Model Updates: 140,394
Cumulative Timesteps: 1,170,917,192

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1170917192...
Checkpoint 1170917192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,645.12497
Policy Entropy: 3.14834
Value Function Loss: 0.00392

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.57473
Value Function Update Magnitude: 0.53649

Collected Steps per Second: 21,437.27166
Overall Steps per Second: 10,278.97368

Timestep Collection Time: 2.33360
Timestep Consumption Time: 2.53323
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.86683

Cumulative Model Updates: 140,400
Cumulative Timesteps: 1,170,967,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329.25900
Policy Entropy: 3.14011
Value Function Loss: 0.00425

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.59218
Value Function Update Magnitude: 0.56927

Collected Steps per Second: 22,513.93682
Overall Steps per Second: 10,528.14082

Timestep Collection Time: 2.22111
Timestep Consumption Time: 2.52863
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.74975

Cumulative Model Updates: 140,406
Cumulative Timesteps: 1,171,017,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1171017224...
Checkpoint 1171017224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.72619
Policy Entropy: 3.14759
Value Function Loss: 0.00406

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.58859
Value Function Update Magnitude: 0.59893

Collected Steps per Second: 21,739.51979
Overall Steps per Second: 10,348.01491

Timestep Collection Time: 2.30033
Timestep Consumption Time: 2.53229
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.83262

Cumulative Model Updates: 140,412
Cumulative Timesteps: 1,171,067,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.99596
Policy Entropy: 3.13703
Value Function Loss: 0.00428

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.58063
Value Function Update Magnitude: 0.57276

Collected Steps per Second: 19,723.57102
Overall Steps per Second: 9,840.32826

Timestep Collection Time: 2.53524
Timestep Consumption Time: 2.54630
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 5.08154

Cumulative Model Updates: 140,418
Cumulative Timesteps: 1,171,117,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1171117236...
Checkpoint 1171117236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924.75319
Policy Entropy: 3.12723
Value Function Loss: 0.00420

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.58045
Value Function Update Magnitude: 0.54564

Collected Steps per Second: 18,628.58560
Overall Steps per Second: 9,345.93536

Timestep Collection Time: 2.68415
Timestep Consumption Time: 2.66598
PPO Batch Consumption Time: 0.30930
Total Iteration Time: 5.35013

Cumulative Model Updates: 140,424
Cumulative Timesteps: 1,171,167,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.18945
Policy Entropy: 3.13565
Value Function Loss: 0.00397

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.57159
Value Function Update Magnitude: 0.53401

Collected Steps per Second: 18,991.06483
Overall Steps per Second: 9,832.06270

Timestep Collection Time: 2.63292
Timestep Consumption Time: 2.45268
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 5.08561

Cumulative Model Updates: 140,430
Cumulative Timesteps: 1,171,217,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1171217240...
Checkpoint 1171217240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.18591
Policy Entropy: 3.13338
Value Function Loss: 0.00393

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.51314

Collected Steps per Second: 18,945.39594
Overall Steps per Second: 9,714.58969

Timestep Collection Time: 2.63990
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 5.14834

Cumulative Model Updates: 140,436
Cumulative Timesteps: 1,171,267,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.54211
Policy Entropy: 3.15037
Value Function Loss: 0.00386

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.50463

Collected Steps per Second: 21,147.05077
Overall Steps per Second: 10,217.24766

Timestep Collection Time: 2.36515
Timestep Consumption Time: 2.53010
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.89525

Cumulative Model Updates: 140,442
Cumulative Timesteps: 1,171,317,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1171317270...
Checkpoint 1171317270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,796.30989
Policy Entropy: 3.16802
Value Function Loss: 0.00407

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.51079

Collected Steps per Second: 20,659.18860
Overall Steps per Second: 10,018.91489

Timestep Collection Time: 2.42149
Timestep Consumption Time: 2.57167
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.99316

Cumulative Model Updates: 140,448
Cumulative Timesteps: 1,171,367,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.25235
Policy Entropy: 3.16170
Value Function Loss: 0.00401

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.57678
Value Function Update Magnitude: 0.52702

Collected Steps per Second: 17,193.44401
Overall Steps per Second: 8,961.29049

Timestep Collection Time: 2.90960
Timestep Consumption Time: 2.67286
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 5.58245

Cumulative Model Updates: 140,454
Cumulative Timesteps: 1,171,417,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1171417322...
Checkpoint 1171417322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.47993
Policy Entropy: 3.14852
Value Function Loss: 0.00401

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.52557

Collected Steps per Second: 20,370.62863
Overall Steps per Second: 10,021.84230

Timestep Collection Time: 2.45520
Timestep Consumption Time: 2.53530
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.99050

Cumulative Model Updates: 140,460
Cumulative Timesteps: 1,171,467,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.14016
Policy Entropy: 3.14868
Value Function Loss: 0.00376

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.50498

Collected Steps per Second: 17,710.78649
Overall Steps per Second: 8,957.10244

Timestep Collection Time: 2.82438
Timestep Consumption Time: 2.76024
PPO Batch Consumption Time: 0.32719
Total Iteration Time: 5.58462

Cumulative Model Updates: 140,466
Cumulative Timesteps: 1,171,517,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1171517358...
Checkpoint 1171517358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.42648
Policy Entropy: 3.15828
Value Function Loss: 0.00366

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.49151

Collected Steps per Second: 16,351.78094
Overall Steps per Second: 8,759.17443

Timestep Collection Time: 3.05997
Timestep Consumption Time: 2.65244
PPO Batch Consumption Time: 0.30145
Total Iteration Time: 5.71241

Cumulative Model Updates: 140,472
Cumulative Timesteps: 1,171,567,394

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.82827
Policy Entropy: 3.16343
Value Function Loss: 0.00400

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.51709

Collected Steps per Second: 17,395.22441
Overall Steps per Second: 6,500.83136

Timestep Collection Time: 2.87573
Timestep Consumption Time: 4.81928
PPO Batch Consumption Time: 0.53676
Total Iteration Time: 7.69502

Cumulative Model Updates: 140,478
Cumulative Timesteps: 1,171,617,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1171617418...
Checkpoint 1171617418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,668.50671
Policy Entropy: 3.15434
Value Function Loss: 0.00412

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.57675
Value Function Update Magnitude: 0.57391

Collected Steps per Second: 6,624.56898
Overall Steps per Second: 4,456.56196

Timestep Collection Time: 7.54947
Timestep Consumption Time: 3.67263
PPO Batch Consumption Time: 0.35798
Total Iteration Time: 11.22210

Cumulative Model Updates: 140,484
Cumulative Timesteps: 1,171,667,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1171667430...
Checkpoint 1171667430 saved!
