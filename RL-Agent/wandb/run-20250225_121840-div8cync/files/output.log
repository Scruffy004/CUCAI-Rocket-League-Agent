Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.13314
Policy Entropy: 3.76343
Value Function Loss: 0.07034

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04086
Policy Update Magnitude: 0.21887
Value Function Update Magnitude: 0.23644

Collected Steps per Second: 7,375.65081
Overall Steps per Second: 3,693.70591

Timestep Collection Time: 6.78123
Timestep Consumption Time: 6.75964
PPO Batch Consumption Time: 2.91422
Total Iteration Time: 13.54087

Cumulative Model Updates: 82,012
Cumulative Timesteps: 683,970,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239.01559
Policy Entropy: 3.74193
Value Function Loss: 0.06885

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.21964
Value Function Update Magnitude: 0.27178

Collected Steps per Second: 20,707.80263
Overall Steps per Second: 13,182.59719

Timestep Collection Time: 2.41455
Timestep Consumption Time: 1.37833
PPO Batch Consumption Time: 0.33875
Total Iteration Time: 3.79288

Cumulative Model Updates: 82,014
Cumulative Timesteps: 684,020,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 684020856...
Checkpoint 684020856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,049.70348
Policy Entropy: 3.73421
Value Function Loss: 0.06890

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.42355
Value Function Update Magnitude: 0.57430

Collected Steps per Second: 21,685.10334
Overall Steps per Second: 11,871.85413

Timestep Collection Time: 2.30665
Timestep Consumption Time: 1.90667
PPO Batch Consumption Time: 0.30217
Total Iteration Time: 4.21333

Cumulative Model Updates: 82,018
Cumulative Timesteps: 684,070,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,076.74136
Policy Entropy: 3.72316
Value Function Loss: 0.06719

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.65773
Value Function Update Magnitude: 0.86032

Collected Steps per Second: 22,195.61013
Overall Steps per Second: 10,766.94834

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.39229
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.64607

Cumulative Model Updates: 82,024
Cumulative Timesteps: 684,120,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 684120900...
Checkpoint 684120900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.66038
Policy Entropy: 3.72956
Value Function Loss: 0.06369

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.58368
Value Function Update Magnitude: 0.82223

Collected Steps per Second: 22,132.61172
Overall Steps per Second: 10,888.68167

Timestep Collection Time: 2.26037
Timestep Consumption Time: 2.33412
PPO Batch Consumption Time: 0.27463
Total Iteration Time: 4.59450

Cumulative Model Updates: 82,030
Cumulative Timesteps: 684,170,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.52082
Policy Entropy: 3.72619
Value Function Loss: 0.06257

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.63547
Value Function Update Magnitude: 0.70099

Collected Steps per Second: 22,143.79922
Overall Steps per Second: 10,855.80988

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.34861
PPO Batch Consumption Time: 0.27585
Total Iteration Time: 4.60730

Cumulative Model Updates: 82,036
Cumulative Timesteps: 684,220,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 684220944...
Checkpoint 684220944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,435.70631
Policy Entropy: 3.71176
Value Function Loss: 0.06727

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.68197
Value Function Update Magnitude: 0.66756

Collected Steps per Second: 21,949.23383
Overall Steps per Second: 10,695.44771

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.39719
PPO Batch Consumption Time: 0.27489
Total Iteration Time: 4.67545

Cumulative Model Updates: 82,042
Cumulative Timesteps: 684,270,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.45454
Policy Entropy: 3.69002
Value Function Loss: 0.06753

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.66235
Value Function Update Magnitude: 0.67833

Collected Steps per Second: 21,751.91962
Overall Steps per Second: 10,533.34652

Timestep Collection Time: 2.29865
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.74683

Cumulative Model Updates: 82,048
Cumulative Timesteps: 684,320,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 684320950...
Checkpoint 684320950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,683.87392
Policy Entropy: 3.69443
Value Function Loss: 0.07005

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.59703
Value Function Update Magnitude: 0.69852

Collected Steps per Second: 21,846.86699
Overall Steps per Second: 10,507.96708

Timestep Collection Time: 2.28948
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.76001

Cumulative Model Updates: 82,054
Cumulative Timesteps: 684,370,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,823.29698
Policy Entropy: 3.70226
Value Function Loss: 0.07019

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.70743

Collected Steps per Second: 22,515.06720
Overall Steps per Second: 10,825.88981

Timestep Collection Time: 2.22074
Timestep Consumption Time: 2.39782
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.61856

Cumulative Model Updates: 82,060
Cumulative Timesteps: 684,420,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 684420968...
Checkpoint 684420968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,532.62094
Policy Entropy: 3.70135
Value Function Loss: 0.06951

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.69482

Collected Steps per Second: 21,362.10611
Overall Steps per Second: 10,321.07503

Timestep Collection Time: 2.34144
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.84620

Cumulative Model Updates: 82,066
Cumulative Timesteps: 684,470,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,649.01460
Policy Entropy: 3.70473
Value Function Loss: 0.06635

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.66493

Collected Steps per Second: 22,459.92277
Overall Steps per Second: 10,559.86182

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.50993
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.73718

Cumulative Model Updates: 82,072
Cumulative Timesteps: 684,521,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 684521010...
Checkpoint 684521010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,525.96094
Policy Entropy: 3.71663
Value Function Loss: 0.06557

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.69026

Collected Steps per Second: 22,733.06998
Overall Steps per Second: 10,598.79281

Timestep Collection Time: 2.20049
Timestep Consumption Time: 2.51929
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.71978

Cumulative Model Updates: 82,078
Cumulative Timesteps: 684,571,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,199.46613
Policy Entropy: 3.71376
Value Function Loss: 0.06747

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.74372

Collected Steps per Second: 22,853.12079
Overall Steps per Second: 10,838.74751

Timestep Collection Time: 2.18850
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.61437

Cumulative Model Updates: 82,084
Cumulative Timesteps: 684,621,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 684621048...
Checkpoint 684621048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,140.47619
Policy Entropy: 3.70111
Value Function Loss: 0.07147

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.56652
Value Function Update Magnitude: 0.82554

Collected Steps per Second: 22,602.59387
Overall Steps per Second: 10,642.33895

Timestep Collection Time: 2.21267
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.69934

Cumulative Model Updates: 82,090
Cumulative Timesteps: 684,671,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,694.35314
Policy Entropy: 3.69106
Value Function Loss: 0.07069

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.54489
Value Function Update Magnitude: 0.86085

Collected Steps per Second: 22,830.24983
Overall Steps per Second: 10,805.75910

Timestep Collection Time: 2.19069
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.62846

Cumulative Model Updates: 82,096
Cumulative Timesteps: 684,721,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 684721074...
Checkpoint 684721074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,019.88939
Policy Entropy: 3.69039
Value Function Loss: 0.07221

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.58803
Value Function Update Magnitude: 0.79226

Collected Steps per Second: 22,655.85843
Overall Steps per Second: 10,707.52544

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.46396
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.67204

Cumulative Model Updates: 82,102
Cumulative Timesteps: 684,771,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,759.18572
Policy Entropy: 3.69935
Value Function Loss: 0.07131

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.58679
Value Function Update Magnitude: 0.76077

Collected Steps per Second: 22,869.18305
Overall Steps per Second: 10,809.74229

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.43979
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.62675

Cumulative Model Updates: 82,108
Cumulative Timesteps: 684,821,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 684821114...
Checkpoint 684821114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,386.63874
Policy Entropy: 3.70563
Value Function Loss: 0.06978

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.77529

Collected Steps per Second: 22,029.23091
Overall Steps per Second: 10,639.80299

Timestep Collection Time: 2.27017
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.70028

Cumulative Model Updates: 82,114
Cumulative Timesteps: 684,871,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,010.44835
Policy Entropy: 3.71001
Value Function Loss: 0.06698

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.63412
Value Function Update Magnitude: 0.76888

Collected Steps per Second: 22,537.96929
Overall Steps per Second: 10,696.59134

Timestep Collection Time: 2.21919
Timestep Consumption Time: 2.45669
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.67588

Cumulative Model Updates: 82,120
Cumulative Timesteps: 684,921,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 684921140...
Checkpoint 684921140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.24521
Policy Entropy: 3.70088
Value Function Loss: 0.06495

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.63449
Value Function Update Magnitude: 0.81727

Collected Steps per Second: 22,534.57606
Overall Steps per Second: 10,512.80569

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.53760
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.75668

Cumulative Model Updates: 82,126
Cumulative Timesteps: 684,971,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.90776
Policy Entropy: 3.70514
Value Function Loss: 0.06443

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.87652

Collected Steps per Second: 21,747.48458
Overall Steps per Second: 10,441.81943

Timestep Collection Time: 2.29930
Timestep Consumption Time: 2.48952
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.78882

Cumulative Model Updates: 82,132
Cumulative Timesteps: 685,021,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 685021150...
Checkpoint 685021150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,841.31533
Policy Entropy: 3.70072
Value Function Loss: 0.06605

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.51680
Value Function Update Magnitude: 0.80135

Collected Steps per Second: 22,504.04692
Overall Steps per Second: 10,614.79666

Timestep Collection Time: 2.22280
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.71248

Cumulative Model Updates: 82,138
Cumulative Timesteps: 685,071,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,704.46530
Policy Entropy: 3.70804
Value Function Loss: 0.06816

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.52325
Value Function Update Magnitude: 0.83950

Collected Steps per Second: 22,659.93177
Overall Steps per Second: 10,525.57352

Timestep Collection Time: 2.20671
Timestep Consumption Time: 2.54400
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.75072

Cumulative Model Updates: 82,144
Cumulative Timesteps: 685,121,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 685121176...
Checkpoint 685121176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,889.53336
Policy Entropy: 3.69813
Value Function Loss: 0.06892

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.52754
Value Function Update Magnitude: 0.86581

Collected Steps per Second: 22,876.35069
Overall Steps per Second: 10,649.54970

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.69579

Cumulative Model Updates: 82,150
Cumulative Timesteps: 685,171,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.48104
Policy Entropy: 3.69665
Value Function Loss: 0.06577

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.52797
Value Function Update Magnitude: 0.86048

Collected Steps per Second: 22,676.71334
Overall Steps per Second: 10,763.27663

Timestep Collection Time: 2.20632
Timestep Consumption Time: 2.44208
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.64840

Cumulative Model Updates: 82,156
Cumulative Timesteps: 685,221,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 685221216...
Checkpoint 685221216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,186.02834
Policy Entropy: 3.69117
Value Function Loss: 0.06264

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.53417
Value Function Update Magnitude: 0.87196

Collected Steps per Second: 22,486.22479
Overall Steps per Second: 10,763.69360

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.64580

Cumulative Model Updates: 82,162
Cumulative Timesteps: 685,271,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,795.13687
Policy Entropy: 3.69704
Value Function Loss: 0.06461

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.88941

Collected Steps per Second: 22,744.11380
Overall Steps per Second: 10,784.88318

Timestep Collection Time: 2.19890
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.63723

Cumulative Model Updates: 82,168
Cumulative Timesteps: 685,321,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 685321234...
Checkpoint 685321234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,064.31559
Policy Entropy: 3.69491
Value Function Loss: 0.06559

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.88924

Collected Steps per Second: 22,631.03161
Overall Steps per Second: 10,726.49026

Timestep Collection Time: 2.21024
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.66322

Cumulative Model Updates: 82,174
Cumulative Timesteps: 685,371,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.66074
Policy Entropy: 3.68948
Value Function Loss: 0.06804

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.61938
Value Function Update Magnitude: 0.87760

Collected Steps per Second: 22,175.18324
Overall Steps per Second: 10,490.41461

Timestep Collection Time: 2.25576
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.76835

Cumulative Model Updates: 82,180
Cumulative Timesteps: 685,421,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 685421276...
Checkpoint 685421276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.87888
Policy Entropy: 3.68696
Value Function Loss: 0.06583

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.62855
Value Function Update Magnitude: 0.87824

Collected Steps per Second: 21,446.92816
Overall Steps per Second: 10,497.62368

Timestep Collection Time: 2.33134
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.76298

Cumulative Model Updates: 82,186
Cumulative Timesteps: 685,471,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.27574
Policy Entropy: 3.68278
Value Function Loss: 0.06644

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.63815
Value Function Update Magnitude: 0.86398

Collected Steps per Second: 21,834.30702
Overall Steps per Second: 10,589.66651

Timestep Collection Time: 2.29098
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.72366

Cumulative Model Updates: 82,192
Cumulative Timesteps: 685,521,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 685521298...
Checkpoint 685521298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,571.44628
Policy Entropy: 3.68415
Value Function Loss: 0.06737

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.59463
Value Function Update Magnitude: 0.76008

Collected Steps per Second: 22,146.91157
Overall Steps per Second: 10,599.53461

Timestep Collection Time: 2.25864
Timestep Consumption Time: 2.46062
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.71926

Cumulative Model Updates: 82,198
Cumulative Timesteps: 685,571,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,034.36814
Policy Entropy: 3.66886
Value Function Loss: 0.06845

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.58681
Value Function Update Magnitude: 0.77616

Collected Steps per Second: 22,449.74267
Overall Steps per Second: 10,358.82540

Timestep Collection Time: 2.22809
Timestep Consumption Time: 2.60064
PPO Batch Consumption Time: 0.30509
Total Iteration Time: 4.82873

Cumulative Model Updates: 82,204
Cumulative Timesteps: 685,621,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 685621340...
Checkpoint 685621340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,706.23395
Policy Entropy: 3.67940
Value Function Loss: 0.06520

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.86636

Collected Steps per Second: 22,365.91961
Overall Steps per Second: 10,621.75056

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.47306
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.70977

Cumulative Model Updates: 82,210
Cumulative Timesteps: 685,671,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,618.35911
Policy Entropy: 3.67125
Value Function Loss: 0.06468

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.90066

Collected Steps per Second: 22,696.91888
Overall Steps per Second: 10,586.70013

Timestep Collection Time: 2.20303
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.72310

Cumulative Model Updates: 82,216
Cumulative Timesteps: 685,721,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 685721368...
Checkpoint 685721368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.84186
Policy Entropy: 3.68574
Value Function Loss: 0.06422

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.57621
Value Function Update Magnitude: 0.89018

Collected Steps per Second: 22,562.48802
Overall Steps per Second: 10,587.34266

Timestep Collection Time: 2.21678
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.72413

Cumulative Model Updates: 82,222
Cumulative Timesteps: 685,771,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,949.72504
Policy Entropy: 3.69841
Value Function Loss: 0.06385

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.60563
Value Function Update Magnitude: 0.87674

Collected Steps per Second: 22,546.36618
Overall Steps per Second: 10,575.92814

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.51067
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.72885

Cumulative Model Updates: 82,228
Cumulative Timesteps: 685,821,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 685821396...
Checkpoint 685821396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220.25297
Policy Entropy: 3.69952
Value Function Loss: 0.06168

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.61900
Value Function Update Magnitude: 0.87683

Collected Steps per Second: 22,721.78032
Overall Steps per Second: 10,624.93122

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.50588
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.70685

Cumulative Model Updates: 82,234
Cumulative Timesteps: 685,871,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,277.34362
Policy Entropy: 3.70316
Value Function Loss: 0.06469

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.61085
Value Function Update Magnitude: 0.87716

Collected Steps per Second: 23,189.05797
Overall Steps per Second: 10,805.68965

Timestep Collection Time: 2.15645
Timestep Consumption Time: 2.47130
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.62775

Cumulative Model Updates: 82,240
Cumulative Timesteps: 685,921,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 685921412...
Checkpoint 685921412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,537.09228
Policy Entropy: 3.70026
Value Function Loss: 0.06516

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.66478
Value Function Update Magnitude: 0.85230

Collected Steps per Second: 22,567.89714
Overall Steps per Second: 10,646.05175

Timestep Collection Time: 2.21633
Timestep Consumption Time: 2.48193
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.69827

Cumulative Model Updates: 82,246
Cumulative Timesteps: 685,971,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,292.61503
Policy Entropy: 3.69691
Value Function Loss: 0.06761

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.62527
Value Function Update Magnitude: 0.85405

Collected Steps per Second: 22,164.00995
Overall Steps per Second: 10,432.53949

Timestep Collection Time: 2.25672
Timestep Consumption Time: 2.53770
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.79442

Cumulative Model Updates: 82,252
Cumulative Timesteps: 686,021,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 686021448...
Checkpoint 686021448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,598.02060
Policy Entropy: 3.70073
Value Function Loss: 0.06846

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.57345
Value Function Update Magnitude: 0.86056

Collected Steps per Second: 22,141.75006
Overall Steps per Second: 10,621.57970

Timestep Collection Time: 2.25845
Timestep Consumption Time: 2.44951
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.70796

Cumulative Model Updates: 82,258
Cumulative Timesteps: 686,071,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,390.92937
Policy Entropy: 3.68553
Value Function Loss: 0.07016

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07081
Policy Update Magnitude: 0.71053
Value Function Update Magnitude: 0.82777

Collected Steps per Second: 22,432.84540
Overall Steps per Second: 10,539.92819

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.74652

Cumulative Model Updates: 82,264
Cumulative Timesteps: 686,121,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 686121482...
Checkpoint 686121482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,707.90176
Policy Entropy: 3.67672
Value Function Loss: 0.07220

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.65356
Value Function Update Magnitude: 0.81637

Collected Steps per Second: 22,251.74268
Overall Steps per Second: 10,551.33055

Timestep Collection Time: 2.24710
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.73893

Cumulative Model Updates: 82,270
Cumulative Timesteps: 686,171,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,347.65027
Policy Entropy: 3.67846
Value Function Loss: 0.06921

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.68114
Value Function Update Magnitude: 0.84642

Collected Steps per Second: 22,182.28947
Overall Steps per Second: 10,496.11989

Timestep Collection Time: 2.25540
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.76652

Cumulative Model Updates: 82,276
Cumulative Timesteps: 686,221,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 686221514...
Checkpoint 686221514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,094.24839
Policy Entropy: 3.67954
Value Function Loss: 0.06820

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.77388
Value Function Update Magnitude: 0.87949

Collected Steps per Second: 22,592.40455
Overall Steps per Second: 10,550.22230

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.52620
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.73943

Cumulative Model Updates: 82,282
Cumulative Timesteps: 686,271,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,255.90560
Policy Entropy: 3.67680
Value Function Loss: 0.06647

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.71253
Value Function Update Magnitude: 0.87256

Collected Steps per Second: 22,866.04038
Overall Steps per Second: 10,500.94437

Timestep Collection Time: 2.18796
Timestep Consumption Time: 2.57637
PPO Batch Consumption Time: 0.30162
Total Iteration Time: 4.76433

Cumulative Model Updates: 82,288
Cumulative Timesteps: 686,321,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 686321546...
Checkpoint 686321546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,147.89871
Policy Entropy: 3.66701
Value Function Loss: 0.06730

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.19758
Policy Update Magnitude: 0.54217
Value Function Update Magnitude: 0.84669

Collected Steps per Second: 22,591.30782
Overall Steps per Second: 10,689.48183

Timestep Collection Time: 2.21439
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.67993

Cumulative Model Updates: 82,294
Cumulative Timesteps: 686,371,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.22446
Policy Entropy: 3.68402
Value Function Loss: 0.06651

Mean KL Divergence: 0.03568
SB3 Clip Fraction: 0.21291
Policy Update Magnitude: 0.43857
Value Function Update Magnitude: 0.80859

Collected Steps per Second: 22,661.12825
Overall Steps per Second: 10,635.59784

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.70326

Cumulative Model Updates: 82,300
Cumulative Timesteps: 686,421,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 686421594...
Checkpoint 686421594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206.71614
Policy Entropy: 3.70584
Value Function Loss: 0.06527

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.18575
Policy Update Magnitude: 0.48337
Value Function Update Magnitude: 0.82167

Collected Steps per Second: 22,352.60797
Overall Steps per Second: 10,543.29564

Timestep Collection Time: 2.23813
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.74501

Cumulative Model Updates: 82,306
Cumulative Timesteps: 686,471,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.10140
Policy Entropy: 3.71435
Value Function Loss: 0.06353

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.56602
Value Function Update Magnitude: 0.76990

Collected Steps per Second: 22,837.22542
Overall Steps per Second: 10,785.87045

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.63588

Cumulative Model Updates: 82,312
Cumulative Timesteps: 686,521,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 686521624...
Checkpoint 686521624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,555.49956
Policy Entropy: 3.68635
Value Function Loss: 0.06392

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.61052
Value Function Update Magnitude: 0.66424

Collected Steps per Second: 22,567.05838
Overall Steps per Second: 10,661.95205

Timestep Collection Time: 2.21651
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.69145

Cumulative Model Updates: 82,318
Cumulative Timesteps: 686,571,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,424.48944
Policy Entropy: 3.68721
Value Function Loss: 0.06184

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.62547
Value Function Update Magnitude: 0.69965

Collected Steps per Second: 22,327.68730
Overall Steps per Second: 10,498.55300

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.52359
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.76332

Cumulative Model Updates: 82,324
Cumulative Timesteps: 686,621,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 686621652...
Checkpoint 686621652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,681.63192
Policy Entropy: 3.68333
Value Function Loss: 0.06160

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.67302
Value Function Update Magnitude: 0.80104

Collected Steps per Second: 22,307.23516
Overall Steps per Second: 10,595.46554

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.47837
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.72051

Cumulative Model Updates: 82,330
Cumulative Timesteps: 686,671,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.72432
Policy Entropy: 3.67060
Value Function Loss: 0.06367

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.64112
Value Function Update Magnitude: 0.81444

Collected Steps per Second: 22,206.22544
Overall Steps per Second: 10,494.70813

Timestep Collection Time: 2.25198
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.76507

Cumulative Model Updates: 82,336
Cumulative Timesteps: 686,721,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 686721676...
Checkpoint 686721676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.40138
Policy Entropy: 3.66392
Value Function Loss: 0.06514

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.57953
Value Function Update Magnitude: 0.80369

Collected Steps per Second: 22,319.15590
Overall Steps per Second: 10,632.02347

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.46373
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.70503

Cumulative Model Updates: 82,342
Cumulative Timesteps: 686,771,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.28749
Policy Entropy: 3.65440
Value Function Loss: 0.06771

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.56978
Value Function Update Magnitude: 0.73723

Collected Steps per Second: 22,375.51389
Overall Steps per Second: 10,526.83906

Timestep Collection Time: 2.23539
Timestep Consumption Time: 2.51608
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.75147

Cumulative Model Updates: 82,348
Cumulative Timesteps: 686,821,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 686821718...
Checkpoint 686821718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,864.94006
Policy Entropy: 3.66222
Value Function Loss: 0.06588

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.68897
Value Function Update Magnitude: 0.70931

Collected Steps per Second: 22,560.07104
Overall Steps per Second: 10,506.46099

Timestep Collection Time: 2.21719
Timestep Consumption Time: 2.54369
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.76088

Cumulative Model Updates: 82,354
Cumulative Timesteps: 686,871,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,288.03584
Policy Entropy: 3.66354
Value Function Loss: 0.06498

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.71069
Value Function Update Magnitude: 0.80068

Collected Steps per Second: 22,724.18099
Overall Steps per Second: 10,623.96728

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.70916

Cumulative Model Updates: 82,360
Cumulative Timesteps: 686,921,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 686921768...
Checkpoint 686921768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,129.99554
Policy Entropy: 3.66731
Value Function Loss: 0.06542

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.61080
Value Function Update Magnitude: 0.82214

Collected Steps per Second: 22,614.69652
Overall Steps per Second: 10,493.48948

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.55411
PPO Batch Consumption Time: 0.30317
Total Iteration Time: 4.76524

Cumulative Model Updates: 82,366
Cumulative Timesteps: 686,971,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,831.31916
Policy Entropy: 3.65229
Value Function Loss: 0.06900

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.63929
Value Function Update Magnitude: 0.78263

Collected Steps per Second: 22,863.48075
Overall Steps per Second: 10,845.08376

Timestep Collection Time: 2.18838
Timestep Consumption Time: 2.42514
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.61352

Cumulative Model Updates: 82,372
Cumulative Timesteps: 687,021,806

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 687021806...
Checkpoint 687021806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,578.21474
Policy Entropy: 3.64723
Value Function Loss: 0.07052

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.54540
Value Function Update Magnitude: 0.73509

Collected Steps per Second: 22,519.41531
Overall Steps per Second: 10,739.56141

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.43606
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.65699

Cumulative Model Updates: 82,378
Cumulative Timesteps: 687,071,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,283.80722
Policy Entropy: 3.65058
Value Function Loss: 0.07073

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.44222
Value Function Update Magnitude: 0.69442

Collected Steps per Second: 23,245.47347
Overall Steps per Second: 10,883.69248

Timestep Collection Time: 2.15207
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.59642

Cumulative Model Updates: 82,384
Cumulative Timesteps: 687,121,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 687121846...
Checkpoint 687121846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,674.14739
Policy Entropy: 3.64367
Value Function Loss: 0.06997

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.57349
Value Function Update Magnitude: 0.72748

Collected Steps per Second: 22,586.35433
Overall Steps per Second: 10,671.23625

Timestep Collection Time: 2.21443
Timestep Consumption Time: 2.47256
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.68699

Cumulative Model Updates: 82,390
Cumulative Timesteps: 687,171,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.08844
Policy Entropy: 3.64430
Value Function Loss: 0.07043

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.57496
Value Function Update Magnitude: 0.71328

Collected Steps per Second: 22,140.58666
Overall Steps per Second: 10,430.98744

Timestep Collection Time: 2.25893
Timestep Consumption Time: 2.53582
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.79475

Cumulative Model Updates: 82,396
Cumulative Timesteps: 687,221,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 687221876...
Checkpoint 687221876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,914.34666
Policy Entropy: 3.63025
Value Function Loss: 0.07076

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.71426

Collected Steps per Second: 22,274.71285
Overall Steps per Second: 10,678.21141

Timestep Collection Time: 2.24506
Timestep Consumption Time: 2.43812
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.68318

Cumulative Model Updates: 82,402
Cumulative Timesteps: 687,271,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,190.41334
Policy Entropy: 3.63096
Value Function Loss: 0.06844

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.70154

Collected Steps per Second: 22,447.18873
Overall Steps per Second: 10,598.90442

Timestep Collection Time: 2.22843
Timestep Consumption Time: 2.49111
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.71954

Cumulative Model Updates: 82,408
Cumulative Timesteps: 687,321,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 687321906...
Checkpoint 687321906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,069.08821
Policy Entropy: 3.64621
Value Function Loss: 0.06446

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.56907
Value Function Update Magnitude: 0.70484

Collected Steps per Second: 21,405.08775
Overall Steps per Second: 10,466.10189

Timestep Collection Time: 2.33655
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.77867

Cumulative Model Updates: 82,414
Cumulative Timesteps: 687,371,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.10328
Policy Entropy: 3.65187
Value Function Loss: 0.06537

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.76121

Collected Steps per Second: 22,095.17599
Overall Steps per Second: 10,438.21968

Timestep Collection Time: 2.26348
Timestep Consumption Time: 2.52776
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.79124

Cumulative Model Updates: 82,420
Cumulative Timesteps: 687,421,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 687421932...
Checkpoint 687421932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.76430
Policy Entropy: 3.65718
Value Function Loss: 0.06523

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.56460
Value Function Update Magnitude: 0.71751

Collected Steps per Second: 22,126.25613
Overall Steps per Second: 10,696.19039

Timestep Collection Time: 2.25985
Timestep Consumption Time: 2.41490
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.67475

Cumulative Model Updates: 82,426
Cumulative Timesteps: 687,471,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,833.76831
Policy Entropy: 3.65324
Value Function Loss: 0.06812

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.68860

Collected Steps per Second: 22,756.69599
Overall Steps per Second: 10,618.55368

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.71025

Cumulative Model Updates: 82,432
Cumulative Timesteps: 687,521,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 687521950...
Checkpoint 687521950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,244.72514
Policy Entropy: 3.66839
Value Function Loss: 0.06814

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.53900
Value Function Update Magnitude: 0.69120

Collected Steps per Second: 22,722.98187
Overall Steps per Second: 10,601.04162

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.51650
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.71727

Cumulative Model Updates: 82,438
Cumulative Timesteps: 687,571,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,862.46701
Policy Entropy: 3.67192
Value Function Loss: 0.07132

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10372
Policy Update Magnitude: 0.51823
Value Function Update Magnitude: 0.68841

Collected Steps per Second: 22,144.08117
Overall Steps per Second: 10,605.21794

Timestep Collection Time: 2.25794
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.71466

Cumulative Model Updates: 82,444
Cumulative Timesteps: 687,621,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 687621958...
Checkpoint 687621958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,883.08666
Policy Entropy: 3.66484
Value Function Loss: 0.07016

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.50423
Value Function Update Magnitude: 0.69573

Collected Steps per Second: 22,094.10584
Overall Steps per Second: 10,547.44482

Timestep Collection Time: 2.26386
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.74219

Cumulative Model Updates: 82,450
Cumulative Timesteps: 687,671,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,325.42620
Policy Entropy: 3.65648
Value Function Loss: 0.07026

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.64018
Value Function Update Magnitude: 0.65186

Collected Steps per Second: 22,956.98384
Overall Steps per Second: 10,706.76076

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.67032

Cumulative Model Updates: 82,456
Cumulative Timesteps: 687,721,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 687721980...
Checkpoint 687721980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.48187
Policy Entropy: 3.65873
Value Function Loss: 0.06847

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.75291
Value Function Update Magnitude: 0.74891

Collected Steps per Second: 22,630.98735
Overall Steps per Second: 10,605.86092

Timestep Collection Time: 2.20998
Timestep Consumption Time: 2.50572
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.71569

Cumulative Model Updates: 82,462
Cumulative Timesteps: 687,771,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,451.67766
Policy Entropy: 3.67112
Value Function Loss: 0.06854

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.72452
Value Function Update Magnitude: 0.80033

Collected Steps per Second: 22,735.76391
Overall Steps per Second: 10,622.94050

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.50902
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.70943

Cumulative Model Updates: 82,468
Cumulative Timesteps: 687,822,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 687822022...
Checkpoint 687822022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,249.27379
Policy Entropy: 3.66786
Value Function Loss: 0.06818

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06870
Policy Update Magnitude: 0.72371
Value Function Update Magnitude: 0.76793

Collected Steps per Second: 22,676.69179
Overall Steps per Second: 10,641.35350

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.49524
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.70147

Cumulative Model Updates: 82,474
Cumulative Timesteps: 687,872,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,905.31722
Policy Entropy: 3.65891
Value Function Loss: 0.07125

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.70020
Value Function Update Magnitude: 0.78838

Collected Steps per Second: 22,539.03632
Overall Steps per Second: 10,705.71212

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.45242
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.67115

Cumulative Model Updates: 82,480
Cumulative Timesteps: 687,922,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 687922060...
Checkpoint 687922060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,666.95453
Policy Entropy: 3.66432
Value Function Loss: 0.07064

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.83834

Collected Steps per Second: 21,833.00635
Overall Steps per Second: 10,585.75200

Timestep Collection Time: 2.29148
Timestep Consumption Time: 2.43468
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.72616

Cumulative Model Updates: 82,486
Cumulative Timesteps: 687,972,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,008.82437
Policy Entropy: 3.67946
Value Function Loss: 0.06946

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.49901
Value Function Update Magnitude: 0.87984

Collected Steps per Second: 22,190.62623
Overall Steps per Second: 10,532.26903

Timestep Collection Time: 2.25465
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.75035

Cumulative Model Updates: 82,492
Cumulative Timesteps: 688,022,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 688022122...
Checkpoint 688022122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,618.26469
Policy Entropy: 3.68843
Value Function Loss: 0.06560

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.49605
Value Function Update Magnitude: 0.87091

Collected Steps per Second: 21,846.54792
Overall Steps per Second: 10,570.37966

Timestep Collection Time: 2.28906
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73096

Cumulative Model Updates: 82,498
Cumulative Timesteps: 688,072,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,819.53157
Policy Entropy: 3.69428
Value Function Loss: 0.06362

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.49531
Value Function Update Magnitude: 0.73532

Collected Steps per Second: 22,284.65936
Overall Steps per Second: 10,562.28906

Timestep Collection Time: 2.24379
Timestep Consumption Time: 2.49023
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.73401

Cumulative Model Updates: 82,504
Cumulative Timesteps: 688,122,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 688122132...
Checkpoint 688122132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,924.84895
Policy Entropy: 3.69811
Value Function Loss: 0.06142

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.72385

Collected Steps per Second: 22,457.93648
Overall Steps per Second: 10,610.75693

Timestep Collection Time: 2.22763
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.71484

Cumulative Model Updates: 82,510
Cumulative Timesteps: 688,172,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,788.86945
Policy Entropy: 3.69750
Value Function Loss: 0.06085

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.65008
Value Function Update Magnitude: 0.69860

Collected Steps per Second: 22,709.94997
Overall Steps per Second: 10,570.05478

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.53120
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.73507

Cumulative Model Updates: 82,516
Cumulative Timesteps: 688,222,210

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 688222210...
Checkpoint 688222210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,877.77909
Policy Entropy: 3.68813
Value Function Loss: 0.05896

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.63346
Value Function Update Magnitude: 0.76370

Collected Steps per Second: 21,735.96467
Overall Steps per Second: 10,564.24681

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.73313

Cumulative Model Updates: 82,522
Cumulative Timesteps: 688,272,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.91145
Policy Entropy: 3.69380
Value Function Loss: 0.05700

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.58036
Value Function Update Magnitude: 0.77966

Collected Steps per Second: 22,822.29165
Overall Steps per Second: 10,669.09147

Timestep Collection Time: 2.19198
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.68887

Cumulative Model Updates: 82,528
Cumulative Timesteps: 688,322,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 688322238...
Checkpoint 688322238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,956.04176
Policy Entropy: 3.67815
Value Function Loss: 0.05777

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.62551
Value Function Update Magnitude: 0.80384

Collected Steps per Second: 22,234.86787
Overall Steps per Second: 10,540.59577

Timestep Collection Time: 2.24917
Timestep Consumption Time: 2.49534
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74451

Cumulative Model Updates: 82,534
Cumulative Timesteps: 688,372,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,493.95536
Policy Entropy: 3.68790
Value Function Loss: 0.05787

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.78259

Collected Steps per Second: 22,941.42023
Overall Steps per Second: 10,840.69398

Timestep Collection Time: 2.18077
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.61502

Cumulative Model Updates: 82,540
Cumulative Timesteps: 688,422,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 688422278...
Checkpoint 688422278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,685.82195
Policy Entropy: 3.68140
Value Function Loss: 0.06004

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08333
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.69586

Collected Steps per Second: 22,284.81269
Overall Steps per Second: 10,670.58847

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.69009

Cumulative Model Updates: 82,546
Cumulative Timesteps: 688,472,324

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,484.22815
Policy Entropy: 3.67847
Value Function Loss: 0.05850

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.53124
Value Function Update Magnitude: 0.71801

Collected Steps per Second: 22,330.53106
Overall Steps per Second: 10,585.00682

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.48517
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.72480

Cumulative Model Updates: 82,552
Cumulative Timesteps: 688,522,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 688522336...
Checkpoint 688522336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,455.13846
Policy Entropy: 3.68891
Value Function Loss: 0.05683

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.75013

Collected Steps per Second: 22,295.77359
Overall Steps per Second: 10,612.05875

Timestep Collection Time: 2.24285
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.71219

Cumulative Model Updates: 82,558
Cumulative Timesteps: 688,572,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,287.64383
Policy Entropy: 3.69996
Value Function Loss: 0.05354

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.73776

Collected Steps per Second: 22,262.06737
Overall Steps per Second: 10,663.56257

Timestep Collection Time: 2.24597
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.68886

Cumulative Model Updates: 82,564
Cumulative Timesteps: 688,622,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 688622342...
Checkpoint 688622342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.14876
Policy Entropy: 3.71205
Value Function Loss: 0.05481

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.74241

Collected Steps per Second: 22,293.62108
Overall Steps per Second: 10,665.88825

Timestep Collection Time: 2.24342
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.68915

Cumulative Model Updates: 82,570
Cumulative Timesteps: 688,672,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,020.50104
Policy Entropy: 3.71212
Value Function Loss: 0.05709

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.60910
Value Function Update Magnitude: 0.76520

Collected Steps per Second: 23,028.42427
Overall Steps per Second: 10,663.57959

Timestep Collection Time: 2.17184
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.69017

Cumulative Model Updates: 82,576
Cumulative Timesteps: 688,722,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 688722370...
Checkpoint 688722370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,462.02209
Policy Entropy: 3.70692
Value Function Loss: 0.05870

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.63914
Value Function Update Magnitude: 0.77630

Collected Steps per Second: 22,599.30105
Overall Steps per Second: 10,633.07065

Timestep Collection Time: 2.21272
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.70287

Cumulative Model Updates: 82,582
Cumulative Timesteps: 688,772,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.10476
Policy Entropy: 3.70742
Value Function Loss: 0.06146

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.60671
Value Function Update Magnitude: 0.78189

Collected Steps per Second: 22,194.24393
Overall Steps per Second: 10,710.61196

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.66864

Cumulative Model Updates: 82,588
Cumulative Timesteps: 688,822,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 688822380...
Checkpoint 688822380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.46542
Policy Entropy: 3.70634
Value Function Loss: 0.06301

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.76719

Collected Steps per Second: 21,885.72262
Overall Steps per Second: 10,496.04780

Timestep Collection Time: 2.28533
Timestep Consumption Time: 2.47990
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.76522

Cumulative Model Updates: 82,594
Cumulative Timesteps: 688,872,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,869.65211
Policy Entropy: 3.70261
Value Function Loss: 0.06464

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.50291
Value Function Update Magnitude: 0.78562

Collected Steps per Second: 22,186.99688
Overall Steps per Second: 10,642.95104

Timestep Collection Time: 2.25393
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.69870

Cumulative Model Updates: 82,600
Cumulative Timesteps: 688,922,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 688922404...
Checkpoint 688922404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,057.71167
Policy Entropy: 3.69868
Value Function Loss: 0.06560

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.49220
Value Function Update Magnitude: 0.79803

Collected Steps per Second: 22,060.62907
Overall Steps per Second: 10,632.45670

Timestep Collection Time: 2.26793
Timestep Consumption Time: 2.43766
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.70559

Cumulative Model Updates: 82,606
Cumulative Timesteps: 688,972,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,134.38530
Policy Entropy: 3.70107
Value Function Loss: 0.06540

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.49756
Value Function Update Magnitude: 0.78415

Collected Steps per Second: 22,260.90188
Overall Steps per Second: 10,800.03969

Timestep Collection Time: 2.24735
Timestep Consumption Time: 2.38486
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.63221

Cumulative Model Updates: 82,612
Cumulative Timesteps: 689,022,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 689022464...
Checkpoint 689022464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,415.35368
Policy Entropy: 3.72324
Value Function Loss: 0.06517

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07676
Policy Update Magnitude: 0.47924
Value Function Update Magnitude: 0.75598

Collected Steps per Second: 21,518.21303
Overall Steps per Second: 10,682.14802

Timestep Collection Time: 2.32482
Timestep Consumption Time: 2.35832
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.68314

Cumulative Model Updates: 82,618
Cumulative Timesteps: 689,072,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,520.37003
Policy Entropy: 3.72362
Value Function Loss: 0.06550

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.49234
Value Function Update Magnitude: 0.77502

Collected Steps per Second: 21,551.33403
Overall Steps per Second: 10,527.59867

Timestep Collection Time: 2.32032
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.74999

Cumulative Model Updates: 82,624
Cumulative Timesteps: 689,122,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 689122496...
Checkpoint 689122496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.61197
Policy Entropy: 3.71774
Value Function Loss: 0.06611

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.50731
Value Function Update Magnitude: 0.76300

Collected Steps per Second: 21,265.66273
Overall Steps per Second: 10,606.95145

Timestep Collection Time: 2.35243
Timestep Consumption Time: 2.36391
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.71634

Cumulative Model Updates: 82,630
Cumulative Timesteps: 689,172,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.29791
Policy Entropy: 3.69588
Value Function Loss: 0.06716

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.52550
Value Function Update Magnitude: 0.82270

Collected Steps per Second: 22,025.38575
Overall Steps per Second: 10,669.85499

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.68610

Cumulative Model Updates: 82,636
Cumulative Timesteps: 689,222,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 689222522...
Checkpoint 689222522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,546.49371
Policy Entropy: 3.69371
Value Function Loss: 0.06848

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.51816
Value Function Update Magnitude: 0.83134

Collected Steps per Second: 20,309.69895
Overall Steps per Second: 10,061.48484

Timestep Collection Time: 2.46207
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.96984

Cumulative Model Updates: 82,642
Cumulative Timesteps: 689,272,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,308.62075
Policy Entropy: 3.67235
Value Function Loss: 0.06775

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.51764
Value Function Update Magnitude: 0.82885

Collected Steps per Second: 22,718.92313
Overall Steps per Second: 10,786.15777

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.63650

Cumulative Model Updates: 82,648
Cumulative Timesteps: 689,322,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 689322536...
Checkpoint 689322536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,712.67865
Policy Entropy: 3.67324
Value Function Loss: 0.06968

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.51785
Value Function Update Magnitude: 0.81487

Collected Steps per Second: 22,311.28321
Overall Steps per Second: 10,759.01049

Timestep Collection Time: 2.24218
Timestep Consumption Time: 2.40750
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.64968

Cumulative Model Updates: 82,654
Cumulative Timesteps: 689,372,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,174.92278
Policy Entropy: 3.66900
Value Function Loss: 0.07087

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.50727
Value Function Update Magnitude: 0.76001

Collected Steps per Second: 23,066.90916
Overall Steps per Second: 10,904.89596

Timestep Collection Time: 2.16821
Timestep Consumption Time: 2.41817
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.58638

Cumulative Model Updates: 82,660
Cumulative Timesteps: 689,422,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 689422576...
Checkpoint 689422576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,050.92642
Policy Entropy: 3.67467
Value Function Loss: 0.07153

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05721
Policy Update Magnitude: 0.64135
Value Function Update Magnitude: 0.76565

Collected Steps per Second: 22,198.70030
Overall Steps per Second: 10,620.34784

Timestep Collection Time: 2.25274
Timestep Consumption Time: 2.45595
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.70870

Cumulative Model Updates: 82,666
Cumulative Timesteps: 689,472,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,057.55775
Policy Entropy: 3.67143
Value Function Loss: 0.07013

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.75397
Value Function Update Magnitude: 0.81160

Collected Steps per Second: 23,208.17225
Overall Steps per Second: 10,880.94559

Timestep Collection Time: 2.15484
Timestep Consumption Time: 2.44126
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.59611

Cumulative Model Updates: 82,672
Cumulative Timesteps: 689,522,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 689522594...
Checkpoint 689522594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,539.42574
Policy Entropy: 3.66832
Value Function Loss: 0.07218

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.71272
Value Function Update Magnitude: 0.82118

Collected Steps per Second: 22,241.02511
Overall Steps per Second: 10,671.26529

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.68848

Cumulative Model Updates: 82,678
Cumulative Timesteps: 689,572,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.56201
Policy Entropy: 3.65761
Value Function Loss: 0.07408

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.71496
Value Function Update Magnitude: 0.70888

Collected Steps per Second: 22,474.15744
Overall Steps per Second: 10,592.66649

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.72044

Cumulative Model Updates: 82,684
Cumulative Timesteps: 689,622,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 689622628...
Checkpoint 689622628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,140.27775
Policy Entropy: 3.66247
Value Function Loss: 0.07771

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.65307
Value Function Update Magnitude: 0.64540

Collected Steps per Second: 22,201.55358
Overall Steps per Second: 10,484.94320

Timestep Collection Time: 2.25236
Timestep Consumption Time: 2.51695
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.76932

Cumulative Model Updates: 82,690
Cumulative Timesteps: 689,672,634

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,453.35337
Policy Entropy: 3.65417
Value Function Loss: 0.07814

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.53785
Value Function Update Magnitude: 0.62915

Collected Steps per Second: 22,617.27092
Overall Steps per Second: 10,614.12373

Timestep Collection Time: 2.21176
Timestep Consumption Time: 2.50120
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.71297

Cumulative Model Updates: 82,696
Cumulative Timesteps: 689,722,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 689722658...
Checkpoint 689722658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,194.23087
Policy Entropy: 3.65392
Value Function Loss: 0.07900

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.51965
Value Function Update Magnitude: 0.66318

Collected Steps per Second: 22,559.18244
Overall Steps per Second: 10,574.26631

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.72922

Cumulative Model Updates: 82,702
Cumulative Timesteps: 689,772,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,990.73754
Policy Entropy: 3.65059
Value Function Loss: 0.07506

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.51743
Value Function Update Magnitude: 0.69399

Collected Steps per Second: 23,018.03497
Overall Steps per Second: 10,787.28088

Timestep Collection Time: 2.17334
Timestep Consumption Time: 2.46416
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.63750

Cumulative Model Updates: 82,708
Cumulative Timesteps: 689,822,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 689822692...
Checkpoint 689822692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,246.81230
Policy Entropy: 3.65732
Value Function Loss: 0.07310

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.61320
Value Function Update Magnitude: 0.70522

Collected Steps per Second: 22,701.52505
Overall Steps per Second: 10,638.91969

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.70142

Cumulative Model Updates: 82,714
Cumulative Timesteps: 689,872,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.06907
Policy Entropy: 3.66401
Value Function Loss: 0.07125

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.69092
Value Function Update Magnitude: 0.69937

Collected Steps per Second: 23,105.63105
Overall Steps per Second: 10,868.83464

Timestep Collection Time: 2.16536
Timestep Consumption Time: 2.43789
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60325

Cumulative Model Updates: 82,720
Cumulative Timesteps: 689,922,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 689922742...
Checkpoint 689922742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.28346
Policy Entropy: 3.66486
Value Function Loss: 0.07370

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07678
Policy Update Magnitude: 0.70075
Value Function Update Magnitude: 0.65244

Collected Steps per Second: 22,640.11576
Overall Steps per Second: 10,703.37079

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.46404
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.67348

Cumulative Model Updates: 82,726
Cumulative Timesteps: 689,972,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,528.33804
Policy Entropy: 3.65662
Value Function Loss: 0.07650

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.69967
Value Function Update Magnitude: 0.68018

Collected Steps per Second: 22,708.31501
Overall Steps per Second: 10,611.62241

Timestep Collection Time: 2.20263
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.71351

Cumulative Model Updates: 82,732
Cumulative Timesteps: 690,022,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 690022782...
Checkpoint 690022782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,634.30060
Policy Entropy: 3.65637
Value Function Loss: 0.07806

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.59813
Value Function Update Magnitude: 0.65955

Collected Steps per Second: 22,681.59794
Overall Steps per Second: 10,662.75885

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.48489
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.68941

Cumulative Model Updates: 82,738
Cumulative Timesteps: 690,072,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,081.07927
Policy Entropy: 3.67040
Value Function Loss: 0.07704

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.51779
Value Function Update Magnitude: 0.62712

Collected Steps per Second: 22,666.53099
Overall Steps per Second: 10,724.93556

Timestep Collection Time: 2.20625
Timestep Consumption Time: 2.45653
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.66278

Cumulative Model Updates: 82,744
Cumulative Timesteps: 690,122,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 690122792...
Checkpoint 690122792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,554.84837
Policy Entropy: 3.67440
Value Function Loss: 0.07676

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.49148
Value Function Update Magnitude: 0.67229

Collected Steps per Second: 22,374.68059
Overall Steps per Second: 10,648.52737

Timestep Collection Time: 2.23583
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.69793

Cumulative Model Updates: 82,750
Cumulative Timesteps: 690,172,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,814.99457
Policy Entropy: 3.68203
Value Function Loss: 0.07519

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.52406
Value Function Update Magnitude: 0.68834

Collected Steps per Second: 22,321.96444
Overall Steps per Second: 10,540.84320

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.50471
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74573

Cumulative Model Updates: 82,756
Cumulative Timesteps: 690,222,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 690222842...
Checkpoint 690222842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,588.13619
Policy Entropy: 3.67742
Value Function Loss: 0.07652

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.68705

Collected Steps per Second: 22,029.94389
Overall Steps per Second: 10,554.54108

Timestep Collection Time: 2.26964
Timestep Consumption Time: 2.46766
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.73730

Cumulative Model Updates: 82,762
Cumulative Timesteps: 690,272,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,883.98778
Policy Entropy: 3.69018
Value Function Loss: 0.07452

Mean KL Divergence: 0.03067
SB3 Clip Fraction: 0.20046
Policy Update Magnitude: 0.48122
Value Function Update Magnitude: 0.67834

Collected Steps per Second: 22,527.81626
Overall Steps per Second: 10,532.99365

Timestep Collection Time: 2.22045
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.74908

Cumulative Model Updates: 82,768
Cumulative Timesteps: 690,322,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 690322864...
Checkpoint 690322864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,289.62352
Policy Entropy: 3.68962
Value Function Loss: 0.07671

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.17465
Policy Update Magnitude: 0.45248
Value Function Update Magnitude: 0.63384

Collected Steps per Second: 22,812.04599
Overall Steps per Second: 10,524.00046

Timestep Collection Time: 2.19261
Timestep Consumption Time: 2.56014
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75276

Cumulative Model Updates: 82,774
Cumulative Timesteps: 690,372,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,728.31617
Policy Entropy: 3.70083
Value Function Loss: 0.07552

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.63196
Value Function Update Magnitude: 0.68073

Collected Steps per Second: 23,009.92948
Overall Steps per Second: 10,808.54310

Timestep Collection Time: 2.17419
Timestep Consumption Time: 2.45437
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.62856

Cumulative Model Updates: 82,780
Cumulative Timesteps: 690,422,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 690422910...
Checkpoint 690422910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,260.04076
Policy Entropy: 3.68929
Value Function Loss: 0.07427

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.62399
Value Function Update Magnitude: 0.69417

Collected Steps per Second: 22,775.11543
Overall Steps per Second: 10,775.43946

Timestep Collection Time: 2.19564
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.64074

Cumulative Model Updates: 82,786
Cumulative Timesteps: 690,472,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,635.94605
Policy Entropy: 3.70600
Value Function Loss: 0.07324

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.58032
Value Function Update Magnitude: 0.65488

Collected Steps per Second: 22,891.75566
Overall Steps per Second: 10,823.89553

Timestep Collection Time: 2.18515
Timestep Consumption Time: 2.43629
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.62144

Cumulative Model Updates: 82,792
Cumulative Timesteps: 690,522,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 690522938...
Checkpoint 690522938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,927.87151
Policy Entropy: 3.70345
Value Function Loss: 0.07042

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.67316
Value Function Update Magnitude: 0.71291

Collected Steps per Second: 22,259.80501
Overall Steps per Second: 10,654.99867

Timestep Collection Time: 2.24701
Timestep Consumption Time: 2.44731
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.69432

Cumulative Model Updates: 82,798
Cumulative Timesteps: 690,572,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,026.71938
Policy Entropy: 3.71086
Value Function Loss: 0.07143

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.65978
Value Function Update Magnitude: 0.74922

Collected Steps per Second: 22,468.54000
Overall Steps per Second: 10,543.74878

Timestep Collection Time: 2.22578
Timestep Consumption Time: 2.51732
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.74309

Cumulative Model Updates: 82,804
Cumulative Timesteps: 690,622,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 690622966...
Checkpoint 690622966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.77339
Policy Entropy: 3.70620
Value Function Loss: 0.07048

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.61525
Value Function Update Magnitude: 0.74856

Collected Steps per Second: 22,003.25998
Overall Steps per Second: 10,637.35564

Timestep Collection Time: 2.27339
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.70248

Cumulative Model Updates: 82,810
Cumulative Timesteps: 690,672,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,387.22741
Policy Entropy: 3.71107
Value Function Loss: 0.07192

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.63962
Value Function Update Magnitude: 0.73201

Collected Steps per Second: 22,657.67012
Overall Steps per Second: 10,682.18079

Timestep Collection Time: 2.20685
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.68088

Cumulative Model Updates: 82,816
Cumulative Timesteps: 690,722,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 690722990...
Checkpoint 690722990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,296.35064
Policy Entropy: 3.70608
Value Function Loss: 0.07063

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.61209
Value Function Update Magnitude: 0.72148

Collected Steps per Second: 21,935.34630
Overall Steps per Second: 10,452.80583

Timestep Collection Time: 2.28006
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.78474

Cumulative Model Updates: 82,822
Cumulative Timesteps: 690,773,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,956.69474
Policy Entropy: 3.70719
Value Function Loss: 0.07143

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.65222
Value Function Update Magnitude: 0.77205

Collected Steps per Second: 22,451.41538
Overall Steps per Second: 10,563.02931

Timestep Collection Time: 2.22792
Timestep Consumption Time: 2.50746
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.73538

Cumulative Model Updates: 82,828
Cumulative Timesteps: 690,823,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 690823024...
Checkpoint 690823024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,583.72201
Policy Entropy: 3.68756
Value Function Loss: 0.07548

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.68522
Value Function Update Magnitude: 0.78730

Collected Steps per Second: 22,420.84622
Overall Steps per Second: 10,431.04844

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.56413
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.79492

Cumulative Model Updates: 82,834
Cumulative Timesteps: 690,873,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,152.32590
Policy Entropy: 3.68717
Value Function Loss: 0.07813

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.61812
Value Function Update Magnitude: 0.73859

Collected Steps per Second: 22,365.49851
Overall Steps per Second: 10,508.14422

Timestep Collection Time: 2.23746
Timestep Consumption Time: 2.52475
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.76221

Cumulative Model Updates: 82,840
Cumulative Timesteps: 690,923,082

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 690923082...
Checkpoint 690923082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,095.77488
Policy Entropy: 3.69201
Value Function Loss: 0.07697

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.59182
Value Function Update Magnitude: 0.70694

Collected Steps per Second: 22,601.83114
Overall Steps per Second: 10,638.84856

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.70201

Cumulative Model Updates: 82,846
Cumulative Timesteps: 690,973,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,633.09642
Policy Entropy: 3.70686
Value Function Loss: 0.07309

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07420
Policy Update Magnitude: 0.69901
Value Function Update Magnitude: 0.67339

Collected Steps per Second: 22,535.21330
Overall Steps per Second: 10,550.00014

Timestep Collection Time: 2.22052
Timestep Consumption Time: 2.52260
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74313

Cumulative Model Updates: 82,852
Cumulative Timesteps: 691,023,146

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 691023146...
Checkpoint 691023146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,277.98248
Policy Entropy: 3.71455
Value Function Loss: 0.07052

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.62778
Value Function Update Magnitude: 0.67237

Collected Steps per Second: 22,777.81433
Overall Steps per Second: 10,733.50356

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.46467
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.66111

Cumulative Model Updates: 82,858
Cumulative Timesteps: 691,073,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.45033
Policy Entropy: 3.71146
Value Function Loss: 0.07242

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.66938

Collected Steps per Second: 22,868.21838
Overall Steps per Second: 10,739.48847

Timestep Collection Time: 2.18758
Timestep Consumption Time: 2.47056
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.65814

Cumulative Model Updates: 82,864
Cumulative Timesteps: 691,123,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 691123202...
Checkpoint 691123202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,089.84285
Policy Entropy: 3.69893
Value Function Loss: 0.07401

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.53784
Value Function Update Magnitude: 0.63941

Collected Steps per Second: 21,010.01126
Overall Steps per Second: 10,183.41550

Timestep Collection Time: 2.38058
Timestep Consumption Time: 2.53094
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.91152

Cumulative Model Updates: 82,870
Cumulative Timesteps: 691,173,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,994.65655
Policy Entropy: 3.71016
Value Function Loss: 0.07356

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.51563
Value Function Update Magnitude: 0.72961

Collected Steps per Second: 22,489.37059
Overall Steps per Second: 10,491.16167

Timestep Collection Time: 2.22461
Timestep Consumption Time: 2.54417
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.76878

Cumulative Model Updates: 82,876
Cumulative Timesteps: 691,223,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 691223248...
Checkpoint 691223248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.56483
Policy Entropy: 3.69243
Value Function Loss: 0.07162

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.77318

Collected Steps per Second: 22,058.44212
Overall Steps per Second: 10,613.39930

Timestep Collection Time: 2.26716
Timestep Consumption Time: 2.44481
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.71197

Cumulative Model Updates: 82,882
Cumulative Timesteps: 691,273,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,003.43238
Policy Entropy: 3.70465
Value Function Loss: 0.06864

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.61136
Value Function Update Magnitude: 0.74971

Collected Steps per Second: 22,758.26266
Overall Steps per Second: 10,837.66555

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.41683
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61409

Cumulative Model Updates: 82,888
Cumulative Timesteps: 691,323,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 691323264...
Checkpoint 691323264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,470.54533
Policy Entropy: 3.69990
Value Function Loss: 0.07096

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07684
Policy Update Magnitude: 0.71393
Value Function Update Magnitude: 0.69539

Collected Steps per Second: 22,177.15377
Overall Steps per Second: 10,614.39608

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.71228

Cumulative Model Updates: 82,894
Cumulative Timesteps: 691,373,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,400.70738
Policy Entropy: 3.70851
Value Function Loss: 0.07297

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.64829
Value Function Update Magnitude: 0.62390

Collected Steps per Second: 22,870.32766
Overall Steps per Second: 10,533.96283

Timestep Collection Time: 2.18641
Timestep Consumption Time: 2.56052
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.74693

Cumulative Model Updates: 82,900
Cumulative Timesteps: 691,423,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 691423286...
Checkpoint 691423286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,981.53173
Policy Entropy: 3.70219
Value Function Loss: 0.07231

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.57391
Value Function Update Magnitude: 0.63023

Collected Steps per Second: 22,601.93730
Overall Steps per Second: 10,651.93969

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.69473

Cumulative Model Updates: 82,906
Cumulative Timesteps: 691,473,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.19036
Policy Entropy: 3.70107
Value Function Loss: 0.07115

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.65820

Collected Steps per Second: 23,160.68864
Overall Steps per Second: 10,656.63992

Timestep Collection Time: 2.16004
Timestep Consumption Time: 2.53450
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.69454

Cumulative Model Updates: 82,912
Cumulative Timesteps: 691,523,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 691523322...
Checkpoint 691523322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,437.62653
Policy Entropy: 3.70798
Value Function Loss: 0.06791

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.63217
Value Function Update Magnitude: 0.76107

Collected Steps per Second: 22,445.55691
Overall Steps per Second: 10,583.13367

Timestep Collection Time: 2.22841
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72620

Cumulative Model Updates: 82,918
Cumulative Timesteps: 691,573,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,087.01862
Policy Entropy: 3.72000
Value Function Loss: 0.06766

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.74114
Value Function Update Magnitude: 0.83707

Collected Steps per Second: 23,308.04536
Overall Steps per Second: 10,792.04785

Timestep Collection Time: 2.14604
Timestep Consumption Time: 2.48885
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.63489

Cumulative Model Updates: 82,924
Cumulative Timesteps: 691,623,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 691623360...
Checkpoint 691623360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.29221
Policy Entropy: 3.72347
Value Function Loss: 0.06757

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.76037
Value Function Update Magnitude: 0.86538

Collected Steps per Second: 22,799.76043
Overall Steps per Second: 10,729.30389

Timestep Collection Time: 2.19344
Timestep Consumption Time: 2.46762
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.66107

Cumulative Model Updates: 82,930
Cumulative Timesteps: 691,673,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,397.84502
Policy Entropy: 3.71919
Value Function Loss: 0.06935

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.71165
Value Function Update Magnitude: 0.87578

Collected Steps per Second: 22,598.64131
Overall Steps per Second: 10,760.23202

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.64767

Cumulative Model Updates: 82,936
Cumulative Timesteps: 691,723,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 691723380...
Checkpoint 691723380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,150.17446
Policy Entropy: 3.70674
Value Function Loss: 0.07173

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.61750
Value Function Update Magnitude: 0.84179

Collected Steps per Second: 21,912.90717
Overall Steps per Second: 10,603.00090

Timestep Collection Time: 2.28276
Timestep Consumption Time: 2.43496
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.71772

Cumulative Model Updates: 82,942
Cumulative Timesteps: 691,773,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.67718
Policy Entropy: 3.70071
Value Function Loss: 0.07498

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.53354
Value Function Update Magnitude: 0.83830

Collected Steps per Second: 22,381.22032
Overall Steps per Second: 10,507.40369

Timestep Collection Time: 2.23562
Timestep Consumption Time: 2.52635
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.76198

Cumulative Model Updates: 82,948
Cumulative Timesteps: 691,823,438

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 691823438...
Checkpoint 691823438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.68562
Policy Entropy: 3.69290
Value Function Loss: 0.07430

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.49304
Value Function Update Magnitude: 0.81967

Collected Steps per Second: 22,115.32060
Overall Steps per Second: 10,715.04598

Timestep Collection Time: 2.26214
Timestep Consumption Time: 2.40681
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.66895

Cumulative Model Updates: 82,954
Cumulative Timesteps: 691,873,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,193.18442
Policy Entropy: 3.70131
Value Function Loss: 0.07549

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.50838
Value Function Update Magnitude: 0.84557

Collected Steps per Second: 22,781.20853
Overall Steps per Second: 10,750.06009

Timestep Collection Time: 2.19558
Timestep Consumption Time: 2.45723
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.65281

Cumulative Model Updates: 82,960
Cumulative Timesteps: 691,923,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 691923484...
Checkpoint 691923484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,681.29523
Policy Entropy: 3.71500
Value Function Loss: 0.07628

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.53488
Value Function Update Magnitude: 0.85488

Collected Steps per Second: 22,420.53373
Overall Steps per Second: 10,674.30174

Timestep Collection Time: 2.23099
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.68602

Cumulative Model Updates: 82,966
Cumulative Timesteps: 691,973,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,724.81237
Policy Entropy: 3.71589
Value Function Loss: 0.07589

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.64885
Value Function Update Magnitude: 0.89027

Collected Steps per Second: 22,726.13337
Overall Steps per Second: 10,694.59538

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.47525
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.67545

Cumulative Model Updates: 82,972
Cumulative Timesteps: 692,023,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 692023506...
Checkpoint 692023506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.95736
Policy Entropy: 3.70768
Value Function Loss: 0.07305

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07579
Policy Update Magnitude: 0.71637
Value Function Update Magnitude: 0.88498

Collected Steps per Second: 22,853.29862
Overall Steps per Second: 10,814.56521

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.62506

Cumulative Model Updates: 82,978
Cumulative Timesteps: 692,073,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.13112
Policy Entropy: 3.67616
Value Function Loss: 0.07427

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.69367
Value Function Update Magnitude: 0.81730

Collected Steps per Second: 22,994.85431
Overall Steps per Second: 10,713.62357

Timestep Collection Time: 2.17553
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.66938

Cumulative Model Updates: 82,984
Cumulative Timesteps: 692,123,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 692123550...
Checkpoint 692123550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.63919
Policy Entropy: 3.67637
Value Function Loss: 0.07522

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.59590
Value Function Update Magnitude: 0.80728

Collected Steps per Second: 22,709.70455
Overall Steps per Second: 10,862.63822

Timestep Collection Time: 2.20285
Timestep Consumption Time: 2.40248
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.60533

Cumulative Model Updates: 82,990
Cumulative Timesteps: 692,173,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,405.83342
Policy Entropy: 3.68051
Value Function Loss: 0.07589

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.53481
Value Function Update Magnitude: 0.88529

Collected Steps per Second: 22,969.41256
Overall Steps per Second: 10,637.85542

Timestep Collection Time: 2.17698
Timestep Consumption Time: 2.52359
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.70057

Cumulative Model Updates: 82,996
Cumulative Timesteps: 692,223,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 692223580...
Checkpoint 692223580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,849.66611
Policy Entropy: 3.69659
Value Function Loss: 0.07296

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.42452
Value Function Update Magnitude: 0.91770

Collected Steps per Second: 22,248.92295
Overall Steps per Second: 10,513.68065

Timestep Collection Time: 2.24838
Timestep Consumption Time: 2.50961
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.75799

Cumulative Model Updates: 83,002
Cumulative Timesteps: 692,273,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,759.91468
Policy Entropy: 3.69800
Value Function Loss: 0.07387

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.45656
Value Function Update Magnitude: 0.83646

Collected Steps per Second: 22,725.53705
Overall Steps per Second: 10,861.40693

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.40434
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60548

Cumulative Model Updates: 83,008
Cumulative Timesteps: 692,323,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 692323626...
Checkpoint 692323626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,160.44742
Policy Entropy: 3.68134
Value Function Loss: 0.07350

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.46800
Value Function Update Magnitude: 0.79038

Collected Steps per Second: 22,153.74804
Overall Steps per Second: 10,664.67862

Timestep Collection Time: 2.25795
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.69044

Cumulative Model Updates: 83,014
Cumulative Timesteps: 692,373,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.03978
Policy Entropy: 3.67108
Value Function Loss: 0.07614

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.44000
Value Function Update Magnitude: 0.84053

Collected Steps per Second: 22,723.41738
Overall Steps per Second: 10,621.55095

Timestep Collection Time: 2.20178
Timestep Consumption Time: 2.50864
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.71042

Cumulative Model Updates: 83,020
Cumulative Timesteps: 692,423,680

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 692423680...
Checkpoint 692423680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,549.23946
Policy Entropy: 3.67275
Value Function Loss: 0.07758

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.46347
Value Function Update Magnitude: 0.85559

Collected Steps per Second: 22,677.67657
Overall Steps per Second: 10,559.51959

Timestep Collection Time: 2.20490
Timestep Consumption Time: 2.53035
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.73525

Cumulative Model Updates: 83,026
Cumulative Timesteps: 692,473,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,907.75120
Policy Entropy: 3.67906
Value Function Loss: 0.07848

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.48530
Value Function Update Magnitude: 0.74364

Collected Steps per Second: 22,887.16187
Overall Steps per Second: 10,850.17852

Timestep Collection Time: 2.18673
Timestep Consumption Time: 2.42591
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61264

Cumulative Model Updates: 83,032
Cumulative Timesteps: 692,523,730

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 692523730...
Checkpoint 692523730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,590.22418
Policy Entropy: 3.68312
Value Function Loss: 0.07929

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.49356
Value Function Update Magnitude: 0.67119

Collected Steps per Second: 22,572.90801
Overall Steps per Second: 10,646.72828

Timestep Collection Time: 2.21558
Timestep Consumption Time: 2.48183
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.69741

Cumulative Model Updates: 83,038
Cumulative Timesteps: 692,573,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,887.74658
Policy Entropy: 3.66606
Value Function Loss: 0.08223

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.48080
Value Function Update Magnitude: 0.69246

Collected Steps per Second: 22,979.06222
Overall Steps per Second: 10,820.32374

Timestep Collection Time: 2.17676
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.62278

Cumulative Model Updates: 83,044
Cumulative Timesteps: 692,623,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 692623762...
Checkpoint 692623762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.58831
Policy Entropy: 3.64854
Value Function Loss: 0.08650

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.58606
Value Function Update Magnitude: 0.68762

Collected Steps per Second: 22,742.66377
Overall Steps per Second: 10,781.83592

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.43999
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.63947

Cumulative Model Updates: 83,050
Cumulative Timesteps: 692,673,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,965.95661
Policy Entropy: 3.64768
Value Function Loss: 0.08645

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.59580
Value Function Update Magnitude: 0.70771

Collected Steps per Second: 22,955.92478
Overall Steps per Second: 10,833.05645

Timestep Collection Time: 2.17905
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.61753

Cumulative Model Updates: 83,056
Cumulative Timesteps: 692,723,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 692723806...
Checkpoint 692723806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.77056
Policy Entropy: 3.65036
Value Function Loss: 0.08362

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.16489
Policy Update Magnitude: 0.47080
Value Function Update Magnitude: 0.81591

Collected Steps per Second: 22,126.33514
Overall Steps per Second: 10,667.54678

Timestep Collection Time: 2.26011
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.68786

Cumulative Model Updates: 83,062
Cumulative Timesteps: 692,773,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.56762
Policy Entropy: 3.66770
Value Function Loss: 0.07865

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.78738

Collected Steps per Second: 22,656.09503
Overall Steps per Second: 10,541.74006

Timestep Collection Time: 2.20859
Timestep Consumption Time: 2.53807
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.74665

Cumulative Model Updates: 83,068
Cumulative Timesteps: 692,823,852

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 692823852...
Checkpoint 692823852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,652.51770
Policy Entropy: 3.66219
Value Function Loss: 0.07589

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.72076
Value Function Update Magnitude: 0.74646

Collected Steps per Second: 22,278.40783
Overall Steps per Second: 10,573.44890

Timestep Collection Time: 2.24451
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.72920

Cumulative Model Updates: 83,074
Cumulative Timesteps: 692,873,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,436.35800
Policy Entropy: 3.66616
Value Function Loss: 0.07535

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.67255
Value Function Update Magnitude: 0.79265

Collected Steps per Second: 22,154.27830
Overall Steps per Second: 10,462.33062

Timestep Collection Time: 2.25735
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.78001

Cumulative Model Updates: 83,080
Cumulative Timesteps: 692,923,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 692923866...
Checkpoint 692923866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,274.76727
Policy Entropy: 3.64939
Value Function Loss: 0.07289

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.60833
Value Function Update Magnitude: 0.80394

Collected Steps per Second: 22,454.76464
Overall Steps per Second: 10,639.20660

Timestep Collection Time: 2.22812
Timestep Consumption Time: 2.47448
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.70261

Cumulative Model Updates: 83,086
Cumulative Timesteps: 692,973,898

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.90912
Policy Entropy: 3.66421
Value Function Loss: 0.07173

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15321
Policy Update Magnitude: 0.50384
Value Function Update Magnitude: 0.80759

Collected Steps per Second: 22,814.10779
Overall Steps per Second: 10,556.12833

Timestep Collection Time: 2.19303
Timestep Consumption Time: 2.54659
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.73962

Cumulative Model Updates: 83,092
Cumulative Timesteps: 693,023,930

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 693023930...
Checkpoint 693023930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.91443
Policy Entropy: 3.67241
Value Function Loss: 0.06994

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.47961
Value Function Update Magnitude: 0.77042

Collected Steps per Second: 22,499.24687
Overall Steps per Second: 10,444.11662

Timestep Collection Time: 2.22239
Timestep Consumption Time: 2.56519
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.78758

Cumulative Model Updates: 83,098
Cumulative Timesteps: 693,073,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,158.14765
Policy Entropy: 3.68986
Value Function Loss: 0.06735

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.47399
Value Function Update Magnitude: 0.72403

Collected Steps per Second: 22,815.30774
Overall Steps per Second: 10,673.81332

Timestep Collection Time: 2.19283
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.68717

Cumulative Model Updates: 83,104
Cumulative Timesteps: 693,123,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 693123962...
Checkpoint 693123962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.87236
Policy Entropy: 3.69207
Value Function Loss: 0.06450

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.43621
Value Function Update Magnitude: 0.70512

Collected Steps per Second: 22,669.71286
Overall Steps per Second: 10,606.23084

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.71628

Cumulative Model Updates: 83,110
Cumulative Timesteps: 693,173,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,225.45801
Policy Entropy: 3.69961
Value Function Loss: 0.06042

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06139
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.74637

Collected Steps per Second: 22,850.34962
Overall Steps per Second: 10,768.40362

Timestep Collection Time: 2.19008
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.64730

Cumulative Model Updates: 83,116
Cumulative Timesteps: 693,224,028

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 693224028...
Checkpoint 693224028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.39729
Policy Entropy: 3.70185
Value Function Loss: 0.06009

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.69964
Value Function Update Magnitude: 0.70080

Collected Steps per Second: 22,473.87857
Overall Steps per Second: 10,721.06862

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.66409

Cumulative Model Updates: 83,122
Cumulative Timesteps: 693,274,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.50255
Policy Entropy: 3.68986
Value Function Loss: 0.06018

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.68973
Value Function Update Magnitude: 0.68715

Collected Steps per Second: 22,469.90464
Overall Steps per Second: 10,582.45557

Timestep Collection Time: 2.22538
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.72518

Cumulative Model Updates: 83,128
Cumulative Timesteps: 693,324,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 693324036...
Checkpoint 693324036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,767.99066
Policy Entropy: 3.67041
Value Function Loss: 0.06418

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.59479
Value Function Update Magnitude: 0.67664

Collected Steps per Second: 21,952.02314
Overall Steps per Second: 10,454.93718

Timestep Collection Time: 2.27779
Timestep Consumption Time: 2.50484
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.78262

Cumulative Model Updates: 83,134
Cumulative Timesteps: 693,374,038

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,299.51047
Policy Entropy: 3.67308
Value Function Loss: 0.06539

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.51989
Value Function Update Magnitude: 0.64109

Collected Steps per Second: 22,390.07945
Overall Steps per Second: 10,518.70343

Timestep Collection Time: 2.23465
Timestep Consumption Time: 2.52202
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.75667

Cumulative Model Updates: 83,140
Cumulative Timesteps: 693,424,072

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 693424072...
Checkpoint 693424072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,997.61920
Policy Entropy: 3.67267
Value Function Loss: 0.06573

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.63824

Collected Steps per Second: 22,002.76138
Overall Steps per Second: 10,608.72758

Timestep Collection Time: 2.27408
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.71649

Cumulative Model Updates: 83,146
Cumulative Timesteps: 693,474,108

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,239.08076
Policy Entropy: 3.67875
Value Function Loss: 0.06582

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.56201
Value Function Update Magnitude: 0.68706

Collected Steps per Second: 22,904.22348
Overall Steps per Second: 10,544.97760

Timestep Collection Time: 2.18388
Timestep Consumption Time: 2.55961
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.74349

Cumulative Model Updates: 83,152
Cumulative Timesteps: 693,524,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 693524128...
Checkpoint 693524128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.22916
Policy Entropy: 3.67989
Value Function Loss: 0.06545

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.56888
Value Function Update Magnitude: 0.73780

Collected Steps per Second: 22,078.21866
Overall Steps per Second: 10,532.02911

Timestep Collection Time: 2.26649
Timestep Consumption Time: 2.48473
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.75122

Cumulative Model Updates: 83,158
Cumulative Timesteps: 693,574,168

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.53458
Policy Entropy: 3.68914
Value Function Loss: 0.06486

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.53298
Value Function Update Magnitude: 0.75570

Collected Steps per Second: 23,167.32446
Overall Steps per Second: 10,920.28862

Timestep Collection Time: 2.15942
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.58120

Cumulative Model Updates: 83,164
Cumulative Timesteps: 693,624,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 693624196...
Checkpoint 693624196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,604.10128
Policy Entropy: 3.70203
Value Function Loss: 0.06450

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.59253
Value Function Update Magnitude: 0.75332

Collected Steps per Second: 22,434.79110
Overall Steps per Second: 10,605.99725

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.48663
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.71620

Cumulative Model Updates: 83,170
Cumulative Timesteps: 693,674,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,341.29860
Policy Entropy: 3.69662
Value Function Loss: 0.06478

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.66567
Value Function Update Magnitude: 0.74408

Collected Steps per Second: 22,897.51321
Overall Steps per Second: 10,687.01709

Timestep Collection Time: 2.18452
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68045

Cumulative Model Updates: 83,176
Cumulative Timesteps: 693,724,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 693724236...
Checkpoint 693724236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,835.68096
Policy Entropy: 3.69440
Value Function Loss: 0.06671

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.60558
Value Function Update Magnitude: 0.72267

Collected Steps per Second: 22,568.57984
Overall Steps per Second: 10,605.98243

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.71545

Cumulative Model Updates: 83,182
Cumulative Timesteps: 693,774,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,990.35465
Policy Entropy: 3.69612
Value Function Loss: 0.06783

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.57785
Value Function Update Magnitude: 0.69959

Collected Steps per Second: 22,712.39868
Overall Steps per Second: 10,727.74817

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.66323

Cumulative Model Updates: 83,188
Cumulative Timesteps: 693,824,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 693824274...
Checkpoint 693824274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,974.55250
Policy Entropy: 3.68752
Value Function Loss: 0.06835

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.64142
Value Function Update Magnitude: 0.71018

Collected Steps per Second: 22,043.13794
Overall Steps per Second: 10,613.12106

Timestep Collection Time: 2.26946
Timestep Consumption Time: 2.44414
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.71360

Cumulative Model Updates: 83,194
Cumulative Timesteps: 693,874,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,102.91113
Policy Entropy: 3.69696
Value Function Loss: 0.06812

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.57536
Value Function Update Magnitude: 0.72301

Collected Steps per Second: 21,880.94961
Overall Steps per Second: 10,518.76704

Timestep Collection Time: 2.28555
Timestep Consumption Time: 2.46881
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.75436

Cumulative Model Updates: 83,200
Cumulative Timesteps: 693,924,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 693924310...
Checkpoint 693924310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,818.80484
Policy Entropy: 3.69049
Value Function Loss: 0.06777

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.75772

Collected Steps per Second: 21,624.70740
Overall Steps per Second: 10,373.16637

Timestep Collection Time: 2.31226
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.82032

Cumulative Model Updates: 83,206
Cumulative Timesteps: 693,974,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,411.81925
Policy Entropy: 3.69148
Value Function Loss: 0.06807

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.52117
Value Function Update Magnitude: 0.80892

Collected Steps per Second: 22,577.59169
Overall Steps per Second: 10,698.49333

Timestep Collection Time: 2.21609
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.67673

Cumulative Model Updates: 83,212
Cumulative Timesteps: 694,024,346

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 694024346...
Checkpoint 694024346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.18805
Policy Entropy: 3.68719
Value Function Loss: 0.06767

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.50334
Value Function Update Magnitude: 0.83594

Collected Steps per Second: 22,370.51118
Overall Steps per Second: 10,629.48016

Timestep Collection Time: 2.23589
Timestep Consumption Time: 2.46970
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.70559

Cumulative Model Updates: 83,218
Cumulative Timesteps: 694,074,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,337.96816
Policy Entropy: 3.68879
Value Function Loss: 0.06703

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.46962
Value Function Update Magnitude: 0.86562

Collected Steps per Second: 22,856.27785
Overall Steps per Second: 10,643.19137

Timestep Collection Time: 2.18793
Timestep Consumption Time: 2.51066
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.69859

Cumulative Model Updates: 83,224
Cumulative Timesteps: 694,124,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 694124372...
Checkpoint 694124372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.82524
Policy Entropy: 3.67986
Value Function Loss: 0.06898

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.46823
Value Function Update Magnitude: 0.87793

Collected Steps per Second: 22,434.30663
Overall Steps per Second: 10,368.72259

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.59419
PPO Batch Consumption Time: 0.30748
Total Iteration Time: 4.82354

Cumulative Model Updates: 83,230
Cumulative Timesteps: 694,174,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,249.76680
Policy Entropy: 3.67906
Value Function Loss: 0.06780

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.43722
Value Function Update Magnitude: 0.86599

Collected Steps per Second: 22,866.73246
Overall Steps per Second: 10,619.33270

Timestep Collection Time: 2.18737
Timestep Consumption Time: 2.52272
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.71009

Cumulative Model Updates: 83,236
Cumulative Timesteps: 694,224,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 694224404...
Checkpoint 694224404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,481.36156
Policy Entropy: 3.68177
Value Function Loss: 0.06790

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.46428
Value Function Update Magnitude: 0.84847

Collected Steps per Second: 22,654.46727
Overall Steps per Second: 10,597.45691

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.71830

Cumulative Model Updates: 83,242
Cumulative Timesteps: 694,274,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.63719
Policy Entropy: 3.68685
Value Function Loss: 0.06223

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.15122
Policy Update Magnitude: 0.46358
Value Function Update Magnitude: 0.82218

Collected Steps per Second: 22,734.42684
Overall Steps per Second: 10,649.61388

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.49570
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.69501

Cumulative Model Updates: 83,248
Cumulative Timesteps: 694,324,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 694324406...
Checkpoint 694324406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.49434
Policy Entropy: 3.70160
Value Function Loss: 0.06017

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.44753
Value Function Update Magnitude: 0.79781

Collected Steps per Second: 22,559.34604
Overall Steps per Second: 10,645.36974

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.69857

Cumulative Model Updates: 83,254
Cumulative Timesteps: 694,374,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.93592
Policy Entropy: 3.71231
Value Function Loss: 0.05801

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.47552
Value Function Update Magnitude: 0.76449

Collected Steps per Second: 22,726.56539
Overall Steps per Second: 10,681.42563

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.68290

Cumulative Model Updates: 83,260
Cumulative Timesteps: 694,424,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 694424444...
Checkpoint 694424444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,567.71433
Policy Entropy: 3.70391
Value Function Loss: 0.05688

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.52304
Value Function Update Magnitude: 0.75223

Collected Steps per Second: 22,043.13831
Overall Steps per Second: 10,623.04108

Timestep Collection Time: 2.26928
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.70882

Cumulative Model Updates: 83,266
Cumulative Timesteps: 694,474,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,658.18486
Policy Entropy: 3.69411
Value Function Loss: 0.05746

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.54963
Value Function Update Magnitude: 0.73207

Collected Steps per Second: 22,165.92485
Overall Steps per Second: 10,514.81973

Timestep Collection Time: 2.25608
Timestep Consumption Time: 2.49988
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.75595

Cumulative Model Updates: 83,272
Cumulative Timesteps: 694,524,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 694524474...
Checkpoint 694524474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.91618
Policy Entropy: 3.68981
Value Function Loss: 0.05744

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.61002
Value Function Update Magnitude: 0.73182

Collected Steps per Second: 22,151.94416
Overall Steps per Second: 10,656.63443

Timestep Collection Time: 2.25732
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.69229

Cumulative Model Updates: 83,278
Cumulative Timesteps: 694,574,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,458.64966
Policy Entropy: 3.68444
Value Function Loss: 0.05546

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.52608
Value Function Update Magnitude: 0.71989

Collected Steps per Second: 22,146.60753
Overall Steps per Second: 10,636.50622

Timestep Collection Time: 2.25859
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.70267

Cumulative Model Updates: 83,284
Cumulative Timesteps: 694,624,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 694624498...
Checkpoint 694624498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,349.16477
Policy Entropy: 3.69773
Value Function Loss: 0.05486

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.46387
Value Function Update Magnitude: 0.70846

Collected Steps per Second: 21,958.78895
Overall Steps per Second: 10,659.78189

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.41450
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69240

Cumulative Model Updates: 83,290
Cumulative Timesteps: 694,674,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,142.86973
Policy Entropy: 3.69899
Value Function Loss: 0.05746

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.48329
Value Function Update Magnitude: 0.73396

Collected Steps per Second: 22,479.31507
Overall Steps per Second: 10,730.90042

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.65981

Cumulative Model Updates: 83,296
Cumulative Timesteps: 694,724,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 694724522...
Checkpoint 694724522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.16081
Policy Entropy: 3.70783
Value Function Loss: 0.05998

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.76966

Collected Steps per Second: 21,860.19145
Overall Steps per Second: 10,603.09243

Timestep Collection Time: 2.28799
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.71711

Cumulative Model Updates: 83,302
Cumulative Timesteps: 694,774,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.05459
Policy Entropy: 3.70668
Value Function Loss: 0.06245

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.53457
Value Function Update Magnitude: 0.79358

Collected Steps per Second: 22,198.17363
Overall Steps per Second: 10,723.63908

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.41238
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.66689

Cumulative Model Updates: 83,308
Cumulative Timesteps: 694,824,584

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 694824584...
Checkpoint 694824584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,565.80068
Policy Entropy: 3.71282
Value Function Loss: 0.06212

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.53112
Value Function Update Magnitude: 0.80666

Collected Steps per Second: 21,671.12880
Overall Steps per Second: 10,561.22873

Timestep Collection Time: 2.30925
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73846

Cumulative Model Updates: 83,314
Cumulative Timesteps: 694,874,628

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859.84723
Policy Entropy: 3.71308
Value Function Loss: 0.06347

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.55168
Value Function Update Magnitude: 0.81351

Collected Steps per Second: 21,790.93661
Overall Steps per Second: 10,692.10740

Timestep Collection Time: 2.29472
Timestep Consumption Time: 2.38201
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.67672

Cumulative Model Updates: 83,320
Cumulative Timesteps: 694,924,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 694924632...
Checkpoint 694924632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.79321
Policy Entropy: 3.72018
Value Function Loss: 0.06535

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.57646
Value Function Update Magnitude: 0.72065

Collected Steps per Second: 20,973.51646
Overall Steps per Second: 10,328.62831

Timestep Collection Time: 2.38405
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.84111

Cumulative Model Updates: 83,326
Cumulative Timesteps: 694,974,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,094.60130
Policy Entropy: 3.70590
Value Function Loss: 0.06748

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.58019
Value Function Update Magnitude: 0.66594

Collected Steps per Second: 21,960.47983
Overall Steps per Second: 10,754.43527

Timestep Collection Time: 2.27709
Timestep Consumption Time: 2.37271
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.64980

Cumulative Model Updates: 83,332
Cumulative Timesteps: 695,024,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 695024640...
Checkpoint 695024640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,391.27335
Policy Entropy: 3.70006
Value Function Loss: 0.06657

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.75826

Collected Steps per Second: 21,310.23242
Overall Steps per Second: 10,593.23560

Timestep Collection Time: 2.34667
Timestep Consumption Time: 2.37408
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.72075

Cumulative Model Updates: 83,338
Cumulative Timesteps: 695,074,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,218.24429
Policy Entropy: 3.69637
Value Function Loss: 0.06425

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.76586

Collected Steps per Second: 21,928.83331
Overall Steps per Second: 10,521.75564

Timestep Collection Time: 2.28092
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.75377

Cumulative Model Updates: 83,344
Cumulative Timesteps: 695,124,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 695124666...
Checkpoint 695124666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,742.84726
Policy Entropy: 3.70149
Value Function Loss: 0.06495

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.54110
Value Function Update Magnitude: 0.76899

Collected Steps per Second: 22,520.76760
Overall Steps per Second: 10,631.59322

Timestep Collection Time: 2.22026
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.70315

Cumulative Model Updates: 83,350
Cumulative Timesteps: 695,174,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.54524
Policy Entropy: 3.70120
Value Function Loss: 0.06374

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.59955
Value Function Update Magnitude: 0.79743

Collected Steps per Second: 22,323.90275
Overall Steps per Second: 10,452.68496

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.54513
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.78614

Cumulative Model Updates: 83,356
Cumulative Timesteps: 695,224,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 695224696...
Checkpoint 695224696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,429.57350
Policy Entropy: 3.69320
Value Function Loss: 0.06405

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.66279
Value Function Update Magnitude: 0.82730

Collected Steps per Second: 22,248.12346
Overall Steps per Second: 10,750.11945

Timestep Collection Time: 2.24837
Timestep Consumption Time: 2.40479
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.65316

Cumulative Model Updates: 83,362
Cumulative Timesteps: 695,274,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,999.19124
Policy Entropy: 3.68658
Value Function Loss: 0.06470

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.68602
Value Function Update Magnitude: 0.81853

Collected Steps per Second: 22,939.99025
Overall Steps per Second: 10,827.88971

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.61863

Cumulative Model Updates: 83,368
Cumulative Timesteps: 695,324,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 695324728...
Checkpoint 695324728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,477.16235
Policy Entropy: 3.68812
Value Function Loss: 0.06591

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.67032
Value Function Update Magnitude: 0.74078

Collected Steps per Second: 22,128.16337
Overall Steps per Second: 10,633.04005

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.70383

Cumulative Model Updates: 83,374
Cumulative Timesteps: 695,374,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,521.05148
Policy Entropy: 3.69765
Value Function Loss: 0.06980

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.61104
Value Function Update Magnitude: 0.66257

Collected Steps per Second: 22,490.60827
Overall Steps per Second: 10,543.64033

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.52025
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.74447

Cumulative Model Updates: 83,380
Cumulative Timesteps: 695,424,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 695424768...
Checkpoint 695424768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,798.31935
Policy Entropy: 3.69500
Value Function Loss: 0.06869

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.72187

Collected Steps per Second: 22,129.06584
Overall Steps per Second: 10,638.49450

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.70161

Cumulative Model Updates: 83,386
Cumulative Timesteps: 695,474,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,786.28919
Policy Entropy: 3.68453
Value Function Loss: 0.07254

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.61254
Value Function Update Magnitude: 0.76296

Collected Steps per Second: 22,085.57516
Overall Steps per Second: 10,337.39984

Timestep Collection Time: 2.26501
Timestep Consumption Time: 2.57412
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.83913

Cumulative Model Updates: 83,392
Cumulative Timesteps: 695,524,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 695524810...
Checkpoint 695524810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,424.48836
Policy Entropy: 3.67889
Value Function Loss: 0.07370

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.17305
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.74277

Collected Steps per Second: 21,518.58949
Overall Steps per Second: 10,335.28605

Timestep Collection Time: 2.32385
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.83838

Cumulative Model Updates: 83,398
Cumulative Timesteps: 695,574,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,466.04076
Policy Entropy: 3.68133
Value Function Loss: 0.07869

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.16852
Policy Update Magnitude: 0.45969
Value Function Update Magnitude: 0.66951

Collected Steps per Second: 22,547.50163
Overall Steps per Second: 10,747.40237

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.65378

Cumulative Model Updates: 83,404
Cumulative Timesteps: 695,624,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 695624832...
Checkpoint 695624832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,909.44112
Policy Entropy: 3.67665
Value Function Loss: 0.07668

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.60872
Value Function Update Magnitude: 0.64145

Collected Steps per Second: 21,860.75287
Overall Steps per Second: 10,413.08912

Timestep Collection Time: 2.28748
Timestep Consumption Time: 2.51475
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.80223

Cumulative Model Updates: 83,410
Cumulative Timesteps: 695,674,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.73306
Policy Entropy: 3.67316
Value Function Loss: 0.07628

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.71239
Value Function Update Magnitude: 0.62558

Collected Steps per Second: 22,958.18984
Overall Steps per Second: 10,724.66488

Timestep Collection Time: 2.17874
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.66402

Cumulative Model Updates: 83,416
Cumulative Timesteps: 695,724,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 695724858...
Checkpoint 695724858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,954.87102
Policy Entropy: 3.67904
Value Function Loss: 0.07307

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.66907
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 22,163.83222
Overall Steps per Second: 10,605.38189

Timestep Collection Time: 2.25602
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.71478

Cumulative Model Updates: 83,422
Cumulative Timesteps: 695,774,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,762.82951
Policy Entropy: 3.66526
Value Function Loss: 0.07313

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11720
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.67668

Collected Steps per Second: 22,813.30986
Overall Steps per Second: 10,647.58952

Timestep Collection Time: 2.19284
Timestep Consumption Time: 2.50550
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.69834

Cumulative Model Updates: 83,428
Cumulative Timesteps: 695,824,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 695824886...
Checkpoint 695824886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,459.39704
Policy Entropy: 3.67572
Value Function Loss: 0.07378

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.51579
Value Function Update Magnitude: 0.70462

Collected Steps per Second: 22,539.10213
Overall Steps per Second: 10,566.30329

Timestep Collection Time: 2.21943
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.73430

Cumulative Model Updates: 83,434
Cumulative Timesteps: 695,874,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,363.77734
Policy Entropy: 3.66997
Value Function Loss: 0.07704

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.61099
Value Function Update Magnitude: 0.66161

Collected Steps per Second: 23,247.47672
Overall Steps per Second: 10,917.95115

Timestep Collection Time: 2.15146
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.58108

Cumulative Model Updates: 83,440
Cumulative Timesteps: 695,924,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 695924926...
Checkpoint 695924926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,686.25528
Policy Entropy: 3.67697
Value Function Loss: 0.07859

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.69984
Value Function Update Magnitude: 0.61758

Collected Steps per Second: 22,468.08667
Overall Steps per Second: 10,617.27633

Timestep Collection Time: 2.22636
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.71138

Cumulative Model Updates: 83,446
Cumulative Timesteps: 695,974,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,248.80211
Policy Entropy: 3.68026
Value Function Loss: 0.07802

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11231
Policy Update Magnitude: 0.66741
Value Function Update Magnitude: 0.61728

Collected Steps per Second: 21,996.90203
Overall Steps per Second: 10,778.07070

Timestep Collection Time: 2.27323
Timestep Consumption Time: 2.36619
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.63942

Cumulative Model Updates: 83,452
Cumulative Timesteps: 696,024,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 696024952...
Checkpoint 696024952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.98103
Policy Entropy: 3.69171
Value Function Loss: 0.07831

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.16167
Policy Update Magnitude: 0.53511
Value Function Update Magnitude: 0.64898

Collected Steps per Second: 21,187.82541
Overall Steps per Second: 10,427.47803

Timestep Collection Time: 2.36079
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.79694

Cumulative Model Updates: 83,458
Cumulative Timesteps: 696,074,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.36223
Policy Entropy: 3.68703
Value Function Loss: 0.07768

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.51761
Value Function Update Magnitude: 0.65650

Collected Steps per Second: 21,786.35383
Overall Steps per Second: 10,735.41176

Timestep Collection Time: 2.29593
Timestep Consumption Time: 2.36341
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.65935

Cumulative Model Updates: 83,464
Cumulative Timesteps: 696,124,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 696124992...
Checkpoint 696124992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,920.91298
Policy Entropy: 3.66926
Value Function Loss: 0.07617

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.59826
Value Function Update Magnitude: 0.78890

Collected Steps per Second: 20,982.96440
Overall Steps per Second: 10,432.55466

Timestep Collection Time: 2.38336
Timestep Consumption Time: 2.41029
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.79365

Cumulative Model Updates: 83,470
Cumulative Timesteps: 696,175,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,675.11187
Policy Entropy: 3.65745
Value Function Loss: 0.07552

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.59563
Value Function Update Magnitude: 0.81515

Collected Steps per Second: 21,573.98840
Overall Steps per Second: 10,689.29221

Timestep Collection Time: 2.31825
Timestep Consumption Time: 2.36063
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.67889

Cumulative Model Updates: 83,476
Cumulative Timesteps: 696,225,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 696225016...
Checkpoint 696225016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,571.97786
Policy Entropy: 3.65350
Value Function Loss: 0.07550

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.57099
Value Function Update Magnitude: 0.74712

Collected Steps per Second: 21,778.22561
Overall Steps per Second: 10,688.25123

Timestep Collection Time: 2.29651
Timestep Consumption Time: 2.38283
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.67934

Cumulative Model Updates: 83,482
Cumulative Timesteps: 696,275,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,869.89400
Policy Entropy: 3.66663
Value Function Loss: 0.07417

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.59534
Value Function Update Magnitude: 0.77894

Collected Steps per Second: 22,253.45212
Overall Steps per Second: 10,537.60849

Timestep Collection Time: 2.24756
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.74643

Cumulative Model Updates: 83,488
Cumulative Timesteps: 696,325,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 696325046...
Checkpoint 696325046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,250.19970
Policy Entropy: 3.66193
Value Function Loss: 0.07368

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.58040
Value Function Update Magnitude: 0.83330

Collected Steps per Second: 22,321.51524
Overall Steps per Second: 10,578.64807

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.72783

Cumulative Model Updates: 83,494
Cumulative Timesteps: 696,375,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,325.56296
Policy Entropy: 3.67407
Value Function Loss: 0.07310

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.50991
Value Function Update Magnitude: 0.84171

Collected Steps per Second: 22,752.27058
Overall Steps per Second: 10,817.41767

Timestep Collection Time: 2.19846
Timestep Consumption Time: 2.42556
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.62402

Cumulative Model Updates: 83,500
Cumulative Timesteps: 696,425,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 696425080...
Checkpoint 696425080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,455.41550
Policy Entropy: 3.68249
Value Function Loss: 0.07272

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.49052
Value Function Update Magnitude: 0.77129

Collected Steps per Second: 22,668.49435
Overall Steps per Second: 10,642.85528

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.69799

Cumulative Model Updates: 83,506
Cumulative Timesteps: 696,475,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,743.42809
Policy Entropy: 3.68532
Value Function Loss: 0.07176

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07144
Policy Update Magnitude: 0.58436
Value Function Update Magnitude: 0.78761

Collected Steps per Second: 22,908.01710
Overall Steps per Second: 10,879.04247

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.41354
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.59636

Cumulative Model Updates: 83,512
Cumulative Timesteps: 696,525,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 696525084...
Checkpoint 696525084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.81213
Policy Entropy: 3.66514
Value Function Loss: 0.07312

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.61733
Value Function Update Magnitude: 0.77440

Collected Steps per Second: 22,681.38165
Overall Steps per Second: 10,692.15107

Timestep Collection Time: 2.20463
Timestep Consumption Time: 2.47207
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.67670

Cumulative Model Updates: 83,518
Cumulative Timesteps: 696,575,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,860.91117
Policy Entropy: 3.64390
Value Function Loss: 0.07608

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.61838
Value Function Update Magnitude: 0.71315

Collected Steps per Second: 22,490.46854
Overall Steps per Second: 10,553.70655

Timestep Collection Time: 2.22316
Timestep Consumption Time: 2.51451
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.73767

Cumulative Model Updates: 83,524
Cumulative Timesteps: 696,625,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 696625088...
Checkpoint 696625088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,784.11375
Policy Entropy: 3.63679
Value Function Loss: 0.07903

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.52531
Value Function Update Magnitude: 0.63832

Collected Steps per Second: 22,104.24766
Overall Steps per Second: 10,508.27526

Timestep Collection Time: 2.26282
Timestep Consumption Time: 2.49704
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.75987

Cumulative Model Updates: 83,530
Cumulative Timesteps: 696,675,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,644.72017
Policy Entropy: 3.63460
Value Function Loss: 0.07931

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.42387
Value Function Update Magnitude: 0.59166

Collected Steps per Second: 22,471.14706
Overall Steps per Second: 10,487.13332

Timestep Collection Time: 2.22641
Timestep Consumption Time: 2.54420
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.77061

Cumulative Model Updates: 83,536
Cumulative Timesteps: 696,725,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 696725136...
Checkpoint 696725136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,734.99389
Policy Entropy: 3.64589
Value Function Loss: 0.07674

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.37746
Value Function Update Magnitude: 0.61848

Collected Steps per Second: 21,929.76397
Overall Steps per Second: 10,572.12459

Timestep Collection Time: 2.28019
Timestep Consumption Time: 2.44961
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72980

Cumulative Model Updates: 83,542
Cumulative Timesteps: 696,775,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,305.68603
Policy Entropy: 3.65023
Value Function Loss: 0.07488

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.47019
Value Function Update Magnitude: 0.60948

Collected Steps per Second: 22,528.45437
Overall Steps per Second: 10,498.80337

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.54374
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.76378

Cumulative Model Updates: 83,548
Cumulative Timesteps: 696,825,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 696825154...
Checkpoint 696825154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,709.29302
Policy Entropy: 3.66068
Value Function Loss: 0.07046

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.49817
Value Function Update Magnitude: 0.68325

Collected Steps per Second: 21,960.51988
Overall Steps per Second: 10,526.30028

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.75229

Cumulative Model Updates: 83,554
Cumulative Timesteps: 696,875,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,962.32287
Policy Entropy: 3.65242
Value Function Loss: 0.07240

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.69205

Collected Steps per Second: 22,648.80516
Overall Steps per Second: 10,566.66861

Timestep Collection Time: 2.20806
Timestep Consumption Time: 2.52474
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.73281

Cumulative Model Updates: 83,560
Cumulative Timesteps: 696,925,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 696925188...
Checkpoint 696925188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,706.93761
Policy Entropy: 3.64012
Value Function Loss: 0.07338

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.67658
Value Function Update Magnitude: 0.67323

Collected Steps per Second: 22,265.30094
Overall Steps per Second: 10,676.16494

Timestep Collection Time: 2.24628
Timestep Consumption Time: 2.43837
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.68464

Cumulative Model Updates: 83,566
Cumulative Timesteps: 696,975,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,459.04002
Policy Entropy: 3.63310
Value Function Loss: 0.07341

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.62222
Value Function Update Magnitude: 0.71677

Collected Steps per Second: 22,680.00280
Overall Steps per Second: 10,750.09162

Timestep Collection Time: 2.20547
Timestep Consumption Time: 2.44752
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.65298

Cumulative Model Updates: 83,572
Cumulative Timesteps: 697,025,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 697025222...
Checkpoint 697025222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,710.06706
Policy Entropy: 3.65600
Value Function Loss: 0.07144

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.69243

Collected Steps per Second: 22,039.19570
Overall Steps per Second: 10,468.74658

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.50864
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.77841

Cumulative Model Updates: 83,578
Cumulative Timesteps: 697,075,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,511.67564
Policy Entropy: 3.67798
Value Function Loss: 0.07008

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.53454
Value Function Update Magnitude: 0.70341

Collected Steps per Second: 22,881.29142
Overall Steps per Second: 10,768.60945

Timestep Collection Time: 2.18580
Timestep Consumption Time: 2.45862
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.64443

Cumulative Model Updates: 83,584
Cumulative Timesteps: 697,125,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 697125260...
Checkpoint 697125260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,450.54940
Policy Entropy: 3.66948
Value Function Loss: 0.07595

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.48623
Value Function Update Magnitude: 0.61345

Collected Steps per Second: 21,991.13449
Overall Steps per Second: 10,632.67138

Timestep Collection Time: 2.27364
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.70249

Cumulative Model Updates: 83,590
Cumulative Timesteps: 697,175,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,526.89015
Policy Entropy: 3.64624
Value Function Loss: 0.07926

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.45645
Value Function Update Magnitude: 0.53941

Collected Steps per Second: 22,485.62844
Overall Steps per Second: 10,549.68054

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.51684
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.74138

Cumulative Model Updates: 83,596
Cumulative Timesteps: 697,225,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 697225280...
Checkpoint 697225280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,540.05587
Policy Entropy: 3.62818
Value Function Loss: 0.08050

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.52860
Value Function Update Magnitude: 0.54153

Collected Steps per Second: 22,405.03590
Overall Steps per Second: 10,516.06099

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.52430
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.75710

Cumulative Model Updates: 83,602
Cumulative Timesteps: 697,275,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,113.07340
Policy Entropy: 3.62942
Value Function Loss: 0.07733

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.50408
Value Function Update Magnitude: 0.59597

Collected Steps per Second: 23,179.47226
Overall Steps per Second: 10,827.12734

Timestep Collection Time: 2.15829
Timestep Consumption Time: 2.46233
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62062

Cumulative Model Updates: 83,608
Cumulative Timesteps: 697,325,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 697325334...
Checkpoint 697325334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,227.73367
Policy Entropy: 3.64323
Value Function Loss: 0.07564

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.51110
Value Function Update Magnitude: 0.62535

Collected Steps per Second: 22,243.26696
Overall Steps per Second: 10,675.99594

Timestep Collection Time: 2.24886
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.68546

Cumulative Model Updates: 83,614
Cumulative Timesteps: 697,375,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.75785
Policy Entropy: 3.64184
Value Function Loss: 0.07654

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.58304

Collected Steps per Second: 22,832.62618
Overall Steps per Second: 10,617.45892

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.52008
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.71054

Cumulative Model Updates: 83,620
Cumulative Timesteps: 697,425,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 697425370...
Checkpoint 697425370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,332.05946
Policy Entropy: 3.63493
Value Function Loss: 0.07906

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.49748
Value Function Update Magnitude: 0.57507

Collected Steps per Second: 22,545.76769
Overall Steps per Second: 10,365.29457

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.60691
PPO Batch Consumption Time: 0.30887
Total Iteration Time: 4.82533

Cumulative Model Updates: 83,626
Cumulative Timesteps: 697,475,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,992.06126
Policy Entropy: 3.63547
Value Function Loss: 0.07862

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.49363
Value Function Update Magnitude: 0.55205

Collected Steps per Second: 22,996.59593
Overall Steps per Second: 10,630.29181

Timestep Collection Time: 2.17519
Timestep Consumption Time: 2.53042
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.70561

Cumulative Model Updates: 83,632
Cumulative Timesteps: 697,525,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 697525408...
Checkpoint 697525408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,355.12121
Policy Entropy: 3.64455
Value Function Loss: 0.07764

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.46185
Value Function Update Magnitude: 0.53284

Collected Steps per Second: 22,383.32246
Overall Steps per Second: 10,639.38150

Timestep Collection Time: 2.23381
Timestep Consumption Time: 2.46572
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.69952

Cumulative Model Updates: 83,638
Cumulative Timesteps: 697,575,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,236.25468
Policy Entropy: 3.63849
Value Function Loss: 0.07944

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.42959
Value Function Update Magnitude: 0.53525

Collected Steps per Second: 22,100.50995
Overall Steps per Second: 10,683.95239

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68141

Cumulative Model Updates: 83,644
Cumulative Timesteps: 697,625,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 697625424...
Checkpoint 697625424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,117.01074
Policy Entropy: 3.63540
Value Function Loss: 0.08096

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.48811
Value Function Update Magnitude: 0.57213

Collected Steps per Second: 21,563.70171
Overall Steps per Second: 10,541.54661

Timestep Collection Time: 2.31899
Timestep Consumption Time: 2.42472
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.74371

Cumulative Model Updates: 83,650
Cumulative Timesteps: 697,675,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,883.39301
Policy Entropy: 3.62776
Value Function Loss: 0.08175

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.53352
Value Function Update Magnitude: 0.62778

Collected Steps per Second: 21,914.62951
Overall Steps per Second: 10,730.22650

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.37891
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.66122

Cumulative Model Updates: 83,656
Cumulative Timesteps: 697,725,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 697725446...
Checkpoint 697725446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,624.66587
Policy Entropy: 3.62449
Value Function Loss: 0.08061

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.64924

Collected Steps per Second: 21,404.08083
Overall Steps per Second: 10,616.77525

Timestep Collection Time: 2.33684
Timestep Consumption Time: 2.37438
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.71122

Cumulative Model Updates: 83,662
Cumulative Timesteps: 697,775,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,906.52528
Policy Entropy: 3.62605
Value Function Loss: 0.08022

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.14638
Policy Update Magnitude: 0.43136
Value Function Update Magnitude: 0.74584

Collected Steps per Second: 22,182.39281
Overall Steps per Second: 10,616.51617

Timestep Collection Time: 2.25467
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.71096

Cumulative Model Updates: 83,668
Cumulative Timesteps: 697,825,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 697825478...
Checkpoint 697825478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,346.40914
Policy Entropy: 3.62408
Value Function Loss: 0.08075

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.48199
Value Function Update Magnitude: 0.72185

Collected Steps per Second: 22,052.99735
Overall Steps per Second: 10,649.37570

Timestep Collection Time: 2.26917
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.69905

Cumulative Model Updates: 83,674
Cumulative Timesteps: 697,875,520

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,944.63060
Policy Entropy: 3.63039
Value Function Loss: 0.08218

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.47575
Value Function Update Magnitude: 0.61960

Collected Steps per Second: 22,121.62232
Overall Steps per Second: 10,797.71829

Timestep Collection Time: 2.26159
Timestep Consumption Time: 2.37180
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63339

Cumulative Model Updates: 83,680
Cumulative Timesteps: 697,925,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 697925550...
Checkpoint 697925550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,618.03585
Policy Entropy: 3.60948
Value Function Loss: 0.08139

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.43823
Value Function Update Magnitude: 0.56933

Collected Steps per Second: 21,827.52191
Overall Steps per Second: 10,615.88361

Timestep Collection Time: 2.29151
Timestep Consumption Time: 2.42011
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.71162

Cumulative Model Updates: 83,686
Cumulative Timesteps: 697,975,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.77058
Policy Entropy: 3.61348
Value Function Loss: 0.07975

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.43870
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 22,887.62622
Overall Steps per Second: 10,859.50451

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.60573

Cumulative Model Updates: 83,692
Cumulative Timesteps: 698,025,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 698025584...
Checkpoint 698025584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,593.45434
Policy Entropy: 3.60956
Value Function Loss: 0.07888

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.44208
Value Function Update Magnitude: 0.66177

Collected Steps per Second: 22,557.71012
Overall Steps per Second: 10,731.71906

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.66169

Cumulative Model Updates: 83,698
Cumulative Timesteps: 698,075,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,846.24864
Policy Entropy: 3.60805
Value Function Loss: 0.08236

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06750
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.66913

Collected Steps per Second: 22,552.83505
Overall Steps per Second: 10,653.80181

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69579

Cumulative Model Updates: 83,704
Cumulative Timesteps: 698,125,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 698125640...
Checkpoint 698125640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,982.88006
Policy Entropy: 3.59734
Value Function Loss: 0.08464

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.63776

Collected Steps per Second: 22,012.31803
Overall Steps per Second: 10,286.16846

Timestep Collection Time: 2.27355
Timestep Consumption Time: 2.59182
PPO Batch Consumption Time: 0.30639
Total Iteration Time: 4.86537

Cumulative Model Updates: 83,710
Cumulative Timesteps: 698,175,686

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.24538
Policy Entropy: 3.61149
Value Function Loss: 0.07850

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.18052
Policy Update Magnitude: 0.48284
Value Function Update Magnitude: 0.61270

Collected Steps per Second: 22,308.10247
Overall Steps per Second: 10,592.19142

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.72046

Cumulative Model Updates: 83,716
Cumulative Timesteps: 698,225,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 698225686...
Checkpoint 698225686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,527.24439
Policy Entropy: 3.62470
Value Function Loss: 0.07500

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.60551

Collected Steps per Second: 22,063.01305
Overall Steps per Second: 10,593.01636

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.45415
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.72066

Cumulative Model Updates: 83,722
Cumulative Timesteps: 698,275,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,872.28619
Policy Entropy: 3.62252
Value Function Loss: 0.07312

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.61081
Value Function Update Magnitude: 0.61422

Collected Steps per Second: 22,824.31576
Overall Steps per Second: 10,599.15203

Timestep Collection Time: 2.19073
Timestep Consumption Time: 2.52681
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.71755

Cumulative Model Updates: 83,728
Cumulative Timesteps: 698,325,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 698325694...
Checkpoint 698325694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,902.91024
Policy Entropy: 3.62398
Value Function Loss: 0.07558

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.54351
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 22,481.45498
Overall Steps per Second: 10,564.21388

Timestep Collection Time: 2.22486
Timestep Consumption Time: 2.50981
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.73466

Cumulative Model Updates: 83,734
Cumulative Timesteps: 698,375,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,128.91029
Policy Entropy: 3.62423
Value Function Loss: 0.07619

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.16292
Policy Update Magnitude: 0.44403
Value Function Update Magnitude: 0.59322

Collected Steps per Second: 22,675.73696
Overall Steps per Second: 10,587.15293

Timestep Collection Time: 2.20509
Timestep Consumption Time: 2.51781
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.72289

Cumulative Model Updates: 83,740
Cumulative Timesteps: 698,425,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 698425714...
Checkpoint 698425714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,100.98688
Policy Entropy: 3.63503
Value Function Loss: 0.07611

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.44724
Value Function Update Magnitude: 0.60589

Collected Steps per Second: 22,662.20061
Overall Steps per Second: 10,609.76588

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71490

Cumulative Model Updates: 83,746
Cumulative Timesteps: 698,475,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.56389
Policy Entropy: 3.63575
Value Function Loss: 0.07392

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.41414
Value Function Update Magnitude: 0.56362

Collected Steps per Second: 23,063.00133
Overall Steps per Second: 10,815.34388

Timestep Collection Time: 2.16910
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.62547

Cumulative Model Updates: 83,752
Cumulative Timesteps: 698,525,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 698525764...
Checkpoint 698525764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,282.46076
Policy Entropy: 3.64458
Value Function Loss: 0.07441

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.45570
Value Function Update Magnitude: 0.54569

Collected Steps per Second: 22,124.16773
Overall Steps per Second: 10,670.48966

Timestep Collection Time: 2.26142
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.68882

Cumulative Model Updates: 83,758
Cumulative Timesteps: 698,575,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,914.16795
Policy Entropy: 3.64809
Value Function Loss: 0.07248

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.16234
Policy Update Magnitude: 0.40625
Value Function Update Magnitude: 0.62625

Collected Steps per Second: 22,809.30208
Overall Steps per Second: 10,791.43133

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.63460

Cumulative Model Updates: 83,764
Cumulative Timesteps: 698,625,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 698625810...
Checkpoint 698625810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,928.62042
Policy Entropy: 3.65383
Value Function Loss: 0.07133

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.41569
Value Function Update Magnitude: 0.67567

Collected Steps per Second: 22,429.63119
Overall Steps per Second: 10,693.08020

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.44682
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.67611

Cumulative Model Updates: 83,770
Cumulative Timesteps: 698,675,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,821.68857
Policy Entropy: 3.65007
Value Function Loss: 0.06982

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.16461
Policy Update Magnitude: 0.45340
Value Function Update Magnitude: 0.69528

Collected Steps per Second: 22,487.14274
Overall Steps per Second: 10,545.54013

Timestep Collection Time: 2.22394
Timestep Consumption Time: 2.51835
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.74229

Cumulative Model Updates: 83,776
Cumulative Timesteps: 698,725,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 698725822...
Checkpoint 698725822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,589.66895
Policy Entropy: 3.67663
Value Function Loss: 0.06918

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.42420
Value Function Update Magnitude: 0.65507

Collected Steps per Second: 21,859.24541
Overall Steps per Second: 10,513.75511

Timestep Collection Time: 2.28846
Timestep Consumption Time: 2.46950
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.75796

Cumulative Model Updates: 83,782
Cumulative Timesteps: 698,775,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,675.81404
Policy Entropy: 3.68441
Value Function Loss: 0.06897

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.45890
Value Function Update Magnitude: 0.63579

Collected Steps per Second: 21,877.00983
Overall Steps per Second: 10,486.29666

Timestep Collection Time: 2.28642
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.77003

Cumulative Model Updates: 83,788
Cumulative Timesteps: 698,825,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 698825866...
Checkpoint 698825866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,322.26293
Policy Entropy: 3.68543
Value Function Loss: 0.06570

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.45456
Value Function Update Magnitude: 0.64937

Collected Steps per Second: 21,847.96210
Overall Steps per Second: 10,599.01471

Timestep Collection Time: 2.28928
Timestep Consumption Time: 2.42965
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.71893

Cumulative Model Updates: 83,794
Cumulative Timesteps: 698,875,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,375.03586
Policy Entropy: 3.69249
Value Function Loss: 0.06339

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.45463
Value Function Update Magnitude: 0.68074

Collected Steps per Second: 22,926.07576
Overall Steps per Second: 10,552.07630

Timestep Collection Time: 2.18153
Timestep Consumption Time: 2.55820
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.73973

Cumulative Model Updates: 83,800
Cumulative Timesteps: 698,925,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 698925896...
Checkpoint 698925896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,432.56509
Policy Entropy: 3.71016
Value Function Loss: 0.05716

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.47944
Value Function Update Magnitude: 0.74197

Collected Steps per Second: 22,412.02746
Overall Steps per Second: 10,704.60060

Timestep Collection Time: 2.23148
Timestep Consumption Time: 2.44053
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.67201

Cumulative Model Updates: 83,806
Cumulative Timesteps: 698,975,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,236.83390
Policy Entropy: 3.72162
Value Function Loss: 0.05386

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.52555
Value Function Update Magnitude: 0.75540

Collected Steps per Second: 22,741.73068
Overall Steps per Second: 10,735.27329

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.45993
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.65941

Cumulative Model Updates: 83,812
Cumulative Timesteps: 699,025,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 699025928...
Checkpoint 699025928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.66011
Policy Entropy: 3.71117
Value Function Loss: 0.05385

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.75068

Collected Steps per Second: 21,842.42311
Overall Steps per Second: 10,745.75677

Timestep Collection Time: 2.28995
Timestep Consumption Time: 2.36473
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.65467

Cumulative Model Updates: 83,818
Cumulative Timesteps: 699,075,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,741.06820
Policy Entropy: 3.69469
Value Function Loss: 0.05800

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.60186
Value Function Update Magnitude: 0.72681

Collected Steps per Second: 22,133.38766
Overall Steps per Second: 10,809.86983

Timestep Collection Time: 2.25903
Timestep Consumption Time: 2.36637
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.62540

Cumulative Model Updates: 83,824
Cumulative Timesteps: 699,125,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 699125946...
Checkpoint 699125946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.77771
Policy Entropy: 3.69494
Value Function Loss: 0.05880

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07114
Policy Update Magnitude: 0.64677
Value Function Update Magnitude: 0.73735

Collected Steps per Second: 21,487.60586
Overall Steps per Second: 10,635.03394

Timestep Collection Time: 2.32813
Timestep Consumption Time: 2.37575
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.70389

Cumulative Model Updates: 83,830
Cumulative Timesteps: 699,175,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,759.88571
Policy Entropy: 3.69512
Value Function Loss: 0.06108

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06221
Policy Update Magnitude: 0.67327
Value Function Update Magnitude: 0.71823

Collected Steps per Second: 21,944.07463
Overall Steps per Second: 10,601.55810

Timestep Collection Time: 2.27961
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.71855

Cumulative Model Updates: 83,836
Cumulative Timesteps: 699,225,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 699225996...
Checkpoint 699225996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,555.62297
Policy Entropy: 3.69312
Value Function Loss: 0.06341

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.70704
Value Function Update Magnitude: 0.69052

Collected Steps per Second: 21,471.13602
Overall Steps per Second: 10,344.26877

Timestep Collection Time: 2.32927
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.30371
Total Iteration Time: 4.83475

Cumulative Model Updates: 83,842
Cumulative Timesteps: 699,276,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,988.85604
Policy Entropy: 3.69165
Value Function Loss: 0.06472

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.69693
Value Function Update Magnitude: 0.70710

Collected Steps per Second: 21,344.05511
Overall Steps per Second: 10,633.13896

Timestep Collection Time: 2.34379
Timestep Consumption Time: 2.36093
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.70473

Cumulative Model Updates: 83,848
Cumulative Timesteps: 699,326,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 699326034...
Checkpoint 699326034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,033.65074
Policy Entropy: 3.68856
Value Function Loss: 0.06323

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07252
Policy Update Magnitude: 0.67082
Value Function Update Magnitude: 0.73923

Collected Steps per Second: 21,572.91800
Overall Steps per Second: 10,467.66876

Timestep Collection Time: 2.31809
Timestep Consumption Time: 2.45929
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.77738

Cumulative Model Updates: 83,854
Cumulative Timesteps: 699,376,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,566.29782
Policy Entropy: 3.68148
Value Function Loss: 0.06371

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06192
Policy Update Magnitude: 0.71050
Value Function Update Magnitude: 0.76186

Collected Steps per Second: 22,716.36176
Overall Steps per Second: 10,705.75203

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.46982
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.67132

Cumulative Model Updates: 83,860
Cumulative Timesteps: 699,426,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 699426052...
Checkpoint 699426052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,276.31592
Policy Entropy: 3.67569
Value Function Loss: 0.06532

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06644
Policy Update Magnitude: 0.74684
Value Function Update Magnitude: 0.77660

Collected Steps per Second: 22,379.22172
Overall Steps per Second: 10,660.44521

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.45671
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.69155

Cumulative Model Updates: 83,866
Cumulative Timesteps: 699,476,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,436.09514
Policy Entropy: 3.66600
Value Function Loss: 0.06866

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.74914
Value Function Update Magnitude: 0.79420

Collected Steps per Second: 22,987.02624
Overall Steps per Second: 10,817.33858

Timestep Collection Time: 2.17531
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62258

Cumulative Model Updates: 83,872
Cumulative Timesteps: 699,526,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 699526070...
Checkpoint 699526070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,148.16769
Policy Entropy: 3.67274
Value Function Loss: 0.06996

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.68209
Value Function Update Magnitude: 0.76820

Collected Steps per Second: 22,630.53391
Overall Steps per Second: 10,684.54667

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.68003

Cumulative Model Updates: 83,878
Cumulative Timesteps: 699,576,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,566.30052
Policy Entropy: 3.66985
Value Function Loss: 0.07113

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.56040
Value Function Update Magnitude: 0.73318

Collected Steps per Second: 23,115.49465
Overall Steps per Second: 10,910.78933

Timestep Collection Time: 2.16357
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.58372

Cumulative Model Updates: 83,884
Cumulative Timesteps: 699,626,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 699626086...
Checkpoint 699626086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,500.04951
Policy Entropy: 3.68414
Value Function Loss: 0.06887

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.47090
Value Function Update Magnitude: 0.70978

Collected Steps per Second: 22,749.06278
Overall Steps per Second: 10,627.51639

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.50788
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.70665

Cumulative Model Updates: 83,890
Cumulative Timesteps: 699,676,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,304.33690
Policy Entropy: 3.68486
Value Function Loss: 0.06826

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.49065
Value Function Update Magnitude: 0.69470

Collected Steps per Second: 23,270.66870
Overall Steps per Second: 10,942.98280

Timestep Collection Time: 2.14871
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.56932

Cumulative Model Updates: 83,896
Cumulative Timesteps: 699,726,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 699726108...
Checkpoint 699726108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,822.38338
Policy Entropy: 3.68470
Value Function Loss: 0.06907

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05399
Policy Update Magnitude: 0.63280
Value Function Update Magnitude: 0.71040

Collected Steps per Second: 22,549.43133
Overall Steps per Second: 10,641.87379

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.48137
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.69898

Cumulative Model Updates: 83,902
Cumulative Timesteps: 699,776,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,758.29325
Policy Entropy: 3.67780
Value Function Loss: 0.07120

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.68060
Value Function Update Magnitude: 0.72114

Collected Steps per Second: 22,702.92550
Overall Steps per Second: 10,835.69619

Timestep Collection Time: 2.20298
Timestep Consumption Time: 2.41269
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61567

Cumulative Model Updates: 83,908
Cumulative Timesteps: 699,826,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 699826128...
Checkpoint 699826128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,961.81678
Policy Entropy: 3.67080
Value Function Loss: 0.07149

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06392
Policy Update Magnitude: 0.72676
Value Function Update Magnitude: 0.73415

Collected Steps per Second: 22,296.93771
Overall Steps per Second: 10,658.46023

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.44904
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.69186

Cumulative Model Updates: 83,914
Cumulative Timesteps: 699,876,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,907.29691
Policy Entropy: 3.67435
Value Function Loss: 0.07224

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.71785
Value Function Update Magnitude: 0.79198

Collected Steps per Second: 22,976.73733
Overall Steps per Second: 10,834.29790

Timestep Collection Time: 2.17707
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61700

Cumulative Model Updates: 83,920
Cumulative Timesteps: 699,926,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 699926158...
Checkpoint 699926158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,247.96238
Policy Entropy: 3.65900
Value Function Loss: 0.07515

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06663
Policy Update Magnitude: 0.70621
Value Function Update Magnitude: 0.77756

Collected Steps per Second: 22,716.02319
Overall Steps per Second: 10,806.50857

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.62814

Cumulative Model Updates: 83,926
Cumulative Timesteps: 699,976,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.29632
Policy Entropy: 3.64727
Value Function Loss: 0.08050

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.70132
Value Function Update Magnitude: 0.74435

Collected Steps per Second: 23,228.49092
Overall Steps per Second: 10,808.27343

Timestep Collection Time: 2.15356
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.62831

Cumulative Model Updates: 83,932
Cumulative Timesteps: 700,026,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 700026196...
Checkpoint 700026196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,610.53473
Policy Entropy: 3.64734
Value Function Loss: 0.08003

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.68057
Value Function Update Magnitude: 0.69895

Collected Steps per Second: 22,635.56318
Overall Steps per Second: 10,651.59646

Timestep Collection Time: 2.21024
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.69695

Cumulative Model Updates: 83,938
Cumulative Timesteps: 700,076,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,255.61883
Policy Entropy: 3.66543
Value Function Loss: 0.07840

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.60439
Value Function Update Magnitude: 0.77227

Collected Steps per Second: 23,151.94648
Overall Steps per Second: 10,964.82981

Timestep Collection Time: 2.15982
Timestep Consumption Time: 2.40058
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.56040

Cumulative Model Updates: 83,944
Cumulative Timesteps: 700,126,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 700126230...
Checkpoint 700126230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,041.14771
Policy Entropy: 3.68138
Value Function Loss: 0.07744

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.54341
Value Function Update Magnitude: 0.87903

Collected Steps per Second: 22,642.34849
Overall Steps per Second: 10,620.71564

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.70966

Cumulative Model Updates: 83,950
Cumulative Timesteps: 700,176,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,735.61990
Policy Entropy: 3.67849
Value Function Loss: 0.07643

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.61029
Value Function Update Magnitude: 0.91726

Collected Steps per Second: 22,537.42386
Overall Steps per Second: 10,503.18922

Timestep Collection Time: 2.21880
Timestep Consumption Time: 2.54223
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76103

Cumulative Model Updates: 83,956
Cumulative Timesteps: 700,226,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 700226256...
Checkpoint 700226256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.99569
Policy Entropy: 3.67632
Value Function Loss: 0.07909

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.94050

Collected Steps per Second: 22,790.06724
Overall Steps per Second: 10,657.91577

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.69285

Cumulative Model Updates: 83,962
Cumulative Timesteps: 700,276,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,235.75479
Policy Entropy: 3.68604
Value Function Loss: 0.07742

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.51716
Value Function Update Magnitude: 0.89580

Collected Steps per Second: 22,769.11591
Overall Steps per Second: 10,794.47663

Timestep Collection Time: 2.19613
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.63237

Cumulative Model Updates: 83,968
Cumulative Timesteps: 700,326,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 700326276...
Checkpoint 700326276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,303.01298
Policy Entropy: 3.68063
Value Function Loss: 0.08183

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.77805

Collected Steps per Second: 22,227.77410
Overall Steps per Second: 10,716.86873

Timestep Collection Time: 2.24989
Timestep Consumption Time: 2.41659
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.66647

Cumulative Model Updates: 83,974
Cumulative Timesteps: 700,376,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.52204
Policy Entropy: 3.68058
Value Function Loss: 0.07847

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.56546
Value Function Update Magnitude: 0.83927

Collected Steps per Second: 22,775.70790
Overall Steps per Second: 10,775.12744

Timestep Collection Time: 2.19638
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.64254

Cumulative Model Updates: 83,980
Cumulative Timesteps: 700,426,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 700426310...
Checkpoint 700426310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,262.39631
Policy Entropy: 3.67991
Value Function Loss: 0.07529

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.90407

Collected Steps per Second: 22,607.76109
Overall Steps per Second: 10,708.43322

Timestep Collection Time: 2.21260
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.67127

Cumulative Model Updates: 83,986
Cumulative Timesteps: 700,476,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,295.93823
Policy Entropy: 3.67694
Value Function Loss: 0.07439

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.59444
Value Function Update Magnitude: 0.90869

Collected Steps per Second: 23,106.48544
Overall Steps per Second: 10,850.11536

Timestep Collection Time: 2.16554
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61175

Cumulative Model Updates: 83,992
Cumulative Timesteps: 700,526,370

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 700526370...
Checkpoint 700526370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,183.72970
Policy Entropy: 3.67575
Value Function Loss: 0.07428

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.92089

Collected Steps per Second: 22,679.75082
Overall Steps per Second: 10,750.02023

Timestep Collection Time: 2.20664
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.65543

Cumulative Model Updates: 83,998
Cumulative Timesteps: 700,576,416

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,523.15173
Policy Entropy: 3.65815
Value Function Loss: 0.07482

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.91557

Collected Steps per Second: 23,096.17492
Overall Steps per Second: 10,879.11299

Timestep Collection Time: 2.16547
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59725

Cumulative Model Updates: 84,004
Cumulative Timesteps: 700,626,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 700626430...
Checkpoint 700626430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,338.04213
Policy Entropy: 3.66047
Value Function Loss: 0.07484

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.58647
Value Function Update Magnitude: 0.80148

Collected Steps per Second: 22,975.27306
Overall Steps per Second: 10,645.50029

Timestep Collection Time: 2.17730
Timestep Consumption Time: 2.52178
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.69907

Cumulative Model Updates: 84,010
Cumulative Timesteps: 700,676,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,259.32761
Policy Entropy: 3.65297
Value Function Loss: 0.07669

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.48599
Value Function Update Magnitude: 0.67790

Collected Steps per Second: 22,557.90984
Overall Steps per Second: 10,585.88523

Timestep Collection Time: 2.21723
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.72478

Cumulative Model Updates: 84,016
Cumulative Timesteps: 700,726,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 700726470...
Checkpoint 700726470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,494.87544
Policy Entropy: 3.66707
Value Function Loss: 0.07803

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.53433
Value Function Update Magnitude: 0.66400

Collected Steps per Second: 22,245.83840
Overall Steps per Second: 10,509.52356

Timestep Collection Time: 2.24761
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.75759

Cumulative Model Updates: 84,022
Cumulative Timesteps: 700,776,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,980.02510
Policy Entropy: 3.66436
Value Function Loss: 0.08153

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.58352
Value Function Update Magnitude: 0.67157

Collected Steps per Second: 22,664.93908
Overall Steps per Second: 10,628.78587

Timestep Collection Time: 2.20817
Timestep Consumption Time: 2.50055
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.70872

Cumulative Model Updates: 84,028
Cumulative Timesteps: 700,826,518

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 700826518...
Checkpoint 700826518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,832.17741
Policy Entropy: 3.66870
Value Function Loss: 0.08139

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.57853
Value Function Update Magnitude: 0.72668

Collected Steps per Second: 22,174.19169
Overall Steps per Second: 10,481.90149

Timestep Collection Time: 2.25532
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.77108

Cumulative Model Updates: 84,034
Cumulative Timesteps: 700,876,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,583.43678
Policy Entropy: 3.67692
Value Function Loss: 0.08036

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.55719
Value Function Update Magnitude: 0.76950

Collected Steps per Second: 22,973.25172
Overall Steps per Second: 10,844.01202

Timestep Collection Time: 2.17723
Timestep Consumption Time: 2.43527
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.61250

Cumulative Model Updates: 84,040
Cumulative Timesteps: 700,926,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 700926546...
Checkpoint 700926546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,749.70120
Policy Entropy: 3.67101
Value Function Loss: 0.08188

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.59222
Value Function Update Magnitude: 0.72978

Collected Steps per Second: 22,115.84334
Overall Steps per Second: 10,620.49758

Timestep Collection Time: 2.26173
Timestep Consumption Time: 2.44803
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.70976

Cumulative Model Updates: 84,046
Cumulative Timesteps: 700,976,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,854.64767
Policy Entropy: 3.67063
Value Function Loss: 0.08198

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06401
Policy Update Magnitude: 0.67107
Value Function Update Magnitude: 0.78379

Collected Steps per Second: 23,067.41816
Overall Steps per Second: 10,699.80464

Timestep Collection Time: 2.16973
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.67766

Cumulative Model Updates: 84,052
Cumulative Timesteps: 701,026,616

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 701026616...
Checkpoint 701026616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,665.31941
Policy Entropy: 3.66350
Value Function Loss: 0.08282

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.73707
Value Function Update Magnitude: 0.81306

Collected Steps per Second: 22,973.27449
Overall Steps per Second: 10,854.98290

Timestep Collection Time: 2.17731
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60802

Cumulative Model Updates: 84,058
Cumulative Timesteps: 701,076,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,332.67364
Policy Entropy: 3.66699
Value Function Loss: 0.07999

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.68676
Value Function Update Magnitude: 0.79054

Collected Steps per Second: 23,032.29097
Overall Steps per Second: 10,926.16191

Timestep Collection Time: 2.17225
Timestep Consumption Time: 2.40685
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.57910

Cumulative Model Updates: 84,064
Cumulative Timesteps: 701,126,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 701126668...
Checkpoint 701126668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,726.99949
Policy Entropy: 3.66028
Value Function Loss: 0.07868

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.16024
Policy Update Magnitude: 0.50213
Value Function Update Magnitude: 0.81876

Collected Steps per Second: 22,667.24503
Overall Steps per Second: 10,736.19530

Timestep Collection Time: 2.20644
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.65845

Cumulative Model Updates: 84,070
Cumulative Timesteps: 701,176,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,480.54028
Policy Entropy: 3.67250
Value Function Loss: 0.07541

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.79552

Collected Steps per Second: 23,114.73371
Overall Steps per Second: 10,839.08803

Timestep Collection Time: 2.16356
Timestep Consumption Time: 2.45030
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61386

Cumulative Model Updates: 84,076
Cumulative Timesteps: 701,226,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 701226692...
Checkpoint 701226692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,794.52043
Policy Entropy: 3.68475
Value Function Loss: 0.07214

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.87495

Collected Steps per Second: 22,545.36118
Overall Steps per Second: 10,685.84832

Timestep Collection Time: 2.21846
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.68058

Cumulative Model Updates: 84,082
Cumulative Timesteps: 701,276,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,512.54396
Policy Entropy: 3.69769
Value Function Loss: 0.06961

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.51707
Value Function Update Magnitude: 0.90533

Collected Steps per Second: 22,447.03558
Overall Steps per Second: 10,598.07140

Timestep Collection Time: 2.22871
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.72048

Cumulative Model Updates: 84,088
Cumulative Timesteps: 701,326,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 701326736...
Checkpoint 701326736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,115.70981
Policy Entropy: 3.69844
Value Function Loss: 0.06821

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.51511
Value Function Update Magnitude: 0.91363

Collected Steps per Second: 22,100.46890
Overall Steps per Second: 10,527.29946

Timestep Collection Time: 2.26321
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.75127

Cumulative Model Updates: 84,094
Cumulative Timesteps: 701,376,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,867.04970
Policy Entropy: 3.69901
Value Function Loss: 0.06830

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.50439
Value Function Update Magnitude: 0.88805

Collected Steps per Second: 23,005.28777
Overall Steps per Second: 10,827.23939

Timestep Collection Time: 2.17515
Timestep Consumption Time: 2.44652
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62168

Cumulative Model Updates: 84,100
Cumulative Timesteps: 701,426,794

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 701426794...
Checkpoint 701426794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,054.79077
Policy Entropy: 3.69610
Value Function Loss: 0.07481

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.82878

Collected Steps per Second: 22,761.64454
Overall Steps per Second: 10,683.72781

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.68020

Cumulative Model Updates: 84,106
Cumulative Timesteps: 701,476,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,662.95514
Policy Entropy: 3.69326
Value Function Loss: 0.07901

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.86391

Collected Steps per Second: 23,247.75172
Overall Steps per Second: 10,901.67338

Timestep Collection Time: 2.15186
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.58884

Cumulative Model Updates: 84,112
Cumulative Timesteps: 701,526,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 701526822...
Checkpoint 701526822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,735.27284
Policy Entropy: 3.68888
Value Function Loss: 0.07934

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.51760
Value Function Update Magnitude: 0.88537

Collected Steps per Second: 22,611.44925
Overall Steps per Second: 10,692.59283

Timestep Collection Time: 2.21207
Timestep Consumption Time: 2.46575
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.67782

Cumulative Model Updates: 84,118
Cumulative Timesteps: 701,576,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,559.94133
Policy Entropy: 3.68113
Value Function Loss: 0.07888

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.56761
Value Function Update Magnitude: 0.90039

Collected Steps per Second: 22,969.53769
Overall Steps per Second: 10,823.00264

Timestep Collection Time: 2.17741
Timestep Consumption Time: 2.44368
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.62108

Cumulative Model Updates: 84,124
Cumulative Timesteps: 701,626,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 701626854...
Checkpoint 701626854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.04855
Policy Entropy: 3.67374
Value Function Loss: 0.07530

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.92380

Collected Steps per Second: 22,435.55060
Overall Steps per Second: 10,715.63237

Timestep Collection Time: 2.22985
Timestep Consumption Time: 2.43884
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.66869

Cumulative Model Updates: 84,130
Cumulative Timesteps: 701,676,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,715.12040
Policy Entropy: 3.66540
Value Function Loss: 0.07614

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.63529
Value Function Update Magnitude: 0.92871

Collected Steps per Second: 22,683.26242
Overall Steps per Second: 10,648.96452

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.69698

Cumulative Model Updates: 84,136
Cumulative Timesteps: 701,726,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 701726900...
Checkpoint 701726900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,213.68661
Policy Entropy: 3.66618
Value Function Loss: 0.07410

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.15805
Policy Update Magnitude: 0.61515
Value Function Update Magnitude: 0.80773

Collected Steps per Second: 22,259.71777
Overall Steps per Second: 10,576.78266

Timestep Collection Time: 2.24738
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.72979

Cumulative Model Updates: 84,142
Cumulative Timesteps: 701,776,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,076.58910
Policy Entropy: 3.68153
Value Function Loss: 0.07690

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.52209
Value Function Update Magnitude: 0.70748

Collected Steps per Second: 22,457.18611
Overall Steps per Second: 10,715.16691

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.44080
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.66815

Cumulative Model Updates: 84,148
Cumulative Timesteps: 701,826,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 701826946...
Checkpoint 701826946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,066.74566
Policy Entropy: 3.68412
Value Function Loss: 0.07662

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.55963
Value Function Update Magnitude: 0.73885

Collected Steps per Second: 22,378.02967
Overall Steps per Second: 10,663.83856

Timestep Collection Time: 2.23478
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.68968

Cumulative Model Updates: 84,154
Cumulative Timesteps: 701,876,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,472.58666
Policy Entropy: 3.68266
Value Function Loss: 0.07572

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.68331
Value Function Update Magnitude: 0.70007

Collected Steps per Second: 22,277.14925
Overall Steps per Second: 10,477.90049

Timestep Collection Time: 2.24589
Timestep Consumption Time: 2.52911
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.77500

Cumulative Model Updates: 84,160
Cumulative Timesteps: 701,926,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 701926988...
Checkpoint 701926988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,865.58658
Policy Entropy: 3.66100
Value Function Loss: 0.07600

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.75000
Value Function Update Magnitude: 0.64831

Collected Steps per Second: 22,304.84399
Overall Steps per Second: 10,694.45809

Timestep Collection Time: 2.24229
Timestep Consumption Time: 2.43433
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.67663

Cumulative Model Updates: 84,166
Cumulative Timesteps: 701,977,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.33007
Policy Entropy: 3.65685
Value Function Loss: 0.07614

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07280
Policy Update Magnitude: 0.76003
Value Function Update Magnitude: 0.68123

Collected Steps per Second: 23,092.96534
Overall Steps per Second: 10,806.88787

Timestep Collection Time: 2.16620
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62890

Cumulative Model Updates: 84,172
Cumulative Timesteps: 702,027,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 702027026...
Checkpoint 702027026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,363.21067
Policy Entropy: 3.65939
Value Function Loss: 0.07393

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.76314
Value Function Update Magnitude: 0.75690

Collected Steps per Second: 22,817.16669
Overall Steps per Second: 10,660.38690

Timestep Collection Time: 2.19142
Timestep Consumption Time: 2.49903
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.69045

Cumulative Model Updates: 84,178
Cumulative Timesteps: 702,077,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,430.69254
Policy Entropy: 3.67317
Value Function Loss: 0.07431

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.74389
Value Function Update Magnitude: 0.75452

Collected Steps per Second: 23,295.72304
Overall Steps per Second: 10,908.84593

Timestep Collection Time: 2.14709
Timestep Consumption Time: 2.43800
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.58509

Cumulative Model Updates: 84,184
Cumulative Timesteps: 702,127,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 702127046...
Checkpoint 702127046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.54363
Policy Entropy: 3.66969
Value Function Loss: 0.07811

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.68062
Value Function Update Magnitude: 0.66695

Collected Steps per Second: 22,563.32105
Overall Steps per Second: 10,642.05210

Timestep Collection Time: 2.21634
Timestep Consumption Time: 2.48275
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.69909

Cumulative Model Updates: 84,190
Cumulative Timesteps: 702,177,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,515.88765
Policy Entropy: 3.65831
Value Function Loss: 0.08372

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.73801

Collected Steps per Second: 23,172.79148
Overall Steps per Second: 10,887.00228

Timestep Collection Time: 2.15848
Timestep Consumption Time: 2.43581
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.59429

Cumulative Model Updates: 84,196
Cumulative Timesteps: 702,227,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 702227072...
Checkpoint 702227072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,722.96152
Policy Entropy: 3.65576
Value Function Loss: 0.08308

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.53141
Value Function Update Magnitude: 0.85057

Collected Steps per Second: 22,840.79355
Overall Steps per Second: 10,695.68226

Timestep Collection Time: 2.18907
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.67478

Cumulative Model Updates: 84,202
Cumulative Timesteps: 702,277,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,014.80141
Policy Entropy: 3.65196
Value Function Loss: 0.07981

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.48489
Value Function Update Magnitude: 0.86482

Collected Steps per Second: 22,825.71904
Overall Steps per Second: 10,810.16771

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62620

Cumulative Model Updates: 84,208
Cumulative Timesteps: 702,327,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 702327082...
Checkpoint 702327082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,590.83030
Policy Entropy: 3.63935
Value Function Loss: 0.07809

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.52407
Value Function Update Magnitude: 0.86205

Collected Steps per Second: 22,178.03956
Overall Steps per Second: 10,711.51874

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.41436
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.66974

Cumulative Model Updates: 84,214
Cumulative Timesteps: 702,377,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,918.07235
Policy Entropy: 3.63558
Value Function Loss: 0.07914

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.56886
Value Function Update Magnitude: 0.86257

Collected Steps per Second: 22,988.00188
Overall Steps per Second: 10,831.00043

Timestep Collection Time: 2.17627
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61896

Cumulative Model Updates: 84,220
Cumulative Timesteps: 702,427,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 702427130...
Checkpoint 702427130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,966.31111
Policy Entropy: 3.63567
Value Function Loss: 0.08316

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.57340
Value Function Update Magnitude: 0.86882

Collected Steps per Second: 22,340.12895
Overall Steps per Second: 10,673.04279

Timestep Collection Time: 2.23938
Timestep Consumption Time: 2.44794
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68732

Cumulative Model Updates: 84,226
Cumulative Timesteps: 702,477,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,885.26523
Policy Entropy: 3.65061
Value Function Loss: 0.08296

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.86504

Collected Steps per Second: 23,195.41572
Overall Steps per Second: 10,715.92363

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.66707

Cumulative Model Updates: 84,232
Cumulative Timesteps: 702,527,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 702527170...
Checkpoint 702527170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.61915
Policy Entropy: 3.65573
Value Function Loss: 0.08284

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.49886
Value Function Update Magnitude: 0.86358

Collected Steps per Second: 22,534.61034
Overall Steps per Second: 10,633.40133

Timestep Collection Time: 2.22005
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.70480

Cumulative Model Updates: 84,238
Cumulative Timesteps: 702,577,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,900.03928
Policy Entropy: 3.64948
Value Function Loss: 0.08248

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.47048
Value Function Update Magnitude: 0.72525

Collected Steps per Second: 22,215.62718
Overall Steps per Second: 10,626.64386

Timestep Collection Time: 2.25085
Timestep Consumption Time: 2.45468
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.70553

Cumulative Model Updates: 84,244
Cumulative Timesteps: 702,627,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 702627202...
Checkpoint 702627202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,749.46272
Policy Entropy: 3.64292
Value Function Loss: 0.08140

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.45266
Value Function Update Magnitude: 0.63452

Collected Steps per Second: 22,829.71813
Overall Steps per Second: 10,715.21408

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.47643
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.66682

Cumulative Model Updates: 84,250
Cumulative Timesteps: 702,677,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,907.24634
Policy Entropy: 3.64227
Value Function Loss: 0.08019

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.48647
Value Function Update Magnitude: 0.63521

Collected Steps per Second: 22,997.82094
Overall Steps per Second: 10,854.58765

Timestep Collection Time: 2.17516
Timestep Consumption Time: 2.43340
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.60856

Cumulative Model Updates: 84,256
Cumulative Timesteps: 702,727,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 702727232...
Checkpoint 702727232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,815.96920
Policy Entropy: 3.63714
Value Function Loss: 0.07948

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.52328
Value Function Update Magnitude: 0.68144

Collected Steps per Second: 22,674.82505
Overall Steps per Second: 10,719.77047

Timestep Collection Time: 2.20562
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.66540

Cumulative Model Updates: 84,262
Cumulative Timesteps: 702,777,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.00598
Policy Entropy: 3.63422
Value Function Loss: 0.07531

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.43311
Value Function Update Magnitude: 0.74704

Collected Steps per Second: 22,859.46685
Overall Steps per Second: 10,810.62406

Timestep Collection Time: 2.18737
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.62526

Cumulative Model Updates: 84,268
Cumulative Timesteps: 702,827,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 702827246...
Checkpoint 702827246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,001.56962
Policy Entropy: 3.64087
Value Function Loss: 0.07248

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.53513
Value Function Update Magnitude: 0.81422

Collected Steps per Second: 22,145.23007
Overall Steps per Second: 10,658.37531

Timestep Collection Time: 2.25882
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.69321

Cumulative Model Updates: 84,274
Cumulative Timesteps: 702,877,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,077.05808
Policy Entropy: 3.66096
Value Function Loss: 0.07218

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.57196
Value Function Update Magnitude: 0.78851

Collected Steps per Second: 22,985.72849
Overall Steps per Second: 10,756.64827

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.47401
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.65015

Cumulative Model Updates: 84,280
Cumulative Timesteps: 702,927,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 702927288...
Checkpoint 702927288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.69570
Policy Entropy: 3.66436
Value Function Loss: 0.07459

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.74056

Collected Steps per Second: 22,411.69367
Overall Steps per Second: 10,772.12758

Timestep Collection Time: 2.23098
Timestep Consumption Time: 2.41063
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.64161

Cumulative Model Updates: 84,286
Cumulative Timesteps: 702,977,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,350.99141
Policy Entropy: 3.66813
Value Function Loss: 0.07551

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.52743
Value Function Update Magnitude: 0.71460

Collected Steps per Second: 23,046.83723
Overall Steps per Second: 10,603.99762

Timestep Collection Time: 2.16984
Timestep Consumption Time: 2.54612
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.71596

Cumulative Model Updates: 84,292
Cumulative Timesteps: 703,027,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 703027296...
Checkpoint 703027296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,285.15878
Policy Entropy: 3.66300
Value Function Loss: 0.07447

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.50646
Value Function Update Magnitude: 0.83031

Collected Steps per Second: 22,891.27386
Overall Steps per Second: 10,906.47839

Timestep Collection Time: 2.18546
Timestep Consumption Time: 2.40154
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.58700

Cumulative Model Updates: 84,298
Cumulative Timesteps: 703,077,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.29697
Policy Entropy: 3.66913
Value Function Loss: 0.06982

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.90098

Collected Steps per Second: 23,048.19952
Overall Steps per Second: 10,731.68207

Timestep Collection Time: 2.16954
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.65947

Cumulative Model Updates: 84,304
Cumulative Timesteps: 703,127,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 703127328...
Checkpoint 703127328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,228.67568
Policy Entropy: 3.67096
Value Function Loss: 0.06937

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.87868

Collected Steps per Second: 22,895.10902
Overall Steps per Second: 10,895.44893

Timestep Collection Time: 2.18396
Timestep Consumption Time: 2.40530
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58926

Cumulative Model Updates: 84,310
Cumulative Timesteps: 703,177,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,998.45970
Policy Entropy: 3.66643
Value Function Loss: 0.06771

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.59100
Value Function Update Magnitude: 0.88344

Collected Steps per Second: 22,762.25369
Overall Steps per Second: 10,636.35355

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.70218

Cumulative Model Updates: 84,316
Cumulative Timesteps: 703,227,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 703227344...
Checkpoint 703227344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,351.84817
Policy Entropy: 3.65910
Value Function Loss: 0.06888

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.53265
Value Function Update Magnitude: 0.86687

Collected Steps per Second: 22,791.29786
Overall Steps per Second: 10,867.33364

Timestep Collection Time: 2.19452
Timestep Consumption Time: 2.40790
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60242

Cumulative Model Updates: 84,322
Cumulative Timesteps: 703,277,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.30523
Policy Entropy: 3.66201
Value Function Loss: 0.07047

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.52136
Value Function Update Magnitude: 0.83090

Collected Steps per Second: 22,430.96880
Overall Steps per Second: 10,557.39838

Timestep Collection Time: 2.22977
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.73753

Cumulative Model Updates: 84,328
Cumulative Timesteps: 703,327,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 703327376...
Checkpoint 703327376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.46845
Policy Entropy: 3.66325
Value Function Loss: 0.07051

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.50526
Value Function Update Magnitude: 0.87016

Collected Steps per Second: 22,184.09668
Overall Steps per Second: 10,674.07777

Timestep Collection Time: 2.25396
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.68443

Cumulative Model Updates: 84,334
Cumulative Timesteps: 703,377,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,868.18471
Policy Entropy: 3.66639
Value Function Loss: 0.07135

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.49062
Value Function Update Magnitude: 0.91663

Collected Steps per Second: 22,528.18636
Overall Steps per Second: 10,747.52720

Timestep Collection Time: 2.21971
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.65279

Cumulative Model Updates: 84,340
Cumulative Timesteps: 703,427,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 703427384...
Checkpoint 703427384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,683.82424
Policy Entropy: 3.67850
Value Function Loss: 0.07220

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.52601
Value Function Update Magnitude: 0.93483

Collected Steps per Second: 22,825.69514
Overall Steps per Second: 10,780.61500

Timestep Collection Time: 2.19183
Timestep Consumption Time: 2.44891
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.64074

Cumulative Model Updates: 84,346
Cumulative Timesteps: 703,477,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,232.49035
Policy Entropy: 3.67941
Value Function Loss: 0.07217

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.53704
Value Function Update Magnitude: 0.88128

Collected Steps per Second: 23,305.40047
Overall Steps per Second: 10,795.69756

Timestep Collection Time: 2.14603
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.63277

Cumulative Model Updates: 84,352
Cumulative Timesteps: 703,527,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 703527428...
Checkpoint 703527428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,736.85386
Policy Entropy: 3.68004
Value Function Loss: 0.07538

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.50430
Value Function Update Magnitude: 0.80675

Collected Steps per Second: 22,696.17529
Overall Steps per Second: 10,713.81276

Timestep Collection Time: 2.20363
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.66818

Cumulative Model Updates: 84,358
Cumulative Timesteps: 703,577,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,162.02266
Policy Entropy: 3.66530
Value Function Loss: 0.07603

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.80773

Collected Steps per Second: 23,159.28819
Overall Steps per Second: 10,826.82491

Timestep Collection Time: 2.15896
Timestep Consumption Time: 2.45920
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.61816

Cumulative Model Updates: 84,364
Cumulative Timesteps: 703,627,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 703627442...
Checkpoint 703627442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,366.29589
Policy Entropy: 3.65849
Value Function Loss: 0.08023

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.78611

Collected Steps per Second: 22,595.21660
Overall Steps per Second: 10,672.53534

Timestep Collection Time: 2.21321
Timestep Consumption Time: 2.47246
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.68567

Cumulative Model Updates: 84,370
Cumulative Timesteps: 703,677,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,782.94044
Policy Entropy: 3.64500
Value Function Loss: 0.07859

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11052
Policy Update Magnitude: 0.54162
Value Function Update Magnitude: 0.68499

Collected Steps per Second: 23,140.78011
Overall Steps per Second: 10,876.96120

Timestep Collection Time: 2.16086
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59724

Cumulative Model Updates: 84,376
Cumulative Timesteps: 703,727,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 703727454...
Checkpoint 703727454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,852.54327
Policy Entropy: 3.65100
Value Function Loss: 0.08064

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.48137
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,461.93129
Overall Steps per Second: 10,701.45112

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.44784
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.67525

Cumulative Model Updates: 84,382
Cumulative Timesteps: 703,777,486

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,992.73156
Policy Entropy: 3.64855
Value Function Loss: 0.08245

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.42301
Value Function Update Magnitude: 0.61458

Collected Steps per Second: 22,342.36393
Overall Steps per Second: 10,508.94902

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.76185

Cumulative Model Updates: 84,388
Cumulative Timesteps: 703,827,528

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 703827528...
Checkpoint 703827528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,642.62064
Policy Entropy: 3.64927
Value Function Loss: 0.08371

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.42184
Value Function Update Magnitude: 0.64721

Collected Steps per Second: 22,344.59484
Overall Steps per Second: 10,601.96099

Timestep Collection Time: 2.23857
Timestep Consumption Time: 2.47942
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.71800

Cumulative Model Updates: 84,394
Cumulative Timesteps: 703,877,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,947.00873
Policy Entropy: 3.66061
Value Function Loss: 0.08244

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.41828
Value Function Update Magnitude: 0.69237

Collected Steps per Second: 22,629.90836
Overall Steps per Second: 10,667.18573

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.47791
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.68746

Cumulative Model Updates: 84,400
Cumulative Timesteps: 703,927,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 703927550...
Checkpoint 703927550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,352.12688
Policy Entropy: 3.66342
Value Function Loss: 0.08047

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.40687
Value Function Update Magnitude: 0.69084

Collected Steps per Second: 22,369.67484
Overall Steps per Second: 10,576.11963

Timestep Collection Time: 2.23606
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.72952

Cumulative Model Updates: 84,406
Cumulative Timesteps: 703,977,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,664.30060
Policy Entropy: 3.66864
Value Function Loss: 0.07710

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.71712

Collected Steps per Second: 22,899.61707
Overall Steps per Second: 10,785.88773

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.45244
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.63606

Cumulative Model Updates: 84,412
Cumulative Timesteps: 704,027,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 704027574...
Checkpoint 704027574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,151.91707
Policy Entropy: 3.66723
Value Function Loss: 0.07384

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.71493

Collected Steps per Second: 22,609.11971
Overall Steps per Second: 10,515.41642

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.54465
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.75721

Cumulative Model Updates: 84,418
Cumulative Timesteps: 704,077,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,713.55183
Policy Entropy: 3.66078
Value Function Loss: 0.07587

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.48213
Value Function Update Magnitude: 0.71947

Collected Steps per Second: 22,937.29686
Overall Steps per Second: 10,752.19155

Timestep Collection Time: 2.18012
Timestep Consumption Time: 2.47066
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.65077

Cumulative Model Updates: 84,424
Cumulative Timesteps: 704,127,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 704127604...
Checkpoint 704127604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,808.13265
Policy Entropy: 3.66809
Value Function Loss: 0.07355

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.46509
Value Function Update Magnitude: 0.71987

Collected Steps per Second: 22,296.64341
Overall Steps per Second: 10,593.02475

Timestep Collection Time: 2.24375
Timestep Consumption Time: 2.47898
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.72273

Cumulative Model Updates: 84,430
Cumulative Timesteps: 704,177,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,655.77095
Policy Entropy: 3.66834
Value Function Loss: 0.07406

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.59845
Value Function Update Magnitude: 0.77719

Collected Steps per Second: 23,185.46929
Overall Steps per Second: 10,716.14628

Timestep Collection Time: 2.15695
Timestep Consumption Time: 2.50984
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.66679

Cumulative Model Updates: 84,436
Cumulative Timesteps: 704,227,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 704227642...
Checkpoint 704227642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,989.76209
Policy Entropy: 3.67417
Value Function Loss: 0.07250

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.71901
Value Function Update Magnitude: 0.75533

Collected Steps per Second: 22,809.46709
Overall Steps per Second: 10,626.74629

Timestep Collection Time: 2.19339
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.70793

Cumulative Model Updates: 84,442
Cumulative Timesteps: 704,277,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.01706
Policy Entropy: 3.67115
Value Function Loss: 0.07257

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.70859
Value Function Update Magnitude: 0.73263

Collected Steps per Second: 22,106.87059
Overall Steps per Second: 10,822.70867

Timestep Collection Time: 2.26292
Timestep Consumption Time: 2.35940
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.62232

Cumulative Model Updates: 84,448
Cumulative Timesteps: 704,327,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 704327698...
Checkpoint 704327698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,325.15204
Policy Entropy: 3.66769
Value Function Loss: 0.07470

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.59304
Value Function Update Magnitude: 0.74227

Collected Steps per Second: 21,580.35675
Overall Steps per Second: 10,709.77535

Timestep Collection Time: 2.31711
Timestep Consumption Time: 2.35190
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.66901

Cumulative Model Updates: 84,454
Cumulative Timesteps: 704,377,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,852.65873
Policy Entropy: 3.67810
Value Function Loss: 0.07199

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.50410
Value Function Update Magnitude: 0.81685

Collected Steps per Second: 21,811.04984
Overall Steps per Second: 10,609.53215

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.42081
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.71369

Cumulative Model Updates: 84,460
Cumulative Timesteps: 704,427,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 704427712...
Checkpoint 704427712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,962.67284
Policy Entropy: 3.67712
Value Function Loss: 0.07141

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.45145
Value Function Update Magnitude: 0.86303

Collected Steps per Second: 21,734.62718
Overall Steps per Second: 10,562.76920

Timestep Collection Time: 2.30075
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.73418

Cumulative Model Updates: 84,466
Cumulative Timesteps: 704,477,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,701.11583
Policy Entropy: 3.67567
Value Function Loss: 0.06928

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.47705
Value Function Update Magnitude: 0.85924

Collected Steps per Second: 22,034.71748
Overall Steps per Second: 10,749.11982

Timestep Collection Time: 2.26996
Timestep Consumption Time: 2.38325
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.65322

Cumulative Model Updates: 84,472
Cumulative Timesteps: 704,527,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 704527736...
Checkpoint 704527736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,515.60722
Policy Entropy: 3.68045
Value Function Loss: 0.06990

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.50165
Value Function Update Magnitude: 0.84213

Collected Steps per Second: 21,998.29160
Overall Steps per Second: 10,761.52202

Timestep Collection Time: 2.27418
Timestep Consumption Time: 2.37461
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.64878

Cumulative Model Updates: 84,478
Cumulative Timesteps: 704,577,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.41424
Policy Entropy: 3.66951
Value Function Loss: 0.07290

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.52199
Value Function Update Magnitude: 0.70322

Collected Steps per Second: 22,593.92030
Overall Steps per Second: 10,766.14780

Timestep Collection Time: 2.21343
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.64512

Cumulative Model Updates: 84,484
Cumulative Timesteps: 704,627,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 704627774...
Checkpoint 704627774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,878.03164
Policy Entropy: 3.67829
Value Function Loss: 0.07573

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.52619
Value Function Update Magnitude: 0.67986

Collected Steps per Second: 22,723.08975
Overall Steps per Second: 10,757.27967

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.44830
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.64932

Cumulative Model Updates: 84,490
Cumulative Timesteps: 704,677,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,996.50360
Policy Entropy: 3.66529
Value Function Loss: 0.07438

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.71316

Collected Steps per Second: 23,122.72760
Overall Steps per Second: 10,941.43502

Timestep Collection Time: 2.16324
Timestep Consumption Time: 2.40837
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.57161

Cumulative Model Updates: 84,496
Cumulative Timesteps: 704,727,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 704727808...
Checkpoint 704727808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.14881
Policy Entropy: 3.66828
Value Function Loss: 0.07545

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.64978
Value Function Update Magnitude: 0.73282

Collected Steps per Second: 22,748.38983
Overall Steps per Second: 10,724.21117

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.46567
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.66477

Cumulative Model Updates: 84,502
Cumulative Timesteps: 704,777,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,695.30675
Policy Entropy: 3.66497
Value Function Loss: 0.07549

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.62754
Value Function Update Magnitude: 0.80524

Collected Steps per Second: 23,082.06264
Overall Steps per Second: 10,807.51122

Timestep Collection Time: 2.16705
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.62826

Cumulative Model Updates: 84,508
Cumulative Timesteps: 704,827,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 704827854...
Checkpoint 704827854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.41016
Policy Entropy: 3.67870
Value Function Loss: 0.07434

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.87082

Collected Steps per Second: 22,667.02585
Overall Steps per Second: 10,681.89066

Timestep Collection Time: 2.20611
Timestep Consumption Time: 2.47527
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68138

Cumulative Model Updates: 84,514
Cumulative Timesteps: 704,877,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,196.13736
Policy Entropy: 3.68267
Value Function Loss: 0.07122

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.51820
Value Function Update Magnitude: 0.87058

Collected Steps per Second: 22,814.64413
Overall Steps per Second: 10,816.19694

Timestep Collection Time: 2.19166
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.62288

Cumulative Model Updates: 84,520
Cumulative Timesteps: 704,927,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 704927862...
Checkpoint 704927862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.05104
Policy Entropy: 3.68948
Value Function Loss: 0.07190

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.53223
Value Function Update Magnitude: 0.88267

Collected Steps per Second: 21,844.72273
Overall Steps per Second: 10,586.45678

Timestep Collection Time: 2.28998
Timestep Consumption Time: 2.43530
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.72528

Cumulative Model Updates: 84,526
Cumulative Timesteps: 704,977,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.17934
Policy Entropy: 3.67137
Value Function Loss: 0.07552

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.48567
Value Function Update Magnitude: 0.88972

Collected Steps per Second: 22,742.25709
Overall Steps per Second: 10,594.22439

Timestep Collection Time: 2.19987
Timestep Consumption Time: 2.52251
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72238

Cumulative Model Updates: 84,532
Cumulative Timesteps: 705,027,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 705027916...
Checkpoint 705027916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,613.51341
Policy Entropy: 3.66533
Value Function Loss: 0.07831

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.49018
Value Function Update Magnitude: 0.88796

Collected Steps per Second: 22,673.21030
Overall Steps per Second: 10,648.46798

Timestep Collection Time: 2.20595
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.69701

Cumulative Model Updates: 84,538
Cumulative Timesteps: 705,077,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,135.95073
Policy Entropy: 3.65120
Value Function Loss: 0.08059

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.49106
Value Function Update Magnitude: 0.80859

Collected Steps per Second: 23,143.86293
Overall Steps per Second: 10,811.95868

Timestep Collection Time: 2.16075
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62525

Cumulative Model Updates: 84,544
Cumulative Timesteps: 705,127,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 705127940...
Checkpoint 705127940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,713.70376
Policy Entropy: 3.66162
Value Function Loss: 0.08054

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.51085
Value Function Update Magnitude: 0.77496

Collected Steps per Second: 22,621.10971
Overall Steps per Second: 10,666.89689

Timestep Collection Time: 2.21094
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.68871

Cumulative Model Updates: 84,550
Cumulative Timesteps: 705,177,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,656.10044
Policy Entropy: 3.65071
Value Function Loss: 0.08200

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.61851
Value Function Update Magnitude: 0.79234

Collected Steps per Second: 22,345.25850
Overall Steps per Second: 10,618.47286

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.71009

Cumulative Model Updates: 84,556
Cumulative Timesteps: 705,227,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 705227968...
Checkpoint 705227968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,285.19071
Policy Entropy: 3.65017
Value Function Loss: 0.08127

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.15911
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.73504

Collected Steps per Second: 22,844.04945
Overall Steps per Second: 10,827.13873

Timestep Collection Time: 2.18980
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62024

Cumulative Model Updates: 84,562
Cumulative Timesteps: 705,277,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,664.08328
Policy Entropy: 3.64128
Value Function Loss: 0.08030

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14638
Policy Update Magnitude: 0.41592
Value Function Update Magnitude: 0.66245

Collected Steps per Second: 23,301.80360
Overall Steps per Second: 10,904.27678

Timestep Collection Time: 2.14619
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.58627

Cumulative Model Updates: 84,568
Cumulative Timesteps: 705,328,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 705328002...
Checkpoint 705328002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,062.46766
Policy Entropy: 3.65452
Value Function Loss: 0.07973

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.42572
Value Function Update Magnitude: 0.76710

Collected Steps per Second: 22,679.66367
Overall Steps per Second: 10,817.89930

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.41754
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.62234

Cumulative Model Updates: 84,574
Cumulative Timesteps: 705,378,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,306.55407
Policy Entropy: 3.64805
Value Function Loss: 0.07956

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.46479
Value Function Update Magnitude: 0.82055

Collected Steps per Second: 22,758.00054
Overall Steps per Second: 10,773.13154

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.64378

Cumulative Model Updates: 84,580
Cumulative Timesteps: 705,428,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 705428034...
Checkpoint 705428034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,899.86027
Policy Entropy: 3.66298
Value Function Loss: 0.08176

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.76067

Collected Steps per Second: 22,426.56973
Overall Steps per Second: 10,735.04401

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.65895

Cumulative Model Updates: 84,586
Cumulative Timesteps: 705,478,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,936.43136
Policy Entropy: 3.64885
Value Function Loss: 0.08289

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.62412
Value Function Update Magnitude: 0.76247

Collected Steps per Second: 22,582.49123
Overall Steps per Second: 10,647.52320

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69856

Cumulative Model Updates: 84,592
Cumulative Timesteps: 705,528,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 705528076...
Checkpoint 705528076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,516.91533
Policy Entropy: 3.67128
Value Function Loss: 0.07897

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.86337

Collected Steps per Second: 22,340.03165
Overall Steps per Second: 10,583.86274

Timestep Collection Time: 2.23849
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.72493

Cumulative Model Updates: 84,598
Cumulative Timesteps: 705,578,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,863.83774
Policy Entropy: 3.67430
Value Function Loss: 0.07476

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.93279

Collected Steps per Second: 23,088.60090
Overall Steps per Second: 10,714.45882

Timestep Collection Time: 2.16670
Timestep Consumption Time: 2.50232
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.66902

Cumulative Model Updates: 84,604
Cumulative Timesteps: 705,628,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 705628110...
Checkpoint 705628110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,202.05952
Policy Entropy: 3.69629
Value Function Loss: 0.07403

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.94751

Collected Steps per Second: 22,617.35551
Overall Steps per Second: 10,610.26524

Timestep Collection Time: 2.21166
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.71449

Cumulative Model Updates: 84,610
Cumulative Timesteps: 705,678,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,230.17787
Policy Entropy: 3.69991
Value Function Loss: 0.07471

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.60093
Value Function Update Magnitude: 0.95313

Collected Steps per Second: 22,830.34165
Overall Steps per Second: 10,713.37861

Timestep Collection Time: 2.19103
Timestep Consumption Time: 2.47808
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.66912

Cumulative Model Updates: 84,616
Cumulative Timesteps: 705,728,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 705728154...
Checkpoint 705728154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.14679
Policy Entropy: 3.70647
Value Function Loss: 0.07119

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.65936
Value Function Update Magnitude: 0.96861

Collected Steps per Second: 22,784.92821
Overall Steps per Second: 10,801.58450

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.63117

Cumulative Model Updates: 84,622
Cumulative Timesteps: 705,778,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,412.29220
Policy Entropy: 3.70186
Value Function Loss: 0.07015

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.61921
Value Function Update Magnitude: 0.93860

Collected Steps per Second: 22,707.67324
Overall Steps per Second: 10,591.73118

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.72199

Cumulative Model Updates: 84,628
Cumulative Timesteps: 705,828,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 705828192...
Checkpoint 705828192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,410.23401
Policy Entropy: 3.69853
Value Function Loss: 0.07045

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.59872
Value Function Update Magnitude: 0.85756

Collected Steps per Second: 22,556.60733
Overall Steps per Second: 10,552.31133

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.52226
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.73944

Cumulative Model Updates: 84,634
Cumulative Timesteps: 705,878,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,048.10951
Policy Entropy: 3.69623
Value Function Loss: 0.07210

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.69084
Value Function Update Magnitude: 0.78427

Collected Steps per Second: 23,071.90098
Overall Steps per Second: 10,930.91229

Timestep Collection Time: 2.16827
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.57656

Cumulative Model Updates: 84,640
Cumulative Timesteps: 705,928,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 705928230...
Checkpoint 705928230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.30931
Policy Entropy: 3.70927
Value Function Loss: 0.07251

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.64906
Value Function Update Magnitude: 0.81538

Collected Steps per Second: 22,484.75570
Overall Steps per Second: 10,652.17259

Timestep Collection Time: 2.22400
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.69444

Cumulative Model Updates: 84,646
Cumulative Timesteps: 705,978,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,876.47733
Policy Entropy: 3.71179
Value Function Loss: 0.07107

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.67773
Value Function Update Magnitude: 0.79075

Collected Steps per Second: 21,988.85753
Overall Steps per Second: 10,433.67583

Timestep Collection Time: 2.27497
Timestep Consumption Time: 2.51950
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.79448

Cumulative Model Updates: 84,652
Cumulative Timesteps: 706,028,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 706028260...
Checkpoint 706028260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,525.84411
Policy Entropy: 3.72327
Value Function Loss: 0.07214

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.63143
Value Function Update Magnitude: 0.87401

Collected Steps per Second: 22,595.88262
Overall Steps per Second: 10,625.60880

Timestep Collection Time: 2.21341
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.70693

Cumulative Model Updates: 84,658
Cumulative Timesteps: 706,078,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,294.68395
Policy Entropy: 3.72141
Value Function Loss: 0.07439

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.67120
Value Function Update Magnitude: 0.83043

Collected Steps per Second: 23,191.62467
Overall Steps per Second: 10,845.51603

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.61057

Cumulative Model Updates: 84,664
Cumulative Timesteps: 706,128,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 706128278...
Checkpoint 706128278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.67107
Policy Entropy: 3.72395
Value Function Loss: 0.07207

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.62305
Value Function Update Magnitude: 0.83437

Collected Steps per Second: 22,702.90157
Overall Steps per Second: 10,738.43288

Timestep Collection Time: 2.20333
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.65822

Cumulative Model Updates: 84,670
Cumulative Timesteps: 706,178,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.48141
Policy Entropy: 3.73837
Value Function Loss: 0.06966

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.66528
Value Function Update Magnitude: 0.89367

Collected Steps per Second: 23,335.29995
Overall Steps per Second: 10,875.33344

Timestep Collection Time: 2.14328
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.59885

Cumulative Model Updates: 84,676
Cumulative Timesteps: 706,228,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 706228314...
Checkpoint 706228314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.55092
Policy Entropy: 3.75707
Value Function Loss: 0.06368

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.62406
Value Function Update Magnitude: 0.88421

Collected Steps per Second: 22,806.86617
Overall Steps per Second: 10,719.07592

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.66570

Cumulative Model Updates: 84,682
Cumulative Timesteps: 706,278,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,881.23623
Policy Entropy: 3.75762
Value Function Loss: 0.06130

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.89065

Collected Steps per Second: 22,907.19934
Overall Steps per Second: 10,830.71713

Timestep Collection Time: 2.18464
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.62056

Cumulative Model Updates: 84,688
Cumulative Timesteps: 706,328,370

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 706328370...
Checkpoint 706328370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,205.49090
Policy Entropy: 3.75175
Value Function Loss: 0.06177

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.84420

Collected Steps per Second: 22,667.29026
Overall Steps per Second: 10,656.52343

Timestep Collection Time: 2.20591
Timestep Consumption Time: 2.48624
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.69215

Cumulative Model Updates: 84,694
Cumulative Timesteps: 706,378,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.64115
Policy Entropy: 3.75073
Value Function Loss: 0.06081

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.57557
Value Function Update Magnitude: 0.82217

Collected Steps per Second: 22,654.24986
Overall Steps per Second: 10,656.99346

Timestep Collection Time: 2.20762
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69288

Cumulative Model Updates: 84,700
Cumulative Timesteps: 706,428,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 706428384...
Checkpoint 706428384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,131.69733
Policy Entropy: 3.74723
Value Function Loss: 0.06146

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.82259

Collected Steps per Second: 21,465.43756
Overall Steps per Second: 10,446.64111

Timestep Collection Time: 2.33007
Timestep Consumption Time: 2.45769
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.78776

Cumulative Model Updates: 84,706
Cumulative Timesteps: 706,478,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,562.82130
Policy Entropy: 3.75240
Value Function Loss: 0.05996

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.66292
Value Function Update Magnitude: 0.80128

Collected Steps per Second: 22,500.06694
Overall Steps per Second: 10,605.11219

Timestep Collection Time: 2.22230
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.71490

Cumulative Model Updates: 84,712
Cumulative Timesteps: 706,528,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 706528402...
Checkpoint 706528402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.38309
Policy Entropy: 3.74844
Value Function Loss: 0.05880

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.68885
Value Function Update Magnitude: 0.79787

Collected Steps per Second: 21,967.34909
Overall Steps per Second: 10,510.77487

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.75912

Cumulative Model Updates: 84,718
Cumulative Timesteps: 706,578,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,997.75718
Policy Entropy: 3.75397
Value Function Loss: 0.05873

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.61450
Value Function Update Magnitude: 0.73259

Collected Steps per Second: 22,532.99247
Overall Steps per Second: 10,552.19416

Timestep Collection Time: 2.22021
Timestep Consumption Time: 2.52079
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.74100

Cumulative Model Updates: 84,724
Cumulative Timesteps: 706,628,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 706628452...
Checkpoint 706628452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.18649
Policy Entropy: 3.75134
Value Function Loss: 0.05829

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.60994
Value Function Update Magnitude: 0.80125

Collected Steps per Second: 22,824.46865
Overall Steps per Second: 10,603.77604

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.71530

Cumulative Model Updates: 84,730
Cumulative Timesteps: 706,678,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,440.94799
Policy Entropy: 3.74543
Value Function Loss: 0.05824

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.73511
Value Function Update Magnitude: 0.83443

Collected Steps per Second: 22,916.91815
Overall Steps per Second: 10,798.91390

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.63232

Cumulative Model Updates: 84,736
Cumulative Timesteps: 706,728,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 706728476...
Checkpoint 706728476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.05748
Policy Entropy: 3.74071
Value Function Loss: 0.06122

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.69185
Value Function Update Magnitude: 0.79659

Collected Steps per Second: 22,617.03761
Overall Steps per Second: 10,665.70223

Timestep Collection Time: 2.21143
Timestep Consumption Time: 2.47799
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.68942

Cumulative Model Updates: 84,742
Cumulative Timesteps: 706,778,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.32404
Policy Entropy: 3.73646
Value Function Loss: 0.06303

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.56854
Value Function Update Magnitude: 0.72014

Collected Steps per Second: 22,902.14963
Overall Steps per Second: 10,858.63666

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.42220
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60610

Cumulative Model Updates: 84,748
Cumulative Timesteps: 706,828,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 706828508...
Checkpoint 706828508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.34658
Policy Entropy: 3.74412
Value Function Loss: 0.06066

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.72532

Collected Steps per Second: 23,028.40835
Overall Steps per Second: 10,669.18153

Timestep Collection Time: 2.17201
Timestep Consumption Time: 2.51607
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.68808

Cumulative Model Updates: 84,754
Cumulative Timesteps: 706,878,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,832.04091
Policy Entropy: 3.73561
Value Function Loss: 0.05825

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.58198
Value Function Update Magnitude: 0.78768

Collected Steps per Second: 23,069.68958
Overall Steps per Second: 10,856.62430

Timestep Collection Time: 2.16769
Timestep Consumption Time: 2.43853
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.60622

Cumulative Model Updates: 84,760
Cumulative Timesteps: 706,928,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 706928534...
Checkpoint 706928534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,806.70183
Policy Entropy: 3.73197
Value Function Loss: 0.05868

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.80891

Collected Steps per Second: 22,462.73348
Overall Steps per Second: 10,724.42691

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.43722
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.66393

Cumulative Model Updates: 84,766
Cumulative Timesteps: 706,978,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,643.51900
Policy Entropy: 3.72576
Value Function Loss: 0.06049

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.60765
Value Function Update Magnitude: 0.80420

Collected Steps per Second: 22,546.25619
Overall Steps per Second: 10,782.22574

Timestep Collection Time: 2.21926
Timestep Consumption Time: 2.42134
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64060

Cumulative Model Updates: 84,772
Cumulative Timesteps: 707,028,588

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 707028588...
Checkpoint 707028588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,034.49444
Policy Entropy: 3.72020
Value Function Loss: 0.06357

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.63689
Value Function Update Magnitude: 0.79267

Collected Steps per Second: 22,352.94070
Overall Steps per Second: 10,664.68541

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.45172
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.68875

Cumulative Model Updates: 84,778
Cumulative Timesteps: 707,078,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.35737
Policy Entropy: 3.71706
Value Function Loss: 0.06502

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.60917
Value Function Update Magnitude: 0.77581

Collected Steps per Second: 22,648.80401
Overall Steps per Second: 10,712.33840

Timestep Collection Time: 2.20965
Timestep Consumption Time: 2.46216
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.67181

Cumulative Model Updates: 84,784
Cumulative Timesteps: 707,128,638

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 707128638...
Checkpoint 707128638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,990.32804
Policy Entropy: 3.70060
Value Function Loss: 0.06534

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.64853
Value Function Update Magnitude: 0.80217

Collected Steps per Second: 23,037.73262
Overall Steps per Second: 10,823.26188

Timestep Collection Time: 2.17174
Timestep Consumption Time: 2.45089
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.62264

Cumulative Model Updates: 84,790
Cumulative Timesteps: 707,178,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,383.77976
Policy Entropy: 3.69149
Value Function Loss: 0.06649

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.57499
Value Function Update Magnitude: 0.82852

Collected Steps per Second: 22,143.18754
Overall Steps per Second: 10,513.78368

Timestep Collection Time: 2.25921
Timestep Consumption Time: 2.49893
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.75813

Cumulative Model Updates: 84,796
Cumulative Timesteps: 707,228,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 707228696...
Checkpoint 707228696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,057.70559
Policy Entropy: 3.69360
Value Function Loss: 0.06427

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.52593
Value Function Update Magnitude: 0.85232

Collected Steps per Second: 22,510.57265
Overall Steps per Second: 10,643.13280

Timestep Collection Time: 2.22118
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.69786

Cumulative Model Updates: 84,802
Cumulative Timesteps: 707,278,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,607.25423
Policy Entropy: 3.70021
Value Function Loss: 0.06404

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.50741
Value Function Update Magnitude: 0.83140

Collected Steps per Second: 23,028.81609
Overall Steps per Second: 10,861.74616

Timestep Collection Time: 2.17171
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60442

Cumulative Model Updates: 84,808
Cumulative Timesteps: 707,328,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 707328708...
Checkpoint 707328708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.46210
Policy Entropy: 3.69493
Value Function Loss: 0.06617

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.61137
Value Function Update Magnitude: 0.76180

Collected Steps per Second: 22,925.07124
Overall Steps per Second: 10,735.60796

Timestep Collection Time: 2.18294
Timestep Consumption Time: 2.47856
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.66150

Cumulative Model Updates: 84,814
Cumulative Timesteps: 707,378,752

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,208.35797
Policy Entropy: 3.68215
Value Function Loss: 0.07111

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.66544
Value Function Update Magnitude: 0.67665

Collected Steps per Second: 22,939.55522
Overall Steps per Second: 10,823.65350

Timestep Collection Time: 2.18034
Timestep Consumption Time: 2.44065
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62099

Cumulative Model Updates: 84,820
Cumulative Timesteps: 707,428,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 707428768...
Checkpoint 707428768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,467.48646
Policy Entropy: 3.66950
Value Function Loss: 0.07386

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.59935
Value Function Update Magnitude: 0.69311

Collected Steps per Second: 22,587.39448
Overall Steps per Second: 10,774.41559

Timestep Collection Time: 2.21566
Timestep Consumption Time: 2.42923
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.64489

Cumulative Model Updates: 84,826
Cumulative Timesteps: 707,478,814

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,322.95845
Policy Entropy: 3.67514
Value Function Loss: 0.07422

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.69239

Collected Steps per Second: 22,678.12181
Overall Steps per Second: 10,806.05582

Timestep Collection Time: 2.20591
Timestep Consumption Time: 2.42353
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.62944

Cumulative Model Updates: 84,832
Cumulative Timesteps: 707,528,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 707528840...
Checkpoint 707528840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,179.89329
Policy Entropy: 3.67942
Value Function Loss: 0.07343

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.60188
Value Function Update Magnitude: 0.65217

Collected Steps per Second: 22,115.73708
Overall Steps per Second: 10,643.52116

Timestep Collection Time: 2.26101
Timestep Consumption Time: 2.43705
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.69807

Cumulative Model Updates: 84,838
Cumulative Timesteps: 707,578,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.47086
Policy Entropy: 3.67566
Value Function Loss: 0.07248

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.61217
Value Function Update Magnitude: 0.74827

Collected Steps per Second: 22,575.29647
Overall Steps per Second: 10,670.34063

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.68682

Cumulative Model Updates: 84,844
Cumulative Timesteps: 707,628,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 707628854...
Checkpoint 707628854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,121.27182
Policy Entropy: 3.69209
Value Function Loss: 0.07185

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.78915

Collected Steps per Second: 22,216.10955
Overall Steps per Second: 10,519.46907

Timestep Collection Time: 2.25179
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.75556

Cumulative Model Updates: 84,850
Cumulative Timesteps: 707,678,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,481.96233
Policy Entropy: 3.68297
Value Function Loss: 0.07227

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.54687
Value Function Update Magnitude: 0.72605

Collected Steps per Second: 23,070.69981
Overall Steps per Second: 10,786.80911

Timestep Collection Time: 2.16742
Timestep Consumption Time: 2.46824
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.63566

Cumulative Model Updates: 84,856
Cumulative Timesteps: 707,728,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 707728884...
Checkpoint 707728884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,747.64027
Policy Entropy: 3.68033
Value Function Loss: 0.07417

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.71165

Collected Steps per Second: 22,812.55607
Overall Steps per Second: 10,682.39334

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.49032
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.68341

Cumulative Model Updates: 84,862
Cumulative Timesteps: 707,778,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,232.61775
Policy Entropy: 3.65916
Value Function Loss: 0.07343

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.50351
Value Function Update Magnitude: 0.73145

Collected Steps per Second: 22,798.50744
Overall Steps per Second: 10,706.87928

Timestep Collection Time: 2.19339
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.67046

Cumulative Model Updates: 84,868
Cumulative Timesteps: 707,828,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 707828920...
Checkpoint 707828920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,587.83804
Policy Entropy: 3.65853
Value Function Loss: 0.07337

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.58068
Value Function Update Magnitude: 0.81028

Collected Steps per Second: 22,890.03754
Overall Steps per Second: 10,821.62307

Timestep Collection Time: 2.18436
Timestep Consumption Time: 2.43602
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.62038

Cumulative Model Updates: 84,874
Cumulative Timesteps: 707,878,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,568.11255
Policy Entropy: 3.66411
Value Function Loss: 0.07264

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11422
Policy Update Magnitude: 0.58344
Value Function Update Magnitude: 0.83550

Collected Steps per Second: 23,019.65035
Overall Steps per Second: 10,923.99565

Timestep Collection Time: 2.17214
Timestep Consumption Time: 2.40512
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.57726

Cumulative Model Updates: 84,880
Cumulative Timesteps: 707,928,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 707928922...
Checkpoint 707928922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,081.37721
Policy Entropy: 3.67215
Value Function Loss: 0.07265

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.61149
Value Function Update Magnitude: 0.80777

Collected Steps per Second: 22,666.99542
Overall Steps per Second: 10,678.05568

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.47764
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.68437

Cumulative Model Updates: 84,886
Cumulative Timesteps: 707,978,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,745.88306
Policy Entropy: 3.66526
Value Function Loss: 0.07250

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.70291

Collected Steps per Second: 22,311.67553
Overall Steps per Second: 10,548.76105

Timestep Collection Time: 2.24152
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74103

Cumulative Model Updates: 84,892
Cumulative Timesteps: 708,028,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 708028954...
Checkpoint 708028954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.30905
Policy Entropy: 3.66692
Value Function Loss: 0.07449

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.56501
Value Function Update Magnitude: 0.66597

Collected Steps per Second: 22,182.93003
Overall Steps per Second: 10,530.83571

Timestep Collection Time: 2.25417
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.74834

Cumulative Model Updates: 84,898
Cumulative Timesteps: 708,078,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,556.50970
Policy Entropy: 3.66886
Value Function Loss: 0.07404

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.59940
Value Function Update Magnitude: 0.68246

Collected Steps per Second: 22,812.57167
Overall Steps per Second: 10,701.23094

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.67516

Cumulative Model Updates: 84,904
Cumulative Timesteps: 708,128,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 708128988...
Checkpoint 708128988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,359.30056
Policy Entropy: 3.66789
Value Function Loss: 0.07668

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.61843
Value Function Update Magnitude: 0.70417

Collected Steps per Second: 22,280.93278
Overall Steps per Second: 10,596.98667

Timestep Collection Time: 2.24533
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.72096

Cumulative Model Updates: 84,910
Cumulative Timesteps: 708,179,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,075.79064
Policy Entropy: 3.65708
Value Function Loss: 0.07641

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.67334
Value Function Update Magnitude: 0.81868

Collected Steps per Second: 22,784.61716
Overall Steps per Second: 10,785.35930

Timestep Collection Time: 2.19622
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.63962

Cumulative Model Updates: 84,916
Cumulative Timesteps: 708,229,056

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 708229056...
Checkpoint 708229056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,768.68966
Policy Entropy: 3.66561
Value Function Loss: 0.07628

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.59898
Value Function Update Magnitude: 0.84072

Collected Steps per Second: 23,114.34146
Overall Steps per Second: 10,633.62969

Timestep Collection Time: 2.16420
Timestep Consumption Time: 2.54012
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.70432

Cumulative Model Updates: 84,922
Cumulative Timesteps: 708,279,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.12866
Policy Entropy: 3.67577
Value Function Loss: 0.07098

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.49721
Value Function Update Magnitude: 0.80838

Collected Steps per Second: 23,140.39158
Overall Steps per Second: 10,890.39671

Timestep Collection Time: 2.16185
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.59359

Cumulative Model Updates: 84,928
Cumulative Timesteps: 708,329,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 708329106...
Checkpoint 708329106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,056.93089
Policy Entropy: 3.69041
Value Function Loss: 0.06976

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.55270
Value Function Update Magnitude: 0.75396

Collected Steps per Second: 21,764.90750
Overall Steps per Second: 10,561.64112

Timestep Collection Time: 2.29847
Timestep Consumption Time: 2.43810
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73657

Cumulative Model Updates: 84,934
Cumulative Timesteps: 708,379,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,418.46733
Policy Entropy: 3.68715
Value Function Loss: 0.07053

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.56044
Value Function Update Magnitude: 0.76524

Collected Steps per Second: 22,798.75898
Overall Steps per Second: 10,602.06841

Timestep Collection Time: 2.19337
Timestep Consumption Time: 2.52326
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.71663

Cumulative Model Updates: 84,940
Cumulative Timesteps: 708,429,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 708429138...
Checkpoint 708429138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,982.50910
Policy Entropy: 3.66243
Value Function Loss: 0.07387

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.50105
Value Function Update Magnitude: 0.81429

Collected Steps per Second: 22,913.41202
Overall Steps per Second: 10,726.84429

Timestep Collection Time: 2.18265
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.66232

Cumulative Model Updates: 84,946
Cumulative Timesteps: 708,479,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,857.78520
Policy Entropy: 3.67267
Value Function Loss: 0.07385

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.49092
Value Function Update Magnitude: 0.84373

Collected Steps per Second: 22,782.06183
Overall Steps per Second: 10,736.60560

Timestep Collection Time: 2.19524
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.65808

Cumulative Model Updates: 84,952
Cumulative Timesteps: 708,529,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 708529162...
Checkpoint 708529162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,802.27909
Policy Entropy: 3.65419
Value Function Loss: 0.07045

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.83572

Collected Steps per Second: 22,246.61844
Overall Steps per Second: 10,633.09162

Timestep Collection Time: 2.24807
Timestep Consumption Time: 2.45536
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.70343

Cumulative Model Updates: 84,958
Cumulative Timesteps: 708,579,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,202.78681
Policy Entropy: 3.68030
Value Function Loss: 0.06969

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.77218

Collected Steps per Second: 22,215.80728
Overall Steps per Second: 10,655.39888

Timestep Collection Time: 2.25065
Timestep Consumption Time: 2.44181
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.69246

Cumulative Model Updates: 84,964
Cumulative Timesteps: 708,629,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 708629174...
Checkpoint 708629174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,325.72801
Policy Entropy: 3.66560
Value Function Loss: 0.06986

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.71845

Collected Steps per Second: 22,736.62491
Overall Steps per Second: 10,799.87535

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63061

Cumulative Model Updates: 84,970
Cumulative Timesteps: 708,679,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,896.48654
Policy Entropy: 3.67312
Value Function Loss: 0.07052

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.62863
Value Function Update Magnitude: 0.74820

Collected Steps per Second: 22,768.82222
Overall Steps per Second: 10,561.38663

Timestep Collection Time: 2.19722
Timestep Consumption Time: 2.53966
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.73688

Cumulative Model Updates: 84,976
Cumulative Timesteps: 708,729,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 708729212...
Checkpoint 708729212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,250.13401
Policy Entropy: 3.66363
Value Function Loss: 0.07042

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.70262
Value Function Update Magnitude: 0.76134

Collected Steps per Second: 22,852.84459
Overall Steps per Second: 10,618.76670

Timestep Collection Time: 2.18879
Timestep Consumption Time: 2.52174
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.71053

Cumulative Model Updates: 84,982
Cumulative Timesteps: 708,779,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.59008
Policy Entropy: 3.66135
Value Function Loss: 0.07313

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.62550
Value Function Update Magnitude: 0.72161

Collected Steps per Second: 22,962.80713
Overall Steps per Second: 10,816.36156

Timestep Collection Time: 2.17848
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.62485

Cumulative Model Updates: 84,988
Cumulative Timesteps: 708,829,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 708829256...
Checkpoint 708829256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,311.68710
Policy Entropy: 3.67065
Value Function Loss: 0.07432

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.59168
Value Function Update Magnitude: 0.67134

Collected Steps per Second: 22,757.50969
Overall Steps per Second: 10,709.69655

Timestep Collection Time: 2.19734
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.66923

Cumulative Model Updates: 84,994
Cumulative Timesteps: 708,879,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,796.26376
Policy Entropy: 3.65598
Value Function Loss: 0.07520

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.65291
Value Function Update Magnitude: 0.65359

Collected Steps per Second: 23,137.44921
Overall Steps per Second: 10,965.98899

Timestep Collection Time: 2.16230
Timestep Consumption Time: 2.39999
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.56229

Cumulative Model Updates: 85,000
Cumulative Timesteps: 708,929,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 708929292...
Checkpoint 708929292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,241.21531
Policy Entropy: 3.65175
Value Function Loss: 0.07613

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.67229

Collected Steps per Second: 22,887.10838
Overall Steps per Second: 10,681.17802

Timestep Collection Time: 2.18560
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68319

Cumulative Model Updates: 85,006
Cumulative Timesteps: 708,979,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,130.94819
Policy Entropy: 3.62880
Value Function Loss: 0.07885

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.63123

Collected Steps per Second: 22,297.56321
Overall Steps per Second: 10,556.94671

Timestep Collection Time: 2.24240
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.73622

Cumulative Model Updates: 85,012
Cumulative Timesteps: 709,029,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 709029314...
Checkpoint 709029314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,941.92669
Policy Entropy: 3.63002
Value Function Loss: 0.07886

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.68192
Value Function Update Magnitude: 0.72428

Collected Steps per Second: 22,518.44479
Overall Steps per Second: 10,636.64275

Timestep Collection Time: 2.22147
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.70299

Cumulative Model Updates: 85,018
Cumulative Timesteps: 709,079,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,664.54113
Policy Entropy: 3.62947
Value Function Loss: 0.07341

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.59682
Value Function Update Magnitude: 0.79110

Collected Steps per Second: 22,619.62727
Overall Steps per Second: 10,722.89333

Timestep Collection Time: 2.21109
Timestep Consumption Time: 2.45314
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.66423

Cumulative Model Updates: 85,024
Cumulative Timesteps: 709,129,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 709129352...
Checkpoint 709129352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.55901
Policy Entropy: 3.64223
Value Function Loss: 0.07273

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.79256

Collected Steps per Second: 22,414.99703
Overall Steps per Second: 10,627.75209

Timestep Collection Time: 2.23163
Timestep Consumption Time: 2.47510
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.70673

Cumulative Model Updates: 85,030
Cumulative Timesteps: 709,179,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,289.55185
Policy Entropy: 3.63896
Value Function Loss: 0.07273

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.51082
Value Function Update Magnitude: 0.73440

Collected Steps per Second: 22,661.58463
Overall Steps per Second: 10,621.69442

Timestep Collection Time: 2.20744
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.70961

Cumulative Model Updates: 85,036
Cumulative Timesteps: 709,229,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 709229398...
Checkpoint 709229398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,125.78141
Policy Entropy: 3.62145
Value Function Loss: 0.07672

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.48988
Value Function Update Magnitude: 0.70314

Collected Steps per Second: 22,632.75502
Overall Steps per Second: 10,539.36739

Timestep Collection Time: 2.21034
Timestep Consumption Time: 2.53625
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.74658

Cumulative Model Updates: 85,042
Cumulative Timesteps: 709,279,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,437.33626
Policy Entropy: 3.62106
Value Function Loss: 0.07977

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.52804
Value Function Update Magnitude: 0.67090

Collected Steps per Second: 23,059.37764
Overall Steps per Second: 10,850.23789

Timestep Collection Time: 2.16927
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61022

Cumulative Model Updates: 85,048
Cumulative Timesteps: 709,329,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 709329446...
Checkpoint 709329446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,905.13995
Policy Entropy: 3.62245
Value Function Loss: 0.08361

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.53213
Value Function Update Magnitude: 0.74777

Collected Steps per Second: 22,351.96715
Overall Steps per Second: 10,615.45868

Timestep Collection Time: 2.23766
Timestep Consumption Time: 2.47396
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.71162

Cumulative Model Updates: 85,054
Cumulative Timesteps: 709,379,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,706.69712
Policy Entropy: 3.64673
Value Function Loss: 0.08130

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.51499
Value Function Update Magnitude: 0.70839

Collected Steps per Second: 22,669.28112
Overall Steps per Second: 10,644.01821

Timestep Collection Time: 2.20686
Timestep Consumption Time: 2.49324
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.70010

Cumulative Model Updates: 85,060
Cumulative Timesteps: 709,429,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 709429490...
Checkpoint 709429490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,591.45437
Policy Entropy: 3.64491
Value Function Loss: 0.07989

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.72277

Collected Steps per Second: 22,867.97367
Overall Steps per Second: 10,817.93935

Timestep Collection Time: 2.18699
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.62306

Cumulative Model Updates: 85,066
Cumulative Timesteps: 709,479,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,509.67580
Policy Entropy: 3.65280
Value Function Loss: 0.07810

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.48428
Value Function Update Magnitude: 0.71031

Collected Steps per Second: 23,140.73192
Overall Steps per Second: 10,796.14230

Timestep Collection Time: 2.16087
Timestep Consumption Time: 2.47079
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.63165

Cumulative Model Updates: 85,072
Cumulative Timesteps: 709,529,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 709529506...
Checkpoint 709529506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,909.53394
Policy Entropy: 3.65699
Value Function Loss: 0.07903

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.43909
Value Function Update Magnitude: 0.70470

Collected Steps per Second: 22,669.00702
Overall Steps per Second: 10,808.35444

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.42107
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.62735

Cumulative Model Updates: 85,078
Cumulative Timesteps: 709,579,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,773.42268
Policy Entropy: 3.67901
Value Function Loss: 0.07753

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06857
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.72989

Collected Steps per Second: 22,454.95440
Overall Steps per Second: 10,522.59855

Timestep Collection Time: 2.22748
Timestep Consumption Time: 2.52591
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.75339

Cumulative Model Updates: 85,084
Cumulative Timesteps: 709,629,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 709629538...
Checkpoint 709629538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,273.50598
Policy Entropy: 3.66050
Value Function Loss: 0.07766

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.68887
Value Function Update Magnitude: 0.70233

Collected Steps per Second: 22,280.22672
Overall Steps per Second: 10,717.69296

Timestep Collection Time: 2.24423
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.66537

Cumulative Model Updates: 85,090
Cumulative Timesteps: 709,679,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,540.24601
Policy Entropy: 3.63862
Value Function Loss: 0.07823

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.72990
Value Function Update Magnitude: 0.65282

Collected Steps per Second: 22,425.96975
Overall Steps per Second: 10,748.13765

Timestep Collection Time: 2.23000
Timestep Consumption Time: 2.42290
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.65290

Cumulative Model Updates: 85,096
Cumulative Timesteps: 709,729,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 709729550...
Checkpoint 709729550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.02135
Policy Entropy: 3.63599
Value Function Loss: 0.07845

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.61502
Value Function Update Magnitude: 0.62221

Collected Steps per Second: 22,420.33145
Overall Steps per Second: 10,754.17016

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.41963
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.65010

Cumulative Model Updates: 85,102
Cumulative Timesteps: 709,779,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,632.84865
Policy Entropy: 3.64269
Value Function Loss: 0.07825

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.53474
Value Function Update Magnitude: 0.62840

Collected Steps per Second: 22,583.26943
Overall Steps per Second: 10,522.61553

Timestep Collection Time: 2.21518
Timestep Consumption Time: 2.53896
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.75414

Cumulative Model Updates: 85,108
Cumulative Timesteps: 709,829,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 709829584...
Checkpoint 709829584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,124.66214
Policy Entropy: 3.64341
Value Function Loss: 0.07819

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.50747
Value Function Update Magnitude: 0.62971

Collected Steps per Second: 22,901.36807
Overall Steps per Second: 10,710.90270

Timestep Collection Time: 2.18389
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.66945

Cumulative Model Updates: 85,114
Cumulative Timesteps: 709,879,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,924.81676
Policy Entropy: 3.63843
Value Function Loss: 0.07708

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.51927
Value Function Update Magnitude: 0.62698

Collected Steps per Second: 23,013.06783
Overall Steps per Second: 10,713.78115

Timestep Collection Time: 2.17390
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.66950

Cumulative Model Updates: 85,120
Cumulative Timesteps: 709,929,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 709929626...
Checkpoint 709929626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,890.06843
Policy Entropy: 3.63332
Value Function Loss: 0.07672

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.56236
Value Function Update Magnitude: 0.60943

Collected Steps per Second: 22,793.11236
Overall Steps per Second: 10,861.40336

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.41058
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.60493

Cumulative Model Updates: 85,126
Cumulative Timesteps: 709,979,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,600.48859
Policy Entropy: 3.64994
Value Function Loss: 0.07498

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.56153
Value Function Update Magnitude: 0.59917

Collected Steps per Second: 22,875.81116
Overall Steps per Second: 10,818.33743

Timestep Collection Time: 2.18650
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62345

Cumulative Model Updates: 85,132
Cumulative Timesteps: 710,029,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 710029660...
Checkpoint 710029660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,513.21410
Policy Entropy: 3.65395
Value Function Loss: 0.07545

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.62341
Value Function Update Magnitude: 0.62266

Collected Steps per Second: 22,724.22057
Overall Steps per Second: 10,630.76752

Timestep Collection Time: 2.20038
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.70352

Cumulative Model Updates: 85,138
Cumulative Timesteps: 710,079,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,685.83030
Policy Entropy: 3.66152
Value Function Loss: 0.07371

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.55165
Value Function Update Magnitude: 0.60371

Collected Steps per Second: 22,055.96610
Overall Steps per Second: 10,701.10928

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.40555
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.67260

Cumulative Model Updates: 85,144
Cumulative Timesteps: 710,129,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 710129664...
Checkpoint 710129664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,646.95063
Policy Entropy: 3.64889
Value Function Loss: 0.07414

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.50788
Value Function Update Magnitude: 0.60178

Collected Steps per Second: 21,803.89439
Overall Steps per Second: 10,790.95584

Timestep Collection Time: 2.29445
Timestep Consumption Time: 2.34165
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.63610

Cumulative Model Updates: 85,150
Cumulative Timesteps: 710,179,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,055.30143
Policy Entropy: 3.63663
Value Function Loss: 0.07720

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.60426

Collected Steps per Second: 21,662.00945
Overall Steps per Second: 10,505.66380

Timestep Collection Time: 2.31003
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.76315

Cumulative Model Updates: 85,156
Cumulative Timesteps: 710,229,732

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 710229732...
Checkpoint 710229732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,683.67875
Policy Entropy: 3.64218
Value Function Loss: 0.07992

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.60441
Value Function Update Magnitude: 0.57378

Collected Steps per Second: 21,893.33245
Overall Steps per Second: 10,610.20112

Timestep Collection Time: 2.28444
Timestep Consumption Time: 2.42933
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.71377

Cumulative Model Updates: 85,162
Cumulative Timesteps: 710,279,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,896.97359
Policy Entropy: 3.63824
Value Function Loss: 0.07693

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.20033
Policy Update Magnitude: 0.51137
Value Function Update Magnitude: 0.59647

Collected Steps per Second: 22,397.07522
Overall Steps per Second: 10,883.15488

Timestep Collection Time: 2.23404
Timestep Consumption Time: 2.36352
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.59756

Cumulative Model Updates: 85,168
Cumulative Timesteps: 710,329,782

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 710329782...
Checkpoint 710329782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,801.41236
Policy Entropy: 3.65608
Value Function Loss: 0.07482

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.50604
Value Function Update Magnitude: 0.61036

Collected Steps per Second: 22,269.95720
Overall Steps per Second: 10,770.10285

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.39740
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.64267

Cumulative Model Updates: 85,174
Cumulative Timesteps: 710,379,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,384.20458
Policy Entropy: 3.64832
Value Function Loss: 0.07422

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.53495
Value Function Update Magnitude: 0.66398

Collected Steps per Second: 23,013.78223
Overall Steps per Second: 10,941.23183

Timestep Collection Time: 2.17348
Timestep Consumption Time: 2.39822
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.57170

Cumulative Model Updates: 85,180
Cumulative Timesteps: 710,429,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 710429804...
Checkpoint 710429804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,989.86363
Policy Entropy: 3.63318
Value Function Loss: 0.07762

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.69418

Collected Steps per Second: 22,653.62992
Overall Steps per Second: 10,677.99458

Timestep Collection Time: 2.20777
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.68384

Cumulative Model Updates: 85,186
Cumulative Timesteps: 710,479,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,435.54937
Policy Entropy: 3.64056
Value Function Loss: 0.08052

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.59308
Value Function Update Magnitude: 0.66104

Collected Steps per Second: 22,982.08652
Overall Steps per Second: 10,834.47248

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.44046
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.61711

Cumulative Model Updates: 85,192
Cumulative Timesteps: 710,529,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 710529842...
Checkpoint 710529842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.74511
Policy Entropy: 3.65339
Value Function Loss: 0.08060

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.66245
Value Function Update Magnitude: 0.65628

Collected Steps per Second: 22,373.40508
Overall Steps per Second: 10,589.80105

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.72549

Cumulative Model Updates: 85,198
Cumulative Timesteps: 710,579,884

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,104.62728
Policy Entropy: 3.64695
Value Function Loss: 0.08329

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.57797
Value Function Update Magnitude: 0.64965

Collected Steps per Second: 22,449.52594
Overall Steps per Second: 10,540.49639

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.74399

Cumulative Model Updates: 85,204
Cumulative Timesteps: 710,629,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 710629888...
Checkpoint 710629888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,853.85427
Policy Entropy: 3.65056
Value Function Loss: 0.08433

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.57284
Value Function Update Magnitude: 0.67840

Collected Steps per Second: 22,825.42838
Overall Steps per Second: 10,715.10893

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.66724

Cumulative Model Updates: 85,210
Cumulative Timesteps: 710,679,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,878.40187
Policy Entropy: 3.64330
Value Function Loss: 0.08247

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.63021

Collected Steps per Second: 23,374.96541
Overall Steps per Second: 10,791.90087

Timestep Collection Time: 2.14015
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.63551

Cumulative Model Updates: 85,216
Cumulative Timesteps: 710,729,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 710729924...
Checkpoint 710729924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,209.29246
Policy Entropy: 3.64771
Value Function Loss: 0.08084

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.51011
Value Function Update Magnitude: 0.60424

Collected Steps per Second: 22,825.82843
Overall Steps per Second: 10,752.35949

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.46063
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.65200

Cumulative Model Updates: 85,222
Cumulative Timesteps: 710,779,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,816.05104
Policy Entropy: 3.64202
Value Function Loss: 0.08017

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.47744
Value Function Update Magnitude: 0.62509

Collected Steps per Second: 23,034.58909
Overall Steps per Second: 10,761.19528

Timestep Collection Time: 2.17178
Timestep Consumption Time: 2.47696
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.64874

Cumulative Model Updates: 85,228
Cumulative Timesteps: 710,829,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 710829970...
Checkpoint 710829970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,997.16735
Policy Entropy: 3.62723
Value Function Loss: 0.08136

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.47276
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 22,685.17859
Overall Steps per Second: 10,660.02080

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.48654
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.69080

Cumulative Model Updates: 85,234
Cumulative Timesteps: 710,879,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,653.68524
Policy Entropy: 3.62802
Value Function Loss: 0.08109

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.50672
Value Function Update Magnitude: 0.65688

Collected Steps per Second: 23,059.20756
Overall Steps per Second: 10,877.49450

Timestep Collection Time: 2.16929
Timestep Consumption Time: 2.42938
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59867

Cumulative Model Updates: 85,240
Cumulative Timesteps: 710,929,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 710929996...
Checkpoint 710929996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,119.30307
Policy Entropy: 3.63709
Value Function Loss: 0.08079

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.51033
Value Function Update Magnitude: 0.66620

Collected Steps per Second: 22,620.43941
Overall Steps per Second: 10,692.52828

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.46636
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.67728

Cumulative Model Updates: 85,246
Cumulative Timesteps: 710,980,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,459.78722
Policy Entropy: 3.64433
Value Function Loss: 0.08163

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.55290
Value Function Update Magnitude: 0.63282

Collected Steps per Second: 22,371.32263
Overall Steps per Second: 10,558.83422

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.50137
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.73727

Cumulative Model Updates: 85,252
Cumulative Timesteps: 711,030,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 711030028...
Checkpoint 711030028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,907.15720
Policy Entropy: 3.64290
Value Function Loss: 0.08088

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11128
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.63492

Collected Steps per Second: 22,111.99770
Overall Steps per Second: 10,513.95615

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.49547
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.75768

Cumulative Model Updates: 85,258
Cumulative Timesteps: 711,080,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,213.43750
Policy Entropy: 3.63542
Value Function Loss: 0.07993

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.50694
Value Function Update Magnitude: 0.64957

Collected Steps per Second: 22,659.03233
Overall Steps per Second: 10,667.70659

Timestep Collection Time: 2.20830
Timestep Consumption Time: 2.48230
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.69061

Cumulative Model Updates: 85,264
Cumulative Timesteps: 711,130,088

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 711130088...
Checkpoint 711130088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,663.73892
Policy Entropy: 3.61275
Value Function Loss: 0.08020

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.50441
Value Function Update Magnitude: 0.59922

Collected Steps per Second: 22,567.43299
Overall Steps per Second: 10,638.20060

Timestep Collection Time: 2.21682
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.70267

Cumulative Model Updates: 85,270
Cumulative Timesteps: 711,180,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,806.08279
Policy Entropy: 3.60424
Value Function Loss: 0.08294

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.47275
Value Function Update Magnitude: 0.56925

Collected Steps per Second: 23,265.67338
Overall Steps per Second: 10,687.28336

Timestep Collection Time: 2.14952
Timestep Consumption Time: 2.52987
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.67939

Cumulative Model Updates: 85,276
Cumulative Timesteps: 711,230,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 711230126...
Checkpoint 711230126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,041.48592
Policy Entropy: 3.59998
Value Function Loss: 0.08673

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.46034
Value Function Update Magnitude: 0.55618

Collected Steps per Second: 22,890.04299
Overall Steps per Second: 10,643.31287

Timestep Collection Time: 2.18497
Timestep Consumption Time: 2.51413
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.69910

Cumulative Model Updates: 85,282
Cumulative Timesteps: 711,280,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,015.17699
Policy Entropy: 3.60938
Value Function Loss: 0.08491

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.45978
Value Function Update Magnitude: 0.63423

Collected Steps per Second: 23,104.64430
Overall Steps per Second: 10,881.76033

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.59521

Cumulative Model Updates: 85,288
Cumulative Timesteps: 711,330,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 711330144...
Checkpoint 711330144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,453.03870
Policy Entropy: 3.62214
Value Function Loss: 0.08228

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.58778
Value Function Update Magnitude: 0.70993

Collected Steps per Second: 22,740.94137
Overall Steps per Second: 10,679.53136

Timestep Collection Time: 2.19929
Timestep Consumption Time: 2.48387
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.68316

Cumulative Model Updates: 85,294
Cumulative Timesteps: 711,380,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,769.57251
Policy Entropy: 3.62430
Value Function Loss: 0.08058

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.59759
Value Function Update Magnitude: 0.75611

Collected Steps per Second: 23,081.71339
Overall Steps per Second: 10,863.94570

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.60275

Cumulative Model Updates: 85,300
Cumulative Timesteps: 711,430,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 711430162...
Checkpoint 711430162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,354.83592
Policy Entropy: 3.65279
Value Function Loss: 0.07778

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.57249
Value Function Update Magnitude: 0.83202

Collected Steps per Second: 22,326.44244
Overall Steps per Second: 10,677.05887

Timestep Collection Time: 2.24021
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.68444

Cumulative Model Updates: 85,306
Cumulative Timesteps: 711,480,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,640.05489
Policy Entropy: 3.66066
Value Function Loss: 0.07416

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.89937

Collected Steps per Second: 22,054.68331
Overall Steps per Second: 10,837.29109

Timestep Collection Time: 2.26863
Timestep Consumption Time: 2.34820
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61684

Cumulative Model Updates: 85,312
Cumulative Timesteps: 711,530,212

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 711530212...
Checkpoint 711530212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,543.32606
Policy Entropy: 3.67734
Value Function Loss: 0.07292

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.45483
Value Function Update Magnitude: 0.89454

Collected Steps per Second: 21,695.04880
Overall Steps per Second: 10,706.07395

Timestep Collection Time: 2.30477
Timestep Consumption Time: 2.36567
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.67043

Cumulative Model Updates: 85,318
Cumulative Timesteps: 711,580,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,744.91049
Policy Entropy: 3.65901
Value Function Loss: 0.07512

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.47156
Value Function Update Magnitude: 0.87261

Collected Steps per Second: 21,741.61396
Overall Steps per Second: 10,591.51989

Timestep Collection Time: 2.30038
Timestep Consumption Time: 2.42170
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.72208

Cumulative Model Updates: 85,324
Cumulative Timesteps: 711,630,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 711630228...
Checkpoint 711630228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,571.10614
Policy Entropy: 3.65799
Value Function Loss: 0.07526

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.49367
Value Function Update Magnitude: 0.79007

Collected Steps per Second: 21,803.29327
Overall Steps per Second: 10,637.85967

Timestep Collection Time: 2.29433
Timestep Consumption Time: 2.40812
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.70245

Cumulative Model Updates: 85,330
Cumulative Timesteps: 711,680,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,873.99375
Policy Entropy: 3.68274
Value Function Loss: 0.07509

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.45660
Value Function Update Magnitude: 0.70477

Collected Steps per Second: 22,144.42978
Overall Steps per Second: 10,701.48767

Timestep Collection Time: 2.25872
Timestep Consumption Time: 2.41521
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.67393

Cumulative Model Updates: 85,336
Cumulative Timesteps: 711,730,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 711730270...
Checkpoint 711730270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.65341
Policy Entropy: 3.69183
Value Function Loss: 0.07213

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.45224
Value Function Update Magnitude: 0.70043

Collected Steps per Second: 22,630.42281
Overall Steps per Second: 10,719.42386

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.45541
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.66518

Cumulative Model Updates: 85,342
Cumulative Timesteps: 711,780,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,509.50393
Policy Entropy: 3.69815
Value Function Loss: 0.06757

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.49856
Value Function Update Magnitude: 0.77049

Collected Steps per Second: 22,613.76013
Overall Steps per Second: 10,810.31254

Timestep Collection Time: 2.21131
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62577

Cumulative Model Updates: 85,348
Cumulative Timesteps: 711,830,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 711830284...
Checkpoint 711830284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,834.43272
Policy Entropy: 3.67355
Value Function Loss: 0.06448

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.52569
Value Function Update Magnitude: 0.79339

Collected Steps per Second: 22,748.86672
Overall Steps per Second: 10,663.39758

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.49232
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.69138

Cumulative Model Updates: 85,354
Cumulative Timesteps: 711,880,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360.42475
Policy Entropy: 3.67709
Value Function Loss: 0.06202

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.51089
Value Function Update Magnitude: 0.77446

Collected Steps per Second: 23,097.47930
Overall Steps per Second: 10,916.86353

Timestep Collection Time: 2.16543
Timestep Consumption Time: 2.41610
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.58154

Cumulative Model Updates: 85,360
Cumulative Timesteps: 711,930,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 711930326...
Checkpoint 711930326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,585.54311
Policy Entropy: 3.66764
Value Function Loss: 0.06250

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.63170
Value Function Update Magnitude: 0.77508

Collected Steps per Second: 22,885.40345
Overall Steps per Second: 10,684.90525

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.68212

Cumulative Model Updates: 85,366
Cumulative Timesteps: 711,980,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,940.78276
Policy Entropy: 3.68485
Value Function Loss: 0.06390

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.74312
Value Function Update Magnitude: 0.68146

Collected Steps per Second: 22,772.64670
Overall Steps per Second: 10,773.30338

Timestep Collection Time: 2.19579
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.64147

Cumulative Model Updates: 85,372
Cumulative Timesteps: 712,030,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 712030358...
Checkpoint 712030358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348.10900
Policy Entropy: 3.67654
Value Function Loss: 0.06482

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07206
Policy Update Magnitude: 0.78481
Value Function Update Magnitude: 0.71392

Collected Steps per Second: 22,207.41195
Overall Steps per Second: 10,693.01800

Timestep Collection Time: 2.25159
Timestep Consumption Time: 2.42454
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.67614

Cumulative Model Updates: 85,378
Cumulative Timesteps: 712,080,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,160.06987
Policy Entropy: 3.68312
Value Function Loss: 0.06591

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.69750
Value Function Update Magnitude: 0.69250

Collected Steps per Second: 22,622.91672
Overall Steps per Second: 10,589.76169

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.51210
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.72286

Cumulative Model Updates: 85,384
Cumulative Timesteps: 712,130,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 712130374...
Checkpoint 712130374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,051.87298
Policy Entropy: 3.67331
Value Function Loss: 0.06765

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.67865

Collected Steps per Second: 22,332.42453
Overall Steps per Second: 10,545.55646

Timestep Collection Time: 2.23926
Timestep Consumption Time: 2.50284
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.74209

Cumulative Model Updates: 85,390
Cumulative Timesteps: 712,180,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,920.78672
Policy Entropy: 3.68076
Value Function Loss: 0.06782

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.44625
Value Function Update Magnitude: 0.66665

Collected Steps per Second: 21,896.58298
Overall Steps per Second: 10,439.62098

Timestep Collection Time: 2.28392
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.79040

Cumulative Model Updates: 85,396
Cumulative Timesteps: 712,230,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 712230392...
Checkpoint 712230392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,937.15745
Policy Entropy: 3.68325
Value Function Loss: 0.07082

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.44763
Value Function Update Magnitude: 0.64226

Collected Steps per Second: 22,324.31106
Overall Steps per Second: 10,681.58413

Timestep Collection Time: 2.24105
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.68376

Cumulative Model Updates: 85,402
Cumulative Timesteps: 712,280,422

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,756.68677
Policy Entropy: 3.68899
Value Function Loss: 0.06793

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.49025
Value Function Update Magnitude: 0.49554

Collected Steps per Second: 23,154.53101
Overall Steps per Second: 10,809.23906

Timestep Collection Time: 2.16001
Timestep Consumption Time: 2.46696
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.62697

Cumulative Model Updates: 85,408
Cumulative Timesteps: 712,330,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 712330436...
Checkpoint 712330436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,287.98159
Policy Entropy: 3.68049
Value Function Loss: 0.06896

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.52872
Value Function Update Magnitude: 0.46116

Collected Steps per Second: 22,764.49305
Overall Steps per Second: 10,721.70389

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.46763
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.66456

Cumulative Model Updates: 85,414
Cumulative Timesteps: 712,380,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,227.25412
Policy Entropy: 3.67868
Value Function Loss: 0.06604

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.47557
Value Function Update Magnitude: 0.53510

Collected Steps per Second: 22,632.20130
Overall Steps per Second: 10,619.92050

Timestep Collection Time: 2.21004
Timestep Consumption Time: 2.49979
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.70983

Cumulative Model Updates: 85,420
Cumulative Timesteps: 712,430,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 712430466...
Checkpoint 712430466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,956.98647
Policy Entropy: 3.67263
Value Function Loss: 0.06703

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.46942
Value Function Update Magnitude: 0.65989

Collected Steps per Second: 22,952.78668
Overall Steps per Second: 10,836.13676

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61456

Cumulative Model Updates: 85,426
Cumulative Timesteps: 712,480,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,720.13963
Policy Entropy: 3.67946
Value Function Loss: 0.06886

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.50082
Value Function Update Magnitude: 0.75997

Collected Steps per Second: 22,906.30959
Overall Steps per Second: 10,697.67042

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.67560

Cumulative Model Updates: 85,432
Cumulative Timesteps: 712,530,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 712530488...
Checkpoint 712530488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,290.38194
Policy Entropy: 3.67846
Value Function Loss: 0.07205

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.54804
Value Function Update Magnitude: 0.79047

Collected Steps per Second: 22,612.42356
Overall Steps per Second: 10,635.26358

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.70228

Cumulative Model Updates: 85,438
Cumulative Timesteps: 712,580,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,881.10917
Policy Entropy: 3.67284
Value Function Loss: 0.07394

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.72307

Collected Steps per Second: 22,608.68480
Overall Steps per Second: 10,733.26420

Timestep Collection Time: 2.21251
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.66046

Cumulative Model Updates: 85,444
Cumulative Timesteps: 712,630,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 712630520...
Checkpoint 712630520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,226.71083
Policy Entropy: 3.67078
Value Function Loss: 0.07452

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.54287
Value Function Update Magnitude: 0.66290

Collected Steps per Second: 22,175.04865
Overall Steps per Second: 10,686.44926

Timestep Collection Time: 2.25569
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.68069

Cumulative Model Updates: 85,450
Cumulative Timesteps: 712,680,540

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,551.04936
Policy Entropy: 3.65945
Value Function Loss: 0.07760

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.61488
Value Function Update Magnitude: 0.66902

Collected Steps per Second: 22,517.78966
Overall Steps per Second: 10,591.05365

Timestep Collection Time: 2.22091
Timestep Consumption Time: 2.50100
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.72191

Cumulative Model Updates: 85,456
Cumulative Timesteps: 712,730,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 712730550...
Checkpoint 712730550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,613.70265
Policy Entropy: 3.65523
Value Function Loss: 0.07551

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.64930

Collected Steps per Second: 22,579.58201
Overall Steps per Second: 10,561.88372

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.73457

Cumulative Model Updates: 85,462
Cumulative Timesteps: 712,780,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,936.19459
Policy Entropy: 3.64641
Value Function Loss: 0.07519

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.52180
Value Function Update Magnitude: 0.62606

Collected Steps per Second: 22,856.11614
Overall Steps per Second: 10,768.32185

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.45653
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.64492

Cumulative Model Updates: 85,468
Cumulative Timesteps: 712,830,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 712830574...
Checkpoint 712830574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,289.38331
Policy Entropy: 3.65519
Value Function Loss: 0.07238

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.66635

Collected Steps per Second: 22,252.91129
Overall Steps per Second: 10,627.74267

Timestep Collection Time: 2.24771
Timestep Consumption Time: 2.45866
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.70636

Cumulative Model Updates: 85,474
Cumulative Timesteps: 712,880,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,841.80116
Policy Entropy: 3.65469
Value Function Loss: 0.07539

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.65020

Collected Steps per Second: 22,627.52238
Overall Steps per Second: 10,619.45376

Timestep Collection Time: 2.20970
Timestep Consumption Time: 2.49864
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.70834

Cumulative Model Updates: 85,480
Cumulative Timesteps: 712,930,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 712930592...
Checkpoint 712930592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,501.31493
Policy Entropy: 3.66431
Value Function Loss: 0.07861

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.52688
Value Function Update Magnitude: 0.57918

Collected Steps per Second: 23,200.24402
Overall Steps per Second: 10,883.93536

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59558

Cumulative Model Updates: 85,486
Cumulative Timesteps: 712,980,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.41960
Policy Entropy: 3.65429
Value Function Loss: 0.08256

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.47606
Value Function Update Magnitude: 0.61612

Collected Steps per Second: 22,997.63213
Overall Steps per Second: 10,742.18949

Timestep Collection Time: 2.17457
Timestep Consumption Time: 2.48090
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.65548

Cumulative Model Updates: 85,492
Cumulative Timesteps: 713,030,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 713030620...
Checkpoint 713030620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,749.57311
Policy Entropy: 3.64501
Value Function Loss: 0.08181

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.44353
Value Function Update Magnitude: 0.61495

Collected Steps per Second: 23,108.70755
Overall Steps per Second: 10,853.75305

Timestep Collection Time: 2.16412
Timestep Consumption Time: 2.44350
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.60762

Cumulative Model Updates: 85,498
Cumulative Timesteps: 713,080,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,312.57658
Policy Entropy: 3.63458
Value Function Loss: 0.08173

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.62557

Collected Steps per Second: 21,776.27320
Overall Steps per Second: 10,610.10816

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.41709
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.71381

Cumulative Model Updates: 85,504
Cumulative Timesteps: 713,130,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 713130644...
Checkpoint 713130644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,804.63874
Policy Entropy: 3.63646
Value Function Loss: 0.08098

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.50032
Value Function Update Magnitude: 0.63000

Collected Steps per Second: 21,827.68340
Overall Steps per Second: 10,635.57727

Timestep Collection Time: 2.29168
Timestep Consumption Time: 2.41159
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.70327

Cumulative Model Updates: 85,510
Cumulative Timesteps: 713,180,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,939.91744
Policy Entropy: 3.63577
Value Function Loss: 0.08469

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.51285
Value Function Update Magnitude: 0.59784

Collected Steps per Second: 21,884.74295
Overall Steps per Second: 10,756.01560

Timestep Collection Time: 2.28470
Timestep Consumption Time: 2.36386
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.64856

Cumulative Model Updates: 85,516
Cumulative Timesteps: 713,230,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 713230666...
Checkpoint 713230666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,791.11928
Policy Entropy: 3.63024
Value Function Loss: 0.08420

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.66334
Value Function Update Magnitude: 0.65262

Collected Steps per Second: 21,839.47722
Overall Steps per Second: 10,628.78957

Timestep Collection Time: 2.28980
Timestep Consumption Time: 2.41516
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.70496

Cumulative Model Updates: 85,522
Cumulative Timesteps: 713,280,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,824.07589
Policy Entropy: 3.63549
Value Function Loss: 0.08432

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.65567
Value Function Update Magnitude: 0.65397

Collected Steps per Second: 22,177.23406
Overall Steps per Second: 10,649.63338

Timestep Collection Time: 2.25556
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.69706

Cumulative Model Updates: 85,528
Cumulative Timesteps: 713,330,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 713330696...
Checkpoint 713330696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,713.12349
Policy Entropy: 3.64334
Value Function Loss: 0.08449

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.68968
Value Function Update Magnitude: 0.66538

Collected Steps per Second: 22,560.11051
Overall Steps per Second: 10,799.84774

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.41339
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62969

Cumulative Model Updates: 85,534
Cumulative Timesteps: 713,380,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,413.02018
Policy Entropy: 3.63028
Value Function Loss: 0.08646

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.73929
Value Function Update Magnitude: 0.68862

Collected Steps per Second: 22,628.37242
Overall Steps per Second: 10,654.94075

Timestep Collection Time: 2.21015
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.69378

Cumulative Model Updates: 85,540
Cumulative Timesteps: 713,430,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 713430708...
Checkpoint 713430708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,886.80329
Policy Entropy: 3.62808
Value Function Loss: 0.08407

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.65568
Value Function Update Magnitude: 0.71278

Collected Steps per Second: 23,031.35739
Overall Steps per Second: 10,914.89342

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.41110
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.58310

Cumulative Model Updates: 85,546
Cumulative Timesteps: 713,480,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,610.74261
Policy Entropy: 3.61844
Value Function Loss: 0.08413

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.59428
Value Function Update Magnitude: 0.73316

Collected Steps per Second: 22,900.62602
Overall Steps per Second: 10,764.16536

Timestep Collection Time: 2.18431
Timestep Consumption Time: 2.46278
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.64709

Cumulative Model Updates: 85,552
Cumulative Timesteps: 713,530,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 713530754...
Checkpoint 713530754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,124.91042
Policy Entropy: 3.63012
Value Function Loss: 0.08097

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.66913
Value Function Update Magnitude: 0.72519

Collected Steps per Second: 23,040.46834
Overall Steps per Second: 10,894.79577

Timestep Collection Time: 2.17062
Timestep Consumption Time: 2.41983
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.59045

Cumulative Model Updates: 85,558
Cumulative Timesteps: 713,580,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.31058
Policy Entropy: 3.61788
Value Function Loss: 0.08590

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.71460
Value Function Update Magnitude: 0.67888

Collected Steps per Second: 22,530.73287
Overall Steps per Second: 10,595.21644

Timestep Collection Time: 2.22061
Timestep Consumption Time: 2.50152
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.72213

Cumulative Model Updates: 85,564
Cumulative Timesteps: 713,630,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 713630798...
Checkpoint 713630798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,705.72241
Policy Entropy: 3.61401
Value Function Loss: 0.08382

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.70261
Value Function Update Magnitude: 0.72196

Collected Steps per Second: 22,110.57702
Overall Steps per Second: 10,493.28531

Timestep Collection Time: 2.26227
Timestep Consumption Time: 2.50459
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.76686

Cumulative Model Updates: 85,570
Cumulative Timesteps: 713,680,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,472.68217
Policy Entropy: 3.58758
Value Function Loss: 0.08344

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.70850

Collected Steps per Second: 22,417.39450
Overall Steps per Second: 10,561.23719

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.50539
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.73713

Cumulative Model Updates: 85,576
Cumulative Timesteps: 713,730,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 713730848...
Checkpoint 713730848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,335.75659
Policy Entropy: 3.58114
Value Function Loss: 0.08478

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.48928
Value Function Update Magnitude: 0.65948

Collected Steps per Second: 22,786.30957
Overall Steps per Second: 10,639.11964

Timestep Collection Time: 2.19474
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.70058

Cumulative Model Updates: 85,582
Cumulative Timesteps: 713,780,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,527.11222
Policy Entropy: 3.59082
Value Function Loss: 0.08754

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.50038
Value Function Update Magnitude: 0.64399

Collected Steps per Second: 23,075.88906
Overall Steps per Second: 10,763.46336

Timestep Collection Time: 2.16780
Timestep Consumption Time: 2.47977
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.64757

Cumulative Model Updates: 85,588
Cumulative Timesteps: 713,830,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 713830882...
Checkpoint 713830882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.45121
Policy Entropy: 3.61746
Value Function Loss: 0.08764

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.44721
Value Function Update Magnitude: 0.64531

Collected Steps per Second: 22,972.98042
Overall Steps per Second: 10,655.14060

Timestep Collection Time: 2.17812
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.69614

Cumulative Model Updates: 85,594
Cumulative Timesteps: 713,880,920

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,140.75023
Policy Entropy: 3.63446
Value Function Loss: 0.08618

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.44846
Value Function Update Magnitude: 0.67960

Collected Steps per Second: 22,971.70841
Overall Steps per Second: 10,849.25635

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60861

Cumulative Model Updates: 85,600
Cumulative Timesteps: 713,930,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 713930920...
Checkpoint 713930920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,780.77510
Policy Entropy: 3.62411
Value Function Loss: 0.08222

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.44830
Value Function Update Magnitude: 0.71571

Collected Steps per Second: 22,788.73109
Overall Steps per Second: 10,724.67088

Timestep Collection Time: 2.19424
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.66252

Cumulative Model Updates: 85,606
Cumulative Timesteps: 713,980,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,647.99549
Policy Entropy: 3.61153
Value Function Loss: 0.08147

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.51422
Value Function Update Magnitude: 0.73608

Collected Steps per Second: 22,761.47245
Overall Steps per Second: 10,789.82298

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.63826

Cumulative Model Updates: 85,612
Cumulative Timesteps: 714,030,970

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 714030970...
Checkpoint 714030970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,145.28781
Policy Entropy: 3.60486
Value Function Loss: 0.08369

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.56757
Value Function Update Magnitude: 0.69911

Collected Steps per Second: 22,867.25510
Overall Steps per Second: 10,741.98509

Timestep Collection Time: 2.18688
Timestep Consumption Time: 2.46850
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.65538

Cumulative Model Updates: 85,618
Cumulative Timesteps: 714,080,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,397.16905
Policy Entropy: 3.61060
Value Function Loss: 0.08609

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.67569

Collected Steps per Second: 21,373.33872
Overall Steps per Second: 10,489.81342

Timestep Collection Time: 2.34011
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.76805

Cumulative Model Updates: 85,624
Cumulative Timesteps: 714,130,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 714130994...
Checkpoint 714130994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657.14815
Policy Entropy: 3.61754
Value Function Loss: 0.08747

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.57146
Value Function Update Magnitude: 0.66951

Collected Steps per Second: 22,604.58281
Overall Steps per Second: 10,618.96996

Timestep Collection Time: 2.21212
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.70893

Cumulative Model Updates: 85,630
Cumulative Timesteps: 714,180,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,638.61703
Policy Entropy: 3.61461
Value Function Loss: 0.08728

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.65819
Value Function Update Magnitude: 0.71434

Collected Steps per Second: 22,701.57145
Overall Steps per Second: 10,777.54739

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.43688
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.63946

Cumulative Model Updates: 85,636
Cumulative Timesteps: 714,231,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 714231000...
Checkpoint 714231000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,504.33241
Policy Entropy: 3.61256
Value Function Loss: 0.08589

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.62111
Value Function Update Magnitude: 0.73143

Collected Steps per Second: 21,862.69439
Overall Steps per Second: 10,788.56629

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.34857
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.63658

Cumulative Model Updates: 85,642
Cumulative Timesteps: 714,281,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,632.92267
Policy Entropy: 3.61541
Value Function Loss: 0.08404

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.57684
Value Function Update Magnitude: 0.70755

Collected Steps per Second: 22,286.71602
Overall Steps per Second: 10,808.28506

Timestep Collection Time: 2.24349
Timestep Consumption Time: 2.38259
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62608

Cumulative Model Updates: 85,648
Cumulative Timesteps: 714,331,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 714331022...
Checkpoint 714331022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.15000
Policy Entropy: 3.61493
Value Function Loss: 0.08486

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.47395
Value Function Update Magnitude: 0.70870

Collected Steps per Second: 22,481.32879
Overall Steps per Second: 10,728.37382

Timestep Collection Time: 2.22460
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.66166

Cumulative Model Updates: 85,654
Cumulative Timesteps: 714,381,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,752.70160
Policy Entropy: 3.62508
Value Function Loss: 0.08314

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.44161
Value Function Update Magnitude: 0.74827

Collected Steps per Second: 22,153.59023
Overall Steps per Second: 10,798.83561

Timestep Collection Time: 2.25832
Timestep Consumption Time: 2.37458
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.63291

Cumulative Model Updates: 85,660
Cumulative Timesteps: 714,431,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 714431064...
Checkpoint 714431064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.01979
Policy Entropy: 3.63445
Value Function Loss: 0.08104

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.73432

Collected Steps per Second: 21,967.81164
Overall Steps per Second: 10,712.29179

Timestep Collection Time: 2.27651
Timestep Consumption Time: 2.39196
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.66847

Cumulative Model Updates: 85,666
Cumulative Timesteps: 714,481,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,239.80664
Policy Entropy: 3.64910
Value Function Loss: 0.07724

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.62391
Value Function Update Magnitude: 0.79612

Collected Steps per Second: 22,489.24056
Overall Steps per Second: 10,668.67668

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.46461
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.68905

Cumulative Model Updates: 85,672
Cumulative Timesteps: 714,531,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 714531100...
Checkpoint 714531100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,320.32322
Policy Entropy: 3.65387
Value Function Loss: 0.07439

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.64817
Value Function Update Magnitude: 0.82383

Collected Steps per Second: 23,070.91118
Overall Steps per Second: 10,863.82365

Timestep Collection Time: 2.16775
Timestep Consumption Time: 2.43578
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.60354

Cumulative Model Updates: 85,678
Cumulative Timesteps: 714,581,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,681.02119
Policy Entropy: 3.63806
Value Function Loss: 0.07259

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.60031
Value Function Update Magnitude: 0.86880

Collected Steps per Second: 22,456.33408
Overall Steps per Second: 10,639.10402

Timestep Collection Time: 2.22699
Timestep Consumption Time: 2.47360
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.70058

Cumulative Model Updates: 85,684
Cumulative Timesteps: 714,631,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 714631122...
Checkpoint 714631122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,925.99023
Policy Entropy: 3.63702
Value Function Loss: 0.07297

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.50782
Value Function Update Magnitude: 0.86299

Collected Steps per Second: 22,320.27515
Overall Steps per Second: 10,667.47923

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.68902

Cumulative Model Updates: 85,690
Cumulative Timesteps: 714,681,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.40799
Policy Entropy: 3.62339
Value Function Loss: 0.07570

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.45612
Value Function Update Magnitude: 0.77198

Collected Steps per Second: 23,000.65115
Overall Steps per Second: 10,729.24673

Timestep Collection Time: 2.17385
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.66016

Cumulative Model Updates: 85,696
Cumulative Timesteps: 714,731,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 714731142...
Checkpoint 714731142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,890.28796
Policy Entropy: 3.63077
Value Function Loss: 0.08084

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.45937
Value Function Update Magnitude: 0.65749

Collected Steps per Second: 22,911.02473
Overall Steps per Second: 10,615.66597

Timestep Collection Time: 2.18332
Timestep Consumption Time: 2.52878
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.71209

Cumulative Model Updates: 85,702
Cumulative Timesteps: 714,781,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,911.58890
Policy Entropy: 3.62957
Value Function Loss: 0.08173

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.48132
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 22,676.83305
Overall Steps per Second: 10,596.82905

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.51400
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.71934

Cumulative Model Updates: 85,708
Cumulative Timesteps: 714,831,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 714831174...
Checkpoint 714831174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,063.73715
Policy Entropy: 3.64281
Value Function Loss: 0.07920

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.51097
Value Function Update Magnitude: 0.68778

Collected Steps per Second: 23,039.54883
Overall Steps per Second: 10,846.50692

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.43979
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.61015

Cumulative Model Updates: 85,714
Cumulative Timesteps: 714,881,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,913.87687
Policy Entropy: 3.63127
Value Function Loss: 0.07758

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.52782
Value Function Update Magnitude: 0.74823

Collected Steps per Second: 22,727.43487
Overall Steps per Second: 10,595.06805

Timestep Collection Time: 2.20069
Timestep Consumption Time: 2.52000
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72069

Cumulative Model Updates: 85,720
Cumulative Timesteps: 714,931,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 714931194...
Checkpoint 714931194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,556.77546
Policy Entropy: 3.63116
Value Function Loss: 0.08039

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.48720
Value Function Update Magnitude: 0.77575

Collected Steps per Second: 23,060.07967
Overall Steps per Second: 10,743.66005

Timestep Collection Time: 2.16903
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.65558

Cumulative Model Updates: 85,726
Cumulative Timesteps: 714,981,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,940.78011
Policy Entropy: 3.61964
Value Function Loss: 0.08178

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.17796
Policy Update Magnitude: 0.47666
Value Function Update Magnitude: 0.72597

Collected Steps per Second: 23,053.44374
Overall Steps per Second: 10,740.40969

Timestep Collection Time: 2.16957
Timestep Consumption Time: 2.48724
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.65681

Cumulative Model Updates: 85,732
Cumulative Timesteps: 715,031,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 715031228...
Checkpoint 715031228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,515.25976
Policy Entropy: 3.63525
Value Function Loss: 0.08162

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.39166
Value Function Update Magnitude: 0.66803

Collected Steps per Second: 22,900.98495
Overall Steps per Second: 10,646.20470

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.69820

Cumulative Model Updates: 85,738
Cumulative Timesteps: 715,081,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,403.38853
Policy Entropy: 3.64932
Value Function Loss: 0.07964

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.46513
Value Function Update Magnitude: 0.64808

Collected Steps per Second: 22,634.78038
Overall Steps per Second: 10,658.00265

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69337

Cumulative Model Updates: 85,744
Cumulative Timesteps: 715,131,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 715131268...
Checkpoint 715131268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,993.18663
Policy Entropy: 3.65976
Value Function Loss: 0.07823

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.16625
Policy Update Magnitude: 0.49573
Value Function Update Magnitude: 0.64006

Collected Steps per Second: 22,368.05263
Overall Steps per Second: 10,831.00168

Timestep Collection Time: 2.23712
Timestep Consumption Time: 2.38295
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62007

Cumulative Model Updates: 85,750
Cumulative Timesteps: 715,181,308

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,337.24185
Policy Entropy: 3.65561
Value Function Loss: 0.07833

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.40194
Value Function Update Magnitude: 0.66415

Collected Steps per Second: 22,403.75887
Overall Steps per Second: 10,522.36106

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.52123
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.75407

Cumulative Model Updates: 85,756
Cumulative Timesteps: 715,231,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 715231332...
Checkpoint 715231332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,268.33979
Policy Entropy: 3.65727
Value Function Loss: 0.07954

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.37026
Value Function Update Magnitude: 0.78779

Collected Steps per Second: 22,612.05183
Overall Steps per Second: 10,634.48456

Timestep Collection Time: 2.21209
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.70357

Cumulative Model Updates: 85,762
Cumulative Timesteps: 715,281,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,928.76844
Policy Entropy: 3.65760
Value Function Loss: 0.07699

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.37185
Value Function Update Magnitude: 0.87453

Collected Steps per Second: 22,858.07364
Overall Steps per Second: 10,625.83206

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.51881
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70683

Cumulative Model Updates: 85,768
Cumulative Timesteps: 715,331,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 715331366...
Checkpoint 715331366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,798.80000
Policy Entropy: 3.66872
Value Function Loss: 0.07572

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.36683
Value Function Update Magnitude: 0.88333

Collected Steps per Second: 22,963.07088
Overall Steps per Second: 10,675.96796

Timestep Collection Time: 2.17793
Timestep Consumption Time: 2.50661
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.68454

Cumulative Model Updates: 85,774
Cumulative Timesteps: 715,381,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,840.91519
Policy Entropy: 3.66971
Value Function Loss: 0.07356

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.36302
Value Function Update Magnitude: 0.83419

Collected Steps per Second: 23,024.81260
Overall Steps per Second: 10,769.47371

Timestep Collection Time: 2.17235
Timestep Consumption Time: 2.47207
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.64442

Cumulative Model Updates: 85,780
Cumulative Timesteps: 715,431,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 715431396...
Checkpoint 715431396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,408.33573
Policy Entropy: 3.68262
Value Function Loss: 0.07333

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.37162
Value Function Update Magnitude: 0.71685

Collected Steps per Second: 22,910.28810
Overall Steps per Second: 10,695.39000

Timestep Collection Time: 2.18339
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.67697

Cumulative Model Updates: 85,786
Cumulative Timesteps: 715,481,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,622.95543
Policy Entropy: 3.69183
Value Function Loss: 0.06945

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.39167
Value Function Update Magnitude: 0.72237

Collected Steps per Second: 23,030.53388
Overall Steps per Second: 10,811.42260

Timestep Collection Time: 2.17173
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.62622

Cumulative Model Updates: 85,792
Cumulative Timesteps: 715,531,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 715531434...
Checkpoint 715531434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,575.40990
Policy Entropy: 3.68668
Value Function Loss: 0.06708

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.44489
Value Function Update Magnitude: 0.80695

Collected Steps per Second: 22,755.17732
Overall Steps per Second: 10,712.52354

Timestep Collection Time: 2.19783
Timestep Consumption Time: 2.47073
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.66855

Cumulative Model Updates: 85,798
Cumulative Timesteps: 715,581,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,538.56522
Policy Entropy: 3.68399
Value Function Loss: 0.06716

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.44187
Value Function Update Magnitude: 0.85385

Collected Steps per Second: 22,701.31482
Overall Steps per Second: 10,764.42068

Timestep Collection Time: 2.20269
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.64530

Cumulative Model Updates: 85,804
Cumulative Timesteps: 715,631,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 715631450...
Checkpoint 715631450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.50430
Policy Entropy: 3.67622
Value Function Loss: 0.06522

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.40791
Value Function Update Magnitude: 0.86815

Collected Steps per Second: 22,150.57030
Overall Steps per Second: 10,696.57294

Timestep Collection Time: 2.25854
Timestep Consumption Time: 2.41847
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.67701

Cumulative Model Updates: 85,810
Cumulative Timesteps: 715,681,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.11699
Policy Entropy: 3.68482
Value Function Loss: 0.06513

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.42486
Value Function Update Magnitude: 0.86215

Collected Steps per Second: 22,555.48444
Overall Steps per Second: 10,648.97752

Timestep Collection Time: 2.21782
Timestep Consumption Time: 2.47972
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.69754

Cumulative Model Updates: 85,816
Cumulative Timesteps: 715,731,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 715731502...
Checkpoint 715731502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.11412
Policy Entropy: 3.69564
Value Function Loss: 0.06044

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.45713
Value Function Update Magnitude: 0.78308

Collected Steps per Second: 22,542.90354
Overall Steps per Second: 10,626.15308

Timestep Collection Time: 2.21799
Timestep Consumption Time: 2.48738
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.70537

Cumulative Model Updates: 85,822
Cumulative Timesteps: 715,781,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370.72843
Policy Entropy: 3.70108
Value Function Loss: 0.05655

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.45892
Value Function Update Magnitude: 0.80867

Collected Steps per Second: 22,448.65013
Overall Steps per Second: 10,749.89781

Timestep Collection Time: 2.22748
Timestep Consumption Time: 2.42410
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.65158

Cumulative Model Updates: 85,828
Cumulative Timesteps: 715,831,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 715831506...
Checkpoint 715831506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.44416
Policy Entropy: 3.71014
Value Function Loss: 0.05277

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.47622
Value Function Update Magnitude: 0.82311

Collected Steps per Second: 22,510.08754
Overall Steps per Second: 10,564.92984

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.51332
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.73624

Cumulative Model Updates: 85,834
Cumulative Timesteps: 715,881,544

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.28365
Policy Entropy: 3.71270
Value Function Loss: 0.05206

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.53336
Value Function Update Magnitude: 0.80705

Collected Steps per Second: 23,223.17585
Overall Steps per Second: 10,951.05594

Timestep Collection Time: 2.15371
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.56723

Cumulative Model Updates: 85,840
Cumulative Timesteps: 715,931,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 715931560...
Checkpoint 715931560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,152.65443
Policy Entropy: 3.71744
Value Function Loss: 0.05464

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.58798
Value Function Update Magnitude: 0.73600

Collected Steps per Second: 22,914.15098
Overall Steps per Second: 10,610.24235

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.53047
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71262

Cumulative Model Updates: 85,846
Cumulative Timesteps: 715,981,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,948.45402
Policy Entropy: 3.72341
Value Function Loss: 0.05656

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.67159
Value Function Update Magnitude: 0.75952

Collected Steps per Second: 22,764.17600
Overall Steps per Second: 10,528.17709

Timestep Collection Time: 2.19758
Timestep Consumption Time: 2.55405
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.75163

Cumulative Model Updates: 85,852
Cumulative Timesteps: 716,031,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 716031588...
Checkpoint 716031588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,717.84194
Policy Entropy: 3.72730
Value Function Loss: 0.05783

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.64299
Value Function Update Magnitude: 0.80570

Collected Steps per Second: 22,832.85363
Overall Steps per Second: 10,561.36903

Timestep Collection Time: 2.19018
Timestep Consumption Time: 2.54481
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73499

Cumulative Model Updates: 85,858
Cumulative Timesteps: 716,081,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,499.12800
Policy Entropy: 3.72617
Value Function Loss: 0.06021

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06832
Policy Update Magnitude: 0.65221
Value Function Update Magnitude: 0.74292

Collected Steps per Second: 23,130.10353
Overall Steps per Second: 10,793.43439

Timestep Collection Time: 2.16246
Timestep Consumption Time: 2.47165
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.63411

Cumulative Model Updates: 85,864
Cumulative Timesteps: 716,131,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 716131614...
Checkpoint 716131614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,833.22819
Policy Entropy: 3.73413
Value Function Loss: 0.06050

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.75661
Value Function Update Magnitude: 0.71775

Collected Steps per Second: 22,649.72111
Overall Steps per Second: 10,768.97225

Timestep Collection Time: 2.20753
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.64297

Cumulative Model Updates: 85,870
Cumulative Timesteps: 716,181,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,286.82744
Policy Entropy: 3.73475
Value Function Loss: 0.06136

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.71440
Value Function Update Magnitude: 0.75810

Collected Steps per Second: 22,413.68602
Overall Steps per Second: 10,549.01418

Timestep Collection Time: 2.23167
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.74168

Cumulative Model Updates: 85,876
Cumulative Timesteps: 716,231,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 716231634...
Checkpoint 716231634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,107.93671
Policy Entropy: 3.72678
Value Function Loss: 0.06420

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.62254
Value Function Update Magnitude: 0.68872

Collected Steps per Second: 22,549.90173
Overall Steps per Second: 10,581.78782

Timestep Collection Time: 2.21801
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.72661

Cumulative Model Updates: 85,882
Cumulative Timesteps: 716,281,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.67597
Policy Entropy: 3.72604
Value Function Loss: 0.06764

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.60690
Value Function Update Magnitude: 0.67385

Collected Steps per Second: 22,500.79420
Overall Steps per Second: 10,784.06066

Timestep Collection Time: 2.22330
Timestep Consumption Time: 2.41558
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.63888

Cumulative Model Updates: 85,888
Cumulative Timesteps: 716,331,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 716331676...
Checkpoint 716331676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,486.39811
Policy Entropy: 3.71505
Value Function Loss: 0.06957

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.59526
Value Function Update Magnitude: 0.71056

Collected Steps per Second: 22,334.82058
Overall Steps per Second: 10,701.52975

Timestep Collection Time: 2.23964
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.67429

Cumulative Model Updates: 85,894
Cumulative Timesteps: 716,381,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,373.02102
Policy Entropy: 3.71754
Value Function Loss: 0.07094

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.62599
Value Function Update Magnitude: 0.73612

Collected Steps per Second: 22,909.94726
Overall Steps per Second: 10,631.39995

Timestep Collection Time: 2.18255
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70324

Cumulative Model Updates: 85,900
Cumulative Timesteps: 716,431,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 716431700...
Checkpoint 716431700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681.15976
Policy Entropy: 3.72260
Value Function Loss: 0.07008

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.58378
Value Function Update Magnitude: 0.76869

Collected Steps per Second: 23,101.79995
Overall Steps per Second: 10,879.83582

Timestep Collection Time: 2.16537
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59786

Cumulative Model Updates: 85,906
Cumulative Timesteps: 716,481,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,991.03653
Policy Entropy: 3.70544
Value Function Loss: 0.07159

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.61010
Value Function Update Magnitude: 0.77195

Collected Steps per Second: 22,707.81680
Overall Steps per Second: 10,643.13164

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.69899

Cumulative Model Updates: 85,912
Cumulative Timesteps: 716,531,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 716531736...
Checkpoint 716531736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,221.28626
Policy Entropy: 3.70838
Value Function Loss: 0.07073

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.61978
Value Function Update Magnitude: 0.78247

Collected Steps per Second: 23,006.72653
Overall Steps per Second: 10,737.42674

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.65810

Cumulative Model Updates: 85,918
Cumulative Timesteps: 716,581,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.92126
Policy Entropy: 3.70280
Value Function Loss: 0.07215

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.62929
Value Function Update Magnitude: 0.81941

Collected Steps per Second: 22,988.09044
Overall Steps per Second: 10,682.84982

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.68115

Cumulative Model Updates: 85,924
Cumulative Timesteps: 716,631,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 716631760...
Checkpoint 716631760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,823.08661
Policy Entropy: 3.71023
Value Function Loss: 0.06980

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.63901
Value Function Update Magnitude: 0.74377

Collected Steps per Second: 23,147.02647
Overall Steps per Second: 10,731.78620

Timestep Collection Time: 2.16071
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.66036

Cumulative Model Updates: 85,930
Cumulative Timesteps: 716,681,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.12484
Policy Entropy: 3.69910
Value Function Loss: 0.07247

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.72268
Value Function Update Magnitude: 0.72237

Collected Steps per Second: 22,736.93619
Overall Steps per Second: 10,793.36383

Timestep Collection Time: 2.19924
Timestep Consumption Time: 2.43361
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.63285

Cumulative Model Updates: 85,936
Cumulative Timesteps: 716,731,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 716731778...
Checkpoint 716731778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,773.20102
Policy Entropy: 3.69058
Value Function Loss: 0.07686

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.78202
Value Function Update Magnitude: 0.75096

Collected Steps per Second: 22,539.67666
Overall Steps per Second: 10,673.72141

Timestep Collection Time: 2.21875
Timestep Consumption Time: 2.46658
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.68534

Cumulative Model Updates: 85,942
Cumulative Timesteps: 716,781,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.75210
Policy Entropy: 3.68118
Value Function Loss: 0.08365

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.82955
Value Function Update Magnitude: 0.77399

Collected Steps per Second: 21,985.48448
Overall Steps per Second: 10,432.04328

Timestep Collection Time: 2.27423
Timestep Consumption Time: 2.51870
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.79292

Cumulative Model Updates: 85,948
Cumulative Timesteps: 716,831,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 716831788...
Checkpoint 716831788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,406.75214
Policy Entropy: 3.68104
Value Function Loss: 0.08498

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.71957
Value Function Update Magnitude: 0.78110

Collected Steps per Second: 22,353.05587
Overall Steps per Second: 10,567.98260

Timestep Collection Time: 2.23826
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.73430

Cumulative Model Updates: 85,954
Cumulative Timesteps: 716,881,820

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,109.79809
Policy Entropy: 3.67521
Value Function Loss: 0.08475

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.54948
Value Function Update Magnitude: 0.74345

Collected Steps per Second: 22,287.79512
Overall Steps per Second: 10,514.38006

Timestep Collection Time: 2.24446
Timestep Consumption Time: 2.51322
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.75767

Cumulative Model Updates: 85,960
Cumulative Timesteps: 716,931,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 716931844...
Checkpoint 716931844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,351.95206
Policy Entropy: 3.67735
Value Function Loss: 0.08079

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.49349
Value Function Update Magnitude: 0.75436

Collected Steps per Second: 22,272.45362
Overall Steps per Second: 10,685.92269

Timestep Collection Time: 2.24618
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.68167

Cumulative Model Updates: 85,966
Cumulative Timesteps: 716,981,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.27866
Policy Entropy: 3.67145
Value Function Loss: 0.07952

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.86815

Collected Steps per Second: 22,541.58895
Overall Steps per Second: 10,549.66243

Timestep Collection Time: 2.21830
Timestep Consumption Time: 2.52157
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.73987

Cumulative Model Updates: 85,972
Cumulative Timesteps: 717,031,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 717031876...
Checkpoint 717031876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.98120
Policy Entropy: 3.66675
Value Function Loss: 0.07656

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.94366

Collected Steps per Second: 22,957.96029
Overall Steps per Second: 10,850.73921

Timestep Collection Time: 2.17885
Timestep Consumption Time: 2.43116
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61001

Cumulative Model Updates: 85,978
Cumulative Timesteps: 717,081,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,619.06544
Policy Entropy: 3.67169
Value Function Loss: 0.07638

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.93846

Collected Steps per Second: 22,674.67718
Overall Steps per Second: 10,583.93777

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.52004
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.72603

Cumulative Model Updates: 85,984
Cumulative Timesteps: 717,131,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 717131918...
Checkpoint 717131918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,825.69641
Policy Entropy: 3.68400
Value Function Loss: 0.07550

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.93841

Collected Steps per Second: 22,802.25791
Overall Steps per Second: 10,619.28039

Timestep Collection Time: 2.19355
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.71011

Cumulative Model Updates: 85,990
Cumulative Timesteps: 717,181,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,790.10786
Policy Entropy: 3.69661
Value Function Loss: 0.07501

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.51376
Value Function Update Magnitude: 0.91695

Collected Steps per Second: 23,051.07307
Overall Steps per Second: 10,836.78521

Timestep Collection Time: 2.16962
Timestep Consumption Time: 2.44540
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61502

Cumulative Model Updates: 85,996
Cumulative Timesteps: 717,231,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 717231948...
Checkpoint 717231948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.83018
Policy Entropy: 3.68151
Value Function Loss: 0.07517

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.52698
Value Function Update Magnitude: 0.90617

Collected Steps per Second: 22,765.09741
Overall Steps per Second: 10,727.98667

Timestep Collection Time: 2.19740
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.66294

Cumulative Model Updates: 86,002
Cumulative Timesteps: 717,281,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,016.93474
Policy Entropy: 3.64213
Value Function Loss: 0.08201

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.77838

Collected Steps per Second: 22,618.53845
Overall Steps per Second: 10,665.85484

Timestep Collection Time: 2.21066
Timestep Consumption Time: 2.47738
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.68804

Cumulative Model Updates: 86,008
Cumulative Timesteps: 717,331,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 717331974...
Checkpoint 717331974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,658.16498
Policy Entropy: 3.64006
Value Function Loss: 0.08339

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.54429
Value Function Update Magnitude: 0.76835

Collected Steps per Second: 22,597.60101
Overall Steps per Second: 10,783.28330

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.42515
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.63866

Cumulative Model Updates: 86,014
Cumulative Timesteps: 717,381,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,355.76504
Policy Entropy: 3.65145
Value Function Loss: 0.08434

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.53022
Value Function Update Magnitude: 0.82841

Collected Steps per Second: 22,311.08985
Overall Steps per Second: 10,512.40457

Timestep Collection Time: 2.24149
Timestep Consumption Time: 2.51575
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.75724

Cumulative Model Updates: 86,020
Cumulative Timesteps: 717,432,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 717432004...
Checkpoint 717432004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,162.44330
Policy Entropy: 3.66832
Value Function Loss: 0.07916

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.52376
Value Function Update Magnitude: 0.90683

Collected Steps per Second: 22,263.24004
Overall Steps per Second: 10,708.75347

Timestep Collection Time: 2.24612
Timestep Consumption Time: 2.42351
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.66964

Cumulative Model Updates: 86,026
Cumulative Timesteps: 717,482,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,304.21541
Policy Entropy: 3.66401
Value Function Loss: 0.07866

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.84730

Collected Steps per Second: 21,843.57178
Overall Steps per Second: 10,394.79330

Timestep Collection Time: 2.29001
Timestep Consumption Time: 2.52221
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.81222

Cumulative Model Updates: 86,032
Cumulative Timesteps: 717,532,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 717532032...
Checkpoint 717532032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,371.59032
Policy Entropy: 3.65877
Value Function Loss: 0.08026

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.78076

Collected Steps per Second: 22,865.82264
Overall Steps per Second: 10,664.03196

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.50239
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.68941

Cumulative Model Updates: 86,038
Cumulative Timesteps: 717,582,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,548.70283
Policy Entropy: 3.65911
Value Function Loss: 0.08135

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.81507

Collected Steps per Second: 22,796.42082
Overall Steps per Second: 10,652.82555

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.50066
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.69434

Cumulative Model Updates: 86,044
Cumulative Timesteps: 717,632,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 717632048...
Checkpoint 717632048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,739.68289
Policy Entropy: 3.66074
Value Function Loss: 0.07783

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.87970

Collected Steps per Second: 22,999.26576
Overall Steps per Second: 10,835.40538

Timestep Collection Time: 2.17450
Timestep Consumption Time: 2.44111
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61561

Cumulative Model Updates: 86,050
Cumulative Timesteps: 717,682,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,742.84894
Policy Entropy: 3.65644
Value Function Loss: 0.07923

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.59375
Value Function Update Magnitude: 0.88513

Collected Steps per Second: 23,189.17043
Overall Steps per Second: 10,882.70822

Timestep Collection Time: 2.15618
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.59444

Cumulative Model Updates: 86,056
Cumulative Timesteps: 717,732,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 717732060...
Checkpoint 717732060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,782.24248
Policy Entropy: 3.64882
Value Function Loss: 0.07717

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.59814
Value Function Update Magnitude: 0.81275

Collected Steps per Second: 22,845.75593
Overall Steps per Second: 10,693.55936

Timestep Collection Time: 2.18938
Timestep Consumption Time: 2.48802
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.67739

Cumulative Model Updates: 86,062
Cumulative Timesteps: 717,782,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.40653
Policy Entropy: 3.65964
Value Function Loss: 0.07744

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.53636
Value Function Update Magnitude: 0.81158

Collected Steps per Second: 22,943.39393
Overall Steps per Second: 10,816.48951

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62535

Cumulative Model Updates: 86,068
Cumulative Timesteps: 717,832,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 717832108...
Checkpoint 717832108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,145.46402
Policy Entropy: 3.66052
Value Function Loss: 0.07588

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.49410
Value Function Update Magnitude: 0.90959

Collected Steps per Second: 22,345.79254
Overall Steps per Second: 10,698.84699

Timestep Collection Time: 2.23783
Timestep Consumption Time: 2.43614
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.67396

Cumulative Model Updates: 86,074
Cumulative Timesteps: 717,882,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,447.87139
Policy Entropy: 3.65659
Value Function Loss: 0.07710

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.52408
Value Function Update Magnitude: 0.93864

Collected Steps per Second: 22,494.98138
Overall Steps per Second: 10,570.98752

Timestep Collection Time: 2.22476
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.73428

Cumulative Model Updates: 86,080
Cumulative Timesteps: 717,932,160

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 717932160...
Checkpoint 717932160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,890.34070
Policy Entropy: 3.65099
Value Function Loss: 0.07870

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.62745
Value Function Update Magnitude: 0.87937

Collected Steps per Second: 22,376.80800
Overall Steps per Second: 10,557.22944

Timestep Collection Time: 2.23535
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.73799

Cumulative Model Updates: 86,086
Cumulative Timesteps: 717,982,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,405.46654
Policy Entropy: 3.64930
Value Function Loss: 0.07743

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.59139
Value Function Update Magnitude: 0.80204

Collected Steps per Second: 22,571.44193
Overall Steps per Second: 10,797.48739

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.41600
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.63163

Cumulative Model Updates: 86,092
Cumulative Timesteps: 718,032,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 718032190...
Checkpoint 718032190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,524.79101
Policy Entropy: 3.63635
Value Function Loss: 0.07823

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15642
Policy Update Magnitude: 0.47370
Value Function Update Magnitude: 0.81738

Collected Steps per Second: 22,860.32963
Overall Steps per Second: 10,739.62380

Timestep Collection Time: 2.18833
Timestep Consumption Time: 2.46975
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.65808

Cumulative Model Updates: 86,098
Cumulative Timesteps: 718,082,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,486.84029
Policy Entropy: 3.63153
Value Function Loss: 0.07742

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.39963
Value Function Update Magnitude: 0.83629

Collected Steps per Second: 22,910.66389
Overall Steps per Second: 10,710.67684

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.66973

Cumulative Model Updates: 86,104
Cumulative Timesteps: 718,132,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 718132232...
Checkpoint 718132232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.74694
Policy Entropy: 3.63398
Value Function Loss: 0.07640

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.40009
Value Function Update Magnitude: 0.76693

Collected Steps per Second: 22,875.61669
Overall Steps per Second: 10,837.43099

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.42849
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61475

Cumulative Model Updates: 86,110
Cumulative Timesteps: 718,182,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,975.77938
Policy Entropy: 3.64870
Value Function Loss: 0.07511

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.45289
Value Function Update Magnitude: 0.68474

Collected Steps per Second: 22,640.68897
Overall Steps per Second: 10,616.02629

Timestep Collection Time: 2.21045
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.71419

Cumulative Model Updates: 86,116
Cumulative Timesteps: 718,232,290

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 718232290...
Checkpoint 718232290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,268.60426
Policy Entropy: 3.66513
Value Function Loss: 0.07086

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.43460
Value Function Update Magnitude: 0.75666

Collected Steps per Second: 22,957.83388
Overall Steps per Second: 10,726.61825

Timestep Collection Time: 2.17834
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.66223

Cumulative Model Updates: 86,122
Cumulative Timesteps: 718,282,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,525.40411
Policy Entropy: 3.67093
Value Function Loss: 0.06698

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.46838
Value Function Update Magnitude: 0.78969

Collected Steps per Second: 22,917.25703
Overall Steps per Second: 10,721.01713

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.66486

Cumulative Model Updates: 86,128
Cumulative Timesteps: 718,332,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 718332312...
Checkpoint 718332312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,910.12076
Policy Entropy: 3.68825
Value Function Loss: 0.06248

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.48667
Value Function Update Magnitude: 0.77031

Collected Steps per Second: 22,448.95623
Overall Steps per Second: 10,648.89888

Timestep Collection Time: 2.22772
Timestep Consumption Time: 2.46854
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.69626

Cumulative Model Updates: 86,134
Cumulative Timesteps: 718,382,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,766.19422
Policy Entropy: 3.67116
Value Function Loss: 0.06217

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.52783
Value Function Update Magnitude: 0.78299

Collected Steps per Second: 22,333.41255
Overall Steps per Second: 10,647.19025

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.45836
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69814

Cumulative Model Updates: 86,140
Cumulative Timesteps: 718,432,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 718432344...
Checkpoint 718432344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.62072
Policy Entropy: 3.67545
Value Function Loss: 0.06025

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.51415
Value Function Update Magnitude: 0.74718

Collected Steps per Second: 22,596.41951
Overall Steps per Second: 10,773.41287

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.64217

Cumulative Model Updates: 86,146
Cumulative Timesteps: 718,482,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,394.26678
Policy Entropy: 3.68306
Value Function Loss: 0.05694

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.50903
Value Function Update Magnitude: 0.74859

Collected Steps per Second: 22,326.89757
Overall Steps per Second: 10,560.20014

Timestep Collection Time: 2.23990
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.73571

Cumulative Model Updates: 86,152
Cumulative Timesteps: 718,532,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 718532366...
Checkpoint 718532366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,606.53373
Policy Entropy: 3.69853
Value Function Loss: 0.05396

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.65779
Value Function Update Magnitude: 0.74516

Collected Steps per Second: 22,616.68796
Overall Steps per Second: 10,639.43018

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70232

Cumulative Model Updates: 86,158
Cumulative Timesteps: 718,582,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,276.02881
Policy Entropy: 3.70968
Value Function Loss: 0.05236

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.72833
Value Function Update Magnitude: 0.76604

Collected Steps per Second: 20,438.73968
Overall Steps per Second: 9,926.79022

Timestep Collection Time: 2.44653
Timestep Consumption Time: 2.59075
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 5.03728

Cumulative Model Updates: 86,164
Cumulative Timesteps: 718,632,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 718632400...
Checkpoint 718632400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.28778
Policy Entropy: 3.70292
Value Function Loss: 0.05169

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.63697
Value Function Update Magnitude: 0.78215

Collected Steps per Second: 21,610.17440
Overall Steps per Second: 10,318.35391

Timestep Collection Time: 2.31511
Timestep Consumption Time: 2.53353
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.84864

Cumulative Model Updates: 86,170
Cumulative Timesteps: 718,682,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,965.18528
Policy Entropy: 3.70650
Value Function Loss: 0.05231

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.60478
Value Function Update Magnitude: 0.77264

Collected Steps per Second: 22,600.28634
Overall Steps per Second: 10,579.72014

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.51457
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.72772

Cumulative Model Updates: 86,176
Cumulative Timesteps: 718,732,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 718732448...
Checkpoint 718732448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,067.77927
Policy Entropy: 3.70509
Value Function Loss: 0.05294

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.60903
Value Function Update Magnitude: 0.77533

Collected Steps per Second: 23,249.29442
Overall Steps per Second: 10,922.11579

Timestep Collection Time: 2.15060
Timestep Consumption Time: 2.42726
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.57787

Cumulative Model Updates: 86,182
Cumulative Timesteps: 718,782,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.92442
Policy Entropy: 3.70338
Value Function Loss: 0.05429

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.67072
Value Function Update Magnitude: 0.78410

Collected Steps per Second: 22,988.59664
Overall Steps per Second: 10,690.85131

Timestep Collection Time: 2.17508
Timestep Consumption Time: 2.50200
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67708

Cumulative Model Updates: 86,188
Cumulative Timesteps: 718,832,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 718832450...
Checkpoint 718832450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,752.82732
Policy Entropy: 3.69864
Value Function Loss: 0.05494

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.74011
Value Function Update Magnitude: 0.78603

Collected Steps per Second: 22,879.36937
Overall Steps per Second: 10,834.21483

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.43080
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61722

Cumulative Model Updates: 86,194
Cumulative Timesteps: 718,882,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.60926
Policy Entropy: 3.70875
Value Function Loss: 0.05450

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07142
Policy Update Magnitude: 0.75850
Value Function Update Magnitude: 0.77277

Collected Steps per Second: 22,941.81998
Overall Steps per Second: 10,677.31671

Timestep Collection Time: 2.17960
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.68320

Cumulative Model Updates: 86,200
Cumulative Timesteps: 718,932,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 718932478...
Checkpoint 718932478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.83141
Policy Entropy: 3.72598
Value Function Loss: 0.05660

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.73391
Value Function Update Magnitude: 0.77432

Collected Steps per Second: 22,928.81252
Overall Steps per Second: 10,726.19753

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.66409

Cumulative Model Updates: 86,206
Cumulative Timesteps: 718,982,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.12605
Policy Entropy: 3.71650
Value Function Loss: 0.05806

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.61956
Value Function Update Magnitude: 0.77114

Collected Steps per Second: 22,547.52510
Overall Steps per Second: 10,748.77226

Timestep Collection Time: 2.21878
Timestep Consumption Time: 2.43552
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.65430

Cumulative Model Updates: 86,212
Cumulative Timesteps: 719,032,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 719032534...
Checkpoint 719032534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,618.60514
Policy Entropy: 3.69977
Value Function Loss: 0.06218

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.59061
Value Function Update Magnitude: 0.77995

Collected Steps per Second: 22,222.22913
Overall Steps per Second: 10,595.65614

Timestep Collection Time: 2.25090
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.72080

Cumulative Model Updates: 86,218
Cumulative Timesteps: 719,082,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,955.45005
Policy Entropy: 3.69155
Value Function Loss: 0.06241

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.64503
Value Function Update Magnitude: 0.81671

Collected Steps per Second: 22,667.59616
Overall Steps per Second: 10,659.93391

Timestep Collection Time: 2.20579
Timestep Consumption Time: 2.48467
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69046

Cumulative Model Updates: 86,224
Cumulative Timesteps: 719,132,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 719132554...
Checkpoint 719132554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,749.92132
Policy Entropy: 3.68541
Value Function Loss: 0.06846

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06920
Policy Update Magnitude: 0.78182
Value Function Update Magnitude: 0.84967

Collected Steps per Second: 22,379.76649
Overall Steps per Second: 10,582.86031

Timestep Collection Time: 2.23425
Timestep Consumption Time: 2.49056
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72481

Cumulative Model Updates: 86,230
Cumulative Timesteps: 719,182,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,911.28516
Policy Entropy: 3.67862
Value Function Loss: 0.06995

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.77595
Value Function Update Magnitude: 0.85792

Collected Steps per Second: 22,896.39015
Overall Steps per Second: 10,735.63439

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.47413
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.65832

Cumulative Model Updates: 86,236
Cumulative Timesteps: 719,232,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 719232566...
Checkpoint 719232566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.40762
Policy Entropy: 3.66910
Value Function Loss: 0.07149

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.66941
Value Function Update Magnitude: 0.84612

Collected Steps per Second: 23,020.73584
Overall Steps per Second: 10,638.18402

Timestep Collection Time: 2.17195
Timestep Consumption Time: 2.52810
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.70005

Cumulative Model Updates: 86,242
Cumulative Timesteps: 719,282,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,821.27254
Policy Entropy: 3.66943
Value Function Loss: 0.07074

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.65724
Value Function Update Magnitude: 0.74510

Collected Steps per Second: 23,200.87771
Overall Steps per Second: 10,895.79325

Timestep Collection Time: 2.15552
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.58984

Cumulative Model Updates: 86,248
Cumulative Timesteps: 719,332,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 719332576...
Checkpoint 719332576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,837.79672
Policy Entropy: 3.67053
Value Function Loss: 0.07096

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.59635
Value Function Update Magnitude: 0.67112

Collected Steps per Second: 22,676.84110
Overall Steps per Second: 10,689.60406

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.67913

Cumulative Model Updates: 86,254
Cumulative Timesteps: 719,382,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,960.68065
Policy Entropy: 3.68744
Value Function Loss: 0.07086

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.59219
Value Function Update Magnitude: 0.71417

Collected Steps per Second: 22,664.11551
Overall Steps per Second: 10,623.63062

Timestep Collection Time: 2.20622
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70668

Cumulative Model Updates: 86,260
Cumulative Timesteps: 719,432,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 719432596...
Checkpoint 719432596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,214.33132
Policy Entropy: 3.68493
Value Function Loss: 0.07098

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.62898
Value Function Update Magnitude: 0.71976

Collected Steps per Second: 22,707.58663
Overall Steps per Second: 10,751.85647

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.44914
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.65166

Cumulative Model Updates: 86,266
Cumulative Timesteps: 719,482,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,477.11916
Policy Entropy: 3.68748
Value Function Loss: 0.07171

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.61925
Value Function Update Magnitude: 0.77125

Collected Steps per Second: 22,687.58139
Overall Steps per Second: 10,629.59936

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.50270
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.70893

Cumulative Model Updates: 86,272
Cumulative Timesteps: 719,532,664

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 719532664...
Checkpoint 719532664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,477.49465
Policy Entropy: 3.67814
Value Function Loss: 0.07194

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.81516

Collected Steps per Second: 22,618.12739
Overall Steps per Second: 10,605.72040

Timestep Collection Time: 2.21115
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.71557

Cumulative Model Updates: 86,278
Cumulative Timesteps: 719,582,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,893.84023
Policy Entropy: 3.67698
Value Function Loss: 0.07294

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.63986
Value Function Update Magnitude: 0.86792

Collected Steps per Second: 22,675.12316
Overall Steps per Second: 10,658.82675

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.48639
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.69189

Cumulative Model Updates: 86,284
Cumulative Timesteps: 719,632,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 719632686...
Checkpoint 719632686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,328.16863
Policy Entropy: 3.67475
Value Function Loss: 0.07173

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.60257
Value Function Update Magnitude: 0.88275

Collected Steps per Second: 22,765.78418
Overall Steps per Second: 10,791.33454

Timestep Collection Time: 2.19645
Timestep Consumption Time: 2.43726
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.63372

Cumulative Model Updates: 86,290
Cumulative Timesteps: 719,682,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,293.70299
Policy Entropy: 3.66859
Value Function Loss: 0.07281

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.63630
Value Function Update Magnitude: 0.88203

Collected Steps per Second: 22,431.31883
Overall Steps per Second: 10,537.90454

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.74535

Cumulative Model Updates: 86,296
Cumulative Timesteps: 719,732,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 719732696...
Checkpoint 719732696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.16521
Policy Entropy: 3.67709
Value Function Loss: 0.07227

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.58146
Value Function Update Magnitude: 0.87642

Collected Steps per Second: 22,958.21919
Overall Steps per Second: 10,681.55510

Timestep Collection Time: 2.17865
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.68265

Cumulative Model Updates: 86,302
Cumulative Timesteps: 719,782,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,296.25751
Policy Entropy: 3.68409
Value Function Loss: 0.07456

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.84938

Collected Steps per Second: 22,970.53543
Overall Steps per Second: 10,794.96195

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.45646
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.63438

Cumulative Model Updates: 86,308
Cumulative Timesteps: 719,832,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 719832742...
Checkpoint 719832742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,186.32697
Policy Entropy: 3.70123
Value Function Loss: 0.07354

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.78202

Collected Steps per Second: 22,163.74355
Overall Steps per Second: 10,655.85757

Timestep Collection Time: 2.25693
Timestep Consumption Time: 2.43739
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.69432

Cumulative Model Updates: 86,314
Cumulative Timesteps: 719,882,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,079.15105
Policy Entropy: 3.68163
Value Function Loss: 0.07268

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.69191
Value Function Update Magnitude: 0.77133

Collected Steps per Second: 22,854.09972
Overall Steps per Second: 10,646.07069

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.69694

Cumulative Model Updates: 86,320
Cumulative Timesteps: 719,932,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 719932768...
Checkpoint 719932768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,704.97408
Policy Entropy: 3.68221
Value Function Loss: 0.07383

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.71868
Value Function Update Magnitude: 0.80659

Collected Steps per Second: 22,352.40199
Overall Steps per Second: 10,541.58838

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.50773
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.74596

Cumulative Model Updates: 86,326
Cumulative Timesteps: 719,982,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,299.72229
Policy Entropy: 3.68950
Value Function Loss: 0.07393

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.20375
Policy Update Magnitude: 0.57459
Value Function Update Magnitude: 0.80801

Collected Steps per Second: 22,426.29889
Overall Steps per Second: 10,516.52319

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.52631
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.75709

Cumulative Model Updates: 86,332
Cumulative Timesteps: 720,032,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 720032826...
Checkpoint 720032826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,129.09625
Policy Entropy: 3.70288
Value Function Loss: 0.07640

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.59672
Value Function Update Magnitude: 0.82677

Collected Steps per Second: 22,888.17746
Overall Steps per Second: 10,677.70156

Timestep Collection Time: 2.18462
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.68284

Cumulative Model Updates: 86,338
Cumulative Timesteps: 720,082,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,364.78074
Policy Entropy: 3.68747
Value Function Loss: 0.07789

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.15925
Policy Update Magnitude: 0.64067
Value Function Update Magnitude: 0.79963

Collected Steps per Second: 22,844.30350
Overall Steps per Second: 10,787.78130

Timestep Collection Time: 2.18952
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.63654

Cumulative Model Updates: 86,344
Cumulative Timesteps: 720,132,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 720132846...
Checkpoint 720132846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,360.67277
Policy Entropy: 3.66993
Value Function Loss: 0.07847

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.16403
Policy Update Magnitude: 0.50632
Value Function Update Magnitude: 0.77716

Collected Steps per Second: 22,815.72753
Overall Steps per Second: 10,657.23372

Timestep Collection Time: 2.19226
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.69334

Cumulative Model Updates: 86,350
Cumulative Timesteps: 720,182,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.13850
Policy Entropy: 3.67537
Value Function Loss: 0.07715

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11247
Policy Update Magnitude: 0.47089
Value Function Update Magnitude: 0.75900

Collected Steps per Second: 22,949.64972
Overall Steps per Second: 10,797.65048

Timestep Collection Time: 2.17999
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.63342

Cumulative Model Updates: 86,356
Cumulative Timesteps: 720,232,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 720232894...
Checkpoint 720232894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,438.92072
Policy Entropy: 3.67029
Value Function Loss: 0.07776

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.58982
Value Function Update Magnitude: 0.70082

Collected Steps per Second: 22,447.09209
Overall Steps per Second: 10,718.26314

Timestep Collection Time: 2.22808
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.66624

Cumulative Model Updates: 86,362
Cumulative Timesteps: 720,282,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,309.13592
Policy Entropy: 3.66839
Value Function Loss: 0.07831

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.62726
Value Function Update Magnitude: 0.67939

Collected Steps per Second: 23,070.79921
Overall Steps per Second: 10,878.55630

Timestep Collection Time: 2.16794
Timestep Consumption Time: 2.42973
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.59767

Cumulative Model Updates: 86,368
Cumulative Timesteps: 720,332,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 720332924...
Checkpoint 720332924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,428.62252
Policy Entropy: 3.66457
Value Function Loss: 0.07818

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.59444
Value Function Update Magnitude: 0.70951

Collected Steps per Second: 22,328.27401
Overall Steps per Second: 10,733.55085

Timestep Collection Time: 2.24048
Timestep Consumption Time: 2.42024
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.66071

Cumulative Model Updates: 86,374
Cumulative Timesteps: 720,382,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,138.01303
Policy Entropy: 3.66882
Value Function Loss: 0.07296

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.60314
Value Function Update Magnitude: 0.78048

Collected Steps per Second: 22,449.08834
Overall Steps per Second: 10,568.66287

Timestep Collection Time: 2.22762
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.73172

Cumulative Model Updates: 86,380
Cumulative Timesteps: 720,432,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 720432958...
Checkpoint 720432958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,650.16620
Policy Entropy: 3.67524
Value Function Loss: 0.06989

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.57955
Value Function Update Magnitude: 0.82267

Collected Steps per Second: 22,129.97637
Overall Steps per Second: 10,423.00425

Timestep Collection Time: 2.25947
Timestep Consumption Time: 2.53780
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.79727

Cumulative Model Updates: 86,386
Cumulative Timesteps: 720,482,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,471.98805
Policy Entropy: 3.68405
Value Function Loss: 0.06818

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.60000
Value Function Update Magnitude: 0.82688

Collected Steps per Second: 22,589.10904
Overall Steps per Second: 10,616.29900

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.49668
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.71049

Cumulative Model Updates: 86,392
Cumulative Timesteps: 720,532,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 720532968...
Checkpoint 720532968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,158.55145
Policy Entropy: 3.67340
Value Function Loss: 0.07014

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.66180
Value Function Update Magnitude: 0.80759

Collected Steps per Second: 22,748.28031
Overall Steps per Second: 10,666.67600

Timestep Collection Time: 2.19823
Timestep Consumption Time: 2.48983
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.68806

Cumulative Model Updates: 86,398
Cumulative Timesteps: 720,582,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,362.63892
Policy Entropy: 3.66476
Value Function Loss: 0.07435

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.61639
Value Function Update Magnitude: 0.77382

Collected Steps per Second: 22,744.35616
Overall Steps per Second: 10,728.90487

Timestep Collection Time: 2.19844
Timestep Consumption Time: 2.46206
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.66049

Cumulative Model Updates: 86,404
Cumulative Timesteps: 720,632,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 720632976...
Checkpoint 720632976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,267.53308
Policy Entropy: 3.66865
Value Function Loss: 0.07632

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.85577

Collected Steps per Second: 22,801.33368
Overall Steps per Second: 10,645.47807

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.50408
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.69702

Cumulative Model Updates: 86,410
Cumulative Timesteps: 720,682,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,083.44954
Policy Entropy: 3.67810
Value Function Loss: 0.07508

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.55176
Value Function Update Magnitude: 0.89786

Collected Steps per Second: 23,094.78098
Overall Steps per Second: 10,890.09907

Timestep Collection Time: 2.16620
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59390

Cumulative Model Updates: 86,416
Cumulative Timesteps: 720,733,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 720733006...
Checkpoint 720733006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,328.34782
Policy Entropy: 3.68317
Value Function Loss: 0.07569

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.62524
Value Function Update Magnitude: 0.82128

Collected Steps per Second: 22,005.82012
Overall Steps per Second: 10,748.53291

Timestep Collection Time: 2.27322
Timestep Consumption Time: 2.38081
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.65403

Cumulative Model Updates: 86,422
Cumulative Timesteps: 720,783,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,612.59563
Policy Entropy: 3.67859
Value Function Loss: 0.07625

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.58723
Value Function Update Magnitude: 0.74151

Collected Steps per Second: 22,367.01843
Overall Steps per Second: 10,849.07502

Timestep Collection Time: 2.23651
Timestep Consumption Time: 2.37439
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61090

Cumulative Model Updates: 86,428
Cumulative Timesteps: 720,833,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 720833054...
Checkpoint 720833054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,784.10023
Policy Entropy: 3.65915
Value Function Loss: 0.07607

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.51338
Value Function Update Magnitude: 0.73808

Collected Steps per Second: 22,140.88945
Overall Steps per Second: 10,676.87184

Timestep Collection Time: 2.25917
Timestep Consumption Time: 2.42572
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68489

Cumulative Model Updates: 86,434
Cumulative Timesteps: 720,883,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,165.64354
Policy Entropy: 3.66421
Value Function Loss: 0.07316

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.72442

Collected Steps per Second: 21,991.62881
Overall Steps per Second: 10,665.59119

Timestep Collection Time: 2.27423
Timestep Consumption Time: 2.41506
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.68929

Cumulative Model Updates: 86,440
Cumulative Timesteps: 720,933,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 720933088...
Checkpoint 720933088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,425.91447
Policy Entropy: 3.64997
Value Function Loss: 0.07280

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.58163
Value Function Update Magnitude: 0.73310

Collected Steps per Second: 21,925.32692
Overall Steps per Second: 10,635.64311

Timestep Collection Time: 2.28092
Timestep Consumption Time: 2.42119
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.70211

Cumulative Model Updates: 86,446
Cumulative Timesteps: 720,983,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.27831
Policy Entropy: 3.64752
Value Function Loss: 0.07428

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.72264

Collected Steps per Second: 22,154.06231
Overall Steps per Second: 10,686.36209

Timestep Collection Time: 2.25819
Timestep Consumption Time: 2.42329
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.68148

Cumulative Model Updates: 86,452
Cumulative Timesteps: 721,033,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 721033126...
Checkpoint 721033126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,331.75422
Policy Entropy: 3.65101
Value Function Loss: 0.07665

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.63210
Value Function Update Magnitude: 0.72849

Collected Steps per Second: 22,363.59724
Overall Steps per Second: 10,649.66333

Timestep Collection Time: 2.23587
Timestep Consumption Time: 2.45931
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69517

Cumulative Model Updates: 86,458
Cumulative Timesteps: 721,083,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,960.00160
Policy Entropy: 3.66612
Value Function Loss: 0.07522

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.60849
Value Function Update Magnitude: 0.69681

Collected Steps per Second: 22,756.04199
Overall Steps per Second: 10,698.28092

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.67458

Cumulative Model Updates: 86,464
Cumulative Timesteps: 721,133,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721133138...
Checkpoint 721133138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.44366
Policy Entropy: 3.67356
Value Function Loss: 0.07491

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.65916
Value Function Update Magnitude: 0.68842

Collected Steps per Second: 22,794.94983
Overall Steps per Second: 10,854.14480

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.41355
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.60746

Cumulative Model Updates: 86,470
Cumulative Timesteps: 721,183,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,110.18176
Policy Entropy: 3.67089
Value Function Loss: 0.07422

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.71739
Value Function Update Magnitude: 0.76237

Collected Steps per Second: 23,086.62381
Overall Steps per Second: 10,939.03774

Timestep Collection Time: 2.16645
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.57225

Cumulative Model Updates: 86,476
Cumulative Timesteps: 721,233,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 721233164...
Checkpoint 721233164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,615.48516
Policy Entropy: 3.65959
Value Function Loss: 0.07205

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.64271
Value Function Update Magnitude: 0.85490

Collected Steps per Second: 22,926.31297
Overall Steps per Second: 10,684.25248

Timestep Collection Time: 2.18169
Timestep Consumption Time: 2.49978
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.68147

Cumulative Model Updates: 86,482
Cumulative Timesteps: 721,283,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,577.26987
Policy Entropy: 3.64178
Value Function Loss: 0.07495

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.64352
Value Function Update Magnitude: 0.84980

Collected Steps per Second: 22,871.16887
Overall Steps per Second: 10,816.00839

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.43769
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.62481

Cumulative Model Updates: 86,488
Cumulative Timesteps: 721,333,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 721333204...
Checkpoint 721333204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,626.64240
Policy Entropy: 3.63288
Value Function Loss: 0.07476

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.70050
Value Function Update Magnitude: 0.78255

Collected Steps per Second: 22,712.65754
Overall Steps per Second: 10,667.61907

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.48626
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.68821

Cumulative Model Updates: 86,494
Cumulative Timesteps: 721,383,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,523.65091
Policy Entropy: 3.63666
Value Function Loss: 0.07425

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.61766
Value Function Update Magnitude: 0.77825

Collected Steps per Second: 22,659.71138
Overall Steps per Second: 10,655.20610

Timestep Collection Time: 2.20665
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.69273

Cumulative Model Updates: 86,500
Cumulative Timesteps: 721,433,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 721433218...
Checkpoint 721433218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,439.87700
Policy Entropy: 3.64051
Value Function Loss: 0.07309

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.54652
Value Function Update Magnitude: 0.84675

Collected Steps per Second: 22,586.97986
Overall Steps per Second: 10,765.72952

Timestep Collection Time: 2.21366
Timestep Consumption Time: 2.43070
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.64437

Cumulative Model Updates: 86,506
Cumulative Timesteps: 721,483,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,581.97411
Policy Entropy: 3.63416
Value Function Loss: 0.07648

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.51859
Value Function Update Magnitude: 0.80268

Collected Steps per Second: 22,884.72973
Overall Steps per Second: 10,652.63878

Timestep Collection Time: 2.18539
Timestep Consumption Time: 2.50941
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.69480

Cumulative Model Updates: 86,512
Cumulative Timesteps: 721,533,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 721533230...
Checkpoint 721533230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.24965
Policy Entropy: 3.63298
Value Function Loss: 0.07646

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.58808
Value Function Update Magnitude: 0.74890

Collected Steps per Second: 23,048.28579
Overall Steps per Second: 10,690.85544

Timestep Collection Time: 2.17014
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.67858

Cumulative Model Updates: 86,518
Cumulative Timesteps: 721,583,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,278.06068
Policy Entropy: 3.63684
Value Function Loss: 0.07842

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.63027
Value Function Update Magnitude: 0.71858

Collected Steps per Second: 23,088.88181
Overall Steps per Second: 10,707.83468

Timestep Collection Time: 2.16572
Timestep Consumption Time: 2.50413
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.66985

Cumulative Model Updates: 86,524
Cumulative Timesteps: 721,633,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 721633252...
Checkpoint 721633252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,658.94338
Policy Entropy: 3.64850
Value Function Loss: 0.07816

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.77660

Collected Steps per Second: 22,910.80163
Overall Steps per Second: 10,663.68301

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68937

Cumulative Model Updates: 86,530
Cumulative Timesteps: 721,683,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,120.08380
Policy Entropy: 3.64694
Value Function Loss: 0.07770

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.46650
Value Function Update Magnitude: 0.78914

Collected Steps per Second: 22,736.90778
Overall Steps per Second: 10,655.24723

Timestep Collection Time: 2.20030
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.69515

Cumulative Model Updates: 86,536
Cumulative Timesteps: 721,733,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 721733286...
Checkpoint 721733286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,369.88988
Policy Entropy: 3.64452
Value Function Loss: 0.07457

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.51464
Value Function Update Magnitude: 0.79978

Collected Steps per Second: 21,889.46686
Overall Steps per Second: 10,440.27326

Timestep Collection Time: 2.28548
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.79183

Cumulative Model Updates: 86,542
Cumulative Timesteps: 721,783,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.66880
Policy Entropy: 3.64158
Value Function Loss: 0.07554

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.59543
Value Function Update Magnitude: 0.79981

Collected Steps per Second: 23,123.58765
Overall Steps per Second: 10,863.15013

Timestep Collection Time: 2.16359
Timestep Consumption Time: 2.44189
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60548

Cumulative Model Updates: 86,548
Cumulative Timesteps: 721,833,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 721833344...
Checkpoint 721833344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,706.24295
Policy Entropy: 3.65131
Value Function Loss: 0.07791

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.63422
Value Function Update Magnitude: 0.72503

Collected Steps per Second: 22,775.82313
Overall Steps per Second: 10,709.30426

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.47560
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.67276

Cumulative Model Updates: 86,554
Cumulative Timesteps: 721,883,386

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,901.13326
Policy Entropy: 3.65569
Value Function Loss: 0.07908

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.62448
Value Function Update Magnitude: 0.75278

Collected Steps per Second: 22,418.15926
Overall Steps per Second: 10,577.35505

Timestep Collection Time: 2.23123
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72897

Cumulative Model Updates: 86,560
Cumulative Timesteps: 721,933,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 721933406...
Checkpoint 721933406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,892.04831
Policy Entropy: 3.65941
Value Function Loss: 0.07789

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.80567

Collected Steps per Second: 22,528.49550
Overall Steps per Second: 10,601.20588

Timestep Collection Time: 2.22021
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.71814

Cumulative Model Updates: 86,566
Cumulative Timesteps: 721,983,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.46668
Policy Entropy: 3.64369
Value Function Loss: 0.08159

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.75465

Collected Steps per Second: 22,649.38283
Overall Steps per Second: 10,751.13861

Timestep Collection Time: 2.20854
Timestep Consumption Time: 2.44418
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.65272

Cumulative Model Updates: 86,572
Cumulative Timesteps: 722,033,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 722033446...
Checkpoint 722033446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,010.99539
Policy Entropy: 3.63336
Value Function Loss: 0.08534

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.49183
Value Function Update Magnitude: 0.66399

Collected Steps per Second: 22,182.52197
Overall Steps per Second: 10,646.40023

Timestep Collection Time: 2.25529
Timestep Consumption Time: 2.44376
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.69905

Cumulative Model Updates: 86,578
Cumulative Timesteps: 722,083,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,425.14945
Policy Entropy: 3.62924
Value Function Loss: 0.08486

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.47593
Value Function Update Magnitude: 0.62944

Collected Steps per Second: 22,743.35927
Overall Steps per Second: 10,561.67144

Timestep Collection Time: 2.19862
Timestep Consumption Time: 2.53586
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.73448

Cumulative Model Updates: 86,584
Cumulative Timesteps: 722,133,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 722133478...
Checkpoint 722133478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,685.40928
Policy Entropy: 3.62502
Value Function Loss: 0.08257

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.42947
Value Function Update Magnitude: 0.59066

Collected Steps per Second: 22,741.26080
Overall Steps per Second: 10,618.38946

Timestep Collection Time: 2.19944
Timestep Consumption Time: 2.51107
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.71051

Cumulative Model Updates: 86,590
Cumulative Timesteps: 722,183,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,287.70301
Policy Entropy: 3.63436
Value Function Loss: 0.08046

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.42036
Value Function Update Magnitude: 0.60435

Collected Steps per Second: 22,676.76752
Overall Steps per Second: 10,766.93697

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.64812

Cumulative Model Updates: 86,596
Cumulative Timesteps: 722,233,542

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 722233542...
Checkpoint 722233542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,087.24939
Policy Entropy: 3.64635
Value Function Loss: 0.08008

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.41874
Value Function Update Magnitude: 0.63534

Collected Steps per Second: 22,635.75298
Overall Steps per Second: 10,793.01962

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.63485

Cumulative Model Updates: 86,602
Cumulative Timesteps: 722,283,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,754.33049
Policy Entropy: 3.64760
Value Function Loss: 0.07695

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.42292
Value Function Update Magnitude: 0.79919

Collected Steps per Second: 22,926.05132
Overall Steps per Second: 10,815.45382

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.44297
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62468

Cumulative Model Updates: 86,608
Cumulative Timesteps: 722,333,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 722333584...
Checkpoint 722333584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,411.99521
Policy Entropy: 3.64650
Value Function Loss: 0.07340

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.43640
Value Function Update Magnitude: 0.86666

Collected Steps per Second: 22,568.92178
Overall Steps per Second: 10,717.70056

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.66817

Cumulative Model Updates: 86,614
Cumulative Timesteps: 722,383,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.46900
Policy Entropy: 3.64785
Value Function Loss: 0.07070

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.44292
Value Function Update Magnitude: 0.79653

Collected Steps per Second: 22,925.68936
Overall Steps per Second: 10,809.49965

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.62556

Cumulative Model Updates: 86,620
Cumulative Timesteps: 722,433,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 722433616...
Checkpoint 722433616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,504.89340
Policy Entropy: 3.67121
Value Function Loss: 0.06529

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.45364
Value Function Update Magnitude: 0.76032

Collected Steps per Second: 22,449.97244
Overall Steps per Second: 10,752.09466

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.42328
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.65063

Cumulative Model Updates: 86,626
Cumulative Timesteps: 722,483,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.85659
Policy Entropy: 3.66492
Value Function Loss: 0.06227

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.49342
Value Function Update Magnitude: 0.80922

Collected Steps per Second: 22,045.44894
Overall Steps per Second: 10,810.42824

Timestep Collection Time: 2.26840
Timestep Consumption Time: 2.35750
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.62590

Cumulative Model Updates: 86,632
Cumulative Timesteps: 722,533,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 722533628...
Checkpoint 722533628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,907.29297
Policy Entropy: 3.67650
Value Function Loss: 0.05976

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.54365
Value Function Update Magnitude: 0.79847

Collected Steps per Second: 21,332.04010
Overall Steps per Second: 10,637.07175

Timestep Collection Time: 2.34492
Timestep Consumption Time: 2.35769
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.70261

Cumulative Model Updates: 86,638
Cumulative Timesteps: 722,583,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,573.03404
Policy Entropy: 3.67375
Value Function Loss: 0.06019

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.52424
Value Function Update Magnitude: 0.78782

Collected Steps per Second: 21,725.81936
Overall Steps per Second: 10,518.42779

Timestep Collection Time: 2.30178
Timestep Consumption Time: 2.45255
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.75432

Cumulative Model Updates: 86,644
Cumulative Timesteps: 722,633,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 722633658...
Checkpoint 722633658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,424.69657
Policy Entropy: 3.69594
Value Function Loss: 0.05659

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.77126

Collected Steps per Second: 21,911.80379
Overall Steps per Second: 10,634.86902

Timestep Collection Time: 2.28270
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.70321

Cumulative Model Updates: 86,650
Cumulative Timesteps: 722,683,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,910.04504
Policy Entropy: 3.68793
Value Function Loss: 0.05750

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.62719
Value Function Update Magnitude: 0.76710

Collected Steps per Second: 22,264.35577
Overall Steps per Second: 10,828.26506

Timestep Collection Time: 2.24619
Timestep Consumption Time: 2.37228
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.61847

Cumulative Model Updates: 86,656
Cumulative Timesteps: 722,733,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 722733686...
Checkpoint 722733686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,945.63511
Policy Entropy: 3.68860
Value Function Loss: 0.06002

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.77919

Collected Steps per Second: 21,889.23804
Overall Steps per Second: 10,708.43281

Timestep Collection Time: 2.28459
Timestep Consumption Time: 2.38537
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.66996

Cumulative Model Updates: 86,662
Cumulative Timesteps: 722,783,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561.30023
Policy Entropy: 3.68225
Value Function Loss: 0.06165

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.78013

Collected Steps per Second: 22,391.43037
Overall Steps per Second: 10,607.98296

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.71494

Cumulative Model Updates: 86,668
Cumulative Timesteps: 722,833,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 722833710...
Checkpoint 722833710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,967.36165
Policy Entropy: 3.68590
Value Function Loss: 0.06061

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.52826
Value Function Update Magnitude: 0.74090

Collected Steps per Second: 22,694.76650
Overall Steps per Second: 10,852.60969

Timestep Collection Time: 2.20447
Timestep Consumption Time: 2.40548
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60995

Cumulative Model Updates: 86,674
Cumulative Timesteps: 722,883,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.22617
Policy Entropy: 3.69559
Value Function Loss: 0.05895

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.55799
Value Function Update Magnitude: 0.72831

Collected Steps per Second: 22,427.54957
Overall Steps per Second: 10,606.52475

Timestep Collection Time: 2.23065
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.71672

Cumulative Model Updates: 86,680
Cumulative Timesteps: 722,933,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 722933768...
Checkpoint 722933768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,602.52196
Policy Entropy: 3.68955
Value Function Loss: 0.06120

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.70896

Collected Steps per Second: 22,437.44459
Overall Steps per Second: 10,600.03455

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.71923

Cumulative Model Updates: 86,686
Cumulative Timesteps: 722,983,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,106.99063
Policy Entropy: 3.68777
Value Function Loss: 0.06408

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.59650
Value Function Update Magnitude: 0.67968

Collected Steps per Second: 22,751.21014
Overall Steps per Second: 10,692.25033

Timestep Collection Time: 2.19892
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.67890

Cumulative Model Updates: 86,692
Cumulative Timesteps: 723,033,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 723033820...
Checkpoint 723033820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,264.79932
Policy Entropy: 3.68211
Value Function Loss: 0.06694

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.66540
Value Function Update Magnitude: 0.63529

Collected Steps per Second: 22,668.42432
Overall Steps per Second: 10,851.81990

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.40210
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60808

Cumulative Model Updates: 86,698
Cumulative Timesteps: 723,083,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,721.71534
Policy Entropy: 3.68754
Value Function Loss: 0.06684

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.64805

Collected Steps per Second: 22,673.93744
Overall Steps per Second: 10,631.82400

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.49769
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.70286

Cumulative Model Updates: 86,704
Cumulative Timesteps: 723,133,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 723133826...
Checkpoint 723133826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,432.05237
Policy Entropy: 3.69167
Value Function Loss: 0.07110

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.51484
Value Function Update Magnitude: 0.68517

Collected Steps per Second: 22,231.32068
Overall Steps per Second: 10,471.75295

Timestep Collection Time: 2.24971
Timestep Consumption Time: 2.52638
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.77609

Cumulative Model Updates: 86,710
Cumulative Timesteps: 723,183,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,630.45568
Policy Entropy: 3.69651
Value Function Loss: 0.07165

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.70519

Collected Steps per Second: 22,832.53451
Overall Steps per Second: 10,551.39922

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.54946
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.73985

Cumulative Model Updates: 86,716
Cumulative Timesteps: 723,233,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 723233852...
Checkpoint 723233852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,274.17162
Policy Entropy: 3.69535
Value Function Loss: 0.07373

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06754
Policy Update Magnitude: 0.65152
Value Function Update Magnitude: 0.68574

Collected Steps per Second: 22,850.82914
Overall Steps per Second: 10,588.78101

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.53509
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.72425

Cumulative Model Updates: 86,722
Cumulative Timesteps: 723,283,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,133.75550
Policy Entropy: 3.69431
Value Function Loss: 0.07450

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.75644
Value Function Update Magnitude: 0.66740

Collected Steps per Second: 22,943.64391
Overall Steps per Second: 10,842.10240

Timestep Collection Time: 2.17951
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61221

Cumulative Model Updates: 86,728
Cumulative Timesteps: 723,333,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 723333882...
Checkpoint 723333882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.64831
Policy Entropy: 3.68805
Value Function Loss: 0.07675

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.75820
Value Function Update Magnitude: 0.67826

Collected Steps per Second: 23,032.14192
Overall Steps per Second: 10,686.12733

Timestep Collection Time: 2.17114
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.67953

Cumulative Model Updates: 86,734
Cumulative Timesteps: 723,383,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.78093
Policy Entropy: 3.69113
Value Function Loss: 0.07828

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.65913
Value Function Update Magnitude: 0.78680

Collected Steps per Second: 23,036.99713
Overall Steps per Second: 10,833.23815

Timestep Collection Time: 2.17060
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.61579

Cumulative Model Updates: 86,740
Cumulative Timesteps: 723,433,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 723433892...
Checkpoint 723433892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,515.88777
Policy Entropy: 3.67951
Value Function Loss: 0.07861

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.57976
Value Function Update Magnitude: 0.83719

Collected Steps per Second: 23,009.02840
Overall Steps per Second: 10,681.04807

Timestep Collection Time: 2.17332
Timestep Consumption Time: 2.50843
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.68175

Cumulative Model Updates: 86,746
Cumulative Timesteps: 723,483,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,422.76198
Policy Entropy: 3.68540
Value Function Loss: 0.07741

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.52756
Value Function Update Magnitude: 0.79087

Collected Steps per Second: 22,913.27525
Overall Steps per Second: 10,891.52592

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.40935
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59219

Cumulative Model Updates: 86,752
Cumulative Timesteps: 723,533,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 723533914...
Checkpoint 723533914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,810.09923
Policy Entropy: 3.68898
Value Function Loss: 0.07644

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.50489
Value Function Update Magnitude: 0.79405

Collected Steps per Second: 22,718.08893
Overall Steps per Second: 10,660.41726

Timestep Collection Time: 2.20151
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.69156

Cumulative Model Updates: 86,758
Cumulative Timesteps: 723,583,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,085.14613
Policy Entropy: 3.69406
Value Function Loss: 0.07635

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.51872
Value Function Update Magnitude: 0.78042

Collected Steps per Second: 22,535.64220
Overall Steps per Second: 10,618.00274

Timestep Collection Time: 2.21986
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.71143

Cumulative Model Updates: 86,764
Cumulative Timesteps: 723,633,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 723633954...
Checkpoint 723633954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.25013
Policy Entropy: 3.68048
Value Function Loss: 0.07501

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.46652
Value Function Update Magnitude: 0.73180

Collected Steps per Second: 22,677.69928
Overall Steps per Second: 10,571.73751

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.52610
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.73205

Cumulative Model Updates: 86,770
Cumulative Timesteps: 723,683,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,036.34631
Policy Entropy: 3.67378
Value Function Loss: 0.07737

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.50311
Value Function Update Magnitude: 0.66556

Collected Steps per Second: 23,039.55035
Overall Steps per Second: 10,804.68412

Timestep Collection Time: 2.17088
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.62910

Cumulative Model Updates: 86,776
Cumulative Timesteps: 723,733,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 723733996...
Checkpoint 723733996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,705.07002
Policy Entropy: 3.67684
Value Function Loss: 0.07754

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.51294
Value Function Update Magnitude: 0.65858

Collected Steps per Second: 22,821.79055
Overall Steps per Second: 10,634.51199

Timestep Collection Time: 2.19220
Timestep Consumption Time: 2.51229
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.70449

Cumulative Model Updates: 86,782
Cumulative Timesteps: 723,784,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,247.89454
Policy Entropy: 3.68491
Value Function Loss: 0.07810

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.67733

Collected Steps per Second: 22,945.54305
Overall Steps per Second: 10,820.39430

Timestep Collection Time: 2.18029
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62349

Cumulative Model Updates: 86,788
Cumulative Timesteps: 723,834,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 723834054...
Checkpoint 723834054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,016.60765
Policy Entropy: 3.68465
Value Function Loss: 0.07556

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.61420
Value Function Update Magnitude: 0.74191

Collected Steps per Second: 22,506.35086
Overall Steps per Second: 10,743.36462

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.65534

Cumulative Model Updates: 86,794
Cumulative Timesteps: 723,884,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,020.32305
Policy Entropy: 3.68575
Value Function Loss: 0.07440

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.60865
Value Function Update Magnitude: 0.78978

Collected Steps per Second: 22,397.06941
Overall Steps per Second: 10,497.32207

Timestep Collection Time: 2.23333
Timestep Consumption Time: 2.53170
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.76502

Cumulative Model Updates: 86,800
Cumulative Timesteps: 723,934,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 723934088...
Checkpoint 723934088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,213.30273
Policy Entropy: 3.67972
Value Function Loss: 0.07649

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.81345

Collected Steps per Second: 22,414.53780
Overall Steps per Second: 10,620.73848

Timestep Collection Time: 2.23096
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.70834

Cumulative Model Updates: 86,806
Cumulative Timesteps: 723,984,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,150.58788
Policy Entropy: 3.66746
Value Function Loss: 0.07980

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.81683

Collected Steps per Second: 22,710.36881
Overall Steps per Second: 10,656.78015

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.49171
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.69466

Cumulative Model Updates: 86,812
Cumulative Timesteps: 724,034,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 724034124...
Checkpoint 724034124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,068.87439
Policy Entropy: 3.65391
Value Function Loss: 0.07857

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.59078
Value Function Update Magnitude: 0.83939

Collected Steps per Second: 22,998.93305
Overall Steps per Second: 10,793.17517

Timestep Collection Time: 2.17488
Timestep Consumption Time: 2.45953
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.63441

Cumulative Model Updates: 86,818
Cumulative Timesteps: 724,084,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,808.99435
Policy Entropy: 3.65891
Value Function Loss: 0.07720

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.57359
Value Function Update Magnitude: 0.86523

Collected Steps per Second: 22,741.12972
Overall Steps per Second: 10,610.05166

Timestep Collection Time: 2.19892
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.71308

Cumulative Model Updates: 86,824
Cumulative Timesteps: 724,134,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 724134150...
Checkpoint 724134150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,350.85239
Policy Entropy: 3.66422
Value Function Loss: 0.07624

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.86176

Collected Steps per Second: 22,316.32259
Overall Steps per Second: 10,554.03783

Timestep Collection Time: 2.24177
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.74018

Cumulative Model Updates: 86,830
Cumulative Timesteps: 724,184,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,886.48919
Policy Entropy: 3.67501
Value Function Loss: 0.07530

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.68695
Value Function Update Magnitude: 0.87776

Collected Steps per Second: 22,932.16500
Overall Steps per Second: 10,830.24183

Timestep Collection Time: 2.18139
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61892

Cumulative Model Updates: 86,836
Cumulative Timesteps: 724,234,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 724234202...
Checkpoint 724234202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,590.58154
Policy Entropy: 3.67989
Value Function Loss: 0.07567

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.74050
Value Function Update Magnitude: 0.89436

Collected Steps per Second: 22,569.82882
Overall Steps per Second: 10,744.59585

Timestep Collection Time: 2.21544
Timestep Consumption Time: 2.43825
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.65369

Cumulative Model Updates: 86,842
Cumulative Timesteps: 724,284,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,711.70405
Policy Entropy: 3.68639
Value Function Loss: 0.07645

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.70825
Value Function Update Magnitude: 0.84997

Collected Steps per Second: 23,335.85180
Overall Steps per Second: 10,974.00529

Timestep Collection Time: 2.14297
Timestep Consumption Time: 2.41398
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.55695

Cumulative Model Updates: 86,848
Cumulative Timesteps: 724,334,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 724334212...
Checkpoint 724334212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,624.10690
Policy Entropy: 3.68176
Value Function Loss: 0.07672

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.62275
Value Function Update Magnitude: 0.73555

Collected Steps per Second: 22,378.61231
Overall Steps per Second: 10,580.63794

Timestep Collection Time: 2.23508
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.72731

Cumulative Model Updates: 86,854
Cumulative Timesteps: 724,384,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.15956
Policy Entropy: 3.68662
Value Function Loss: 0.07553

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.77679

Collected Steps per Second: 22,562.61756
Overall Steps per Second: 10,597.66963

Timestep Collection Time: 2.21703
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.72009

Cumulative Model Updates: 86,860
Cumulative Timesteps: 724,434,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 724434252...
Checkpoint 724434252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,975.95404
Policy Entropy: 3.69177
Value Function Loss: 0.07674

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.50499
Value Function Update Magnitude: 0.76387

Collected Steps per Second: 22,156.48345
Overall Steps per Second: 10,480.57808

Timestep Collection Time: 2.25695
Timestep Consumption Time: 2.51436
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.77130

Cumulative Model Updates: 86,866
Cumulative Timesteps: 724,484,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,784.52916
Policy Entropy: 3.68314
Value Function Loss: 0.07748

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.53283
Value Function Update Magnitude: 0.73126

Collected Steps per Second: 22,778.56594
Overall Steps per Second: 10,825.44506

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.61893

Cumulative Model Updates: 86,872
Cumulative Timesteps: 724,534,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 724534260...
Checkpoint 724534260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,856.94892
Policy Entropy: 3.68775
Value Function Loss: 0.07651

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.81506

Collected Steps per Second: 22,144.84826
Overall Steps per Second: 10,643.57846

Timestep Collection Time: 2.25795
Timestep Consumption Time: 2.43990
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.69786

Cumulative Model Updates: 86,878
Cumulative Timesteps: 724,584,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,873.74191
Policy Entropy: 3.68812
Value Function Loss: 0.07536

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.55826
Value Function Update Magnitude: 0.76558

Collected Steps per Second: 22,717.53633
Overall Steps per Second: 10,578.82948

Timestep Collection Time: 2.20121
Timestep Consumption Time: 2.52578
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.72699

Cumulative Model Updates: 86,884
Cumulative Timesteps: 724,634,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 724634268...
Checkpoint 724634268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,366.28741
Policy Entropy: 3.68697
Value Function Loss: 0.07622

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.65503
Value Function Update Magnitude: 0.68529

Collected Steps per Second: 22,731.75430
Overall Steps per Second: 10,571.26854

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.73056

Cumulative Model Updates: 86,890
Cumulative Timesteps: 724,684,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,056.62039
Policy Entropy: 3.69081
Value Function Loss: 0.07743

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.74008
Value Function Update Magnitude: 0.64927

Collected Steps per Second: 22,880.17054
Overall Steps per Second: 10,713.60525

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.67014

Cumulative Model Updates: 86,896
Cumulative Timesteps: 724,734,310

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 724734310...
Checkpoint 724734310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,374.65399
Policy Entropy: 3.67585
Value Function Loss: 0.07914

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.66586
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 22,935.20143
Overall Steps per Second: 10,892.87637

Timestep Collection Time: 2.18101
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.59218

Cumulative Model Updates: 86,902
Cumulative Timesteps: 724,784,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,154.95514
Policy Entropy: 3.66648
Value Function Loss: 0.08038

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.59804
Value Function Update Magnitude: 0.60246

Collected Steps per Second: 22,263.27908
Overall Steps per Second: 10,823.15784

Timestep Collection Time: 2.24675
Timestep Consumption Time: 2.37482
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.62157

Cumulative Model Updates: 86,908
Cumulative Timesteps: 724,834,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 724834352...
Checkpoint 724834352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,087.67423
Policy Entropy: 3.65644
Value Function Loss: 0.08228

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.57360
Value Function Update Magnitude: 0.56818

Collected Steps per Second: 22,138.38549
Overall Steps per Second: 10,676.47899

Timestep Collection Time: 2.25915
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.68450

Cumulative Model Updates: 86,914
Cumulative Timesteps: 724,884,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,114.08580
Policy Entropy: 3.65684
Value Function Loss: 0.08216

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.52407
Value Function Update Magnitude: 0.58853

Collected Steps per Second: 21,688.11305
Overall Steps per Second: 10,562.41302

Timestep Collection Time: 2.30633
Timestep Consumption Time: 2.42933
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.73566

Cumulative Model Updates: 86,920
Cumulative Timesteps: 724,934,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 724934386...
Checkpoint 724934386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,318.22193
Policy Entropy: 3.66279
Value Function Loss: 0.07979

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.47558
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 21,655.85584
Overall Steps per Second: 10,572.49098

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.42089
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.73020

Cumulative Model Updates: 86,926
Cumulative Timesteps: 724,984,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,183.22502
Policy Entropy: 3.66445
Value Function Loss: 0.07765

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.51710
Value Function Update Magnitude: 0.65035

Collected Steps per Second: 22,184.28566
Overall Steps per Second: 10,830.05107

Timestep Collection Time: 2.25511
Timestep Consumption Time: 2.36426
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61937

Cumulative Model Updates: 86,932
Cumulative Timesteps: 725,034,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 725034424...
Checkpoint 725034424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,075.50446
Policy Entropy: 3.67680
Value Function Loss: 0.07514

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.49114
Value Function Update Magnitude: 0.64000

Collected Steps per Second: 21,695.59413
Overall Steps per Second: 10,754.11073

Timestep Collection Time: 2.30572
Timestep Consumption Time: 2.34589
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.65162

Cumulative Model Updates: 86,938
Cumulative Timesteps: 725,084,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,616.53292
Policy Entropy: 3.67469
Value Function Loss: 0.07532

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.47029
Value Function Update Magnitude: 0.68743

Collected Steps per Second: 22,248.30466
Overall Steps per Second: 10,542.98524

Timestep Collection Time: 2.24817
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.74420

Cumulative Model Updates: 86,944
Cumulative Timesteps: 725,134,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 725134466...
Checkpoint 725134466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,456.60363
Policy Entropy: 3.67350
Value Function Loss: 0.07047

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.52680
Value Function Update Magnitude: 0.67620

Collected Steps per Second: 22,930.46312
Overall Steps per Second: 10,876.85445

Timestep Collection Time: 2.18112
Timestep Consumption Time: 2.41709
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59820

Cumulative Model Updates: 86,950
Cumulative Timesteps: 725,184,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,756.23508
Policy Entropy: 3.67425
Value Function Loss: 0.06774

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.56296
Value Function Update Magnitude: 0.65416

Collected Steps per Second: 22,889.32371
Overall Steps per Second: 10,743.77421

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.65646

Cumulative Model Updates: 86,956
Cumulative Timesteps: 725,234,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 725234508...
Checkpoint 725234508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,941.29232
Policy Entropy: 3.67749
Value Function Loss: 0.06346

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.62759
Value Function Update Magnitude: 0.66566

Collected Steps per Second: 22,524.74605
Overall Steps per Second: 10,813.74233

Timestep Collection Time: 2.22031
Timestep Consumption Time: 2.40454
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.62486

Cumulative Model Updates: 86,962
Cumulative Timesteps: 725,284,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,527.07001
Policy Entropy: 3.67479
Value Function Loss: 0.06204

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.59035
Value Function Update Magnitude: 0.72262

Collected Steps per Second: 23,149.46183
Overall Steps per Second: 10,902.62366

Timestep Collection Time: 2.16031
Timestep Consumption Time: 2.42666
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.58697

Cumulative Model Updates: 86,968
Cumulative Timesteps: 725,334,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 725334530...
Checkpoint 725334530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.13687
Policy Entropy: 3.66959
Value Function Loss: 0.05958

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.61634
Value Function Update Magnitude: 0.71577

Collected Steps per Second: 22,545.25382
Overall Steps per Second: 10,720.75010

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.66777

Cumulative Model Updates: 86,974
Cumulative Timesteps: 725,384,572

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,874.72699
Policy Entropy: 3.67058
Value Function Loss: 0.06287

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.67188
Value Function Update Magnitude: 0.72018

Collected Steps per Second: 22,545.54817
Overall Steps per Second: 10,587.06252

Timestep Collection Time: 2.21844
Timestep Consumption Time: 2.50581
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.72426

Cumulative Model Updates: 86,980
Cumulative Timesteps: 725,434,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 725434588...
Checkpoint 725434588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,498.39388
Policy Entropy: 3.68206
Value Function Loss: 0.06660

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.72728

Collected Steps per Second: 22,271.83197
Overall Steps per Second: 10,502.47847

Timestep Collection Time: 2.24526
Timestep Consumption Time: 2.51609
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.76135

Cumulative Model Updates: 86,986
Cumulative Timesteps: 725,484,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.68710
Policy Entropy: 3.67526
Value Function Loss: 0.06880

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09545
Policy Update Magnitude: 0.56265
Value Function Update Magnitude: 0.76333

Collected Steps per Second: 22,445.44884
Overall Steps per Second: 10,564.44910

Timestep Collection Time: 2.22789
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.73342

Cumulative Model Updates: 86,992
Cumulative Timesteps: 725,534,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 725534600...
Checkpoint 725534600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,919.82672
Policy Entropy: 3.68318
Value Function Loss: 0.06950

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.51408
Value Function Update Magnitude: 0.78275

Collected Steps per Second: 21,992.09403
Overall Steps per Second: 10,546.64796

Timestep Collection Time: 2.27464
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.74312

Cumulative Model Updates: 86,998
Cumulative Timesteps: 725,584,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.26615
Policy Entropy: 3.67715
Value Function Loss: 0.06702

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.50785
Value Function Update Magnitude: 0.78709

Collected Steps per Second: 22,640.23802
Overall Steps per Second: 10,633.10929

Timestep Collection Time: 2.20881
Timestep Consumption Time: 2.49424
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.70305

Cumulative Model Updates: 87,004
Cumulative Timesteps: 725,634,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 725634632...
Checkpoint 725634632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,749.24599
Policy Entropy: 3.68926
Value Function Loss: 0.06782

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.56355
Value Function Update Magnitude: 0.82710

Collected Steps per Second: 22,322.39314
Overall Steps per Second: 10,519.00445

Timestep Collection Time: 2.24008
Timestep Consumption Time: 2.51360
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.75368

Cumulative Model Updates: 87,010
Cumulative Timesteps: 725,684,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,043.69579
Policy Entropy: 3.67447
Value Function Loss: 0.06822

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.50246
Value Function Update Magnitude: 0.85978

Collected Steps per Second: 22,970.24036
Overall Steps per Second: 10,791.02134

Timestep Collection Time: 2.17760
Timestep Consumption Time: 2.45773
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.63534

Cumulative Model Updates: 87,016
Cumulative Timesteps: 725,734,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 725734656...
Checkpoint 725734656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,712.50397
Policy Entropy: 3.68175
Value Function Loss: 0.06892

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.86178

Collected Steps per Second: 22,591.41153
Overall Steps per Second: 10,677.26984

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.47011
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.68378

Cumulative Model Updates: 87,022
Cumulative Timesteps: 725,784,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.86255
Policy Entropy: 3.67189
Value Function Loss: 0.06904

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.86354

Collected Steps per Second: 22,843.96806
Overall Steps per Second: 10,798.04355

Timestep Collection Time: 2.18946
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.63195

Cumulative Model Updates: 87,028
Cumulative Timesteps: 725,834,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 725834682...
Checkpoint 725834682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772.15698
Policy Entropy: 3.69250
Value Function Loss: 0.06972

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.59948
Value Function Update Magnitude: 0.87552

Collected Steps per Second: 22,753.97428
Overall Steps per Second: 10,717.37727

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.66663

Cumulative Model Updates: 87,034
Cumulative Timesteps: 725,884,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,320.73544
Policy Entropy: 3.68655
Value Function Loss: 0.06917

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.59645
Value Function Update Magnitude: 0.86665

Collected Steps per Second: 23,182.36787
Overall Steps per Second: 10,866.64621

Timestep Collection Time: 2.15776
Timestep Consumption Time: 2.44550
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60326

Cumulative Model Updates: 87,040
Cumulative Timesteps: 725,934,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 725934718...
Checkpoint 725934718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,252.93899
Policy Entropy: 3.67331
Value Function Loss: 0.06852

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.58586
Value Function Update Magnitude: 0.84213

Collected Steps per Second: 22,764.22601
Overall Steps per Second: 10,726.60849

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.46586
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.66317

Cumulative Model Updates: 87,046
Cumulative Timesteps: 725,984,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,168.30786
Policy Entropy: 3.67642
Value Function Loss: 0.06830

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.88277

Collected Steps per Second: 22,723.34466
Overall Steps per Second: 10,833.69748

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.41610
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61763

Cumulative Model Updates: 87,052
Cumulative Timesteps: 726,034,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 726034764...
Checkpoint 726034764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,597.91534
Policy Entropy: 3.67253
Value Function Loss: 0.06886

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.61716
Value Function Update Magnitude: 0.88796

Collected Steps per Second: 22,087.71686
Overall Steps per Second: 10,657.56130

Timestep Collection Time: 2.26370
Timestep Consumption Time: 2.42780
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.69150

Cumulative Model Updates: 87,058
Cumulative Timesteps: 726,084,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,135.16755
Policy Entropy: 3.68116
Value Function Loss: 0.07102

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.59693
Value Function Update Magnitude: 0.86399

Collected Steps per Second: 22,504.43656
Overall Steps per Second: 10,658.29648

Timestep Collection Time: 2.22312
Timestep Consumption Time: 2.47088
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.69400

Cumulative Model Updates: 87,064
Cumulative Timesteps: 726,134,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 726134794...
Checkpoint 726134794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,624.23439
Policy Entropy: 3.68192
Value Function Loss: 0.07010

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.88143

Collected Steps per Second: 22,613.32076
Overall Steps per Second: 10,654.38829

Timestep Collection Time: 2.21224
Timestep Consumption Time: 2.48311
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.69534

Cumulative Model Updates: 87,070
Cumulative Timesteps: 726,184,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,426.68662
Policy Entropy: 3.67553
Value Function Loss: 0.07461

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.87409

Collected Steps per Second: 22,832.37518
Overall Steps per Second: 10,677.24812

Timestep Collection Time: 2.19014
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.68342

Cumulative Model Updates: 87,076
Cumulative Timesteps: 726,234,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 726234826...
Checkpoint 726234826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,215.06721
Policy Entropy: 3.66873
Value Function Loss: 0.07999

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.51243
Value Function Update Magnitude: 0.81879

Collected Steps per Second: 22,572.87550
Overall Steps per Second: 10,674.13881

Timestep Collection Time: 2.21602
Timestep Consumption Time: 2.47026
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.68628

Cumulative Model Updates: 87,082
Cumulative Timesteps: 726,284,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.24142
Policy Entropy: 3.66081
Value Function Loss: 0.08011

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.51754
Value Function Update Magnitude: 0.82674

Collected Steps per Second: 23,279.11963
Overall Steps per Second: 10,890.82067

Timestep Collection Time: 2.14879
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.59304

Cumulative Model Updates: 87,088
Cumulative Timesteps: 726,334,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 726334870...
Checkpoint 726334870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,007.57232
Policy Entropy: 3.66327
Value Function Loss: 0.07935

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.49886
Value Function Update Magnitude: 0.79539

Collected Steps per Second: 22,911.64002
Overall Steps per Second: 10,659.84128

Timestep Collection Time: 2.18291
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.69181

Cumulative Model Updates: 87,094
Cumulative Timesteps: 726,384,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,790.58547
Policy Entropy: 3.65644
Value Function Loss: 0.07684

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.79141

Collected Steps per Second: 23,146.07605
Overall Steps per Second: 10,909.98523

Timestep Collection Time: 2.16054
Timestep Consumption Time: 2.42315
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.58369

Cumulative Model Updates: 87,100
Cumulative Timesteps: 726,434,892

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 726434892...
Checkpoint 726434892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,302.08928
Policy Entropy: 3.65322
Value Function Loss: 0.07860

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.76509

Collected Steps per Second: 22,737.87576
Overall Steps per Second: 10,625.83919

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.70645

Cumulative Model Updates: 87,106
Cumulative Timesteps: 726,484,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,306.60644
Policy Entropy: 3.65810
Value Function Loss: 0.07825

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.76687

Collected Steps per Second: 22,660.72001
Overall Steps per Second: 10,682.41615

Timestep Collection Time: 2.20779
Timestep Consumption Time: 2.47561
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.68340

Cumulative Model Updates: 87,112
Cumulative Timesteps: 726,534,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 726534932...
Checkpoint 726534932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,067.38886
Policy Entropy: 3.66420
Value Function Loss: 0.07704

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.76305

Collected Steps per Second: 22,316.44164
Overall Steps per Second: 10,581.64199

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.72554

Cumulative Model Updates: 87,118
Cumulative Timesteps: 726,584,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,737.39369
Policy Entropy: 3.66194
Value Function Loss: 0.07808

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.49002
Value Function Update Magnitude: 0.74805

Collected Steps per Second: 22,347.91422
Overall Steps per Second: 10,675.77735

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.44713
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.68537

Cumulative Model Updates: 87,124
Cumulative Timesteps: 726,634,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 726634956...
Checkpoint 726634956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,263.97494
Policy Entropy: 3.65324
Value Function Loss: 0.08021

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.48805
Value Function Update Magnitude: 0.68162

Collected Steps per Second: 22,312.08875
Overall Steps per Second: 10,671.18074

Timestep Collection Time: 2.24174
Timestep Consumption Time: 2.44546
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.68720

Cumulative Model Updates: 87,130
Cumulative Timesteps: 726,684,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,841.57732
Policy Entropy: 3.65679
Value Function Loss: 0.08104

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.53340
Value Function Update Magnitude: 0.67135

Collected Steps per Second: 23,180.94179
Overall Steps per Second: 10,886.91050

Timestep Collection Time: 2.15729
Timestep Consumption Time: 2.43612
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59341

Cumulative Model Updates: 87,136
Cumulative Timesteps: 726,734,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 726734982...
Checkpoint 726734982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,634.06517
Policy Entropy: 3.65518
Value Function Loss: 0.07703

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.75953

Collected Steps per Second: 22,858.18926
Overall Steps per Second: 10,732.90694

Timestep Collection Time: 2.18871
Timestep Consumption Time: 2.47265
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.66137

Cumulative Model Updates: 87,142
Cumulative Timesteps: 726,785,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,770.55148
Policy Entropy: 3.66238
Value Function Loss: 0.07723

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.74273

Collected Steps per Second: 22,928.34612
Overall Steps per Second: 10,810.59066

Timestep Collection Time: 2.18106
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62583

Cumulative Model Updates: 87,148
Cumulative Timesteps: 726,835,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 726835020...
Checkpoint 726835020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,270.78089
Policy Entropy: 3.65463
Value Function Loss: 0.07805

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.58108
Value Function Update Magnitude: 0.73502

Collected Steps per Second: 22,455.38823
Overall Steps per Second: 10,703.24579

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.44563
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.67297

Cumulative Model Updates: 87,154
Cumulative Timesteps: 726,885,036

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,779.78776
Policy Entropy: 3.63478
Value Function Loss: 0.08150

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.71671
Value Function Update Magnitude: 0.80044

Collected Steps per Second: 23,067.43507
Overall Steps per Second: 10,864.38961

Timestep Collection Time: 2.16938
Timestep Consumption Time: 2.43668
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.60606

Cumulative Model Updates: 87,160
Cumulative Timesteps: 726,935,078

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 726935078...
Checkpoint 726935078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,537.33040
Policy Entropy: 3.62875
Value Function Loss: 0.08124

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.74180
Value Function Update Magnitude: 0.82140

Collected Steps per Second: 22,556.19531
Overall Steps per Second: 10,793.20216

Timestep Collection Time: 2.21722
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.63366

Cumulative Model Updates: 87,166
Cumulative Timesteps: 726,985,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,691.71557
Policy Entropy: 3.64104
Value Function Loss: 0.08106

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.63516
Value Function Update Magnitude: 0.84291

Collected Steps per Second: 22,967.44243
Overall Steps per Second: 10,822.94437

Timestep Collection Time: 2.17734
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.62055

Cumulative Model Updates: 87,172
Cumulative Timesteps: 727,035,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 727035098...
Checkpoint 727035098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,795.68857
Policy Entropy: 3.64669
Value Function Loss: 0.07939

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.60468
Value Function Update Magnitude: 0.84035

Collected Steps per Second: 22,188.50239
Overall Steps per Second: 10,682.00409

Timestep Collection Time: 2.25459
Timestep Consumption Time: 2.42861
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.68320

Cumulative Model Updates: 87,178
Cumulative Timesteps: 727,085,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,203.51924
Policy Entropy: 3.63773
Value Function Loss: 0.07960

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.59569
Value Function Update Magnitude: 0.79510

Collected Steps per Second: 22,259.41522
Overall Steps per Second: 10,506.56459

Timestep Collection Time: 2.24642
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.75931

Cumulative Model Updates: 87,184
Cumulative Timesteps: 727,135,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 727135128...
Checkpoint 727135128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,705.09385
Policy Entropy: 3.62661
Value Function Loss: 0.08346

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.67850

Collected Steps per Second: 22,862.18483
Overall Steps per Second: 10,681.87423

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68251

Cumulative Model Updates: 87,190
Cumulative Timesteps: 727,185,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,704.60345
Policy Entropy: 3.61825
Value Function Loss: 0.08754

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.61479

Collected Steps per Second: 23,212.91883
Overall Steps per Second: 10,791.04413

Timestep Collection Time: 2.15415
Timestep Consumption Time: 2.47970
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.63384

Cumulative Model Updates: 87,196
Cumulative Timesteps: 727,235,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 727235150...
Checkpoint 727235150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,287.48496
Policy Entropy: 3.61274
Value Function Loss: 0.08756

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.53727
Value Function Update Magnitude: 0.62737

Collected Steps per Second: 22,652.82963
Overall Steps per Second: 10,634.90366

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70451

Cumulative Model Updates: 87,202
Cumulative Timesteps: 727,285,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,668.51644
Policy Entropy: 3.61734
Value Function Loss: 0.08536

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.50304
Value Function Update Magnitude: 0.62798

Collected Steps per Second: 23,199.24285
Overall Steps per Second: 10,951.10440

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.41099
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.56666

Cumulative Model Updates: 87,208
Cumulative Timesteps: 727,335,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 727335192...
Checkpoint 727335192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,691.51578
Policy Entropy: 3.62920
Value Function Loss: 0.08388

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.48977
Value Function Update Magnitude: 0.61361

Collected Steps per Second: 22,861.99202
Overall Steps per Second: 10,673.13040

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.68485

Cumulative Model Updates: 87,214
Cumulative Timesteps: 727,385,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,559.51217
Policy Entropy: 3.64252
Value Function Loss: 0.08434

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.50414
Value Function Update Magnitude: 0.60478

Collected Steps per Second: 22,808.44191
Overall Steps per Second: 10,839.07501

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.61552

Cumulative Model Updates: 87,220
Cumulative Timesteps: 727,435,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 727435222...
Checkpoint 727435222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,818.08265
Policy Entropy: 3.63619
Value Function Loss: 0.08465

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.53192
Value Function Update Magnitude: 0.60399

Collected Steps per Second: 22,021.06936
Overall Steps per Second: 10,673.23061

Timestep Collection Time: 2.27192
Timestep Consumption Time: 2.41551
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.68743

Cumulative Model Updates: 87,226
Cumulative Timesteps: 727,485,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,172.27665
Policy Entropy: 3.65483
Value Function Loss: 0.08470

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.44417
Value Function Update Magnitude: 0.62085

Collected Steps per Second: 20,881.10199
Overall Steps per Second: 10,408.30361

Timestep Collection Time: 2.39470
Timestep Consumption Time: 2.40954
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.80424

Cumulative Model Updates: 87,232
Cumulative Timesteps: 727,535,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 727535256...
Checkpoint 727535256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,406.86443
Policy Entropy: 3.65538
Value Function Loss: 0.08400

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.50556
Value Function Update Magnitude: 0.65148

Collected Steps per Second: 21,589.31689
Overall Steps per Second: 10,640.69974

Timestep Collection Time: 2.31726
Timestep Consumption Time: 2.38431
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.70157

Cumulative Model Updates: 87,238
Cumulative Timesteps: 727,585,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,186.93940
Policy Entropy: 3.67070
Value Function Loss: 0.08239

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.49417
Value Function Update Magnitude: 0.70368

Collected Steps per Second: 21,889.05667
Overall Steps per Second: 10,628.98738

Timestep Collection Time: 2.28470
Timestep Consumption Time: 2.42035
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.70506

Cumulative Model Updates: 87,244
Cumulative Timesteps: 727,635,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 727635294...
Checkpoint 727635294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,154.60724
Policy Entropy: 3.66638
Value Function Loss: 0.07965

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.53682
Value Function Update Magnitude: 0.83081

Collected Steps per Second: 21,810.04629
Overall Steps per Second: 10,489.91846

Timestep Collection Time: 2.29270
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.76686

Cumulative Model Updates: 87,250
Cumulative Timesteps: 727,685,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,061.18772
Policy Entropy: 3.64945
Value Function Loss: 0.07609

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.51959
Value Function Update Magnitude: 0.85876

Collected Steps per Second: 22,431.59876
Overall Steps per Second: 10,658.32176

Timestep Collection Time: 2.22944
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.69211

Cumulative Model Updates: 87,256
Cumulative Timesteps: 727,735,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 727735308...
Checkpoint 727735308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,360.02098
Policy Entropy: 3.64436
Value Function Loss: 0.07575

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.44243
Value Function Update Magnitude: 0.75722

Collected Steps per Second: 22,705.13832
Overall Steps per Second: 10,797.95189

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.63180

Cumulative Model Updates: 87,262
Cumulative Timesteps: 727,785,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,210.90308
Policy Entropy: 3.63032
Value Function Loss: 0.07205

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.46477
Value Function Update Magnitude: 0.82758

Collected Steps per Second: 23,239.27037
Overall Steps per Second: 10,952.61237

Timestep Collection Time: 2.15274
Timestep Consumption Time: 2.41494
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.56768

Cumulative Model Updates: 87,268
Cumulative Timesteps: 727,835,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 727835350...
Checkpoint 727835350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,939.28096
Policy Entropy: 3.64269
Value Function Loss: 0.06955

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.54673
Value Function Update Magnitude: 0.78204

Collected Steps per Second: 22,402.06811
Overall Steps per Second: 10,716.18822

Timestep Collection Time: 2.23229
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.66658

Cumulative Model Updates: 87,274
Cumulative Timesteps: 727,885,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,561.20800
Policy Entropy: 3.64053
Value Function Loss: 0.06942

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.59247
Value Function Update Magnitude: 0.68214

Collected Steps per Second: 23,144.86512
Overall Steps per Second: 10,917.99639

Timestep Collection Time: 2.16108
Timestep Consumption Time: 2.42016
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.58124

Cumulative Model Updates: 87,280
Cumulative Timesteps: 727,935,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 727935376...
Checkpoint 727935376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,528.33112
Policy Entropy: 3.65067
Value Function Loss: 0.07097

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.52764
Value Function Update Magnitude: 0.65786

Collected Steps per Second: 22,918.23546
Overall Steps per Second: 10,692.61274

Timestep Collection Time: 2.18228
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.67743

Cumulative Model Updates: 87,286
Cumulative Timesteps: 727,985,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,472.57479
Policy Entropy: 3.65976
Value Function Loss: 0.07069

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.59239
Value Function Update Magnitude: 0.70387

Collected Steps per Second: 23,135.06543
Overall Steps per Second: 10,822.10696

Timestep Collection Time: 2.16235
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.62257

Cumulative Model Updates: 87,292
Cumulative Timesteps: 728,035,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 728035416...
Checkpoint 728035416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.75192
Policy Entropy: 3.66598
Value Function Loss: 0.07002

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.60265
Value Function Update Magnitude: 0.80756

Collected Steps per Second: 22,342.87368
Overall Steps per Second: 10,626.40990

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.46948
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.70921

Cumulative Model Updates: 87,298
Cumulative Timesteps: 728,085,458

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,132.80431
Policy Entropy: 3.66565
Value Function Loss: 0.06737

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.62509
Value Function Update Magnitude: 0.79605

Collected Steps per Second: 22,522.07047
Overall Steps per Second: 10,604.97296

Timestep Collection Time: 2.22209
Timestep Consumption Time: 2.49702
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.71911

Cumulative Model Updates: 87,304
Cumulative Timesteps: 728,135,504

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 728135504...
Checkpoint 728135504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.65354
Policy Entropy: 3.66899
Value Function Loss: 0.06503

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.64900
Value Function Update Magnitude: 0.74741

Collected Steps per Second: 22,446.86238
Overall Steps per Second: 10,577.29540

Timestep Collection Time: 2.22820
Timestep Consumption Time: 2.50042
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.72862

Cumulative Model Updates: 87,310
Cumulative Timesteps: 728,185,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,176.11680
Policy Entropy: 3.67887
Value Function Loss: 0.06392

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.66990
Value Function Update Magnitude: 0.75757

Collected Steps per Second: 22,724.68790
Overall Steps per Second: 10,769.04973

Timestep Collection Time: 2.20078
Timestep Consumption Time: 2.44327
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.64405

Cumulative Model Updates: 87,316
Cumulative Timesteps: 728,235,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 728235532...
Checkpoint 728235532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,167.15460
Policy Entropy: 3.68810
Value Function Loss: 0.06165

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.67913
Value Function Update Magnitude: 0.77381

Collected Steps per Second: 22,480.31590
Overall Steps per Second: 10,661.01218

Timestep Collection Time: 2.22426
Timestep Consumption Time: 2.46592
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.69017

Cumulative Model Updates: 87,322
Cumulative Timesteps: 728,285,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.06453
Policy Entropy: 3.67897
Value Function Loss: 0.06468

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.71515
Value Function Update Magnitude: 0.73665

Collected Steps per Second: 23,045.68207
Overall Steps per Second: 10,730.96941

Timestep Collection Time: 2.17030
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.66090

Cumulative Model Updates: 87,328
Cumulative Timesteps: 728,335,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 728335550...
Checkpoint 728335550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,102.89170
Policy Entropy: 3.68333
Value Function Loss: 0.06516

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.66919
Value Function Update Magnitude: 0.74264

Collected Steps per Second: 22,858.58566
Overall Steps per Second: 10,815.64754

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.43606
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.62386

Cumulative Model Updates: 87,334
Cumulative Timesteps: 728,385,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,456.80601
Policy Entropy: 3.67361
Value Function Loss: 0.06469

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.60223
Value Function Update Magnitude: 0.76216

Collected Steps per Second: 23,201.81739
Overall Steps per Second: 10,899.36835

Timestep Collection Time: 2.15509
Timestep Consumption Time: 2.43252
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.58761

Cumulative Model Updates: 87,340
Cumulative Timesteps: 728,435,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 728435562...
Checkpoint 728435562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,884.85300
Policy Entropy: 3.67686
Value Function Loss: 0.06334

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.78214

Collected Steps per Second: 22,657.00204
Overall Steps per Second: 10,655.25651

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.69252

Cumulative Model Updates: 87,346
Cumulative Timesteps: 728,485,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,462.56599
Policy Entropy: 3.67523
Value Function Loss: 0.06405

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.79579

Collected Steps per Second: 23,006.73398
Overall Steps per Second: 10,873.43267

Timestep Collection Time: 2.17510
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.60223

Cumulative Model Updates: 87,352
Cumulative Timesteps: 728,535,604

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 728535604...
Checkpoint 728535604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,001.23150
Policy Entropy: 3.67879
Value Function Loss: 0.06702

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.57487
Value Function Update Magnitude: 0.80072

Collected Steps per Second: 22,292.61380
Overall Steps per Second: 10,703.05697

Timestep Collection Time: 2.24370
Timestep Consumption Time: 2.42954
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.67324

Cumulative Model Updates: 87,358
Cumulative Timesteps: 728,585,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,316.34957
Policy Entropy: 3.67153
Value Function Loss: 0.06900

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.65524
Value Function Update Magnitude: 0.79961

Collected Steps per Second: 22,688.90370
Overall Steps per Second: 10,613.63669

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.50740
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.71130

Cumulative Model Updates: 87,364
Cumulative Timesteps: 728,635,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 728635626...
Checkpoint 728635626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,076.64712
Policy Entropy: 3.66625
Value Function Loss: 0.07032

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.64720
Value Function Update Magnitude: 0.81299

Collected Steps per Second: 22,272.56898
Overall Steps per Second: 10,515.57126

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.75561

Cumulative Model Updates: 87,370
Cumulative Timesteps: 728,685,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,365.72977
Policy Entropy: 3.65565
Value Function Loss: 0.07071

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.59989
Value Function Update Magnitude: 0.77509

Collected Steps per Second: 22,631.53664
Overall Steps per Second: 10,517.54751

Timestep Collection Time: 2.20948
Timestep Consumption Time: 2.54486
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.75434

Cumulative Model Updates: 87,376
Cumulative Timesteps: 728,735,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 728735638...
Checkpoint 728735638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,224.07509
Policy Entropy: 3.65876
Value Function Loss: 0.07040

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.58736
Value Function Update Magnitude: 0.75662

Collected Steps per Second: 22,834.22660
Overall Steps per Second: 10,592.81614

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.53180
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.72263

Cumulative Model Updates: 87,382
Cumulative Timesteps: 728,785,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,783.25361
Policy Entropy: 3.66632
Value Function Loss: 0.07051

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.76498

Collected Steps per Second: 23,310.65655
Overall Steps per Second: 10,869.00150

Timestep Collection Time: 2.14606
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.60263

Cumulative Model Updates: 87,388
Cumulative Timesteps: 728,835,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 728835690...
Checkpoint 728835690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,240.60101
Policy Entropy: 3.65957
Value Function Loss: 0.07039

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.77397

Collected Steps per Second: 21,830.33532
Overall Steps per Second: 10,579.58673

Timestep Collection Time: 2.29076
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72684

Cumulative Model Updates: 87,394
Cumulative Timesteps: 728,885,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,999.34769
Policy Entropy: 3.64759
Value Function Loss: 0.07304

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.50534
Value Function Update Magnitude: 0.74613

Collected Steps per Second: 23,163.66696
Overall Steps per Second: 10,909.19028

Timestep Collection Time: 2.15942
Timestep Consumption Time: 2.42571
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.58512

Cumulative Model Updates: 87,400
Cumulative Timesteps: 728,935,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 728935718...
Checkpoint 728935718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,116.68382
Policy Entropy: 3.63606
Value Function Loss: 0.07870

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.52165
Value Function Update Magnitude: 0.72469

Collected Steps per Second: 22,662.98656
Overall Steps per Second: 10,722.69387

Timestep Collection Time: 2.20703
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.66469

Cumulative Model Updates: 87,406
Cumulative Timesteps: 728,985,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,531.76618
Policy Entropy: 3.62949
Value Function Loss: 0.08158

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.52244
Value Function Update Magnitude: 0.75934

Collected Steps per Second: 22,946.43765
Overall Steps per Second: 10,853.76005

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60836

Cumulative Model Updates: 87,412
Cumulative Timesteps: 729,035,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 729035754...
Checkpoint 729035754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,127.04025
Policy Entropy: 3.63729
Value Function Loss: 0.08141

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.71403

Collected Steps per Second: 22,269.33665
Overall Steps per Second: 10,727.92314

Timestep Collection Time: 2.24659
Timestep Consumption Time: 2.41694
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.66353

Cumulative Model Updates: 87,418
Cumulative Timesteps: 729,085,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,928.25365
Policy Entropy: 3.62651
Value Function Loss: 0.07806

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.76043

Collected Steps per Second: 22,750.73720
Overall Steps per Second: 10,813.72105

Timestep Collection Time: 2.19791
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62413

Cumulative Model Updates: 87,424
Cumulative Timesteps: 729,135,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 729135788...
Checkpoint 729135788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,938.23163
Policy Entropy: 3.62080
Value Function Loss: 0.07675

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.74990

Collected Steps per Second: 22,007.30133
Overall Steps per Second: 10,635.96044

Timestep Collection Time: 2.27306
Timestep Consumption Time: 2.43023
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.70329

Cumulative Model Updates: 87,430
Cumulative Timesteps: 729,185,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,044.42499
Policy Entropy: 3.62990
Value Function Loss: 0.07713

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.65412

Collected Steps per Second: 22,189.94712
Overall Steps per Second: 10,722.15261

Timestep Collection Time: 2.25354
Timestep Consumption Time: 2.41026
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.66380

Cumulative Model Updates: 87,436
Cumulative Timesteps: 729,235,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 729235818...
Checkpoint 729235818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.84864
Policy Entropy: 3.63107
Value Function Loss: 0.07742

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.59825
Value Function Update Magnitude: 0.62994

Collected Steps per Second: 21,670.50829
Overall Steps per Second: 10,564.88938

Timestep Collection Time: 2.30848
Timestep Consumption Time: 2.42664
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.73512

Cumulative Model Updates: 87,442
Cumulative Timesteps: 729,285,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,972.17414
Policy Entropy: 3.63374
Value Function Loss: 0.08066

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.59228
Value Function Update Magnitude: 0.63907

Collected Steps per Second: 22,471.69909
Overall Steps per Second: 10,763.51625

Timestep Collection Time: 2.22564
Timestep Consumption Time: 2.42098
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.64662

Cumulative Model Updates: 87,448
Cumulative Timesteps: 729,335,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 729335858...
Checkpoint 729335858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,844.94020
Policy Entropy: 3.62709
Value Function Loss: 0.07906

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.61513
Value Function Update Magnitude: 0.66234

Collected Steps per Second: 22,251.74229
Overall Steps per Second: 10,718.96276

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.66519

Cumulative Model Updates: 87,454
Cumulative Timesteps: 729,385,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,715.43699
Policy Entropy: 3.62999
Value Function Loss: 0.07856

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.63430
Value Function Update Magnitude: 0.67131

Collected Steps per Second: 22,451.67718
Overall Steps per Second: 10,586.62636

Timestep Collection Time: 2.22754
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.72407

Cumulative Model Updates: 87,460
Cumulative Timesteps: 729,435,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 729435876...
Checkpoint 729435876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,512.88405
Policy Entropy: 3.63557
Value Function Loss: 0.07781

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.62243
Value Function Update Magnitude: 0.65866

Collected Steps per Second: 22,688.55833
Overall Steps per Second: 10,833.98464

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.41241
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61714

Cumulative Model Updates: 87,466
Cumulative Timesteps: 729,485,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,889.26894
Policy Entropy: 3.64762
Value Function Loss: 0.07679

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.54535
Value Function Update Magnitude: 0.68156

Collected Steps per Second: 22,765.57199
Overall Steps per Second: 10,730.18810

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.66273

Cumulative Model Updates: 87,472
Cumulative Timesteps: 729,535,930

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 729535930...
Checkpoint 729535930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.50840
Policy Entropy: 3.65236
Value Function Loss: 0.07442

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.44543
Value Function Update Magnitude: 0.66289

Collected Steps per Second: 22,751.22528
Overall Steps per Second: 10,859.41791

Timestep Collection Time: 2.19848
Timestep Consumption Time: 2.40748
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60596

Cumulative Model Updates: 87,478
Cumulative Timesteps: 729,585,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,068.13199
Policy Entropy: 3.65320
Value Function Loss: 0.07411

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.45518
Value Function Update Magnitude: 0.60657

Collected Steps per Second: 22,398.57759
Overall Steps per Second: 10,649.97000

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.69504

Cumulative Model Updates: 87,484
Cumulative Timesteps: 729,635,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 729635950...
Checkpoint 729635950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,490.57050
Policy Entropy: 3.64910
Value Function Loss: 0.07507

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.46629
Value Function Update Magnitude: 0.63985

Collected Steps per Second: 22,472.31505
Overall Steps per Second: 10,668.51126

Timestep Collection Time: 2.22532
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.68744

Cumulative Model Updates: 87,490
Cumulative Timesteps: 729,685,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,398.12755
Policy Entropy: 3.65294
Value Function Loss: 0.07584

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.59679
Value Function Update Magnitude: 0.70531

Collected Steps per Second: 23,094.96015
Overall Steps per Second: 10,782.67714

Timestep Collection Time: 2.16567
Timestep Consumption Time: 2.47288
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.63855

Cumulative Model Updates: 87,496
Cumulative Timesteps: 729,735,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 729735974...
Checkpoint 729735974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,061.38119
Policy Entropy: 3.64507
Value Function Loss: 0.07571

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.70045
Value Function Update Magnitude: 0.71108

Collected Steps per Second: 22,586.35431
Overall Steps per Second: 10,570.43002

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.51746
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.73207

Cumulative Model Updates: 87,502
Cumulative Timesteps: 729,785,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,461.39686
Policy Entropy: 3.64284
Value Function Loss: 0.07606

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.73467
Value Function Update Magnitude: 0.66411

Collected Steps per Second: 23,170.84625
Overall Steps per Second: 10,834.41835

Timestep Collection Time: 2.15806
Timestep Consumption Time: 2.45723
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.61529

Cumulative Model Updates: 87,508
Cumulative Timesteps: 729,835,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 729835998...
Checkpoint 729835998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.40981
Policy Entropy: 3.63602
Value Function Loss: 0.07755

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.63406
Value Function Update Magnitude: 0.60731

Collected Steps per Second: 22,553.55647
Overall Steps per Second: 10,732.01579

Timestep Collection Time: 2.21757
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.66026

Cumulative Model Updates: 87,514
Cumulative Timesteps: 729,886,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,384.36674
Policy Entropy: 3.64774
Value Function Loss: 0.07652

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.75045
Value Function Update Magnitude: 0.59976

Collected Steps per Second: 23,299.01883
Overall Steps per Second: 10,911.13782

Timestep Collection Time: 2.14661
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.58376

Cumulative Model Updates: 87,520
Cumulative Timesteps: 729,936,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 729936026...
Checkpoint 729936026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.25636
Policy Entropy: 3.64986
Value Function Loss: 0.07574

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.76224
Value Function Update Magnitude: 0.56297

Collected Steps per Second: 22,961.55897
Overall Steps per Second: 10,769.05193

Timestep Collection Time: 2.17781
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.64349

Cumulative Model Updates: 87,526
Cumulative Timesteps: 729,986,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.49847
Policy Entropy: 3.65366
Value Function Loss: 0.07388

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.64335
Value Function Update Magnitude: 0.59178

Collected Steps per Second: 23,287.13548
Overall Steps per Second: 10,736.81166

Timestep Collection Time: 2.14831
Timestep Consumption Time: 2.51117
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.65948

Cumulative Model Updates: 87,532
Cumulative Timesteps: 730,036,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 730036060...
Checkpoint 730036060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,050.29551
Policy Entropy: 3.65027
Value Function Loss: 0.07337

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.57903
Value Function Update Magnitude: 0.56505

Collected Steps per Second: 22,573.95721
Overall Steps per Second: 10,652.02748

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.48059
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.69695

Cumulative Model Updates: 87,538
Cumulative Timesteps: 730,086,092

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,986.91342
Policy Entropy: 3.65172
Value Function Loss: 0.07306

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.58899
Value Function Update Magnitude: 0.59929

Collected Steps per Second: 22,684.07848
Overall Steps per Second: 10,657.52705

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.69190

Cumulative Model Updates: 87,544
Cumulative Timesteps: 730,136,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 730136096...
Checkpoint 730136096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,025.61192
Policy Entropy: 3.66037
Value Function Loss: 0.07103

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.64548
Value Function Update Magnitude: 0.61580

Collected Steps per Second: 22,348.75125
Overall Steps per Second: 10,568.56219

Timestep Collection Time: 2.23789
Timestep Consumption Time: 2.49445
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.73234

Cumulative Model Updates: 87,550
Cumulative Timesteps: 730,186,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,963.60110
Policy Entropy: 3.67848
Value Function Loss: 0.06759

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 22,832.63654
Overall Steps per Second: 10,825.34489

Timestep Collection Time: 2.19055
Timestep Consumption Time: 2.42972
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.62027

Cumulative Model Updates: 87,556
Cumulative Timesteps: 730,236,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 730236126...
Checkpoint 730236126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,128.89889
Policy Entropy: 3.67588
Value Function Loss: 0.06768

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.52198
Value Function Update Magnitude: 0.68831

Collected Steps per Second: 22,452.74541
Overall Steps per Second: 10,668.30483

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.46096
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.68884

Cumulative Model Updates: 87,562
Cumulative Timesteps: 730,286,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.80751
Policy Entropy: 3.67645
Value Function Loss: 0.07016

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.53529
Value Function Update Magnitude: 0.76949

Collected Steps per Second: 23,080.14962
Overall Steps per Second: 10,872.66844

Timestep Collection Time: 2.16784
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.60181

Cumulative Model Updates: 87,568
Cumulative Timesteps: 730,336,182

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 730336182...
Checkpoint 730336182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,778.63573
Policy Entropy: 3.66952
Value Function Loss: 0.07493

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.81159

Collected Steps per Second: 22,890.19594
Overall Steps per Second: 10,640.88311

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.51522
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.70017

Cumulative Model Updates: 87,574
Cumulative Timesteps: 730,386,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,695.98057
Policy Entropy: 3.66602
Value Function Loss: 0.07712

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.83278

Collected Steps per Second: 23,278.11566
Overall Steps per Second: 10,889.72129

Timestep Collection Time: 2.14803
Timestep Consumption Time: 2.44364
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59167

Cumulative Model Updates: 87,580
Cumulative Timesteps: 730,436,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 730436198...
Checkpoint 730436198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,260.60500
Policy Entropy: 3.66285
Value Function Loss: 0.08033

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.60970
Value Function Update Magnitude: 0.73028

Collected Steps per Second: 22,636.21200
Overall Steps per Second: 10,616.94141

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.71002

Cumulative Model Updates: 87,586
Cumulative Timesteps: 730,486,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,486.48778
Policy Entropy: 3.65542
Value Function Loss: 0.08243

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.65310
Value Function Update Magnitude: 0.65402

Collected Steps per Second: 22,835.06357
Overall Steps per Second: 10,694.89777

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.67513

Cumulative Model Updates: 87,592
Cumulative Timesteps: 730,536,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730536204...
Checkpoint 730536204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,172.54738
Policy Entropy: 3.65623
Value Function Loss: 0.08370

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.61029

Collected Steps per Second: 22,596.21081
Overall Steps per Second: 10,798.84758

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.63049

Cumulative Model Updates: 87,598
Cumulative Timesteps: 730,586,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,954.94106
Policy Entropy: 3.63638
Value Function Loss: 0.08254

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.56048
Value Function Update Magnitude: 0.73264

Collected Steps per Second: 23,029.98817
Overall Steps per Second: 10,921.10205

Timestep Collection Time: 2.17126
Timestep Consumption Time: 2.40740
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.57866

Cumulative Model Updates: 87,604
Cumulative Timesteps: 730,636,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 730636212...
Checkpoint 730636212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,178.56018
Policy Entropy: 3.63761
Value Function Loss: 0.08049

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.69750
Value Function Update Magnitude: 0.81559

Collected Steps per Second: 22,062.55307
Overall Steps per Second: 10,648.09049

Timestep Collection Time: 2.26628
Timestep Consumption Time: 2.42939
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.69568

Cumulative Model Updates: 87,610
Cumulative Timesteps: 730,686,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,892.39992
Policy Entropy: 3.63485
Value Function Loss: 0.07917

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.72262
Value Function Update Magnitude: 0.82824

Collected Steps per Second: 22,781.71335
Overall Steps per Second: 10,664.18251

Timestep Collection Time: 2.19509
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.68934

Cumulative Model Updates: 87,616
Cumulative Timesteps: 730,736,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 730736220...
Checkpoint 730736220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,593.38958
Policy Entropy: 3.65161
Value Function Loss: 0.08022

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.64381
Value Function Update Magnitude: 0.79439

Collected Steps per Second: 22,539.85476
Overall Steps per Second: 10,628.40204

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70551

Cumulative Model Updates: 87,622
Cumulative Timesteps: 730,786,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,360.43137
Policy Entropy: 3.64325
Value Function Loss: 0.08527

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.68730
Value Function Update Magnitude: 0.67713

Collected Steps per Second: 23,384.87208
Overall Steps per Second: 10,756.07026

Timestep Collection Time: 2.13839
Timestep Consumption Time: 2.51070
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.64910

Cumulative Model Updates: 87,628
Cumulative Timesteps: 730,836,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 730836238...
Checkpoint 730836238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,297.56711
Policy Entropy: 3.64610
Value Function Loss: 0.08581

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.75217
Value Function Update Magnitude: 0.62398

Collected Steps per Second: 22,494.29210
Overall Steps per Second: 10,608.18973

Timestep Collection Time: 2.22350
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.71485

Cumulative Model Updates: 87,634
Cumulative Timesteps: 730,886,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,870.27922
Policy Entropy: 3.66203
Value Function Loss: 0.08473

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.70373
Value Function Update Magnitude: 0.63056

Collected Steps per Second: 22,865.21616
Overall Steps per Second: 10,828.78191

Timestep Collection Time: 2.18795
Timestep Consumption Time: 2.43196
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61991

Cumulative Model Updates: 87,640
Cumulative Timesteps: 730,936,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 730936282...
Checkpoint 730936282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,595.42045
Policy Entropy: 3.66089
Value Function Loss: 0.08508

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.64861
Value Function Update Magnitude: 0.62548

Collected Steps per Second: 22,517.71130
Overall Steps per Second: 10,766.73634

Timestep Collection Time: 2.22172
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.64653

Cumulative Model Updates: 87,646
Cumulative Timesteps: 730,986,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,474.93582
Policy Entropy: 3.66428
Value Function Loss: 0.08578

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.59461
Value Function Update Magnitude: 0.65492

Collected Steps per Second: 23,238.69925
Overall Steps per Second: 10,920.42844

Timestep Collection Time: 2.15210
Timestep Consumption Time: 2.42757
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.57967

Cumulative Model Updates: 87,652
Cumulative Timesteps: 731,036,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 731036322...
Checkpoint 731036322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,142.80069
Policy Entropy: 3.66278
Value Function Loss: 0.08817

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.67706
Value Function Update Magnitude: 0.70744

Collected Steps per Second: 22,467.65793
Overall Steps per Second: 10,590.09185

Timestep Collection Time: 2.22596
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.72253

Cumulative Model Updates: 87,658
Cumulative Timesteps: 731,086,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,066.24044
Policy Entropy: 3.66194
Value Function Loss: 0.08724

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.63743
Value Function Update Magnitude: 0.72461

Collected Steps per Second: 22,486.21024
Overall Steps per Second: 10,595.52942

Timestep Collection Time: 2.22439
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.72067

Cumulative Model Updates: 87,664
Cumulative Timesteps: 731,136,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 731136352...
Checkpoint 731136352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,786.42170
Policy Entropy: 3.63511
Value Function Loss: 0.08883

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.59674
Value Function Update Magnitude: 0.65928

Collected Steps per Second: 22,463.90754
Overall Steps per Second: 10,587.95729

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.72272

Cumulative Model Updates: 87,670
Cumulative Timesteps: 731,186,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,605.36268
Policy Entropy: 3.62862
Value Function Loss: 0.08610

Mean KL Divergence: 0.02699
SB3 Clip Fraction: 0.19091
Policy Update Magnitude: 0.58881
Value Function Update Magnitude: 0.65760

Collected Steps per Second: 22,647.84454
Overall Steps per Second: 10,731.40466

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.45249
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.66109

Cumulative Model Updates: 87,676
Cumulative Timesteps: 731,236,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 731236376...
Checkpoint 731236376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,276.79604
Policy Entropy: 3.64976
Value Function Loss: 0.08599

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.19425
Policy Update Magnitude: 0.53403
Value Function Update Magnitude: 0.59613

Collected Steps per Second: 22,219.43710
Overall Steps per Second: 10,643.36242

Timestep Collection Time: 2.25244
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.70227

Cumulative Model Updates: 87,682
Cumulative Timesteps: 731,286,424

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,059.48174
Policy Entropy: 3.67599
Value Function Loss: 0.08343

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.49209
Value Function Update Magnitude: 0.52393

Collected Steps per Second: 22,745.63569
Overall Steps per Second: 10,546.15878

Timestep Collection Time: 2.19822
Timestep Consumption Time: 2.54284
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.74106

Cumulative Model Updates: 87,688
Cumulative Timesteps: 731,336,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 731336424...
Checkpoint 731336424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,531.98493
Policy Entropy: 3.68764
Value Function Loss: 0.08589

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.58116

Collected Steps per Second: 22,182.50120
Overall Steps per Second: 10,652.50740

Timestep Collection Time: 2.25439
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.69448

Cumulative Model Updates: 87,694
Cumulative Timesteps: 731,386,432

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,578.97370
Policy Entropy: 3.68063
Value Function Loss: 0.08483

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.66951
Value Function Update Magnitude: 0.71302

Collected Steps per Second: 22,960.72119
Overall Steps per Second: 10,826.31281

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.62022

Cumulative Model Updates: 87,700
Cumulative Timesteps: 731,436,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 731436452...
Checkpoint 731436452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,430.72675
Policy Entropy: 3.67256
Value Function Loss: 0.08402

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.62824
Value Function Update Magnitude: 0.67632

Collected Steps per Second: 22,363.81222
Overall Steps per Second: 10,710.17118

Timestep Collection Time: 2.23701
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.67107

Cumulative Model Updates: 87,706
Cumulative Timesteps: 731,486,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,288.34745
Policy Entropy: 3.65472
Value Function Loss: 0.08341

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.62439

Collected Steps per Second: 22,903.50470
Overall Steps per Second: 10,665.18140

Timestep Collection Time: 2.18342
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.68890

Cumulative Model Updates: 87,712
Cumulative Timesteps: 731,536,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 731536488...
Checkpoint 731536488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,483.57164
Policy Entropy: 3.66346
Value Function Loss: 0.08124

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.47376
Value Function Update Magnitude: 0.71253

Collected Steps per Second: 21,801.55900
Overall Steps per Second: 10,444.19832

Timestep Collection Time: 2.29424
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.78907

Cumulative Model Updates: 87,718
Cumulative Timesteps: 731,586,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.80270
Policy Entropy: 3.66546
Value Function Loss: 0.08064

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.64158
Value Function Update Magnitude: 0.75574

Collected Steps per Second: 23,285.74277
Overall Steps per Second: 10,874.26684

Timestep Collection Time: 2.14835
Timestep Consumption Time: 2.45205
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.60040

Cumulative Model Updates: 87,724
Cumulative Timesteps: 731,636,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 731636532...
Checkpoint 731636532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,121.07463
Policy Entropy: 3.68782
Value Function Loss: 0.07417

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.67570
Value Function Update Magnitude: 0.75833

Collected Steps per Second: 22,599.89548
Overall Steps per Second: 10,671.38154

Timestep Collection Time: 2.21267
Timestep Consumption Time: 2.47333
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.68599

Cumulative Model Updates: 87,730
Cumulative Timesteps: 731,686,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.95320
Policy Entropy: 3.68077
Value Function Loss: 0.07408

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.72057
Value Function Update Magnitude: 0.78770

Collected Steps per Second: 23,169.79723
Overall Steps per Second: 10,964.47656

Timestep Collection Time: 2.15902
Timestep Consumption Time: 2.40335
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.56237

Cumulative Model Updates: 87,736
Cumulative Timesteps: 731,736,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 731736562...
Checkpoint 731736562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,212.46724
Policy Entropy: 3.67165
Value Function Loss: 0.07196

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.77527
Value Function Update Magnitude: 0.78064

Collected Steps per Second: 22,804.01578
Overall Steps per Second: 10,663.86016

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.69005

Cumulative Model Updates: 87,742
Cumulative Timesteps: 731,786,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,179.90919
Policy Entropy: 3.65669
Value Function Loss: 0.07384

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.70901
Value Function Update Magnitude: 0.73360

Collected Steps per Second: 22,975.13159
Overall Steps per Second: 10,813.47855

Timestep Collection Time: 2.17644
Timestep Consumption Time: 2.44779
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62423

Cumulative Model Updates: 87,748
Cumulative Timesteps: 731,836,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 731836580...
Checkpoint 731836580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,295.55977
Policy Entropy: 3.66272
Value Function Loss: 0.07317

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.60236
Value Function Update Magnitude: 0.67665

Collected Steps per Second: 22,061.29393
Overall Steps per Second: 10,619.65933

Timestep Collection Time: 2.26714
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.70976

Cumulative Model Updates: 87,754
Cumulative Timesteps: 731,886,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.83387
Policy Entropy: 3.66364
Value Function Loss: 0.07436

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.63860
Value Function Update Magnitude: 0.67863

Collected Steps per Second: 22,255.69012
Overall Steps per Second: 10,522.65204

Timestep Collection Time: 2.24832
Timestep Consumption Time: 2.50694
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.75527

Cumulative Model Updates: 87,760
Cumulative Timesteps: 731,936,634

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 731936634...
Checkpoint 731936634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,464.33507
Policy Entropy: 3.66146
Value Function Loss: 0.07475

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.61863
Value Function Update Magnitude: 0.69533

Collected Steps per Second: 22,652.60625
Overall Steps per Second: 10,618.00693

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.71162

Cumulative Model Updates: 87,766
Cumulative Timesteps: 731,986,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,350.67675
Policy Entropy: 3.66606
Value Function Loss: 0.07275

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.16573
Policy Update Magnitude: 0.49886
Value Function Update Magnitude: 0.66282

Collected Steps per Second: 22,754.87743
Overall Steps per Second: 10,612.62583

Timestep Collection Time: 2.19742
Timestep Consumption Time: 2.51414
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.71156

Cumulative Model Updates: 87,772
Cumulative Timesteps: 732,036,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 732036664...
Checkpoint 732036664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,498.74698
Policy Entropy: 3.65680
Value Function Loss: 0.07145

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.43163
Value Function Update Magnitude: 0.60128

Collected Steps per Second: 22,533.41382
Overall Steps per Second: 10,524.42775

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.53213
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.75123

Cumulative Model Updates: 87,778
Cumulative Timesteps: 732,086,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,133.25312
Policy Entropy: 3.66901
Value Function Loss: 0.07095

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.46839
Value Function Update Magnitude: 0.59226

Collected Steps per Second: 23,494.64693
Overall Steps per Second: 10,820.20002

Timestep Collection Time: 2.12866
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.62210

Cumulative Model Updates: 87,784
Cumulative Timesteps: 732,136,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 732136680...
Checkpoint 732136680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,292.80117
Policy Entropy: 3.67450
Value Function Loss: 0.07205

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.48668
Value Function Update Magnitude: 0.62657

Collected Steps per Second: 22,741.25490
Overall Steps per Second: 10,667.20957

Timestep Collection Time: 2.19988
Timestep Consumption Time: 2.49001
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.68989

Cumulative Model Updates: 87,790
Cumulative Timesteps: 732,186,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,877.10382
Policy Entropy: 3.68358
Value Function Loss: 0.07390

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06420
Policy Update Magnitude: 0.63071
Value Function Update Magnitude: 0.61808

Collected Steps per Second: 23,143.41900
Overall Steps per Second: 10,944.49571

Timestep Collection Time: 2.16105
Timestep Consumption Time: 2.40874
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.56979

Cumulative Model Updates: 87,796
Cumulative Timesteps: 732,236,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 732236722...
Checkpoint 732236722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.27071
Policy Entropy: 3.68243
Value Function Loss: 0.07487

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.73402
Value Function Update Magnitude: 0.61822

Collected Steps per Second: 22,965.31572
Overall Steps per Second: 10,684.11068

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.68265

Cumulative Model Updates: 87,802
Cumulative Timesteps: 732,286,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,693.85367
Policy Entropy: 3.66799
Value Function Loss: 0.07796

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.62145
Value Function Update Magnitude: 0.59035

Collected Steps per Second: 23,105.68340
Overall Steps per Second: 10,884.15184

Timestep Collection Time: 2.16492
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.59586

Cumulative Model Updates: 87,808
Cumulative Timesteps: 732,336,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 732336774...
Checkpoint 732336774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,968.68655
Policy Entropy: 3.67275
Value Function Loss: 0.07771

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.52324
Value Function Update Magnitude: 0.55125

Collected Steps per Second: 22,832.33427
Overall Steps per Second: 10,666.04272

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68927

Cumulative Model Updates: 87,814
Cumulative Timesteps: 732,386,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,269.63163
Policy Entropy: 3.67022
Value Function Loss: 0.07370

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.59237
Value Function Update Magnitude: 0.63557

Collected Steps per Second: 22,578.23346
Overall Steps per Second: 10,617.58718

Timestep Collection Time: 2.21514
Timestep Consumption Time: 2.49534
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.71049

Cumulative Model Updates: 87,820
Cumulative Timesteps: 732,436,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 732436804...
Checkpoint 732436804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,172.56752
Policy Entropy: 3.67448
Value Function Loss: 0.07160

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.72580
Value Function Update Magnitude: 0.69590

Collected Steps per Second: 22,306.99272
Overall Steps per Second: 10,655.36592

Timestep Collection Time: 2.24253
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69472

Cumulative Model Updates: 87,826
Cumulative Timesteps: 732,486,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,544.87698
Policy Entropy: 3.65923
Value Function Loss: 0.07047

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.61401
Value Function Update Magnitude: 0.72810

Collected Steps per Second: 22,638.71419
Overall Steps per Second: 10,705.54532

Timestep Collection Time: 2.20861
Timestep Consumption Time: 2.46187
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.67048

Cumulative Model Updates: 87,832
Cumulative Timesteps: 732,536,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 732536828...
Checkpoint 732536828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,915.26922
Policy Entropy: 3.66063
Value Function Loss: 0.07210

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.52425
Value Function Update Magnitude: 0.76866

Collected Steps per Second: 22,580.26124
Overall Steps per Second: 10,608.57931

Timestep Collection Time: 2.21485
Timestep Consumption Time: 2.49944
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.71430

Cumulative Model Updates: 87,838
Cumulative Timesteps: 732,586,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,509.46188
Policy Entropy: 3.65806
Value Function Loss: 0.07504

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.50395
Value Function Update Magnitude: 0.70115

Collected Steps per Second: 23,481.08106
Overall Steps per Second: 10,973.05233

Timestep Collection Time: 2.13057
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.55917

Cumulative Model Updates: 87,844
Cumulative Timesteps: 732,636,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 732636868...
Checkpoint 732636868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,970.46669
Policy Entropy: 3.67368
Value Function Loss: 0.07578

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.58983
Value Function Update Magnitude: 0.60746

Collected Steps per Second: 22,242.61855
Overall Steps per Second: 10,576.23922

Timestep Collection Time: 2.24812
Timestep Consumption Time: 2.47984
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.72796

Cumulative Model Updates: 87,850
Cumulative Timesteps: 732,686,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,407.64799
Policy Entropy: 3.66660
Value Function Loss: 0.07585

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.60702

Collected Steps per Second: 22,990.04676
Overall Steps per Second: 10,833.08216

Timestep Collection Time: 2.17651
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.61900

Cumulative Model Updates: 87,856
Cumulative Timesteps: 732,736,910

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 732736910...
Checkpoint 732736910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.94887
Policy Entropy: 3.65577
Value Function Loss: 0.07591

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.42814
Value Function Update Magnitude: 0.62263

Collected Steps per Second: 22,486.85948
Overall Steps per Second: 10,741.08390

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.65726

Cumulative Model Updates: 87,862
Cumulative Timesteps: 732,786,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,313.33521
Policy Entropy: 3.64376
Value Function Loss: 0.07567

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.16224
Policy Update Magnitude: 0.42635
Value Function Update Magnitude: 0.77136

Collected Steps per Second: 23,328.73843
Overall Steps per Second: 10,881.80720

Timestep Collection Time: 2.14354
Timestep Consumption Time: 2.45184
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.59538

Cumulative Model Updates: 87,868
Cumulative Timesteps: 732,836,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 732836940...
Checkpoint 732836940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,056.33282
Policy Entropy: 3.66444
Value Function Loss: 0.07491

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.41943
Value Function Update Magnitude: 0.83838

Collected Steps per Second: 22,695.82534
Overall Steps per Second: 10,649.42772

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.69659

Cumulative Model Updates: 87,874
Cumulative Timesteps: 732,886,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,994.48595
Policy Entropy: 3.65633
Value Function Loss: 0.07459

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.84713

Collected Steps per Second: 22,813.13378
Overall Steps per Second: 10,700.20519

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.67299

Cumulative Model Updates: 87,880
Cumulative Timesteps: 732,936,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 732936958...
Checkpoint 732936958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,524.81449
Policy Entropy: 3.65463
Value Function Loss: 0.07481

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.64153
Value Function Update Magnitude: 0.87568

Collected Steps per Second: 21,923.05438
Overall Steps per Second: 10,457.72347

Timestep Collection Time: 2.28070
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.78116

Cumulative Model Updates: 87,886
Cumulative Timesteps: 732,986,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,147.04180
Policy Entropy: 3.64271
Value Function Loss: 0.07320

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.58842
Value Function Update Magnitude: 0.87532

Collected Steps per Second: 22,707.68091
Overall Steps per Second: 10,784.87103

Timestep Collection Time: 2.20199
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.63631

Cumulative Model Updates: 87,892
Cumulative Timesteps: 733,036,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 733036960...
Checkpoint 733036960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,184.15985
Policy Entropy: 3.63545
Value Function Loss: 0.07224

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.57720
Value Function Update Magnitude: 0.86064

Collected Steps per Second: 22,272.11665
Overall Steps per Second: 10,676.74618

Timestep Collection Time: 2.24532
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.68382

Cumulative Model Updates: 87,898
Cumulative Timesteps: 733,086,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.26225
Policy Entropy: 3.63880
Value Function Loss: 0.07041

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.55326
Value Function Update Magnitude: 0.83806

Collected Steps per Second: 22,328.87685
Overall Steps per Second: 10,547.82736

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.74031

Cumulative Model Updates: 87,904
Cumulative Timesteps: 733,136,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 733136968...
Checkpoint 733136968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,276.20842
Policy Entropy: 3.64033
Value Function Loss: 0.07128

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.44515
Value Function Update Magnitude: 0.78136

Collected Steps per Second: 22,516.10746
Overall Steps per Second: 10,580.85217

Timestep Collection Time: 2.22063
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.72552

Cumulative Model Updates: 87,910
Cumulative Timesteps: 733,186,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.37769
Policy Entropy: 3.65596
Value Function Loss: 0.07372

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.40594
Value Function Update Magnitude: 0.67229

Collected Steps per Second: 23,248.72562
Overall Steps per Second: 10,858.46625

Timestep Collection Time: 2.15126
Timestep Consumption Time: 2.45473
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60599

Cumulative Model Updates: 87,916
Cumulative Timesteps: 733,236,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 733236982...
Checkpoint 733236982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.52797
Policy Entropy: 3.65700
Value Function Loss: 0.07547

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.44056
Value Function Update Magnitude: 0.66735

Collected Steps per Second: 21,511.79236
Overall Steps per Second: 10,359.58860

Timestep Collection Time: 2.32449
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.82683

Cumulative Model Updates: 87,922
Cumulative Timesteps: 733,286,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,300.49762
Policy Entropy: 3.64234
Value Function Loss: 0.07715

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.40530
Value Function Update Magnitude: 0.69150

Collected Steps per Second: 22,984.86891
Overall Steps per Second: 10,782.65568

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.63782

Cumulative Model Updates: 87,928
Cumulative Timesteps: 733,336,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 733336994...
Checkpoint 733336994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,558.15165
Policy Entropy: 3.63744
Value Function Loss: 0.07902

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.39520
Value Function Update Magnitude: 0.64190

Collected Steps per Second: 22,838.02905
Overall Steps per Second: 10,661.69683

Timestep Collection Time: 2.19091
Timestep Consumption Time: 2.50215
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69306

Cumulative Model Updates: 87,934
Cumulative Timesteps: 733,387,030

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,125.84487
Policy Entropy: 3.63764
Value Function Loss: 0.07646

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.46356
Value Function Update Magnitude: 0.59164

Collected Steps per Second: 22,852.99152
Overall Steps per Second: 10,779.69320

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.45065
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.63872

Cumulative Model Updates: 87,940
Cumulative Timesteps: 733,437,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 733437034...
Checkpoint 733437034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,146.37914
Policy Entropy: 3.65405
Value Function Loss: 0.07335

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.42672
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 22,197.10810
Overall Steps per Second: 10,705.30129

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.41900
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.67245

Cumulative Model Updates: 87,946
Cumulative Timesteps: 733,487,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.00367
Policy Entropy: 3.65300
Value Function Loss: 0.06836

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.50934
Value Function Update Magnitude: 0.64766

Collected Steps per Second: 22,854.55702
Overall Steps per Second: 10,716.73374

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.47884
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.66747

Cumulative Model Updates: 87,952
Cumulative Timesteps: 733,537,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 733537074...
Checkpoint 733537074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,349.81440
Policy Entropy: 3.64622
Value Function Loss: 0.07253

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.64259

Collected Steps per Second: 22,523.95731
Overall Steps per Second: 10,793.83535

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.41386
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.63505

Cumulative Model Updates: 87,958
Cumulative Timesteps: 733,587,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,797.89184
Policy Entropy: 3.65756
Value Function Loss: 0.07198

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.67376

Collected Steps per Second: 22,791.70333
Overall Steps per Second: 10,879.00332

Timestep Collection Time: 2.19387
Timestep Consumption Time: 2.40232
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.59619

Cumulative Model Updates: 87,964
Cumulative Timesteps: 733,637,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 733637106...
Checkpoint 733637106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.50732
Policy Entropy: 3.68386
Value Function Loss: 0.07290

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.68591

Collected Steps per Second: 22,227.35539
Overall Steps per Second: 10,660.16988

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.44176
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.69205

Cumulative Model Updates: 87,970
Cumulative Timesteps: 733,687,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,549.50682
Policy Entropy: 3.67622
Value Function Loss: 0.07276

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.65639
Value Function Update Magnitude: 0.67907

Collected Steps per Second: 23,340.07311
Overall Steps per Second: 10,901.77341

Timestep Collection Time: 2.14275
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.58751

Cumulative Model Updates: 87,976
Cumulative Timesteps: 733,737,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 733737136...
Checkpoint 733737136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.01920
Policy Entropy: 3.67432
Value Function Loss: 0.07518

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.59846
Value Function Update Magnitude: 0.66107

Collected Steps per Second: 22,736.35858
Overall Steps per Second: 10,718.20895

Timestep Collection Time: 2.19947
Timestep Consumption Time: 2.46623
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.66570

Cumulative Model Updates: 87,982
Cumulative Timesteps: 733,787,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,639.72130
Policy Entropy: 3.66453
Value Function Loss: 0.07491

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.55038
Value Function Update Magnitude: 0.65093

Collected Steps per Second: 22,883.93615
Overall Steps per Second: 10,822.07349

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.62019

Cumulative Model Updates: 87,988
Cumulative Timesteps: 733,837,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 733837144...
Checkpoint 733837144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,553.61926
Policy Entropy: 3.66797
Value Function Loss: 0.07553

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.65065
Value Function Update Magnitude: 0.69563

Collected Steps per Second: 22,310.72313
Overall Steps per Second: 10,696.58288

Timestep Collection Time: 2.24143
Timestep Consumption Time: 2.43370
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.67514

Cumulative Model Updates: 87,994
Cumulative Timesteps: 733,887,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,166.17918
Policy Entropy: 3.66551
Value Function Loss: 0.07522

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07786
Policy Update Magnitude: 0.75932
Value Function Update Magnitude: 0.83150

Collected Steps per Second: 23,227.75923
Overall Steps per Second: 10,929.39770

Timestep Collection Time: 2.15277
Timestep Consumption Time: 2.42241
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.57518

Cumulative Model Updates: 88,000
Cumulative Timesteps: 733,937,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 733937156...
Checkpoint 733937156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,818.48822
Policy Entropy: 3.65424
Value Function Loss: 0.07542

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.72250
Value Function Update Magnitude: 0.85495

Collected Steps per Second: 22,615.63859
Overall Steps per Second: 10,706.83454

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.45984
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.67141

Cumulative Model Updates: 88,006
Cumulative Timesteps: 733,987,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,218.38887
Policy Entropy: 3.64719
Value Function Loss: 0.07706

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.87160

Collected Steps per Second: 22,911.07134
Overall Steps per Second: 10,807.28691

Timestep Collection Time: 2.18270
Timestep Consumption Time: 2.44455
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62725

Cumulative Model Updates: 88,012
Cumulative Timesteps: 734,037,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 734037180...
Checkpoint 734037180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,865.55924
Policy Entropy: 3.63638
Value Function Loss: 0.07535

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.49878
Value Function Update Magnitude: 0.88137

Collected Steps per Second: 21,988.36887
Overall Steps per Second: 10,620.29400

Timestep Collection Time: 2.27493
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.71004

Cumulative Model Updates: 88,018
Cumulative Timesteps: 734,087,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,830.33631
Policy Entropy: 3.62799
Value Function Loss: 0.07835

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.46404
Value Function Update Magnitude: 0.82570

Collected Steps per Second: 22,677.92307
Overall Steps per Second: 10,542.89434

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.53825
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.74348

Cumulative Model Updates: 88,024
Cumulative Timesteps: 734,137,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 734137212...
Checkpoint 734137212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,315.57135
Policy Entropy: 3.63213
Value Function Loss: 0.07717

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.48547
Value Function Update Magnitude: 0.75844

Collected Steps per Second: 22,485.96874
Overall Steps per Second: 10,678.92016

Timestep Collection Time: 2.22503
Timestep Consumption Time: 2.46009
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.68512

Cumulative Model Updates: 88,030
Cumulative Timesteps: 734,187,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,095.22477
Policy Entropy: 3.63434
Value Function Loss: 0.07846

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.60003
Value Function Update Magnitude: 0.78310

Collected Steps per Second: 23,032.35949
Overall Steps per Second: 10,783.93708

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.46685
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.63875

Cumulative Model Updates: 88,036
Cumulative Timesteps: 734,237,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 734237268...
Checkpoint 734237268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,491.47211
Policy Entropy: 3.63288
Value Function Loss: 0.07476

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.69533
Value Function Update Magnitude: 0.76271

Collected Steps per Second: 22,568.75603
Overall Steps per Second: 10,726.90895

Timestep Collection Time: 2.21598
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.66229

Cumulative Model Updates: 88,042
Cumulative Timesteps: 734,287,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,283.86659
Policy Entropy: 3.62869
Value Function Loss: 0.07198

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.60541
Value Function Update Magnitude: 0.67343

Collected Steps per Second: 23,184.49324
Overall Steps per Second: 10,885.21244

Timestep Collection Time: 2.15730
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.59486

Cumulative Model Updates: 88,048
Cumulative Timesteps: 734,337,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 734337296...
Checkpoint 734337296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,785.47752
Policy Entropy: 3.63675
Value Function Loss: 0.07171

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.58933
Value Function Update Magnitude: 0.63769

Collected Steps per Second: 22,585.87086
Overall Steps per Second: 10,674.23189

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.47100
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.68530

Cumulative Model Updates: 88,054
Cumulative Timesteps: 734,387,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,020.88644
Policy Entropy: 3.63690
Value Function Loss: 0.07335

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.52157
Value Function Update Magnitude: 0.65428

Collected Steps per Second: 22,915.75726
Overall Steps per Second: 10,810.22570

Timestep Collection Time: 2.18252
Timestep Consumption Time: 2.44403
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62655

Cumulative Model Updates: 88,060
Cumulative Timesteps: 734,437,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 734437322...
Checkpoint 734437322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,560.33340
Policy Entropy: 3.63707
Value Function Loss: 0.07503

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.50931
Value Function Update Magnitude: 0.68510

Collected Steps per Second: 22,759.62734
Overall Steps per Second: 10,753.48757

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.45366
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.65133

Cumulative Model Updates: 88,066
Cumulative Timesteps: 734,487,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,824.65688
Policy Entropy: 3.62513
Value Function Loss: 0.07891

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.54711
Value Function Update Magnitude: 0.65670

Collected Steps per Second: 22,590.49479
Overall Steps per Second: 10,640.69414

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69969

Cumulative Model Updates: 88,072
Cumulative Timesteps: 734,537,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 734537348...
Checkpoint 734537348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,772.66781
Policy Entropy: 3.62135
Value Function Loss: 0.07838

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.48939
Value Function Update Magnitude: 0.66528

Collected Steps per Second: 22,486.97168
Overall Steps per Second: 10,662.16786

Timestep Collection Time: 2.22458
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69173

Cumulative Model Updates: 88,078
Cumulative Timesteps: 734,587,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.39288
Policy Entropy: 3.62373
Value Function Loss: 0.07650

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.45733
Value Function Update Magnitude: 0.68976

Collected Steps per Second: 22,931.56882
Overall Steps per Second: 10,659.36268

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69165

Cumulative Model Updates: 88,084
Cumulative Timesteps: 734,637,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 734637382...
Checkpoint 734637382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.48290
Policy Entropy: 3.61451
Value Function Loss: 0.07584

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.52482
Value Function Update Magnitude: 0.79132

Collected Steps per Second: 22,572.53936
Overall Steps per Second: 10,697.43687

Timestep Collection Time: 2.21606
Timestep Consumption Time: 2.46002
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.67607

Cumulative Model Updates: 88,090
Cumulative Timesteps: 734,687,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.08148
Policy Entropy: 3.62297
Value Function Loss: 0.07915

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.52694
Value Function Update Magnitude: 0.80415

Collected Steps per Second: 23,177.61153
Overall Steps per Second: 10,915.65599

Timestep Collection Time: 2.15820
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.58259

Cumulative Model Updates: 88,096
Cumulative Timesteps: 734,737,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 734737426...
Checkpoint 734737426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,261.35023
Policy Entropy: 3.61196
Value Function Loss: 0.08584

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.48714
Value Function Update Magnitude: 0.78207

Collected Steps per Second: 22,677.53377
Overall Steps per Second: 10,641.90066

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.70085

Cumulative Model Updates: 88,102
Cumulative Timesteps: 734,787,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,074.06705
Policy Entropy: 3.61583
Value Function Loss: 0.09072

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.47140
Value Function Update Magnitude: 0.68517

Collected Steps per Second: 22,483.45129
Overall Steps per Second: 10,865.01116

Timestep Collection Time: 2.22457
Timestep Consumption Time: 2.37883
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.60340

Cumulative Model Updates: 88,108
Cumulative Timesteps: 734,837,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 734837468...
Checkpoint 734837468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,428.76291
Policy Entropy: 3.59907
Value Function Loss: 0.09151

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.45627
Value Function Update Magnitude: 0.63748

Collected Steps per Second: 22,071.36260
Overall Steps per Second: 10,606.76404

Timestep Collection Time: 2.26574
Timestep Consumption Time: 2.44899
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.71473

Cumulative Model Updates: 88,114
Cumulative Timesteps: 734,887,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,969.30098
Policy Entropy: 3.59585
Value Function Loss: 0.08672

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.47204
Value Function Update Magnitude: 0.67722

Collected Steps per Second: 22,331.46335
Overall Steps per Second: 10,876.06956

Timestep Collection Time: 2.23998
Timestep Consumption Time: 2.35929
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.59927

Cumulative Model Updates: 88,120
Cumulative Timesteps: 734,937,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 734937498...
Checkpoint 734937498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,206.05878
Policy Entropy: 3.59417
Value Function Loss: 0.08384

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.45689
Value Function Update Magnitude: 0.70280

Collected Steps per Second: 21,896.21138
Overall Steps per Second: 10,721.86209

Timestep Collection Time: 2.28359
Timestep Consumption Time: 2.37996
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.66356

Cumulative Model Updates: 88,126
Cumulative Timesteps: 734,987,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.85725
Policy Entropy: 3.60159
Value Function Loss: 0.08324

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.49328
Value Function Update Magnitude: 0.64781

Collected Steps per Second: 22,077.74632
Overall Steps per Second: 10,512.95425

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.75623

Cumulative Model Updates: 88,132
Cumulative Timesteps: 735,037,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 735037502...
Checkpoint 735037502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,518.35074
Policy Entropy: 3.61145
Value Function Loss: 0.08586

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.51021
Value Function Update Magnitude: 0.59704

Collected Steps per Second: 22,126.82073
Overall Steps per Second: 10,533.02148

Timestep Collection Time: 2.26006
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.74774

Cumulative Model Updates: 88,138
Cumulative Timesteps: 735,087,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,001.93436
Policy Entropy: 3.60629
Value Function Loss: 0.08608

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.59902
Value Function Update Magnitude: 0.57692

Collected Steps per Second: 22,772.25937
Overall Steps per Second: 10,867.36918

Timestep Collection Time: 2.19601
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.60167

Cumulative Model Updates: 88,144
Cumulative Timesteps: 735,137,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 735137518...
Checkpoint 735137518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,895.34433
Policy Entropy: 3.60338
Value Function Loss: 0.08580

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.55701
Value Function Update Magnitude: 0.58381

Collected Steps per Second: 22,637.75633
Overall Steps per Second: 10,670.99681

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.47700
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.68579

Cumulative Model Updates: 88,150
Cumulative Timesteps: 735,187,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,254.30616
Policy Entropy: 3.61001
Value Function Loss: 0.08435

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.49748
Value Function Update Magnitude: 0.64054

Collected Steps per Second: 22,727.89868
Overall Steps per Second: 10,852.69410

Timestep Collection Time: 2.20029
Timestep Consumption Time: 2.40760
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60789

Cumulative Model Updates: 88,156
Cumulative Timesteps: 735,237,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 735237528...
Checkpoint 735237528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,111.07915
Policy Entropy: 3.62352
Value Function Loss: 0.08454

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.47907
Value Function Update Magnitude: 0.67923

Collected Steps per Second: 22,342.17040
Overall Steps per Second: 10,681.67942

Timestep Collection Time: 2.23873
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.68260

Cumulative Model Updates: 88,162
Cumulative Timesteps: 735,287,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.15149
Policy Entropy: 3.61487
Value Function Loss: 0.08428

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.50742
Value Function Update Magnitude: 0.72151

Collected Steps per Second: 23,101.29079
Overall Steps per Second: 10,878.01534

Timestep Collection Time: 2.16516
Timestep Consumption Time: 2.43292
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.59808

Cumulative Model Updates: 88,168
Cumulative Timesteps: 735,337,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 735337564...
Checkpoint 735337564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,075.40159
Policy Entropy: 3.60929
Value Function Loss: 0.08622

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.63954

Collected Steps per Second: 22,269.20690
Overall Steps per Second: 10,722.29665

Timestep Collection Time: 2.24669
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.66616

Cumulative Model Updates: 88,174
Cumulative Timesteps: 735,387,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,319.92512
Policy Entropy: 3.59605
Value Function Loss: 0.08812

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.66259

Collected Steps per Second: 22,979.43600
Overall Steps per Second: 10,768.43382

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.46892
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.64617

Cumulative Model Updates: 88,180
Cumulative Timesteps: 735,437,628

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 735437628...
Checkpoint 735437628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,454.36246
Policy Entropy: 3.59761
Value Function Loss: 0.09405

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.70223

Collected Steps per Second: 22,654.35009
Overall Steps per Second: 10,611.12113

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.71241

Cumulative Model Updates: 88,186
Cumulative Timesteps: 735,487,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,450.99622
Policy Entropy: 3.58827
Value Function Loss: 0.09823

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.59300
Value Function Update Magnitude: 0.65978

Collected Steps per Second: 23,181.04807
Overall Steps per Second: 10,779.42183

Timestep Collection Time: 2.15693
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.63847

Cumulative Model Updates: 88,192
Cumulative Timesteps: 735,537,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 735537632...
Checkpoint 735537632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,041.22892
Policy Entropy: 3.59877
Value Function Loss: 0.09622

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.16657
Policy Update Magnitude: 0.53313
Value Function Update Magnitude: 0.62667

Collected Steps per Second: 22,858.55421
Overall Steps per Second: 10,829.82688

Timestep Collection Time: 2.18798
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.61817

Cumulative Model Updates: 88,198
Cumulative Timesteps: 735,587,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,023.71468
Policy Entropy: 3.61563
Value Function Loss: 0.09280

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.42377
Value Function Update Magnitude: 0.68984

Collected Steps per Second: 23,104.85283
Overall Steps per Second: 10,854.39293

Timestep Collection Time: 2.16483
Timestep Consumption Time: 2.44326
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60809

Cumulative Model Updates: 88,204
Cumulative Timesteps: 735,637,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 735637664...
Checkpoint 735637664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,587.85106
Policy Entropy: 3.61397
Value Function Loss: 0.08727

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.39998
Value Function Update Magnitude: 0.77850

Collected Steps per Second: 22,626.97148
Overall Steps per Second: 10,772.02198

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.64165

Cumulative Model Updates: 88,210
Cumulative Timesteps: 735,687,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,977.40094
Policy Entropy: 3.59962
Value Function Loss: 0.08577

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.44061
Value Function Update Magnitude: 0.78026

Collected Steps per Second: 22,628.01103
Overall Steps per Second: 10,767.70884

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.64593

Cumulative Model Updates: 88,216
Cumulative Timesteps: 735,737,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 735737690...
Checkpoint 735737690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,104.97496
Policy Entropy: 3.59962
Value Function Loss: 0.08335

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.41613
Value Function Update Magnitude: 0.80186

Collected Steps per Second: 22,047.72002
Overall Steps per Second: 10,666.70215

Timestep Collection Time: 2.26862
Timestep Consumption Time: 2.42055
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.68917

Cumulative Model Updates: 88,222
Cumulative Timesteps: 735,787,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,634.36392
Policy Entropy: 3.60368
Value Function Loss: 0.08160

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.42089
Value Function Update Magnitude: 0.71859

Collected Steps per Second: 22,515.80847
Overall Steps per Second: 10,582.69527

Timestep Collection Time: 2.22137
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.72621

Cumulative Model Updates: 88,228
Cumulative Timesteps: 735,837,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 735837724...
Checkpoint 735837724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,350.08049
Policy Entropy: 3.61936
Value Function Loss: 0.07962

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.46776
Value Function Update Magnitude: 0.62602

Collected Steps per Second: 22,399.82059
Overall Steps per Second: 10,579.27338

Timestep Collection Time: 2.23305
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.72811

Cumulative Model Updates: 88,234
Cumulative Timesteps: 735,887,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.71655
Policy Entropy: 3.63633
Value Function Loss: 0.07482

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.47773
Value Function Update Magnitude: 0.65129

Collected Steps per Second: 22,823.71892
Overall Steps per Second: 10,830.49425

Timestep Collection Time: 2.19114
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.61752

Cumulative Model Updates: 88,240
Cumulative Timesteps: 735,937,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 735937754...
Checkpoint 735937754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,714.24534
Policy Entropy: 3.64693
Value Function Loss: 0.07515

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.49049
Value Function Update Magnitude: 0.70478

Collected Steps per Second: 22,389.64383
Overall Steps per Second: 10,698.14247

Timestep Collection Time: 2.23344
Timestep Consumption Time: 2.44083
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.67427

Cumulative Model Updates: 88,246
Cumulative Timesteps: 735,987,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,085.10131
Policy Entropy: 3.64996
Value Function Loss: 0.07227

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.47014
Value Function Update Magnitude: 0.71551

Collected Steps per Second: 23,028.38498
Overall Steps per Second: 10,834.00157

Timestep Collection Time: 2.17254
Timestep Consumption Time: 2.44533
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.61787

Cumulative Model Updates: 88,252
Cumulative Timesteps: 736,037,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 736037790...
Checkpoint 736037790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,167.21270
Policy Entropy: 3.65610
Value Function Loss: 0.07085

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.46754
Value Function Update Magnitude: 0.64395

Collected Steps per Second: 22,331.73194
Overall Steps per Second: 10,704.11781

Timestep Collection Time: 2.23986
Timestep Consumption Time: 2.43311
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.67297

Cumulative Model Updates: 88,258
Cumulative Timesteps: 736,087,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,976.01093
Policy Entropy: 3.66809
Value Function Loss: 0.06635

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.46604
Value Function Update Magnitude: 0.70382

Collected Steps per Second: 23,033.36610
Overall Steps per Second: 10,879.48280

Timestep Collection Time: 2.17128
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59691

Cumulative Model Updates: 88,264
Cumulative Timesteps: 736,137,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 736137822...
Checkpoint 736137822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.04783
Policy Entropy: 3.65019
Value Function Loss: 0.06866

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.72781

Collected Steps per Second: 22,747.34601
Overall Steps per Second: 10,722.83452

Timestep Collection Time: 2.19876
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.66444

Cumulative Model Updates: 88,270
Cumulative Timesteps: 736,187,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,673.23145
Policy Entropy: 3.65238
Value Function Loss: 0.07105

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.63692

Collected Steps per Second: 22,673.47173
Overall Steps per Second: 10,682.12195

Timestep Collection Time: 2.20628
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.68296

Cumulative Model Updates: 88,276
Cumulative Timesteps: 736,237,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 736237862...
Checkpoint 736237862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,803.45501
Policy Entropy: 3.64122
Value Function Loss: 0.07433

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.50494
Value Function Update Magnitude: 0.63862

Collected Steps per Second: 22,313.78901
Overall Steps per Second: 10,624.94189

Timestep Collection Time: 2.24104
Timestep Consumption Time: 2.46544
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.70647

Cumulative Model Updates: 88,282
Cumulative Timesteps: 736,287,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594.88972
Policy Entropy: 3.65041
Value Function Loss: 0.07441

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.61329
Value Function Update Magnitude: 0.65064

Collected Steps per Second: 22,752.99711
Overall Steps per Second: 10,723.43319

Timestep Collection Time: 2.19830
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.66436

Cumulative Model Updates: 88,288
Cumulative Timesteps: 736,337,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 736337886...
Checkpoint 736337886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,862.06921
Policy Entropy: 3.65250
Value Function Loss: 0.07295

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.60310
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 22,748.21708
Overall Steps per Second: 10,603.79572

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.71774

Cumulative Model Updates: 88,294
Cumulative Timesteps: 736,387,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,284.41546
Policy Entropy: 3.65597
Value Function Loss: 0.07197

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.65402

Collected Steps per Second: 23,409.65644
Overall Steps per Second: 10,944.81863

Timestep Collection Time: 2.13604
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.56874

Cumulative Model Updates: 88,300
Cumulative Timesteps: 736,437,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 736437916...
Checkpoint 736437916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,805.53556
Policy Entropy: 3.64555
Value Function Loss: 0.07165

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.54213
Value Function Update Magnitude: 0.63228

Collected Steps per Second: 22,847.25332
Overall Steps per Second: 10,634.21707

Timestep Collection Time: 2.18967
Timestep Consumption Time: 2.51476
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.70444

Cumulative Model Updates: 88,306
Cumulative Timesteps: 736,487,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,157.58776
Policy Entropy: 3.65257
Value Function Loss: 0.07287

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.55438
Value Function Update Magnitude: 0.62615

Collected Steps per Second: 23,031.82059
Overall Steps per Second: 10,883.49796

Timestep Collection Time: 2.17143
Timestep Consumption Time: 2.42378
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.59521

Cumulative Model Updates: 88,312
Cumulative Timesteps: 736,537,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 736537956...
Checkpoint 736537956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,216.27167
Policy Entropy: 3.66335
Value Function Loss: 0.07006

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.67075
Value Function Update Magnitude: 0.64934

Collected Steps per Second: 23,182.61650
Overall Steps per Second: 10,796.02835

Timestep Collection Time: 2.15731
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.63244

Cumulative Model Updates: 88,318
Cumulative Timesteps: 736,587,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,198.21735
Policy Entropy: 3.65762
Value Function Loss: 0.06839

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.73599
Value Function Update Magnitude: 0.66996

Collected Steps per Second: 22,887.24896
Overall Steps per Second: 10,728.90277

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.66329

Cumulative Model Updates: 88,324
Cumulative Timesteps: 736,638,000

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 736638000...
Checkpoint 736638000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,545.06661
Policy Entropy: 3.65845
Value Function Loss: 0.06830

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.75710
Value Function Update Magnitude: 0.68647

Collected Steps per Second: 22,613.61814
Overall Steps per Second: 10,666.13742

Timestep Collection Time: 2.21115
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.68792

Cumulative Model Updates: 88,330
Cumulative Timesteps: 736,688,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,538.72022
Policy Entropy: 3.65989
Value Function Loss: 0.07342

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08685
Policy Update Magnitude: 0.76512
Value Function Update Magnitude: 0.72207

Collected Steps per Second: 22,572.72780
Overall Steps per Second: 10,636.54995

Timestep Collection Time: 2.21604
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.70284

Cumulative Model Updates: 88,336
Cumulative Timesteps: 736,738,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 736738024...
Checkpoint 736738024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,088.83742
Policy Entropy: 3.65782
Value Function Loss: 0.07437

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.66113
Value Function Update Magnitude: 0.67838

Collected Steps per Second: 22,664.99825
Overall Steps per Second: 10,868.84728

Timestep Collection Time: 2.20640
Timestep Consumption Time: 2.39464
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.60104

Cumulative Model Updates: 88,342
Cumulative Timesteps: 736,788,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.65586
Policy Entropy: 3.64797
Value Function Loss: 0.07556

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.61197
Value Function Update Magnitude: 0.74668

Collected Steps per Second: 22,527.98330
Overall Steps per Second: 10,575.13726

Timestep Collection Time: 2.22017
Timestep Consumption Time: 2.50941
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.72958

Cumulative Model Updates: 88,348
Cumulative Timesteps: 736,838,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 736838048...
Checkpoint 736838048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,662.26787
Policy Entropy: 3.66142
Value Function Loss: 0.07479

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.59910
Value Function Update Magnitude: 0.79677

Collected Steps per Second: 22,156.21754
Overall Steps per Second: 10,562.21253

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.47834
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.73613

Cumulative Model Updates: 88,354
Cumulative Timesteps: 736,888,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.07515
Policy Entropy: 3.66762
Value Function Loss: 0.07501

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.59025
Value Function Update Magnitude: 0.83738

Collected Steps per Second: 22,935.39585
Overall Steps per Second: 10,660.67626

Timestep Collection Time: 2.18030
Timestep Consumption Time: 2.51040
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69070

Cumulative Model Updates: 88,360
Cumulative Timesteps: 736,938,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 736938078...
Checkpoint 736938078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,933.19987
Policy Entropy: 3.68381
Value Function Loss: 0.07174

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.87909

Collected Steps per Second: 22,798.30010
Overall Steps per Second: 10,815.56941

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.62389

Cumulative Model Updates: 88,366
Cumulative Timesteps: 736,988,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,851.24452
Policy Entropy: 3.68378
Value Function Loss: 0.07214

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.63035
Value Function Update Magnitude: 0.88277

Collected Steps per Second: 22,851.63878
Overall Steps per Second: 10,623.71348

Timestep Collection Time: 2.18934
Timestep Consumption Time: 2.51994
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.70928

Cumulative Model Updates: 88,372
Cumulative Timesteps: 737,038,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 737038118...
Checkpoint 737038118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,759.10472
Policy Entropy: 3.68678
Value Function Loss: 0.07136

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.61946
Value Function Update Magnitude: 0.90364

Collected Steps per Second: 22,808.51596
Overall Steps per Second: 10,681.91819

Timestep Collection Time: 2.19260
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.68174

Cumulative Model Updates: 88,378
Cumulative Timesteps: 737,088,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,524.87112
Policy Entropy: 3.67307
Value Function Loss: 0.07346

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.55893
Value Function Update Magnitude: 0.85355

Collected Steps per Second: 21,791.34172
Overall Steps per Second: 10,408.66152

Timestep Collection Time: 2.29486
Timestep Consumption Time: 2.50960
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.80446

Cumulative Model Updates: 88,384
Cumulative Timesteps: 737,138,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 737138136...
Checkpoint 737138136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,392.63161
Policy Entropy: 3.65974
Value Function Loss: 0.07513

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.80953

Collected Steps per Second: 22,360.23589
Overall Steps per Second: 10,534.03687

Timestep Collection Time: 2.23638
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.74709

Cumulative Model Updates: 88,390
Cumulative Timesteps: 737,188,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,316.12806
Policy Entropy: 3.65375
Value Function Loss: 0.07564

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.59034
Value Function Update Magnitude: 0.83259

Collected Steps per Second: 22,479.94246
Overall Steps per Second: 10,573.88143

Timestep Collection Time: 2.22527
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73090

Cumulative Model Updates: 88,396
Cumulative Timesteps: 737,238,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 737238166...
Checkpoint 737238166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,943.48272
Policy Entropy: 3.64701
Value Function Loss: 0.07536

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.64393
Value Function Update Magnitude: 0.89966

Collected Steps per Second: 22,566.04552
Overall Steps per Second: 10,597.17656

Timestep Collection Time: 2.21634
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.71956

Cumulative Model Updates: 88,402
Cumulative Timesteps: 737,288,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,577.28892
Policy Entropy: 3.65837
Value Function Loss: 0.07579

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.91767

Collected Steps per Second: 23,125.22771
Overall Steps per Second: 10,876.02074

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.59819

Cumulative Model Updates: 88,408
Cumulative Timesteps: 737,338,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 737338190...
Checkpoint 737338190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,646.79301
Policy Entropy: 3.64865
Value Function Loss: 0.07733

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.17219
Policy Update Magnitude: 0.54470
Value Function Update Magnitude: 0.89123

Collected Steps per Second: 22,326.37488
Overall Steps per Second: 10,584.08317

Timestep Collection Time: 2.24058
Timestep Consumption Time: 2.48576
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.72634

Cumulative Model Updates: 88,414
Cumulative Timesteps: 737,388,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,160.31185
Policy Entropy: 3.66988
Value Function Loss: 0.07445

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.48480
Value Function Update Magnitude: 0.87653

Collected Steps per Second: 23,236.35641
Overall Steps per Second: 10,922.52430

Timestep Collection Time: 2.15197
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.57806

Cumulative Model Updates: 88,420
Cumulative Timesteps: 737,438,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 737438218...
Checkpoint 737438218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,911.48467
Policy Entropy: 3.66777
Value Function Loss: 0.07074

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.90474

Collected Steps per Second: 22,775.90392
Overall Steps per Second: 10,621.37305

Timestep Collection Time: 2.19565
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.70824

Cumulative Model Updates: 88,426
Cumulative Timesteps: 737,488,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,391.35068
Policy Entropy: 3.67688
Value Function Loss: 0.06972

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.64052
Value Function Update Magnitude: 0.89789

Collected Steps per Second: 22,985.72326
Overall Steps per Second: 10,864.65860

Timestep Collection Time: 2.17535
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60226

Cumulative Model Updates: 88,432
Cumulative Timesteps: 737,538,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 737538228...
Checkpoint 737538228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,473.09328
Policy Entropy: 3.66931
Value Function Loss: 0.07066

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.63528
Value Function Update Magnitude: 0.92998

Collected Steps per Second: 22,588.60298
Overall Steps per Second: 10,722.29937

Timestep Collection Time: 2.21519
Timestep Consumption Time: 2.45153
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.66672

Cumulative Model Updates: 88,438
Cumulative Timesteps: 737,588,266

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,542.54530
Policy Entropy: 3.66946
Value Function Loss: 0.07188

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.65815
Value Function Update Magnitude: 0.94348

Collected Steps per Second: 22,514.42001
Overall Steps per Second: 10,639.97206

Timestep Collection Time: 2.22098
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.69964

Cumulative Model Updates: 88,444
Cumulative Timesteps: 737,638,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 737638270...
Checkpoint 737638270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.03964
Policy Entropy: 3.68169
Value Function Loss: 0.07098

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.70879
Value Function Update Magnitude: 0.91046

Collected Steps per Second: 22,072.75436
Overall Steps per Second: 10,494.17577

Timestep Collection Time: 2.26524
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.76455

Cumulative Model Updates: 88,450
Cumulative Timesteps: 737,688,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,052.34971
Policy Entropy: 3.68892
Value Function Loss: 0.07069

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.70616
Value Function Update Magnitude: 0.92176

Collected Steps per Second: 22,322.57532
Overall Steps per Second: 10,618.94666

Timestep Collection Time: 2.24042
Timestep Consumption Time: 2.46927
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.70970

Cumulative Model Updates: 88,456
Cumulative Timesteps: 737,738,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 737738282...
Checkpoint 737738282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.53570
Policy Entropy: 3.70761
Value Function Loss: 0.06976

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.77772
Value Function Update Magnitude: 0.97194

Collected Steps per Second: 22,461.32117
Overall Steps per Second: 10,779.56463

Timestep Collection Time: 2.22641
Timestep Consumption Time: 2.41274
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.63915

Cumulative Model Updates: 88,462
Cumulative Timesteps: 737,788,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,395.34686
Policy Entropy: 3.70496
Value Function Loss: 0.07081

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.73269
Value Function Update Magnitude: 0.95317

Collected Steps per Second: 23,188.44503
Overall Steps per Second: 10,681.27809

Timestep Collection Time: 2.15754
Timestep Consumption Time: 2.52636
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.68390

Cumulative Model Updates: 88,468
Cumulative Timesteps: 737,838,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 737838320...
Checkpoint 737838320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,356.14297
Policy Entropy: 3.69123
Value Function Loss: 0.07464

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.67070
Value Function Update Magnitude: 0.91851

Collected Steps per Second: 22,847.39406
Overall Steps per Second: 10,837.05865

Timestep Collection Time: 2.18870
Timestep Consumption Time: 2.42566
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61435

Cumulative Model Updates: 88,474
Cumulative Timesteps: 737,888,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.99216
Policy Entropy: 3.69013
Value Function Loss: 0.07584

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.88623

Collected Steps per Second: 22,836.76802
Overall Steps per Second: 10,673.68890

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.68592

Cumulative Model Updates: 88,480
Cumulative Timesteps: 737,938,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 737938342...
Checkpoint 737938342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.10222
Policy Entropy: 3.69594
Value Function Loss: 0.07276

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.52453
Value Function Update Magnitude: 0.85885

Collected Steps per Second: 23,038.31158
Overall Steps per Second: 10,896.19173

Timestep Collection Time: 2.17151
Timestep Consumption Time: 2.41982
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.59133

Cumulative Model Updates: 88,486
Cumulative Timesteps: 737,988,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,720.22728
Policy Entropy: 3.70777
Value Function Loss: 0.07065

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.82326

Collected Steps per Second: 22,881.96019
Overall Steps per Second: 10,696.03082

Timestep Collection Time: 2.18548
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.67538

Cumulative Model Updates: 88,492
Cumulative Timesteps: 738,038,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 738038378...
Checkpoint 738038378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,643.74013
Policy Entropy: 3.69652
Value Function Loss: 0.06886

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.66898
Value Function Update Magnitude: 0.75679

Collected Steps per Second: 22,883.64166
Overall Steps per Second: 10,865.58167

Timestep Collection Time: 2.18619
Timestep Consumption Time: 2.41807
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.60426

Cumulative Model Updates: 88,498
Cumulative Timesteps: 738,088,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,603.71956
Policy Entropy: 3.69202
Value Function Loss: 0.07203

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.71537
Value Function Update Magnitude: 0.74679

Collected Steps per Second: 22,271.91727
Overall Steps per Second: 10,518.22801

Timestep Collection Time: 2.24534
Timestep Consumption Time: 2.50907
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.75441

Cumulative Model Updates: 88,504
Cumulative Timesteps: 738,138,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 738138414...
Checkpoint 738138414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,769.82581
Policy Entropy: 3.68997
Value Function Loss: 0.07332

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.62227
Value Function Update Magnitude: 0.75017

Collected Steps per Second: 22,516.86481
Overall Steps per Second: 10,674.48205

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.68819

Cumulative Model Updates: 88,510
Cumulative Timesteps: 738,188,458

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.23741
Policy Entropy: 3.68455
Value Function Loss: 0.07574

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.74490

Collected Steps per Second: 22,582.96984
Overall Steps per Second: 10,810.32483

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.41211
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.62706

Cumulative Model Updates: 88,516
Cumulative Timesteps: 738,238,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 738238478...
Checkpoint 738238478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.51804
Policy Entropy: 3.68897
Value Function Loss: 0.07559

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.55262
Value Function Update Magnitude: 0.81628

Collected Steps per Second: 22,555.04287
Overall Steps per Second: 10,696.50084

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.45782
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.67480

Cumulative Model Updates: 88,522
Cumulative Timesteps: 738,288,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,246.51709
Policy Entropy: 3.68260
Value Function Loss: 0.07538

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.76692

Collected Steps per Second: 23,086.68157
Overall Steps per Second: 10,846.56127

Timestep Collection Time: 2.16679
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61197

Cumulative Model Updates: 88,528
Cumulative Timesteps: 738,338,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 738338506...
Checkpoint 738338506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,331.25720
Policy Entropy: 3.68574
Value Function Loss: 0.07741

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.72872

Collected Steps per Second: 22,693.31480
Overall Steps per Second: 10,718.73264

Timestep Collection Time: 2.20400
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.66622

Cumulative Model Updates: 88,534
Cumulative Timesteps: 738,388,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161.78204
Policy Entropy: 3.68111
Value Function Loss: 0.07947

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.72685
Value Function Update Magnitude: 0.75180

Collected Steps per Second: 23,198.13217
Overall Steps per Second: 10,889.05079

Timestep Collection Time: 2.15759
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59654

Cumulative Model Updates: 88,540
Cumulative Timesteps: 738,438,574

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 738438574...
Checkpoint 738438574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,198.89160
Policy Entropy: 3.68091
Value Function Loss: 0.07756

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.84904
Value Function Update Magnitude: 0.78080

Collected Steps per Second: 22,791.66344
Overall Steps per Second: 10,634.41687

Timestep Collection Time: 2.19449
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.70322

Cumulative Model Updates: 88,546
Cumulative Timesteps: 738,488,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.12000
Policy Entropy: 3.67002
Value Function Loss: 0.07881

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.79913
Value Function Update Magnitude: 0.75461

Collected Steps per Second: 22,802.16585
Overall Steps per Second: 10,755.40337

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.45733
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.65124

Cumulative Model Updates: 88,552
Cumulative Timesteps: 738,538,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 738538616...
Checkpoint 738538616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.36930
Policy Entropy: 3.66743
Value Function Loss: 0.07531

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.66341
Value Function Update Magnitude: 0.79323

Collected Steps per Second: 22,848.90828
Overall Steps per Second: 10,828.62463

Timestep Collection Time: 2.18951
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61998

Cumulative Model Updates: 88,558
Cumulative Timesteps: 738,588,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.52866
Policy Entropy: 3.66826
Value Function Loss: 0.07386

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.61062
Value Function Update Magnitude: 0.82247

Collected Steps per Second: 22,424.92547
Overall Steps per Second: 10,553.61813

Timestep Collection Time: 2.22975
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.73790

Cumulative Model Updates: 88,564
Cumulative Timesteps: 738,638,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 738638646...
Checkpoint 738638646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,874.20856
Policy Entropy: 3.67036
Value Function Loss: 0.07248

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.64451
Value Function Update Magnitude: 0.83628

Collected Steps per Second: 21,793.62273
Overall Steps per Second: 10,635.11606

Timestep Collection Time: 2.29434
Timestep Consumption Time: 2.40725
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.70159

Cumulative Model Updates: 88,570
Cumulative Timesteps: 738,688,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,390.33851
Policy Entropy: 3.66316
Value Function Loss: 0.07099

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.62853
Value Function Update Magnitude: 0.89731

Collected Steps per Second: 21,852.07692
Overall Steps per Second: 10,769.20963

Timestep Collection Time: 2.28839
Timestep Consumption Time: 2.35504
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.64342

Cumulative Model Updates: 88,576
Cumulative Timesteps: 738,738,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 738738654...
Checkpoint 738738654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.60181
Policy Entropy: 3.64868
Value Function Loss: 0.07174

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.61666
Value Function Update Magnitude: 0.93010

Collected Steps per Second: 21,990.33266
Overall Steps per Second: 10,719.89193

Timestep Collection Time: 2.27409
Timestep Consumption Time: 2.39088
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.66497

Cumulative Model Updates: 88,582
Cumulative Timesteps: 738,788,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.31235
Policy Entropy: 3.63832
Value Function Loss: 0.07488

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.52750
Value Function Update Magnitude: 0.83588

Collected Steps per Second: 22,425.92432
Overall Steps per Second: 10,831.05077

Timestep Collection Time: 2.23010
Timestep Consumption Time: 2.38737
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.61747

Cumulative Model Updates: 88,588
Cumulative Timesteps: 738,838,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 738838674...
Checkpoint 738838674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,440.28182
Policy Entropy: 3.63501
Value Function Loss: 0.07759

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.80392

Collected Steps per Second: 22,196.89656
Overall Steps per Second: 10,673.90940

Timestep Collection Time: 2.25428
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68788

Cumulative Model Updates: 88,594
Cumulative Timesteps: 738,888,712

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,042.23109
Policy Entropy: 3.62964
Value Function Loss: 0.07714

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.78519

Collected Steps per Second: 22,383.12295
Overall Steps per Second: 10,898.11765

Timestep Collection Time: 2.23499
Timestep Consumption Time: 2.35535
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.59033

Cumulative Model Updates: 88,600
Cumulative Timesteps: 738,938,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 738938738...
Checkpoint 738938738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.98946
Policy Entropy: 3.63001
Value Function Loss: 0.07396

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.53534
Value Function Update Magnitude: 0.80713

Collected Steps per Second: 22,107.08844
Overall Steps per Second: 10,661.02625

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.69242

Cumulative Model Updates: 88,606
Cumulative Timesteps: 738,988,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.04044
Policy Entropy: 3.63491
Value Function Loss: 0.07236

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.50467
Value Function Update Magnitude: 0.86372

Collected Steps per Second: 22,223.17824
Overall Steps per Second: 10,460.63049

Timestep Collection Time: 2.25008
Timestep Consumption Time: 2.53013
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.78021

Cumulative Model Updates: 88,612
Cumulative Timesteps: 739,038,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 739038768...
Checkpoint 739038768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,797.19505
Policy Entropy: 3.62141
Value Function Loss: 0.07522

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.88327

Collected Steps per Second: 22,542.37549
Overall Steps per Second: 10,627.78941

Timestep Collection Time: 2.21822
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.70502

Cumulative Model Updates: 88,618
Cumulative Timesteps: 739,088,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,410.48057
Policy Entropy: 3.63275
Value Function Loss: 0.07814

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.52337
Value Function Update Magnitude: 0.78844

Collected Steps per Second: 22,239.32362
Overall Steps per Second: 10,628.04192

Timestep Collection Time: 2.24998
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.70811

Cumulative Model Updates: 88,624
Cumulative Timesteps: 739,138,810

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 739138810...
Checkpoint 739138810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,153.54030
Policy Entropy: 3.63075
Value Function Loss: 0.07974

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.53639
Value Function Update Magnitude: 0.77460

Collected Steps per Second: 22,419.53212
Overall Steps per Second: 10,724.89980

Timestep Collection Time: 2.23029
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.66223

Cumulative Model Updates: 88,630
Cumulative Timesteps: 739,188,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,531.21413
Policy Entropy: 3.62987
Value Function Loss: 0.07895

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.65699
Value Function Update Magnitude: 0.86147

Collected Steps per Second: 22,757.99155
Overall Steps per Second: 10,675.47537

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.48730
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.68494

Cumulative Model Updates: 88,636
Cumulative Timesteps: 739,238,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 739238826...
Checkpoint 739238826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,570.15920
Policy Entropy: 3.61568
Value Function Loss: 0.07951

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.90372

Collected Steps per Second: 22,587.62062
Overall Steps per Second: 10,605.38227

Timestep Collection Time: 2.21440
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.71628

Cumulative Model Updates: 88,642
Cumulative Timesteps: 739,288,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,882.34006
Policy Entropy: 3.61127
Value Function Loss: 0.07795

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.62507
Value Function Update Magnitude: 0.88269

Collected Steps per Second: 22,668.06919
Overall Steps per Second: 10,645.85635

Timestep Collection Time: 2.20583
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.69685

Cumulative Model Updates: 88,648
Cumulative Timesteps: 739,338,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 739338846...
Checkpoint 739338846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,832.69104
Policy Entropy: 3.60265
Value Function Loss: 0.07917

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.75031
Value Function Update Magnitude: 0.77221

Collected Steps per Second: 23,025.90829
Overall Steps per Second: 10,833.48031

Timestep Collection Time: 2.17147
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61532

Cumulative Model Updates: 88,654
Cumulative Timesteps: 739,388,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,240.95199
Policy Entropy: 3.60775
Value Function Loss: 0.07788

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.63271
Value Function Update Magnitude: 0.64198

Collected Steps per Second: 22,791.69771
Overall Steps per Second: 10,660.88560

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.69154

Cumulative Model Updates: 88,660
Cumulative Timesteps: 739,438,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 739438862...
Checkpoint 739438862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.16173
Policy Entropy: 3.61861
Value Function Loss: 0.07665

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.52855
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 23,148.42893
Overall Steps per Second: 10,850.81195

Timestep Collection Time: 2.15997
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60795

Cumulative Model Updates: 88,666
Cumulative Timesteps: 739,488,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,098.84127
Policy Entropy: 3.62396
Value Function Loss: 0.07762

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.64590

Collected Steps per Second: 22,743.61243
Overall Steps per Second: 10,640.14625

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.69994

Cumulative Model Updates: 88,672
Cumulative Timesteps: 739,538,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 739538870...
Checkpoint 739538870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,985.24406
Policy Entropy: 3.62704
Value Function Loss: 0.07915

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.16244
Policy Update Magnitude: 0.44892
Value Function Update Magnitude: 0.64986

Collected Steps per Second: 22,912.46606
Overall Steps per Second: 10,945.41216

Timestep Collection Time: 2.18361
Timestep Consumption Time: 2.38743
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.57105

Cumulative Model Updates: 88,678
Cumulative Timesteps: 739,588,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,442.52339
Policy Entropy: 3.62298
Value Function Loss: 0.07911

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.15755
Policy Update Magnitude: 0.40591
Value Function Update Magnitude: 0.65903

Collected Steps per Second: 22,026.32405
Overall Steps per Second: 10,551.96516

Timestep Collection Time: 2.27083
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.74016

Cumulative Model Updates: 88,684
Cumulative Timesteps: 739,638,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 739638920...
Checkpoint 739638920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.68002
Policy Entropy: 3.62763
Value Function Loss: 0.07583

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.43364
Value Function Update Magnitude: 0.66664

Collected Steps per Second: 22,492.43845
Overall Steps per Second: 10,600.53576

Timestep Collection Time: 2.22395
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.71882

Cumulative Model Updates: 88,690
Cumulative Timesteps: 739,688,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,881.62294
Policy Entropy: 3.63927
Value Function Loss: 0.07237

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.61626
Value Function Update Magnitude: 0.64261

Collected Steps per Second: 22,671.25435
Overall Steps per Second: 10,637.35232

Timestep Collection Time: 2.20605
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.70173

Cumulative Model Updates: 88,696
Cumulative Timesteps: 739,738,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 739738956...
Checkpoint 739738956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,293.97545
Policy Entropy: 3.62558
Value Function Loss: 0.07335

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.73003

Collected Steps per Second: 22,832.17285
Overall Steps per Second: 10,852.00335

Timestep Collection Time: 2.19033
Timestep Consumption Time: 2.41804
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.60837

Cumulative Model Updates: 88,702
Cumulative Timesteps: 739,788,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,052.67610
Policy Entropy: 3.63961
Value Function Loss: 0.07234

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.50046
Value Function Update Magnitude: 0.73907

Collected Steps per Second: 22,848.43243
Overall Steps per Second: 10,792.88529

Timestep Collection Time: 2.18956
Timestep Consumption Time: 2.44572
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.63528

Cumulative Model Updates: 88,708
Cumulative Timesteps: 739,838,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 739838994...
Checkpoint 739838994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,156.48754
Policy Entropy: 3.64180
Value Function Loss: 0.07336

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.49645
Value Function Update Magnitude: 0.77339

Collected Steps per Second: 22,930.60715
Overall Steps per Second: 10,723.52834

Timestep Collection Time: 2.18110
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.66395

Cumulative Model Updates: 88,714
Cumulative Timesteps: 739,889,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,477.38710
Policy Entropy: 3.64350
Value Function Loss: 0.07095

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05897
Policy Update Magnitude: 0.67479
Value Function Update Magnitude: 0.80560

Collected Steps per Second: 23,058.96910
Overall Steps per Second: 10,866.93883

Timestep Collection Time: 2.16922
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60295

Cumulative Model Updates: 88,720
Cumulative Timesteps: 739,939,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 739939028...
Checkpoint 739939028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,595.52648
Policy Entropy: 3.64038
Value Function Loss: 0.07263

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.69159
Value Function Update Magnitude: 0.74524

Collected Steps per Second: 22,798.28589
Overall Steps per Second: 10,658.53890

Timestep Collection Time: 2.19438
Timestep Consumption Time: 2.49933
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.69370

Cumulative Model Updates: 88,726
Cumulative Timesteps: 739,989,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,614.81824
Policy Entropy: 3.64946
Value Function Loss: 0.07350

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.60717
Value Function Update Magnitude: 0.73188

Collected Steps per Second: 22,642.04665
Overall Steps per Second: 10,617.87839

Timestep Collection Time: 2.20846
Timestep Consumption Time: 2.50096
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.70942

Cumulative Model Updates: 88,732
Cumulative Timesteps: 740,039,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 740039060...
Checkpoint 740039060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,500.71264
Policy Entropy: 3.64973
Value Function Loss: 0.07491

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.60226
Value Function Update Magnitude: 0.79432

Collected Steps per Second: 23,252.45262
Overall Steps per Second: 10,929.52602

Timestep Collection Time: 2.15031
Timestep Consumption Time: 2.42445
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.57476

Cumulative Model Updates: 88,738
Cumulative Timesteps: 740,089,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,331.14840
Policy Entropy: 3.65260
Value Function Loss: 0.07873

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.16267
Policy Update Magnitude: 0.52334
Value Function Update Magnitude: 0.79110

Collected Steps per Second: 22,367.53596
Overall Steps per Second: 10,583.58131

Timestep Collection Time: 2.23556
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.72468

Cumulative Model Updates: 88,744
Cumulative Timesteps: 740,139,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 740139064...
Checkpoint 740139064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,573.15996
Policy Entropy: 3.64846
Value Function Loss: 0.07893

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.52562
Value Function Update Magnitude: 0.77273

Collected Steps per Second: 22,367.38922
Overall Steps per Second: 10,585.14538

Timestep Collection Time: 2.23745
Timestep Consumption Time: 2.49049
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72795

Cumulative Model Updates: 88,750
Cumulative Timesteps: 740,189,110

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.51832
Policy Entropy: 3.65123
Value Function Loss: 0.07539

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.63658
Value Function Update Magnitude: 0.80843

Collected Steps per Second: 22,552.91638
Overall Steps per Second: 10,746.21864

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.65540

Cumulative Model Updates: 88,756
Cumulative Timesteps: 740,239,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 740239138...
Checkpoint 740239138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,799.16253
Policy Entropy: 3.66586
Value Function Loss: 0.06923

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.57518
Value Function Update Magnitude: 0.84919

Collected Steps per Second: 22,407.40849
Overall Steps per Second: 10,696.80021

Timestep Collection Time: 2.23212
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.67579

Cumulative Model Updates: 88,762
Cumulative Timesteps: 740,289,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,710.77933
Policy Entropy: 3.66742
Value Function Loss: 0.06834

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.52271
Value Function Update Magnitude: 0.88244

Collected Steps per Second: 22,885.75989
Overall Steps per Second: 10,880.19678

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.41161
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59716

Cumulative Model Updates: 88,768
Cumulative Timesteps: 740,339,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 740339172...
Checkpoint 740339172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,854.21505
Policy Entropy: 3.67141
Value Function Loss: 0.06823

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.50698
Value Function Update Magnitude: 0.89140

Collected Steps per Second: 22,869.81860
Overall Steps per Second: 10,728.53984

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.47655
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.66494

Cumulative Model Updates: 88,774
Cumulative Timesteps: 740,389,220

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.64158
Policy Entropy: 3.65847
Value Function Loss: 0.07065

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.51099
Value Function Update Magnitude: 0.90320

Collected Steps per Second: 23,032.34951
Overall Steps per Second: 10,825.69955

Timestep Collection Time: 2.17129
Timestep Consumption Time: 2.44827
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.61956

Cumulative Model Updates: 88,780
Cumulative Timesteps: 740,439,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 740439230...
Checkpoint 740439230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,402.71703
Policy Entropy: 3.65616
Value Function Loss: 0.07169

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.53940
Value Function Update Magnitude: 0.93997

Collected Steps per Second: 22,897.36880
Overall Steps per Second: 10,673.09272

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.68543

Cumulative Model Updates: 88,786
Cumulative Timesteps: 740,489,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.56680
Policy Entropy: 3.66259
Value Function Loss: 0.07040

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.93219

Collected Steps per Second: 22,767.40228
Overall Steps per Second: 10,814.20696

Timestep Collection Time: 2.19709
Timestep Consumption Time: 2.42849
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62558

Cumulative Model Updates: 88,792
Cumulative Timesteps: 740,539,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 740539260...
Checkpoint 740539260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.50555
Policy Entropy: 3.67048
Value Function Loss: 0.07363

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.90603

Collected Steps per Second: 22,913.05887
Overall Steps per Second: 10,755.21624

Timestep Collection Time: 2.18295
Timestep Consumption Time: 2.46763
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.65058

Cumulative Model Updates: 88,798
Cumulative Timesteps: 740,589,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.45006
Policy Entropy: 3.66934
Value Function Loss: 0.07750

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.53618
Value Function Update Magnitude: 0.78017

Collected Steps per Second: 22,947.69156
Overall Steps per Second: 10,835.12671

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.61462

Cumulative Model Updates: 88,804
Cumulative Timesteps: 740,639,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 740639278...
Checkpoint 740639278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.47161
Policy Entropy: 3.66789
Value Function Loss: 0.07835

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.76026

Collected Steps per Second: 22,261.84829
Overall Steps per Second: 10,661.48459

Timestep Collection Time: 2.24689
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.69165

Cumulative Model Updates: 88,810
Cumulative Timesteps: 740,689,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,795.11400
Policy Entropy: 3.65580
Value Function Loss: 0.07796

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.74377

Collected Steps per Second: 22,478.35783
Overall Steps per Second: 10,578.33483

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.72797

Cumulative Model Updates: 88,816
Cumulative Timesteps: 740,739,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 740739312...
Checkpoint 740739312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,432.80377
Policy Entropy: 3.67300
Value Function Loss: 0.07372

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.74726

Collected Steps per Second: 22,321.04303
Overall Steps per Second: 10,572.26786

Timestep Collection Time: 2.24058
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.73049

Cumulative Model Updates: 88,822
Cumulative Timesteps: 740,789,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,639.20668
Policy Entropy: 3.66431
Value Function Loss: 0.07448

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.59414
Value Function Update Magnitude: 0.81444

Collected Steps per Second: 22,312.62388
Overall Steps per Second: 10,560.42126

Timestep Collection Time: 2.24160
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.73617

Cumulative Model Updates: 88,828
Cumulative Timesteps: 740,839,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 740839340...
Checkpoint 740839340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,623.58910
Policy Entropy: 3.67055
Value Function Loss: 0.07498

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.60475
Value Function Update Magnitude: 0.82005

Collected Steps per Second: 22,099.91051
Overall Steps per Second: 10,513.09983

Timestep Collection Time: 2.26245
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.75597

Cumulative Model Updates: 88,834
Cumulative Timesteps: 740,889,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.51445
Policy Entropy: 3.66332
Value Function Loss: 0.07977

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.87376

Collected Steps per Second: 23,156.27545
Overall Steps per Second: 10,836.22639

Timestep Collection Time: 2.15950
Timestep Consumption Time: 2.45521
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.61471

Cumulative Model Updates: 88,840
Cumulative Timesteps: 740,939,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 740939346...
Checkpoint 740939346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,979.38647
Policy Entropy: 3.67248
Value Function Loss: 0.07685

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.58752
Value Function Update Magnitude: 0.94048

Collected Steps per Second: 22,421.49452
Overall Steps per Second: 10,747.50271

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.65466

Cumulative Model Updates: 88,846
Cumulative Timesteps: 740,989,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,115.39173
Policy Entropy: 3.67435
Value Function Loss: 0.07539

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.62534
Value Function Update Magnitude: 0.92176

Collected Steps per Second: 23,071.27491
Overall Steps per Second: 10,871.23720

Timestep Collection Time: 2.16789
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60076

Cumulative Model Updates: 88,852
Cumulative Timesteps: 741,039,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 741039388...
Checkpoint 741039388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,908.42525
Policy Entropy: 3.68001
Value Function Loss: 0.07501

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.59403
Value Function Update Magnitude: 0.88381

Collected Steps per Second: 22,820.19891
Overall Steps per Second: 10,652.68838

Timestep Collection Time: 2.19130
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.69421

Cumulative Model Updates: 88,858
Cumulative Timesteps: 741,089,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.63375
Policy Entropy: 3.67647
Value Function Loss: 0.07821

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.59350
Value Function Update Magnitude: 0.83383

Collected Steps per Second: 22,828.66777
Overall Steps per Second: 10,839.88918

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61352

Cumulative Model Updates: 88,864
Cumulative Timesteps: 741,139,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 741139404...
Checkpoint 741139404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,796.29933
Policy Entropy: 3.68237
Value Function Loss: 0.07962

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.62296
Value Function Update Magnitude: 0.87010

Collected Steps per Second: 22,961.75826
Overall Steps per Second: 10,775.11884

Timestep Collection Time: 2.17788
Timestep Consumption Time: 2.46318
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.64106

Cumulative Model Updates: 88,870
Cumulative Timesteps: 741,189,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.29640
Policy Entropy: 3.68210
Value Function Loss: 0.07898

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.60540
Value Function Update Magnitude: 0.85662

Collected Steps per Second: 22,779.66149
Overall Steps per Second: 10,789.15279

Timestep Collection Time: 2.19608
Timestep Consumption Time: 2.44061
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.63669

Cumulative Model Updates: 88,876
Cumulative Timesteps: 741,239,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 741239438...
Checkpoint 741239438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,353.59192
Policy Entropy: 3.68260
Value Function Loss: 0.07654

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10776
Policy Update Magnitude: 0.60971
Value Function Update Magnitude: 0.86483

Collected Steps per Second: 22,555.32244
Overall Steps per Second: 10,652.52928

Timestep Collection Time: 2.21792
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.69616

Cumulative Model Updates: 88,882
Cumulative Timesteps: 741,289,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,802.90861
Policy Entropy: 3.67545
Value Function Loss: 0.07251

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.90587

Collected Steps per Second: 22,719.37216
Overall Steps per Second: 10,664.89287

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.69109

Cumulative Model Updates: 88,888
Cumulative Timesteps: 741,339,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 741339494...
Checkpoint 741339494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,228.11438
Policy Entropy: 3.68117
Value Function Loss: 0.07071

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.88578

Collected Steps per Second: 22,430.87209
Overall Steps per Second: 10,622.25003

Timestep Collection Time: 2.22934
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.70767

Cumulative Model Updates: 88,894
Cumulative Timesteps: 741,389,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,975.67074
Policy Entropy: 3.67141
Value Function Loss: 0.07339

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.54559
Value Function Update Magnitude: 0.87688

Collected Steps per Second: 23,047.59285
Overall Steps per Second: 10,772.36004

Timestep Collection Time: 2.17038
Timestep Consumption Time: 2.47317
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.64355

Cumulative Model Updates: 88,900
Cumulative Timesteps: 741,439,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 741439522...
Checkpoint 741439522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302.28333
Policy Entropy: 3.67487
Value Function Loss: 0.07261

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.49747
Value Function Update Magnitude: 0.88566

Collected Steps per Second: 22,568.33500
Overall Steps per Second: 10,516.28730

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.53995
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.75624

Cumulative Model Updates: 88,906
Cumulative Timesteps: 741,489,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,343.55106
Policy Entropy: 3.66009
Value Function Loss: 0.07541

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.89251

Collected Steps per Second: 22,527.60219
Overall Steps per Second: 10,596.09785

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.72174

Cumulative Model Updates: 88,912
Cumulative Timesteps: 741,539,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 741539572...
Checkpoint 741539572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,620.81366
Policy Entropy: 3.65136
Value Function Loss: 0.07729

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.57436
Value Function Update Magnitude: 0.88630

Collected Steps per Second: 22,883.70562
Overall Steps per Second: 10,701.94845

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.67335

Cumulative Model Updates: 88,918
Cumulative Timesteps: 741,589,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,417.12702
Policy Entropy: 3.64435
Value Function Loss: 0.07864

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.84024

Collected Steps per Second: 22,881.38004
Overall Steps per Second: 10,765.87939

Timestep Collection Time: 2.18658
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.64727

Cumulative Model Updates: 88,924
Cumulative Timesteps: 741,639,618

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 741639618...
Checkpoint 741639618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,569.22996
Policy Entropy: 3.64750
Value Function Loss: 0.07699

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.16819
Policy Update Magnitude: 0.47751
Value Function Update Magnitude: 0.78896

Collected Steps per Second: 22,724.38226
Overall Steps per Second: 10,616.72850

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.50987
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71068

Cumulative Model Updates: 88,930
Cumulative Timesteps: 741,689,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.31621
Policy Entropy: 3.65206
Value Function Loss: 0.07317

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.46028
Value Function Update Magnitude: 0.81680

Collected Steps per Second: 22,380.34647
Overall Steps per Second: 10,571.82959

Timestep Collection Time: 2.23419
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.72974

Cumulative Model Updates: 88,936
Cumulative Timesteps: 741,739,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 741739632...
Checkpoint 741739632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,471.11616
Policy Entropy: 3.66819
Value Function Loss: 0.07145

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.47187
Value Function Update Magnitude: 0.80389

Collected Steps per Second: 22,343.00549
Overall Steps per Second: 10,590.15458

Timestep Collection Time: 2.23981
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.72552

Cumulative Model Updates: 88,942
Cumulative Timesteps: 741,789,676

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,368.68545
Policy Entropy: 3.66339
Value Function Loss: 0.07158

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.46095
Value Function Update Magnitude: 0.71914

Collected Steps per Second: 22,451.38772
Overall Steps per Second: 10,586.25129

Timestep Collection Time: 2.22766
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.72443

Cumulative Model Updates: 88,948
Cumulative Timesteps: 741,839,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 741839690...
Checkpoint 741839690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.86755
Policy Entropy: 3.66609
Value Function Loss: 0.07335

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.46849
Value Function Update Magnitude: 0.71479

Collected Steps per Second: 22,513.28074
Overall Steps per Second: 10,515.77312

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.53436
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.75571

Cumulative Model Updates: 88,954
Cumulative Timesteps: 741,889,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,225.10096
Policy Entropy: 3.66310
Value Function Loss: 0.07395

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.53858
Value Function Update Magnitude: 0.69145

Collected Steps per Second: 22,970.61415
Overall Steps per Second: 10,794.12701

Timestep Collection Time: 2.17774
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.63437

Cumulative Model Updates: 88,960
Cumulative Timesteps: 741,939,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 741939724...
Checkpoint 741939724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,774.58614
Policy Entropy: 3.66793
Value Function Loss: 0.07207

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.73612

Collected Steps per Second: 22,697.94932
Overall Steps per Second: 10,726.79967

Timestep Collection Time: 2.20302
Timestep Consumption Time: 2.45858
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.66160

Cumulative Model Updates: 88,966
Cumulative Timesteps: 741,989,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,422.39505
Policy Entropy: 3.67401
Value Function Loss: 0.06902

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.50951
Value Function Update Magnitude: 0.73998

Collected Steps per Second: 23,043.33390
Overall Steps per Second: 10,849.93948

Timestep Collection Time: 2.17000
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60869

Cumulative Model Updates: 88,972
Cumulative Timesteps: 742,039,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 742039732...
Checkpoint 742039732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,152.76866
Policy Entropy: 3.67337
Value Function Loss: 0.06604

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.51892
Value Function Update Magnitude: 0.72535

Collected Steps per Second: 22,738.95118
Overall Steps per Second: 10,667.80848

Timestep Collection Time: 2.19966
Timestep Consumption Time: 2.48902
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68869

Cumulative Model Updates: 88,978
Cumulative Timesteps: 742,089,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.21424
Policy Entropy: 3.68574
Value Function Loss: 0.06453

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07649
Policy Update Magnitude: 0.59941
Value Function Update Magnitude: 0.72323

Collected Steps per Second: 23,147.83531
Overall Steps per Second: 10,896.48123

Timestep Collection Time: 2.16063
Timestep Consumption Time: 2.42929
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.58992

Cumulative Model Updates: 88,984
Cumulative Timesteps: 742,139,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 742139764...
Checkpoint 742139764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.65016
Policy Entropy: 3.67280
Value Function Loss: 0.06427

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.73177
Value Function Update Magnitude: 0.77766

Collected Steps per Second: 22,814.20050
Overall Steps per Second: 10,726.46036

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.47074
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.66323

Cumulative Model Updates: 88,990
Cumulative Timesteps: 742,189,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,055.82108
Policy Entropy: 3.67123
Value Function Loss: 0.06454

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.76698
Value Function Update Magnitude: 0.79971

Collected Steps per Second: 22,682.37798
Overall Steps per Second: 10,771.37764

Timestep Collection Time: 2.20577
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.64490

Cumulative Model Updates: 88,996
Cumulative Timesteps: 742,239,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 742239816...
Checkpoint 742239816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,780.46468
Policy Entropy: 3.67442
Value Function Loss: 0.06460

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07098
Policy Update Magnitude: 0.78269
Value Function Update Magnitude: 0.81249

Collected Steps per Second: 22,520.18503
Overall Steps per Second: 10,727.95926

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.44127
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.66221

Cumulative Model Updates: 89,002
Cumulative Timesteps: 742,289,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,232.15449
Policy Entropy: 3.68369
Value Function Loss: 0.06483

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.77166
Value Function Update Magnitude: 0.80963

Collected Steps per Second: 22,498.70541
Overall Steps per Second: 10,671.96316

Timestep Collection Time: 2.22368
Timestep Consumption Time: 2.46430
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.68798

Cumulative Model Updates: 89,008
Cumulative Timesteps: 742,339,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 742339862...
Checkpoint 742339862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.69430
Policy Entropy: 3.67187
Value Function Loss: 0.06592

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07186
Policy Update Magnitude: 0.76470
Value Function Update Magnitude: 0.84507

Collected Steps per Second: 22,700.55535
Overall Steps per Second: 10,800.66215

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.63009

Cumulative Model Updates: 89,014
Cumulative Timesteps: 742,389,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,094.32254
Policy Entropy: 3.66054
Value Function Loss: 0.06818

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.71144
Value Function Update Magnitude: 0.84038

Collected Steps per Second: 23,462.64582
Overall Steps per Second: 10,894.64036

Timestep Collection Time: 2.13113
Timestep Consumption Time: 2.45846
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.58960

Cumulative Model Updates: 89,020
Cumulative Timesteps: 742,439,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 742439872...
Checkpoint 742439872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,979.17578
Policy Entropy: 3.65069
Value Function Loss: 0.06986

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.66775
Value Function Update Magnitude: 0.76938

Collected Steps per Second: 22,725.47959
Overall Steps per Second: 10,797.81809

Timestep Collection Time: 2.20158
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.63353

Cumulative Model Updates: 89,026
Cumulative Timesteps: 742,489,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,314.13490
Policy Entropy: 3.65607
Value Function Loss: 0.07025

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.61122
Value Function Update Magnitude: 0.70480

Collected Steps per Second: 23,002.52014
Overall Steps per Second: 10,879.00934

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.59729

Cumulative Model Updates: 89,032
Cumulative Timesteps: 742,539,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 742539918...
Checkpoint 742539918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.13815
Policy Entropy: 3.65469
Value Function Loss: 0.06946

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.58350
Value Function Update Magnitude: 0.71116

Collected Steps per Second: 22,918.27886
Overall Steps per Second: 10,710.20170

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.67013

Cumulative Model Updates: 89,038
Cumulative Timesteps: 742,589,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,229.25046
Policy Entropy: 3.65499
Value Function Loss: 0.07045

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.71352

Collected Steps per Second: 23,045.35519
Overall Steps per Second: 10,822.51082

Timestep Collection Time: 2.16963
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.62000

Cumulative Model Updates: 89,044
Cumulative Timesteps: 742,639,936

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 742639936...
Checkpoint 742639936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,046.43432
Policy Entropy: 3.65052
Value Function Loss: 0.07276

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.69090
Value Function Update Magnitude: 0.78084

Collected Steps per Second: 22,742.83212
Overall Steps per Second: 10,627.72373

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.70618

Cumulative Model Updates: 89,050
Cumulative Timesteps: 742,689,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,795.66188
Policy Entropy: 3.64635
Value Function Loss: 0.07164

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.60293
Value Function Update Magnitude: 0.82797

Collected Steps per Second: 22,166.46840
Overall Steps per Second: 10,527.39841

Timestep Collection Time: 2.25575
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.74970

Cumulative Model Updates: 89,056
Cumulative Timesteps: 742,739,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 742739954...
Checkpoint 742739954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,592.91242
Policy Entropy: 3.65039
Value Function Loss: 0.07026

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.56432
Value Function Update Magnitude: 0.74033

Collected Steps per Second: 22,675.26805
Overall Steps per Second: 10,633.72013

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.70221

Cumulative Model Updates: 89,062
Cumulative Timesteps: 742,789,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.61964
Policy Entropy: 3.65398
Value Function Loss: 0.07102

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.72591

Collected Steps per Second: 22,759.55432
Overall Steps per Second: 10,789.31082

Timestep Collection Time: 2.19714
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.63477

Cumulative Model Updates: 89,068
Cumulative Timesteps: 742,839,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 742839962...
Checkpoint 742839962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,472.76007
Policy Entropy: 3.65068
Value Function Loss: 0.07411

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.50469
Value Function Update Magnitude: 0.73816

Collected Steps per Second: 21,619.65583
Overall Steps per Second: 10,295.62747

Timestep Collection Time: 2.31308
Timestep Consumption Time: 2.54413
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.85721

Cumulative Model Updates: 89,074
Cumulative Timesteps: 742,889,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,876.16448
Policy Entropy: 3.63846
Value Function Loss: 0.07636

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.46945
Value Function Update Magnitude: 0.76863

Collected Steps per Second: 22,824.65355
Overall Steps per Second: 10,767.38869

Timestep Collection Time: 2.19149
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.64551

Cumulative Model Updates: 89,080
Cumulative Timesteps: 742,939,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 742939990...
Checkpoint 742939990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,774.31658
Policy Entropy: 3.63941
Value Function Loss: 0.07184

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.49238
Value Function Update Magnitude: 0.73771

Collected Steps per Second: 22,788.99042
Overall Steps per Second: 10,791.91782

Timestep Collection Time: 2.19474
Timestep Consumption Time: 2.43984
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.63458

Cumulative Model Updates: 89,086
Cumulative Timesteps: 742,990,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,947.99015
Policy Entropy: 3.63517
Value Function Loss: 0.07201

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.50126
Value Function Update Magnitude: 0.72732

Collected Steps per Second: 23,216.45868
Overall Steps per Second: 10,830.42124

Timestep Collection Time: 2.15390
Timestep Consumption Time: 2.46328
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.61718

Cumulative Model Updates: 89,092
Cumulative Timesteps: 743,040,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 743040012...
Checkpoint 743040012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,218.23339
Policy Entropy: 3.64341
Value Function Loss: 0.07003

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.49424
Value Function Update Magnitude: 0.72861

Collected Steps per Second: 22,915.36632
Overall Steps per Second: 10,643.57094

Timestep Collection Time: 2.18308
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.70011

Cumulative Model Updates: 89,098
Cumulative Timesteps: 743,090,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.90654
Policy Entropy: 3.62574
Value Function Loss: 0.07230

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.45971
Value Function Update Magnitude: 0.67433

Collected Steps per Second: 22,644.93123
Overall Steps per Second: 10,655.61752

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.69292

Cumulative Model Updates: 89,104
Cumulative Timesteps: 743,140,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 743140044...
Checkpoint 743140044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,352.92466
Policy Entropy: 3.62726
Value Function Loss: 0.07517

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.47333
Value Function Update Magnitude: 0.67130

Collected Steps per Second: 22,831.97654
Overall Steps per Second: 10,830.93501

Timestep Collection Time: 2.19114
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61899

Cumulative Model Updates: 89,110
Cumulative Timesteps: 743,190,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.12562
Policy Entropy: 3.62593
Value Function Loss: 0.07775

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.51793
Value Function Update Magnitude: 0.69041

Collected Steps per Second: 22,575.63547
Overall Steps per Second: 10,580.97816

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.51159
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.72716

Cumulative Model Updates: 89,116
Cumulative Timesteps: 743,240,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 743240090...
Checkpoint 743240090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,130.61205
Policy Entropy: 3.62932
Value Function Loss: 0.08083

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.53340
Value Function Update Magnitude: 0.74648

Collected Steps per Second: 22,564.93102
Overall Steps per Second: 10,571.06961

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.73140

Cumulative Model Updates: 89,122
Cumulative Timesteps: 743,290,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,718.98889
Policy Entropy: 3.63185
Value Function Loss: 0.08068

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.77475

Collected Steps per Second: 22,288.83513
Overall Steps per Second: 10,526.32421

Timestep Collection Time: 2.24328
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.75000

Cumulative Model Updates: 89,128
Cumulative Timesteps: 743,340,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 743340106...
Checkpoint 743340106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,589.72421
Policy Entropy: 3.62090
Value Function Loss: 0.08061

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.50071
Value Function Update Magnitude: 0.82432

Collected Steps per Second: 22,539.36279
Overall Steps per Second: 10,596.93437

Timestep Collection Time: 2.21958
Timestep Consumption Time: 2.50140
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.72099

Cumulative Model Updates: 89,134
Cumulative Timesteps: 743,390,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,693.84931
Policy Entropy: 3.62855
Value Function Loss: 0.07696

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.48255
Value Function Update Magnitude: 0.78191

Collected Steps per Second: 22,339.95654
Overall Steps per Second: 10,517.14019

Timestep Collection Time: 2.23841
Timestep Consumption Time: 2.51630
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.75471

Cumulative Model Updates: 89,140
Cumulative Timesteps: 743,440,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 743440140...
Checkpoint 743440140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.01242
Policy Entropy: 3.63104
Value Function Loss: 0.07721

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.48967
Value Function Update Magnitude: 0.75893

Collected Steps per Second: 22,572.22254
Overall Steps per Second: 10,603.92670

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71712

Cumulative Model Updates: 89,146
Cumulative Timesteps: 743,490,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.23678
Policy Entropy: 3.64380
Value Function Loss: 0.07738

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.49034
Value Function Update Magnitude: 0.78224

Collected Steps per Second: 23,155.81743
Overall Steps per Second: 10,821.14489

Timestep Collection Time: 2.16049
Timestep Consumption Time: 2.46268
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.62317

Cumulative Model Updates: 89,152
Cumulative Timesteps: 743,540,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 743540188...
Checkpoint 743540188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329.13394
Policy Entropy: 3.64249
Value Function Loss: 0.07684

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05838
Policy Update Magnitude: 0.66321
Value Function Update Magnitude: 0.80220

Collected Steps per Second: 22,963.52287
Overall Steps per Second: 10,699.72304

Timestep Collection Time: 2.17841
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.67526

Cumulative Model Updates: 89,158
Cumulative Timesteps: 743,590,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190.89219
Policy Entropy: 3.63726
Value Function Loss: 0.07857

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.82198
Value Function Update Magnitude: 0.85141

Collected Steps per Second: 23,172.62470
Overall Steps per Second: 10,870.94224

Timestep Collection Time: 2.15815
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.60034

Cumulative Model Updates: 89,164
Cumulative Timesteps: 743,640,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 743640222...
Checkpoint 743640222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,046.18794
Policy Entropy: 3.63787
Value Function Loss: 0.08276

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.79340
Value Function Update Magnitude: 0.78194

Collected Steps per Second: 22,984.79342
Overall Steps per Second: 10,639.71708

Timestep Collection Time: 2.17666
Timestep Consumption Time: 2.52554
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.70219

Cumulative Model Updates: 89,170
Cumulative Timesteps: 743,690,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,023.12230
Policy Entropy: 3.62910
Value Function Loss: 0.08395

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.75015
Value Function Update Magnitude: 0.72365

Collected Steps per Second: 23,154.30855
Overall Steps per Second: 10,869.16594

Timestep Collection Time: 2.16098
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.60348

Cumulative Model Updates: 89,176
Cumulative Timesteps: 743,740,288

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 743740288...
Checkpoint 743740288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,109.40449
Policy Entropy: 3.63199
Value Function Loss: 0.08214

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.75268
Value Function Update Magnitude: 0.69497

Collected Steps per Second: 22,708.00034
Overall Steps per Second: 10,724.30816

Timestep Collection Time: 2.20204
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.66268

Cumulative Model Updates: 89,182
Cumulative Timesteps: 743,790,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.84147
Policy Entropy: 3.63525
Value Function Loss: 0.08121

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.73166
Value Function Update Magnitude: 0.69155

Collected Steps per Second: 22,780.33808
Overall Steps per Second: 10,801.41320

Timestep Collection Time: 2.19558
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.63051

Cumulative Model Updates: 89,188
Cumulative Timesteps: 743,840,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 743840308...
Checkpoint 743840308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,697.80006
Policy Entropy: 3.64145
Value Function Loss: 0.08083

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.74739
Value Function Update Magnitude: 0.69832

Collected Steps per Second: 22,322.44535
Overall Steps per Second: 10,706.10913

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.67341

Cumulative Model Updates: 89,194
Cumulative Timesteps: 743,890,342

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,442.59506
Policy Entropy: 3.64031
Value Function Loss: 0.07998

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.64279
Value Function Update Magnitude: 0.80558

Collected Steps per Second: 22,430.19357
Overall Steps per Second: 10,672.22537

Timestep Collection Time: 2.22976
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68637

Cumulative Model Updates: 89,200
Cumulative Timesteps: 743,940,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 743940356...
Checkpoint 743940356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,057.26945
Policy Entropy: 3.64336
Value Function Loss: 0.08195

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.52648
Value Function Update Magnitude: 0.81380

Collected Steps per Second: 22,740.77711
Overall Steps per Second: 10,881.62441

Timestep Collection Time: 2.19878
Timestep Consumption Time: 2.39630
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.59509

Cumulative Model Updates: 89,206
Cumulative Timesteps: 743,990,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,171.06100
Policy Entropy: 3.64394
Value Function Loss: 0.08321

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.52961
Value Function Update Magnitude: 0.72385

Collected Steps per Second: 23,169.90211
Overall Steps per Second: 10,838.59957

Timestep Collection Time: 2.15797
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61314

Cumulative Model Updates: 89,212
Cumulative Timesteps: 744,040,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 744040358...
Checkpoint 744040358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,734.67986
Policy Entropy: 3.65003
Value Function Loss: 0.08238

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.53223
Value Function Update Magnitude: 0.73284

Collected Steps per Second: 22,595.54095
Overall Steps per Second: 10,603.95808

Timestep Collection Time: 2.21433
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.71843

Cumulative Model Updates: 89,218
Cumulative Timesteps: 744,090,392

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,174.77945
Policy Entropy: 3.64247
Value Function Loss: 0.07818

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.47658
Value Function Update Magnitude: 0.73297

Collected Steps per Second: 22,707.60136
Overall Steps per Second: 10,627.19689

Timestep Collection Time: 2.20279
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.70679

Cumulative Model Updates: 89,224
Cumulative Timesteps: 744,140,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 744140412...
Checkpoint 744140412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.12556
Policy Entropy: 3.64157
Value Function Loss: 0.07676

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.46052
Value Function Update Magnitude: 0.76129

Collected Steps per Second: 22,926.74242
Overall Steps per Second: 10,681.45236

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.68251

Cumulative Model Updates: 89,230
Cumulative Timesteps: 744,190,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.83288
Policy Entropy: 3.65035
Value Function Loss: 0.07842

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.47317
Value Function Update Magnitude: 0.76806

Collected Steps per Second: 22,904.38541
Overall Steps per Second: 10,850.45400

Timestep Collection Time: 2.18404
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.61031

Cumulative Model Updates: 89,236
Cumulative Timesteps: 744,240,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 744240452...
Checkpoint 744240452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,638.04804
Policy Entropy: 3.65596
Value Function Loss: 0.07693

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.63452
Value Function Update Magnitude: 0.82894

Collected Steps per Second: 22,854.69646
Overall Steps per Second: 10,660.59720

Timestep Collection Time: 2.18817
Timestep Consumption Time: 2.50294
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.69111

Cumulative Model Updates: 89,242
Cumulative Timesteps: 744,290,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,183.86922
Policy Entropy: 3.64933
Value Function Loss: 0.07493

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.65049
Value Function Update Magnitude: 0.81903

Collected Steps per Second: 22,419.88642
Overall Steps per Second: 10,623.94996

Timestep Collection Time: 2.23088
Timestep Consumption Time: 2.47698
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.70785

Cumulative Model Updates: 89,248
Cumulative Timesteps: 744,340,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 744340478...
Checkpoint 744340478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,450.17659
Policy Entropy: 3.63782
Value Function Loss: 0.07533

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.78038

Collected Steps per Second: 22,470.97424
Overall Steps per Second: 10,629.80274

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.70545

Cumulative Model Updates: 89,254
Cumulative Timesteps: 744,390,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,709.32513
Policy Entropy: 3.63546
Value Function Loss: 0.07249

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.15932
Policy Update Magnitude: 0.49088
Value Function Update Magnitude: 0.88022

Collected Steps per Second: 22,321.04907
Overall Steps per Second: 10,659.42684

Timestep Collection Time: 2.24093
Timestep Consumption Time: 2.45163
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.69256

Cumulative Model Updates: 89,260
Cumulative Timesteps: 744,440,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 744440516...
Checkpoint 744440516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,726.63662
Policy Entropy: 3.64152
Value Function Loss: 0.07221

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.44123
Value Function Update Magnitude: 0.89394

Collected Steps per Second: 22,556.60597
Overall Steps per Second: 10,627.72624

Timestep Collection Time: 2.21727
Timestep Consumption Time: 2.48873
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.70599

Cumulative Model Updates: 89,266
Cumulative Timesteps: 744,490,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.24832
Policy Entropy: 3.65237
Value Function Loss: 0.07410

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.50686
Value Function Update Magnitude: 0.86304

Collected Steps per Second: 22,559.39071
Overall Steps per Second: 10,617.98210

Timestep Collection Time: 2.21699
Timestep Consumption Time: 2.49332
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.71031

Cumulative Model Updates: 89,272
Cumulative Timesteps: 744,540,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 744540544...
Checkpoint 744540544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.15633
Policy Entropy: 3.65030
Value Function Loss: 0.07888

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.69334
Value Function Update Magnitude: 0.78191

Collected Steps per Second: 22,781.68759
Overall Steps per Second: 10,565.40861

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.53890
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.73470

Cumulative Model Updates: 89,278
Cumulative Timesteps: 744,590,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,876.75623
Policy Entropy: 3.64508
Value Function Loss: 0.07748

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.75184
Value Function Update Magnitude: 0.66692

Collected Steps per Second: 22,793.59745
Overall Steps per Second: 10,770.56576

Timestep Collection Time: 2.19430
Timestep Consumption Time: 2.44947
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.64377

Cumulative Model Updates: 89,284
Cumulative Timesteps: 744,640,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 744640584...
Checkpoint 744640584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,432.04998
Policy Entropy: 3.65072
Value Function Loss: 0.07513

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.66875
Value Function Update Magnitude: 0.69730

Collected Steps per Second: 22,870.30095
Overall Steps per Second: 10,727.20141

Timestep Collection Time: 2.18720
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.66310

Cumulative Model Updates: 89,290
Cumulative Timesteps: 744,690,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,142.00942
Policy Entropy: 3.65885
Value Function Loss: 0.07501

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.16953
Policy Update Magnitude: 0.49291
Value Function Update Magnitude: 0.68760

Collected Steps per Second: 23,006.78668
Overall Steps per Second: 10,922.64811

Timestep Collection Time: 2.17336
Timestep Consumption Time: 2.40447
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.57783

Cumulative Model Updates: 89,296
Cumulative Timesteps: 744,740,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 744740608...
Checkpoint 744740608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.75671
Policy Entropy: 3.67321
Value Function Loss: 0.07147

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.48438
Value Function Update Magnitude: 0.78151

Collected Steps per Second: 22,842.70762
Overall Steps per Second: 10,672.44738

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.68777

Cumulative Model Updates: 89,302
Cumulative Timesteps: 744,790,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.38698
Policy Entropy: 3.68017
Value Function Loss: 0.07064

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.84804

Collected Steps per Second: 23,204.70492
Overall Steps per Second: 10,802.63076

Timestep Collection Time: 2.15586
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.63091

Cumulative Model Updates: 89,308
Cumulative Timesteps: 744,840,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 744840664...
Checkpoint 744840664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,021.71554
Policy Entropy: 3.67282
Value Function Loss: 0.06620

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.60065
Value Function Update Magnitude: 0.86655

Collected Steps per Second: 22,441.96396
Overall Steps per Second: 10,636.79808

Timestep Collection Time: 2.22797
Timestep Consumption Time: 2.47269
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.70066

Cumulative Model Updates: 89,314
Cumulative Timesteps: 744,890,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,243.01827
Policy Entropy: 3.67526
Value Function Loss: 0.06834

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.60117
Value Function Update Magnitude: 0.81381

Collected Steps per Second: 22,678.39166
Overall Steps per Second: 10,677.09025

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.47997
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.68630

Cumulative Model Updates: 89,320
Cumulative Timesteps: 744,940,700

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 744940700...
Checkpoint 744940700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.22646
Policy Entropy: 3.67278
Value Function Loss: 0.06588

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.60367
Value Function Update Magnitude: 0.81484

Collected Steps per Second: 22,570.57943
Overall Steps per Second: 10,829.10040

Timestep Collection Time: 2.21598
Timestep Consumption Time: 2.40268
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61867

Cumulative Model Updates: 89,326
Cumulative Timesteps: 744,990,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,624.25832
Policy Entropy: 3.67007
Value Function Loss: 0.06589

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.83691

Collected Steps per Second: 22,912.93538
Overall Steps per Second: 10,579.50022

Timestep Collection Time: 2.18340
Timestep Consumption Time: 2.54537
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.72877

Cumulative Model Updates: 89,332
Cumulative Timesteps: 745,040,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 745040744...
Checkpoint 745040744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,090.60823
Policy Entropy: 3.67212
Value Function Loss: 0.06471

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.62427
Value Function Update Magnitude: 0.83603

Collected Steps per Second: 22,980.92212
Overall Steps per Second: 10,630.89891

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.52776
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.70365

Cumulative Model Updates: 89,338
Cumulative Timesteps: 745,090,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,399.37616
Policy Entropy: 3.67649
Value Function Loss: 0.06344

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.68114
Value Function Update Magnitude: 0.83124

Collected Steps per Second: 22,571.64459
Overall Steps per Second: 10,838.68110

Timestep Collection Time: 2.21552
Timestep Consumption Time: 2.39832
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61385

Cumulative Model Updates: 89,344
Cumulative Timesteps: 745,140,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 745140756...
Checkpoint 745140756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,774.22728
Policy Entropy: 3.67074
Value Function Loss: 0.06671

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.75443
Value Function Update Magnitude: 0.84702

Collected Steps per Second: 22,851.14696
Overall Steps per Second: 10,645.18775

Timestep Collection Time: 2.18816
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.69715

Cumulative Model Updates: 89,350
Cumulative Timesteps: 745,190,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,360.26010
Policy Entropy: 3.68558
Value Function Loss: 0.06710

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.79788
Value Function Update Magnitude: 0.86731

Collected Steps per Second: 23,281.82688
Overall Steps per Second: 10,885.05602

Timestep Collection Time: 2.14777
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.59382

Cumulative Model Updates: 89,356
Cumulative Timesteps: 745,240,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 745240762...
Checkpoint 745240762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,569.40263
Policy Entropy: 3.67185
Value Function Loss: 0.06832

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.78029
Value Function Update Magnitude: 0.86301

Collected Steps per Second: 22,879.57417
Overall Steps per Second: 10,662.40642

Timestep Collection Time: 2.18684
Timestep Consumption Time: 2.50572
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.69256

Cumulative Model Updates: 89,362
Cumulative Timesteps: 745,290,796

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,800.54414
Policy Entropy: 3.67036
Value Function Loss: 0.06921

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.68480
Value Function Update Magnitude: 0.80072

Collected Steps per Second: 22,666.35812
Overall Steps per Second: 10,633.42396

Timestep Collection Time: 2.20644
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.70328

Cumulative Model Updates: 89,368
Cumulative Timesteps: 745,340,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 745340808...
Checkpoint 745340808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.03405
Policy Entropy: 3.66016
Value Function Loss: 0.07339

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.60873
Value Function Update Magnitude: 0.69844

Collected Steps per Second: 22,501.23234
Overall Steps per Second: 10,614.95854

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.71052

Cumulative Model Updates: 89,374
Cumulative Timesteps: 745,390,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,288.37487
Policy Entropy: 3.66436
Value Function Loss: 0.07431

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.52646
Value Function Update Magnitude: 0.73055

Collected Steps per Second: 22,841.56502
Overall Steps per Second: 10,734.56821

Timestep Collection Time: 2.19022
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.66046

Cumulative Model Updates: 89,380
Cumulative Timesteps: 745,440,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 745440838...
Checkpoint 745440838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,084.13441
Policy Entropy: 3.66908
Value Function Loss: 0.07838

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.73404

Collected Steps per Second: 22,626.14367
Overall Steps per Second: 10,675.19487

Timestep Collection Time: 2.21045
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.68507

Cumulative Model Updates: 89,386
Cumulative Timesteps: 745,490,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,979.87132
Policy Entropy: 3.66259
Value Function Loss: 0.07810

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.77492

Collected Steps per Second: 22,588.19866
Overall Steps per Second: 10,670.16830

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.68840

Cumulative Model Updates: 89,392
Cumulative Timesteps: 745,540,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 745540878...
Checkpoint 745540878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.77574
Policy Entropy: 3.65196
Value Function Loss: 0.07785

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.58291
Value Function Update Magnitude: 0.80495

Collected Steps per Second: 22,862.37920
Overall Steps per Second: 10,778.62202

Timestep Collection Time: 2.18735
Timestep Consumption Time: 2.45221
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.63955

Cumulative Model Updates: 89,398
Cumulative Timesteps: 745,590,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,209.95221
Policy Entropy: 3.65801
Value Function Loss: 0.07440

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.49882
Value Function Update Magnitude: 0.84624

Collected Steps per Second: 22,859.21796
Overall Steps per Second: 10,686.47628

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.67937

Cumulative Model Updates: 89,404
Cumulative Timesteps: 745,640,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 745640892...
Checkpoint 745640892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,336.69153
Policy Entropy: 3.66504
Value Function Loss: 0.07431

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.67581
Value Function Update Magnitude: 0.85298

Collected Steps per Second: 22,919.11545
Overall Steps per Second: 10,847.97530

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.42854
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.61100

Cumulative Model Updates: 89,410
Cumulative Timesteps: 745,690,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,388.42987
Policy Entropy: 3.66126
Value Function Loss: 0.07871

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.74718
Value Function Update Magnitude: 0.80763

Collected Steps per Second: 22,688.55679
Overall Steps per Second: 10,621.18902

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.70983

Cumulative Model Updates: 89,416
Cumulative Timesteps: 745,740,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 745740936...
Checkpoint 745740936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,380.96554
Policy Entropy: 3.65330
Value Function Loss: 0.08160

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.76535
Value Function Update Magnitude: 0.71558

Collected Steps per Second: 22,836.91851
Overall Steps per Second: 10,696.53651

Timestep Collection Time: 2.19040
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.67647

Cumulative Model Updates: 89,422
Cumulative Timesteps: 745,790,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,543.77439
Policy Entropy: 3.62556
Value Function Loss: 0.08296

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.62222
Value Function Update Magnitude: 0.65206

Collected Steps per Second: 22,938.16919
Overall Steps per Second: 10,786.55705

Timestep Collection Time: 2.18091
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.63781

Cumulative Model Updates: 89,428
Cumulative Timesteps: 745,840,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 745840984...
Checkpoint 745840984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,862.34383
Policy Entropy: 3.62160
Value Function Loss: 0.08088

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.57143
Value Function Update Magnitude: 0.67830

Collected Steps per Second: 22,136.74328
Overall Steps per Second: 10,657.18974

Timestep Collection Time: 2.25914
Timestep Consumption Time: 2.43347
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.69261

Cumulative Model Updates: 89,434
Cumulative Timesteps: 745,890,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,422.64763
Policy Entropy: 3.63227
Value Function Loss: 0.07922

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.51847
Value Function Update Magnitude: 0.61683

Collected Steps per Second: 22,361.51670
Overall Steps per Second: 10,600.90806

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.48188
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.71903

Cumulative Model Updates: 89,440
Cumulative Timesteps: 745,941,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 745941020...
Checkpoint 745941020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,489.68189
Policy Entropy: 3.63165
Value Function Loss: 0.08076

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.54141
Value Function Update Magnitude: 0.59512

Collected Steps per Second: 22,334.55758
Overall Steps per Second: 10,566.13496

Timestep Collection Time: 2.23877
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.73229

Cumulative Model Updates: 89,446
Cumulative Timesteps: 745,991,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,329.18455
Policy Entropy: 3.62224
Value Function Loss: 0.07954

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.61325
Value Function Update Magnitude: 0.60228

Collected Steps per Second: 22,579.30310
Overall Steps per Second: 10,769.42931

Timestep Collection Time: 2.21566
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.64537

Cumulative Model Updates: 89,452
Cumulative Timesteps: 746,041,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 746041050...
Checkpoint 746041050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.17385
Policy Entropy: 3.61478
Value Function Loss: 0.08049

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.70722
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 22,442.97725
Overall Steps per Second: 10,727.90046

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.66317

Cumulative Model Updates: 89,458
Cumulative Timesteps: 746,091,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,190.03577
Policy Entropy: 3.62396
Value Function Loss: 0.08030

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.73752
Value Function Update Magnitude: 0.69513

Collected Steps per Second: 23,029.37523
Overall Steps per Second: 10,789.03913

Timestep Collection Time: 2.17210
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.63637

Cumulative Model Updates: 89,464
Cumulative Timesteps: 746,141,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 746141098...
Checkpoint 746141098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,462.04999
Policy Entropy: 3.62851
Value Function Loss: 0.08182

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.73730
Value Function Update Magnitude: 0.82166

Collected Steps per Second: 22,404.33609
Overall Steps per Second: 10,748.75446

Timestep Collection Time: 2.23243
Timestep Consumption Time: 2.42077
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.65319

Cumulative Model Updates: 89,470
Cumulative Timesteps: 746,191,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,538.85537
Policy Entropy: 3.61953
Value Function Loss: 0.08037

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.56541
Value Function Update Magnitude: 0.83612

Collected Steps per Second: 22,999.23129
Overall Steps per Second: 10,855.56575

Timestep Collection Time: 2.17442
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.60685

Cumulative Model Updates: 89,476
Cumulative Timesteps: 746,241,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 746241124...
Checkpoint 746241124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,715.67349
Policy Entropy: 3.61593
Value Function Loss: 0.07975

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.47064
Value Function Update Magnitude: 0.84422

Collected Steps per Second: 22,952.25174
Overall Steps per Second: 10,708.62919

Timestep Collection Time: 2.17844
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.66913

Cumulative Model Updates: 89,482
Cumulative Timesteps: 746,291,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,453.17489
Policy Entropy: 3.61479
Value Function Loss: 0.07806

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.46272
Value Function Update Magnitude: 0.83309

Collected Steps per Second: 22,289.74059
Overall Steps per Second: 10,906.15699

Timestep Collection Time: 2.24327
Timestep Consumption Time: 2.34148
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.58475

Cumulative Model Updates: 89,488
Cumulative Timesteps: 746,341,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 746341126...
Checkpoint 746341126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,117.13600
Policy Entropy: 3.62208
Value Function Loss: 0.08158

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.52822
Value Function Update Magnitude: 0.75108

Collected Steps per Second: 22,016.61913
Overall Steps per Second: 10,687.81064

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.40789
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.67954

Cumulative Model Updates: 89,494
Cumulative Timesteps: 746,391,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,147.53487
Policy Entropy: 3.63938
Value Function Loss: 0.08438

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.51202
Value Function Update Magnitude: 0.71023

Collected Steps per Second: 21,805.08236
Overall Steps per Second: 10,743.47858

Timestep Collection Time: 2.29350
Timestep Consumption Time: 2.36141
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.65492

Cumulative Model Updates: 89,500
Cumulative Timesteps: 746,441,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 746441150...
Checkpoint 746441150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,018.08451
Policy Entropy: 3.63542
Value Function Loss: 0.08708

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.57781
Value Function Update Magnitude: 0.66109

Collected Steps per Second: 21,692.92545
Overall Steps per Second: 10,735.23822

Timestep Collection Time: 2.30490
Timestep Consumption Time: 2.35266
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.65756

Cumulative Model Updates: 89,506
Cumulative Timesteps: 746,491,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,995.11530
Policy Entropy: 3.62474
Value Function Loss: 0.08302

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.61959
Value Function Update Magnitude: 0.69760

Collected Steps per Second: 21,667.24348
Overall Steps per Second: 10,623.48131

Timestep Collection Time: 2.30809
Timestep Consumption Time: 2.39940
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.70750

Cumulative Model Updates: 89,512
Cumulative Timesteps: 746,541,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 746541160...
Checkpoint 746541160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,212.07805
Policy Entropy: 3.61100
Value Function Loss: 0.07994

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.75679

Collected Steps per Second: 22,157.09719
Overall Steps per Second: 10,799.99712

Timestep Collection Time: 2.25761
Timestep Consumption Time: 2.37406
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.63167

Cumulative Model Updates: 89,518
Cumulative Timesteps: 746,591,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,682.07981
Policy Entropy: 3.60829
Value Function Loss: 0.07826

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.73620

Collected Steps per Second: 22,311.86336
Overall Steps per Second: 10,557.34416

Timestep Collection Time: 2.24096
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.73604

Cumulative Model Updates: 89,524
Cumulative Timesteps: 746,641,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 746641182...
Checkpoint 746641182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,627.97192
Policy Entropy: 3.63213
Value Function Loss: 0.07819

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.16973
Policy Update Magnitude: 0.54711
Value Function Update Magnitude: 0.83049

Collected Steps per Second: 22,918.36004
Overall Steps per Second: 10,787.04463

Timestep Collection Time: 2.18314
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.63834

Cumulative Model Updates: 89,530
Cumulative Timesteps: 746,691,216

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,037.87259
Policy Entropy: 3.67427
Value Function Loss: 0.07548

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.16719
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.83905

Collected Steps per Second: 22,551.42930
Overall Steps per Second: 10,738.12764

Timestep Collection Time: 2.21760
Timestep Consumption Time: 2.43964
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.65724

Cumulative Model Updates: 89,536
Cumulative Timesteps: 746,741,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 746741226...
Checkpoint 746741226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,581.41086
Policy Entropy: 3.69320
Value Function Loss: 0.07201

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.59688
Value Function Update Magnitude: 0.80952

Collected Steps per Second: 22,751.44157
Overall Steps per Second: 10,704.20888

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.47429
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.67274

Cumulative Model Updates: 89,542
Cumulative Timesteps: 746,791,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,317.08529
Policy Entropy: 3.70423
Value Function Loss: 0.07019

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.67039
Value Function Update Magnitude: 0.79245

Collected Steps per Second: 23,058.34531
Overall Steps per Second: 10,833.79893

Timestep Collection Time: 2.16885
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.61611

Cumulative Model Updates: 89,548
Cumulative Timesteps: 746,841,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 746841254...
Checkpoint 746841254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,165.36757
Policy Entropy: 3.69368
Value Function Loss: 0.06983

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.68207
Value Function Update Magnitude: 0.68131

Collected Steps per Second: 22,820.57364
Overall Steps per Second: 10,729.40595

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.47057
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.66289

Cumulative Model Updates: 89,554
Cumulative Timesteps: 746,891,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.25003
Policy Entropy: 3.69310
Value Function Loss: 0.07083

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.70196
Value Function Update Magnitude: 0.63774

Collected Steps per Second: 22,341.62880
Overall Steps per Second: 10,789.38787

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.39621
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.63418

Cumulative Model Updates: 89,560
Cumulative Timesteps: 746,941,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 746941284...
Checkpoint 746941284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,259.25719
Policy Entropy: 3.69435
Value Function Loss: 0.07288

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.77170
Value Function Update Magnitude: 0.66502

Collected Steps per Second: 22,073.57331
Overall Steps per Second: 10,647.27600

Timestep Collection Time: 2.26579
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.69735

Cumulative Model Updates: 89,566
Cumulative Timesteps: 746,991,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,796.00017
Policy Entropy: 3.69271
Value Function Loss: 0.07460

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.81071
Value Function Update Magnitude: 0.67374

Collected Steps per Second: 22,650.98524
Overall Steps per Second: 10,627.84098

Timestep Collection Time: 2.20741
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.70462

Cumulative Model Updates: 89,572
Cumulative Timesteps: 747,041,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 747041298...
Checkpoint 747041298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,301.72533
Policy Entropy: 3.67583
Value Function Loss: 0.07664

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.72667
Value Function Update Magnitude: 0.74947

Collected Steps per Second: 22,674.93155
Overall Steps per Second: 10,862.94049

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.40012
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.60741

Cumulative Model Updates: 89,578
Cumulative Timesteps: 747,091,348

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.54621
Policy Entropy: 3.65332
Value Function Loss: 0.07526

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.63033
Value Function Update Magnitude: 0.78509

Collected Steps per Second: 22,942.60101
Overall Steps per Second: 10,618.23801

Timestep Collection Time: 2.17953
Timestep Consumption Time: 2.52973
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.70926

Cumulative Model Updates: 89,584
Cumulative Timesteps: 747,141,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 747141352...
Checkpoint 747141352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,222.65115
Policy Entropy: 3.65368
Value Function Loss: 0.07327

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10429
Policy Update Magnitude: 0.52629
Value Function Update Magnitude: 0.79820

Collected Steps per Second: 22,917.33159
Overall Steps per Second: 10,928.88556

Timestep Collection Time: 2.18228
Timestep Consumption Time: 2.39385
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.57613

Cumulative Model Updates: 89,590
Cumulative Timesteps: 747,191,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,297.87694
Policy Entropy: 3.64064
Value Function Loss: 0.07431

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.80645

Collected Steps per Second: 23,402.12469
Overall Steps per Second: 10,934.06180

Timestep Collection Time: 2.13801
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.57598

Cumulative Model Updates: 89,596
Cumulative Timesteps: 747,241,398

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 747241398...
Checkpoint 747241398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.00964
Policy Entropy: 3.65092
Value Function Loss: 0.07196

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.16994
Policy Update Magnitude: 0.48460
Value Function Update Magnitude: 0.79604

Collected Steps per Second: 22,614.54990
Overall Steps per Second: 10,738.72549

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.65865

Cumulative Model Updates: 89,602
Cumulative Timesteps: 747,291,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,124.43936
Policy Entropy: 3.66204
Value Function Loss: 0.07100

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.51053
Value Function Update Magnitude: 0.80664

Collected Steps per Second: 22,915.33868
Overall Steps per Second: 10,849.43342

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.42756
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61038

Cumulative Model Updates: 89,608
Cumulative Timesteps: 747,341,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 747341446...
Checkpoint 747341446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,782.40998
Policy Entropy: 3.65989
Value Function Loss: 0.07201

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.70268

Collected Steps per Second: 22,750.76298
Overall Steps per Second: 10,685.56186

Timestep Collection Time: 2.19782
Timestep Consumption Time: 2.48158
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.67940

Cumulative Model Updates: 89,614
Cumulative Timesteps: 747,391,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.99979
Policy Entropy: 3.65456
Value Function Loss: 0.07050

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.50411
Value Function Update Magnitude: 0.64742

Collected Steps per Second: 22,624.63503
Overall Steps per Second: 10,653.43655

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.48354
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.69370

Cumulative Model Updates: 89,620
Cumulative Timesteps: 747,441,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 747441452...
Checkpoint 747441452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,921.73871
Policy Entropy: 3.66112
Value Function Loss: 0.06998

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.63103
Value Function Update Magnitude: 0.62951

Collected Steps per Second: 22,414.14496
Overall Steps per Second: 10,626.55197

Timestep Collection Time: 2.23100
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.70576

Cumulative Model Updates: 89,626
Cumulative Timesteps: 747,491,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,231.45315
Policy Entropy: 3.65110
Value Function Loss: 0.06828

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.65581
Value Function Update Magnitude: 0.66765

Collected Steps per Second: 22,347.61679
Overall Steps per Second: 10,677.81632

Timestep Collection Time: 2.23809
Timestep Consumption Time: 2.44601
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.68410

Cumulative Model Updates: 89,632
Cumulative Timesteps: 747,541,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 747541474...
Checkpoint 747541474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.53212
Policy Entropy: 3.64915
Value Function Loss: 0.07186

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.68789

Collected Steps per Second: 22,502.10623
Overall Steps per Second: 10,672.72626

Timestep Collection Time: 2.22210
Timestep Consumption Time: 2.46292
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.68503

Cumulative Model Updates: 89,638
Cumulative Timesteps: 747,591,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.00570
Policy Entropy: 3.64761
Value Function Loss: 0.07329

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.65030
Value Function Update Magnitude: 0.73500

Collected Steps per Second: 22,933.85938
Overall Steps per Second: 10,596.18577

Timestep Collection Time: 2.18079
Timestep Consumption Time: 2.53921
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.72000

Cumulative Model Updates: 89,644
Cumulative Timesteps: 747,641,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 747641490...
Checkpoint 747641490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,687.77737
Policy Entropy: 3.66214
Value Function Loss: 0.07031

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.58993
Value Function Update Magnitude: 0.81044

Collected Steps per Second: 22,823.41073
Overall Steps per Second: 10,851.40237

Timestep Collection Time: 2.19091
Timestep Consumption Time: 2.41716
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.60807

Cumulative Model Updates: 89,650
Cumulative Timesteps: 747,691,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,238.43824
Policy Entropy: 3.65791
Value Function Loss: 0.06896

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.79802

Collected Steps per Second: 22,983.93091
Overall Steps per Second: 10,739.64727

Timestep Collection Time: 2.17683
Timestep Consumption Time: 2.48180
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.65863

Cumulative Model Updates: 89,656
Cumulative Timesteps: 747,741,526

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 747741526...
Checkpoint 747741526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,781.56270
Policy Entropy: 3.65853
Value Function Loss: 0.06796

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.68779
Value Function Update Magnitude: 0.78816

Collected Steps per Second: 22,868.76756
Overall Steps per Second: 10,853.20395

Timestep Collection Time: 2.18726
Timestep Consumption Time: 2.42151
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.60878

Cumulative Model Updates: 89,662
Cumulative Timesteps: 747,791,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,579.68871
Policy Entropy: 3.65662
Value Function Loss: 0.06824

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.72304
Value Function Update Magnitude: 0.78192

Collected Steps per Second: 22,866.78736
Overall Steps per Second: 10,688.85694

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.49249
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.68020

Cumulative Model Updates: 89,668
Cumulative Timesteps: 747,841,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 747841572...
Checkpoint 747841572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.64138
Policy Entropy: 3.65882
Value Function Loss: 0.06960

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.67513
Value Function Update Magnitude: 0.76882

Collected Steps per Second: 22,708.01297
Overall Steps per Second: 10,803.39682

Timestep Collection Time: 2.20195
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.62836

Cumulative Model Updates: 89,674
Cumulative Timesteps: 747,891,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370.00891
Policy Entropy: 3.65221
Value Function Loss: 0.07373

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.63092
Value Function Update Magnitude: 0.77110

Collected Steps per Second: 22,437.92819
Overall Steps per Second: 10,563.94221

Timestep Collection Time: 2.22855
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.73346

Cumulative Model Updates: 89,680
Cumulative Timesteps: 747,941,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 747941578...
Checkpoint 747941578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,166.85581
Policy Entropy: 3.63174
Value Function Loss: 0.07750

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.78996

Collected Steps per Second: 22,311.85103
Overall Steps per Second: 10,710.87525

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.67039

Cumulative Model Updates: 89,686
Cumulative Timesteps: 747,991,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,482.26580
Policy Entropy: 3.62289
Value Function Loss: 0.07841

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.68022
Value Function Update Magnitude: 0.82486

Collected Steps per Second: 22,669.90153
Overall Steps per Second: 10,758.36722

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.44247
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.64847

Cumulative Model Updates: 89,692
Cumulative Timesteps: 748,041,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 748041612...
Checkpoint 748041612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,465.07156
Policy Entropy: 3.63061
Value Function Loss: 0.07547

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.65113
Value Function Update Magnitude: 0.80829

Collected Steps per Second: 23,021.67649
Overall Steps per Second: 10,694.86867

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.50467
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.67776

Cumulative Model Updates: 89,698
Cumulative Timesteps: 748,091,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,950.37458
Policy Entropy: 3.63610
Value Function Loss: 0.07438

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.53537
Value Function Update Magnitude: 0.72713

Collected Steps per Second: 22,829.56075
Overall Steps per Second: 10,802.05111

Timestep Collection Time: 2.19041
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.62931

Cumulative Model Updates: 89,704
Cumulative Timesteps: 748,141,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 748141646...
Checkpoint 748141646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.89613
Policy Entropy: 3.65075
Value Function Loss: 0.07286

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.49070
Value Function Update Magnitude: 0.64944

Collected Steps per Second: 22,790.23486
Overall Steps per Second: 10,742.56003

Timestep Collection Time: 2.19515
Timestep Consumption Time: 2.46184
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.65699

Cumulative Model Updates: 89,710
Cumulative Timesteps: 748,191,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041.12973
Policy Entropy: 3.65589
Value Function Loss: 0.07261

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.16666
Policy Update Magnitude: 0.50558
Value Function Update Magnitude: 0.73053

Collected Steps per Second: 22,963.76875
Overall Steps per Second: 10,849.11022

Timestep Collection Time: 2.17943
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61310

Cumulative Model Updates: 89,716
Cumulative Timesteps: 748,241,722

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 748241722...
Checkpoint 748241722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.40509
Policy Entropy: 3.65127
Value Function Loss: 0.07298

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.43124
Value Function Update Magnitude: 0.74694

Collected Steps per Second: 22,770.14119
Overall Steps per Second: 10,739.32566

Timestep Collection Time: 2.19779
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.65988

Cumulative Model Updates: 89,722
Cumulative Timesteps: 748,291,766

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,538.23842
Policy Entropy: 3.65940
Value Function Loss: 0.07204

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.44276
Value Function Update Magnitude: 0.67251

Collected Steps per Second: 22,863.16024
Overall Steps per Second: 10,855.00262

Timestep Collection Time: 2.18719
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.60672

Cumulative Model Updates: 89,728
Cumulative Timesteps: 748,341,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 748341772...
Checkpoint 748341772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.65306
Policy Entropy: 3.65452
Value Function Loss: 0.07088

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.51361
Value Function Update Magnitude: 0.63839

Collected Steps per Second: 22,211.64539
Overall Steps per Second: 10,733.06250

Timestep Collection Time: 2.25188
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.66018

Cumulative Model Updates: 89,734
Cumulative Timesteps: 748,391,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,917.00037
Policy Entropy: 3.66841
Value Function Loss: 0.07136

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.58796
Value Function Update Magnitude: 0.65493

Collected Steps per Second: 21,946.20525
Overall Steps per Second: 10,796.31584

Timestep Collection Time: 2.27857
Timestep Consumption Time: 2.35319
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.63177

Cumulative Model Updates: 89,740
Cumulative Timesteps: 748,441,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 748441796...
Checkpoint 748441796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,968.58204
Policy Entropy: 3.66126
Value Function Loss: 0.07214

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.59353
Value Function Update Magnitude: 0.68897

Collected Steps per Second: 21,522.54424
Overall Steps per Second: 10,680.70912

Timestep Collection Time: 2.32417
Timestep Consumption Time: 2.35923
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.68340

Cumulative Model Updates: 89,746
Cumulative Timesteps: 748,491,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,527.22027
Policy Entropy: 3.67173
Value Function Loss: 0.07240

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.57485
Value Function Update Magnitude: 0.71413

Collected Steps per Second: 22,104.49262
Overall Steps per Second: 10,660.25844

Timestep Collection Time: 2.26334
Timestep Consumption Time: 2.42979
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69313

Cumulative Model Updates: 89,752
Cumulative Timesteps: 748,541,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 748541848...
Checkpoint 748541848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,675.98499
Policy Entropy: 3.67463
Value Function Loss: 0.07214

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07250
Policy Update Magnitude: 0.59755
Value Function Update Magnitude: 0.73174

Collected Steps per Second: 22,023.76697
Overall Steps per Second: 10,681.09545

Timestep Collection Time: 2.27146
Timestep Consumption Time: 2.41215
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68360

Cumulative Model Updates: 89,758
Cumulative Timesteps: 748,591,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,196.73524
Policy Entropy: 3.67127
Value Function Loss: 0.07357

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.69997
Value Function Update Magnitude: 0.72920

Collected Steps per Second: 21,502.70450
Overall Steps per Second: 10,627.01943

Timestep Collection Time: 2.32613
Timestep Consumption Time: 2.38056
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.70668

Cumulative Model Updates: 89,764
Cumulative Timesteps: 748,641,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 748641892...
Checkpoint 748641892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,167.29506
Policy Entropy: 3.66763
Value Function Loss: 0.07625

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.58870
Value Function Update Magnitude: 0.74376

Collected Steps per Second: 22,002.78592
Overall Steps per Second: 10,657.14447

Timestep Collection Time: 2.27271
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.69225

Cumulative Model Updates: 89,770
Cumulative Timesteps: 748,691,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,087.39711
Policy Entropy: 3.67228
Value Function Loss: 0.07708

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.50445
Value Function Update Magnitude: 0.80525

Collected Steps per Second: 23,061.37307
Overall Steps per Second: 10,920.65054

Timestep Collection Time: 2.16873
Timestep Consumption Time: 2.41103
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.57976

Cumulative Model Updates: 89,776
Cumulative Timesteps: 748,741,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 748741912...
Checkpoint 748741912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.73614
Policy Entropy: 3.66456
Value Function Loss: 0.07919

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.51856
Value Function Update Magnitude: 0.77863

Collected Steps per Second: 22,641.97585
Overall Steps per Second: 10,667.17791

Timestep Collection Time: 2.20873
Timestep Consumption Time: 2.47948
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.68821

Cumulative Model Updates: 89,782
Cumulative Timesteps: 748,791,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,196.67351
Policy Entropy: 3.66491
Value Function Loss: 0.07866

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.50421
Value Function Update Magnitude: 0.70479

Collected Steps per Second: 23,322.55477
Overall Steps per Second: 10,912.66094

Timestep Collection Time: 2.14453
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.58330

Cumulative Model Updates: 89,788
Cumulative Timesteps: 748,841,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 748841938...
Checkpoint 748841938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,262.49976
Policy Entropy: 3.64515
Value Function Loss: 0.08133

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.64125
Value Function Update Magnitude: 0.78683

Collected Steps per Second: 22,403.58888
Overall Steps per Second: 10,639.00947

Timestep Collection Time: 2.23205
Timestep Consumption Time: 2.46820
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.70025

Cumulative Model Updates: 89,794
Cumulative Timesteps: 748,891,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,575.04130
Policy Entropy: 3.66035
Value Function Loss: 0.07631

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.73012
Value Function Update Magnitude: 0.77439

Collected Steps per Second: 22,595.55289
Overall Steps per Second: 10,646.63298

Timestep Collection Time: 2.21344
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.69764

Cumulative Model Updates: 89,800
Cumulative Timesteps: 748,941,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 748941958...
Checkpoint 748941958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,058.74793
Policy Entropy: 3.65129
Value Function Loss: 0.07405

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.69396
Value Function Update Magnitude: 0.81504

Collected Steps per Second: 22,386.99173
Overall Steps per Second: 10,804.43340

Timestep Collection Time: 2.23398
Timestep Consumption Time: 2.39486
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.62884

Cumulative Model Updates: 89,806
Cumulative Timesteps: 748,991,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,464.15421
Policy Entropy: 3.66183
Value Function Loss: 0.07511

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.18026
Policy Update Magnitude: 0.52976
Value Function Update Magnitude: 0.81562

Collected Steps per Second: 22,799.90263
Overall Steps per Second: 10,609.24538

Timestep Collection Time: 2.19334
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.71362

Cumulative Model Updates: 89,812
Cumulative Timesteps: 749,041,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 749041978...
Checkpoint 749041978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.75531
Policy Entropy: 3.67126
Value Function Loss: 0.07472

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.49619
Value Function Update Magnitude: 0.81100

Collected Steps per Second: 22,605.27334
Overall Steps per Second: 10,564.35124

Timestep Collection Time: 2.21355
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.73650

Cumulative Model Updates: 89,818
Cumulative Timesteps: 749,092,016

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,043.75169
Policy Entropy: 3.66803
Value Function Loss: 0.07706

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.83210

Collected Steps per Second: 23,117.40569
Overall Steps per Second: 10,845.56474

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61073

Cumulative Model Updates: 89,824
Cumulative Timesteps: 749,142,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 749142022...
Checkpoint 749142022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,493.86068
Policy Entropy: 3.67801
Value Function Loss: 0.07578

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.59951
Value Function Update Magnitude: 0.78214

Collected Steps per Second: 22,432.19628
Overall Steps per Second: 10,758.71233

Timestep Collection Time: 2.22921
Timestep Consumption Time: 2.41875
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.64795

Cumulative Model Updates: 89,830
Cumulative Timesteps: 749,192,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.38373
Policy Entropy: 3.66634
Value Function Loss: 0.07784

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.76509

Collected Steps per Second: 23,122.59209
Overall Steps per Second: 10,864.31455

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.44032
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.60314

Cumulative Model Updates: 89,836
Cumulative Timesteps: 749,242,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 749242038...
Checkpoint 749242038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.26637
Policy Entropy: 3.66918
Value Function Loss: 0.07662

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.83181

Collected Steps per Second: 23,258.26615
Overall Steps per Second: 10,773.61262

Timestep Collection Time: 2.15089
Timestep Consumption Time: 2.49249
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.64338

Cumulative Model Updates: 89,842
Cumulative Timesteps: 749,292,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,685.80064
Policy Entropy: 3.66915
Value Function Loss: 0.07548

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.51329
Value Function Update Magnitude: 0.84959

Collected Steps per Second: 22,778.05899
Overall Steps per Second: 10,821.05331

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.62302

Cumulative Model Updates: 89,848
Cumulative Timesteps: 749,342,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 749342090...
Checkpoint 749342090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,190.27067
Policy Entropy: 3.67887
Value Function Loss: 0.07335

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.46380
Value Function Update Magnitude: 0.86964

Collected Steps per Second: 22,202.45750
Overall Steps per Second: 10,586.52853

Timestep Collection Time: 2.25227
Timestep Consumption Time: 2.47128
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.72355

Cumulative Model Updates: 89,854
Cumulative Timesteps: 749,392,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,086.69528
Policy Entropy: 3.67936
Value Function Loss: 0.07225

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.54577
Value Function Update Magnitude: 0.89117

Collected Steps per Second: 22,707.57494
Overall Steps per Second: 10,647.81974

Timestep Collection Time: 2.20191
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.69580

Cumulative Model Updates: 89,860
Cumulative Timesteps: 749,442,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 749442096...
Checkpoint 749442096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,298.97666
Policy Entropy: 3.66563
Value Function Loss: 0.07416

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11369
Policy Update Magnitude: 0.59764
Value Function Update Magnitude: 0.90133

Collected Steps per Second: 22,584.44539
Overall Steps per Second: 10,676.69897

Timestep Collection Time: 2.21498
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.68534

Cumulative Model Updates: 89,866
Cumulative Timesteps: 749,492,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,473.06066
Policy Entropy: 3.65495
Value Function Loss: 0.07832

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.62630
Value Function Update Magnitude: 0.86312

Collected Steps per Second: 22,931.55987
Overall Steps per Second: 10,680.41819

Timestep Collection Time: 2.18110
Timestep Consumption Time: 2.50186
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.68296

Cumulative Model Updates: 89,872
Cumulative Timesteps: 749,542,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 749542136...
Checkpoint 749542136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,197.85292
Policy Entropy: 3.65345
Value Function Loss: 0.07597

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.49304
Value Function Update Magnitude: 0.88745

Collected Steps per Second: 22,015.19585
Overall Steps per Second: 10,543.35436

Timestep Collection Time: 2.27207
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.74422

Cumulative Model Updates: 89,878
Cumulative Timesteps: 749,592,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,316.95666
Policy Entropy: 3.66939
Value Function Loss: 0.07672

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.48178
Value Function Update Magnitude: 0.89099

Collected Steps per Second: 23,134.00306
Overall Steps per Second: 10,683.83666

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.51996
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.68240

Cumulative Model Updates: 89,884
Cumulative Timesteps: 749,642,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 749642182...
Checkpoint 749642182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,859.92258
Policy Entropy: 3.66240
Value Function Loss: 0.07533

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.51862
Value Function Update Magnitude: 0.89018

Collected Steps per Second: 22,891.46816
Overall Steps per Second: 10,713.79055

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.48326
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.66800

Cumulative Model Updates: 89,890
Cumulative Timesteps: 749,692,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,825.44022
Policy Entropy: 3.66761
Value Function Loss: 0.07358

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.88517

Collected Steps per Second: 23,080.88635
Overall Steps per Second: 10,695.89484

Timestep Collection Time: 2.16759
Timestep Consumption Time: 2.50990
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.67750

Cumulative Model Updates: 89,896
Cumulative Timesteps: 749,742,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 749742224...
Checkpoint 749742224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,034.62071
Policy Entropy: 3.67471
Value Function Loss: 0.06996

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.53245
Value Function Update Magnitude: 0.85160

Collected Steps per Second: 22,606.15205
Overall Steps per Second: 10,643.35839

Timestep Collection Time: 2.21241
Timestep Consumption Time: 2.48667
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.69908

Cumulative Model Updates: 89,902
Cumulative Timesteps: 749,792,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,139.49747
Policy Entropy: 3.67947
Value Function Loss: 0.06686

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.42735
Value Function Update Magnitude: 0.72759

Collected Steps per Second: 22,750.73551
Overall Steps per Second: 10,679.99005

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.68278

Cumulative Model Updates: 89,908
Cumulative Timesteps: 749,842,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 749842250...
Checkpoint 749842250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,066.91057
Policy Entropy: 3.67563
Value Function Loss: 0.07343

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.68371

Collected Steps per Second: 22,922.67969
Overall Steps per Second: 10,840.24535

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61484

Cumulative Model Updates: 89,914
Cumulative Timesteps: 749,892,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,211.66612
Policy Entropy: 3.66239
Value Function Loss: 0.07547

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11049
Policy Update Magnitude: 0.60338
Value Function Update Magnitude: 0.63959

Collected Steps per Second: 22,366.23782
Overall Steps per Second: 10,560.22614

Timestep Collection Time: 2.23721
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.73835

Cumulative Model Updates: 89,920
Cumulative Timesteps: 749,942,314

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 749942314...
Checkpoint 749942314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.84197
Policy Entropy: 3.66357
Value Function Loss: 0.07646

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.57926
Value Function Update Magnitude: 0.63529

Collected Steps per Second: 22,148.19028
Overall Steps per Second: 10,597.33657

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.46193
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.72062

Cumulative Model Updates: 89,926
Cumulative Timesteps: 749,992,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,561.77685
Policy Entropy: 3.67524
Value Function Loss: 0.07220

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.51321
Value Function Update Magnitude: 0.61640

Collected Steps per Second: 22,442.48659
Overall Steps per Second: 10,549.28780

Timestep Collection Time: 2.22890
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.74174

Cumulative Model Updates: 89,932
Cumulative Timesteps: 750,042,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 750042362...
Checkpoint 750042362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,926.69721
Policy Entropy: 3.67765
Value Function Loss: 0.07201

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.51438
Value Function Update Magnitude: 0.61091

Collected Steps per Second: 22,462.27713
Overall Steps per Second: 10,534.20505

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.74796

Cumulative Model Updates: 89,938
Cumulative Timesteps: 750,092,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,109.37390
Policy Entropy: 3.67248
Value Function Loss: 0.06965

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.65593

Collected Steps per Second: 22,805.97893
Overall Steps per Second: 10,646.95027

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.50467
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.69787

Cumulative Model Updates: 89,944
Cumulative Timesteps: 750,142,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 750142396...
Checkpoint 750142396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,211.20719
Policy Entropy: 3.67264
Value Function Loss: 0.06563

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.70830

Collected Steps per Second: 22,504.99031
Overall Steps per Second: 10,610.48212

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.49079
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.71270

Cumulative Model Updates: 89,950
Cumulative Timesteps: 750,192,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,796.89086
Policy Entropy: 3.67849
Value Function Loss: 0.05876

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.50229
Value Function Update Magnitude: 0.75097

Collected Steps per Second: 22,987.95003
Overall Steps per Second: 10,738.42885

Timestep Collection Time: 2.17592
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.65804

Cumulative Model Updates: 89,956
Cumulative Timesteps: 750,242,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 750242420...
Checkpoint 750242420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,544.19259
Policy Entropy: 3.67681
Value Function Loss: 0.05495

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.52608
Value Function Update Magnitude: 0.76332

Collected Steps per Second: 22,991.13308
Overall Steps per Second: 10,698.96709

Timestep Collection Time: 2.17519
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.67428

Cumulative Model Updates: 89,962
Cumulative Timesteps: 750,292,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,382.33305
Policy Entropy: 3.68926
Value Function Loss: 0.05260

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.58216
Value Function Update Magnitude: 0.75501

Collected Steps per Second: 22,940.46056
Overall Steps per Second: 10,811.34775

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.44629
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62681

Cumulative Model Updates: 89,968
Cumulative Timesteps: 750,342,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 750342452...
Checkpoint 750342452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,849.26967
Policy Entropy: 3.69242
Value Function Loss: 0.05271

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.75825

Collected Steps per Second: 22,641.97520
Overall Steps per Second: 10,682.01000

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.47278
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.68133

Cumulative Model Updates: 89,974
Cumulative Timesteps: 750,392,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,350.18381
Policy Entropy: 3.70717
Value Function Loss: 0.05521

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.62183
Value Function Update Magnitude: 0.75937

Collected Steps per Second: 22,505.37589
Overall Steps per Second: 10,611.22354

Timestep Collection Time: 2.22196
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.71256

Cumulative Model Updates: 89,980
Cumulative Timesteps: 750,442,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 750442464...
Checkpoint 750442464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,306.55169
Policy Entropy: 3.70394
Value Function Loss: 0.05767

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.66611
Value Function Update Magnitude: 0.76682

Collected Steps per Second: 22,467.73984
Overall Steps per Second: 10,579.45761

Timestep Collection Time: 2.22657
Timestep Consumption Time: 2.50203
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.72860

Cumulative Model Updates: 89,986
Cumulative Timesteps: 750,492,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.43879
Policy Entropy: 3.69456
Value Function Loss: 0.06190

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06005
Policy Update Magnitude: 0.75110
Value Function Update Magnitude: 0.77581

Collected Steps per Second: 22,782.86184
Overall Steps per Second: 10,736.61154

Timestep Collection Time: 2.19525
Timestep Consumption Time: 2.46302
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.65827

Cumulative Model Updates: 89,992
Cumulative Timesteps: 750,542,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 750542504...
Checkpoint 750542504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.20848
Policy Entropy: 3.67289
Value Function Loss: 0.06067

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.76568
Value Function Update Magnitude: 0.78797

Collected Steps per Second: 22,298.24270
Overall Steps per Second: 10,677.68414

Timestep Collection Time: 2.24323
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.68454

Cumulative Model Updates: 89,998
Cumulative Timesteps: 750,592,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.03080
Policy Entropy: 3.67132
Value Function Loss: 0.05928

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.75540
Value Function Update Magnitude: 0.78029

Collected Steps per Second: 22,918.96192
Overall Steps per Second: 10,862.48783

Timestep Collection Time: 2.18204
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60392

Cumulative Model Updates: 90,004
Cumulative Timesteps: 750,642,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 750642534...
Checkpoint 750642534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.68655
Policy Entropy: 3.66795
Value Function Loss: 0.05878

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.72164
Value Function Update Magnitude: 0.76479

Collected Steps per Second: 22,423.25844
Overall Steps per Second: 10,707.14642

Timestep Collection Time: 2.23081
Timestep Consumption Time: 2.44102
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.67183

Cumulative Model Updates: 90,010
Cumulative Timesteps: 750,692,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,387.87739
Policy Entropy: 3.67935
Value Function Loss: 0.06459

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.69584
Value Function Update Magnitude: 0.72696

Collected Steps per Second: 23,163.82732
Overall Steps per Second: 10,883.02577

Timestep Collection Time: 2.15992
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.59725

Cumulative Model Updates: 90,016
Cumulative Timesteps: 750,742,588

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 750742588...
Checkpoint 750742588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,607.38516
Policy Entropy: 3.66401
Value Function Loss: 0.06753

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.56256
Value Function Update Magnitude: 0.69862

Collected Steps per Second: 22,565.38443
Overall Steps per Second: 10,688.52941

Timestep Collection Time: 2.21632
Timestep Consumption Time: 2.46272
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.67903

Cumulative Model Updates: 90,022
Cumulative Timesteps: 750,792,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.33992
Policy Entropy: 3.68083
Value Function Loss: 0.06749

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.52408
Value Function Update Magnitude: 0.70747

Collected Steps per Second: 22,618.39811
Overall Steps per Second: 10,776.47188

Timestep Collection Time: 2.21174
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.64215

Cumulative Model Updates: 90,028
Cumulative Timesteps: 750,842,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 750842626...
Checkpoint 750842626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,891.77619
Policy Entropy: 3.68264
Value Function Loss: 0.06507

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.50734
Value Function Update Magnitude: 0.71425

Collected Steps per Second: 22,837.30189
Overall Steps per Second: 10,765.48482

Timestep Collection Time: 2.19010
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.64596

Cumulative Model Updates: 90,034
Cumulative Timesteps: 750,892,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,307.86093
Policy Entropy: 3.67752
Value Function Loss: 0.06551

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.55673
Value Function Update Magnitude: 0.74890

Collected Steps per Second: 22,948.96073
Overall Steps per Second: 10,843.63686

Timestep Collection Time: 2.17892
Timestep Consumption Time: 2.43245
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.61137

Cumulative Model Updates: 90,040
Cumulative Timesteps: 750,942,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 750942646...
Checkpoint 750942646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,290.28811
Policy Entropy: 3.67270
Value Function Loss: 0.06717

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.77905

Collected Steps per Second: 21,783.30200
Overall Steps per Second: 10,452.28281

Timestep Collection Time: 2.29653
Timestep Consumption Time: 2.48960
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.78613

Cumulative Model Updates: 90,046
Cumulative Timesteps: 750,992,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,761.76404
Policy Entropy: 3.67104
Value Function Loss: 0.06742

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.55006
Value Function Update Magnitude: 0.78680

Collected Steps per Second: 22,939.47014
Overall Steps per Second: 10,699.62392

Timestep Collection Time: 2.18026
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.67437

Cumulative Model Updates: 90,052
Cumulative Timesteps: 751,042,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 751042686...
Checkpoint 751042686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,402.56590
Policy Entropy: 3.68713
Value Function Loss: 0.06665

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.48959
Value Function Update Magnitude: 0.78600

Collected Steps per Second: 22,518.78461
Overall Steps per Second: 10,630.65873

Timestep Collection Time: 2.22037
Timestep Consumption Time: 2.48301
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.70338

Cumulative Model Updates: 90,058
Cumulative Timesteps: 751,092,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,160.27555
Policy Entropy: 3.67380
Value Function Loss: 0.06774

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.38218
Value Function Update Magnitude: 0.81402

Collected Steps per Second: 23,008.65161
Overall Steps per Second: 10,687.20647

Timestep Collection Time: 2.17449
Timestep Consumption Time: 2.50700
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.68149

Cumulative Model Updates: 90,064
Cumulative Timesteps: 751,142,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 751142718...
Checkpoint 751142718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,276.52021
Policy Entropy: 3.66445
Value Function Loss: 0.07169

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.35402
Value Function Update Magnitude: 0.82975

Collected Steps per Second: 22,862.87872
Overall Steps per Second: 10,804.90843

Timestep Collection Time: 2.18774
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.62919

Cumulative Model Updates: 90,070
Cumulative Timesteps: 751,192,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,794.62704
Policy Entropy: 3.65747
Value Function Loss: 0.07350

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.40316
Value Function Update Magnitude: 0.82781

Collected Steps per Second: 22,950.34007
Overall Steps per Second: 10,668.67446

Timestep Collection Time: 2.17870
Timestep Consumption Time: 2.50810
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.68681

Cumulative Model Updates: 90,076
Cumulative Timesteps: 751,242,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 751242738...
Checkpoint 751242738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,983.77757
Policy Entropy: 3.66926
Value Function Loss: 0.07339

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.37303
Value Function Update Magnitude: 0.72819

Collected Steps per Second: 22,863.11861
Overall Steps per Second: 10,878.80577

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.41022
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.59811

Cumulative Model Updates: 90,082
Cumulative Timesteps: 751,292,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,444.94519
Policy Entropy: 3.67979
Value Function Loss: 0.07262

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.40615
Value Function Update Magnitude: 0.63925

Collected Steps per Second: 22,296.02918
Overall Steps per Second: 10,537.49460

Timestep Collection Time: 2.24327
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.74648

Cumulative Model Updates: 90,088
Cumulative Timesteps: 751,342,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 751342776...
Checkpoint 751342776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,988.60105
Policy Entropy: 3.68497
Value Function Loss: 0.06999

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.49172
Value Function Update Magnitude: 0.66995

Collected Steps per Second: 22,610.94333
Overall Steps per Second: 10,627.74351

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.49445
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.70674

Cumulative Model Updates: 90,094
Cumulative Timesteps: 751,392,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,589.90904
Policy Entropy: 3.68073
Value Function Loss: 0.07018

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.46840
Value Function Update Magnitude: 0.69959

Collected Steps per Second: 22,057.26375
Overall Steps per Second: 10,440.15841

Timestep Collection Time: 2.26701
Timestep Consumption Time: 2.52257
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.78958

Cumulative Model Updates: 90,100
Cumulative Timesteps: 751,442,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 751442802...
Checkpoint 751442802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.31233
Policy Entropy: 3.69647
Value Function Loss: 0.06639

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.48068
Value Function Update Magnitude: 0.77418

Collected Steps per Second: 22,091.22781
Overall Steps per Second: 10,646.20207

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.69801

Cumulative Model Updates: 90,106
Cumulative Timesteps: 751,492,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,785.42805
Policy Entropy: 3.69758
Value Function Loss: 0.06824

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.72192

Collected Steps per Second: 22,650.74358
Overall Steps per Second: 10,607.86627

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.71707

Cumulative Model Updates: 90,112
Cumulative Timesteps: 751,542,856

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 751542856...
Checkpoint 751542856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.12913
Policy Entropy: 3.68900
Value Function Loss: 0.06855

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.70220
Value Function Update Magnitude: 0.68116

Collected Steps per Second: 22,594.34134
Overall Steps per Second: 10,515.26922

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.54225
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.75537

Cumulative Model Updates: 90,118
Cumulative Timesteps: 751,592,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.14749
Policy Entropy: 3.67535
Value Function Loss: 0.06894

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.63597
Value Function Update Magnitude: 0.66701

Collected Steps per Second: 22,997.58127
Overall Steps per Second: 10,778.39311

Timestep Collection Time: 2.17536
Timestep Consumption Time: 2.46615
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.64151

Cumulative Model Updates: 90,124
Cumulative Timesteps: 751,642,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 751642888...
Checkpoint 751642888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,004.57762
Policy Entropy: 3.67742
Value Function Loss: 0.06897

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.63668

Collected Steps per Second: 22,829.55444
Overall Steps per Second: 10,774.42877

Timestep Collection Time: 2.19032
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.64099

Cumulative Model Updates: 90,130
Cumulative Timesteps: 751,692,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,985.88492
Policy Entropy: 3.67986
Value Function Loss: 0.06793

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 23,124.93792
Overall Steps per Second: 10,904.14269

Timestep Collection Time: 2.16260
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.58633

Cumulative Model Updates: 90,136
Cumulative Timesteps: 751,742,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 751742902...
Checkpoint 751742902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,683.23354
Policy Entropy: 3.67742
Value Function Loss: 0.06699

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.60122
Value Function Update Magnitude: 0.67854

Collected Steps per Second: 22,543.51602
Overall Steps per Second: 10,662.03229

Timestep Collection Time: 2.21926
Timestep Consumption Time: 2.47309
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.69235

Cumulative Model Updates: 90,142
Cumulative Timesteps: 751,792,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.83766
Policy Entropy: 3.67085
Value Function Loss: 0.06763

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.69262

Collected Steps per Second: 22,934.84615
Overall Steps per Second: 10,830.08663

Timestep Collection Time: 2.18140
Timestep Consumption Time: 2.43814
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.61954

Cumulative Model Updates: 90,148
Cumulative Timesteps: 751,842,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 751842962...
Checkpoint 751842962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,489.33514
Policy Entropy: 3.66915
Value Function Loss: 0.06777

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.63990

Collected Steps per Second: 22,408.22325
Overall Steps per Second: 10,751.54231

Timestep Collection Time: 2.23231
Timestep Consumption Time: 2.42024
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.65254

Cumulative Model Updates: 90,154
Cumulative Timesteps: 751,892,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,780.34959
Policy Entropy: 3.68445
Value Function Loss: 0.06705

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.64673

Collected Steps per Second: 22,771.70223
Overall Steps per Second: 10,809.08904

Timestep Collection Time: 2.19597
Timestep Consumption Time: 2.43032
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.62629

Cumulative Model Updates: 90,160
Cumulative Timesteps: 751,942,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 751942990...
Checkpoint 751942990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,339.53440
Policy Entropy: 3.68536
Value Function Loss: 0.06571

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.62816

Collected Steps per Second: 22,033.26440
Overall Steps per Second: 10,654.12297

Timestep Collection Time: 2.26948
Timestep Consumption Time: 2.42392
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.69339

Cumulative Model Updates: 90,166
Cumulative Timesteps: 751,992,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.92340
Policy Entropy: 3.68438
Value Function Loss: 0.06756

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.61904
Value Function Update Magnitude: 0.62705

Collected Steps per Second: 22,538.39102
Overall Steps per Second: 10,578.68548

Timestep Collection Time: 2.21968
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.72913

Cumulative Model Updates: 90,172
Cumulative Timesteps: 752,043,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 752043022...
Checkpoint 752043022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,366.72420
Policy Entropy: 3.67214
Value Function Loss: 0.06581

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.59738
Value Function Update Magnitude: 0.63504

Collected Steps per Second: 22,283.96813
Overall Steps per Second: 10,554.90800

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.49347
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.73732

Cumulative Model Updates: 90,178
Cumulative Timesteps: 752,093,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,832.58586
Policy Entropy: 3.67198
Value Function Loss: 0.06612

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.48690
Value Function Update Magnitude: 0.64712

Collected Steps per Second: 23,081.90402
Overall Steps per Second: 10,841.73151

Timestep Collection Time: 2.16672
Timestep Consumption Time: 2.44620
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.61292

Cumulative Model Updates: 90,184
Cumulative Timesteps: 752,143,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 752143036...
Checkpoint 752143036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,281.98658
Policy Entropy: 3.67605
Value Function Loss: 0.06753

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.52179
Value Function Update Magnitude: 0.64472

Collected Steps per Second: 22,319.02568
Overall Steps per Second: 10,697.62400

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.67468

Cumulative Model Updates: 90,190
Cumulative Timesteps: 752,193,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,190.34754
Policy Entropy: 3.67313
Value Function Loss: 0.07003

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.58799

Collected Steps per Second: 22,946.02623
Overall Steps per Second: 10,833.86935

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.61626

Cumulative Model Updates: 90,196
Cumulative Timesteps: 752,243,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 752243056...
Checkpoint 752243056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,723.99413
Policy Entropy: 3.67372
Value Function Loss: 0.07334

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.60135
Value Function Update Magnitude: 0.59481

Collected Steps per Second: 22,614.05165
Overall Steps per Second: 10,735.87461

Timestep Collection Time: 2.21216
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.65970

Cumulative Model Updates: 90,202
Cumulative Timesteps: 752,293,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,201.82473
Policy Entropy: 3.66695
Value Function Loss: 0.07168

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.64221
Value Function Update Magnitude: 0.60439

Collected Steps per Second: 23,202.40829
Overall Steps per Second: 10,925.57998

Timestep Collection Time: 2.15572
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.57806

Cumulative Model Updates: 90,208
Cumulative Timesteps: 752,343,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 752343100...
Checkpoint 752343100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,029.47983
Policy Entropy: 3.65400
Value Function Loss: 0.06925

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.73048
Value Function Update Magnitude: 0.59659

Collected Steps per Second: 22,232.87635
Overall Steps per Second: 10,615.90034

Timestep Collection Time: 2.24910
Timestep Consumption Time: 2.46119
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.71029

Cumulative Model Updates: 90,214
Cumulative Timesteps: 752,393,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.98222
Policy Entropy: 3.64174
Value Function Loss: 0.07107

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.69244
Value Function Update Magnitude: 0.56934

Collected Steps per Second: 22,049.36019
Overall Steps per Second: 10,813.21955

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.35642
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62415

Cumulative Model Updates: 90,220
Cumulative Timesteps: 752,443,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 752443106...
Checkpoint 752443106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,733.53516
Policy Entropy: 3.66129
Value Function Loss: 0.07127

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.52740
Value Function Update Magnitude: 0.63020

Collected Steps per Second: 20,914.67258
Overall Steps per Second: 10,363.31867

Timestep Collection Time: 2.39153
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.82645

Cumulative Model Updates: 90,226
Cumulative Timesteps: 752,493,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.91716
Policy Entropy: 3.66844
Value Function Loss: 0.06957

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.66307

Collected Steps per Second: 21,885.67137
Overall Steps per Second: 10,794.77473

Timestep Collection Time: 2.28506
Timestep Consumption Time: 2.34774
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.63280

Cumulative Model Updates: 90,232
Cumulative Timesteps: 752,543,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 752543134...
Checkpoint 752543134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.22530
Policy Entropy: 3.67378
Value Function Loss: 0.06602

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.64709
Value Function Update Magnitude: 0.65005

Collected Steps per Second: 21,470.32036
Overall Steps per Second: 10,713.08329

Timestep Collection Time: 2.32991
Timestep Consumption Time: 2.33952
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.66943

Cumulative Model Updates: 90,238
Cumulative Timesteps: 752,593,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.69615
Policy Entropy: 3.67443
Value Function Loss: 0.06604

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.64704
Value Function Update Magnitude: 0.62522

Collected Steps per Second: 22,413.11054
Overall Steps per Second: 10,821.94218

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.38979
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.62098

Cumulative Model Updates: 90,244
Cumulative Timesteps: 752,643,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 752643166...
Checkpoint 752643166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.80302
Policy Entropy: 3.68041
Value Function Loss: 0.06585

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.59609
Value Function Update Magnitude: 0.62990

Collected Steps per Second: 22,007.61728
Overall Steps per Second: 10,626.04683

Timestep Collection Time: 2.27330
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.70824

Cumulative Model Updates: 90,250
Cumulative Timesteps: 752,693,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,364.10135
Policy Entropy: 3.67566
Value Function Loss: 0.06780

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.60591
Value Function Update Magnitude: 0.67375

Collected Steps per Second: 22,478.79822
Overall Steps per Second: 10,896.37812

Timestep Collection Time: 2.22432
Timestep Consumption Time: 2.36436
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.58868

Cumulative Model Updates: 90,256
Cumulative Timesteps: 752,743,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 752743196...
Checkpoint 752743196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,914.57203
Policy Entropy: 3.67799
Value Function Loss: 0.06672

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.59691
Value Function Update Magnitude: 0.64777

Collected Steps per Second: 21,990.80934
Overall Steps per Second: 10,669.10217

Timestep Collection Time: 2.27422
Timestep Consumption Time: 2.41333
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.68755

Cumulative Model Updates: 90,262
Cumulative Timesteps: 752,793,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,998.61561
Policy Entropy: 3.66996
Value Function Loss: 0.06806

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.61123
Value Function Update Magnitude: 0.62271

Collected Steps per Second: 22,955.65092
Overall Steps per Second: 10,883.90564

Timestep Collection Time: 2.17837
Timestep Consumption Time: 2.41612
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.59449

Cumulative Model Updates: 90,268
Cumulative Timesteps: 752,843,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 752843214...
Checkpoint 752843214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,215.85210
Policy Entropy: 3.66777
Value Function Loss: 0.06900

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.59579
Value Function Update Magnitude: 0.65646

Collected Steps per Second: 22,626.75403
Overall Steps per Second: 10,719.14263

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.45625
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.66735

Cumulative Model Updates: 90,274
Cumulative Timesteps: 752,893,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.86256
Policy Entropy: 3.67407
Value Function Loss: 0.07156

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.65025

Collected Steps per Second: 22,946.59971
Overall Steps per Second: 10,879.90361

Timestep Collection Time: 2.18019
Timestep Consumption Time: 2.41801
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.59820

Cumulative Model Updates: 90,280
Cumulative Timesteps: 752,943,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 752943272...
Checkpoint 752943272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.53718
Policy Entropy: 3.66450
Value Function Loss: 0.07613

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.59059
Value Function Update Magnitude: 0.66562

Collected Steps per Second: 22,264.51312
Overall Steps per Second: 10,664.38941

Timestep Collection Time: 2.24671
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.69056

Cumulative Model Updates: 90,286
Cumulative Timesteps: 752,993,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.18985
Policy Entropy: 3.67381
Value Function Loss: 0.07499

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.59662
Value Function Update Magnitude: 0.76594

Collected Steps per Second: 22,709.32034
Overall Steps per Second: 10,826.33710

Timestep Collection Time: 2.20280
Timestep Consumption Time: 2.41779
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.62058

Cumulative Model Updates: 90,292
Cumulative Timesteps: 753,043,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 753043318...
Checkpoint 753043318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.71061
Policy Entropy: 3.66756
Value Function Loss: 0.07568

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.60785
Value Function Update Magnitude: 0.77604

Collected Steps per Second: 22,628.28980
Overall Steps per Second: 10,759.33615

Timestep Collection Time: 2.20998
Timestep Consumption Time: 2.43789
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.64787

Cumulative Model Updates: 90,298
Cumulative Timesteps: 753,093,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,973.79648
Policy Entropy: 3.67280
Value Function Loss: 0.07465

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.65954
Value Function Update Magnitude: 0.80037

Collected Steps per Second: 23,112.94917
Overall Steps per Second: 10,773.92284

Timestep Collection Time: 2.16441
Timestep Consumption Time: 2.47883
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.64325

Cumulative Model Updates: 90,304
Cumulative Timesteps: 753,143,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 753143352...
Checkpoint 753143352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,852.22835
Policy Entropy: 3.66752
Value Function Loss: 0.07322

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.58910
Value Function Update Magnitude: 0.85381

Collected Steps per Second: 22,632.10370
Overall Steps per Second: 10,735.46364

Timestep Collection Time: 2.20925
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.65746

Cumulative Model Updates: 90,310
Cumulative Timesteps: 753,193,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,281.55544
Policy Entropy: 3.68280
Value Function Loss: 0.07157

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.83980

Collected Steps per Second: 23,130.08676
Overall Steps per Second: 10,963.14216

Timestep Collection Time: 2.16238
Timestep Consumption Time: 2.39982
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.56220

Cumulative Model Updates: 90,316
Cumulative Timesteps: 753,243,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 753243368...
Checkpoint 753243368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,960.24155
Policy Entropy: 3.68552
Value Function Loss: 0.07169

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.83623

Collected Steps per Second: 22,842.25515
Overall Steps per Second: 10,678.29715

Timestep Collection Time: 2.18919
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68296

Cumulative Model Updates: 90,322
Cumulative Timesteps: 753,293,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.25959
Policy Entropy: 3.68404
Value Function Loss: 0.07222

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.54135
Value Function Update Magnitude: 0.84246

Collected Steps per Second: 23,255.30046
Overall Steps per Second: 10,836.22410

Timestep Collection Time: 2.15125
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.61674

Cumulative Model Updates: 90,328
Cumulative Timesteps: 753,343,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 753343402...
Checkpoint 753343402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,730.35533
Policy Entropy: 3.67090
Value Function Loss: 0.07270

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.61613
Value Function Update Magnitude: 0.85351

Collected Steps per Second: 22,275.04145
Overall Steps per Second: 10,621.83181

Timestep Collection Time: 2.24556
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.70917

Cumulative Model Updates: 90,334
Cumulative Timesteps: 753,393,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,557.81628
Policy Entropy: 3.66522
Value Function Loss: 0.07037

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.59368
Value Function Update Magnitude: 0.86401

Collected Steps per Second: 22,447.71347
Overall Steps per Second: 10,686.80096

Timestep Collection Time: 2.22856
Timestep Consumption Time: 2.45254
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.68110

Cumulative Model Updates: 90,340
Cumulative Timesteps: 753,443,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 753443448...
Checkpoint 753443448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,580.59247
Policy Entropy: 3.66817
Value Function Loss: 0.07117

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.59476
Value Function Update Magnitude: 0.86793

Collected Steps per Second: 22,326.49270
Overall Steps per Second: 10,798.64397

Timestep Collection Time: 2.23958
Timestep Consumption Time: 2.39081
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.63040

Cumulative Model Updates: 90,346
Cumulative Timesteps: 753,493,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,831.30613
Policy Entropy: 3.66730
Value Function Loss: 0.07439

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.87097

Collected Steps per Second: 22,434.93579
Overall Steps per Second: 10,548.72404

Timestep Collection Time: 2.23009
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.74294

Cumulative Model Updates: 90,352
Cumulative Timesteps: 753,543,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 753543482...
Checkpoint 753543482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,971.20548
Policy Entropy: 3.67348
Value Function Loss: 0.07497

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.87339

Collected Steps per Second: 22,215.23930
Overall Steps per Second: 10,616.14849

Timestep Collection Time: 2.25089
Timestep Consumption Time: 2.45930
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.71018

Cumulative Model Updates: 90,358
Cumulative Timesteps: 753,593,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,511.37839
Policy Entropy: 3.67242
Value Function Loss: 0.07607

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.58366
Value Function Update Magnitude: 0.86128

Collected Steps per Second: 23,432.54887
Overall Steps per Second: 10,915.56947

Timestep Collection Time: 2.13430
Timestep Consumption Time: 2.44742
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.58171

Cumulative Model Updates: 90,364
Cumulative Timesteps: 753,643,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 753643498...
Checkpoint 753643498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,260.16106
Policy Entropy: 3.67642
Value Function Loss: 0.07292

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.84435

Collected Steps per Second: 22,766.35843
Overall Steps per Second: 10,704.10420

Timestep Collection Time: 2.19622
Timestep Consumption Time: 2.47488
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.67111

Cumulative Model Updates: 90,370
Cumulative Timesteps: 753,693,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.60093
Policy Entropy: 3.65992
Value Function Loss: 0.07225

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.55890
Value Function Update Magnitude: 0.83875

Collected Steps per Second: 23,319.30312
Overall Steps per Second: 10,859.90338

Timestep Collection Time: 2.14492
Timestep Consumption Time: 2.46083
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.60575

Cumulative Model Updates: 90,376
Cumulative Timesteps: 753,743,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 753743516...
Checkpoint 753743516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,390.25603
Policy Entropy: 3.67089
Value Function Loss: 0.07066

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.65388
Value Function Update Magnitude: 0.83554

Collected Steps per Second: 22,640.81946
Overall Steps per Second: 10,612.10164

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.71405

Cumulative Model Updates: 90,382
Cumulative Timesteps: 753,793,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.14100
Policy Entropy: 3.65989
Value Function Loss: 0.07441

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.62422
Value Function Update Magnitude: 0.86209

Collected Steps per Second: 23,052.22161
Overall Steps per Second: 10,835.21433

Timestep Collection Time: 2.16994
Timestep Consumption Time: 2.44667
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61661

Cumulative Model Updates: 90,388
Cumulative Timesteps: 753,843,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 753843564...
Checkpoint 753843564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,115.74169
Policy Entropy: 3.66780
Value Function Loss: 0.07424

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.72330
Value Function Update Magnitude: 0.87737

Collected Steps per Second: 22,291.61175
Overall Steps per Second: 10,693.89892

Timestep Collection Time: 2.24309
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.67575

Cumulative Model Updates: 90,394
Cumulative Timesteps: 753,893,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,079.99213
Policy Entropy: 3.65847
Value Function Loss: 0.07390

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07103
Policy Update Magnitude: 0.79919
Value Function Update Magnitude: 0.84773

Collected Steps per Second: 22,857.22955
Overall Steps per Second: 10,844.95113

Timestep Collection Time: 2.18837
Timestep Consumption Time: 2.42392
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61228

Cumulative Model Updates: 90,400
Cumulative Timesteps: 753,943,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 753943586...
Checkpoint 753943586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.45849
Policy Entropy: 3.66491
Value Function Loss: 0.07513

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07102
Policy Update Magnitude: 0.79602
Value Function Update Magnitude: 0.73454

Collected Steps per Second: 22,023.11679
Overall Steps per Second: 10,660.41860

Timestep Collection Time: 2.27179
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.69325

Cumulative Model Updates: 90,406
Cumulative Timesteps: 753,993,618

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,045.74580
Policy Entropy: 3.65224
Value Function Loss: 0.07453

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.77322
Value Function Update Magnitude: 0.74370

Collected Steps per Second: 22,496.81053
Overall Steps per Second: 10,563.69000

Timestep Collection Time: 2.22396
Timestep Consumption Time: 2.51226
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.73622

Cumulative Model Updates: 90,412
Cumulative Timesteps: 754,043,650

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 754043650...
Checkpoint 754043650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,202.32689
Policy Entropy: 3.65120
Value Function Loss: 0.07711

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.63339
Value Function Update Magnitude: 0.79729

Collected Steps per Second: 22,461.69685
Overall Steps per Second: 10,593.61805

Timestep Collection Time: 2.22601
Timestep Consumption Time: 2.49381
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.71982

Cumulative Model Updates: 90,418
Cumulative Timesteps: 754,093,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,151.64456
Policy Entropy: 3.65109
Value Function Loss: 0.07616

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.58085
Value Function Update Magnitude: 0.78955

Collected Steps per Second: 23,294.82387
Overall Steps per Second: 10,850.87369

Timestep Collection Time: 2.14752
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.61032

Cumulative Model Updates: 90,424
Cumulative Timesteps: 754,143,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 754143676...
Checkpoint 754143676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,169.67176
Policy Entropy: 3.65482
Value Function Loss: 0.07657

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.61259
Value Function Update Magnitude: 0.72095

Collected Steps per Second: 22,818.96447
Overall Steps per Second: 10,685.23313

Timestep Collection Time: 2.19247
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.68216

Cumulative Model Updates: 90,430
Cumulative Timesteps: 754,193,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161.16167
Policy Entropy: 3.65254
Value Function Loss: 0.07455

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.65502
Value Function Update Magnitude: 0.72056

Collected Steps per Second: 22,763.00947
Overall Steps per Second: 10,842.03517

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.41542
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.61223

Cumulative Model Updates: 90,436
Cumulative Timesteps: 754,243,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 754243712...
Checkpoint 754243712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,242.34124
Policy Entropy: 3.66216
Value Function Loss: 0.07335

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.59577
Value Function Update Magnitude: 0.71100

Collected Steps per Second: 22,768.67383
Overall Steps per Second: 10,713.34259

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.47217
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.66913

Cumulative Model Updates: 90,442
Cumulative Timesteps: 754,293,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,327.33897
Policy Entropy: 3.64133
Value Function Loss: 0.07888

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.61303
Value Function Update Magnitude: 0.82583

Collected Steps per Second: 23,342.02009
Overall Steps per Second: 10,902.24846

Timestep Collection Time: 2.14292
Timestep Consumption Time: 2.44513
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.58804

Cumulative Model Updates: 90,448
Cumulative Timesteps: 754,343,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 754343754...
Checkpoint 754343754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,443.58283
Policy Entropy: 3.62734
Value Function Loss: 0.08150

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.57015
Value Function Update Magnitude: 0.88235

Collected Steps per Second: 21,742.94198
Overall Steps per Second: 10,310.74001

Timestep Collection Time: 2.30079
Timestep Consumption Time: 2.55104
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.85183

Cumulative Model Updates: 90,454
Cumulative Timesteps: 754,393,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,599.71540
Policy Entropy: 3.61908
Value Function Loss: 0.08076

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.51497
Value Function Update Magnitude: 0.87276

Collected Steps per Second: 22,949.84742
Overall Steps per Second: 10,819.86288

Timestep Collection Time: 2.18049
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62501

Cumulative Model Updates: 90,460
Cumulative Timesteps: 754,443,822

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 754443822...
Checkpoint 754443822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,208.54355
Policy Entropy: 3.61464
Value Function Loss: 0.07924

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.50341
Value Function Update Magnitude: 0.79185

Collected Steps per Second: 22,264.39215
Overall Steps per Second: 10,704.45036

Timestep Collection Time: 2.24610
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.67170

Cumulative Model Updates: 90,466
Cumulative Timesteps: 754,493,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,783.89115
Policy Entropy: 3.63119
Value Function Loss: 0.07723

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.48857
Value Function Update Magnitude: 0.82107

Collected Steps per Second: 22,824.54575
Overall Steps per Second: 10,793.66545

Timestep Collection Time: 2.19133
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63383

Cumulative Model Updates: 90,472
Cumulative Timesteps: 754,543,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 754543846...
Checkpoint 754543846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,650.75327
Policy Entropy: 3.63452
Value Function Loss: 0.07882

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.49975
Value Function Update Magnitude: 0.80146

Collected Steps per Second: 22,626.38540
Overall Steps per Second: 10,734.81424

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.44842
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.65867

Cumulative Model Updates: 90,478
Cumulative Timesteps: 754,593,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,099.73074
Policy Entropy: 3.64576
Value Function Loss: 0.07886

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.54569
Value Function Update Magnitude: 0.76175

Collected Steps per Second: 22,765.04998
Overall Steps per Second: 10,747.57543

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.45635
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.65314

Cumulative Model Updates: 90,484
Cumulative Timesteps: 754,643,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 754643866...
Checkpoint 754643866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.35755
Policy Entropy: 3.64327
Value Function Loss: 0.07691

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.71919

Collected Steps per Second: 22,533.86184
Overall Steps per Second: 10,742.46842

Timestep Collection Time: 2.21942
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.65554

Cumulative Model Updates: 90,490
Cumulative Timesteps: 754,693,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,003.47772
Policy Entropy: 3.65324
Value Function Loss: 0.07384

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.55494
Value Function Update Magnitude: 0.77829

Collected Steps per Second: 23,167.71527
Overall Steps per Second: 10,860.02734

Timestep Collection Time: 2.15947
Timestep Consumption Time: 2.44733
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60680

Cumulative Model Updates: 90,496
Cumulative Timesteps: 754,743,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 754743908...
Checkpoint 754743908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.22251
Policy Entropy: 3.66507
Value Function Loss: 0.07475

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.60427
Value Function Update Magnitude: 0.83543

Collected Steps per Second: 22,680.29364
Overall Steps per Second: 10,703.89276

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.67325

Cumulative Model Updates: 90,502
Cumulative Timesteps: 754,793,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,139.11034
Policy Entropy: 3.64077
Value Function Loss: 0.07524

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.86300

Collected Steps per Second: 22,644.62089
Overall Steps per Second: 10,644.72208

Timestep Collection Time: 2.20803
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69716

Cumulative Model Updates: 90,508
Cumulative Timesteps: 754,843,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 754843930...
Checkpoint 754843930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,719.40932
Policy Entropy: 3.65034
Value Function Loss: 0.08047

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.65743
Value Function Update Magnitude: 0.81555

Collected Steps per Second: 22,786.67912
Overall Steps per Second: 10,826.67077

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.42512
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62044

Cumulative Model Updates: 90,514
Cumulative Timesteps: 754,893,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,997.41123
Policy Entropy: 3.64659
Value Function Loss: 0.07979

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.60058
Value Function Update Magnitude: 0.78170

Collected Steps per Second: 22,524.01165
Overall Steps per Second: 10,644.85039

Timestep Collection Time: 2.22030
Timestep Consumption Time: 2.47775
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69805

Cumulative Model Updates: 90,520
Cumulative Timesteps: 754,943,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 754943964...
Checkpoint 754943964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.83450
Policy Entropy: 3.66389
Value Function Loss: 0.07904

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.55830
Value Function Update Magnitude: 0.73442

Collected Steps per Second: 22,558.98895
Overall Steps per Second: 10,610.22479

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.71281

Cumulative Model Updates: 90,526
Cumulative Timesteps: 754,993,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,313.98030
Policy Entropy: 3.65367
Value Function Loss: 0.07909

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.67177

Collected Steps per Second: 22,577.26395
Overall Steps per Second: 10,750.71053

Timestep Collection Time: 2.21595
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.65365

Cumulative Model Updates: 90,532
Cumulative Timesteps: 755,043,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 755043998...
Checkpoint 755043998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.32562
Policy Entropy: 3.66056
Value Function Loss: 0.07745

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.59464
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 22,688.95727
Overall Steps per Second: 10,764.72058

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.64480

Cumulative Model Updates: 90,538
Cumulative Timesteps: 755,093,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,391.46231
Policy Entropy: 3.65592
Value Function Loss: 0.07928

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.64720
Value Function Update Magnitude: 0.61732

Collected Steps per Second: 23,223.78402
Overall Steps per Second: 10,897.42694

Timestep Collection Time: 2.15365
Timestep Consumption Time: 2.43605
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.58971

Cumulative Model Updates: 90,544
Cumulative Timesteps: 755,144,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 755144014...
Checkpoint 755144014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,822.49122
Policy Entropy: 3.67764
Value Function Loss: 0.07778

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.62959
Value Function Update Magnitude: 0.64555

Collected Steps per Second: 22,633.64291
Overall Steps per Second: 10,686.86777

Timestep Collection Time: 2.20998
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.68051

Cumulative Model Updates: 90,550
Cumulative Timesteps: 755,194,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,525.74685
Policy Entropy: 3.67191
Value Function Loss: 0.07611

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.63238
Value Function Update Magnitude: 0.67982

Collected Steps per Second: 23,347.06190
Overall Steps per Second: 10,849.14856

Timestep Collection Time: 2.14254
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.61068

Cumulative Model Updates: 90,556
Cumulative Timesteps: 755,244,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 755244056...
Checkpoint 755244056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,697.42897
Policy Entropy: 3.66768
Value Function Loss: 0.07637

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.59880
Value Function Update Magnitude: 0.68019

Collected Steps per Second: 22,716.06979
Overall Steps per Second: 10,648.64701

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.49554
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.69769

Cumulative Model Updates: 90,562
Cumulative Timesteps: 755,294,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.80909
Policy Entropy: 3.67277
Value Function Loss: 0.07525

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.72917

Collected Steps per Second: 22,969.60987
Overall Steps per Second: 10,844.64974

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.43397
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61094

Cumulative Model Updates: 90,568
Cumulative Timesteps: 755,344,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 755344084...
Checkpoint 755344084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,466.44720
Policy Entropy: 3.67144
Value Function Loss: 0.07879

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.59472
Value Function Update Magnitude: 0.68966

Collected Steps per Second: 22,520.70087
Overall Steps per Second: 10,674.59728

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.68477

Cumulative Model Updates: 90,574
Cumulative Timesteps: 755,394,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,203.25468
Policy Entropy: 3.67033
Value Function Loss: 0.07698

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.61018
Value Function Update Magnitude: 0.66118

Collected Steps per Second: 22,740.29201
Overall Steps per Second: 10,804.53226

Timestep Collection Time: 2.19988
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.63009

Cumulative Model Updates: 90,580
Cumulative Timesteps: 755,444,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 755444118...
Checkpoint 755444118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,153.34187
Policy Entropy: 3.66213
Value Function Loss: 0.07811

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.65650
Value Function Update Magnitude: 0.65482

Collected Steps per Second: 22,172.79663
Overall Steps per Second: 10,664.60818

Timestep Collection Time: 2.25556
Timestep Consumption Time: 2.43397
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.68953

Cumulative Model Updates: 90,586
Cumulative Timesteps: 755,494,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.22643
Policy Entropy: 3.66482
Value Function Loss: 0.07889

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.72046
Value Function Update Magnitude: 0.65976

Collected Steps per Second: 22,526.62035
Overall Steps per Second: 10,595.23775

Timestep Collection Time: 2.22102
Timestep Consumption Time: 2.50110
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.72212

Cumulative Model Updates: 90,592
Cumulative Timesteps: 755,544,162

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 755544162...
Checkpoint 755544162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,106.52448
Policy Entropy: 3.65642
Value Function Loss: 0.07776

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.70451
Value Function Update Magnitude: 0.78577

Collected Steps per Second: 22,464.03426
Overall Steps per Second: 10,581.37319

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.50020
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.72661

Cumulative Model Updates: 90,598
Cumulative Timesteps: 755,594,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,161.10810
Policy Entropy: 3.65118
Value Function Loss: 0.07708

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.59580
Value Function Update Magnitude: 0.86084

Collected Steps per Second: 22,964.44612
Overall Steps per Second: 10,644.75665

Timestep Collection Time: 2.17754
Timestep Consumption Time: 2.52017
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.69771

Cumulative Model Updates: 90,604
Cumulative Timesteps: 755,644,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 755644182...
Checkpoint 755644182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,562.84568
Policy Entropy: 3.64538
Value Function Loss: 0.07779

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.62608
Value Function Update Magnitude: 0.88151

Collected Steps per Second: 22,469.52288
Overall Steps per Second: 10,603.80845

Timestep Collection Time: 2.22533
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.71548

Cumulative Model Updates: 90,610
Cumulative Timesteps: 755,694,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,373.32463
Policy Entropy: 3.64934
Value Function Loss: 0.07901

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.55487
Value Function Update Magnitude: 0.88560

Collected Steps per Second: 23,136.41432
Overall Steps per Second: 10,732.26304

Timestep Collection Time: 2.16196
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.66071

Cumulative Model Updates: 90,616
Cumulative Timesteps: 755,744,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 755744204...
Checkpoint 755744204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.28773
Policy Entropy: 3.66197
Value Function Loss: 0.07949

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.50415
Value Function Update Magnitude: 0.82283

Collected Steps per Second: 22,568.92540
Overall Steps per Second: 10,643.69719

Timestep Collection Time: 2.21561
Timestep Consumption Time: 2.48238
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.69799

Cumulative Model Updates: 90,622
Cumulative Timesteps: 755,794,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,493.81244
Policy Entropy: 3.65608
Value Function Loss: 0.08390

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.50749
Value Function Update Magnitude: 0.70629

Collected Steps per Second: 23,177.36961
Overall Steps per Second: 10,873.50773

Timestep Collection Time: 2.15848
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60091

Cumulative Model Updates: 90,628
Cumulative Timesteps: 755,844,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 755844236...
Checkpoint 755844236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,173.19617
Policy Entropy: 3.64048
Value Function Loss: 0.08478

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.50995
Value Function Update Magnitude: 0.67983

Collected Steps per Second: 22,935.19697
Overall Steps per Second: 10,671.92921

Timestep Collection Time: 2.18006
Timestep Consumption Time: 2.50513
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.68519

Cumulative Model Updates: 90,634
Cumulative Timesteps: 755,894,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.85761
Policy Entropy: 3.63302
Value Function Loss: 0.08608

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.56800
Value Function Update Magnitude: 0.81894

Collected Steps per Second: 22,847.91455
Overall Steps per Second: 10,828.69703

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.43053
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.62032

Cumulative Model Updates: 90,640
Cumulative Timesteps: 755,944,268

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 755944268...
Checkpoint 755944268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,109.40282
Policy Entropy: 3.64120
Value Function Loss: 0.08005

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.61850
Value Function Update Magnitude: 0.91216

Collected Steps per Second: 22,247.04988
Overall Steps per Second: 10,690.71979

Timestep Collection Time: 2.24857
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.67920

Cumulative Model Updates: 90,646
Cumulative Timesteps: 755,994,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,347.35185
Policy Entropy: 3.64677
Value Function Loss: 0.07954

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.54329
Value Function Update Magnitude: 0.91989

Collected Steps per Second: 22,890.45841
Overall Steps per Second: 10,820.78060

Timestep Collection Time: 2.18571
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.62370

Cumulative Model Updates: 90,652
Cumulative Timesteps: 756,044,324

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 756044324...
Checkpoint 756044324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,397.34268
Policy Entropy: 3.63802
Value Function Loss: 0.07643

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.50079
Value Function Update Magnitude: 0.91055

Collected Steps per Second: 22,142.22458
Overall Steps per Second: 10,653.58370

Timestep Collection Time: 2.25840
Timestep Consumption Time: 2.43542
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.69382

Cumulative Model Updates: 90,658
Cumulative Timesteps: 756,094,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,646.68043
Policy Entropy: 3.63204
Value Function Loss: 0.07728

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.53481
Value Function Update Magnitude: 0.88423

Collected Steps per Second: 21,924.48565
Overall Steps per Second: 10,520.81283

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.75496

Cumulative Model Updates: 90,664
Cumulative Timesteps: 756,144,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 756144356...
Checkpoint 756144356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,043.20922
Policy Entropy: 3.63059
Value Function Loss: 0.07824

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.78180

Collected Steps per Second: 22,627.69975
Overall Steps per Second: 10,722.27171

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.45488
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.66580

Cumulative Model Updates: 90,670
Cumulative Timesteps: 756,194,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,266.98499
Policy Entropy: 3.62869
Value Function Loss: 0.08107

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.60912
Value Function Update Magnitude: 0.72163

Collected Steps per Second: 23,289.26186
Overall Steps per Second: 10,786.01581

Timestep Collection Time: 2.14794
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.63786

Cumulative Model Updates: 90,676
Cumulative Timesteps: 756,244,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 756244408...
Checkpoint 756244408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,546.98183
Policy Entropy: 3.62373
Value Function Loss: 0.07776

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.60228
Value Function Update Magnitude: 0.73272

Collected Steps per Second: 22,639.60520
Overall Steps per Second: 10,675.73819

Timestep Collection Time: 2.20878
Timestep Consumption Time: 2.47529
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.68408

Cumulative Model Updates: 90,682
Cumulative Timesteps: 756,294,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,422.28063
Policy Entropy: 3.62844
Value Function Loss: 0.07624

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.70045
Value Function Update Magnitude: 0.71716

Collected Steps per Second: 23,018.20161
Overall Steps per Second: 10,876.13411

Timestep Collection Time: 2.17237
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.59759

Cumulative Model Updates: 90,688
Cumulative Timesteps: 756,344,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 756344418...
Checkpoint 756344418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,694.39453
Policy Entropy: 3.63088
Value Function Loss: 0.07588

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.69514
Value Function Update Magnitude: 0.69551

Collected Steps per Second: 22,279.69102
Overall Steps per Second: 10,711.66451

Timestep Collection Time: 2.24473
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.66893

Cumulative Model Updates: 90,694
Cumulative Timesteps: 756,394,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,083.39991
Policy Entropy: 3.65282
Value Function Loss: 0.07479

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.16382
Policy Update Magnitude: 0.55366
Value Function Update Magnitude: 0.75963

Collected Steps per Second: 22,671.13793
Overall Steps per Second: 10,793.52288

Timestep Collection Time: 2.20642
Timestep Consumption Time: 2.42803
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63445

Cumulative Model Updates: 90,700
Cumulative Timesteps: 756,444,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 756444452...
Checkpoint 756444452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.20630
Policy Entropy: 3.65186
Value Function Loss: 0.07226

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.79683

Collected Steps per Second: 22,097.97671
Overall Steps per Second: 10,646.93230

Timestep Collection Time: 2.26283
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.69656

Cumulative Model Updates: 90,706
Cumulative Timesteps: 756,494,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.54635
Policy Entropy: 3.65516
Value Function Loss: 0.06993

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.61799
Value Function Update Magnitude: 0.70775

Collected Steps per Second: 22,610.14059
Overall Steps per Second: 10,538.80105

Timestep Collection Time: 2.21246
Timestep Consumption Time: 2.53419
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.74665

Cumulative Model Updates: 90,712
Cumulative Timesteps: 756,544,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 756544480...
Checkpoint 756544480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,964.64052
Policy Entropy: 3.64919
Value Function Loss: 0.07021

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.60920
Value Function Update Magnitude: 0.68489

Collected Steps per Second: 22,776.86694
Overall Steps per Second: 10,649.01846

Timestep Collection Time: 2.19591
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.69677

Cumulative Model Updates: 90,718
Cumulative Timesteps: 756,594,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,289.64181
Policy Entropy: 3.65749
Value Function Loss: 0.07018

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.69110

Collected Steps per Second: 23,104.62831
Overall Steps per Second: 10,836.47209

Timestep Collection Time: 2.16493
Timestep Consumption Time: 2.45096
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.61589

Cumulative Model Updates: 90,724
Cumulative Timesteps: 756,644,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 756644516...
Checkpoint 756644516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,233.31009
Policy Entropy: 3.66826
Value Function Loss: 0.06795

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.51790
Value Function Update Magnitude: 0.65908

Collected Steps per Second: 22,870.75318
Overall Steps per Second: 10,692.69485

Timestep Collection Time: 2.18725
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.67833

Cumulative Model Updates: 90,730
Cumulative Timesteps: 756,694,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.68279
Policy Entropy: 3.67775
Value Function Loss: 0.06532

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.47232
Value Function Update Magnitude: 0.69322

Collected Steps per Second: 22,089.44334
Overall Steps per Second: 10,428.91237

Timestep Collection Time: 2.26425
Timestep Consumption Time: 2.53165
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.79590

Cumulative Model Updates: 90,736
Cumulative Timesteps: 756,744,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 756744556...
Checkpoint 756744556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,868.07879
Policy Entropy: 3.68214
Value Function Loss: 0.06286

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.53193
Value Function Update Magnitude: 0.74598

Collected Steps per Second: 22,335.61770
Overall Steps per Second: 10,736.48654

Timestep Collection Time: 2.23983
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.65962

Cumulative Model Updates: 90,742
Cumulative Timesteps: 756,794,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,481.80309
Policy Entropy: 3.67648
Value Function Loss: 0.06512

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.73836

Collected Steps per Second: 23,401.86936
Overall Steps per Second: 10,871.93860

Timestep Collection Time: 2.13786
Timestep Consumption Time: 2.46389
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.60176

Cumulative Model Updates: 90,748
Cumulative Timesteps: 756,844,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 756844614...
Checkpoint 756844614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,317.79451
Policy Entropy: 3.67015
Value Function Loss: 0.06734

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.65825

Collected Steps per Second: 22,076.70430
Overall Steps per Second: 10,618.80749

Timestep Collection Time: 2.26492
Timestep Consumption Time: 2.44389
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.70881

Cumulative Model Updates: 90,754
Cumulative Timesteps: 756,894,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,378.30479
Policy Entropy: 3.67318
Value Function Loss: 0.06932

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.55954
Value Function Update Magnitude: 0.64281

Collected Steps per Second: 22,742.59055
Overall Steps per Second: 10,693.13574

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.67758

Cumulative Model Updates: 90,760
Cumulative Timesteps: 756,944,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 756944634...
Checkpoint 756944634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,899.33368
Policy Entropy: 3.68004
Value Function Loss: 0.06742

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06341
Policy Update Magnitude: 0.61706
Value Function Update Magnitude: 0.71029

Collected Steps per Second: 22,431.54081
Overall Steps per Second: 10,671.47922

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.45727
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.68707

Cumulative Model Updates: 90,766
Cumulative Timesteps: 756,994,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.53715
Policy Entropy: 3.66725
Value Function Loss: 0.06948

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.70683
Value Function Update Magnitude: 0.72845

Collected Steps per Second: 22,528.79459
Overall Steps per Second: 10,648.34045

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.69745

Cumulative Model Updates: 90,772
Cumulative Timesteps: 757,044,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 757044672...
Checkpoint 757044672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,990.03666
Policy Entropy: 3.65904
Value Function Loss: 0.06962

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.59894
Value Function Update Magnitude: 0.73237

Collected Steps per Second: 22,458.66114
Overall Steps per Second: 10,660.30096

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.46645
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.69499

Cumulative Model Updates: 90,778
Cumulative Timesteps: 757,094,722

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,224.49160
Policy Entropy: 3.66579
Value Function Loss: 0.07322

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.51943
Value Function Update Magnitude: 0.77985

Collected Steps per Second: 23,165.02577
Overall Steps per Second: 10,873.16125

Timestep Collection Time: 2.15851
Timestep Consumption Time: 2.44015
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59866

Cumulative Model Updates: 90,784
Cumulative Timesteps: 757,144,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 757144724...
Checkpoint 757144724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,239.04504
Policy Entropy: 3.66645
Value Function Loss: 0.07517

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.78545

Collected Steps per Second: 21,738.49649
Overall Steps per Second: 10,682.63330

Timestep Collection Time: 2.30099
Timestep Consumption Time: 2.38138
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.68237

Cumulative Model Updates: 90,790
Cumulative Timesteps: 757,194,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,943.54714
Policy Entropy: 3.65316
Value Function Loss: 0.07890

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.57730
Value Function Update Magnitude: 0.75899

Collected Steps per Second: 22,497.71919
Overall Steps per Second: 10,920.03798

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.35676
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.57965

Cumulative Model Updates: 90,796
Cumulative Timesteps: 757,244,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 757244754...
Checkpoint 757244754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,933.41424
Policy Entropy: 3.65297
Value Function Loss: 0.07798

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.71382

Collected Steps per Second: 22,090.41932
Overall Steps per Second: 10,668.25444

Timestep Collection Time: 2.26424
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.68849

Cumulative Model Updates: 90,802
Cumulative Timesteps: 757,294,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,470.31041
Policy Entropy: 3.65742
Value Function Loss: 0.07841

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.53229
Value Function Update Magnitude: 0.70802

Collected Steps per Second: 22,447.72786
Overall Steps per Second: 10,911.96820

Timestep Collection Time: 2.22793
Timestep Consumption Time: 2.35529
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.58322

Cumulative Model Updates: 90,808
Cumulative Timesteps: 757,344,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 757344784...
Checkpoint 757344784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,281.69133
Policy Entropy: 3.67035
Value Function Loss: 0.07782

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.52717
Value Function Update Magnitude: 0.77175

Collected Steps per Second: 21,703.53064
Overall Steps per Second: 10,623.38797

Timestep Collection Time: 2.30515
Timestep Consumption Time: 2.40427
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.70942

Cumulative Model Updates: 90,814
Cumulative Timesteps: 757,394,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,913.06419
Policy Entropy: 3.66386
Value Function Loss: 0.07925

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.47470
Value Function Update Magnitude: 0.74008

Collected Steps per Second: 22,468.17805
Overall Steps per Second: 10,647.61541

Timestep Collection Time: 2.22608
Timestep Consumption Time: 2.47131
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.69739

Cumulative Model Updates: 90,820
Cumulative Timesteps: 757,444,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 757444830...
Checkpoint 757444830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,449.96195
Policy Entropy: 3.65549
Value Function Loss: 0.07855

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.46053
Value Function Update Magnitude: 0.71781

Collected Steps per Second: 22,105.02472
Overall Steps per Second: 10,586.00997

Timestep Collection Time: 2.26256
Timestep Consumption Time: 2.46197
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.72454

Cumulative Model Updates: 90,826
Cumulative Timesteps: 757,494,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,006.64492
Policy Entropy: 3.64526
Value Function Loss: 0.07880

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.50383
Value Function Update Magnitude: 0.71943

Collected Steps per Second: 22,454.19615
Overall Steps per Second: 10,804.23288

Timestep Collection Time: 2.22791
Timestep Consumption Time: 2.40231
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.63022

Cumulative Model Updates: 90,832
Cumulative Timesteps: 757,544,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 757544870...
Checkpoint 757544870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,799.53270
Policy Entropy: 3.64121
Value Function Loss: 0.07841

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.56574
Value Function Update Magnitude: 0.78245

Collected Steps per Second: 22,318.31584
Overall Steps per Second: 10,583.45065

Timestep Collection Time: 2.24094
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.72568

Cumulative Model Updates: 90,838
Cumulative Timesteps: 757,594,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,172.83491
Policy Entropy: 3.64005
Value Function Loss: 0.07846

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.79226

Collected Steps per Second: 23,248.89614
Overall Steps per Second: 10,897.61086

Timestep Collection Time: 2.15184
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.59073

Cumulative Model Updates: 90,844
Cumulative Timesteps: 757,644,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 757644912...
Checkpoint 757644912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,377.92999
Policy Entropy: 3.63047
Value Function Loss: 0.07953

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.75942

Collected Steps per Second: 22,689.85804
Overall Steps per Second: 10,620.02489

Timestep Collection Time: 2.20477
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.71054

Cumulative Model Updates: 90,850
Cumulative Timesteps: 757,694,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,669.06988
Policy Entropy: 3.62079
Value Function Loss: 0.08055

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.59228
Value Function Update Magnitude: 0.76934

Collected Steps per Second: 23,187.55045
Overall Steps per Second: 10,893.98115

Timestep Collection Time: 2.15659
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59024

Cumulative Model Updates: 90,856
Cumulative Timesteps: 757,744,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 757744944...
Checkpoint 757744944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,620.68392
Policy Entropy: 3.64135
Value Function Loss: 0.07876

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.57125
Value Function Update Magnitude: 0.75918

Collected Steps per Second: 22,779.62002
Overall Steps per Second: 10,697.82340

Timestep Collection Time: 2.19600
Timestep Consumption Time: 2.48009
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.67609

Cumulative Model Updates: 90,862
Cumulative Timesteps: 757,794,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,190.27780
Policy Entropy: 3.65248
Value Function Loss: 0.07587

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.75047

Collected Steps per Second: 22,885.79236
Overall Steps per Second: 10,800.83630

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.44539
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.63094

Cumulative Model Updates: 90,868
Cumulative Timesteps: 757,844,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 757844986...
Checkpoint 757844986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,218.31992
Policy Entropy: 3.65817
Value Function Loss: 0.07341

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.16491
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.74973

Collected Steps per Second: 22,573.92767
Overall Steps per Second: 10,789.71171

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.63701

Cumulative Model Updates: 90,874
Cumulative Timesteps: 757,895,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,070.26152
Policy Entropy: 3.65301
Value Function Loss: 0.07550

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.44788
Value Function Update Magnitude: 0.71157

Collected Steps per Second: 22,560.35793
Overall Steps per Second: 10,667.16970

Timestep Collection Time: 2.21681
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.68840

Cumulative Model Updates: 90,880
Cumulative Timesteps: 757,945,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 757945030...
Checkpoint 757945030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,778.27446
Policy Entropy: 3.66240
Value Function Loss: 0.07449

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.44387
Value Function Update Magnitude: 0.68571

Collected Steps per Second: 22,328.89461
Overall Steps per Second: 10,604.23188

Timestep Collection Time: 2.24140
Timestep Consumption Time: 2.47822
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.71963

Cumulative Model Updates: 90,886
Cumulative Timesteps: 757,995,078

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.90132
Policy Entropy: 3.66126
Value Function Loss: 0.07703

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.51481
Value Function Update Magnitude: 0.64833

Collected Steps per Second: 22,790.86612
Overall Steps per Second: 10,721.36411

Timestep Collection Time: 2.19412
Timestep Consumption Time: 2.47002
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.66415

Cumulative Model Updates: 90,892
Cumulative Timesteps: 758,045,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 758045084...
Checkpoint 758045084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,484.96483
Policy Entropy: 3.66582
Value Function Loss: 0.07444

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.58801
Value Function Update Magnitude: 0.65370

Collected Steps per Second: 22,630.84194
Overall Steps per Second: 10,612.22427

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.50327
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.71362

Cumulative Model Updates: 90,898
Cumulative Timesteps: 758,095,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,882.65572
Policy Entropy: 3.65619
Value Function Loss: 0.07513

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.59793
Value Function Update Magnitude: 0.59102

Collected Steps per Second: 22,890.02383
Overall Steps per Second: 10,672.25249

Timestep Collection Time: 2.18541
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.68730

Cumulative Model Updates: 90,904
Cumulative Timesteps: 758,145,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 758145130...
Checkpoint 758145130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,168.49656
Policy Entropy: 3.64884
Value Function Loss: 0.07374

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.60251
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 22,625.04116
Overall Steps per Second: 10,594.84531

Timestep Collection Time: 2.21109
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.72173

Cumulative Model Updates: 90,910
Cumulative Timesteps: 758,195,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,111.24728
Policy Entropy: 3.64323
Value Function Loss: 0.07373

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.67476

Collected Steps per Second: 21,984.32199
Overall Steps per Second: 10,485.05453

Timestep Collection Time: 2.27489
Timestep Consumption Time: 2.49494
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.76984

Cumulative Model Updates: 90,916
Cumulative Timesteps: 758,245,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 758245168...
Checkpoint 758245168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,152.51851
Policy Entropy: 3.64561
Value Function Loss: 0.07243

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.50611
Value Function Update Magnitude: 0.69333

Collected Steps per Second: 22,365.36745
Overall Steps per Second: 10,595.06064

Timestep Collection Time: 2.23631
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.72069

Cumulative Model Updates: 90,922
Cumulative Timesteps: 758,295,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,521.70811
Policy Entropy: 3.63883
Value Function Loss: 0.07034

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.57405
Value Function Update Magnitude: 0.67458

Collected Steps per Second: 22,833.30111
Overall Steps per Second: 10,822.54430

Timestep Collection Time: 2.19092
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.62239

Cumulative Model Updates: 90,928
Cumulative Timesteps: 758,345,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 758345210...
Checkpoint 758345210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,477.98426
Policy Entropy: 3.64930
Value Function Loss: 0.07267

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.70073

Collected Steps per Second: 22,179.01438
Overall Steps per Second: 10,643.29636

Timestep Collection Time: 2.25664
Timestep Consumption Time: 2.44585
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.70249

Cumulative Model Updates: 90,934
Cumulative Timesteps: 758,395,260

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,893.80745
Policy Entropy: 3.63901
Value Function Loss: 0.07527

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.52489
Value Function Update Magnitude: 0.64204

Collected Steps per Second: 22,814.07695
Overall Steps per Second: 10,793.52773

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.63519

Cumulative Model Updates: 90,940
Cumulative Timesteps: 758,445,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 758445290...
Checkpoint 758445290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,779.50394
Policy Entropy: 3.65190
Value Function Loss: 0.07574

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.58114
Value Function Update Magnitude: 0.66637

Collected Steps per Second: 22,897.26235
Overall Steps per Second: 10,719.07228

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.48141
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.66552

Cumulative Model Updates: 90,946
Cumulative Timesteps: 758,495,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.21362
Policy Entropy: 3.64948
Value Function Loss: 0.07906

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.60103
Value Function Update Magnitude: 0.74226

Collected Steps per Second: 22,983.21316
Overall Steps per Second: 10,840.41673

Timestep Collection Time: 2.17567
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.61274

Cumulative Model Updates: 90,952
Cumulative Timesteps: 758,545,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 758545304...
Checkpoint 758545304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,330.42086
Policy Entropy: 3.64581
Value Function Loss: 0.08320

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.75407

Collected Steps per Second: 22,544.49577
Overall Steps per Second: 10,715.72642

Timestep Collection Time: 2.21881
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.66809

Cumulative Model Updates: 90,958
Cumulative Timesteps: 758,595,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,977.61799
Policy Entropy: 3.64194
Value Function Loss: 0.08289

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.70056

Collected Steps per Second: 23,174.43085
Overall Steps per Second: 10,846.36736

Timestep Collection Time: 2.15798
Timestep Consumption Time: 2.45278
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61076

Cumulative Model Updates: 90,964
Cumulative Timesteps: 758,645,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 758645336...
Checkpoint 758645336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,289.41229
Policy Entropy: 3.63494
Value Function Loss: 0.08019

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.75449

Collected Steps per Second: 22,190.94656
Overall Steps per Second: 10,667.97795

Timestep Collection Time: 2.25443
Timestep Consumption Time: 2.43512
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.68955

Cumulative Model Updates: 90,970
Cumulative Timesteps: 758,695,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,594.75757
Policy Entropy: 3.64547
Value Function Loss: 0.07592

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.57467
Value Function Update Magnitude: 0.82838

Collected Steps per Second: 22,511.67505
Overall Steps per Second: 10,610.80876

Timestep Collection Time: 2.22143
Timestep Consumption Time: 2.49151
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.71293

Cumulative Model Updates: 90,976
Cumulative Timesteps: 758,745,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 758745372...
Checkpoint 758745372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,419.97106
Policy Entropy: 3.64712
Value Function Loss: 0.07429

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.86766

Collected Steps per Second: 22,046.05647
Overall Steps per Second: 10,520.64933

Timestep Collection Time: 2.26934
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.75541

Cumulative Model Updates: 90,982
Cumulative Timesteps: 758,795,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.16238
Policy Entropy: 3.65092
Value Function Loss: 0.07419

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.48101
Value Function Update Magnitude: 0.83935

Collected Steps per Second: 22,807.78261
Overall Steps per Second: 10,803.44632

Timestep Collection Time: 2.19267
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62908

Cumulative Model Updates: 90,988
Cumulative Timesteps: 758,845,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 758845412...
Checkpoint 758845412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,825.94026
Policy Entropy: 3.65158
Value Function Loss: 0.07609

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.77636

Collected Steps per Second: 22,230.64638
Overall Steps per Second: 10,656.74253

Timestep Collection Time: 2.25041
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.69449

Cumulative Model Updates: 90,994
Cumulative Timesteps: 758,895,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,311.54889
Policy Entropy: 3.64317
Value Function Loss: 0.07897

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.52828
Value Function Update Magnitude: 0.74146

Collected Steps per Second: 23,271.30026
Overall Steps per Second: 10,733.57545

Timestep Collection Time: 2.14908
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.65940

Cumulative Model Updates: 91,000
Cumulative Timesteps: 758,945,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 758945452...
Checkpoint 758945452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,008.00159
Policy Entropy: 3.65988
Value Function Loss: 0.07607

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.76163

Collected Steps per Second: 22,700.88609
Overall Steps per Second: 10,806.62425

Timestep Collection Time: 2.20273
Timestep Consumption Time: 2.42443
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.62716

Cumulative Model Updates: 91,006
Cumulative Timesteps: 758,995,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,089.45636
Policy Entropy: 3.66617
Value Function Loss: 0.07135

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.58089
Value Function Update Magnitude: 0.82857

Collected Steps per Second: 23,361.89465
Overall Steps per Second: 10,956.62084

Timestep Collection Time: 2.14049
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.56400

Cumulative Model Updates: 91,012
Cumulative Timesteps: 759,045,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 759045462...
Checkpoint 759045462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,068.66477
Policy Entropy: 3.69547
Value Function Loss: 0.06652

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.57919
Value Function Update Magnitude: 0.86881

Collected Steps per Second: 22,554.22266
Overall Steps per Second: 10,675.74500

Timestep Collection Time: 2.21821
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.68632

Cumulative Model Updates: 91,018
Cumulative Timesteps: 759,095,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,125.27132
Policy Entropy: 3.70428
Value Function Loss: 0.06611

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.60034
Value Function Update Magnitude: 0.88818

Collected Steps per Second: 22,297.69044
Overall Steps per Second: 10,882.30528

Timestep Collection Time: 2.24247
Timestep Consumption Time: 2.35232
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.59480

Cumulative Model Updates: 91,024
Cumulative Timesteps: 759,145,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 759145494...
Checkpoint 759145494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,863.46954
Policy Entropy: 3.72079
Value Function Loss: 0.06747

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.59117
Value Function Update Magnitude: 0.88426

Collected Steps per Second: 21,710.78861
Overall Steps per Second: 10,695.26676

Timestep Collection Time: 2.30356
Timestep Consumption Time: 2.37253
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.67609

Cumulative Model Updates: 91,030
Cumulative Timesteps: 759,195,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,496.49181
Policy Entropy: 3.71622
Value Function Loss: 0.06674

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.88658

Collected Steps per Second: 22,117.79159
Overall Steps per Second: 10,823.40053

Timestep Collection Time: 2.26198
Timestep Consumption Time: 2.36041
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.62239

Cumulative Model Updates: 91,036
Cumulative Timesteps: 759,245,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 759245536...
Checkpoint 759245536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,333.75976
Policy Entropy: 3.70968
Value Function Loss: 0.06729

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.63475
Value Function Update Magnitude: 0.82621

Collected Steps per Second: 21,534.49852
Overall Steps per Second: 10,694.39363

Timestep Collection Time: 2.32325
Timestep Consumption Time: 2.35490
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.67815

Cumulative Model Updates: 91,042
Cumulative Timesteps: 759,295,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,874.40281
Policy Entropy: 3.70879
Value Function Loss: 0.07187

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.60918
Value Function Update Magnitude: 0.71413

Collected Steps per Second: 21,800.71386
Overall Steps per Second: 10,600.80400

Timestep Collection Time: 2.29424
Timestep Consumption Time: 2.42390
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.71813

Cumulative Model Updates: 91,048
Cumulative Timesteps: 759,345,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 759345582...
Checkpoint 759345582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,443.15731
Policy Entropy: 3.70495
Value Function Loss: 0.07503

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.63074
Value Function Update Magnitude: 0.71910

Collected Steps per Second: 21,908.08555
Overall Steps per Second: 10,687.15282

Timestep Collection Time: 2.28327
Timestep Consumption Time: 2.39731
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68057

Cumulative Model Updates: 91,054
Cumulative Timesteps: 759,395,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,369.97240
Policy Entropy: 3.69654
Value Function Loss: 0.07781

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.62124
Value Function Update Magnitude: 0.71211

Collected Steps per Second: 22,642.99535
Overall Steps per Second: 10,718.81655

Timestep Collection Time: 2.20943
Timestep Consumption Time: 2.45788
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.66731

Cumulative Model Updates: 91,060
Cumulative Timesteps: 759,445,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 759445632...
Checkpoint 759445632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.15199
Policy Entropy: 3.68249
Value Function Loss: 0.07547

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.57720
Value Function Update Magnitude: 0.74127

Collected Steps per Second: 22,062.20980
Overall Steps per Second: 10,573.01345

Timestep Collection Time: 2.26759
Timestep Consumption Time: 2.46408
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.73167

Cumulative Model Updates: 91,066
Cumulative Timesteps: 759,495,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,788.57099
Policy Entropy: 3.67497
Value Function Loss: 0.07689

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.52260
Value Function Update Magnitude: 0.82865

Collected Steps per Second: 22,601.43369
Overall Steps per Second: 10,661.86827

Timestep Collection Time: 2.21349
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.69224

Cumulative Model Updates: 91,072
Cumulative Timesteps: 759,545,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 759545688...
Checkpoint 759545688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,386.41166
Policy Entropy: 3.67484
Value Function Loss: 0.07437

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.59861
Value Function Update Magnitude: 0.82485

Collected Steps per Second: 22,711.18417
Overall Steps per Second: 10,868.22924

Timestep Collection Time: 2.20173
Timestep Consumption Time: 2.39920
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60093

Cumulative Model Updates: 91,078
Cumulative Timesteps: 759,595,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.54547
Policy Entropy: 3.66735
Value Function Loss: 0.07611

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.57434
Value Function Update Magnitude: 0.75508

Collected Steps per Second: 22,855.46410
Overall Steps per Second: 10,864.49349

Timestep Collection Time: 2.18801
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.60288

Cumulative Model Updates: 91,084
Cumulative Timesteps: 759,645,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 759645700...
Checkpoint 759645700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,354.08287
Policy Entropy: 3.66361
Value Function Loss: 0.07759

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11964
Policy Update Magnitude: 0.60055
Value Function Update Magnitude: 0.77335

Collected Steps per Second: 22,525.42103
Overall Steps per Second: 10,755.26797

Timestep Collection Time: 2.22078
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.65112

Cumulative Model Updates: 91,090
Cumulative Timesteps: 759,695,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,484.06698
Policy Entropy: 3.65191
Value Function Loss: 0.07779

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.51667
Value Function Update Magnitude: 0.81925

Collected Steps per Second: 22,843.44595
Overall Steps per Second: 10,854.40074

Timestep Collection Time: 2.18977
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.60845

Cumulative Model Updates: 91,096
Cumulative Timesteps: 759,745,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 759745746...
Checkpoint 759745746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,563.76808
Policy Entropy: 3.66041
Value Function Loss: 0.07786

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.50280
Value Function Update Magnitude: 0.74477

Collected Steps per Second: 22,188.83850
Overall Steps per Second: 10,775.29766

Timestep Collection Time: 2.25393
Timestep Consumption Time: 2.38743
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.64136

Cumulative Model Updates: 91,102
Cumulative Timesteps: 759,795,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,935.73474
Policy Entropy: 3.66081
Value Function Loss: 0.07866

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.52782
Value Function Update Magnitude: 0.64934

Collected Steps per Second: 22,695.46174
Overall Steps per Second: 10,820.14090

Timestep Collection Time: 2.20414
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62323

Cumulative Model Updates: 91,108
Cumulative Timesteps: 759,845,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 759845782...
Checkpoint 759845782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.46763
Policy Entropy: 3.67482
Value Function Loss: 0.07653

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.48826
Value Function Update Magnitude: 0.75010

Collected Steps per Second: 22,845.83326
Overall Steps per Second: 10,664.91705

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.68827

Cumulative Model Updates: 91,114
Cumulative Timesteps: 759,895,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,688.99731
Policy Entropy: 3.68110
Value Function Loss: 0.07517

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.78195

Collected Steps per Second: 23,007.76967
Overall Steps per Second: 10,831.00159

Timestep Collection Time: 2.17344
Timestep Consumption Time: 2.44349
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61693

Cumulative Model Updates: 91,120
Cumulative Timesteps: 759,945,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 759945788...
Checkpoint 759945788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,259.32703
Policy Entropy: 3.67943
Value Function Loss: 0.07514

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.81570

Collected Steps per Second: 22,527.31464
Overall Steps per Second: 10,711.87654

Timestep Collection Time: 2.22024
Timestep Consumption Time: 2.44897
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.66921

Cumulative Model Updates: 91,126
Cumulative Timesteps: 759,995,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,325.94666
Policy Entropy: 3.67227
Value Function Loss: 0.07661

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.81084

Collected Steps per Second: 22,532.60275
Overall Steps per Second: 10,623.13923

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.48909
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.70934

Cumulative Model Updates: 91,132
Cumulative Timesteps: 760,045,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 760045832...
Checkpoint 760045832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,587.23615
Policy Entropy: 3.66102
Value Function Loss: 0.07997

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.50079
Value Function Update Magnitude: 0.75321

Collected Steps per Second: 22,931.99861
Overall Steps per Second: 10,846.99688

Timestep Collection Time: 2.18184
Timestep Consumption Time: 2.43086
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61271

Cumulative Model Updates: 91,138
Cumulative Timesteps: 760,095,866

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,356.45945
Policy Entropy: 3.65329
Value Function Loss: 0.07915

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.48888
Value Function Update Magnitude: 0.76529

Collected Steps per Second: 22,664.58360
Overall Steps per Second: 10,524.75523

Timestep Collection Time: 2.20732
Timestep Consumption Time: 2.54604
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.75336

Cumulative Model Updates: 91,144
Cumulative Timesteps: 760,145,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 760145894...
Checkpoint 760145894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,896.19255
Policy Entropy: 3.65729
Value Function Loss: 0.07763

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.50691
Value Function Update Magnitude: 0.82388

Collected Steps per Second: 22,411.38409
Overall Steps per Second: 10,672.59726

Timestep Collection Time: 2.23163
Timestep Consumption Time: 2.45457
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.68621

Cumulative Model Updates: 91,150
Cumulative Timesteps: 760,195,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,693.70816
Policy Entropy: 3.63430
Value Function Loss: 0.07963

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.84539

Collected Steps per Second: 22,533.38974
Overall Steps per Second: 10,628.55362

Timestep Collection Time: 2.22008
Timestep Consumption Time: 2.48667
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.70676

Cumulative Model Updates: 91,156
Cumulative Timesteps: 760,245,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 760245934...
Checkpoint 760245934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,358.25884
Policy Entropy: 3.64016
Value Function Loss: 0.07921

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.57778
Value Function Update Magnitude: 0.82690

Collected Steps per Second: 22,695.29361
Overall Steps per Second: 10,676.31204

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.68608

Cumulative Model Updates: 91,162
Cumulative Timesteps: 760,295,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,681.71383
Policy Entropy: 3.63129
Value Function Loss: 0.08133

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.59183
Value Function Update Magnitude: 0.84442

Collected Steps per Second: 22,817.45276
Overall Steps per Second: 10,723.71001

Timestep Collection Time: 2.19236
Timestep Consumption Time: 2.47245
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.66480

Cumulative Model Updates: 91,168
Cumulative Timesteps: 760,345,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 760345988...
Checkpoint 760345988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,070.50676
Policy Entropy: 3.63054
Value Function Loss: 0.07831

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.47614
Value Function Update Magnitude: 0.83581

Collected Steps per Second: 22,514.28070
Overall Steps per Second: 10,644.15251

Timestep Collection Time: 2.22197
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.69986

Cumulative Model Updates: 91,174
Cumulative Timesteps: 760,396,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,450.73697
Policy Entropy: 3.63827
Value Function Loss: 0.07746

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.43998
Value Function Update Magnitude: 0.80327

Collected Steps per Second: 23,103.92515
Overall Steps per Second: 10,824.94938

Timestep Collection Time: 2.16422
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.61914

Cumulative Model Updates: 91,180
Cumulative Timesteps: 760,446,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 760446016...
Checkpoint 760446016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,944.37636
Policy Entropy: 3.63702
Value Function Loss: 0.07550

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.47049
Value Function Update Magnitude: 0.70735

Collected Steps per Second: 22,649.98789
Overall Steps per Second: 10,627.66058

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.70565

Cumulative Model Updates: 91,186
Cumulative Timesteps: 760,496,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.01997
Policy Entropy: 3.65611
Value Function Loss: 0.07672

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.51240
Value Function Update Magnitude: 0.64962

Collected Steps per Second: 23,177.02459
Overall Steps per Second: 10,998.97020

Timestep Collection Time: 2.15774
Timestep Consumption Time: 2.38905
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.54679

Cumulative Model Updates: 91,192
Cumulative Timesteps: 760,546,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 760546036...
Checkpoint 760546036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,969.40464
Policy Entropy: 3.65771
Value Function Loss: 0.07591

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.47718
Value Function Update Magnitude: 0.74167

Collected Steps per Second: 22,793.24919
Overall Steps per Second: 10,644.51873

Timestep Collection Time: 2.19390
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.69782

Cumulative Model Updates: 91,198
Cumulative Timesteps: 760,596,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,806.55881
Policy Entropy: 3.66760
Value Function Loss: 0.07069

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.47363
Value Function Update Magnitude: 0.73835

Collected Steps per Second: 23,235.14193
Overall Steps per Second: 10,862.32198

Timestep Collection Time: 2.15312
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.60565

Cumulative Model Updates: 91,204
Cumulative Timesteps: 760,646,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 760646070...
Checkpoint 760646070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.16674
Policy Entropy: 3.67222
Value Function Loss: 0.06524

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.46280
Value Function Update Magnitude: 0.74689

Collected Steps per Second: 22,860.46376
Overall Steps per Second: 10,680.88369

Timestep Collection Time: 2.18736
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.68164

Cumulative Model Updates: 91,210
Cumulative Timesteps: 760,696,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.84487
Policy Entropy: 3.67785
Value Function Loss: 0.05861

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.75216

Collected Steps per Second: 22,320.54596
Overall Steps per Second: 10,515.60173

Timestep Collection Time: 2.24072
Timestep Consumption Time: 2.51546
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.75617

Cumulative Model Updates: 91,216
Cumulative Timesteps: 760,746,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 760746088...
Checkpoint 760746088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,346.44654
Policy Entropy: 3.66291
Value Function Loss: 0.05666

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.78557

Collected Steps per Second: 22,021.48612
Overall Steps per Second: 10,535.79034

Timestep Collection Time: 2.27096
Timestep Consumption Time: 2.47571
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.74668

Cumulative Model Updates: 91,222
Cumulative Timesteps: 760,796,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.47323
Policy Entropy: 3.66849
Value Function Loss: 0.05444

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.52779
Value Function Update Magnitude: 0.75999

Collected Steps per Second: 22,663.20330
Overall Steps per Second: 10,652.81592

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.69416

Cumulative Model Updates: 91,228
Cumulative Timesteps: 760,846,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 760846104...
Checkpoint 760846104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,362.93917
Policy Entropy: 3.67286
Value Function Loss: 0.05404

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.50077
Value Function Update Magnitude: 0.76859

Collected Steps per Second: 22,518.21926
Overall Steps per Second: 10,638.13138

Timestep Collection Time: 2.22176
Timestep Consumption Time: 2.48114
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.70289

Cumulative Model Updates: 91,234
Cumulative Timesteps: 760,896,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,687.30490
Policy Entropy: 3.68920
Value Function Loss: 0.05330

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.58858
Value Function Update Magnitude: 0.75186

Collected Steps per Second: 22,607.67698
Overall Steps per Second: 10,773.93576

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.64250

Cumulative Model Updates: 91,240
Cumulative Timesteps: 760,946,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 760946152...
Checkpoint 760946152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.79453
Policy Entropy: 3.69457
Value Function Loss: 0.05401

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.69443
Value Function Update Magnitude: 0.72858

Collected Steps per Second: 22,523.35728
Overall Steps per Second: 10,589.04400

Timestep Collection Time: 2.22054
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72318

Cumulative Model Updates: 91,246
Cumulative Timesteps: 760,996,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,611.05103
Policy Entropy: 3.70085
Value Function Loss: 0.05220

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.71169
Value Function Update Magnitude: 0.72265

Collected Steps per Second: 23,198.55262
Overall Steps per Second: 10,867.70192

Timestep Collection Time: 2.15617
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.60263

Cumulative Model Updates: 91,252
Cumulative Timesteps: 761,046,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 761046186...
Checkpoint 761046186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.14431
Policy Entropy: 3.70168
Value Function Loss: 0.05273

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.70337
Value Function Update Magnitude: 0.71921

Collected Steps per Second: 22,586.90484
Overall Steps per Second: 10,655.17613

Timestep Collection Time: 2.21376
Timestep Consumption Time: 2.47898
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.69274

Cumulative Model Updates: 91,258
Cumulative Timesteps: 761,096,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,639.78094
Policy Entropy: 3.70033
Value Function Loss: 0.05237

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11049
Policy Update Magnitude: 0.58297
Value Function Update Magnitude: 0.72840

Collected Steps per Second: 22,884.24808
Overall Steps per Second: 10,883.72495

Timestep Collection Time: 2.18535
Timestep Consumption Time: 2.40959
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59493

Cumulative Model Updates: 91,264
Cumulative Timesteps: 761,146,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 761146198...
Checkpoint 761146198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,192.99903
Policy Entropy: 3.69015
Value Function Loss: 0.05243

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.49604
Value Function Update Magnitude: 0.73939

Collected Steps per Second: 22,881.45270
Overall Steps per Second: 10,688.41962

Timestep Collection Time: 2.18588
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.67946

Cumulative Model Updates: 91,270
Cumulative Timesteps: 761,196,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,110.89854
Policy Entropy: 3.68406
Value Function Loss: 0.05199

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.51973
Value Function Update Magnitude: 0.74583

Collected Steps per Second: 23,096.44526
Overall Steps per Second: 10,843.29756

Timestep Collection Time: 2.16484
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.61114

Cumulative Model Updates: 91,276
Cumulative Timesteps: 761,246,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 761246214...
Checkpoint 761246214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,960.70652
Policy Entropy: 3.68656
Value Function Loss: 0.05562

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.48240
Value Function Update Magnitude: 0.74315

Collected Steps per Second: 22,164.98788
Overall Steps per Second: 10,652.24241

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.69535

Cumulative Model Updates: 91,282
Cumulative Timesteps: 761,296,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,591.26320
Policy Entropy: 3.68751
Value Function Loss: 0.05603

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.46588
Value Function Update Magnitude: 0.74870

Collected Steps per Second: 22,430.81653
Overall Steps per Second: 10,576.83908

Timestep Collection Time: 2.22988
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.72901

Cumulative Model Updates: 91,288
Cumulative Timesteps: 761,346,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 761346248...
Checkpoint 761346248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,487.08588
Policy Entropy: 3.68705
Value Function Loss: 0.05836

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.50874
Value Function Update Magnitude: 0.75747

Collected Steps per Second: 22,388.36299
Overall Steps per Second: 10,574.77250

Timestep Collection Time: 2.23420
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.73013

Cumulative Model Updates: 91,294
Cumulative Timesteps: 761,396,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,371.76542
Policy Entropy: 3.68437
Value Function Loss: 0.05581

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.16801
Policy Update Magnitude: 0.43040
Value Function Update Magnitude: 0.73987

Collected Steps per Second: 22,532.32711
Overall Steps per Second: 10,629.33206

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.70641

Cumulative Model Updates: 91,300
Cumulative Timesteps: 761,446,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 761446294...
Checkpoint 761446294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.16841
Policy Entropy: 3.69054
Value Function Loss: 0.05664

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.35753
Value Function Update Magnitude: 0.72098

Collected Steps per Second: 22,855.07962
Overall Steps per Second: 10,823.10415

Timestep Collection Time: 2.18796
Timestep Consumption Time: 2.43234
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.62030

Cumulative Model Updates: 91,306
Cumulative Timesteps: 761,496,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.59775
Policy Entropy: 3.68171
Value Function Loss: 0.05513

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.43691
Value Function Update Magnitude: 0.70575

Collected Steps per Second: 22,709.34820
Overall Steps per Second: 10,643.77824

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.70228

Cumulative Model Updates: 91,312
Cumulative Timesteps: 761,546,350

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 761546350...
Checkpoint 761546350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.32480
Policy Entropy: 3.67914
Value Function Loss: 0.05431

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.69588

Collected Steps per Second: 22,814.88170
Overall Steps per Second: 10,920.99186

Timestep Collection Time: 2.19252
Timestep Consumption Time: 2.38784
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.58035

Cumulative Model Updates: 91,318
Cumulative Timesteps: 761,596,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,366.26063
Policy Entropy: 3.67078
Value Function Loss: 0.05326

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.61971
Value Function Update Magnitude: 0.69418

Collected Steps per Second: 22,984.57479
Overall Steps per Second: 10,751.17378

Timestep Collection Time: 2.17607
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.65214

Cumulative Model Updates: 91,324
Cumulative Timesteps: 761,646,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 761646388...
Checkpoint 761646388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,512.57040
Policy Entropy: 3.68145
Value Function Loss: 0.05378

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.61549
Value Function Update Magnitude: 0.69251

Collected Steps per Second: 22,674.63672
Overall Steps per Second: 10,826.43488

Timestep Collection Time: 2.20731
Timestep Consumption Time: 2.41563
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62294

Cumulative Model Updates: 91,330
Cumulative Timesteps: 761,696,438

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.08246
Policy Entropy: 3.68475
Value Function Loss: 0.05537

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.49594
Value Function Update Magnitude: 0.66487

Collected Steps per Second: 22,736.28560
Overall Steps per Second: 10,665.22848

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68813

Cumulative Model Updates: 91,336
Cumulative Timesteps: 761,746,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 761746438...
Checkpoint 761746438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.64758
Policy Entropy: 3.68733
Value Function Loss: 0.05867

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.50904
Value Function Update Magnitude: 0.56841

Collected Steps per Second: 22,232.66059
Overall Steps per Second: 10,473.46425

Timestep Collection Time: 2.24939
Timestep Consumption Time: 2.52553
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.77492

Cumulative Model Updates: 91,342
Cumulative Timesteps: 761,796,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.73161
Policy Entropy: 3.69569
Value Function Loss: 0.05925

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.53110
Value Function Update Magnitude: 0.56090

Collected Steps per Second: 22,355.69166
Overall Steps per Second: 10,540.34021

Timestep Collection Time: 2.23657
Timestep Consumption Time: 2.50711
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.74368

Cumulative Model Updates: 91,348
Cumulative Timesteps: 761,846,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 761846448...
Checkpoint 761846448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,120.81344
Policy Entropy: 3.68763
Value Function Loss: 0.06013

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.51126
Value Function Update Magnitude: 0.52337

Collected Steps per Second: 22,384.24619
Overall Steps per Second: 10,532.34826

Timestep Collection Time: 2.23479
Timestep Consumption Time: 2.51477
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.74956

Cumulative Model Updates: 91,354
Cumulative Timesteps: 761,896,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,657.19264
Policy Entropy: 3.69609
Value Function Loss: 0.06040

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.44523
Value Function Update Magnitude: 0.48522

Collected Steps per Second: 22,661.52133
Overall Steps per Second: 10,654.25674

Timestep Collection Time: 2.20718
Timestep Consumption Time: 2.48747
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.69465

Cumulative Model Updates: 91,360
Cumulative Timesteps: 761,946,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 761946490...
Checkpoint 761946490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,602.33014
Policy Entropy: 3.70426
Value Function Loss: 0.06299

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.41239
Value Function Update Magnitude: 0.46254

Collected Steps per Second: 22,754.99762
Overall Steps per Second: 10,818.23387

Timestep Collection Time: 2.19732
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.62183

Cumulative Model Updates: 91,366
Cumulative Timesteps: 761,996,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.62398
Policy Entropy: 3.70701
Value Function Loss: 0.06362

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.52148
Value Function Update Magnitude: 0.46258

Collected Steps per Second: 22,702.84962
Overall Steps per Second: 10,610.14622

Timestep Collection Time: 2.20237
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.71247

Cumulative Model Updates: 91,372
Cumulative Timesteps: 762,046,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 762046490...
Checkpoint 762046490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.71075
Policy Entropy: 3.70097
Value Function Loss: 0.06377

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.53471
Value Function Update Magnitude: 0.48495

Collected Steps per Second: 22,361.07526
Overall Steps per Second: 10,608.44089

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.71492

Cumulative Model Updates: 91,378
Cumulative Timesteps: 762,096,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.24065
Policy Entropy: 3.69261
Value Function Loss: 0.06346

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.56923
Value Function Update Magnitude: 0.47487

Collected Steps per Second: 22,984.96807
Overall Steps per Second: 10,842.32432

Timestep Collection Time: 2.17560
Timestep Consumption Time: 2.43651
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61211

Cumulative Model Updates: 91,384
Cumulative Timesteps: 762,146,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 762146514...
Checkpoint 762146514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,820.48456
Policy Entropy: 3.68891
Value Function Loss: 0.06277

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.16547
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.50216

Collected Steps per Second: 22,774.79733
Overall Steps per Second: 10,700.02490

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.67382

Cumulative Model Updates: 91,390
Cumulative Timesteps: 762,196,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,165.42721
Policy Entropy: 3.68510
Value Function Loss: 0.06600

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.49005
Value Function Update Magnitude: 0.54435

Collected Steps per Second: 22,998.54561
Overall Steps per Second: 10,838.73081

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.44011
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61512

Cumulative Model Updates: 91,396
Cumulative Timesteps: 762,246,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 762246546...
Checkpoint 762246546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,726.13196
Policy Entropy: 3.68588
Value Function Loss: 0.06496

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.16320
Policy Update Magnitude: 0.49660
Value Function Update Magnitude: 0.56921

Collected Steps per Second: 22,609.58941
Overall Steps per Second: 10,670.05061

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.68976

Cumulative Model Updates: 91,402
Cumulative Timesteps: 762,296,586

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.15948
Policy Entropy: 3.69088
Value Function Loss: 0.06538

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.44165
Value Function Update Magnitude: 0.55984

Collected Steps per Second: 22,584.92573
Overall Steps per Second: 10,638.71862

Timestep Collection Time: 2.21413
Timestep Consumption Time: 2.48625
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.70038

Cumulative Model Updates: 91,408
Cumulative Timesteps: 762,346,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 762346592...
Checkpoint 762346592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,941.73093
Policy Entropy: 3.71036
Value Function Loss: 0.06493

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07086
Policy Update Magnitude: 0.52419
Value Function Update Magnitude: 0.63540

Collected Steps per Second: 22,355.18907
Overall Steps per Second: 10,583.00787

Timestep Collection Time: 2.23733
Timestep Consumption Time: 2.48873
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.72607

Cumulative Model Updates: 91,414
Cumulative Timesteps: 762,396,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.51432
Policy Entropy: 3.71493
Value Function Loss: 0.06443

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06441
Policy Update Magnitude: 0.65050
Value Function Update Magnitude: 0.71692

Collected Steps per Second: 22,639.45527
Overall Steps per Second: 10,757.20496

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.65028

Cumulative Model Updates: 91,420
Cumulative Timesteps: 762,446,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 762446632...
Checkpoint 762446632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,568.68330
Policy Entropy: 3.70470
Value Function Loss: 0.06351

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.66441
Value Function Update Magnitude: 0.73167

Collected Steps per Second: 22,239.25118
Overall Steps per Second: 10,647.34875

Timestep Collection Time: 2.24846
Timestep Consumption Time: 2.44792
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.69638

Cumulative Model Updates: 91,426
Cumulative Timesteps: 762,496,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,921.29292
Policy Entropy: 3.71414
Value Function Loss: 0.06359

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.58857
Value Function Update Magnitude: 0.73938

Collected Steps per Second: 22,918.91046
Overall Steps per Second: 10,866.87668

Timestep Collection Time: 2.18204
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60206

Cumulative Model Updates: 91,432
Cumulative Timesteps: 762,546,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 762546646...
Checkpoint 762546646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.09584
Policy Entropy: 3.72263
Value Function Loss: 0.06488

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.52206
Value Function Update Magnitude: 0.74381

Collected Steps per Second: 22,834.63736
Overall Steps per Second: 10,715.16724

Timestep Collection Time: 2.19009
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.66722

Cumulative Model Updates: 91,438
Cumulative Timesteps: 762,596,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,595.94548
Policy Entropy: 3.73475
Value Function Loss: 0.06694

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.50107
Value Function Update Magnitude: 0.76736

Collected Steps per Second: 22,837.61940
Overall Steps per Second: 10,765.69951

Timestep Collection Time: 2.19060
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.64698

Cumulative Model Updates: 91,444
Cumulative Timesteps: 762,646,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 762646684...
Checkpoint 762646684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,214.64843
Policy Entropy: 3.73444
Value Function Loss: 0.06681

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.76307

Collected Steps per Second: 23,002.26459
Overall Steps per Second: 10,756.36422

Timestep Collection Time: 2.17457
Timestep Consumption Time: 2.47570
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.65027

Cumulative Model Updates: 91,450
Cumulative Timesteps: 762,696,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,334.21107
Policy Entropy: 3.73239
Value Function Loss: 0.06697

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06880
Policy Update Magnitude: 0.60443
Value Function Update Magnitude: 0.79263

Collected Steps per Second: 22,901.89152
Overall Steps per Second: 10,852.49585

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.42508
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60926

Cumulative Model Updates: 91,456
Cumulative Timesteps: 762,746,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 762746726...
Checkpoint 762746726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.82668
Policy Entropy: 3.72686
Value Function Loss: 0.06724

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.66736
Value Function Update Magnitude: 0.81280

Collected Steps per Second: 22,797.81030
Overall Steps per Second: 10,728.50469

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.66123

Cumulative Model Updates: 91,462
Cumulative Timesteps: 762,796,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.99384
Policy Entropy: 3.71097
Value Function Loss: 0.06813

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.61159
Value Function Update Magnitude: 0.81567

Collected Steps per Second: 22,646.12942
Overall Steps per Second: 10,785.45559

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.63810

Cumulative Model Updates: 91,468
Cumulative Timesteps: 762,846,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 762846758...
Checkpoint 762846758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,456.32060
Policy Entropy: 3.71110
Value Function Loss: 0.06948

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 0.58199
Value Function Update Magnitude: 0.79139

Collected Steps per Second: 22,409.09006
Overall Steps per Second: 10,772.98237

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.41135
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.64384

Cumulative Model Updates: 91,474
Cumulative Timesteps: 762,896,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,119.11277
Policy Entropy: 3.70374
Value Function Loss: 0.07085

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.79518

Collected Steps per Second: 22,664.70696
Overall Steps per Second: 10,810.28694

Timestep Collection Time: 2.20775
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.62874

Cumulative Model Updates: 91,480
Cumulative Timesteps: 762,946,824

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 762946824...
Checkpoint 762946824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,865.11704
Policy Entropy: 3.71016
Value Function Loss: 0.07096

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.80739

Collected Steps per Second: 22,450.37014
Overall Steps per Second: 10,752.76377

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.42332
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.65090

Cumulative Model Updates: 91,486
Cumulative Timesteps: 762,996,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,036.69630
Policy Entropy: 3.69513
Value Function Loss: 0.07087

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07137
Policy Update Magnitude: 0.63240
Value Function Update Magnitude: 0.82016

Collected Steps per Second: 22,402.65571
Overall Steps per Second: 10,552.34251

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.50701
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.73942

Cumulative Model Updates: 91,492
Cumulative Timesteps: 763,046,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 763046846...
Checkpoint 763046846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,027.45274
Policy Entropy: 3.69974
Value Function Loss: 0.07060

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.70397
Value Function Update Magnitude: 0.83049

Collected Steps per Second: 22,576.00626
Overall Steps per Second: 10,533.83549

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.53288
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.74851

Cumulative Model Updates: 91,498
Cumulative Timesteps: 763,096,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,873.76203
Policy Entropy: 3.70009
Value Function Loss: 0.07328

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.65395
Value Function Update Magnitude: 0.85208

Collected Steps per Second: 22,777.59448
Overall Steps per Second: 10,781.24714

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.64046

Cumulative Model Updates: 91,504
Cumulative Timesteps: 763,146,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 763146896...
Checkpoint 763146896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,209.04512
Policy Entropy: 3.69808
Value Function Loss: 0.07530

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.61666
Value Function Update Magnitude: 0.86984

Collected Steps per Second: 22,846.28943
Overall Steps per Second: 10,735.01787

Timestep Collection Time: 2.18854
Timestep Consumption Time: 2.46911
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.65765

Cumulative Model Updates: 91,510
Cumulative Timesteps: 763,196,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.61877
Policy Entropy: 3.67726
Value Function Loss: 0.07567

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.66204
Value Function Update Magnitude: 0.86181

Collected Steps per Second: 22,987.72277
Overall Steps per Second: 10,818.79843

Timestep Collection Time: 2.17560
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.62269

Cumulative Model Updates: 91,516
Cumulative Timesteps: 763,246,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 763246908...
Checkpoint 763246908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,681.68056
Policy Entropy: 3.68471
Value Function Loss: 0.07398

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.67965
Value Function Update Magnitude: 0.83267

Collected Steps per Second: 22,605.95882
Overall Steps per Second: 10,704.65828

Timestep Collection Time: 2.21278
Timestep Consumption Time: 2.46014
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.67292

Cumulative Model Updates: 91,522
Cumulative Timesteps: 763,296,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,848.44677
Policy Entropy: 3.68921
Value Function Loss: 0.07204

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.59567
Value Function Update Magnitude: 0.79986

Collected Steps per Second: 22,626.88458
Overall Steps per Second: 10,662.76737

Timestep Collection Time: 2.21056
Timestep Consumption Time: 2.48035
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69090

Cumulative Model Updates: 91,528
Cumulative Timesteps: 763,346,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 763346948...
Checkpoint 763346948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,761.64033
Policy Entropy: 3.69556
Value Function Loss: 0.07145

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.60544
Value Function Update Magnitude: 0.79947

Collected Steps per Second: 22,789.19958
Overall Steps per Second: 10,841.96986

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61392

Cumulative Model Updates: 91,534
Cumulative Timesteps: 763,396,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,417.05313
Policy Entropy: 3.69876
Value Function Loss: 0.07229

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.69544
Value Function Update Magnitude: 0.83268

Collected Steps per Second: 22,372.92669
Overall Steps per Second: 10,519.34055

Timestep Collection Time: 2.23565
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.75486

Cumulative Model Updates: 91,540
Cumulative Timesteps: 763,446,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 763446990...
Checkpoint 763446990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,997.77003
Policy Entropy: 3.68966
Value Function Loss: 0.07476

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.65904
Value Function Update Magnitude: 0.84757

Collected Steps per Second: 22,430.56353
Overall Steps per Second: 10,654.75279

Timestep Collection Time: 2.23053
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.69574

Cumulative Model Updates: 91,546
Cumulative Timesteps: 763,497,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,515.14427
Policy Entropy: 3.67805
Value Function Loss: 0.07534

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.60229
Value Function Update Magnitude: 0.84099

Collected Steps per Second: 22,553.05670
Overall Steps per Second: 10,641.36284

Timestep Collection Time: 2.21779
Timestep Consumption Time: 2.48255
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70034

Cumulative Model Updates: 91,552
Cumulative Timesteps: 763,547,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 763547040...
Checkpoint 763547040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,500.73379
Policy Entropy: 3.64719
Value Function Loss: 0.07785

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.59261
Value Function Update Magnitude: 0.80959

Collected Steps per Second: 22,351.43456
Overall Steps per Second: 10,590.77588

Timestep Collection Time: 2.23735
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.72184

Cumulative Model Updates: 91,558
Cumulative Timesteps: 763,597,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.57109
Policy Entropy: 3.65494
Value Function Loss: 0.08004

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.65570
Value Function Update Magnitude: 0.67446

Collected Steps per Second: 22,970.99845
Overall Steps per Second: 10,793.10510

Timestep Collection Time: 2.17788
Timestep Consumption Time: 2.45730
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.63518

Cumulative Model Updates: 91,564
Cumulative Timesteps: 763,647,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 763647076...
Checkpoint 763647076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,431.31546
Policy Entropy: 3.65084
Value Function Loss: 0.07931

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.64621
Value Function Update Magnitude: 0.62328

Collected Steps per Second: 22,090.03440
Overall Steps per Second: 10,651.35450

Timestep Collection Time: 2.26392
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.69518

Cumulative Model Updates: 91,570
Cumulative Timesteps: 763,697,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,445.18873
Policy Entropy: 3.64842
Value Function Loss: 0.07840

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.54089
Value Function Update Magnitude: 0.68902

Collected Steps per Second: 22,894.93104
Overall Steps per Second: 10,842.88974

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61224

Cumulative Model Updates: 91,576
Cumulative Timesteps: 763,747,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 763747096...
Checkpoint 763747096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,721.37968
Policy Entropy: 3.65322
Value Function Loss: 0.07783

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.69478

Collected Steps per Second: 22,832.26230
Overall Steps per Second: 10,653.62950

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.50425
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.69493

Cumulative Model Updates: 91,582
Cumulative Timesteps: 763,797,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.01266
Policy Entropy: 3.64083
Value Function Loss: 0.08326

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.68576

Collected Steps per Second: 23,100.64684
Overall Steps per Second: 10,888.69532

Timestep Collection Time: 2.16505
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59320

Cumulative Model Updates: 91,588
Cumulative Timesteps: 763,847,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 763847128...
Checkpoint 763847128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,764.71847
Policy Entropy: 3.63881
Value Function Loss: 0.08733

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10949
Policy Update Magnitude: 0.57671
Value Function Update Magnitude: 0.67893

Collected Steps per Second: 22,485.18066
Overall Steps per Second: 10,660.53343

Timestep Collection Time: 2.22458
Timestep Consumption Time: 2.46750
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.69207

Cumulative Model Updates: 91,594
Cumulative Timesteps: 763,897,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,515.50607
Policy Entropy: 3.62314
Value Function Loss: 0.08869

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.69231

Collected Steps per Second: 22,419.73618
Overall Steps per Second: 10,576.59995

Timestep Collection Time: 2.23152
Timestep Consumption Time: 2.49874
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.73025

Cumulative Model Updates: 91,600
Cumulative Timesteps: 763,947,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 763947178...
Checkpoint 763947178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,516.59521
Policy Entropy: 3.62717
Value Function Loss: 0.08797

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.70280

Collected Steps per Second: 21,207.65382
Overall Steps per Second: 10,269.49602

Timestep Collection Time: 2.35783
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.86918

Cumulative Model Updates: 91,606
Cumulative Timesteps: 763,997,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.06610
Policy Entropy: 3.64176
Value Function Loss: 0.08314

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.59509
Value Function Update Magnitude: 0.77694

Collected Steps per Second: 22,123.41245
Overall Steps per Second: 10,713.76853

Timestep Collection Time: 2.26131
Timestep Consumption Time: 2.40819
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.66951

Cumulative Model Updates: 91,612
Cumulative Timesteps: 764,047,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 764047210...
Checkpoint 764047210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,114.75521
Policy Entropy: 3.65541
Value Function Loss: 0.08346

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.61919
Value Function Update Magnitude: 0.75257

Collected Steps per Second: 22,214.48566
Overall Steps per Second: 10,598.72651

Timestep Collection Time: 2.25078
Timestep Consumption Time: 2.46676
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.71755

Cumulative Model Updates: 91,618
Cumulative Timesteps: 764,097,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,418.01818
Policy Entropy: 3.64533
Value Function Loss: 0.08295

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.72059
Value Function Update Magnitude: 0.68435

Collected Steps per Second: 22,336.59925
Overall Steps per Second: 10,866.14169

Timestep Collection Time: 2.23911
Timestep Consumption Time: 2.36363
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60274

Cumulative Model Updates: 91,624
Cumulative Timesteps: 764,147,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 764147224...
Checkpoint 764147224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,521.48393
Policy Entropy: 3.63028
Value Function Loss: 0.08186

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.65695
Value Function Update Magnitude: 0.69334

Collected Steps per Second: 22,137.03627
Overall Steps per Second: 10,744.04430

Timestep Collection Time: 2.25911
Timestep Consumption Time: 2.39556
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.65467

Cumulative Model Updates: 91,630
Cumulative Timesteps: 764,197,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,703.95724
Policy Entropy: 3.63477
Value Function Loss: 0.08192

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.56812
Value Function Update Magnitude: 0.65032

Collected Steps per Second: 22,320.32555
Overall Steps per Second: 10,866.64882

Timestep Collection Time: 2.24020
Timestep Consumption Time: 2.36122
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.60142

Cumulative Model Updates: 91,636
Cumulative Timesteps: 764,247,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 764247236...
Checkpoint 764247236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,713.18563
Policy Entropy: 3.64032
Value Function Loss: 0.08323

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.63230
Value Function Update Magnitude: 0.67495

Collected Steps per Second: 22,084.00098
Overall Steps per Second: 10,636.36629

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70236

Cumulative Model Updates: 91,642
Cumulative Timesteps: 764,297,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,122.90740
Policy Entropy: 3.65630
Value Function Loss: 0.08286

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.68500
Value Function Update Magnitude: 0.63778

Collected Steps per Second: 22,367.30930
Overall Steps per Second: 10,628.26062

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.70651

Cumulative Model Updates: 91,648
Cumulative Timesteps: 764,347,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 764347274...
Checkpoint 764347274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,809.43697
Policy Entropy: 3.66678
Value Function Loss: 0.08182

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.61585
Value Function Update Magnitude: 0.62392

Collected Steps per Second: 22,543.83201
Overall Steps per Second: 10,719.65209

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.44672
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.66489

Cumulative Model Updates: 91,654
Cumulative Timesteps: 764,397,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,530.01770
Policy Entropy: 3.66973
Value Function Loss: 0.07918

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.53756
Value Function Update Magnitude: 0.62186

Collected Steps per Second: 22,395.73946
Overall Steps per Second: 10,681.82845

Timestep Collection Time: 2.23266
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.68103

Cumulative Model Updates: 91,660
Cumulative Timesteps: 764,447,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 764447282...
Checkpoint 764447282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,493.17347
Policy Entropy: 3.67008
Value Function Loss: 0.07701

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.63270

Collected Steps per Second: 22,291.75170
Overall Steps per Second: 10,637.59742

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.70520

Cumulative Model Updates: 91,666
Cumulative Timesteps: 764,497,334

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.04366
Policy Entropy: 3.67085
Value Function Loss: 0.07639

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.54138
Value Function Update Magnitude: 0.71001

Collected Steps per Second: 22,604.28824
Overall Steps per Second: 10,819.49170

Timestep Collection Time: 2.21268
Timestep Consumption Time: 2.41009
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62277

Cumulative Model Updates: 91,672
Cumulative Timesteps: 764,547,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 764547350...
Checkpoint 764547350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,522.29266
Policy Entropy: 3.65536
Value Function Loss: 0.07784

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.48513
Value Function Update Magnitude: 0.70588

Collected Steps per Second: 22,753.87810
Overall Steps per Second: 10,738.56425

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.45908
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.65686

Cumulative Model Updates: 91,678
Cumulative Timesteps: 764,597,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,146.05756
Policy Entropy: 3.65314
Value Function Loss: 0.08294

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.45069
Value Function Update Magnitude: 0.66606

Collected Steps per Second: 22,395.99430
Overall Steps per Second: 10,565.19817

Timestep Collection Time: 2.23290
Timestep Consumption Time: 2.50038
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.73328

Cumulative Model Updates: 91,684
Cumulative Timesteps: 764,647,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 764647366...
Checkpoint 764647366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,260.74263
Policy Entropy: 3.64941
Value Function Loss: 0.08372

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.45729
Value Function Update Magnitude: 0.63573

Collected Steps per Second: 22,725.87863
Overall Steps per Second: 10,655.03906

Timestep Collection Time: 2.20084
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.69412

Cumulative Model Updates: 91,690
Cumulative Timesteps: 764,697,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,351.31834
Policy Entropy: 3.66376
Value Function Loss: 0.07793

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.52161
Value Function Update Magnitude: 0.70766

Collected Steps per Second: 22,883.61769
Overall Steps per Second: 10,788.65728

Timestep Collection Time: 2.18549
Timestep Consumption Time: 2.45012
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.63561

Cumulative Model Updates: 91,696
Cumulative Timesteps: 764,747,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 764747394...
Checkpoint 764747394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,105.96802
Policy Entropy: 3.66849
Value Function Loss: 0.07356

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.73668

Collected Steps per Second: 22,968.80561
Overall Steps per Second: 10,704.53791

Timestep Collection Time: 2.17748
Timestep Consumption Time: 2.49475
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.67222

Cumulative Model Updates: 91,702
Cumulative Timesteps: 764,797,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.00276
Policy Entropy: 3.68637
Value Function Loss: 0.07312

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.56675
Value Function Update Magnitude: 0.82385

Collected Steps per Second: 23,107.64030
Overall Steps per Second: 10,870.92363

Timestep Collection Time: 2.16413
Timestep Consumption Time: 2.43603
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.60016

Cumulative Model Updates: 91,708
Cumulative Timesteps: 764,847,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 764847416...
Checkpoint 764847416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,791.48688
Policy Entropy: 3.67724
Value Function Loss: 0.07382

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.61710
Value Function Update Magnitude: 0.80206

Collected Steps per Second: 22,753.51262
Overall Steps per Second: 10,613.91694

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.51384
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.71174

Cumulative Model Updates: 91,714
Cumulative Timesteps: 764,897,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.06118
Policy Entropy: 3.69394
Value Function Loss: 0.07376

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.66999
Value Function Update Magnitude: 0.75042

Collected Steps per Second: 22,328.15458
Overall Steps per Second: 10,655.05174

Timestep Collection Time: 2.23977
Timestep Consumption Time: 2.45378
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.69355

Cumulative Model Updates: 91,720
Cumulative Timesteps: 764,947,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 764947436...
Checkpoint 764947436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.17554
Policy Entropy: 3.68604
Value Function Loss: 0.07384

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.63867
Value Function Update Magnitude: 0.68554

Collected Steps per Second: 22,684.00108
Overall Steps per Second: 10,847.20642

Timestep Collection Time: 2.20525
Timestep Consumption Time: 2.40644
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.61169

Cumulative Model Updates: 91,726
Cumulative Timesteps: 764,997,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,089.96978
Policy Entropy: 3.68725
Value Function Loss: 0.07264

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.60981
Value Function Update Magnitude: 0.69368

Collected Steps per Second: 22,155.85553
Overall Steps per Second: 10,487.88408

Timestep Collection Time: 2.25809
Timestep Consumption Time: 2.51217
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.77027

Cumulative Model Updates: 91,732
Cumulative Timesteps: 765,047,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 765047490...
Checkpoint 765047490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,922.11547
Policy Entropy: 3.68636
Value Function Loss: 0.07408

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.75512

Collected Steps per Second: 22,660.68243
Overall Steps per Second: 10,635.36094

Timestep Collection Time: 2.20664
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.70167

Cumulative Model Updates: 91,738
Cumulative Timesteps: 765,097,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,560.99642
Policy Entropy: 3.69028
Value Function Loss: 0.07464

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.48324
Value Function Update Magnitude: 0.73626

Collected Steps per Second: 22,978.96675
Overall Steps per Second: 10,864.56730

Timestep Collection Time: 2.17643
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.60322

Cumulative Model Updates: 91,744
Cumulative Timesteps: 765,147,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 765147506...
Checkpoint 765147506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776.07128
Policy Entropy: 3.69908
Value Function Loss: 0.07504

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.48642
Value Function Update Magnitude: 0.73276

Collected Steps per Second: 22,695.47708
Overall Steps per Second: 10,576.40431

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.52473
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.72807

Cumulative Model Updates: 91,750
Cumulative Timesteps: 765,197,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,029.03616
Policy Entropy: 3.70530
Value Function Loss: 0.07018

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.50962
Value Function Update Magnitude: 0.80079

Collected Steps per Second: 23,071.27336
Overall Steps per Second: 10,934.44609

Timestep Collection Time: 2.16893
Timestep Consumption Time: 2.40743
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.57636

Cumulative Model Updates: 91,756
Cumulative Timesteps: 765,247,552

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 765247552...
Checkpoint 765247552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.19444
Policy Entropy: 3.71023
Value Function Loss: 0.06729

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.51940
Value Function Update Magnitude: 0.85366

Collected Steps per Second: 22,769.43912
Overall Steps per Second: 10,740.31684

Timestep Collection Time: 2.19628
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.65610

Cumulative Model Updates: 91,762
Cumulative Timesteps: 765,297,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,052.76187
Policy Entropy: 3.70413
Value Function Loss: 0.06188

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.50912
Value Function Update Magnitude: 0.81839

Collected Steps per Second: 23,060.11976
Overall Steps per Second: 10,850.65881

Timestep Collection Time: 2.16894
Timestep Consumption Time: 2.44055
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60949

Cumulative Model Updates: 91,768
Cumulative Timesteps: 765,347,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 765347576...
Checkpoint 765347576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,508.38387
Policy Entropy: 3.71155
Value Function Loss: 0.06110

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.50287
Value Function Update Magnitude: 0.78878

Collected Steps per Second: 22,456.08854
Overall Steps per Second: 10,680.09103

Timestep Collection Time: 2.22666
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.68180

Cumulative Model Updates: 91,774
Cumulative Timesteps: 765,397,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,765.09990
Policy Entropy: 3.71233
Value Function Loss: 0.05909

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.73472

Collected Steps per Second: 22,498.22642
Overall Steps per Second: 10,536.64395

Timestep Collection Time: 2.22249
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.74553

Cumulative Model Updates: 91,780
Cumulative Timesteps: 765,447,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 765447580...
Checkpoint 765447580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,949.01909
Policy Entropy: 3.70927
Value Function Loss: 0.05978

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.72670

Collected Steps per Second: 22,218.72196
Overall Steps per Second: 10,582.20921

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.72548

Cumulative Model Updates: 91,786
Cumulative Timesteps: 765,497,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.17081
Policy Entropy: 3.70547
Value Function Loss: 0.05789

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.55115
Value Function Update Magnitude: 0.76056

Collected Steps per Second: 22,591.48912
Overall Steps per Second: 10,627.26596

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.70714

Cumulative Model Updates: 91,792
Cumulative Timesteps: 765,547,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 765547610...
Checkpoint 765547610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.66622
Policy Entropy: 3.69306
Value Function Loss: 0.05444

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.52921
Value Function Update Magnitude: 0.75885

Collected Steps per Second: 22,187.33508
Overall Steps per Second: 10,492.77032

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.51315
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.76804

Cumulative Model Updates: 91,798
Cumulative Timesteps: 765,597,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,392.50572
Policy Entropy: 3.69748
Value Function Loss: 0.05303

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.53304
Value Function Update Magnitude: 0.71160

Collected Steps per Second: 22,888.62398
Overall Steps per Second: 10,726.66104

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.66222

Cumulative Model Updates: 91,804
Cumulative Timesteps: 765,647,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 765647650...
Checkpoint 765647650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,016.09889
Policy Entropy: 3.70312
Value Function Loss: 0.05107

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.50326
Value Function Update Magnitude: 0.67144

Collected Steps per Second: 22,791.47997
Overall Steps per Second: 10,820.88424

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.42699
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.62088

Cumulative Model Updates: 91,810
Cumulative Timesteps: 765,697,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.11083
Policy Entropy: 3.70967
Value Function Loss: 0.05207

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.64788

Collected Steps per Second: 23,082.35605
Overall Steps per Second: 10,875.83072

Timestep Collection Time: 2.16711
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.59937

Cumulative Model Updates: 91,816
Cumulative Timesteps: 765,747,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 765747674...
Checkpoint 765747674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,388.26451
Policy Entropy: 3.70912
Value Function Loss: 0.05200

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.61879
Value Function Update Magnitude: 0.63972

Collected Steps per Second: 22,901.19780
Overall Steps per Second: 10,681.89978

Timestep Collection Time: 2.18408
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.68250

Cumulative Model Updates: 91,822
Cumulative Timesteps: 765,797,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,614.85917
Policy Entropy: 3.71548
Value Function Loss: 0.05263

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.59186
Value Function Update Magnitude: 0.58878

Collected Steps per Second: 22,712.62780
Overall Steps per Second: 10,824.47016

Timestep Collection Time: 2.20151
Timestep Consumption Time: 2.41784
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.61935

Cumulative Model Updates: 91,828
Cumulative Timesteps: 765,847,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 765847694...
Checkpoint 765847694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,193.60429
Policy Entropy: 3.71086
Value Function Loss: 0.05418

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.59130
Value Function Update Magnitude: 0.63742

Collected Steps per Second: 22,466.12233
Overall Steps per Second: 10,652.84816

Timestep Collection Time: 2.22709
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.69677

Cumulative Model Updates: 91,834
Cumulative Timesteps: 765,897,728

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.12223
Policy Entropy: 3.71705
Value Function Loss: 0.05615

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06644
Policy Update Magnitude: 0.69334
Value Function Update Magnitude: 0.70119

Collected Steps per Second: 22,565.57867
Overall Steps per Second: 10,630.18362

Timestep Collection Time: 2.21594
Timestep Consumption Time: 2.48802
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.70396

Cumulative Model Updates: 91,840
Cumulative Timesteps: 765,947,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 765947732...
Checkpoint 765947732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.95424
Policy Entropy: 3.71300
Value Function Loss: 0.05813

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06774
Policy Update Magnitude: 0.74235
Value Function Update Magnitude: 0.74123

Collected Steps per Second: 22,765.55151
Overall Steps per Second: 10,815.93239

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.62336

Cumulative Model Updates: 91,846
Cumulative Timesteps: 765,997,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,070.08657
Policy Entropy: 3.70125
Value Function Loss: 0.06095

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.73656
Value Function Update Magnitude: 0.76067

Collected Steps per Second: 22,163.81353
Overall Steps per Second: 10,558.23596

Timestep Collection Time: 2.25674
Timestep Consumption Time: 2.48060
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.73734

Cumulative Model Updates: 91,852
Cumulative Timesteps: 766,047,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 766047756...
Checkpoint 766047756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,632.64332
Policy Entropy: 3.68854
Value Function Loss: 0.06305

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.75683
Value Function Update Magnitude: 0.76394

Collected Steps per Second: 22,316.85057
Overall Steps per Second: 10,610.51723

Timestep Collection Time: 2.24189
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.71532

Cumulative Model Updates: 91,858
Cumulative Timesteps: 766,097,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,242.47137
Policy Entropy: 3.67749
Value Function Loss: 0.06366

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.74795
Value Function Update Magnitude: 0.75776

Collected Steps per Second: 22,744.86956
Overall Steps per Second: 10,548.05114

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.54273
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.74173

Cumulative Model Updates: 91,864
Cumulative Timesteps: 766,147,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 766147804...
Checkpoint 766147804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.77805
Policy Entropy: 3.68891
Value Function Loss: 0.06235

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.63938
Value Function Update Magnitude: 0.75566

Collected Steps per Second: 22,871.21544
Overall Steps per Second: 10,670.68657

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.68761

Cumulative Model Updates: 91,870
Cumulative Timesteps: 766,197,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,886.41028
Policy Entropy: 3.69290
Value Function Loss: 0.06185

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.76392

Collected Steps per Second: 22,319.27050
Overall Steps per Second: 10,553.54555

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.74021

Cumulative Model Updates: 91,876
Cumulative Timesteps: 766,247,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 766247850...
Checkpoint 766247850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.58014
Policy Entropy: 3.70978
Value Function Loss: 0.06141

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.46189
Value Function Update Magnitude: 0.78565

Collected Steps per Second: 23,107.17143
Overall Steps per Second: 10,884.19736

Timestep Collection Time: 2.16383
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59382

Cumulative Model Updates: 91,882
Cumulative Timesteps: 766,297,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,829.47464
Policy Entropy: 3.72318
Value Function Loss: 0.06176

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.48824
Value Function Update Magnitude: 0.78926

Collected Steps per Second: 23,034.98660
Overall Steps per Second: 10,858.87595

Timestep Collection Time: 2.17131
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60600

Cumulative Model Updates: 91,888
Cumulative Timesteps: 766,347,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 766347866...
Checkpoint 766347866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,550.35407
Policy Entropy: 3.73135
Value Function Loss: 0.06112

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.55541
Value Function Update Magnitude: 0.81145

Collected Steps per Second: 22,879.13297
Overall Steps per Second: 10,712.44486

Timestep Collection Time: 2.18540
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.66747

Cumulative Model Updates: 91,894
Cumulative Timesteps: 766,397,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,389.26651
Policy Entropy: 3.73845
Value Function Loss: 0.05915

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.84798

Collected Steps per Second: 22,594.31920
Overall Steps per Second: 10,800.27280

Timestep Collection Time: 2.21427
Timestep Consumption Time: 2.41802
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.63229

Cumulative Model Updates: 91,900
Cumulative Timesteps: 766,447,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 766447896...
Checkpoint 766447896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.86130
Policy Entropy: 3.72867
Value Function Loss: 0.06012

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.56004
Value Function Update Magnitude: 0.73769

Collected Steps per Second: 22,214.75139
Overall Steps per Second: 10,681.59750

Timestep Collection Time: 2.25202
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.68357

Cumulative Model Updates: 91,906
Cumulative Timesteps: 766,497,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.32734
Policy Entropy: 3.72168
Value Function Loss: 0.06211

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.55498
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 22,729.61482
Overall Steps per Second: 10,650.70996

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.69678

Cumulative Model Updates: 91,912
Cumulative Timesteps: 766,547,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 766547948...
Checkpoint 766547948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,721.32784
Policy Entropy: 3.71785
Value Function Loss: 0.06144

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.76016

Collected Steps per Second: 22,474.47117
Overall Steps per Second: 10,646.89178

Timestep Collection Time: 2.22608
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69902

Cumulative Model Updates: 91,918
Cumulative Timesteps: 766,597,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.94119
Policy Entropy: 3.70390
Value Function Loss: 0.06118

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.58928
Value Function Update Magnitude: 0.77511

Collected Steps per Second: 22,545.71851
Overall Steps per Second: 10,764.55424

Timestep Collection Time: 2.21905
Timestep Consumption Time: 2.42861
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.64766

Cumulative Model Updates: 91,924
Cumulative Timesteps: 766,648,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 766648008...
Checkpoint 766648008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,051.60257
Policy Entropy: 3.70705
Value Function Loss: 0.06049

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.65219
Value Function Update Magnitude: 0.79979

Collected Steps per Second: 22,691.73182
Overall Steps per Second: 10,643.76110

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.69834

Cumulative Model Updates: 91,930
Cumulative Timesteps: 766,698,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,456.97174
Policy Entropy: 3.69322
Value Function Loss: 0.06244

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.69620
Value Function Update Magnitude: 0.82438

Collected Steps per Second: 22,340.47377
Overall Steps per Second: 10,863.96904

Timestep Collection Time: 2.23845
Timestep Consumption Time: 2.36466
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.60311

Cumulative Model Updates: 91,936
Cumulative Timesteps: 766,748,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 766748024...
Checkpoint 766748024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,720.67413
Policy Entropy: 3.68796
Value Function Loss: 0.06493

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.62372
Value Function Update Magnitude: 0.81345

Collected Steps per Second: 22,205.85336
Overall Steps per Second: 10,698.96664

Timestep Collection Time: 2.25238
Timestep Consumption Time: 2.42246
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.67484

Cumulative Model Updates: 91,942
Cumulative Timesteps: 766,798,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.00254
Policy Entropy: 3.68069
Value Function Loss: 0.06365

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.82491

Collected Steps per Second: 22,062.23536
Overall Steps per Second: 10,803.39451

Timestep Collection Time: 2.26677
Timestep Consumption Time: 2.36233
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.62910

Cumulative Model Updates: 91,948
Cumulative Timesteps: 766,848,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 766848050...
Checkpoint 766848050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.22571
Policy Entropy: 3.67953
Value Function Loss: 0.06288

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.80551

Collected Steps per Second: 21,951.28322
Overall Steps per Second: 10,664.91158

Timestep Collection Time: 2.27804
Timestep Consumption Time: 2.41079
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.68883

Cumulative Model Updates: 91,954
Cumulative Timesteps: 766,898,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,772.38014
Policy Entropy: 3.67897
Value Function Loss: 0.06407

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.57937
Value Function Update Magnitude: 0.81634

Collected Steps per Second: 22,366.63940
Overall Steps per Second: 10,881.74456

Timestep Collection Time: 2.23655
Timestep Consumption Time: 2.36051
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59706

Cumulative Model Updates: 91,960
Cumulative Timesteps: 766,948,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 766948080...
Checkpoint 766948080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,375.06803
Policy Entropy: 3.67089
Value Function Loss: 0.06598

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.62336
Value Function Update Magnitude: 0.81385

Collected Steps per Second: 21,667.47004
Overall Steps per Second: 10,616.01335

Timestep Collection Time: 2.30881
Timestep Consumption Time: 2.40351
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.71232

Cumulative Model Updates: 91,966
Cumulative Timesteps: 766,998,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,549.36484
Policy Entropy: 3.66388
Value Function Loss: 0.06901

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07047
Policy Update Magnitude: 0.67035
Value Function Update Magnitude: 0.74405

Collected Steps per Second: 22,510.11657
Overall Steps per Second: 10,651.55671

Timestep Collection Time: 2.22158
Timestep Consumption Time: 2.47332
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.69490

Cumulative Model Updates: 91,972
Cumulative Timesteps: 767,048,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 767048114...
Checkpoint 767048114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,377.87849
Policy Entropy: 3.66363
Value Function Loss: 0.07079

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.73250
Value Function Update Magnitude: 0.67702

Collected Steps per Second: 22,225.71047
Overall Steps per Second: 10,583.17416

Timestep Collection Time: 2.25010
Timestep Consumption Time: 2.47533
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.72543

Cumulative Model Updates: 91,978
Cumulative Timesteps: 767,098,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,508.15284
Policy Entropy: 3.66726
Value Function Loss: 0.07006

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.69956
Value Function Update Magnitude: 0.74263

Collected Steps per Second: 22,509.42548
Overall Steps per Second: 10,818.37900

Timestep Collection Time: 2.22129
Timestep Consumption Time: 2.40047
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.62176

Cumulative Model Updates: 91,984
Cumulative Timesteps: 767,148,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 767148124...
Checkpoint 767148124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,914.10731
Policy Entropy: 3.66283
Value Function Loss: 0.07275

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.16066
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.75097

Collected Steps per Second: 22,241.02812
Overall Steps per Second: 10,714.63790

Timestep Collection Time: 2.24918
Timestep Consumption Time: 2.41958
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.66875

Cumulative Model Updates: 91,990
Cumulative Timesteps: 767,198,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,707.87741
Policy Entropy: 3.65328
Value Function Loss: 0.07279

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.46171
Value Function Update Magnitude: 0.80839

Collected Steps per Second: 22,633.44934
Overall Steps per Second: 10,749.71343

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.65315

Cumulative Model Updates: 91,996
Cumulative Timesteps: 767,248,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 767248168...
Checkpoint 767248168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,715.83422
Policy Entropy: 3.64801
Value Function Loss: 0.07465

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.51284
Value Function Update Magnitude: 0.88107

Collected Steps per Second: 22,902.10591
Overall Steps per Second: 10,756.66273

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.46527
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.64865

Cumulative Model Updates: 92,002
Cumulative Timesteps: 767,298,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.04394
Policy Entropy: 3.65569
Value Function Loss: 0.07391

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.90680

Collected Steps per Second: 22,990.73531
Overall Steps per Second: 10,837.94206

Timestep Collection Time: 2.17557
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.61508

Cumulative Model Updates: 92,008
Cumulative Timesteps: 767,348,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 767348190...
Checkpoint 767348190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,705.89125
Policy Entropy: 3.65892
Value Function Loss: 0.07439

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.50292
Value Function Update Magnitude: 0.92364

Collected Steps per Second: 22,796.16481
Overall Steps per Second: 10,688.59408

Timestep Collection Time: 2.19335
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.67788

Cumulative Model Updates: 92,014
Cumulative Timesteps: 767,398,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.79371
Policy Entropy: 3.66390
Value Function Loss: 0.07410

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.91529

Collected Steps per Second: 22,766.50963
Overall Steps per Second: 10,850.32926

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.41272
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.60963

Cumulative Model Updates: 92,020
Cumulative Timesteps: 767,448,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 767448206...
Checkpoint 767448206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,942.82400
Policy Entropy: 3.66747
Value Function Loss: 0.07043

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.57749
Value Function Update Magnitude: 0.89335

Collected Steps per Second: 22,470.24613
Overall Steps per Second: 10,704.73755

Timestep Collection Time: 2.22561
Timestep Consumption Time: 2.44615
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.67176

Cumulative Model Updates: 92,026
Cumulative Timesteps: 767,498,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.65212
Policy Entropy: 3.66240
Value Function Loss: 0.07226

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.55377
Value Function Update Magnitude: 0.79615

Collected Steps per Second: 22,702.62032
Overall Steps per Second: 10,587.83503

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.52102
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.72429

Cumulative Model Updates: 92,032
Cumulative Timesteps: 767,548,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 767548236...
Checkpoint 767548236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,402.05733
Policy Entropy: 3.65303
Value Function Loss: 0.07392

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.52371
Value Function Update Magnitude: 0.75163

Collected Steps per Second: 22,469.74950
Overall Steps per Second: 10,588.08388

Timestep Collection Time: 2.22575
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.72342

Cumulative Model Updates: 92,038
Cumulative Timesteps: 767,598,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,092.43135
Policy Entropy: 3.63893
Value Function Loss: 0.07601

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.54251
Value Function Update Magnitude: 0.79909

Collected Steps per Second: 22,200.91150
Overall Steps per Second: 10,523.96541

Timestep Collection Time: 2.25270
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.75220

Cumulative Model Updates: 92,044
Cumulative Timesteps: 767,648,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 767648260...
Checkpoint 767648260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,484.74227
Policy Entropy: 3.64407
Value Function Loss: 0.07541

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.49758
Value Function Update Magnitude: 0.83607

Collected Steps per Second: 22,654.28391
Overall Steps per Second: 10,613.33455

Timestep Collection Time: 2.20806
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.71313

Cumulative Model Updates: 92,050
Cumulative Timesteps: 767,698,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,904.55902
Policy Entropy: 3.65717
Value Function Loss: 0.07419

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.87811

Collected Steps per Second: 23,156.07569
Overall Steps per Second: 10,849.38529

Timestep Collection Time: 2.15961
Timestep Consumption Time: 2.44969
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60929

Cumulative Model Updates: 92,056
Cumulative Timesteps: 767,748,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 767748290...
Checkpoint 767748290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.35729
Policy Entropy: 3.66721
Value Function Loss: 0.07365

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.63867
Value Function Update Magnitude: 0.91488

Collected Steps per Second: 23,076.08609
Overall Steps per Second: 10,760.01887

Timestep Collection Time: 2.16805
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.64962

Cumulative Model Updates: 92,062
Cumulative Timesteps: 767,798,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,606.18450
Policy Entropy: 3.67205
Value Function Loss: 0.07383

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.60269
Value Function Update Magnitude: 0.85315

Collected Steps per Second: 22,485.74165
Overall Steps per Second: 10,713.87225

Timestep Collection Time: 2.22452
Timestep Consumption Time: 2.44419
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.66871

Cumulative Model Updates: 92,068
Cumulative Timesteps: 767,848,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 767848340...
Checkpoint 767848340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,613.39967
Policy Entropy: 3.67067
Value Function Loss: 0.07616

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.60816
Value Function Update Magnitude: 0.70798

Collected Steps per Second: 21,766.17078
Overall Steps per Second: 10,664.06246

Timestep Collection Time: 2.29834
Timestep Consumption Time: 2.39275
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.69108

Cumulative Model Updates: 92,074
Cumulative Timesteps: 767,898,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,298.03276
Policy Entropy: 3.66265
Value Function Loss: 0.07887

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.59073
Value Function Update Magnitude: 0.75545

Collected Steps per Second: 22,382.75423
Overall Steps per Second: 10,895.00134

Timestep Collection Time: 2.23467
Timestep Consumption Time: 2.35625
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59091

Cumulative Model Updates: 92,080
Cumulative Timesteps: 767,948,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 767948384...
Checkpoint 767948384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,040.80242
Policy Entropy: 3.65810
Value Function Loss: 0.07932

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.59786
Value Function Update Magnitude: 0.76713

Collected Steps per Second: 22,197.39576
Overall Steps per Second: 10,694.52779

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.67791

Cumulative Model Updates: 92,086
Cumulative Timesteps: 767,998,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,410.06677
Policy Entropy: 3.65063
Value Function Loss: 0.08145

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.59575
Value Function Update Magnitude: 0.76621

Collected Steps per Second: 21,860.01279
Overall Steps per Second: 10,642.81487

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.69951

Cumulative Model Updates: 92,092
Cumulative Timesteps: 768,048,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 768048428...
Checkpoint 768048428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,811.53112
Policy Entropy: 3.64604
Value Function Loss: 0.07964

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.62330
Value Function Update Magnitude: 0.68162

Collected Steps per Second: 22,150.44166
Overall Steps per Second: 10,853.87136

Timestep Collection Time: 2.25874
Timestep Consumption Time: 2.35086
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.60960

Cumulative Model Updates: 92,098
Cumulative Timesteps: 768,098,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.65888
Policy Entropy: 3.64905
Value Function Loss: 0.08283

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.63988

Collected Steps per Second: 22,059.74852
Overall Steps per Second: 10,718.72833

Timestep Collection Time: 2.26712
Timestep Consumption Time: 2.39874
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.66585

Cumulative Model Updates: 92,104
Cumulative Timesteps: 768,148,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 768148472...
Checkpoint 768148472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,358.62613
Policy Entropy: 3.65252
Value Function Loss: 0.08144

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.60944
Value Function Update Magnitude: 0.64083

Collected Steps per Second: 22,165.74453
Overall Steps per Second: 10,529.65459

Timestep Collection Time: 2.25655
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.75020

Cumulative Model Updates: 92,110
Cumulative Timesteps: 768,198,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,745.76345
Policy Entropy: 3.65279
Value Function Loss: 0.07958

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.67756

Collected Steps per Second: 22,667.59022
Overall Steps per Second: 10,816.09951

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.41762
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.62403

Cumulative Model Updates: 92,116
Cumulative Timesteps: 768,248,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 768248504...
Checkpoint 768248504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,240.96582
Policy Entropy: 3.65709
Value Function Loss: 0.07702

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.61364
Value Function Update Magnitude: 0.71118

Collected Steps per Second: 22,626.93137
Overall Steps per Second: 10,640.49600

Timestep Collection Time: 2.21082
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70128

Cumulative Model Updates: 92,122
Cumulative Timesteps: 768,298,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,565.88705
Policy Entropy: 3.66202
Value Function Loss: 0.07655

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.68981
Value Function Update Magnitude: 0.74385

Collected Steps per Second: 23,266.34122
Overall Steps per Second: 10,878.13879

Timestep Collection Time: 2.14946
Timestep Consumption Time: 2.44784
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.59729

Cumulative Model Updates: 92,128
Cumulative Timesteps: 768,348,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 768348538...
Checkpoint 768348538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,731.80339
Policy Entropy: 3.66665
Value Function Loss: 0.07761

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.62780
Value Function Update Magnitude: 0.72411

Collected Steps per Second: 23,078.17701
Overall Steps per Second: 10,820.86018

Timestep Collection Time: 2.16733
Timestep Consumption Time: 2.45504
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.62237

Cumulative Model Updates: 92,134
Cumulative Timesteps: 768,398,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,351.48852
Policy Entropy: 3.67270
Value Function Loss: 0.07638

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.61712
Value Function Update Magnitude: 0.67388

Collected Steps per Second: 22,987.43748
Overall Steps per Second: 10,720.81649

Timestep Collection Time: 2.17562
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.66494

Cumulative Model Updates: 92,140
Cumulative Timesteps: 768,448,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 768448568...
Checkpoint 768448568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,195.44933
Policy Entropy: 3.67784
Value Function Loss: 0.07290

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.60446
Value Function Update Magnitude: 0.70448

Collected Steps per Second: 22,273.18519
Overall Steps per Second: 10,649.28500

Timestep Collection Time: 2.24494
Timestep Consumption Time: 2.45040
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.69534

Cumulative Model Updates: 92,146
Cumulative Timesteps: 768,498,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.87231
Policy Entropy: 3.68116
Value Function Loss: 0.07053

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.60932
Value Function Update Magnitude: 0.79333

Collected Steps per Second: 22,802.00199
Overall Steps per Second: 10,830.54302

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.42533
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61953

Cumulative Model Updates: 92,152
Cumulative Timesteps: 768,548,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 768548602...
Checkpoint 768548602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.96797
Policy Entropy: 3.68571
Value Function Loss: 0.06919

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.63431
Value Function Update Magnitude: 0.87932

Collected Steps per Second: 22,607.53152
Overall Steps per Second: 10,700.76079

Timestep Collection Time: 2.21280
Timestep Consumption Time: 2.46219
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.67499

Cumulative Model Updates: 92,158
Cumulative Timesteps: 768,598,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,612.43765
Policy Entropy: 3.68535
Value Function Loss: 0.07263

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.63135
Value Function Update Magnitude: 0.86566

Collected Steps per Second: 22,559.19149
Overall Steps per Second: 10,600.43030

Timestep Collection Time: 2.21657
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.71717

Cumulative Model Updates: 92,164
Cumulative Timesteps: 768,648,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 768648632...
Checkpoint 768648632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.70920
Policy Entropy: 3.69183
Value Function Loss: 0.07069

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.52649
Value Function Update Magnitude: 0.86427

Collected Steps per Second: 22,340.05684
Overall Steps per Second: 10,470.57708

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.53726
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.77548

Cumulative Model Updates: 92,170
Cumulative Timesteps: 768,698,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,422.70673
Policy Entropy: 3.67508
Value Function Loss: 0.07012

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.85380

Collected Steps per Second: 23,051.37202
Overall Steps per Second: 10,689.24102

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.67854

Cumulative Model Updates: 92,176
Cumulative Timesteps: 768,748,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 768748644...
Checkpoint 768748644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,952.23528
Policy Entropy: 3.67080
Value Function Loss: 0.06663

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.71163
Value Function Update Magnitude: 0.81524

Collected Steps per Second: 22,720.94179
Overall Steps per Second: 10,781.58332

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.43809
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63976

Cumulative Model Updates: 92,182
Cumulative Timesteps: 768,798,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,873.24526
Policy Entropy: 3.66284
Value Function Loss: 0.06627

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.79530
Value Function Update Magnitude: 0.76623

Collected Steps per Second: 22,728.82897
Overall Steps per Second: 10,709.30578

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.47007
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.67089

Cumulative Model Updates: 92,188
Cumulative Timesteps: 768,848,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 768848690...
Checkpoint 768848690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,044.43165
Policy Entropy: 3.66612
Value Function Loss: 0.06620

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.76037
Value Function Update Magnitude: 0.78256

Collected Steps per Second: 22,899.35595
Overall Steps per Second: 10,918.19286

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.39624
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.57988

Cumulative Model Updates: 92,194
Cumulative Timesteps: 768,898,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.47218
Policy Entropy: 3.65913
Value Function Loss: 0.06769

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.66111
Value Function Update Magnitude: 0.76927

Collected Steps per Second: 22,830.60411
Overall Steps per Second: 10,903.85472

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.39587
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.58627

Cumulative Model Updates: 92,200
Cumulative Timesteps: 768,948,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 768948702...
Checkpoint 768948702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,248.96024
Policy Entropy: 3.66414
Value Function Loss: 0.06959

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.75567

Collected Steps per Second: 22,624.83356
Overall Steps per Second: 10,686.82259

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.67978

Cumulative Model Updates: 92,206
Cumulative Timesteps: 768,998,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,342.15329
Policy Entropy: 3.66168
Value Function Loss: 0.06702

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.56549
Value Function Update Magnitude: 0.73790

Collected Steps per Second: 22,306.36088
Overall Steps per Second: 10,549.81938

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.74131

Cumulative Model Updates: 92,212
Cumulative Timesteps: 769,048,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 769048734...
Checkpoint 769048734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.45647
Policy Entropy: 3.66349
Value Function Loss: 0.06683

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.63712
Value Function Update Magnitude: 0.70239

Collected Steps per Second: 22,518.56586
Overall Steps per Second: 10,580.04207

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.50569
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.72626

Cumulative Model Updates: 92,218
Cumulative Timesteps: 769,098,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.66375
Policy Entropy: 3.66171
Value Function Loss: 0.06633

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.68243

Collected Steps per Second: 22,643.51389
Overall Steps per Second: 10,835.62723

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.40685
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61551

Cumulative Model Updates: 92,224
Cumulative Timesteps: 769,148,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 769148750...
Checkpoint 769148750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,855.45244
Policy Entropy: 3.66779
Value Function Loss: 0.06803

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.68589

Collected Steps per Second: 22,448.76822
Overall Steps per Second: 10,627.52989

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.70702

Cumulative Model Updates: 92,230
Cumulative Timesteps: 769,198,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.38644
Policy Entropy: 3.67615
Value Function Loss: 0.06636

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.57431
Value Function Update Magnitude: 0.76709

Collected Steps per Second: 22,706.99840
Overall Steps per Second: 10,689.50035

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.47602
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.67842

Cumulative Model Updates: 92,236
Cumulative Timesteps: 769,248,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 769248784...
Checkpoint 769248784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,306.73533
Policy Entropy: 3.67278
Value Function Loss: 0.06855

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.57713
Value Function Update Magnitude: 0.75138

Collected Steps per Second: 23,076.45628
Overall Steps per Second: 10,841.66330

Timestep Collection Time: 2.16697
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61239

Cumulative Model Updates: 92,242
Cumulative Timesteps: 769,298,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.06907
Policy Entropy: 3.66254
Value Function Loss: 0.06898

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.54444
Value Function Update Magnitude: 0.73041

Collected Steps per Second: 22,810.73237
Overall Steps per Second: 10,692.09518

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.67691

Cumulative Model Updates: 92,248
Cumulative Timesteps: 769,348,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 769348796...
Checkpoint 769348796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,290.41098
Policy Entropy: 3.64863
Value Function Loss: 0.07093

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.51129
Value Function Update Magnitude: 0.70925

Collected Steps per Second: 23,007.28498
Overall Steps per Second: 10,916.57674

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.40697
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.58019

Cumulative Model Updates: 92,254
Cumulative Timesteps: 769,398,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,107.84202
Policy Entropy: 3.65113
Value Function Loss: 0.07034

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.50363
Value Function Update Magnitude: 0.66926

Collected Steps per Second: 22,723.08286
Overall Steps per Second: 10,786.16473

Timestep Collection Time: 2.20120
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63724

Cumulative Model Updates: 92,260
Cumulative Timesteps: 769,448,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 769448814...
Checkpoint 769448814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,405.24428
Policy Entropy: 3.64422
Value Function Loss: 0.07374

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.73351

Collected Steps per Second: 22,771.61365
Overall Steps per Second: 10,722.78772

Timestep Collection Time: 2.19616
Timestep Consumption Time: 2.46774
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.66390

Cumulative Model Updates: 92,266
Cumulative Timesteps: 769,498,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,619.16471
Policy Entropy: 3.65090
Value Function Loss: 0.07179

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.73995

Collected Steps per Second: 22,651.86848
Overall Steps per Second: 10,685.23857

Timestep Collection Time: 2.20768
Timestep Consumption Time: 2.47242
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.68010

Cumulative Model Updates: 92,272
Cumulative Timesteps: 769,548,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 769548832...
Checkpoint 769548832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.20538
Policy Entropy: 3.64973
Value Function Loss: 0.07210

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.52478
Value Function Update Magnitude: 0.76129

Collected Steps per Second: 22,338.87454
Overall Steps per Second: 10,809.18523

Timestep Collection Time: 2.23906
Timestep Consumption Time: 2.38830
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62736

Cumulative Model Updates: 92,278
Cumulative Timesteps: 769,598,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,621.33429
Policy Entropy: 3.66279
Value Function Loss: 0.06970

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.51289
Value Function Update Magnitude: 0.80750

Collected Steps per Second: 22,507.20126
Overall Steps per Second: 10,653.09912

Timestep Collection Time: 2.22267
Timestep Consumption Time: 2.47324
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69591

Cumulative Model Updates: 92,284
Cumulative Timesteps: 769,648,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 769648876...
Checkpoint 769648876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,890.69822
Policy Entropy: 3.65269
Value Function Loss: 0.07368

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.52158
Value Function Update Magnitude: 0.82301

Collected Steps per Second: 22,710.72376
Overall Steps per Second: 10,591.72511

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.72123

Cumulative Model Updates: 92,290
Cumulative Timesteps: 769,698,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.46746
Policy Entropy: 3.66010
Value Function Loss: 0.07460

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.52862
Value Function Update Magnitude: 0.80435

Collected Steps per Second: 21,748.18677
Overall Steps per Second: 10,332.72674

Timestep Collection Time: 2.29913
Timestep Consumption Time: 2.54005
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.83919

Cumulative Model Updates: 92,296
Cumulative Timesteps: 769,748,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 769748884...
Checkpoint 769748884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.24841
Policy Entropy: 3.65348
Value Function Loss: 0.07515

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.80682

Collected Steps per Second: 22,687.15178
Overall Steps per Second: 10,671.30583

Timestep Collection Time: 2.20583
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.68959

Cumulative Model Updates: 92,302
Cumulative Timesteps: 769,798,928

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,693.07077
Policy Entropy: 3.66023
Value Function Loss: 0.07292

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.74797

Collected Steps per Second: 22,668.42197
Overall Steps per Second: 10,620.13528

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.70841

Cumulative Model Updates: 92,308
Cumulative Timesteps: 769,848,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 769848932...
Checkpoint 769848932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,724.86989
Policy Entropy: 3.64905
Value Function Loss: 0.07545

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.70768

Collected Steps per Second: 22,908.53240
Overall Steps per Second: 10,843.66978

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61135

Cumulative Model Updates: 92,314
Cumulative Timesteps: 769,898,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.50355
Policy Entropy: 3.66063
Value Function Loss: 0.07387

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.60494
Value Function Update Magnitude: 0.73317

Collected Steps per Second: 22,799.08133
Overall Steps per Second: 10,718.28969

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.47393
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.66884

Cumulative Model Updates: 92,320
Cumulative Timesteps: 769,948,978

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 769948978...
Checkpoint 769948978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.15781
Policy Entropy: 3.65544
Value Function Loss: 0.07495

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.62065
Value Function Update Magnitude: 0.71451

Collected Steps per Second: 22,689.36081
Overall Steps per Second: 10,819.90184

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.41763
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.62148

Cumulative Model Updates: 92,326
Cumulative Timesteps: 769,998,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,799.20311
Policy Entropy: 3.67319
Value Function Loss: 0.07427

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.18025
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.71510

Collected Steps per Second: 21,826.14050
Overall Steps per Second: 10,575.71574

Timestep Collection Time: 2.29156
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.72933

Cumulative Model Updates: 92,332
Cumulative Timesteps: 770,048,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 770048998...
Checkpoint 770048998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,445.20567
Policy Entropy: 3.69103
Value Function Loss: 0.07312

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.16191
Policy Update Magnitude: 0.55394
Value Function Update Magnitude: 0.71040

Collected Steps per Second: 22,331.51557
Overall Steps per Second: 10,588.95905

Timestep Collection Time: 2.24033
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.72473

Cumulative Model Updates: 92,338
Cumulative Timesteps: 770,099,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,756.07933
Policy Entropy: 3.69021
Value Function Loss: 0.07084

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.50980
Value Function Update Magnitude: 0.66566

Collected Steps per Second: 22,618.26753
Overall Steps per Second: 10,696.57865

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.67551

Cumulative Model Updates: 92,344
Cumulative Timesteps: 770,149,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 770149040...
Checkpoint 770149040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.82548
Policy Entropy: 3.70102
Value Function Loss: 0.06662

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.50588
Value Function Update Magnitude: 0.74263

Collected Steps per Second: 22,270.26153
Overall Steps per Second: 10,625.36439

Timestep Collection Time: 2.24649
Timestep Consumption Time: 2.46205
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.70854

Cumulative Model Updates: 92,350
Cumulative Timesteps: 770,199,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,416.21711
Policy Entropy: 3.70512
Value Function Loss: 0.06547

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.52316
Value Function Update Magnitude: 0.77213

Collected Steps per Second: 22,924.64523
Overall Steps per Second: 10,657.21654

Timestep Collection Time: 2.18202
Timestep Consumption Time: 2.51170
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.69372

Cumulative Model Updates: 92,356
Cumulative Timesteps: 770,249,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 770249092...
Checkpoint 770249092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,884.86665
Policy Entropy: 3.70527
Value Function Loss: 0.06506

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.50523
Value Function Update Magnitude: 0.71336

Collected Steps per Second: 22,834.28561
Overall Steps per Second: 10,634.95685

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.70298

Cumulative Model Updates: 92,362
Cumulative Timesteps: 770,299,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.92011
Policy Entropy: 3.69669
Value Function Loss: 0.06411

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.51440
Value Function Update Magnitude: 0.76804

Collected Steps per Second: 22,957.71216
Overall Steps per Second: 10,823.79670

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.44349
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62315

Cumulative Model Updates: 92,368
Cumulative Timesteps: 770,349,148

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 770349148...
Checkpoint 770349148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,347.97673
Policy Entropy: 3.71281
Value Function Loss: 0.06043

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.56732
Value Function Update Magnitude: 0.82063

Collected Steps per Second: 22,644.47161
Overall Steps per Second: 10,807.66761

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.41849
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.62672

Cumulative Model Updates: 92,374
Cumulative Timesteps: 770,399,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,050.58602
Policy Entropy: 3.70757
Value Function Loss: 0.05860

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.66873
Value Function Update Magnitude: 0.81310

Collected Steps per Second: 23,278.66961
Overall Steps per Second: 10,831.15935

Timestep Collection Time: 2.14806
Timestep Consumption Time: 2.46862
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.61668

Cumulative Model Updates: 92,380
Cumulative Timesteps: 770,449,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 770449156...
Checkpoint 770449156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,425.05026
Policy Entropy: 3.70150
Value Function Loss: 0.05835

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.63391
Value Function Update Magnitude: 0.78999

Collected Steps per Second: 21,788.27832
Overall Steps per Second: 10,620.76460

Timestep Collection Time: 2.29582
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.70983

Cumulative Model Updates: 92,386
Cumulative Timesteps: 770,499,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.56725
Policy Entropy: 3.70148
Value Function Loss: 0.05750

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.76023

Collected Steps per Second: 22,047.13775
Overall Steps per Second: 10,684.13953

Timestep Collection Time: 2.26859
Timestep Consumption Time: 2.41274
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.68133

Cumulative Model Updates: 92,392
Cumulative Timesteps: 770,549,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 770549194...
Checkpoint 770549194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,866.06569
Policy Entropy: 3.70182
Value Function Loss: 0.05878

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.59478
Value Function Update Magnitude: 0.75691

Collected Steps per Second: 21,902.03313
Overall Steps per Second: 10,661.45735

Timestep Collection Time: 2.28472
Timestep Consumption Time: 2.40882
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69354

Cumulative Model Updates: 92,398
Cumulative Timesteps: 770,599,234

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.65716
Policy Entropy: 3.71201
Value Function Loss: 0.06001

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.60073
Value Function Update Magnitude: 0.75857

Collected Steps per Second: 21,718.78927
Overall Steps per Second: 10,758.13537

Timestep Collection Time: 2.30289
Timestep Consumption Time: 2.34624
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.64913

Cumulative Model Updates: 92,404
Cumulative Timesteps: 770,649,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 770649250...
Checkpoint 770649250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,114.53459
Policy Entropy: 3.70961
Value Function Loss: 0.06022

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.75743

Collected Steps per Second: 21,732.93868
Overall Steps per Second: 10,604.59106

Timestep Collection Time: 2.30075
Timestep Consumption Time: 2.41438
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.71513

Cumulative Model Updates: 92,410
Cumulative Timesteps: 770,699,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.07836
Policy Entropy: 3.71533
Value Function Loss: 0.06099

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.53532
Value Function Update Magnitude: 0.76583

Collected Steps per Second: 21,995.28009
Overall Steps per Second: 10,812.88260

Timestep Collection Time: 2.27458
Timestep Consumption Time: 2.35231
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.62689

Cumulative Model Updates: 92,416
Cumulative Timesteps: 770,749,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 770749282...
Checkpoint 770749282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,962.60332
Policy Entropy: 3.70773
Value Function Loss: 0.06063

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.59479
Value Function Update Magnitude: 0.79558

Collected Steps per Second: 21,846.53916
Overall Steps per Second: 10,778.00456

Timestep Collection Time: 2.28979
Timestep Consumption Time: 2.35151
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.64130

Cumulative Model Updates: 92,422
Cumulative Timesteps: 770,799,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.58411
Policy Entropy: 3.69826
Value Function Loss: 0.06642

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.80833

Collected Steps per Second: 22,203.25419
Overall Steps per Second: 10,804.43001

Timestep Collection Time: 2.25291
Timestep Consumption Time: 2.37685
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62977

Cumulative Model Updates: 92,428
Cumulative Timesteps: 770,849,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 770849328...
Checkpoint 770849328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,920.66077
Policy Entropy: 3.69264
Value Function Loss: 0.06684

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.81579

Collected Steps per Second: 22,091.77795
Overall Steps per Second: 10,666.98092

Timestep Collection Time: 2.26338
Timestep Consumption Time: 2.42417
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.68755

Cumulative Model Updates: 92,434
Cumulative Timesteps: 770,899,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,740.37449
Policy Entropy: 3.67835
Value Function Loss: 0.06647

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.67387
Value Function Update Magnitude: 0.82478

Collected Steps per Second: 22,535.54027
Overall Steps per Second: 10,703.96758

Timestep Collection Time: 2.21925
Timestep Consumption Time: 2.45304
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67229

Cumulative Model Updates: 92,440
Cumulative Timesteps: 770,949,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 770949342...
Checkpoint 770949342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,713.72541
Policy Entropy: 3.68952
Value Function Loss: 0.06327

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.69479
Value Function Update Magnitude: 0.80745

Collected Steps per Second: 22,919.54318
Overall Steps per Second: 10,950.61441

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.38479
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.56668

Cumulative Model Updates: 92,446
Cumulative Timesteps: 770,999,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.42807
Policy Entropy: 3.68461
Value Function Loss: 0.06340

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.72504
Value Function Update Magnitude: 0.81126

Collected Steps per Second: 22,852.27739
Overall Steps per Second: 10,815.26654

Timestep Collection Time: 2.18919
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.62568

Cumulative Model Updates: 92,452
Cumulative Timesteps: 771,049,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 771049378...
Checkpoint 771049378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,527.60215
Policy Entropy: 3.68759
Value Function Loss: 0.06521

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.78752
Value Function Update Magnitude: 0.81235

Collected Steps per Second: 22,032.33153
Overall Steps per Second: 10,707.15576

Timestep Collection Time: 2.27066
Timestep Consumption Time: 2.40173
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.67239

Cumulative Model Updates: 92,458
Cumulative Timesteps: 771,099,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,884.15258
Policy Entropy: 3.68170
Value Function Loss: 0.06677

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.78539
Value Function Update Magnitude: 0.79685

Collected Steps per Second: 22,584.05090
Overall Steps per Second: 10,847.81531

Timestep Collection Time: 2.21457
Timestep Consumption Time: 2.39594
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.61051

Cumulative Model Updates: 92,464
Cumulative Timesteps: 771,149,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 771149420...
Checkpoint 771149420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,118.36630
Policy Entropy: 3.69125
Value Function Loss: 0.06646

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.75587
Value Function Update Magnitude: 0.80325

Collected Steps per Second: 22,675.14095
Overall Steps per Second: 10,678.42736

Timestep Collection Time: 2.20665
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.68571

Cumulative Model Updates: 92,470
Cumulative Timesteps: 771,199,456

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,371.94605
Policy Entropy: 3.68770
Value Function Loss: 0.06600

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.76541
Value Function Update Magnitude: 0.80459

Collected Steps per Second: 22,375.07044
Overall Steps per Second: 10,781.99691

Timestep Collection Time: 2.23606
Timestep Consumption Time: 2.40427
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.64033

Cumulative Model Updates: 92,476
Cumulative Timesteps: 771,249,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 771249488...
Checkpoint 771249488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,280.20150
Policy Entropy: 3.68192
Value Function Loss: 0.06667

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06740
Policy Update Magnitude: 0.76144
Value Function Update Magnitude: 0.79190

Collected Steps per Second: 22,913.69270
Overall Steps per Second: 10,724.40895

Timestep Collection Time: 2.18297
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.66413

Cumulative Model Updates: 92,482
Cumulative Timesteps: 771,299,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,811.99119
Policy Entropy: 3.66571
Value Function Loss: 0.06943

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09275
Policy Update Magnitude: 0.70352
Value Function Update Magnitude: 0.79582

Collected Steps per Second: 22,773.27820
Overall Steps per Second: 10,682.74985

Timestep Collection Time: 2.19687
Timestep Consumption Time: 2.48638
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.68325

Cumulative Model Updates: 92,488
Cumulative Timesteps: 771,349,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 771349538...
Checkpoint 771349538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,297.60983
Policy Entropy: 3.68018
Value Function Loss: 0.06981

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.60351
Value Function Update Magnitude: 0.79782

Collected Steps per Second: 23,105.73728
Overall Steps per Second: 10,910.68220

Timestep Collection Time: 2.16440
Timestep Consumption Time: 2.41918
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.58358

Cumulative Model Updates: 92,494
Cumulative Timesteps: 771,399,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.76742
Policy Entropy: 3.69075
Value Function Loss: 0.06907

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.66084
Value Function Update Magnitude: 0.84161

Collected Steps per Second: 23,258.48588
Overall Steps per Second: 10,916.59481

Timestep Collection Time: 2.15070
Timestep Consumption Time: 2.43150
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.58220

Cumulative Model Updates: 92,500
Cumulative Timesteps: 771,449,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 771449570...
Checkpoint 771449570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,515.66679
Policy Entropy: 3.68873
Value Function Loss: 0.07024

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.61439
Value Function Update Magnitude: 0.78728

Collected Steps per Second: 22,686.53316
Overall Steps per Second: 10,588.23114

Timestep Collection Time: 2.20536
Timestep Consumption Time: 2.51989
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.72525

Cumulative Model Updates: 92,506
Cumulative Timesteps: 771,499,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,685.29412
Policy Entropy: 3.69046
Value Function Loss: 0.07165

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.60944
Value Function Update Magnitude: 0.70296

Collected Steps per Second: 22,997.94004
Overall Steps per Second: 10,852.71499

Timestep Collection Time: 2.17524
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60954

Cumulative Model Updates: 92,512
Cumulative Timesteps: 771,549,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 771549628...
Checkpoint 771549628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,969.49416
Policy Entropy: 3.68619
Value Function Loss: 0.07251

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.63911
Value Function Update Magnitude: 0.66917

Collected Steps per Second: 22,414.99856
Overall Steps per Second: 10,744.96459

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.42395
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.65576

Cumulative Model Updates: 92,518
Cumulative Timesteps: 771,599,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,745.32105
Policy Entropy: 3.68637
Value Function Loss: 0.07170

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.60771
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 22,557.58859
Overall Steps per Second: 10,635.43741

Timestep Collection Time: 2.21744
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.70314

Cumulative Model Updates: 92,524
Cumulative Timesteps: 771,649,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 771649674...
Checkpoint 771649674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,585.06173
Policy Entropy: 3.67881
Value Function Loss: 0.07117

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.58919
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 22,100.06370
Overall Steps per Second: 10,501.82267

Timestep Collection Time: 2.26307
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.76241

Cumulative Model Updates: 92,530
Cumulative Timesteps: 771,699,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,739.27559
Policy Entropy: 3.67327
Value Function Loss: 0.07315

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.60263

Collected Steps per Second: 22,510.62707
Overall Steps per Second: 10,607.26125

Timestep Collection Time: 2.22206
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.71564

Cumulative Model Updates: 92,536
Cumulative Timesteps: 771,749,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 771749708...
Checkpoint 771749708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,056.59384
Policy Entropy: 3.67637
Value Function Loss: 0.07333

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.48616
Value Function Update Magnitude: 0.62880

Collected Steps per Second: 22,533.36754
Overall Steps per Second: 10,513.76816

Timestep Collection Time: 2.21902
Timestep Consumption Time: 2.53684
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75586

Cumulative Model Updates: 92,542
Cumulative Timesteps: 771,799,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,675.46644
Policy Entropy: 3.67277
Value Function Loss: 0.07575

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06965
Policy Update Magnitude: 0.60663
Value Function Update Magnitude: 0.59929

Collected Steps per Second: 23,092.75983
Overall Steps per Second: 10,744.42085

Timestep Collection Time: 2.16648
Timestep Consumption Time: 2.48989
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.65637

Cumulative Model Updates: 92,548
Cumulative Timesteps: 771,849,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 771849740...
Checkpoint 771849740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,054.21129
Policy Entropy: 3.68096
Value Function Loss: 0.07529

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06060
Policy Update Magnitude: 0.77136
Value Function Update Magnitude: 0.62738

Collected Steps per Second: 22,845.01113
Overall Steps per Second: 10,699.72582

Timestep Collection Time: 2.18892
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.67358

Cumulative Model Updates: 92,554
Cumulative Timesteps: 771,899,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.95033
Policy Entropy: 3.68648
Value Function Loss: 0.07556

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.74462
Value Function Update Magnitude: 0.65453

Collected Steps per Second: 22,974.94646
Overall Steps per Second: 10,847.91852

Timestep Collection Time: 2.17724
Timestep Consumption Time: 2.43397
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61121

Cumulative Model Updates: 92,560
Cumulative Timesteps: 771,949,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 771949768...
Checkpoint 771949768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,368.96156
Policy Entropy: 3.67800
Value Function Loss: 0.07604

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.58512
Value Function Update Magnitude: 0.76306

Collected Steps per Second: 22,602.44896
Overall Steps per Second: 10,755.15697

Timestep Collection Time: 2.21259
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.64986

Cumulative Model Updates: 92,566
Cumulative Timesteps: 771,999,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,100.22996
Policy Entropy: 3.67585
Value Function Loss: 0.07693

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.56250
Value Function Update Magnitude: 0.87766

Collected Steps per Second: 23,028.96430
Overall Steps per Second: 10,889.07082

Timestep Collection Time: 2.17239
Timestep Consumption Time: 2.42194
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.59433

Cumulative Model Updates: 92,572
Cumulative Timesteps: 772,049,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 772049806...
Checkpoint 772049806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,696.89656
Policy Entropy: 3.67081
Value Function Loss: 0.07933

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.57131
Value Function Update Magnitude: 0.88363

Collected Steps per Second: 22,201.39926
Overall Steps per Second: 10,607.48921

Timestep Collection Time: 2.25328
Timestep Consumption Time: 2.46282
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.71610

Cumulative Model Updates: 92,578
Cumulative Timesteps: 772,099,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,833.50442
Policy Entropy: 3.68222
Value Function Loss: 0.07534

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.52681
Value Function Update Magnitude: 0.87389

Collected Steps per Second: 22,543.34364
Overall Steps per Second: 10,612.96382

Timestep Collection Time: 2.21795
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.71122

Cumulative Model Updates: 92,584
Cumulative Timesteps: 772,149,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 772149832...
Checkpoint 772149832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,181.35473
Policy Entropy: 3.67888
Value Function Loss: 0.07522

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.88484

Collected Steps per Second: 22,395.46295
Overall Steps per Second: 10,637.03732

Timestep Collection Time: 2.23349
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70244

Cumulative Model Updates: 92,590
Cumulative Timesteps: 772,199,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,519.57608
Policy Entropy: 3.68202
Value Function Loss: 0.07435

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.62819
Value Function Update Magnitude: 0.88711

Collected Steps per Second: 22,605.36707
Overall Steps per Second: 10,729.58819

Timestep Collection Time: 2.21293
Timestep Consumption Time: 2.44932
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.66225

Cumulative Model Updates: 92,596
Cumulative Timesteps: 772,249,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 772249876...
Checkpoint 772249876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.65094
Policy Entropy: 3.67743
Value Function Loss: 0.07512

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.60951
Value Function Update Magnitude: 0.91301

Collected Steps per Second: 21,991.24352
Overall Steps per Second: 10,578.50988

Timestep Collection Time: 2.27418
Timestep Consumption Time: 2.45352
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.72770

Cumulative Model Updates: 92,602
Cumulative Timesteps: 772,299,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,820.63112
Policy Entropy: 3.67643
Value Function Loss: 0.07682

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.56587
Value Function Update Magnitude: 0.92399

Collected Steps per Second: 22,873.36718
Overall Steps per Second: 10,646.80228

Timestep Collection Time: 2.18691
Timestep Consumption Time: 2.51140
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.69831

Cumulative Model Updates: 92,608
Cumulative Timesteps: 772,349,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 772349910...
Checkpoint 772349910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,376.70411
Policy Entropy: 3.67266
Value Function Loss: 0.07648

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.68056
Value Function Update Magnitude: 0.94892

Collected Steps per Second: 22,985.82175
Overall Steps per Second: 10,750.11608

Timestep Collection Time: 2.17551
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.65167

Cumulative Model Updates: 92,614
Cumulative Timesteps: 772,399,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,181.52296
Policy Entropy: 3.67031
Value Function Loss: 0.07506

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.74666
Value Function Update Magnitude: 0.94164

Collected Steps per Second: 23,310.48383
Overall Steps per Second: 10,864.48655

Timestep Collection Time: 2.14616
Timestep Consumption Time: 2.45857
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.60473

Cumulative Model Updates: 92,620
Cumulative Timesteps: 772,449,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 772449944...
Checkpoint 772449944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,187.61807
Policy Entropy: 3.65796
Value Function Loss: 0.07939

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.62756
Value Function Update Magnitude: 0.90746

Collected Steps per Second: 22,723.79297
Overall Steps per Second: 10,810.33344

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62668

Cumulative Model Updates: 92,626
Cumulative Timesteps: 772,499,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,628.91324
Policy Entropy: 3.65418
Value Function Loss: 0.08359

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.58951
Value Function Update Magnitude: 0.77097

Collected Steps per Second: 22,998.22896
Overall Steps per Second: 10,918.93142

Timestep Collection Time: 2.17538
Timestep Consumption Time: 2.40657
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.58195

Cumulative Model Updates: 92,632
Cumulative Timesteps: 772,549,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 772549990...
Checkpoint 772549990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.58411
Policy Entropy: 3.63419
Value Function Loss: 0.08883

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.69251
Value Function Update Magnitude: 0.71651

Collected Steps per Second: 22,360.30177
Overall Steps per Second: 10,720.99909

Timestep Collection Time: 2.23655
Timestep Consumption Time: 2.42812
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.66468

Cumulative Model Updates: 92,638
Cumulative Timesteps: 772,600,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,797.24003
Policy Entropy: 3.64187
Value Function Loss: 0.08666

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.75461
Value Function Update Magnitude: 0.73113

Collected Steps per Second: 22,459.16746
Overall Steps per Second: 10,542.44804

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.51687
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.74349

Cumulative Model Updates: 92,644
Cumulative Timesteps: 772,650,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 772650008...
Checkpoint 772650008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,498.31174
Policy Entropy: 3.63844
Value Function Loss: 0.08610

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.72258
Value Function Update Magnitude: 0.66816

Collected Steps per Second: 22,297.90186
Overall Steps per Second: 10,590.64889

Timestep Collection Time: 2.24308
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.72266

Cumulative Model Updates: 92,650
Cumulative Timesteps: 772,700,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,264.04344
Policy Entropy: 3.63088
Value Function Loss: 0.08634

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.62821
Value Function Update Magnitude: 0.65424

Collected Steps per Second: 22,486.30338
Overall Steps per Second: 10,592.88155

Timestep Collection Time: 2.22420
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.72147

Cumulative Model Updates: 92,656
Cumulative Timesteps: 772,750,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 772750038...
Checkpoint 772750038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,020.96602
Policy Entropy: 3.62435
Value Function Loss: 0.08685

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.61180
Value Function Update Magnitude: 0.63599

Collected Steps per Second: 22,446.42118
Overall Steps per Second: 10,567.16628

Timestep Collection Time: 2.22851
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.73372

Cumulative Model Updates: 92,662
Cumulative Timesteps: 772,800,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.24499
Policy Entropy: 3.63842
Value Function Loss: 0.08394

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.58575
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 22,987.55914
Overall Steps per Second: 10,752.95053

Timestep Collection Time: 2.17596
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.65175

Cumulative Model Updates: 92,668
Cumulative Timesteps: 772,850,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 772850080...
Checkpoint 772850080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,555.50434
Policy Entropy: 3.64166
Value Function Loss: 0.08164

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.60958
Value Function Update Magnitude: 0.70149

Collected Steps per Second: 22,676.44434
Overall Steps per Second: 10,660.00392

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.69156

Cumulative Model Updates: 92,674
Cumulative Timesteps: 772,900,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,856.70155
Policy Entropy: 3.63954
Value Function Loss: 0.08014

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.59530
Value Function Update Magnitude: 0.70616

Collected Steps per Second: 22,983.86695
Overall Steps per Second: 10,743.98613

Timestep Collection Time: 2.17605
Timestep Consumption Time: 2.47902
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.65507

Cumulative Model Updates: 92,680
Cumulative Timesteps: 772,950,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 772950106...
Checkpoint 772950106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,242.86319
Policy Entropy: 3.61193
Value Function Loss: 0.08711

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.69215

Collected Steps per Second: 22,746.87529
Overall Steps per Second: 10,816.60619

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.62400

Cumulative Model Updates: 92,686
Cumulative Timesteps: 773,000,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,684.32565
Policy Entropy: 3.62552
Value Function Loss: 0.08770

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.50340
Value Function Update Magnitude: 0.69590

Collected Steps per Second: 22,655.44824
Overall Steps per Second: 10,635.75737

Timestep Collection Time: 2.20803
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70338

Cumulative Model Updates: 92,692
Cumulative Timesteps: 773,050,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 773050146...
Checkpoint 773050146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.63889
Policy Entropy: 3.62470
Value Function Loss: 0.08510

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.51731
Value Function Update Magnitude: 0.64654

Collected Steps per Second: 22,619.19295
Overall Steps per Second: 10,661.04647

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.69260

Cumulative Model Updates: 92,698
Cumulative Timesteps: 773,100,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,036.58151
Policy Entropy: 3.65010
Value Function Loss: 0.07936

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.47080
Value Function Update Magnitude: 0.68469

Collected Steps per Second: 23,215.18475
Overall Steps per Second: 10,744.50650

Timestep Collection Time: 2.15488
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.65596

Cumulative Model Updates: 92,704
Cumulative Timesteps: 773,150,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773150200...
Checkpoint 773150200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,931.46408
Policy Entropy: 3.65451
Value Function Loss: 0.07607

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.48046
Value Function Update Magnitude: 0.77411

Collected Steps per Second: 22,245.12470
Overall Steps per Second: 10,660.65478

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.44363
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.69239

Cumulative Model Updates: 92,710
Cumulative Timesteps: 773,200,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.18226
Policy Entropy: 3.65586
Value Function Loss: 0.07372

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.52101
Value Function Update Magnitude: 0.80268

Collected Steps per Second: 22,377.22274
Overall Steps per Second: 10,640.58894

Timestep Collection Time: 2.23558
Timestep Consumption Time: 2.46585
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.70143

Cumulative Model Updates: 92,716
Cumulative Timesteps: 773,250,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773250250...
Checkpoint 773250250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.04899
Policy Entropy: 3.64522
Value Function Loss: 0.07240

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.79969

Collected Steps per Second: 22,217.99234
Overall Steps per Second: 10,522.27802

Timestep Collection Time: 2.25223
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.75562

Cumulative Model Updates: 92,722
Cumulative Timesteps: 773,300,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,216.18861
Policy Entropy: 3.64260
Value Function Loss: 0.07411

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.49424
Value Function Update Magnitude: 0.78849

Collected Steps per Second: 22,591.27897
Overall Steps per Second: 10,757.98831

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.64808

Cumulative Model Updates: 92,728
Cumulative Timesteps: 773,350,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 773350294...
Checkpoint 773350294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,834.65673
Policy Entropy: 3.65551
Value Function Loss: 0.06949

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.48051
Value Function Update Magnitude: 0.77436

Collected Steps per Second: 22,508.11558
Overall Steps per Second: 10,682.43084

Timestep Collection Time: 2.22178
Timestep Consumption Time: 2.45956
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.68133

Cumulative Model Updates: 92,734
Cumulative Timesteps: 773,400,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.11251
Policy Entropy: 3.66694
Value Function Loss: 0.06633

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.48145
Value Function Update Magnitude: 0.77153

Collected Steps per Second: 22,741.08607
Overall Steps per Second: 10,653.21357

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.69511

Cumulative Model Updates: 92,740
Cumulative Timesteps: 773,450,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 773450320...
Checkpoint 773450320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,542.35232
Policy Entropy: 3.68652
Value Function Loss: 0.06140

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.59410
Value Function Update Magnitude: 0.75044

Collected Steps per Second: 22,872.90573
Overall Steps per Second: 10,833.64493

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61765

Cumulative Model Updates: 92,746
Cumulative Timesteps: 773,500,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,455.87408
Policy Entropy: 3.68824
Value Function Loss: 0.06025

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.66947
Value Function Update Magnitude: 0.75475

Collected Steps per Second: 22,888.54353
Overall Steps per Second: 10,886.97574

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.40901
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.59430

Cumulative Model Updates: 92,752
Cumulative Timesteps: 773,550,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 773550364...
Checkpoint 773550364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.48134
Policy Entropy: 3.70487
Value Function Loss: 0.05799

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.65439
Value Function Update Magnitude: 0.74790

Collected Steps per Second: 21,372.77056
Overall Steps per Second: 10,405.99529

Timestep Collection Time: 2.33980
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.80569

Cumulative Model Updates: 92,758
Cumulative Timesteps: 773,600,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.82646
Policy Entropy: 3.70042
Value Function Loss: 0.05624

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.59396
Value Function Update Magnitude: 0.73745

Collected Steps per Second: 22,337.85032
Overall Steps per Second: 10,686.24805

Timestep Collection Time: 2.23952
Timestep Consumption Time: 2.44183
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.68134

Cumulative Model Updates: 92,764
Cumulative Timesteps: 773,650,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773650398...
Checkpoint 773650398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,356.53479
Policy Entropy: 3.71057
Value Function Loss: 0.05514

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.65019
Value Function Update Magnitude: 0.70902

Collected Steps per Second: 21,810.73974
Overall Steps per Second: 10,426.30777

Timestep Collection Time: 2.29291
Timestep Consumption Time: 2.50361
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.79652

Cumulative Model Updates: 92,770
Cumulative Timesteps: 773,700,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,641.60092
Policy Entropy: 3.69033
Value Function Loss: 0.05669

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.69255

Collected Steps per Second: 22,480.24516
Overall Steps per Second: 10,748.56508

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.42800
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.65253

Cumulative Model Updates: 92,776
Cumulative Timesteps: 773,750,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 773750416...
Checkpoint 773750416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,845.57998
Policy Entropy: 3.69331
Value Function Loss: 0.05726

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.53763
Value Function Update Magnitude: 0.69389

Collected Steps per Second: 22,598.41568
Overall Steps per Second: 10,647.18973

Timestep Collection Time: 2.21325
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.69758

Cumulative Model Updates: 92,782
Cumulative Timesteps: 773,800,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,293.27792
Policy Entropy: 3.69278
Value Function Loss: 0.05947

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.67954

Collected Steps per Second: 22,888.62251
Overall Steps per Second: 10,692.72064

Timestep Collection Time: 2.18510
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.67739

Cumulative Model Updates: 92,788
Cumulative Timesteps: 773,850,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 773850446...
Checkpoint 773850446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,422.50739
Policy Entropy: 3.71155
Value Function Loss: 0.05958

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.52120
Value Function Update Magnitude: 0.67729

Collected Steps per Second: 22,883.46169
Overall Steps per Second: 10,901.99761

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.40162
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.58687

Cumulative Model Updates: 92,794
Cumulative Timesteps: 773,900,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.96226
Policy Entropy: 3.71231
Value Function Loss: 0.05989

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.51939
Value Function Update Magnitude: 0.68304

Collected Steps per Second: 22,815.54518
Overall Steps per Second: 10,865.13579

Timestep Collection Time: 2.19254
Timestep Consumption Time: 2.41154
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.60408

Cumulative Model Updates: 92,800
Cumulative Timesteps: 773,950,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 773950476...
Checkpoint 773950476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671.04278
Policy Entropy: 3.71657
Value Function Loss: 0.06193

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.69991

Collected Steps per Second: 22,782.79082
Overall Steps per Second: 10,669.68347

Timestep Collection Time: 2.19552
Timestep Consumption Time: 2.49253
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.68805

Cumulative Model Updates: 92,806
Cumulative Timesteps: 774,000,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.59762
Policy Entropy: 3.69992
Value Function Loss: 0.06506

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.59712
Value Function Update Magnitude: 0.71114

Collected Steps per Second: 23,108.62249
Overall Steps per Second: 10,847.86999

Timestep Collection Time: 2.16473
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61141

Cumulative Model Updates: 92,812
Cumulative Timesteps: 774,050,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 774050520...
Checkpoint 774050520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,046.16980
Policy Entropy: 3.69781
Value Function Loss: 0.06506

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.53189
Value Function Update Magnitude: 0.71925

Collected Steps per Second: 21,964.59563
Overall Steps per Second: 10,602.67431

Timestep Collection Time: 2.27648
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.71598

Cumulative Model Updates: 92,818
Cumulative Timesteps: 774,100,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,007.99779
Policy Entropy: 3.68299
Value Function Loss: 0.06827

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.62960
Value Function Update Magnitude: 0.69532

Collected Steps per Second: 22,495.03720
Overall Steps per Second: 10,550.41256

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.73953

Cumulative Model Updates: 92,824
Cumulative Timesteps: 774,150,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 774150526...
Checkpoint 774150526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.33856
Policy Entropy: 3.68704
Value Function Loss: 0.07030

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.62456

Collected Steps per Second: 22,388.06939
Overall Steps per Second: 10,635.15663

Timestep Collection Time: 2.23476
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.70440

Cumulative Model Updates: 92,830
Cumulative Timesteps: 774,200,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,315.82808
Policy Entropy: 3.69062
Value Function Loss: 0.07465

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.51129
Value Function Update Magnitude: 0.57839

Collected Steps per Second: 22,424.42062
Overall Steps per Second: 10,521.11347

Timestep Collection Time: 2.22980
Timestep Consumption Time: 2.52274
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.75254

Cumulative Model Updates: 92,836
Cumulative Timesteps: 774,250,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 774250560...
Checkpoint 774250560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,914.28661
Policy Entropy: 3.67869
Value Function Loss: 0.07623

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.53305
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 22,471.23042
Overall Steps per Second: 10,554.62953

Timestep Collection Time: 2.22507
Timestep Consumption Time: 2.51219
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.73726

Cumulative Model Updates: 92,842
Cumulative Timesteps: 774,300,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,715.36621
Policy Entropy: 3.66765
Value Function Loss: 0.07678

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.48892
Value Function Update Magnitude: 0.63905

Collected Steps per Second: 22,998.90872
Overall Steps per Second: 10,828.98898

Timestep Collection Time: 2.17489
Timestep Consumption Time: 2.44420
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61908

Cumulative Model Updates: 92,848
Cumulative Timesteps: 774,350,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 774350580...
Checkpoint 774350580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,900.30525
Policy Entropy: 3.65624
Value Function Loss: 0.07968

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.49468
Value Function Update Magnitude: 0.65284

Collected Steps per Second: 22,439.77416
Overall Steps per Second: 10,759.20446

Timestep Collection Time: 2.22845
Timestep Consumption Time: 2.41929
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.64774

Cumulative Model Updates: 92,854
Cumulative Timesteps: 774,400,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,411.83882
Policy Entropy: 3.66727
Value Function Loss: 0.08027

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.46403
Value Function Update Magnitude: 0.64605

Collected Steps per Second: 23,162.30581
Overall Steps per Second: 10,919.58111

Timestep Collection Time: 2.15954
Timestep Consumption Time: 2.42122
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58076

Cumulative Model Updates: 92,860
Cumulative Timesteps: 774,450,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 774450606...
Checkpoint 774450606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,151.56879
Policy Entropy: 3.66974
Value Function Loss: 0.07760

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.47525
Value Function Update Magnitude: 0.69770

Collected Steps per Second: 22,725.17788
Overall Steps per Second: 10,637.25316

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.50026
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.70046

Cumulative Model Updates: 92,866
Cumulative Timesteps: 774,500,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,351.88788
Policy Entropy: 3.67246
Value Function Loss: 0.07371

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.44548
Value Function Update Magnitude: 0.69947

Collected Steps per Second: 23,019.54006
Overall Steps per Second: 10,849.84291

Timestep Collection Time: 2.17320
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.61076

Cumulative Model Updates: 92,872
Cumulative Timesteps: 774,550,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 774550632...
Checkpoint 774550632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,316.74685
Policy Entropy: 3.66151
Value Function Loss: 0.07150

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.44986
Value Function Update Magnitude: 0.62471

Collected Steps per Second: 22,494.35639
Overall Steps per Second: 10,694.13508

Timestep Collection Time: 2.22314
Timestep Consumption Time: 2.45307
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.67621

Cumulative Model Updates: 92,878
Cumulative Timesteps: 774,600,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,681.65737
Policy Entropy: 3.66522
Value Function Loss: 0.07406

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.45392
Value Function Update Magnitude: 0.53803

Collected Steps per Second: 22,560.22724
Overall Steps per Second: 10,635.79232

Timestep Collection Time: 2.21726
Timestep Consumption Time: 2.48591
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.70318

Cumulative Model Updates: 92,884
Cumulative Timesteps: 774,650,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 774650662...
Checkpoint 774650662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212.28403
Policy Entropy: 3.66065
Value Function Loss: 0.07770

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.49903
Value Function Update Magnitude: 0.53920

Collected Steps per Second: 22,610.84707
Overall Steps per Second: 10,794.04826

Timestep Collection Time: 2.21177
Timestep Consumption Time: 2.42134
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.63311

Cumulative Model Updates: 92,890
Cumulative Timesteps: 774,700,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.13462
Policy Entropy: 3.65305
Value Function Loss: 0.07862

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.48658
Value Function Update Magnitude: 0.53394

Collected Steps per Second: 22,275.93771
Overall Steps per Second: 10,559.27738

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.73763

Cumulative Model Updates: 92,896
Cumulative Timesteps: 774,750,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 774750698...
Checkpoint 774750698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,187.38422
Policy Entropy: 3.65485
Value Function Loss: 0.07940

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.49319
Value Function Update Magnitude: 0.57120

Collected Steps per Second: 22,248.74958
Overall Steps per Second: 10,619.77095

Timestep Collection Time: 2.24741
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.70839

Cumulative Model Updates: 92,902
Cumulative Timesteps: 774,800,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,044.28404
Policy Entropy: 3.64993
Value Function Loss: 0.07982

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.61837

Collected Steps per Second: 23,252.53828
Overall Steps per Second: 10,861.57807

Timestep Collection Time: 2.15116
Timestep Consumption Time: 2.45406
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.60522

Cumulative Model Updates: 92,908
Cumulative Timesteps: 774,850,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 774850720...
Checkpoint 774850720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,038.76340
Policy Entropy: 3.66456
Value Function Loss: 0.08054

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.55398
Value Function Update Magnitude: 0.60202

Collected Steps per Second: 22,330.56965
Overall Steps per Second: 10,696.00552

Timestep Collection Time: 2.24043
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.67745

Cumulative Model Updates: 92,914
Cumulative Timesteps: 774,900,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,372.91409
Policy Entropy: 3.66700
Value Function Loss: 0.07968

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.68826

Collected Steps per Second: 22,930.34331
Overall Steps per Second: 10,836.81606

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.43455
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61612

Cumulative Model Updates: 92,920
Cumulative Timesteps: 774,950,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 774950774...
Checkpoint 774950774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,146.36570
Policy Entropy: 3.65975
Value Function Loss: 0.07867

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.77283

Collected Steps per Second: 21,947.50423
Overall Steps per Second: 10,726.54902

Timestep Collection Time: 2.27898
Timestep Consumption Time: 2.38403
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.66301

Cumulative Model Updates: 92,926
Cumulative Timesteps: 775,000,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,768.63294
Policy Entropy: 3.63961
Value Function Loss: 0.07941

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.52413
Value Function Update Magnitude: 0.80702

Collected Steps per Second: 22,565.87471
Overall Steps per Second: 10,880.36331

Timestep Collection Time: 2.21582
Timestep Consumption Time: 2.37979
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.59562

Cumulative Model Updates: 92,932
Cumulative Timesteps: 775,050,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 775050794...
Checkpoint 775050794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,141.69132
Policy Entropy: 3.64116
Value Function Loss: 0.07977

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.46277
Value Function Update Magnitude: 0.77110

Collected Steps per Second: 21,906.73276
Overall Steps per Second: 10,666.31161

Timestep Collection Time: 2.28332
Timestep Consumption Time: 2.40621
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.68953

Cumulative Model Updates: 92,938
Cumulative Timesteps: 775,100,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,780.15526
Policy Entropy: 3.63881
Value Function Loss: 0.08046

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.63228

Collected Steps per Second: 21,798.40217
Overall Steps per Second: 10,439.26938

Timestep Collection Time: 2.29503
Timestep Consumption Time: 2.49726
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.79229

Cumulative Model Updates: 92,944
Cumulative Timesteps: 775,150,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 775150842...
Checkpoint 775150842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,870.44117
Policy Entropy: 3.64267
Value Function Loss: 0.08004

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.47594
Value Function Update Magnitude: 0.61624

Collected Steps per Second: 22,114.41911
Overall Steps per Second: 10,673.63454

Timestep Collection Time: 2.26196
Timestep Consumption Time: 2.42454
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.68650

Cumulative Model Updates: 92,950
Cumulative Timesteps: 775,200,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,019.45714
Policy Entropy: 3.63850
Value Function Loss: 0.08320

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.49437
Value Function Update Magnitude: 0.61323

Collected Steps per Second: 22,840.71491
Overall Steps per Second: 10,852.68572

Timestep Collection Time: 2.18916
Timestep Consumption Time: 2.41818
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.60734

Cumulative Model Updates: 92,956
Cumulative Timesteps: 775,250,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 775250866...
Checkpoint 775250866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,822.80299
Policy Entropy: 3.63268
Value Function Loss: 0.08509

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.61510

Collected Steps per Second: 22,233.14142
Overall Steps per Second: 10,655.39361

Timestep Collection Time: 2.25006
Timestep Consumption Time: 2.44483
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.69490

Cumulative Model Updates: 92,962
Cumulative Timesteps: 775,300,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,235.31436
Policy Entropy: 3.63219
Value Function Loss: 0.08730

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.66049

Collected Steps per Second: 23,084.41650
Overall Steps per Second: 10,649.95726

Timestep Collection Time: 2.16631
Timestep Consumption Time: 2.52930
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.69561

Cumulative Model Updates: 92,968
Cumulative Timesteps: 775,350,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 775350900...
Checkpoint 775350900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,931.07450
Policy Entropy: 3.63622
Value Function Loss: 0.08695

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.52847
Value Function Update Magnitude: 0.66477

Collected Steps per Second: 22,700.34917
Overall Steps per Second: 10,635.02888

Timestep Collection Time: 2.20279
Timestep Consumption Time: 2.49904
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.70182

Cumulative Model Updates: 92,974
Cumulative Timesteps: 775,400,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,546.57912
Policy Entropy: 3.63229
Value Function Loss: 0.08662

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.58334

Collected Steps per Second: 23,050.73443
Overall Steps per Second: 10,680.68016

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.51333
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.68341

Cumulative Model Updates: 92,980
Cumulative Timesteps: 775,450,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 775450926...
Checkpoint 775450926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,867.50455
Policy Entropy: 3.63283
Value Function Loss: 0.08346

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.62111

Collected Steps per Second: 21,277.90369
Overall Steps per Second: 10,266.67386

Timestep Collection Time: 2.35061
Timestep Consumption Time: 2.52108
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.87168

Cumulative Model Updates: 92,986
Cumulative Timesteps: 775,500,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.04480
Policy Entropy: 3.62634
Value Function Loss: 0.08416

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.52218
Value Function Update Magnitude: 0.71194

Collected Steps per Second: 22,733.33949
Overall Steps per Second: 10,770.82171

Timestep Collection Time: 2.19976
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.64291

Cumulative Model Updates: 92,992
Cumulative Timesteps: 775,550,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 775550950...
Checkpoint 775550950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,689.41438
Policy Entropy: 3.62037
Value Function Loss: 0.08391

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.51927
Value Function Update Magnitude: 0.81874

Collected Steps per Second: 22,727.91304
Overall Steps per Second: 10,727.62055

Timestep Collection Time: 2.20064
Timestep Consumption Time: 2.46172
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.66236

Cumulative Model Updates: 92,998
Cumulative Timesteps: 775,600,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,507.91498
Policy Entropy: 3.60682
Value Function Loss: 0.08395

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.51458
Value Function Update Magnitude: 0.81615

Collected Steps per Second: 23,213.89240
Overall Steps per Second: 10,897.13365

Timestep Collection Time: 2.15474
Timestep Consumption Time: 2.43545
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.59020

Cumulative Model Updates: 93,004
Cumulative Timesteps: 775,650,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 775650986...
Checkpoint 775650986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.35932
Policy Entropy: 3.60662
Value Function Loss: 0.08128

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.49608
Value Function Update Magnitude: 0.77902

Collected Steps per Second: 22,128.28966
Overall Steps per Second: 10,643.97246

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.69900

Cumulative Model Updates: 93,010
Cumulative Timesteps: 775,701,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.54734
Policy Entropy: 3.61146
Value Function Loss: 0.07854

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.49223
Value Function Update Magnitude: 0.73947

Collected Steps per Second: 22,705.28560
Overall Steps per Second: 10,610.42360

Timestep Collection Time: 2.20222
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.71254

Cumulative Model Updates: 93,016
Cumulative Timesteps: 775,751,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 775751004...
Checkpoint 775751004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,951.09933
Policy Entropy: 3.62049
Value Function Loss: 0.08085

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.59104
Value Function Update Magnitude: 0.70999

Collected Steps per Second: 22,193.30046
Overall Steps per Second: 10,580.62161

Timestep Collection Time: 2.25374
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.72732

Cumulative Model Updates: 93,022
Cumulative Timesteps: 775,801,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,940.36625
Policy Entropy: 3.61667
Value Function Loss: 0.08380

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.60273
Value Function Update Magnitude: 0.71194

Collected Steps per Second: 22,733.64698
Overall Steps per Second: 10,757.31701

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.44999
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.65060

Cumulative Model Updates: 93,028
Cumulative Timesteps: 775,851,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 775851050...
Checkpoint 775851050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,021.81749
Policy Entropy: 3.62116
Value Function Loss: 0.08683

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.48394
Value Function Update Magnitude: 0.75403

Collected Steps per Second: 22,295.67717
Overall Steps per Second: 10,670.16902

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.68652

Cumulative Model Updates: 93,034
Cumulative Timesteps: 775,901,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,536.28289
Policy Entropy: 3.63816
Value Function Loss: 0.08410

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.44454
Value Function Update Magnitude: 0.75462

Collected Steps per Second: 23,142.89898
Overall Steps per Second: 10,841.78382

Timestep Collection Time: 2.16084
Timestep Consumption Time: 2.45169
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.61253

Cumulative Model Updates: 93,040
Cumulative Timesteps: 775,951,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 775951064...
Checkpoint 775951064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,819.23746
Policy Entropy: 3.63353
Value Function Loss: 0.08412

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.75378

Collected Steps per Second: 22,886.91509
Overall Steps per Second: 10,752.15166

Timestep Collection Time: 2.18535
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.65172

Cumulative Model Updates: 93,046
Cumulative Timesteps: 776,001,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,892.30907
Policy Entropy: 3.63249
Value Function Loss: 0.08273

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.45828
Value Function Update Magnitude: 0.70722

Collected Steps per Second: 22,954.40329
Overall Steps per Second: 10,871.70125

Timestep Collection Time: 2.17849
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.59965

Cumulative Model Updates: 93,052
Cumulative Timesteps: 776,051,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 776051086...
Checkpoint 776051086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,716.29528
Policy Entropy: 3.63076
Value Function Loss: 0.08367

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.46410
Value Function Update Magnitude: 0.69625

Collected Steps per Second: 22,619.64415
Overall Steps per Second: 10,668.71747

Timestep Collection Time: 2.21179
Timestep Consumption Time: 2.47762
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.68941

Cumulative Model Updates: 93,058
Cumulative Timesteps: 776,101,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.93291
Policy Entropy: 3.65071
Value Function Loss: 0.08083

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.47323
Value Function Update Magnitude: 0.70448

Collected Steps per Second: 22,923.25745
Overall Steps per Second: 10,845.20629

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.61236

Cumulative Model Updates: 93,064
Cumulative Timesteps: 776,151,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 776151138...
Checkpoint 776151138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.92215
Policy Entropy: 3.64138
Value Function Loss: 0.07786

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.50297
Value Function Update Magnitude: 0.73789

Collected Steps per Second: 22,637.79675
Overall Steps per Second: 10,720.34580

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.66477

Cumulative Model Updates: 93,070
Cumulative Timesteps: 776,201,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,582.03151
Policy Entropy: 3.62970
Value Function Loss: 0.07969

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.63343

Collected Steps per Second: 22,594.79513
Overall Steps per Second: 10,594.53295

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.50702
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.72036

Cumulative Model Updates: 93,076
Cumulative Timesteps: 776,251,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 776251156...
Checkpoint 776251156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,592.05069
Policy Entropy: 3.61691
Value Function Loss: 0.08314

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.57808
Value Function Update Magnitude: 0.57064

Collected Steps per Second: 22,087.24364
Overall Steps per Second: 10,467.33538

Timestep Collection Time: 2.26429
Timestep Consumption Time: 2.51362
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.77791

Cumulative Model Updates: 93,082
Cumulative Timesteps: 776,301,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,476.66547
Policy Entropy: 3.61957
Value Function Loss: 0.08599

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.57328

Collected Steps per Second: 22,560.72530
Overall Steps per Second: 10,587.90043

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.72502

Cumulative Model Updates: 93,088
Cumulative Timesteps: 776,351,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 776351196...
Checkpoint 776351196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,716.81450
Policy Entropy: 3.62177
Value Function Loss: 0.08602

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.60518

Collected Steps per Second: 22,017.63665
Overall Steps per Second: 10,546.88561

Timestep Collection Time: 2.27100
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.74093

Cumulative Model Updates: 93,094
Cumulative Timesteps: 776,401,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,231.12888
Policy Entropy: 3.63227
Value Function Loss: 0.08701

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.60638

Collected Steps per Second: 22,652.51985
Overall Steps per Second: 10,575.18971

Timestep Collection Time: 2.20779
Timestep Consumption Time: 2.52139
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.72918

Cumulative Model Updates: 93,100
Cumulative Timesteps: 776,451,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 776451210...
Checkpoint 776451210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,611.19688
Policy Entropy: 3.63094
Value Function Loss: 0.08614

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.61401

Collected Steps per Second: 22,696.71698
Overall Steps per Second: 10,496.57305

Timestep Collection Time: 2.20402
Timestep Consumption Time: 2.56173
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.76575

Cumulative Model Updates: 93,106
Cumulative Timesteps: 776,501,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,129.57138
Policy Entropy: 3.63033
Value Function Loss: 0.08683

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.66707

Collected Steps per Second: 23,148.78209
Overall Steps per Second: 10,817.71272

Timestep Collection Time: 2.16167
Timestep Consumption Time: 2.46408
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62575

Cumulative Model Updates: 93,112
Cumulative Timesteps: 776,551,274

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 776551274...
Checkpoint 776551274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,621.22639
Policy Entropy: 3.62795
Value Function Loss: 0.08403

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.49472
Value Function Update Magnitude: 0.70916

Collected Steps per Second: 22,635.89754
Overall Steps per Second: 10,727.87437

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.66169

Cumulative Model Updates: 93,118
Cumulative Timesteps: 776,601,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,766.39832
Policy Entropy: 3.62479
Value Function Loss: 0.08177

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.51444
Value Function Update Magnitude: 0.71829

Collected Steps per Second: 22,918.78157
Overall Steps per Second: 10,829.45895

Timestep Collection Time: 2.18223
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.61833

Cumulative Model Updates: 93,124
Cumulative Timesteps: 776,651,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 776651298...
Checkpoint 776651298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,222.59892
Policy Entropy: 3.62327
Value Function Loss: 0.08021

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.55952
Value Function Update Magnitude: 0.67882

Collected Steps per Second: 22,616.73140
Overall Steps per Second: 10,697.38041

Timestep Collection Time: 2.21075
Timestep Consumption Time: 2.46329
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.67404

Cumulative Model Updates: 93,130
Cumulative Timesteps: 776,701,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,566.23597
Policy Entropy: 3.62304
Value Function Loss: 0.07833

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.57991
Value Function Update Magnitude: 0.65791

Collected Steps per Second: 23,179.83135
Overall Steps per Second: 10,902.64513

Timestep Collection Time: 2.15713
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.58623

Cumulative Model Updates: 93,136
Cumulative Timesteps: 776,751,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 776751300...
Checkpoint 776751300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,529.98143
Policy Entropy: 3.63101
Value Function Loss: 0.07983

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.16408
Policy Update Magnitude: 0.52000
Value Function Update Magnitude: 0.71996

Collected Steps per Second: 22,250.90963
Overall Steps per Second: 10,733.09866

Timestep Collection Time: 2.24791
Timestep Consumption Time: 2.41226
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.66016

Cumulative Model Updates: 93,142
Cumulative Timesteps: 776,801,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.28552
Policy Entropy: 3.63679
Value Function Loss: 0.08337

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.39854
Value Function Update Magnitude: 0.77199

Collected Steps per Second: 22,727.41627
Overall Steps per Second: 10,775.46720

Timestep Collection Time: 2.20087
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.64203

Cumulative Model Updates: 93,148
Cumulative Timesteps: 776,851,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 776851338...
Checkpoint 776851338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,008.36343
Policy Entropy: 3.64659
Value Function Loss: 0.08621

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.46378
Value Function Update Magnitude: 0.74103

Collected Steps per Second: 21,893.10109
Overall Steps per Second: 10,444.76577

Timestep Collection Time: 2.28474
Timestep Consumption Time: 2.50426
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.78900

Cumulative Model Updates: 93,154
Cumulative Timesteps: 776,901,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,564.94117
Policy Entropy: 3.64521
Value Function Loss: 0.08492

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.58034
Value Function Update Magnitude: 0.65858

Collected Steps per Second: 22,640.49579
Overall Steps per Second: 10,790.80475

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.42669
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.63654

Cumulative Model Updates: 93,160
Cumulative Timesteps: 776,951,390

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 776951390...
Checkpoint 776951390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,288.30392
Policy Entropy: 3.65422
Value Function Loss: 0.08160

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.62066
Value Function Update Magnitude: 0.68177

Collected Steps per Second: 22,433.48037
Overall Steps per Second: 10,576.83918

Timestep Collection Time: 2.22908
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.72788

Cumulative Model Updates: 93,166
Cumulative Timesteps: 777,001,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,752.00628
Policy Entropy: 3.65211
Value Function Loss: 0.08062

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.65549
Value Function Update Magnitude: 0.71968

Collected Steps per Second: 23,096.14832
Overall Steps per Second: 10,872.60598

Timestep Collection Time: 2.16538
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59982

Cumulative Model Updates: 93,172
Cumulative Timesteps: 777,051,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 777051408...
Checkpoint 777051408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,498.09854
Policy Entropy: 3.63562
Value Function Loss: 0.08264

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.65266
Value Function Update Magnitude: 0.78487

Collected Steps per Second: 22,320.67271
Overall Steps per Second: 10,729.05850

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.66304

Cumulative Model Updates: 93,178
Cumulative Timesteps: 777,101,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.19023
Policy Entropy: 3.62374
Value Function Loss: 0.08396

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.78238

Collected Steps per Second: 22,245.76672
Overall Steps per Second: 10,867.45794

Timestep Collection Time: 2.24870
Timestep Consumption Time: 2.35440
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60310

Cumulative Model Updates: 93,184
Cumulative Timesteps: 777,151,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 777151462...
Checkpoint 777151462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.94668
Policy Entropy: 3.61694
Value Function Loss: 0.08866

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.68966

Collected Steps per Second: 22,191.88572
Overall Steps per Second: 10,689.64038

Timestep Collection Time: 2.25398
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.67930

Cumulative Model Updates: 93,190
Cumulative Timesteps: 777,201,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.64405
Policy Entropy: 3.61643
Value Function Loss: 0.08972

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.56167
Value Function Update Magnitude: 0.58855

Collected Steps per Second: 22,403.69841
Overall Steps per Second: 10,926.28253

Timestep Collection Time: 2.23231
Timestep Consumption Time: 2.34491
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.57722

Cumulative Model Updates: 93,196
Cumulative Timesteps: 777,251,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 777251494...
Checkpoint 777251494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,621.82988
Policy Entropy: 3.60784
Value Function Loss: 0.09085

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.56885

Collected Steps per Second: 21,645.46005
Overall Steps per Second: 10,598.87748

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.40820
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.71880

Cumulative Model Updates: 93,202
Cumulative Timesteps: 777,301,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,390.96593
Policy Entropy: 3.60964
Value Function Loss: 0.08569

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.44852
Value Function Update Magnitude: 0.59842

Collected Steps per Second: 22,016.45579
Overall Steps per Second: 10,803.20207

Timestep Collection Time: 2.27221
Timestep Consumption Time: 2.35845
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.63066

Cumulative Model Updates: 93,208
Cumulative Timesteps: 777,351,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 777351534...
Checkpoint 777351534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,819.08680
Policy Entropy: 3.62076
Value Function Loss: 0.08022

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.44180
Value Function Update Magnitude: 0.60987

Collected Steps per Second: 21,492.68831
Overall Steps per Second: 10,323.51657

Timestep Collection Time: 2.32647
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.84350

Cumulative Model Updates: 93,214
Cumulative Timesteps: 777,401,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.23089
Policy Entropy: 3.63995
Value Function Loss: 0.07695

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06269
Policy Update Magnitude: 0.58953
Value Function Update Magnitude: 0.61480

Collected Steps per Second: 22,942.50887
Overall Steps per Second: 10,833.89543

Timestep Collection Time: 2.18006
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61662

Cumulative Model Updates: 93,220
Cumulative Timesteps: 777,451,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 777451552...
Checkpoint 777451552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,232.72579
Policy Entropy: 3.64665
Value Function Loss: 0.07680

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.71120
Value Function Update Magnitude: 0.63086

Collected Steps per Second: 22,620.17289
Overall Steps per Second: 10,687.16359

Timestep Collection Time: 2.21121
Timestep Consumption Time: 2.46898
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.68019

Cumulative Model Updates: 93,226
Cumulative Timesteps: 777,501,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,902.06932
Policy Entropy: 3.65642
Value Function Loss: 0.07729

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.66996
Value Function Update Magnitude: 0.70365

Collected Steps per Second: 23,020.66950
Overall Steps per Second: 10,954.10126

Timestep Collection Time: 2.17300
Timestep Consumption Time: 2.39369
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.56669

Cumulative Model Updates: 93,232
Cumulative Timesteps: 777,551,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 777551594...
Checkpoint 777551594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,866.74479
Policy Entropy: 3.63236
Value Function Loss: 0.07590

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.72818
Value Function Update Magnitude: 0.69936

Collected Steps per Second: 22,572.26829
Overall Steps per Second: 10,680.87024

Timestep Collection Time: 2.21582
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68276

Cumulative Model Updates: 93,238
Cumulative Timesteps: 777,601,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,496.05217
Policy Entropy: 3.63489
Value Function Loss: 0.07598

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.77491
Value Function Update Magnitude: 0.68152

Collected Steps per Second: 22,933.16795
Overall Steps per Second: 10,802.75034

Timestep Collection Time: 2.18129
Timestep Consumption Time: 2.44938
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.63067

Cumulative Model Updates: 93,244
Cumulative Timesteps: 777,651,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 777651634...
Checkpoint 777651634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,876.74227
Policy Entropy: 3.62907
Value Function Loss: 0.07416

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.67128
Value Function Update Magnitude: 0.76674

Collected Steps per Second: 22,745.39511
Overall Steps per Second: 10,649.13063

Timestep Collection Time: 2.19869
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.69616

Cumulative Model Updates: 93,250
Cumulative Timesteps: 777,701,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,694.82797
Policy Entropy: 3.64314
Value Function Loss: 0.07511

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.69147
Value Function Update Magnitude: 0.77126

Collected Steps per Second: 23,052.67222
Overall Steps per Second: 10,864.08430

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60471

Cumulative Model Updates: 93,256
Cumulative Timesteps: 777,751,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 777751670...
Checkpoint 777751670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,995.75299
Policy Entropy: 3.66581
Value Function Loss: 0.07320

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.62736
Value Function Update Magnitude: 0.68759

Collected Steps per Second: 22,054.42762
Overall Steps per Second: 10,649.36419

Timestep Collection Time: 2.26748
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.69587

Cumulative Model Updates: 93,262
Cumulative Timesteps: 777,801,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,433.29047
Policy Entropy: 3.65434
Value Function Loss: 0.07683

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.55387
Value Function Update Magnitude: 0.69103

Collected Steps per Second: 22,267.43785
Overall Steps per Second: 10,523.50403

Timestep Collection Time: 2.24588
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.75222

Cumulative Model Updates: 93,268
Cumulative Timesteps: 777,851,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 777851688...
Checkpoint 777851688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,007.67845
Policy Entropy: 3.64704
Value Function Loss: 0.07622

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.53271
Value Function Update Magnitude: 0.70375

Collected Steps per Second: 22,340.06311
Overall Steps per Second: 10,642.43252

Timestep Collection Time: 2.23938
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.70081

Cumulative Model Updates: 93,274
Cumulative Timesteps: 777,901,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.95223
Policy Entropy: 3.63768
Value Function Loss: 0.07788

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.56388
Value Function Update Magnitude: 0.72501

Collected Steps per Second: 22,830.56348
Overall Steps per Second: 10,822.20238

Timestep Collection Time: 2.19048
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.62106

Cumulative Model Updates: 93,280
Cumulative Timesteps: 777,951,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 777951726...
Checkpoint 777951726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,077.89122
Policy Entropy: 3.64687
Value Function Loss: 0.07705

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.53564
Value Function Update Magnitude: 0.69780

Collected Steps per Second: 22,699.90262
Overall Steps per Second: 10,703.65181

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.67373

Cumulative Model Updates: 93,286
Cumulative Timesteps: 778,001,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,254.67353
Policy Entropy: 3.65212
Value Function Loss: 0.07788

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.49533
Value Function Update Magnitude: 0.69428

Collected Steps per Second: 23,325.90268
Overall Steps per Second: 10,893.69674

Timestep Collection Time: 2.14423
Timestep Consumption Time: 2.44705
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.59128

Cumulative Model Updates: 93,292
Cumulative Timesteps: 778,051,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 778051768...
Checkpoint 778051768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,049.46402
Policy Entropy: 3.66272
Value Function Loss: 0.07759

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.76550

Collected Steps per Second: 22,714.73570
Overall Steps per Second: 10,672.64741

Timestep Collection Time: 2.20148
Timestep Consumption Time: 2.48396
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.68544

Cumulative Model Updates: 93,298
Cumulative Timesteps: 778,101,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,316.53001
Policy Entropy: 3.66696
Value Function Loss: 0.07627

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.61905
Value Function Update Magnitude: 0.77924

Collected Steps per Second: 22,747.72302
Overall Steps per Second: 10,640.08741

Timestep Collection Time: 2.19890
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.70109

Cumulative Model Updates: 93,304
Cumulative Timesteps: 778,151,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 778151794...
Checkpoint 778151794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,494.65033
Policy Entropy: 3.65428
Value Function Loss: 0.07857

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.62983
Value Function Update Magnitude: 0.77305

Collected Steps per Second: 22,721.16432
Overall Steps per Second: 10,823.62425

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.41913
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61989

Cumulative Model Updates: 93,310
Cumulative Timesteps: 778,201,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.62465
Policy Entropy: 3.65334
Value Function Loss: 0.07893

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.76082

Collected Steps per Second: 23,133.84116
Overall Steps per Second: 10,883.94165

Timestep Collection Time: 2.16160
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59448

Cumulative Model Updates: 93,316
Cumulative Timesteps: 778,251,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 778251804...
Checkpoint 778251804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.45047
Policy Entropy: 3.64154
Value Function Loss: 0.07923

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.51877
Value Function Update Magnitude: 0.82714

Collected Steps per Second: 22,179.17165
Overall Steps per Second: 10,726.05572

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.66546

Cumulative Model Updates: 93,322
Cumulative Timesteps: 778,301,846

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.89843
Policy Entropy: 3.63899
Value Function Loss: 0.07967

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.47134
Value Function Update Magnitude: 0.90267

Collected Steps per Second: 22,778.34000
Overall Steps per Second: 10,716.40938

Timestep Collection Time: 2.19603
Timestep Consumption Time: 2.47176
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.66779

Cumulative Model Updates: 93,328
Cumulative Timesteps: 778,351,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 778351868...
Checkpoint 778351868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.04510
Policy Entropy: 3.63668
Value Function Loss: 0.08007

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.48764
Value Function Update Magnitude: 0.92594

Collected Steps per Second: 22,303.72355
Overall Steps per Second: 10,785.61529

Timestep Collection Time: 2.24223
Timestep Consumption Time: 2.39450
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.63673

Cumulative Model Updates: 93,334
Cumulative Timesteps: 778,401,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,947.20141
Policy Entropy: 3.63991
Value Function Loss: 0.07771

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.55937
Value Function Update Magnitude: 0.92741

Collected Steps per Second: 23,065.87539
Overall Steps per Second: 10,645.91685

Timestep Collection Time: 2.16857
Timestep Consumption Time: 2.52994
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.69852

Cumulative Model Updates: 93,340
Cumulative Timesteps: 778,451,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 778451898...
Checkpoint 778451898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,941.03030
Policy Entropy: 3.63703
Value Function Loss: 0.07630

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.61056
Value Function Update Magnitude: 0.85716

Collected Steps per Second: 22,614.21235
Overall Steps per Second: 10,579.55899

Timestep Collection Time: 2.21197
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.72817

Cumulative Model Updates: 93,346
Cumulative Timesteps: 778,501,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.29962
Policy Entropy: 3.65072
Value Function Loss: 0.07679

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.58893
Value Function Update Magnitude: 0.76345

Collected Steps per Second: 23,154.37730
Overall Steps per Second: 10,886.68817

Timestep Collection Time: 2.16054
Timestep Consumption Time: 2.43461
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.59515

Cumulative Model Updates: 93,352
Cumulative Timesteps: 778,551,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 778551946...
Checkpoint 778551946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,351.00873
Policy Entropy: 3.64937
Value Function Loss: 0.07954

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.58336
Value Function Update Magnitude: 0.83206

Collected Steps per Second: 22,560.13416
Overall Steps per Second: 10,665.31763

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.69034

Cumulative Model Updates: 93,358
Cumulative Timesteps: 778,601,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,918.96055
Policy Entropy: 3.64408
Value Function Loss: 0.08246

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.63017
Value Function Update Magnitude: 0.89309

Collected Steps per Second: 23,177.50960
Overall Steps per Second: 10,809.56278

Timestep Collection Time: 2.15813
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.62738

Cumulative Model Updates: 93,364
Cumulative Timesteps: 778,651,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 778651990...
Checkpoint 778651990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,636.65247
Policy Entropy: 3.63554
Value Function Loss: 0.08402

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.65828
Value Function Update Magnitude: 0.90708

Collected Steps per Second: 22,645.18266
Overall Steps per Second: 10,653.25764

Timestep Collection Time: 2.20833
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.69415

Cumulative Model Updates: 93,370
Cumulative Timesteps: 778,701,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,966.72837
Policy Entropy: 3.62623
Value Function Loss: 0.08631

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.59307
Value Function Update Magnitude: 0.77688

Collected Steps per Second: 22,932.30817
Overall Steps per Second: 10,777.65560

Timestep Collection Time: 2.18216
Timestep Consumption Time: 2.46096
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.64312

Cumulative Model Updates: 93,376
Cumulative Timesteps: 778,752,040

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 778752040...
Checkpoint 778752040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,275.19707
Policy Entropy: 3.61765
Value Function Loss: 0.08902

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.51935
Value Function Update Magnitude: 0.69039

Collected Steps per Second: 22,240.36080
Overall Steps per Second: 10,711.00284

Timestep Collection Time: 2.24861
Timestep Consumption Time: 2.42042
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.66903

Cumulative Model Updates: 93,382
Cumulative Timesteps: 778,802,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,580.94558
Policy Entropy: 3.62321
Value Function Loss: 0.09105

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.48227
Value Function Update Magnitude: 0.65463

Collected Steps per Second: 22,282.19771
Overall Steps per Second: 10,510.55031

Timestep Collection Time: 2.24421
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.75770

Cumulative Model Updates: 93,388
Cumulative Timesteps: 778,852,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 778852056...
Checkpoint 778852056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,001.09512
Policy Entropy: 3.62885
Value Function Loss: 0.09182

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.57878
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 22,148.28440
Overall Steps per Second: 10,680.78871

Timestep Collection Time: 2.25832
Timestep Consumption Time: 2.42466
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.68299

Cumulative Model Updates: 93,394
Cumulative Timesteps: 778,902,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,540.99191
Policy Entropy: 3.63494
Value Function Loss: 0.08930

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.58818
Value Function Update Magnitude: 0.59557

Collected Steps per Second: 23,073.20451
Overall Steps per Second: 10,866.41378

Timestep Collection Time: 2.16771
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60281

Cumulative Model Updates: 93,400
Cumulative Timesteps: 778,952,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 778952090...
Checkpoint 778952090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,016.66769
Policy Entropy: 3.62311
Value Function Loss: 0.08819

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.68197
Value Function Update Magnitude: 0.59842

Collected Steps per Second: 22,735.63959
Overall Steps per Second: 10,662.17453

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.69229

Cumulative Model Updates: 93,406
Cumulative Timesteps: 779,002,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,680.28298
Policy Entropy: 3.61792
Value Function Loss: 0.08612

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.17225
Policy Update Magnitude: 0.63363
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 23,063.04306
Overall Steps per Second: 10,808.94089

Timestep Collection Time: 2.16875
Timestep Consumption Time: 2.45871
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62747

Cumulative Model Updates: 93,412
Cumulative Timesteps: 779,052,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 779052138...
Checkpoint 779052138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,320.83331
Policy Entropy: 3.60831
Value Function Loss: 0.08741

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.51930
Value Function Update Magnitude: 0.59557

Collected Steps per Second: 22,589.05543
Overall Steps per Second: 10,724.65673

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.44997
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.66458

Cumulative Model Updates: 93,418
Cumulative Timesteps: 779,102,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.42318
Policy Entropy: 3.61526
Value Function Loss: 0.08676

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.50576
Value Function Update Magnitude: 0.57957

Collected Steps per Second: 23,186.58833
Overall Steps per Second: 10,909.55544

Timestep Collection Time: 2.15685
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58405

Cumulative Model Updates: 93,424
Cumulative Timesteps: 779,152,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 779152174...
Checkpoint 779152174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,179.52909
Policy Entropy: 3.61105
Value Function Loss: 0.08366

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.67163

Collected Steps per Second: 22,034.75506
Overall Steps per Second: 10,651.97804

Timestep Collection Time: 2.26951
Timestep Consumption Time: 2.42521
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.69471

Cumulative Model Updates: 93,430
Cumulative Timesteps: 779,202,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,252.59563
Policy Entropy: 3.61994
Value Function Loss: 0.08074

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.65602
Value Function Update Magnitude: 0.74478

Collected Steps per Second: 22,968.60914
Overall Steps per Second: 10,856.17886

Timestep Collection Time: 2.17723
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60641

Cumulative Model Updates: 93,436
Cumulative Timesteps: 779,252,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 779252190...
Checkpoint 779252190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,226.87056
Policy Entropy: 3.61446
Value Function Loss: 0.07866

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.71097
Value Function Update Magnitude: 0.72872

Collected Steps per Second: 22,163.28660
Overall Steps per Second: 10,694.24630

Timestep Collection Time: 2.25598
Timestep Consumption Time: 2.41943
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.67541

Cumulative Model Updates: 93,442
Cumulative Timesteps: 779,302,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,369.79543
Policy Entropy: 3.60902
Value Function Loss: 0.07755

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.73502
Value Function Update Magnitude: 0.71782

Collected Steps per Second: 20,587.50676
Overall Steps per Second: 10,425.45291

Timestep Collection Time: 2.42914
Timestep Consumption Time: 2.36777
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.79691

Cumulative Model Updates: 93,448
Cumulative Timesteps: 779,352,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 779352200...
Checkpoint 779352200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,526.44140
Policy Entropy: 3.61700
Value Function Loss: 0.07738

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.68754
Value Function Update Magnitude: 0.73239

Collected Steps per Second: 21,433.56448
Overall Steps per Second: 10,641.91340

Timestep Collection Time: 2.33382
Timestep Consumption Time: 2.36665
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70047

Cumulative Model Updates: 93,454
Cumulative Timesteps: 779,402,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,222.92105
Policy Entropy: 3.61305
Value Function Loss: 0.07898

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.56954
Value Function Update Magnitude: 0.65704

Collected Steps per Second: 21,961.79698
Overall Steps per Second: 10,642.47834

Timestep Collection Time: 2.27705
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.69891

Cumulative Model Updates: 93,460
Cumulative Timesteps: 779,452,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 779452230...
Checkpoint 779452230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,899.77429
Policy Entropy: 3.62876
Value Function Loss: 0.07830

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.52018
Value Function Update Magnitude: 0.63584

Collected Steps per Second: 22,135.55494
Overall Steps per Second: 10,688.89668

Timestep Collection Time: 2.25998
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.68018

Cumulative Model Updates: 93,466
Cumulative Timesteps: 779,502,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,340.40450
Policy Entropy: 3.60787
Value Function Loss: 0.07947

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.49215
Value Function Update Magnitude: 0.64186

Collected Steps per Second: 22,345.67887
Overall Steps per Second: 10,646.01572

Timestep Collection Time: 2.23837
Timestep Consumption Time: 2.45991
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.69828

Cumulative Model Updates: 93,472
Cumulative Timesteps: 779,552,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 779552274...
Checkpoint 779552274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,737.22687
Policy Entropy: 3.62091
Value Function Loss: 0.07728

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.45979
Value Function Update Magnitude: 0.70612

Collected Steps per Second: 22,120.03722
Overall Steps per Second: 10,751.42746

Timestep Collection Time: 2.26139
Timestep Consumption Time: 2.39120
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.65259

Cumulative Model Updates: 93,478
Cumulative Timesteps: 779,602,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,774.64337
Policy Entropy: 3.62264
Value Function Loss: 0.07989

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.52422
Value Function Update Magnitude: 0.74432

Collected Steps per Second: 23,136.05234
Overall Steps per Second: 10,828.22614

Timestep Collection Time: 2.16156
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.61849

Cumulative Model Updates: 93,484
Cumulative Timesteps: 779,652,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 779652306...
Checkpoint 779652306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,552.69118
Policy Entropy: 3.63362
Value Function Loss: 0.08002

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.80063

Collected Steps per Second: 22,585.84892
Overall Steps per Second: 10,616.77475

Timestep Collection Time: 2.21422
Timestep Consumption Time: 2.49625
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.71047

Cumulative Model Updates: 93,490
Cumulative Timesteps: 779,702,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,377.73358
Policy Entropy: 3.62863
Value Function Loss: 0.08401

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.57494
Value Function Update Magnitude: 0.80211

Collected Steps per Second: 23,127.84715
Overall Steps per Second: 10,934.44713

Timestep Collection Time: 2.16293
Timestep Consumption Time: 2.41197
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.57490

Cumulative Model Updates: 93,496
Cumulative Timesteps: 779,752,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 779752340...
Checkpoint 779752340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923.87645
Policy Entropy: 3.63410
Value Function Loss: 0.08303

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.50210
Value Function Update Magnitude: 0.81945

Collected Steps per Second: 22,197.06460
Overall Steps per Second: 10,645.38804

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.69725

Cumulative Model Updates: 93,502
Cumulative Timesteps: 779,802,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,390.52879
Policy Entropy: 3.61340
Value Function Loss: 0.08640

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.46046
Value Function Update Magnitude: 0.80205

Collected Steps per Second: 22,793.05396
Overall Steps per Second: 10,856.14355

Timestep Collection Time: 2.19374
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60587

Cumulative Model Updates: 93,508
Cumulative Timesteps: 779,852,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 779852346...
Checkpoint 779852346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.70500
Policy Entropy: 3.62151
Value Function Loss: 0.08679

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.43064
Value Function Update Magnitude: 0.73820

Collected Steps per Second: 22,067.25922
Overall Steps per Second: 10,718.98423

Timestep Collection Time: 2.26698
Timestep Consumption Time: 2.40007
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.66705

Cumulative Model Updates: 93,514
Cumulative Timesteps: 779,902,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,635.66869
Policy Entropy: 3.61765
Value Function Loss: 0.08647

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.46555
Value Function Update Magnitude: 0.69420

Collected Steps per Second: 22,616.37242
Overall Steps per Second: 10,808.43209

Timestep Collection Time: 2.21194
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62842

Cumulative Model Updates: 93,520
Cumulative Timesteps: 779,952,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 779952398...
Checkpoint 779952398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,994.60048
Policy Entropy: 3.62903
Value Function Loss: 0.08393

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.52222
Value Function Update Magnitude: 0.68070

Collected Steps per Second: 22,656.49076
Overall Steps per Second: 10,717.17070

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.45893
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.66616

Cumulative Model Updates: 93,526
Cumulative Timesteps: 780,002,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.40984
Policy Entropy: 3.61712
Value Function Loss: 0.08770

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.51090
Value Function Update Magnitude: 0.68519

Collected Steps per Second: 23,212.24468
Overall Steps per Second: 10,823.43147

Timestep Collection Time: 2.15524
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.62219

Cumulative Model Updates: 93,532
Cumulative Timesteps: 780,052,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 780052434...
Checkpoint 780052434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.00553
Policy Entropy: 3.61568
Value Function Loss: 0.08860

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.42033
Value Function Update Magnitude: 0.64530

Collected Steps per Second: 22,515.26679
Overall Steps per Second: 10,742.17469

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.65772

Cumulative Model Updates: 93,538
Cumulative Timesteps: 780,102,468

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,891.58676
Policy Entropy: 3.62795
Value Function Loss: 0.08786

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.47871
Value Function Update Magnitude: 0.61468

Collected Steps per Second: 23,089.21444
Overall Steps per Second: 10,900.72529

Timestep Collection Time: 2.16569
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.58722

Cumulative Model Updates: 93,544
Cumulative Timesteps: 780,152,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 780152472...
Checkpoint 780152472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,193.34049
Policy Entropy: 3.64502
Value Function Loss: 0.08084

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.47757
Value Function Update Magnitude: 0.71338

Collected Steps per Second: 22,763.20721
Overall Steps per Second: 10,612.15534

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.51565
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.71271

Cumulative Model Updates: 93,550
Cumulative Timesteps: 780,202,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,894.25043
Policy Entropy: 3.65604
Value Function Loss: 0.07689

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.43315
Value Function Update Magnitude: 0.77324

Collected Steps per Second: 22,960.13626
Overall Steps per Second: 10,851.50704

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.43094
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60950

Cumulative Model Updates: 93,556
Cumulative Timesteps: 780,252,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 780252504...
Checkpoint 780252504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,562.99162
Policy Entropy: 3.65933
Value Function Loss: 0.07503

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.43440
Value Function Update Magnitude: 0.72472

Collected Steps per Second: 22,041.21301
Overall Steps per Second: 10,654.38534

Timestep Collection Time: 2.26966
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.69534

Cumulative Model Updates: 93,562
Cumulative Timesteps: 780,302,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,259.11303
Policy Entropy: 3.65865
Value Function Loss: 0.07356

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.44100
Value Function Update Magnitude: 0.68333

Collected Steps per Second: 22,590.04409
Overall Steps per Second: 10,606.73313

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71493

Cumulative Model Updates: 93,568
Cumulative Timesteps: 780,352,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 780352540...
Checkpoint 780352540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,976.11673
Policy Entropy: 3.66277
Value Function Loss: 0.07109

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.46544
Value Function Update Magnitude: 0.72748

Collected Steps per Second: 22,262.33194
Overall Steps per Second: 10,581.33664

Timestep Collection Time: 2.24711
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.72776

Cumulative Model Updates: 93,574
Cumulative Timesteps: 780,402,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,679.34410
Policy Entropy: 3.66659
Value Function Loss: 0.07177

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.50190
Value Function Update Magnitude: 0.76681

Collected Steps per Second: 22,431.89948
Overall Steps per Second: 10,562.93230

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.73637

Cumulative Model Updates: 93,580
Cumulative Timesteps: 780,452,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 780452596...
Checkpoint 780452596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,243.54098
Policy Entropy: 3.66408
Value Function Loss: 0.07358

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.51307
Value Function Update Magnitude: 0.83849

Collected Steps per Second: 22,257.91073
Overall Steps per Second: 10,525.78314

Timestep Collection Time: 2.24666
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.75081

Cumulative Model Updates: 93,586
Cumulative Timesteps: 780,502,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,156.88179
Policy Entropy: 3.66733
Value Function Loss: 0.07404

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.51096
Value Function Update Magnitude: 0.84879

Collected Steps per Second: 21,988.07794
Overall Steps per Second: 10,424.35429

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.79857

Cumulative Model Updates: 93,592
Cumulative Timesteps: 780,552,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 780552624...
Checkpoint 780552624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.73302
Policy Entropy: 3.67612
Value Function Loss: 0.06909

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.50479
Value Function Update Magnitude: 0.81276

Collected Steps per Second: 22,527.33019
Overall Steps per Second: 10,665.49561

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.68820

Cumulative Model Updates: 93,598
Cumulative Timesteps: 780,602,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,868.19893
Policy Entropy: 3.68168
Value Function Loss: 0.06867

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.57262
Value Function Update Magnitude: 0.76783

Collected Steps per Second: 23,189.56182
Overall Steps per Second: 10,898.36445

Timestep Collection Time: 2.15632
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58821

Cumulative Model Updates: 93,604
Cumulative Timesteps: 780,652,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 780652630...
Checkpoint 780652630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,783.68438
Policy Entropy: 3.67058
Value Function Loss: 0.07132

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.61723
Value Function Update Magnitude: 0.76183

Collected Steps per Second: 22,329.59881
Overall Steps per Second: 10,656.17985

Timestep Collection Time: 2.23918
Timestep Consumption Time: 2.45293
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.69211

Cumulative Model Updates: 93,610
Cumulative Timesteps: 780,702,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,438.36922
Policy Entropy: 3.65809
Value Function Loss: 0.07534

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.81884

Collected Steps per Second: 23,085.56083
Overall Steps per Second: 10,882.36017

Timestep Collection Time: 2.16768
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.59845

Cumulative Model Updates: 93,616
Cumulative Timesteps: 780,752,672

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 780752672...
Checkpoint 780752672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,309.23142
Policy Entropy: 3.62642
Value Function Loss: 0.07986

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.47891
Value Function Update Magnitude: 0.80469

Collected Steps per Second: 22,825.72325
Overall Steps per Second: 10,648.85588

Timestep Collection Time: 2.19183
Timestep Consumption Time: 2.50633
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.69816

Cumulative Model Updates: 93,622
Cumulative Timesteps: 780,802,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.60084
Policy Entropy: 3.61937
Value Function Loss: 0.08219

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.51822
Value Function Update Magnitude: 0.70553

Collected Steps per Second: 23,166.24565
Overall Steps per Second: 10,888.56712

Timestep Collection Time: 2.15883
Timestep Consumption Time: 2.43424
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59307

Cumulative Model Updates: 93,628
Cumulative Timesteps: 780,852,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 780852714...
Checkpoint 780852714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,665.11563
Policy Entropy: 3.61764
Value Function Loss: 0.08285

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.48729
Value Function Update Magnitude: 0.66365

Collected Steps per Second: 21,698.78215
Overall Steps per Second: 10,646.17396

Timestep Collection Time: 2.30455
Timestep Consumption Time: 2.39253
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.69709

Cumulative Model Updates: 93,634
Cumulative Timesteps: 780,902,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,506.20612
Policy Entropy: 3.63749
Value Function Loss: 0.07933

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.47608
Value Function Update Magnitude: 0.72184

Collected Steps per Second: 21,810.28029
Overall Steps per Second: 10,594.87704

Timestep Collection Time: 2.29387
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.72209

Cumulative Model Updates: 93,640
Cumulative Timesteps: 780,952,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 780952750...
Checkpoint 780952750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,365.58447
Policy Entropy: 3.64727
Value Function Loss: 0.07997

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.41091
Value Function Update Magnitude: 0.80697

Collected Steps per Second: 21,805.74183
Overall Steps per Second: 10,597.91025

Timestep Collection Time: 2.29325
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.71848

Cumulative Model Updates: 93,646
Cumulative Timesteps: 781,002,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,767.32556
Policy Entropy: 3.64745
Value Function Loss: 0.08110

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.45015
Value Function Update Magnitude: 0.86347

Collected Steps per Second: 22,524.70194
Overall Steps per Second: 10,802.95093

Timestep Collection Time: 2.21979
Timestep Consumption Time: 2.40858
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.62837

Cumulative Model Updates: 93,652
Cumulative Timesteps: 781,052,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 781052756...
Checkpoint 781052756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.56544
Policy Entropy: 3.64408
Value Function Loss: 0.08255

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.44948
Value Function Update Magnitude: 0.81787

Collected Steps per Second: 22,038.59322
Overall Steps per Second: 10,708.82810

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.40174
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.67185

Cumulative Model Updates: 93,658
Cumulative Timesteps: 781,102,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,220.04684
Policy Entropy: 3.64471
Value Function Loss: 0.08212

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.48961
Value Function Update Magnitude: 0.73250

Collected Steps per Second: 22,814.11596
Overall Steps per Second: 10,845.25243

Timestep Collection Time: 2.19206
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61123

Cumulative Model Updates: 93,664
Cumulative Timesteps: 781,152,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 781152796...
Checkpoint 781152796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,905.14746
Policy Entropy: 3.64792
Value Function Loss: 0.08100

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.50062
Value Function Update Magnitude: 0.71530

Collected Steps per Second: 22,617.18563
Overall Steps per Second: 10,647.48597

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.69594

Cumulative Model Updates: 93,670
Cumulative Timesteps: 781,202,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,187.21310
Policy Entropy: 3.64024
Value Function Loss: 0.08207

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.69440

Collected Steps per Second: 22,095.72378
Overall Steps per Second: 10,427.46258

Timestep Collection Time: 2.26351
Timestep Consumption Time: 2.53286
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.79637

Cumulative Model Updates: 93,676
Cumulative Timesteps: 781,252,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 781252810...
Checkpoint 781252810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,373.50955
Policy Entropy: 3.63235
Value Function Loss: 0.08107

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.69709

Collected Steps per Second: 22,733.54543
Overall Steps per Second: 10,645.46457

Timestep Collection Time: 2.20001
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.69815

Cumulative Model Updates: 93,682
Cumulative Timesteps: 781,302,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,377.54632
Policy Entropy: 3.61993
Value Function Loss: 0.08174

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.50902
Value Function Update Magnitude: 0.68420

Collected Steps per Second: 22,678.09526
Overall Steps per Second: 10,641.09832

Timestep Collection Time: 2.20671
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.70290

Cumulative Model Updates: 93,688
Cumulative Timesteps: 781,352,868

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 781352868...
Checkpoint 781352868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,448.93438
Policy Entropy: 3.62228
Value Function Loss: 0.08319

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.49171
Value Function Update Magnitude: 0.65149

Collected Steps per Second: 22,303.93691
Overall Steps per Second: 10,549.50716

Timestep Collection Time: 2.24176
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.73956

Cumulative Model Updates: 93,694
Cumulative Timesteps: 781,402,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,304.16843
Policy Entropy: 3.62086
Value Function Loss: 0.08622

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.47697
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 22,273.47009
Overall Steps per Second: 10,565.10269

Timestep Collection Time: 2.24599
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.73502

Cumulative Model Updates: 93,700
Cumulative Timesteps: 781,452,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 781452894...
Checkpoint 781452894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.25581
Policy Entropy: 3.62921
Value Function Loss: 0.08509

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.46041
Value Function Update Magnitude: 0.68890

Collected Steps per Second: 22,412.69964
Overall Steps per Second: 10,591.41785

Timestep Collection Time: 2.23097
Timestep Consumption Time: 2.49002
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.72099

Cumulative Model Updates: 93,706
Cumulative Timesteps: 781,502,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,532.60391
Policy Entropy: 3.61871
Value Function Loss: 0.08500

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.50589
Value Function Update Magnitude: 0.70560

Collected Steps per Second: 23,029.57689
Overall Steps per Second: 10,849.88314

Timestep Collection Time: 2.17173
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.60963

Cumulative Model Updates: 93,712
Cumulative Timesteps: 781,552,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 781552910...
Checkpoint 781552910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,873.95859
Policy Entropy: 3.62321
Value Function Loss: 0.08284

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.52028
Value Function Update Magnitude: 0.70397

Collected Steps per Second: 22,746.52357
Overall Steps per Second: 10,572.00316

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.53214
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.73099

Cumulative Model Updates: 93,718
Cumulative Timesteps: 781,602,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,931.62705
Policy Entropy: 3.61037
Value Function Loss: 0.08661

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.71147

Collected Steps per Second: 23,114.59991
Overall Steps per Second: 10,858.14987

Timestep Collection Time: 2.16383
Timestep Consumption Time: 2.44248
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60631

Cumulative Model Updates: 93,724
Cumulative Timesteps: 781,652,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 781652942...
Checkpoint 781652942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,357.02445
Policy Entropy: 3.60982
Value Function Loss: 0.08707

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.71481

Collected Steps per Second: 22,280.65707
Overall Steps per Second: 10,653.39684

Timestep Collection Time: 2.24482
Timestep Consumption Time: 2.45002
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.69484

Cumulative Model Updates: 93,730
Cumulative Timesteps: 781,702,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,533.01517
Policy Entropy: 3.59466
Value Function Loss: 0.09156

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.50536
Value Function Update Magnitude: 0.73265

Collected Steps per Second: 23,074.69637
Overall Steps per Second: 10,870.68634

Timestep Collection Time: 2.16774
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60137

Cumulative Model Updates: 93,736
Cumulative Timesteps: 781,752,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 781752978...
Checkpoint 781752978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.18879
Policy Entropy: 3.59640
Value Function Loss: 0.09104

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.73825

Collected Steps per Second: 22,576.41320
Overall Steps per Second: 10,693.94679

Timestep Collection Time: 2.21532
Timestep Consumption Time: 2.46153
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.67685

Cumulative Model Updates: 93,742
Cumulative Timesteps: 781,802,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,321.72064
Policy Entropy: 3.59891
Value Function Loss: 0.08795

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.61578
Value Function Update Magnitude: 0.75858

Collected Steps per Second: 23,084.35989
Overall Steps per Second: 10,851.81592

Timestep Collection Time: 2.16718
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.61010

Cumulative Model Updates: 93,748
Cumulative Timesteps: 781,853,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 781853020...
Checkpoint 781853020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,524.65967
Policy Entropy: 3.60595
Value Function Loss: 0.08624

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.17843
Policy Update Magnitude: 0.57236
Value Function Update Magnitude: 0.75826

Collected Steps per Second: 21,899.39242
Overall Steps per Second: 10,612.78460

Timestep Collection Time: 2.28499
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.71507

Cumulative Model Updates: 93,754
Cumulative Timesteps: 781,903,060

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,515.10948
Policy Entropy: 3.62553
Value Function Loss: 0.08131

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.42946
Value Function Update Magnitude: 0.82274

Collected Steps per Second: 22,484.49135
Overall Steps per Second: 10,545.33311

Timestep Collection Time: 2.22482
Timestep Consumption Time: 2.51889
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.74371

Cumulative Model Updates: 93,760
Cumulative Timesteps: 781,953,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 781953084...
Checkpoint 781953084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,336.77626
Policy Entropy: 3.61982
Value Function Loss: 0.08241

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.45329
Value Function Update Magnitude: 0.75277

Collected Steps per Second: 22,252.21214
Overall Steps per Second: 10,662.89550

Timestep Collection Time: 2.24787
Timestep Consumption Time: 2.44317
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.69103

Cumulative Model Updates: 93,766
Cumulative Timesteps: 782,003,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,451.87157
Policy Entropy: 3.62642
Value Function Loss: 0.07706

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.51962
Value Function Update Magnitude: 0.70427

Collected Steps per Second: 22,965.20602
Overall Steps per Second: 10,828.79703

Timestep Collection Time: 2.17782
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61861

Cumulative Model Updates: 93,772
Cumulative Timesteps: 782,053,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 782053118...
Checkpoint 782053118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,346.62576
Policy Entropy: 3.62967
Value Function Loss: 0.08109

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.63745
Value Function Update Magnitude: 0.66487

Collected Steps per Second: 22,485.74495
Overall Steps per Second: 10,685.29703

Timestep Collection Time: 2.22497
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.68213

Cumulative Model Updates: 93,778
Cumulative Timesteps: 782,103,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,118.93487
Policy Entropy: 3.63071
Value Function Loss: 0.08163

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.74459
Value Function Update Magnitude: 0.66897

Collected Steps per Second: 23,168.96339
Overall Steps per Second: 10,859.42703

Timestep Collection Time: 2.15832
Timestep Consumption Time: 2.44653
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60485

Cumulative Model Updates: 93,784
Cumulative Timesteps: 782,153,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 782153154...
Checkpoint 782153154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,253.80295
Policy Entropy: 3.61585
Value Function Loss: 0.08313

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.77433
Value Function Update Magnitude: 0.70873

Collected Steps per Second: 22,870.71913
Overall Steps per Second: 10,723.82151

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.47780
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.66531

Cumulative Model Updates: 93,790
Cumulative Timesteps: 782,203,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,647.16061
Policy Entropy: 3.62624
Value Function Loss: 0.08285

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.15353
Policy Update Magnitude: 0.64380
Value Function Update Magnitude: 0.71116

Collected Steps per Second: 23,286.21439
Overall Steps per Second: 10,928.36753

Timestep Collection Time: 2.14754
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.57598

Cumulative Model Updates: 93,796
Cumulative Timesteps: 782,253,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782253192...
Checkpoint 782253192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.74525
Policy Entropy: 3.64445
Value Function Loss: 0.07841

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.71413

Collected Steps per Second: 22,792.15367
Overall Steps per Second: 10,660.41656

Timestep Collection Time: 2.19426
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69137

Cumulative Model Updates: 93,802
Cumulative Timesteps: 782,303,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,426.94306
Policy Entropy: 3.65528
Value Function Loss: 0.08264

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.69910

Collected Steps per Second: 22,932.71348
Overall Steps per Second: 10,865.57086

Timestep Collection Time: 2.18038
Timestep Consumption Time: 2.42150
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.60188

Cumulative Model Updates: 93,808
Cumulative Timesteps: 782,353,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 782353206...
Checkpoint 782353206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,054.31537
Policy Entropy: 3.65879
Value Function Loss: 0.08166

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.52448
Value Function Update Magnitude: 0.67126

Collected Steps per Second: 22,088.49586
Overall Steps per Second: 10,643.38978

Timestep Collection Time: 2.26389
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.69832

Cumulative Model Updates: 93,814
Cumulative Timesteps: 782,403,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.71636
Policy Entropy: 3.66839
Value Function Loss: 0.08287

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.50601
Value Function Update Magnitude: 0.71156

Collected Steps per Second: 22,080.13983
Overall Steps per Second: 10,810.23547

Timestep Collection Time: 2.26584
Timestep Consumption Time: 2.36218
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.62802

Cumulative Model Updates: 93,820
Cumulative Timesteps: 782,453,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 782453242...
Checkpoint 782453242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,464.62239
Policy Entropy: 3.66719
Value Function Loss: 0.07845

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.51707
Value Function Update Magnitude: 0.74908

Collected Steps per Second: 21,541.12020
Overall Steps per Second: 10,663.82969

Timestep Collection Time: 2.32123
Timestep Consumption Time: 2.36770
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.68893

Cumulative Model Updates: 93,826
Cumulative Timesteps: 782,503,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,258.55649
Policy Entropy: 3.67016
Value Function Loss: 0.07805

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.56084
Value Function Update Magnitude: 0.77308

Collected Steps per Second: 21,927.89191
Overall Steps per Second: 10,651.74644

Timestep Collection Time: 2.28075
Timestep Consumption Time: 2.41444
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.69519

Cumulative Model Updates: 93,832
Cumulative Timesteps: 782,553,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 782553256...
Checkpoint 782553256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,324.29418
Policy Entropy: 3.67464
Value Function Loss: 0.07464

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.68331
Value Function Update Magnitude: 0.81079

Collected Steps per Second: 21,655.89072
Overall Steps per Second: 10,562.06107

Timestep Collection Time: 2.31106
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.73847

Cumulative Model Updates: 93,838
Cumulative Timesteps: 782,603,304

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,016.00926
Policy Entropy: 3.68468
Value Function Loss: 0.07109

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.68136
Value Function Update Magnitude: 0.89140

Collected Steps per Second: 22,450.72043
Overall Steps per Second: 10,895.98052

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.36307
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.59142

Cumulative Model Updates: 93,844
Cumulative Timesteps: 782,653,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 782653332...
Checkpoint 782653332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.31310
Policy Entropy: 3.67255
Value Function Loss: 0.06985

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.62795
Value Function Update Magnitude: 0.89714

Collected Steps per Second: 21,849.01113
Overall Steps per Second: 10,565.98821

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.44403
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.73273

Cumulative Model Updates: 93,850
Cumulative Timesteps: 782,703,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.56136
Policy Entropy: 3.67130
Value Function Loss: 0.07006

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.62770
Value Function Update Magnitude: 0.87867

Collected Steps per Second: 21,779.46435
Overall Steps per Second: 10,569.16212

Timestep Collection Time: 2.29675
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.73283

Cumulative Model Updates: 93,856
Cumulative Timesteps: 782,753,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 782753360...
Checkpoint 782753360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,631.46551
Policy Entropy: 3.65672
Value Function Loss: 0.07146

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.84901

Collected Steps per Second: 22,096.92376
Overall Steps per Second: 10,733.11686

Timestep Collection Time: 2.26357
Timestep Consumption Time: 2.39658
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.66016

Cumulative Model Updates: 93,862
Cumulative Timesteps: 782,803,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.93562
Policy Entropy: 3.66820
Value Function Loss: 0.07088

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.84435

Collected Steps per Second: 22,567.60087
Overall Steps per Second: 10,763.16465

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.64882

Cumulative Model Updates: 93,868
Cumulative Timesteps: 782,853,414

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 782853414...
Checkpoint 782853414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,690.56183
Policy Entropy: 3.66786
Value Function Loss: 0.07223

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.58224
Value Function Update Magnitude: 0.86774

Collected Steps per Second: 21,945.33987
Overall Steps per Second: 10,530.86242

Timestep Collection Time: 2.27930
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.74985

Cumulative Model Updates: 93,874
Cumulative Timesteps: 782,903,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220.00165
Policy Entropy: 3.64866
Value Function Loss: 0.07691

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.57953
Value Function Update Magnitude: 0.88264

Collected Steps per Second: 22,305.73055
Overall Steps per Second: 10,574.68357

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.72846

Cumulative Model Updates: 93,880
Cumulative Timesteps: 782,953,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 782953436...
Checkpoint 782953436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,992.65601
Policy Entropy: 3.63286
Value Function Loss: 0.08192

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.81382

Collected Steps per Second: 22,279.69563
Overall Steps per Second: 10,593.40794

Timestep Collection Time: 2.24455
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.72067

Cumulative Model Updates: 93,886
Cumulative Timesteps: 783,003,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,816.72897
Policy Entropy: 3.62767
Value Function Loss: 0.08337

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.81638

Collected Steps per Second: 22,638.48707
Overall Steps per Second: 10,808.35703

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.62827

Cumulative Model Updates: 93,892
Cumulative Timesteps: 783,053,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 783053468...
Checkpoint 783053468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,575.29137
Policy Entropy: 3.62917
Value Function Loss: 0.07876

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.64348
Value Function Update Magnitude: 0.83993

Collected Steps per Second: 22,481.75004
Overall Steps per Second: 10,704.89845

Timestep Collection Time: 2.22483
Timestep Consumption Time: 2.44761
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.67244

Cumulative Model Updates: 93,898
Cumulative Timesteps: 783,103,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.26269
Policy Entropy: 3.64737
Value Function Loss: 0.07502

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.79110

Collected Steps per Second: 23,118.51525
Overall Steps per Second: 10,915.17388

Timestep Collection Time: 2.16398
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.58334

Cumulative Model Updates: 93,904
Cumulative Timesteps: 783,153,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 783153514...
Checkpoint 783153514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530.44809
Policy Entropy: 3.65377
Value Function Loss: 0.07433

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.46677
Value Function Update Magnitude: 0.74408

Collected Steps per Second: 22,390.96656
Overall Steps per Second: 10,674.28709

Timestep Collection Time: 2.23429
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.68678

Cumulative Model Updates: 93,910
Cumulative Timesteps: 783,203,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,775.94773
Policy Entropy: 3.67272
Value Function Loss: 0.07491

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.72259

Collected Steps per Second: 22,916.44782
Overall Steps per Second: 10,827.47783

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.43721
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62010

Cumulative Model Updates: 93,916
Cumulative Timesteps: 783,253,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 783253566...
Checkpoint 783253566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.56020
Policy Entropy: 3.66550
Value Function Loss: 0.07570

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.67329
Value Function Update Magnitude: 0.64607

Collected Steps per Second: 22,292.88861
Overall Steps per Second: 10,691.94719

Timestep Collection Time: 2.24403
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.67885

Cumulative Model Updates: 93,922
Cumulative Timesteps: 783,303,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.04471
Policy Entropy: 3.66659
Value Function Loss: 0.07800

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.72430
Value Function Update Magnitude: 0.61600

Collected Steps per Second: 22,432.82855
Overall Steps per Second: 10,571.44495

Timestep Collection Time: 2.22968
Timestep Consumption Time: 2.50175
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.73143

Cumulative Model Updates: 93,928
Cumulative Timesteps: 783,353,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 783353610...
Checkpoint 783353610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,215.92716
Policy Entropy: 3.65892
Value Function Loss: 0.07687

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.63173
Value Function Update Magnitude: 0.62190

Collected Steps per Second: 22,067.01002
Overall Steps per Second: 10,608.05133

Timestep Collection Time: 2.26728
Timestep Consumption Time: 2.44914
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.71642

Cumulative Model Updates: 93,934
Cumulative Timesteps: 783,403,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,221.00257
Policy Entropy: 3.66353
Value Function Loss: 0.07933

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.57310
Value Function Update Magnitude: 0.60340

Collected Steps per Second: 22,497.55825
Overall Steps per Second: 10,611.89414

Timestep Collection Time: 2.22300
Timestep Consumption Time: 2.48983
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.71282

Cumulative Model Updates: 93,940
Cumulative Timesteps: 783,453,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 783453654...
Checkpoint 783453654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,125.12655
Policy Entropy: 3.64904
Value Function Loss: 0.08022

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.61086

Collected Steps per Second: 22,517.10016
Overall Steps per Second: 10,596.82977

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.71839

Cumulative Model Updates: 93,946
Cumulative Timesteps: 783,503,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,700.98163
Policy Entropy: 3.64559
Value Function Loss: 0.08121

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.66005
Value Function Update Magnitude: 0.65348

Collected Steps per Second: 23,154.56780
Overall Steps per Second: 10,767.47765

Timestep Collection Time: 2.16061
Timestep Consumption Time: 2.48560
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.64621

Cumulative Model Updates: 93,952
Cumulative Timesteps: 783,553,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 783553682...
Checkpoint 783553682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,452.29905
Policy Entropy: 3.64678
Value Function Loss: 0.08035

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.58702
Value Function Update Magnitude: 0.66285

Collected Steps per Second: 22,510.03956
Overall Steps per Second: 10,597.23879

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.71897

Cumulative Model Updates: 93,958
Cumulative Timesteps: 783,603,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,814.63760
Policy Entropy: 3.65133
Value Function Loss: 0.07928

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.55339
Value Function Update Magnitude: 0.69264

Collected Steps per Second: 22,972.76317
Overall Steps per Second: 10,830.89257

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.44130
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61901

Cumulative Model Updates: 93,964
Cumulative Timesteps: 783,653,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 783653718...
Checkpoint 783653718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,209.82925
Policy Entropy: 3.65809
Value Function Loss: 0.08124

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.60496
Value Function Update Magnitude: 0.68919

Collected Steps per Second: 22,538.91681
Overall Steps per Second: 10,760.00930

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.64777

Cumulative Model Updates: 93,970
Cumulative Timesteps: 783,703,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,512.20344
Policy Entropy: 3.65787
Value Function Loss: 0.08050

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.56557
Value Function Update Magnitude: 0.63181

Collected Steps per Second: 22,785.67448
Overall Steps per Second: 10,647.26808

Timestep Collection Time: 2.19436
Timestep Consumption Time: 2.50168
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.69604

Cumulative Model Updates: 93,976
Cumulative Timesteps: 783,753,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 783753728...
Checkpoint 783753728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,613.14908
Policy Entropy: 3.64506
Value Function Loss: 0.08511

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.51343
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 22,702.23914
Overall Steps per Second: 10,794.00718

Timestep Collection Time: 2.20313
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.63368

Cumulative Model Updates: 93,982
Cumulative Timesteps: 783,803,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,569.14902
Policy Entropy: 3.63184
Value Function Loss: 0.08826

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.51112
Value Function Update Magnitude: 0.50273

Collected Steps per Second: 22,433.84523
Overall Steps per Second: 10,535.87541

Timestep Collection Time: 2.22931
Timestep Consumption Time: 2.51752
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.74683

Cumulative Model Updates: 93,988
Cumulative Timesteps: 783,853,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 783853756...
Checkpoint 783853756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,112.98512
Policy Entropy: 3.63205
Value Function Loss: 0.08678

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.49930
Value Function Update Magnitude: 0.44883

Collected Steps per Second: 21,886.66827
Overall Steps per Second: 10,607.75215

Timestep Collection Time: 2.28459
Timestep Consumption Time: 2.42914
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.71372

Cumulative Model Updates: 93,994
Cumulative Timesteps: 783,903,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,130.04144
Policy Entropy: 3.63210
Value Function Loss: 0.08233

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.49257
Value Function Update Magnitude: 0.54348

Collected Steps per Second: 22,648.80346
Overall Steps per Second: 10,646.16524

Timestep Collection Time: 2.20868
Timestep Consumption Time: 2.49010
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.69878

Cumulative Model Updates: 94,000
Cumulative Timesteps: 783,953,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 783953782...
Checkpoint 783953782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,139.38194
Policy Entropy: 3.63553
Value Function Loss: 0.08211

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07004
Policy Update Magnitude: 0.63329
Value Function Update Magnitude: 0.65173

Collected Steps per Second: 22,518.25759
Overall Steps per Second: 10,616.84493

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.71100

Cumulative Model Updates: 94,006
Cumulative Timesteps: 784,003,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,255.44826
Policy Entropy: 3.62958
Value Function Loss: 0.08522

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.77168
Value Function Update Magnitude: 0.68329

Collected Steps per Second: 22,913.75872
Overall Steps per Second: 10,817.54588

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.62637

Cumulative Model Updates: 94,012
Cumulative Timesteps: 784,053,844

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 784053844...
Checkpoint 784053844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,810.57113
Policy Entropy: 3.62065
Value Function Loss: 0.08606

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.76226
Value Function Update Magnitude: 0.68078

Collected Steps per Second: 22,619.14897
Overall Steps per Second: 10,553.01018

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.52888
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.74064

Cumulative Model Updates: 94,018
Cumulative Timesteps: 784,103,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,389.90582
Policy Entropy: 3.62165
Value Function Loss: 0.08966

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.74625
Value Function Update Magnitude: 0.64916

Collected Steps per Second: 22,723.99598
Overall Steps per Second: 10,643.06417

Timestep Collection Time: 2.20146
Timestep Consumption Time: 2.49888
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.70034

Cumulative Model Updates: 94,024
Cumulative Timesteps: 784,153,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 784153898...
Checkpoint 784153898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,625.23610
Policy Entropy: 3.61912
Value Function Loss: 0.09152

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.66821
Value Function Update Magnitude: 0.59490

Collected Steps per Second: 22,797.60022
Overall Steps per Second: 10,845.24664

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.41710
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61031

Cumulative Model Updates: 94,030
Cumulative Timesteps: 784,203,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,363.83538
Policy Entropy: 3.60924
Value Function Loss: 0.09071

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.58739
Value Function Update Magnitude: 0.60360

Collected Steps per Second: 23,122.97653
Overall Steps per Second: 10,763.32904

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.64763

Cumulative Model Updates: 94,036
Cumulative Timesteps: 784,253,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 784253922...
Checkpoint 784253922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,746.05758
Policy Entropy: 3.60421
Value Function Loss: 0.09047

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.65831

Collected Steps per Second: 22,747.29338
Overall Steps per Second: 10,814.22890

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.62594

Cumulative Model Updates: 94,042
Cumulative Timesteps: 784,303,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,436.93174
Policy Entropy: 3.60864
Value Function Loss: 0.08883

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.55115
Value Function Update Magnitude: 0.64584

Collected Steps per Second: 22,946.39682
Overall Steps per Second: 10,758.14552

Timestep Collection Time: 2.17951
Timestep Consumption Time: 2.46924
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.64876

Cumulative Model Updates: 94,048
Cumulative Timesteps: 784,353,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 784353960...
Checkpoint 784353960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,549.77904
Policy Entropy: 3.60576
Value Function Loss: 0.08859

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.64795
Value Function Update Magnitude: 0.60847

Collected Steps per Second: 22,051.29232
Overall Steps per Second: 10,534.19496

Timestep Collection Time: 2.26762
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.74683

Cumulative Model Updates: 94,054
Cumulative Timesteps: 784,403,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,432.86808
Policy Entropy: 3.61130
Value Function Loss: 0.08542

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.61766
Value Function Update Magnitude: 0.75084

Collected Steps per Second: 22,805.84092
Overall Steps per Second: 10,746.22611

Timestep Collection Time: 2.19242
Timestep Consumption Time: 2.46038
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.65280

Cumulative Model Updates: 94,060
Cumulative Timesteps: 784,453,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 784453964...
Checkpoint 784453964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,693.16775
Policy Entropy: 3.60470
Value Function Loss: 0.08270

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.61436
Value Function Update Magnitude: 0.82340

Collected Steps per Second: 21,778.71238
Overall Steps per Second: 10,600.29634

Timestep Collection Time: 2.29711
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.71949

Cumulative Model Updates: 94,066
Cumulative Timesteps: 784,503,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,815.08641
Policy Entropy: 3.60403
Value Function Loss: 0.08297

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.70096
Value Function Update Magnitude: 0.81105

Collected Steps per Second: 22,464.11800
Overall Steps per Second: 10,579.99121

Timestep Collection Time: 2.22639
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.72723

Cumulative Model Updates: 94,072
Cumulative Timesteps: 784,554,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 784554006...
Checkpoint 784554006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,761.42831
Policy Entropy: 3.59755
Value Function Loss: 0.08305

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.59303
Value Function Update Magnitude: 0.82821

Collected Steps per Second: 22,441.40238
Overall Steps per Second: 10,552.80792

Timestep Collection Time: 2.22865
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.73940

Cumulative Model Updates: 94,078
Cumulative Timesteps: 784,604,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.91327
Policy Entropy: 3.59272
Value Function Loss: 0.08356

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.55709
Value Function Update Magnitude: 0.88544

Collected Steps per Second: 22,385.41227
Overall Steps per Second: 10,857.88869

Timestep Collection Time: 2.23449
Timestep Consumption Time: 2.37230
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60679

Cumulative Model Updates: 94,084
Cumulative Timesteps: 784,654,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 784654040...
Checkpoint 784654040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,977.66893
Policy Entropy: 3.58764
Value Function Loss: 0.08074

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.50786
Value Function Update Magnitude: 0.88142

Collected Steps per Second: 21,958.43777
Overall Steps per Second: 10,682.83351

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.40347
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.68059

Cumulative Model Updates: 94,090
Cumulative Timesteps: 784,704,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,780.44781
Policy Entropy: 3.58567
Value Function Loss: 0.07874

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.46063
Value Function Update Magnitude: 0.86634

Collected Steps per Second: 22,532.34904
Overall Steps per Second: 10,954.44751

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.34664
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.56691

Cumulative Model Updates: 94,096
Cumulative Timesteps: 784,754,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 784754070...
Checkpoint 784754070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,244.07422
Policy Entropy: 3.58901
Value Function Loss: 0.07731

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.50702
Value Function Update Magnitude: 0.83144

Collected Steps per Second: 21,934.55073
Overall Steps per Second: 10,628.24024

Timestep Collection Time: 2.28060
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.70671

Cumulative Model Updates: 94,102
Cumulative Timesteps: 784,804,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,992.87457
Policy Entropy: 3.59237
Value Function Loss: 0.07672

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.85347

Collected Steps per Second: 22,521.39104
Overall Steps per Second: 10,917.42698

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.36114
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.58258

Cumulative Model Updates: 94,108
Cumulative Timesteps: 784,854,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 784854124...
Checkpoint 784854124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,364.79890
Policy Entropy: 3.59588
Value Function Loss: 0.07608

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.43728
Value Function Update Magnitude: 0.74053

Collected Steps per Second: 22,026.14751
Overall Steps per Second: 10,629.53606

Timestep Collection Time: 2.27076
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.70538

Cumulative Model Updates: 94,114
Cumulative Timesteps: 784,904,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,459.22695
Policy Entropy: 3.60204
Value Function Loss: 0.07779

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.67674

Collected Steps per Second: 21,960.89152
Overall Steps per Second: 10,809.08720

Timestep Collection Time: 2.27677
Timestep Consumption Time: 2.34896
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62574

Cumulative Model Updates: 94,120
Cumulative Timesteps: 784,954,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 784954140...
Checkpoint 784954140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.70891
Policy Entropy: 3.61312
Value Function Loss: 0.07819

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.68917
Value Function Update Magnitude: 0.62056

Collected Steps per Second: 22,073.29817
Overall Steps per Second: 10,687.50089

Timestep Collection Time: 2.26654
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.68117

Cumulative Model Updates: 94,126
Cumulative Timesteps: 785,004,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,036.42193
Policy Entropy: 3.60797
Value Function Loss: 0.07679

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.62840
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 22,755.69480
Overall Steps per Second: 10,843.00576

Timestep Collection Time: 2.19796
Timestep Consumption Time: 2.41479
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61274

Cumulative Model Updates: 94,132
Cumulative Timesteps: 785,054,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 785054186...
Checkpoint 785054186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.31914
Policy Entropy: 3.62164
Value Function Loss: 0.07091

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 21,268.68040
Overall Steps per Second: 10,345.55712

Timestep Collection Time: 2.35229
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.83589

Cumulative Model Updates: 94,138
Cumulative Timesteps: 785,104,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,267.10142
Policy Entropy: 3.61926
Value Function Loss: 0.06956

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.55629
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,401.90278
Overall Steps per Second: 10,638.85716

Timestep Collection Time: 2.23302
Timestep Consumption Time: 2.46898
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.70201

Cumulative Model Updates: 94,144
Cumulative Timesteps: 785,154,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 785154240...
Checkpoint 785154240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,605.71934
Policy Entropy: 3.64314
Value Function Loss: 0.06952

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.60951
Value Function Update Magnitude: 0.62420

Collected Steps per Second: 22,258.40503
Overall Steps per Second: 10,644.57112

Timestep Collection Time: 2.24643
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69742

Cumulative Model Updates: 94,150
Cumulative Timesteps: 785,204,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,165.83342
Policy Entropy: 3.63818
Value Function Loss: 0.07072

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.59642

Collected Steps per Second: 23,416.90931
Overall Steps per Second: 10,819.53346

Timestep Collection Time: 2.13529
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.62146

Cumulative Model Updates: 94,156
Cumulative Timesteps: 785,254,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 785254244...
Checkpoint 785254244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,866.86053
Policy Entropy: 3.64087
Value Function Loss: 0.07559

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.58725
Value Function Update Magnitude: 0.60564

Collected Steps per Second: 22,914.32823
Overall Steps per Second: 10,885.85595

Timestep Collection Time: 2.18318
Timestep Consumption Time: 2.41233
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59550

Cumulative Model Updates: 94,162
Cumulative Timesteps: 785,304,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,282.92715
Policy Entropy: 3.62570
Value Function Loss: 0.07642

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.64148

Collected Steps per Second: 23,223.31455
Overall Steps per Second: 10,908.27668

Timestep Collection Time: 2.15439
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58661

Cumulative Model Updates: 94,168
Cumulative Timesteps: 785,354,302

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 785354302...
Checkpoint 785354302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,564.08105
Policy Entropy: 3.62984
Value Function Loss: 0.07620

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.55876
Value Function Update Magnitude: 0.71394

Collected Steps per Second: 22,565.94417
Overall Steps per Second: 10,788.35103

Timestep Collection Time: 2.21679
Timestep Consumption Time: 2.42006
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.63685

Cumulative Model Updates: 94,174
Cumulative Timesteps: 785,404,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.91523
Policy Entropy: 3.62888
Value Function Loss: 0.07594

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.56953
Value Function Update Magnitude: 0.72266

Collected Steps per Second: 23,069.86199
Overall Steps per Second: 10,867.40649

Timestep Collection Time: 2.16768
Timestep Consumption Time: 2.43397
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60165

Cumulative Model Updates: 94,180
Cumulative Timesteps: 785,454,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 785454334...
Checkpoint 785454334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.04100
Policy Entropy: 3.62323
Value Function Loss: 0.07606

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.56061
Value Function Update Magnitude: 0.66273

Collected Steps per Second: 22,734.80273
Overall Steps per Second: 10,607.57533

Timestep Collection Time: 2.20059
Timestep Consumption Time: 2.51585
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.71644

Cumulative Model Updates: 94,186
Cumulative Timesteps: 785,504,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.28404
Policy Entropy: 3.62215
Value Function Loss: 0.07690

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.57595
Value Function Update Magnitude: 0.70158

Collected Steps per Second: 22,608.48682
Overall Steps per Second: 10,645.01410

Timestep Collection Time: 2.21271
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.69948

Cumulative Model Updates: 94,192
Cumulative Timesteps: 785,554,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 785554390...
Checkpoint 785554390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,336.13624
Policy Entropy: 3.62254
Value Function Loss: 0.07372

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.57145
Value Function Update Magnitude: 0.77039

Collected Steps per Second: 22,586.94490
Overall Steps per Second: 10,655.49011

Timestep Collection Time: 2.21438
Timestep Consumption Time: 2.47954
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.69392

Cumulative Model Updates: 94,198
Cumulative Timesteps: 785,604,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.74450
Policy Entropy: 3.62821
Value Function Loss: 0.07259

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.62998
Value Function Update Magnitude: 0.78600

Collected Steps per Second: 22,641.74448
Overall Steps per Second: 10,686.78889

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.68036

Cumulative Model Updates: 94,204
Cumulative Timesteps: 785,654,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 785654424...
Checkpoint 785654424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.02470
Policy Entropy: 3.62175
Value Function Loss: 0.07773

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.73503
Value Function Update Magnitude: 0.75357

Collected Steps per Second: 22,373.42057
Overall Steps per Second: 10,723.88151

Timestep Collection Time: 2.23614
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.66529

Cumulative Model Updates: 94,210
Cumulative Timesteps: 785,704,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.54210
Policy Entropy: 3.61913
Value Function Loss: 0.08067

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.67472
Value Function Update Magnitude: 0.65755

Collected Steps per Second: 22,812.89657
Overall Steps per Second: 10,805.96747

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.43572
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62781

Cumulative Model Updates: 94,216
Cumulative Timesteps: 785,754,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 785754462...
Checkpoint 785754462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.23359
Policy Entropy: 3.61749
Value Function Loss: 0.08232

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.58495
Value Function Update Magnitude: 0.69804

Collected Steps per Second: 22,480.60092
Overall Steps per Second: 10,655.58303

Timestep Collection Time: 2.22423
Timestep Consumption Time: 2.46833
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.69256

Cumulative Model Updates: 94,222
Cumulative Timesteps: 785,804,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,135.80568
Policy Entropy: 3.63558
Value Function Loss: 0.07898

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.56157
Value Function Update Magnitude: 0.68517

Collected Steps per Second: 22,975.00445
Overall Steps per Second: 10,822.94362

Timestep Collection Time: 2.17689
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.62111

Cumulative Model Updates: 94,228
Cumulative Timesteps: 785,854,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 785854478...
Checkpoint 785854478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,150.55791
Policy Entropy: 3.63024
Value Function Loss: 0.07749

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.51499
Value Function Update Magnitude: 0.75400

Collected Steps per Second: 22,341.46823
Overall Steps per Second: 10,695.43162

Timestep Collection Time: 2.23898
Timestep Consumption Time: 2.43797
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.67695

Cumulative Model Updates: 94,234
Cumulative Timesteps: 785,904,500

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,693.03098
Policy Entropy: 3.63131
Value Function Loss: 0.07713

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.51157
Value Function Update Magnitude: 0.74516

Collected Steps per Second: 22,911.25902
Overall Steps per Second: 10,692.03007

Timestep Collection Time: 2.18294
Timestep Consumption Time: 2.49475
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.67769

Cumulative Model Updates: 94,240
Cumulative Timesteps: 785,954,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 785954514...
Checkpoint 785954514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,079.25594
Policy Entropy: 3.62175
Value Function Loss: 0.08070

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.67296

Collected Steps per Second: 22,979.13806
Overall Steps per Second: 10,874.18413

Timestep Collection Time: 2.17745
Timestep Consumption Time: 2.42390
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60136

Cumulative Model Updates: 94,246
Cumulative Timesteps: 786,004,550

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,117.54857
Policy Entropy: 3.61956
Value Function Loss: 0.08201

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.60503
Value Function Update Magnitude: 0.67000

Collected Steps per Second: 23,117.71562
Overall Steps per Second: 10,931.88923

Timestep Collection Time: 2.16310
Timestep Consumption Time: 2.41122
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.57432

Cumulative Model Updates: 94,252
Cumulative Timesteps: 786,054,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 786054556...
Checkpoint 786054556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,911.45489
Policy Entropy: 3.60456
Value Function Loss: 0.08284

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.73179
Value Function Update Magnitude: 0.67648

Collected Steps per Second: 22,453.88343
Overall Steps per Second: 10,675.22540

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.45764
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.68505

Cumulative Model Updates: 94,258
Cumulative Timesteps: 786,104,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,993.28706
Policy Entropy: 3.61230
Value Function Loss: 0.08289

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.65830
Value Function Update Magnitude: 0.75995

Collected Steps per Second: 22,670.62645
Overall Steps per Second: 10,654.93184

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.69304

Cumulative Model Updates: 94,264
Cumulative Timesteps: 786,154,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 786154574...
Checkpoint 786154574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,582.64789
Policy Entropy: 3.63543
Value Function Loss: 0.08153

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.61416
Value Function Update Magnitude: 0.86773

Collected Steps per Second: 22,172.83501
Overall Steps per Second: 10,632.82209

Timestep Collection Time: 2.25627
Timestep Consumption Time: 2.44878
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.70505

Cumulative Model Updates: 94,270
Cumulative Timesteps: 786,204,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,575.95913
Policy Entropy: 3.64798
Value Function Loss: 0.08088

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.72655
Value Function Update Magnitude: 0.75333

Collected Steps per Second: 22,740.45751
Overall Steps per Second: 10,661.03990

Timestep Collection Time: 2.19899
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.69054

Cumulative Model Updates: 94,276
Cumulative Timesteps: 786,254,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 786254608...
Checkpoint 786254608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.41389
Policy Entropy: 3.64730
Value Function Loss: 0.08219

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.66636
Value Function Update Magnitude: 0.70134

Collected Steps per Second: 22,681.47001
Overall Steps per Second: 10,636.00973

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.70233

Cumulative Model Updates: 94,282
Cumulative Timesteps: 786,304,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.91837
Policy Entropy: 3.64127
Value Function Loss: 0.08520

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.63877
Value Function Update Magnitude: 0.72746

Collected Steps per Second: 23,034.53500
Overall Steps per Second: 10,851.88089

Timestep Collection Time: 2.17178
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.60989

Cumulative Model Updates: 94,288
Cumulative Timesteps: 786,354,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 786354648...
Checkpoint 786354648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,869.21232
Policy Entropy: 3.63753
Value Function Loss: 0.08487

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.62054
Value Function Update Magnitude: 0.76863

Collected Steps per Second: 22,903.70540
Overall Steps per Second: 10,724.95255

Timestep Collection Time: 2.18393
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.66389

Cumulative Model Updates: 94,294
Cumulative Timesteps: 786,404,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,178.75125
Policy Entropy: 3.61696
Value Function Loss: 0.08566

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.69734
Value Function Update Magnitude: 0.77894

Collected Steps per Second: 23,073.30095
Overall Steps per Second: 10,860.14073

Timestep Collection Time: 2.16787
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.60583

Cumulative Model Updates: 94,300
Cumulative Timesteps: 786,454,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 786454688...
Checkpoint 786454688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.38618
Policy Entropy: 3.61776
Value Function Loss: 0.08533

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.60614
Value Function Update Magnitude: 0.80335

Collected Steps per Second: 22,862.74824
Overall Steps per Second: 10,652.21671

Timestep Collection Time: 2.18810
Timestep Consumption Time: 2.50820
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.69630

Cumulative Model Updates: 94,306
Cumulative Timesteps: 786,504,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,183.50773
Policy Entropy: 3.62229
Value Function Loss: 0.08486

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.53838
Value Function Update Magnitude: 0.78698

Collected Steps per Second: 22,812.79750
Overall Steps per Second: 10,672.86234

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.68628

Cumulative Model Updates: 94,312
Cumulative Timesteps: 786,554,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 786554730...
Checkpoint 786554730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,198.95321
Policy Entropy: 3.63660
Value Function Loss: 0.08499

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.80337

Collected Steps per Second: 23,068.04862
Overall Steps per Second: 10,894.49530

Timestep Collection Time: 2.16845
Timestep Consumption Time: 2.42304
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.59149

Cumulative Model Updates: 94,318
Cumulative Timesteps: 786,604,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,478.82063
Policy Entropy: 3.64818
Value Function Loss: 0.08223

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.66729
Value Function Update Magnitude: 0.90646

Collected Steps per Second: 22,783.93456
Overall Steps per Second: 10,822.75863

Timestep Collection Time: 2.19488
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62063

Cumulative Model Updates: 94,324
Cumulative Timesteps: 786,654,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 786654760...
Checkpoint 786654760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,855.97497
Policy Entropy: 3.64068
Value Function Loss: 0.07819

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.60670
Value Function Update Magnitude: 0.91266

Collected Steps per Second: 22,112.73126
Overall Steps per Second: 10,660.76565

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.43012
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.69235

Cumulative Model Updates: 94,330
Cumulative Timesteps: 786,704,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,529.89178
Policy Entropy: 3.64525
Value Function Loss: 0.07803

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.59360
Value Function Update Magnitude: 0.93478

Collected Steps per Second: 22,577.26128
Overall Steps per Second: 10,595.74857

Timestep Collection Time: 2.21515
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.72001

Cumulative Model Updates: 94,336
Cumulative Timesteps: 786,754,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 786754796...
Checkpoint 786754796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,612.64875
Policy Entropy: 3.63715
Value Function Loss: 0.08166

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.65601
Value Function Update Magnitude: 0.95758

Collected Steps per Second: 22,373.70711
Overall Steps per Second: 10,608.54204

Timestep Collection Time: 2.23575
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.71526

Cumulative Model Updates: 94,342
Cumulative Timesteps: 786,804,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,042.49328
Policy Entropy: 3.62357
Value Function Loss: 0.08777

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.79540
Value Function Update Magnitude: 0.95626

Collected Steps per Second: 22,931.30490
Overall Steps per Second: 10,778.53178

Timestep Collection Time: 2.18086
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.63978

Cumulative Model Updates: 94,348
Cumulative Timesteps: 786,854,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 786854828...
Checkpoint 786854828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,128.59428
Policy Entropy: 3.61629
Value Function Loss: 0.08748

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.77689
Value Function Update Magnitude: 0.89887

Collected Steps per Second: 22,673.05938
Overall Steps per Second: 10,620.59537

Timestep Collection Time: 2.20526
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.70783

Cumulative Model Updates: 94,354
Cumulative Timesteps: 786,904,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.56425
Policy Entropy: 3.62868
Value Function Loss: 0.08501

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.63761
Value Function Update Magnitude: 0.83174

Collected Steps per Second: 22,627.67085
Overall Steps per Second: 10,713.07170

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.45830
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.66869

Cumulative Model Updates: 94,360
Cumulative Timesteps: 786,954,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 786954844...
Checkpoint 786954844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,916.16667
Policy Entropy: 3.65008
Value Function Loss: 0.08368

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.63834
Value Function Update Magnitude: 0.81037

Collected Steps per Second: 22,287.85361
Overall Steps per Second: 10,465.24427

Timestep Collection Time: 2.24391
Timestep Consumption Time: 2.53495
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.77887

Cumulative Model Updates: 94,366
Cumulative Timesteps: 787,004,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.43770
Policy Entropy: 3.66342
Value Function Loss: 0.08212

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.68372
Value Function Update Magnitude: 0.79780

Collected Steps per Second: 23,236.96810
Overall Steps per Second: 10,888.91366

Timestep Collection Time: 2.15235
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59311

Cumulative Model Updates: 94,372
Cumulative Timesteps: 787,054,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 787054870...
Checkpoint 787054870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,141.14358
Policy Entropy: 3.66634
Value Function Loss: 0.08029

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.70452
Value Function Update Magnitude: 0.83582

Collected Steps per Second: 22,498.54268
Overall Steps per Second: 10,657.74005

Timestep Collection Time: 2.22343
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.69368

Cumulative Model Updates: 94,378
Cumulative Timesteps: 787,104,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.27808
Policy Entropy: 3.68526
Value Function Loss: 0.07667

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.65538
Value Function Update Magnitude: 0.89605

Collected Steps per Second: 22,437.47817
Overall Steps per Second: 10,682.53876

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.68297

Cumulative Model Updates: 94,384
Cumulative Timesteps: 787,154,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 787154920...
Checkpoint 787154920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.89862
Policy Entropy: 3.69202
Value Function Loss: 0.07725

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.60150
Value Function Update Magnitude: 0.86644

Collected Steps per Second: 22,520.82400
Overall Steps per Second: 10,625.64395

Timestep Collection Time: 2.22106
Timestep Consumption Time: 2.48642
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.70748

Cumulative Model Updates: 94,390
Cumulative Timesteps: 787,204,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,981.03733
Policy Entropy: 3.68926
Value Function Loss: 0.07543

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.62070
Value Function Update Magnitude: 0.81271

Collected Steps per Second: 22,790.02099
Overall Steps per Second: 10,705.04380

Timestep Collection Time: 2.19517
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.67331

Cumulative Model Updates: 94,396
Cumulative Timesteps: 787,254,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 787254968...
Checkpoint 787254968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.84774
Policy Entropy: 3.67941
Value Function Loss: 0.07369

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.58767
Value Function Update Magnitude: 0.88329

Collected Steps per Second: 22,595.53456
Overall Steps per Second: 10,633.92882

Timestep Collection Time: 2.21415
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.70475

Cumulative Model Updates: 94,402
Cumulative Timesteps: 787,304,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.86838
Policy Entropy: 3.67370
Value Function Loss: 0.07360

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.68885
Value Function Update Magnitude: 0.90080

Collected Steps per Second: 22,227.57024
Overall Steps per Second: 10,494.58535

Timestep Collection Time: 2.24964
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.76474

Cumulative Model Updates: 94,408
Cumulative Timesteps: 787,355,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 787355002...
Checkpoint 787355002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.10675
Policy Entropy: 3.66696
Value Function Loss: 0.07186

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.81696
Value Function Update Magnitude: 0.93032

Collected Steps per Second: 22,557.54397
Overall Steps per Second: 10,676.44777

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.46734
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.68452

Cumulative Model Updates: 94,414
Cumulative Timesteps: 787,405,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,159.93530
Policy Entropy: 3.65109
Value Function Loss: 0.07500

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.84059
Value Function Update Magnitude: 0.88882

Collected Steps per Second: 23,134.73108
Overall Steps per Second: 10,814.23045

Timestep Collection Time: 2.16125
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62354

Cumulative Model Updates: 94,420
Cumulative Timesteps: 787,455,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 787455016...
Checkpoint 787455016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,152.58419
Policy Entropy: 3.65018
Value Function Loss: 0.07279

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.76214
Value Function Update Magnitude: 0.79592

Collected Steps per Second: 22,660.94156
Overall Steps per Second: 10,676.50808

Timestep Collection Time: 2.20759
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.68561

Cumulative Model Updates: 94,426
Cumulative Timesteps: 787,505,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,184.62726
Policy Entropy: 3.65147
Value Function Loss: 0.07309

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.72747
Value Function Update Magnitude: 0.87037

Collected Steps per Second: 22,954.03709
Overall Steps per Second: 10,836.33115

Timestep Collection Time: 2.17922
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61614

Cumulative Model Updates: 94,432
Cumulative Timesteps: 787,555,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 787555064...
Checkpoint 787555064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,910.67037
Policy Entropy: 3.67437
Value Function Loss: 0.07327

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.64518
Value Function Update Magnitude: 0.85812

Collected Steps per Second: 22,820.08989
Overall Steps per Second: 10,694.07053

Timestep Collection Time: 2.19263
Timestep Consumption Time: 2.48623
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.67885

Cumulative Model Updates: 94,438
Cumulative Timesteps: 787,605,100

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,367.48561
Policy Entropy: 3.67053
Value Function Loss: 0.07405

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.62782
Value Function Update Magnitude: 0.85943

Collected Steps per Second: 22,443.24599
Overall Steps per Second: 10,564.26906

Timestep Collection Time: 2.22829
Timestep Consumption Time: 2.50559
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.73388

Cumulative Model Updates: 94,444
Cumulative Timesteps: 787,655,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 787655110...
Checkpoint 787655110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,169.13504
Policy Entropy: 3.66421
Value Function Loss: 0.07600

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.65133
Value Function Update Magnitude: 0.86706

Collected Steps per Second: 22,930.52599
Overall Steps per Second: 10,730.74503

Timestep Collection Time: 2.18146
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.66156

Cumulative Model Updates: 94,450
Cumulative Timesteps: 787,705,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,641.91294
Policy Entropy: 3.65077
Value Function Loss: 0.07474

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.67500
Value Function Update Magnitude: 0.82714

Collected Steps per Second: 22,760.00362
Overall Steps per Second: 10,674.32158

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.48770
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.68489

Cumulative Model Updates: 94,456
Cumulative Timesteps: 787,755,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 787755140...
Checkpoint 787755140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.35311
Policy Entropy: 3.65463
Value Function Loss: 0.07433

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.61494
Value Function Update Magnitude: 0.76428

Collected Steps per Second: 22,364.82236
Overall Steps per Second: 10,698.67769

Timestep Collection Time: 2.23601
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.67422

Cumulative Model Updates: 94,462
Cumulative Timesteps: 787,805,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,455.56037
Policy Entropy: 3.66196
Value Function Loss: 0.07284

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.67740
Value Function Update Magnitude: 0.74805

Collected Steps per Second: 22,687.65490
Overall Steps per Second: 10,789.21259

Timestep Collection Time: 2.20499
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.63667

Cumulative Model Updates: 94,468
Cumulative Timesteps: 787,855,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 787855174...
Checkpoint 787855174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,037.37551
Policy Entropy: 3.65970
Value Function Loss: 0.07459

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.70585
Value Function Update Magnitude: 0.72225

Collected Steps per Second: 22,563.70841
Overall Steps per Second: 10,713.53883

Timestep Collection Time: 2.21595
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.66699

Cumulative Model Updates: 94,474
Cumulative Timesteps: 787,905,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.60727
Policy Entropy: 3.66842
Value Function Loss: 0.07289

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.66049
Value Function Update Magnitude: 0.74415

Collected Steps per Second: 22,986.53347
Overall Steps per Second: 10,647.96084

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.69780

Cumulative Model Updates: 94,480
Cumulative Timesteps: 787,955,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 787955196...
Checkpoint 787955196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.32337
Policy Entropy: 3.65426
Value Function Loss: 0.07197

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.62138
Value Function Update Magnitude: 0.79554

Collected Steps per Second: 22,959.84520
Overall Steps per Second: 10,843.58523

Timestep Collection Time: 2.17841
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61250

Cumulative Model Updates: 94,486
Cumulative Timesteps: 788,005,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,837.59895
Policy Entropy: 3.66095
Value Function Loss: 0.07238

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.71193
Value Function Update Magnitude: 0.82992

Collected Steps per Second: 22,708.48747
Overall Steps per Second: 10,609.76898

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.51162
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.71415

Cumulative Model Updates: 94,492
Cumulative Timesteps: 788,055,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 788055228...
Checkpoint 788055228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,721.22889
Policy Entropy: 3.64330
Value Function Loss: 0.07531

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.72900
Value Function Update Magnitude: 0.87476

Collected Steps per Second: 22,810.39438
Overall Steps per Second: 10,665.19886

Timestep Collection Time: 2.19260
Timestep Consumption Time: 2.49686
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.68946

Cumulative Model Updates: 94,498
Cumulative Timesteps: 788,105,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,636.90834
Policy Entropy: 3.63966
Value Function Loss: 0.07526

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.60567
Value Function Update Magnitude: 0.87188

Collected Steps per Second: 22,690.85616
Overall Steps per Second: 10,757.45607

Timestep Collection Time: 2.20485
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.65073

Cumulative Model Updates: 94,504
Cumulative Timesteps: 788,155,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 788155272...
Checkpoint 788155272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,775.29919
Policy Entropy: 3.64040
Value Function Loss: 0.07521

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.90833

Collected Steps per Second: 22,800.24050
Overall Steps per Second: 10,709.94475

Timestep Collection Time: 2.19428
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67136

Cumulative Model Updates: 94,510
Cumulative Timesteps: 788,205,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,321.05588
Policy Entropy: 3.64739
Value Function Loss: 0.07618

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.51598
Value Function Update Magnitude: 0.86979

Collected Steps per Second: 22,517.92912
Overall Steps per Second: 10,814.74074

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.40364
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62480

Cumulative Model Updates: 94,516
Cumulative Timesteps: 788,255,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 788255318...
Checkpoint 788255318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,202.08501
Policy Entropy: 3.64828
Value Function Loss: 0.07752

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.84064

Collected Steps per Second: 22,114.61771
Overall Steps per Second: 10,648.95015

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.69793

Cumulative Model Updates: 94,522
Cumulative Timesteps: 788,305,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,302.78867
Policy Entropy: 3.64100
Value Function Loss: 0.08082

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.58056
Value Function Update Magnitude: 0.79521

Collected Steps per Second: 22,498.68048
Overall Steps per Second: 10,569.91691

Timestep Collection Time: 2.22315
Timestep Consumption Time: 2.50896
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.73211

Cumulative Model Updates: 94,528
Cumulative Timesteps: 788,355,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 788355364...
Checkpoint 788355364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,131.21390
Policy Entropy: 3.63864
Value Function Loss: 0.08243

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.68646
Value Function Update Magnitude: 0.77229

Collected Steps per Second: 22,709.77731
Overall Steps per Second: 10,578.05417

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.52558
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.72771

Cumulative Model Updates: 94,534
Cumulative Timesteps: 788,405,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.67251
Policy Entropy: 3.64067
Value Function Loss: 0.08118

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.74054
Value Function Update Magnitude: 0.81065

Collected Steps per Second: 23,158.37606
Overall Steps per Second: 10,844.82270

Timestep Collection Time: 2.16026
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.61308

Cumulative Model Updates: 94,540
Cumulative Timesteps: 788,455,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 788455402...
Checkpoint 788455402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.77934
Policy Entropy: 3.64298
Value Function Loss: 0.07770

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.66711
Value Function Update Magnitude: 0.85563

Collected Steps per Second: 22,808.85228
Overall Steps per Second: 10,706.56453

Timestep Collection Time: 2.19239
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.67059

Cumulative Model Updates: 94,546
Cumulative Timesteps: 788,505,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,684.95769
Policy Entropy: 3.62595
Value Function Loss: 0.07577

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.57408
Value Function Update Magnitude: 0.90142

Collected Steps per Second: 22,947.28714
Overall Steps per Second: 10,840.78200

Timestep Collection Time: 2.17891
Timestep Consumption Time: 2.43331
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61221

Cumulative Model Updates: 94,552
Cumulative Timesteps: 788,555,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 788555408...
Checkpoint 788555408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,909.86940
Policy Entropy: 3.62217
Value Function Loss: 0.07565

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.54537
Value Function Update Magnitude: 0.88917

Collected Steps per Second: 22,516.30715
Overall Steps per Second: 10,716.25472

Timestep Collection Time: 2.22168
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.66805

Cumulative Model Updates: 94,558
Cumulative Timesteps: 788,605,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,968.27872
Policy Entropy: 3.63102
Value Function Loss: 0.07657

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.51206
Value Function Update Magnitude: 0.78956

Collected Steps per Second: 23,107.22044
Overall Steps per Second: 10,968.54925

Timestep Collection Time: 2.16495
Timestep Consumption Time: 2.39591
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.56086

Cumulative Model Updates: 94,564
Cumulative Timesteps: 788,655,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 788655458...
Checkpoint 788655458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,903.24953
Policy Entropy: 3.64185
Value Function Loss: 0.07523

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.77846

Collected Steps per Second: 22,304.85393
Overall Steps per Second: 10,577.29947

Timestep Collection Time: 2.24283
Timestep Consumption Time: 2.48673
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.72956

Cumulative Model Updates: 94,570
Cumulative Timesteps: 788,705,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,808.92611
Policy Entropy: 3.65665
Value Function Loss: 0.07364

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.68740
Value Function Update Magnitude: 0.82877

Collected Steps per Second: 22,432.60798
Overall Steps per Second: 10,603.59226

Timestep Collection Time: 2.22934
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.71633

Cumulative Model Updates: 94,576
Cumulative Timesteps: 788,755,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 788755494...
Checkpoint 788755494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,896.35671
Policy Entropy: 3.65191
Value Function Loss: 0.07326

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.73054
Value Function Update Magnitude: 0.82042

Collected Steps per Second: 22,506.16785
Overall Steps per Second: 10,594.40752

Timestep Collection Time: 2.22241
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.72117

Cumulative Model Updates: 94,582
Cumulative Timesteps: 788,805,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.27794
Policy Entropy: 3.64572
Value Function Loss: 0.07334

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.63263
Value Function Update Magnitude: 0.88206

Collected Steps per Second: 22,731.44188
Overall Steps per Second: 10,747.00589

Timestep Collection Time: 2.19960
Timestep Consumption Time: 2.45286
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.65246

Cumulative Model Updates: 94,588
Cumulative Timesteps: 788,855,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 788855512...
Checkpoint 788855512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.89882
Policy Entropy: 3.62409
Value Function Loss: 0.07462

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.57454
Value Function Update Magnitude: 0.89872

Collected Steps per Second: 22,746.27715
Overall Steps per Second: 10,701.15292

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.47532
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.67445

Cumulative Model Updates: 94,594
Cumulative Timesteps: 788,905,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,422.31248
Policy Entropy: 3.64133
Value Function Loss: 0.07548

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.83331

Collected Steps per Second: 22,865.09934
Overall Steps per Second: 10,815.66949

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62477

Cumulative Model Updates: 94,600
Cumulative Timesteps: 788,955,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 788955554...
Checkpoint 788955554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,173.08593
Policy Entropy: 3.63969
Value Function Loss: 0.07700

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.60883
Value Function Update Magnitude: 0.76605

Collected Steps per Second: 20,460.86317
Overall Steps per Second: 10,184.20340

Timestep Collection Time: 2.44457
Timestep Consumption Time: 2.46676
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.91133

Cumulative Model Updates: 94,606
Cumulative Timesteps: 789,005,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,006.76743
Policy Entropy: 3.64701
Value Function Loss: 0.07533

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.53434
Value Function Update Magnitude: 0.85328

Collected Steps per Second: 22,889.36705
Overall Steps per Second: 10,654.11667

Timestep Collection Time: 2.18512
Timestep Consumption Time: 2.50940
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.69452

Cumulative Model Updates: 94,612
Cumulative Timesteps: 789,055,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 789055588...
Checkpoint 789055588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,639.96985
Policy Entropy: 3.63421
Value Function Loss: 0.07535

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.52501
Value Function Update Magnitude: 0.89425

Collected Steps per Second: 23,020.75491
Overall Steps per Second: 10,750.15899

Timestep Collection Time: 2.17195
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.65109

Cumulative Model Updates: 94,618
Cumulative Timesteps: 789,105,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.10985
Policy Entropy: 3.64184
Value Function Loss: 0.07462

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.48770
Value Function Update Magnitude: 0.88849

Collected Steps per Second: 22,801.56809
Overall Steps per Second: 10,722.79716

Timestep Collection Time: 2.19520
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.66800

Cumulative Model Updates: 94,624
Cumulative Timesteps: 789,155,642

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 789155642...
Checkpoint 789155642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,317.58628
Policy Entropy: 3.64838
Value Function Loss: 0.07425

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.61337
Value Function Update Magnitude: 0.87033

Collected Steps per Second: 22,519.74586
Overall Steps per Second: 10,647.64593

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.69719

Cumulative Model Updates: 94,630
Cumulative Timesteps: 789,205,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,229.15823
Policy Entropy: 3.65603
Value Function Loss: 0.07567

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.66320
Value Function Update Magnitude: 0.86065

Collected Steps per Second: 22,370.97852
Overall Steps per Second: 10,578.82832

Timestep Collection Time: 2.23638
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72926

Cumulative Model Updates: 94,636
Cumulative Timesteps: 789,255,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 789255686...
Checkpoint 789255686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,385.41978
Policy Entropy: 3.64395
Value Function Loss: 0.07976

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.88063

Collected Steps per Second: 22,681.03504
Overall Steps per Second: 10,630.60868

Timestep Collection Time: 2.20634
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.70735

Cumulative Model Updates: 94,642
Cumulative Timesteps: 789,305,728

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,754.76781
Policy Entropy: 3.64842
Value Function Loss: 0.08020

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.49068
Value Function Update Magnitude: 0.85173

Collected Steps per Second: 22,340.79737
Overall Steps per Second: 10,568.81266

Timestep Collection Time: 2.23931
Timestep Consumption Time: 2.49424
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.73355

Cumulative Model Updates: 94,648
Cumulative Timesteps: 789,355,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 789355756...
Checkpoint 789355756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,247.96094
Policy Entropy: 3.64173
Value Function Loss: 0.08059

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.87010

Collected Steps per Second: 22,430.32298
Overall Steps per Second: 10,627.49475

Timestep Collection Time: 2.22984
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.70628

Cumulative Model Updates: 94,654
Cumulative Timesteps: 789,405,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,938.51766
Policy Entropy: 3.64698
Value Function Loss: 0.08176

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.83358

Collected Steps per Second: 22,991.46931
Overall Steps per Second: 10,655.23542

Timestep Collection Time: 2.17585
Timestep Consumption Time: 2.51912
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.69497

Cumulative Model Updates: 94,660
Cumulative Timesteps: 789,455,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 789455798...
Checkpoint 789455798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.51467
Policy Entropy: 3.64296
Value Function Loss: 0.08276

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.53446
Value Function Update Magnitude: 0.79258

Collected Steps per Second: 22,871.29082
Overall Steps per Second: 10,716.99288

Timestep Collection Time: 2.18685
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.66698

Cumulative Model Updates: 94,666
Cumulative Timesteps: 789,505,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,439.24067
Policy Entropy: 3.65106
Value Function Loss: 0.08279

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.54391
Value Function Update Magnitude: 0.85488

Collected Steps per Second: 22,674.93656
Overall Steps per Second: 10,635.96106

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.49805
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70498

Cumulative Model Updates: 94,672
Cumulative Timesteps: 789,555,856

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 789555856...
Checkpoint 789555856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.53705
Policy Entropy: 3.64855
Value Function Loss: 0.08132

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.87130

Collected Steps per Second: 23,020.83688
Overall Steps per Second: 10,899.07851

Timestep Collection Time: 2.17221
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.58809

Cumulative Model Updates: 94,678
Cumulative Timesteps: 789,605,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,093.28955
Policy Entropy: 3.64919
Value Function Loss: 0.08290

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.56658
Value Function Update Magnitude: 0.81707

Collected Steps per Second: 22,667.08375
Overall Steps per Second: 10,622.54656

Timestep Collection Time: 2.20646
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.70829

Cumulative Model Updates: 94,684
Cumulative Timesteps: 789,655,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 789655876...
Checkpoint 789655876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,208.12335
Policy Entropy: 3.64426
Value Function Loss: 0.07840

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.58974
Value Function Update Magnitude: 0.81413

Collected Steps per Second: 23,057.49755
Overall Steps per Second: 10,834.00649

Timestep Collection Time: 2.16971
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61768

Cumulative Model Updates: 94,690
Cumulative Timesteps: 789,705,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,770.62543
Policy Entropy: 3.64811
Value Function Loss: 0.07869

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.79740

Collected Steps per Second: 22,515.63449
Overall Steps per Second: 10,538.13698

Timestep Collection Time: 2.22183
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.74714

Cumulative Model Updates: 94,696
Cumulative Timesteps: 789,755,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 789755930...
Checkpoint 789755930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,516.36239
Policy Entropy: 3.64937
Value Function Loss: 0.07909

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.74389

Collected Steps per Second: 22,277.51673
Overall Steps per Second: 10,650.56703

Timestep Collection Time: 2.24567
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.69721

Cumulative Model Updates: 94,702
Cumulative Timesteps: 789,805,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.07573
Policy Entropy: 3.65367
Value Function Loss: 0.08296

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.73482

Collected Steps per Second: 22,899.37063
Overall Steps per Second: 10,844.80238

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61087

Cumulative Model Updates: 94,708
Cumulative Timesteps: 789,855,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 789855962...
Checkpoint 789855962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,670.96021
Policy Entropy: 3.64714
Value Function Loss: 0.08402

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.73758

Collected Steps per Second: 22,831.04814
Overall Steps per Second: 10,670.46615

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.68583

Cumulative Model Updates: 94,714
Cumulative Timesteps: 789,905,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,589.82270
Policy Entropy: 3.62903
Value Function Loss: 0.08611

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.59351
Value Function Update Magnitude: 0.74728

Collected Steps per Second: 22,811.83172
Overall Steps per Second: 10,836.66884

Timestep Collection Time: 2.19228
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.61489

Cumulative Model Updates: 94,720
Cumulative Timesteps: 789,955,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 789955972...
Checkpoint 789955972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,024.72669
Policy Entropy: 3.63728
Value Function Loss: 0.08312

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.68125
Value Function Update Magnitude: 0.84699

Collected Steps per Second: 22,945.92395
Overall Steps per Second: 10,743.33629

Timestep Collection Time: 2.17982
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.65572

Cumulative Model Updates: 94,726
Cumulative Timesteps: 790,005,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.53399
Policy Entropy: 3.63305
Value Function Loss: 0.08508

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.75752
Value Function Update Magnitude: 0.81777

Collected Steps per Second: 23,059.02333
Overall Steps per Second: 10,951.62114

Timestep Collection Time: 2.16948
Timestep Consumption Time: 2.39843
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.56791

Cumulative Model Updates: 94,732
Cumulative Timesteps: 790,056,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 790056016...
Checkpoint 790056016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,052.37167
Policy Entropy: 3.62890
Value Function Loss: 0.08682

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.61866
Value Function Update Magnitude: 0.86014

Collected Steps per Second: 22,901.87661
Overall Steps per Second: 10,662.28109

Timestep Collection Time: 2.18532
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.69393

Cumulative Model Updates: 94,738
Cumulative Timesteps: 790,106,064

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,119.24908
Policy Entropy: 3.61913
Value Function Loss: 0.08912

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.61550
Value Function Update Magnitude: 0.80835

Collected Steps per Second: 22,821.02141
Overall Steps per Second: 10,807.89805

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.62717

Cumulative Model Updates: 94,744
Cumulative Timesteps: 790,156,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 790156074...
Checkpoint 790156074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,265.41604
Policy Entropy: 3.61980
Value Function Loss: 0.08655

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.67354
Value Function Update Magnitude: 0.81300

Collected Steps per Second: 22,427.57037
Overall Steps per Second: 10,671.19795

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.45680
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.68682

Cumulative Model Updates: 94,750
Cumulative Timesteps: 790,206,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,927.59650
Policy Entropy: 3.61556
Value Function Loss: 0.08506

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.82517

Collected Steps per Second: 22,418.44652
Overall Steps per Second: 10,597.22849

Timestep Collection Time: 2.23040
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.71840

Cumulative Model Updates: 94,756
Cumulative Timesteps: 790,256,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 790256090...
Checkpoint 790256090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,118.53202
Policy Entropy: 3.60953
Value Function Loss: 0.08453

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.45910
Value Function Update Magnitude: 0.74875

Collected Steps per Second: 22,275.28080
Overall Steps per Second: 10,633.68365

Timestep Collection Time: 2.24536
Timestep Consumption Time: 2.45819
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70354

Cumulative Model Updates: 94,762
Cumulative Timesteps: 790,306,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,851.69571
Policy Entropy: 3.59282
Value Function Loss: 0.08908

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.44539
Value Function Update Magnitude: 0.67976

Collected Steps per Second: 22,926.20971
Overall Steps per Second: 10,820.58294

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.62286

Cumulative Model Updates: 94,768
Cumulative Timesteps: 790,356,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 790356128...
Checkpoint 790356128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,781.37587
Policy Entropy: 3.59042
Value Function Loss: 0.08860

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.46353
Value Function Update Magnitude: 0.70314

Collected Steps per Second: 22,848.74593
Overall Steps per Second: 10,627.35116

Timestep Collection Time: 2.18883
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.70597

Cumulative Model Updates: 94,774
Cumulative Timesteps: 790,406,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,390.83713
Policy Entropy: 3.59510
Value Function Loss: 0.08870

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.51004
Value Function Update Magnitude: 0.66912

Collected Steps per Second: 22,968.93532
Overall Steps per Second: 10,833.96610

Timestep Collection Time: 2.17781
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61715

Cumulative Model Updates: 94,780
Cumulative Timesteps: 790,456,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 790456162...
Checkpoint 790456162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.90480
Policy Entropy: 3.59786
Value Function Loss: 0.08684

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.51945
Value Function Update Magnitude: 0.63641

Collected Steps per Second: 23,057.52773
Overall Steps per Second: 10,685.25435

Timestep Collection Time: 2.16979
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.68215

Cumulative Model Updates: 94,786
Cumulative Timesteps: 790,506,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,789.21513
Policy Entropy: 3.58690
Value Function Loss: 0.08638

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.48101
Value Function Update Magnitude: 0.61125

Collected Steps per Second: 22,976.08431
Overall Steps per Second: 10,857.54759

Timestep Collection Time: 2.17644
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60564

Cumulative Model Updates: 94,792
Cumulative Timesteps: 790,556,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 790556198...
Checkpoint 790556198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,673.42508
Policy Entropy: 3.59168
Value Function Loss: 0.08559

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.47864
Value Function Update Magnitude: 0.58392

Collected Steps per Second: 22,858.12274
Overall Steps per Second: 10,688.51163

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.49121
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.67923

Cumulative Model Updates: 94,798
Cumulative Timesteps: 790,606,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,363.39728
Policy Entropy: 3.59266
Value Function Loss: 0.08531

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.53202
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 23,001.84147
Overall Steps per Second: 10,841.17332

Timestep Collection Time: 2.17478
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61426

Cumulative Model Updates: 94,804
Cumulative Timesteps: 790,656,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 790656236...
Checkpoint 790656236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,952.37453
Policy Entropy: 3.60776
Value Function Loss: 0.08456

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.50877
Value Function Update Magnitude: 0.64533

Collected Steps per Second: 22,601.39835
Overall Steps per Second: 10,691.36709

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.67667

Cumulative Model Updates: 94,810
Cumulative Timesteps: 790,706,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,603.79901
Policy Entropy: 3.60070
Value Function Loss: 0.08185

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.58679
Value Function Update Magnitude: 0.69190

Collected Steps per Second: 22,492.98275
Overall Steps per Second: 10,641.67238

Timestep Collection Time: 2.22398
Timestep Consumption Time: 2.47678
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70076

Cumulative Model Updates: 94,816
Cumulative Timesteps: 790,756,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 790756260...
Checkpoint 790756260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,873.15244
Policy Entropy: 3.60986
Value Function Loss: 0.08458

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.51211
Value Function Update Magnitude: 0.66406

Collected Steps per Second: 22,218.53977
Overall Steps per Second: 10,546.97380

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.74183

Cumulative Model Updates: 94,822
Cumulative Timesteps: 790,806,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,814.49469
Policy Entropy: 3.60725
Value Function Loss: 0.08431

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.46994
Value Function Update Magnitude: 0.62296

Collected Steps per Second: 21,899.61682
Overall Steps per Second: 10,459.23202

Timestep Collection Time: 2.28360
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.78142

Cumulative Model Updates: 94,828
Cumulative Timesteps: 790,856,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 790856282...
Checkpoint 790856282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,960.29081
Policy Entropy: 3.61347
Value Function Loss: 0.08636

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.46540
Value Function Update Magnitude: 0.63089

Collected Steps per Second: 22,372.78559
Overall Steps per Second: 10,556.33609

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73820

Cumulative Model Updates: 94,834
Cumulative Timesteps: 790,906,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,896.98002
Policy Entropy: 3.61835
Value Function Loss: 0.08290

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.47000
Value Function Update Magnitude: 0.75934

Collected Steps per Second: 22,410.02231
Overall Steps per Second: 10,588.69911

Timestep Collection Time: 2.23195
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.72372

Cumulative Model Updates: 94,840
Cumulative Timesteps: 790,956,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 790956318...
Checkpoint 790956318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,454.26588
Policy Entropy: 3.61512
Value Function Loss: 0.08386

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.48585
Value Function Update Magnitude: 0.86356

Collected Steps per Second: 22,654.97485
Overall Steps per Second: 10,643.88278

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70016

Cumulative Model Updates: 94,846
Cumulative Timesteps: 791,006,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,464.08558
Policy Entropy: 3.61447
Value Function Loss: 0.08274

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.83880

Collected Steps per Second: 23,084.32095
Overall Steps per Second: 10,719.16282

Timestep Collection Time: 2.16684
Timestep Consumption Time: 2.49957
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.66641

Cumulative Model Updates: 94,852
Cumulative Timesteps: 791,056,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 791056366...
Checkpoint 791056366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,439.78903
Policy Entropy: 3.60463
Value Function Loss: 0.08351

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.84221

Collected Steps per Second: 22,717.67425
Overall Steps per Second: 10,623.00513

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.70714

Cumulative Model Updates: 94,858
Cumulative Timesteps: 791,106,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,159.07701
Policy Entropy: 3.61280
Value Function Loss: 0.08338

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.50371
Value Function Update Magnitude: 0.85585

Collected Steps per Second: 23,156.66271
Overall Steps per Second: 10,982.32825

Timestep Collection Time: 2.16024
Timestep Consumption Time: 2.39471
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.55495

Cumulative Model Updates: 94,864
Cumulative Timesteps: 791,156,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 791156394...
Checkpoint 791156394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.80427
Policy Entropy: 3.59174
Value Function Loss: 0.08942

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.46701
Value Function Update Magnitude: 0.73263

Collected Steps per Second: 22,969.37160
Overall Steps per Second: 10,739.63577

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.65658

Cumulative Model Updates: 94,870
Cumulative Timesteps: 791,206,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,428.80645
Policy Entropy: 3.57592
Value Function Loss: 0.09088

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.46955
Value Function Update Magnitude: 0.63783

Collected Steps per Second: 22,636.85924
Overall Steps per Second: 10,736.51866

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.65924

Cumulative Model Updates: 94,876
Cumulative Timesteps: 791,256,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 791256428...
Checkpoint 791256428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,779.19092
Policy Entropy: 3.55758
Value Function Loss: 0.09416

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.46569
Value Function Update Magnitude: 0.59574

Collected Steps per Second: 22,586.35835
Overall Steps per Second: 10,651.67591

Timestep Collection Time: 2.21497
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.69673

Cumulative Model Updates: 94,882
Cumulative Timesteps: 791,306,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,334.92370
Policy Entropy: 3.56725
Value Function Loss: 0.09490

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06955
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.60658

Collected Steps per Second: 22,688.71834
Overall Steps per Second: 10,675.92283

Timestep Collection Time: 2.20497
Timestep Consumption Time: 2.48109
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.68606

Cumulative Model Updates: 94,888
Cumulative Timesteps: 791,356,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 791356484...
Checkpoint 791356484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.18390
Policy Entropy: 3.56234
Value Function Loss: 0.10008

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.60289
Value Function Update Magnitude: 0.54406

Collected Steps per Second: 22,667.48979
Overall Steps per Second: 10,826.64677

Timestep Collection Time: 2.20704
Timestep Consumption Time: 2.41378
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62082

Cumulative Model Updates: 94,894
Cumulative Timesteps: 791,406,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,200.60187
Policy Entropy: 3.57834
Value Function Loss: 0.09755

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.54792

Collected Steps per Second: 22,528.77578
Overall Steps per Second: 10,563.98384

Timestep Collection Time: 2.21938
Timestep Consumption Time: 2.51368
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.73306

Cumulative Model Updates: 94,900
Cumulative Timesteps: 791,456,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 791456512...
Checkpoint 791456512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.00285
Policy Entropy: 3.57846
Value Function Loss: 0.09296

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.48899
Value Function Update Magnitude: 0.59473

Collected Steps per Second: 22,368.39040
Overall Steps per Second: 10,571.99480

Timestep Collection Time: 2.23619
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.73137

Cumulative Model Updates: 94,906
Cumulative Timesteps: 791,506,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.05882
Policy Entropy: 3.58029
Value Function Loss: 0.09144

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.44911
Value Function Update Magnitude: 0.59870

Collected Steps per Second: 23,204.31988
Overall Steps per Second: 10,862.73104

Timestep Collection Time: 2.15563
Timestep Consumption Time: 2.44910
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.60474

Cumulative Model Updates: 94,912
Cumulative Timesteps: 791,556,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 791556552...
Checkpoint 791556552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,159.30541
Policy Entropy: 3.59125
Value Function Loss: 0.08738

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.42950
Value Function Update Magnitude: 0.61759

Collected Steps per Second: 22,729.85690
Overall Steps per Second: 10,712.10619

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.66911

Cumulative Model Updates: 94,918
Cumulative Timesteps: 791,606,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,913.18226
Policy Entropy: 3.59534
Value Function Loss: 0.08741

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.54411
Value Function Update Magnitude: 0.64660

Collected Steps per Second: 22,864.87753
Overall Steps per Second: 10,808.17170

Timestep Collection Time: 2.18711
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62687

Cumulative Model Updates: 94,924
Cumulative Timesteps: 791,656,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 791656576...
Checkpoint 791656576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,948.50514
Policy Entropy: 3.60491
Value Function Loss: 0.08423

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.58394
Value Function Update Magnitude: 0.69582

Collected Steps per Second: 22,783.86819
Overall Steps per Second: 10,716.02560

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.47226
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.66759

Cumulative Model Updates: 94,930
Cumulative Timesteps: 791,706,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,639.86982
Policy Entropy: 3.59555
Value Function Loss: 0.08458

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.59786
Value Function Update Magnitude: 0.70761

Collected Steps per Second: 22,739.63302
Overall Steps per Second: 10,608.06113

Timestep Collection Time: 2.19986
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.71566

Cumulative Model Updates: 94,936
Cumulative Timesteps: 791,756,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 791756618...
Checkpoint 791756618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,043.74627
Policy Entropy: 3.59013
Value Function Loss: 0.08442

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.65882

Collected Steps per Second: 22,792.39462
Overall Steps per Second: 10,723.50352

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.46973
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.66415

Cumulative Model Updates: 94,942
Cumulative Timesteps: 791,806,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,319.34349
Policy Entropy: 3.58762
Value Function Loss: 0.08976

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.53337
Value Function Update Magnitude: 0.65885

Collected Steps per Second: 23,162.41119
Overall Steps per Second: 10,702.49060

Timestep Collection Time: 2.15884
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.67218

Cumulative Model Updates: 94,948
Cumulative Timesteps: 791,856,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 791856638...
Checkpoint 791856638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,530.00642
Policy Entropy: 3.58458
Value Function Loss: 0.08863

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.51614
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 22,301.93442
Overall Steps per Second: 10,623.97498

Timestep Collection Time: 2.24232
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.70709

Cumulative Model Updates: 94,954
Cumulative Timesteps: 791,906,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,716.53264
Policy Entropy: 3.58697
Value Function Loss: 0.09236

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.49945
Value Function Update Magnitude: 0.62750

Collected Steps per Second: 22,834.20130
Overall Steps per Second: 10,827.50953

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.42885
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.61916

Cumulative Model Updates: 94,960
Cumulative Timesteps: 791,956,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 791956660...
Checkpoint 791956660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,707.80253
Policy Entropy: 3.59911
Value Function Loss: 0.09087

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.45084
Value Function Update Magnitude: 0.68552

Collected Steps per Second: 22,370.26023
Overall Steps per Second: 10,750.38139

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.41714
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.65342

Cumulative Model Updates: 94,966
Cumulative Timesteps: 792,006,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,807.94339
Policy Entropy: 3.59771
Value Function Loss: 0.09262

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.47149
Value Function Update Magnitude: 0.65768

Collected Steps per Second: 22,748.74584
Overall Steps per Second: 10,777.83908

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.44201
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.64063

Cumulative Model Updates: 94,972
Cumulative Timesteps: 792,056,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 792056702...
Checkpoint 792056702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,260.94828
Policy Entropy: 3.58655
Value Function Loss: 0.09041

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.48092
Value Function Update Magnitude: 0.65506

Collected Steps per Second: 22,594.77712
Overall Steps per Second: 10,693.47674

Timestep Collection Time: 2.21299
Timestep Consumption Time: 2.46295
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.67593

Cumulative Model Updates: 94,978
Cumulative Timesteps: 792,106,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.24197
Policy Entropy: 3.58739
Value Function Loss: 0.09249

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.49802
Value Function Update Magnitude: 0.62579

Collected Steps per Second: 22,886.09483
Overall Steps per Second: 10,826.52233

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61847

Cumulative Model Updates: 94,984
Cumulative Timesteps: 792,156,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 792156706...
Checkpoint 792156706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,423.48935
Policy Entropy: 3.59111
Value Function Loss: 0.09293

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.52141
Value Function Update Magnitude: 0.65462

Collected Steps per Second: 22,712.84139
Overall Steps per Second: 10,733.88116

Timestep Collection Time: 2.20228
Timestep Consumption Time: 2.45773
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.66001

Cumulative Model Updates: 94,990
Cumulative Timesteps: 792,206,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,348.09124
Policy Entropy: 3.59430
Value Function Loss: 0.09267

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.63249

Collected Steps per Second: 22,906.05426
Overall Steps per Second: 10,840.44182

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61347

Cumulative Model Updates: 94,996
Cumulative Timesteps: 792,256,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 792256738...
Checkpoint 792256738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,040.23479
Policy Entropy: 3.55567
Value Function Loss: 0.09518

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.60348

Collected Steps per Second: 22,932.41281
Overall Steps per Second: 10,701.52081

Timestep Collection Time: 2.18049
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.67261

Cumulative Model Updates: 95,002
Cumulative Timesteps: 792,306,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,615.31030
Policy Entropy: 3.56263
Value Function Loss: 0.09367

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.45748
Value Function Update Magnitude: 0.57378

Collected Steps per Second: 22,863.26982
Overall Steps per Second: 10,908.05097

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.39762
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.58524

Cumulative Model Updates: 95,008
Cumulative Timesteps: 792,356,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 792356758...
Checkpoint 792356758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,666.95659
Policy Entropy: 3.55800
Value Function Loss: 0.09656

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.47635
Value Function Update Magnitude: 0.55231

Collected Steps per Second: 22,529.96297
Overall Steps per Second: 10,672.90143

Timestep Collection Time: 2.22033
Timestep Consumption Time: 2.46668
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.68701

Cumulative Model Updates: 95,014
Cumulative Timesteps: 792,406,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,570.93207
Policy Entropy: 3.58961
Value Function Loss: 0.08849

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.63011
Value Function Update Magnitude: 0.71679

Collected Steps per Second: 22,482.41868
Overall Steps per Second: 10,593.07119

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.72328

Cumulative Model Updates: 95,020
Cumulative Timesteps: 792,456,816

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 792456816...
Checkpoint 792456816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,953.94467
Policy Entropy: 3.57229
Value Function Loss: 0.08901

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.66872
Value Function Update Magnitude: 0.71297

Collected Steps per Second: 22,288.28172
Overall Steps per Second: 10,533.26181

Timestep Collection Time: 2.24360
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.74744

Cumulative Model Updates: 95,026
Cumulative Timesteps: 792,506,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.44538
Policy Entropy: 3.55717
Value Function Loss: 0.08656

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.59951
Value Function Update Magnitude: 0.62205

Collected Steps per Second: 22,319.73294
Overall Steps per Second: 10,575.03061

Timestep Collection Time: 2.24053
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.72888

Cumulative Model Updates: 95,032
Cumulative Timesteps: 792,556,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 792556830...
Checkpoint 792556830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,427.39604
Policy Entropy: 3.54658
Value Function Loss: 0.08728

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.61752

Collected Steps per Second: 22,800.68991
Overall Steps per Second: 10,649.85427

Timestep Collection Time: 2.19344
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.69603

Cumulative Model Updates: 95,038
Cumulative Timesteps: 792,606,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,639.19684
Policy Entropy: 3.56709
Value Function Loss: 0.08700

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.52348
Value Function Update Magnitude: 0.68055

Collected Steps per Second: 23,379.12189
Overall Steps per Second: 10,764.51662

Timestep Collection Time: 2.13883
Timestep Consumption Time: 2.50643
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.64526

Cumulative Model Updates: 95,044
Cumulative Timesteps: 792,656,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 792656846...
Checkpoint 792656846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,586.69926
Policy Entropy: 3.57643
Value Function Loss: 0.08330

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.51068
Value Function Update Magnitude: 0.69059

Collected Steps per Second: 22,812.99776
Overall Steps per Second: 10,680.33586

Timestep Collection Time: 2.19287
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.68394

Cumulative Model Updates: 95,050
Cumulative Timesteps: 792,706,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,251.15554
Policy Entropy: 3.59271
Value Function Loss: 0.08356

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.51018
Value Function Update Magnitude: 0.62688

Collected Steps per Second: 22,100.54813
Overall Steps per Second: 10,458.14614

Timestep Collection Time: 2.26293
Timestep Consumption Time: 2.51918
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.78211

Cumulative Model Updates: 95,056
Cumulative Timesteps: 792,756,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 792756884...
Checkpoint 792756884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,937.19798
Policy Entropy: 3.57938
Value Function Loss: 0.08473

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.50978
Value Function Update Magnitude: 0.61851

Collected Steps per Second: 23,026.70055
Overall Steps per Second: 10,789.26410

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.46304
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.63461

Cumulative Model Updates: 95,062
Cumulative Timesteps: 792,806,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,315.26312
Policy Entropy: 3.58387
Value Function Loss: 0.08336

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.49523
Value Function Update Magnitude: 0.66727

Collected Steps per Second: 21,897.03927
Overall Steps per Second: 10,662.95164

Timestep Collection Time: 2.28460
Timestep Consumption Time: 2.40697
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.69157

Cumulative Model Updates: 95,068
Cumulative Timesteps: 792,856,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 792856914...
Checkpoint 792856914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,215.05642
Policy Entropy: 3.59194
Value Function Loss: 0.08058

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.50354
Value Function Update Magnitude: 0.63874

Collected Steps per Second: 22,156.68761
Overall Steps per Second: 10,666.15175

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.68998

Cumulative Model Updates: 95,074
Cumulative Timesteps: 792,906,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,599.40343
Policy Entropy: 3.61120
Value Function Loss: 0.07430

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.46516
Value Function Update Magnitude: 0.65580

Collected Steps per Second: 21,722.71581
Overall Steps per Second: 10,628.78397

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.40429
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.70778

Cumulative Model Updates: 95,080
Cumulative Timesteps: 792,956,976

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 792956976...
Checkpoint 792956976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,399.43437
Policy Entropy: 3.62157
Value Function Loss: 0.07142

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.76333

Collected Steps per Second: 21,784.47824
Overall Steps per Second: 10,811.01430

Timestep Collection Time: 2.29641
Timestep Consumption Time: 2.33091
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62732

Cumulative Model Updates: 95,086
Cumulative Timesteps: 793,007,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,864.08978
Policy Entropy: 3.62195
Value Function Loss: 0.07195

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.63528
Value Function Update Magnitude: 0.76811

Collected Steps per Second: 21,700.58451
Overall Steps per Second: 10,551.23884

Timestep Collection Time: 2.30510
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.74087

Cumulative Model Updates: 95,092
Cumulative Timesteps: 793,057,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 793057024...
Checkpoint 793057024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,925.88695
Policy Entropy: 3.61507
Value Function Loss: 0.07283

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.65192

Collected Steps per Second: 21,844.81520
Overall Steps per Second: 10,606.31106

Timestep Collection Time: 2.29080
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.71813

Cumulative Model Updates: 95,098
Cumulative Timesteps: 793,107,066

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,327.74224
Policy Entropy: 3.60961
Value Function Loss: 0.07613

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.60743

Collected Steps per Second: 22,028.63546
Overall Steps per Second: 10,467.28856

Timestep Collection Time: 2.27086
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.77908

Cumulative Model Updates: 95,104
Cumulative Timesteps: 793,157,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 793157090...
Checkpoint 793157090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,262.96145
Policy Entropy: 3.62534
Value Function Loss: 0.07644

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.51098
Value Function Update Magnitude: 0.61036

Collected Steps per Second: 22,795.35179
Overall Steps per Second: 10,707.38229

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.47724
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.67154

Cumulative Model Updates: 95,110
Cumulative Timesteps: 793,207,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.07215
Policy Entropy: 3.63799
Value Function Loss: 0.07749

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.57646
Value Function Update Magnitude: 0.61771

Collected Steps per Second: 23,196.23030
Overall Steps per Second: 10,843.73680

Timestep Collection Time: 2.15570
Timestep Consumption Time: 2.45563
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.61133

Cumulative Model Updates: 95,116
Cumulative Timesteps: 793,257,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 793257114...
Checkpoint 793257114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.56398
Policy Entropy: 3.64184
Value Function Loss: 0.07429

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.68078
Value Function Update Magnitude: 0.61536

Collected Steps per Second: 22,530.36372
Overall Steps per Second: 10,633.47427

Timestep Collection Time: 2.22003
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.70382

Cumulative Model Updates: 95,122
Cumulative Timesteps: 793,307,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,177.76632
Policy Entropy: 3.64563
Value Function Loss: 0.07897

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.67835
Value Function Update Magnitude: 0.63719

Collected Steps per Second: 22,982.51963
Overall Steps per Second: 10,896.55285

Timestep Collection Time: 2.17591
Timestep Consumption Time: 2.41343
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.58934

Cumulative Model Updates: 95,128
Cumulative Timesteps: 793,357,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 793357140...
Checkpoint 793357140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,794.94805
Policy Entropy: 3.64204
Value Function Loss: 0.07987

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 22,932.61575
Overall Steps per Second: 10,671.17100

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.68740

Cumulative Model Updates: 95,134
Cumulative Timesteps: 793,407,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,436.19308
Policy Entropy: 3.64489
Value Function Loss: 0.08230

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.51022
Value Function Update Magnitude: 0.60319

Collected Steps per Second: 22,659.71597
Overall Steps per Second: 10,664.54237

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.48396
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.69237

Cumulative Model Updates: 95,140
Cumulative Timesteps: 793,457,202

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 793457202...
Checkpoint 793457202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,510.73577
Policy Entropy: 3.63492
Value Function Loss: 0.08486

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.58915
Value Function Update Magnitude: 0.62876

Collected Steps per Second: 22,229.80445
Overall Steps per Second: 10,521.21374

Timestep Collection Time: 2.24941
Timestep Consumption Time: 2.50327
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.75268

Cumulative Model Updates: 95,146
Cumulative Timesteps: 793,507,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,597.35316
Policy Entropy: 3.60882
Value Function Loss: 0.09071

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.60365
Value Function Update Magnitude: 0.66065

Collected Steps per Second: 22,466.36065
Overall Steps per Second: 10,745.22374

Timestep Collection Time: 2.22635
Timestep Consumption Time: 2.42855
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.65491

Cumulative Model Updates: 95,152
Cumulative Timesteps: 793,557,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 793557224...
Checkpoint 793557224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,895.52890
Policy Entropy: 3.59420
Value Function Loss: 0.08915

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.65787
Value Function Update Magnitude: 0.70628

Collected Steps per Second: 22,134.76270
Overall Steps per Second: 10,655.55210

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.69352

Cumulative Model Updates: 95,158
Cumulative Timesteps: 793,607,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,707.55667
Policy Entropy: 3.58440
Value Function Loss: 0.08719

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.67866
Value Function Update Magnitude: 0.73013

Collected Steps per Second: 23,024.40545
Overall Steps per Second: 10,609.40330

Timestep Collection Time: 2.17170
Timestep Consumption Time: 2.54129
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.71299

Cumulative Model Updates: 95,164
Cumulative Timesteps: 793,657,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 793657238...
Checkpoint 793657238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,203.96169
Policy Entropy: 3.59513
Value Function Loss: 0.08620

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.71835

Collected Steps per Second: 23,288.40272
Overall Steps per Second: 10,903.80485

Timestep Collection Time: 2.14819
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.58812

Cumulative Model Updates: 95,170
Cumulative Timesteps: 793,707,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,704.92729
Policy Entropy: 3.59257
Value Function Loss: 0.09050

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.51519
Value Function Update Magnitude: 0.76481

Collected Steps per Second: 22,600.89253
Overall Steps per Second: 10,622.77404

Timestep Collection Time: 2.21354
Timestep Consumption Time: 2.49596
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.70950

Cumulative Model Updates: 95,176
Cumulative Timesteps: 793,757,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 793757294...
Checkpoint 793757294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,607.95115
Policy Entropy: 3.59401
Value Function Loss: 0.09542

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.47784
Value Function Update Magnitude: 0.72713

Collected Steps per Second: 22,857.99609
Overall Steps per Second: 10,706.01307

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.67289

Cumulative Model Updates: 95,182
Cumulative Timesteps: 793,807,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,867.58658
Policy Entropy: 3.59012
Value Function Loss: 0.09602

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.46470
Value Function Update Magnitude: 0.64710

Collected Steps per Second: 23,057.26689
Overall Steps per Second: 10,753.64983

Timestep Collection Time: 2.16886
Timestep Consumption Time: 2.48147
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.65033

Cumulative Model Updates: 95,188
Cumulative Timesteps: 793,857,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 793857330...
Checkpoint 793857330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,828.55993
Policy Entropy: 3.59831
Value Function Loss: 0.09171

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.49338
Value Function Update Magnitude: 0.64914

Collected Steps per Second: 22,916.10611
Overall Steps per Second: 10,691.74144

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.67913

Cumulative Model Updates: 95,194
Cumulative Timesteps: 793,907,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,203.94093
Policy Entropy: 3.60487
Value Function Loss: 0.08869

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.70636

Collected Steps per Second: 22,698.97536
Overall Steps per Second: 10,819.09087

Timestep Collection Time: 2.20274
Timestep Consumption Time: 2.41872
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.62146

Cumulative Model Updates: 95,200
Cumulative Timesteps: 793,957,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 793957358...
Checkpoint 793957358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,090.47593
Policy Entropy: 3.60491
Value Function Loss: 0.08859

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.70311

Collected Steps per Second: 22,360.17738
Overall Steps per Second: 10,683.75589

Timestep Collection Time: 2.23728
Timestep Consumption Time: 2.44515
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.68244

Cumulative Model Updates: 95,206
Cumulative Timesteps: 794,007,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,844.86989
Policy Entropy: 3.60835
Value Function Loss: 0.09022

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.50375
Value Function Update Magnitude: 0.66931

Collected Steps per Second: 21,941.93929
Overall Steps per Second: 10,798.22754

Timestep Collection Time: 2.27901
Timestep Consumption Time: 2.35193
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.63095

Cumulative Model Updates: 95,212
Cumulative Timesteps: 794,057,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 794057390...
Checkpoint 794057390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,541.08976
Policy Entropy: 3.60071
Value Function Loss: 0.08668

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.47291
Value Function Update Magnitude: 0.66154

Collected Steps per Second: 21,583.66507
Overall Steps per Second: 10,714.86521

Timestep Collection Time: 2.31759
Timestep Consumption Time: 2.35088
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.66847

Cumulative Model Updates: 95,218
Cumulative Timesteps: 794,107,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,136.36105
Policy Entropy: 3.60144
Value Function Loss: 0.08571

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.49569
Value Function Update Magnitude: 0.66888

Collected Steps per Second: 21,837.57197
Overall Steps per Second: 10,629.31687

Timestep Collection Time: 2.29110
Timestep Consumption Time: 2.41588
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.70698

Cumulative Model Updates: 95,224
Cumulative Timesteps: 794,157,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 794157444...
Checkpoint 794157444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,081.29453
Policy Entropy: 3.58462
Value Function Loss: 0.08681

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.51534
Value Function Update Magnitude: 0.66227

Collected Steps per Second: 22,492.32840
Overall Steps per Second: 10,866.09918

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.37963
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60368

Cumulative Model Updates: 95,230
Cumulative Timesteps: 794,207,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,200.11806
Policy Entropy: 3.57921
Value Function Loss: 0.09286

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.61389

Collected Steps per Second: 22,174.93666
Overall Steps per Second: 10,730.68573

Timestep Collection Time: 2.25561
Timestep Consumption Time: 2.40560
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.66121

Cumulative Model Updates: 95,236
Cumulative Timesteps: 794,257,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 794257486...
Checkpoint 794257486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,184.55441
Policy Entropy: 3.58004
Value Function Loss: 0.09414

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.54137
Value Function Update Magnitude: 0.61778

Collected Steps per Second: 22,359.36603
Overall Steps per Second: 10,633.30891

Timestep Collection Time: 2.23665
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.70315

Cumulative Model Updates: 95,242
Cumulative Timesteps: 794,307,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,748.73393
Policy Entropy: 3.58078
Value Function Loss: 0.09520

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.59093

Collected Steps per Second: 22,756.59080
Overall Steps per Second: 10,730.57054

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.66052

Cumulative Model Updates: 95,248
Cumulative Timesteps: 794,357,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 794357506...
Checkpoint 794357506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,575.37203
Policy Entropy: 3.59239
Value Function Loss: 0.08945

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.59382

Collected Steps per Second: 22,568.87093
Overall Steps per Second: 10,692.24836

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.46134
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.67722

Cumulative Model Updates: 95,254
Cumulative Timesteps: 794,407,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,900.94018
Policy Entropy: 3.60356
Value Function Loss: 0.08630

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.54015
Value Function Update Magnitude: 0.67046

Collected Steps per Second: 22,956.53276
Overall Steps per Second: 10,855.76935

Timestep Collection Time: 2.17820
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.60621

Cumulative Model Updates: 95,260
Cumulative Timesteps: 794,457,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 794457520...
Checkpoint 794457520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,938.93184
Policy Entropy: 3.59811
Value Function Loss: 0.08450

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.53599
Value Function Update Magnitude: 0.69351

Collected Steps per Second: 22,336.35744
Overall Steps per Second: 10,614.72622

Timestep Collection Time: 2.23859
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.71063

Cumulative Model Updates: 95,266
Cumulative Timesteps: 794,507,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,169.59637
Policy Entropy: 3.60378
Value Function Loss: 0.08727

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.47954
Value Function Update Magnitude: 0.65689

Collected Steps per Second: 22,369.99198
Overall Steps per Second: 10,580.14698

Timestep Collection Time: 2.23603
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.72772

Cumulative Model Updates: 95,272
Cumulative Timesteps: 794,557,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 794557542...
Checkpoint 794557542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,065.06808
Policy Entropy: 3.60753
Value Function Loss: 0.08872

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.18076
Policy Update Magnitude: 0.43612
Value Function Update Magnitude: 0.63521

Collected Steps per Second: 22,250.45233
Overall Steps per Second: 10,528.24830

Timestep Collection Time: 2.24795
Timestep Consumption Time: 2.50288
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.75084

Cumulative Model Updates: 95,278
Cumulative Timesteps: 794,607,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,056.81973
Policy Entropy: 3.61322
Value Function Loss: 0.08648

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.38996
Value Function Update Magnitude: 0.59356

Collected Steps per Second: 22,625.96882
Overall Steps per Second: 10,576.36360

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.51808
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.72828

Cumulative Model Updates: 95,284
Cumulative Timesteps: 794,657,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 794657568...
Checkpoint 794657568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,787.80197
Policy Entropy: 3.61908
Value Function Loss: 0.08481

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.44638
Value Function Update Magnitude: 0.64683

Collected Steps per Second: 22,540.26965
Overall Steps per Second: 10,588.96560

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.50505
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.72454

Cumulative Model Updates: 95,290
Cumulative Timesteps: 794,707,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,997.79684
Policy Entropy: 3.60941
Value Function Loss: 0.08654

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.45565
Value Function Update Magnitude: 0.70464

Collected Steps per Second: 22,970.54407
Overall Steps per Second: 10,757.67107

Timestep Collection Time: 2.17705
Timestep Consumption Time: 2.47154
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.64859

Cumulative Model Updates: 95,296
Cumulative Timesteps: 794,757,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 794757604...
Checkpoint 794757604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,787.53264
Policy Entropy: 3.62187
Value Function Loss: 0.08546

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.43137
Value Function Update Magnitude: 0.66157

Collected Steps per Second: 20,733.74355
Overall Steps per Second: 10,209.80748

Timestep Collection Time: 2.41240
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.89901

Cumulative Model Updates: 95,302
Cumulative Timesteps: 794,807,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.84295
Policy Entropy: 3.63437
Value Function Loss: 0.08474

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.45542
Value Function Update Magnitude: 0.70685

Collected Steps per Second: 21,685.98988
Overall Steps per Second: 10,409.49516

Timestep Collection Time: 2.30619
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.80446

Cumulative Model Updates: 95,308
Cumulative Timesteps: 794,857,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 794857634...
Checkpoint 794857634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.92702
Policy Entropy: 3.63383
Value Function Loss: 0.08354

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.45615
Value Function Update Magnitude: 0.70261

Collected Steps per Second: 22,874.07880
Overall Steps per Second: 10,847.39529

Timestep Collection Time: 2.18693
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.61161

Cumulative Model Updates: 95,314
Cumulative Timesteps: 794,907,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,228.37290
Policy Entropy: 3.62562
Value Function Loss: 0.08521

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.47625
Value Function Update Magnitude: 0.66746

Collected Steps per Second: 23,079.72677
Overall Steps per Second: 10,907.35345

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.41824
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.58516

Cumulative Model Updates: 95,320
Cumulative Timesteps: 794,957,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 794957670...
Checkpoint 794957670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,586.35626
Policy Entropy: 3.61837
Value Function Loss: 0.08205

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.47541
Value Function Update Magnitude: 0.65016

Collected Steps per Second: 22,673.85205
Overall Steps per Second: 10,633.23072

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.70468

Cumulative Model Updates: 95,326
Cumulative Timesteps: 795,007,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,002.44508
Policy Entropy: 3.62709
Value Function Loss: 0.07927

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.49124
Value Function Update Magnitude: 0.67062

Collected Steps per Second: 22,474.12621
Overall Steps per Second: 10,397.55769

Timestep Collection Time: 2.22478
Timestep Consumption Time: 2.58404
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.80882

Cumulative Model Updates: 95,332
Cumulative Timesteps: 795,057,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 795057696...
Checkpoint 795057696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,460.40678
Policy Entropy: 3.63522
Value Function Loss: 0.07321

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.52978
Value Function Update Magnitude: 0.72887

Collected Steps per Second: 22,208.16381
Overall Steps per Second: 10,620.21436

Timestep Collection Time: 2.25187
Timestep Consumption Time: 2.45707
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.70894

Cumulative Model Updates: 95,338
Cumulative Timesteps: 795,107,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,886.98046
Policy Entropy: 3.63400
Value Function Loss: 0.07156

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06869
Policy Update Magnitude: 0.59140
Value Function Update Magnitude: 0.78002

Collected Steps per Second: 22,270.75984
Overall Steps per Second: 10,542.67009

Timestep Collection Time: 2.24564
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74377

Cumulative Model Updates: 95,344
Cumulative Timesteps: 795,157,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 795157718...
Checkpoint 795157718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,346.80576
Policy Entropy: 3.63414
Value Function Loss: 0.07012

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07040
Policy Update Magnitude: 0.71923
Value Function Update Magnitude: 0.79334

Collected Steps per Second: 22,464.65567
Overall Steps per Second: 10,589.35789

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.49700
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.72361

Cumulative Model Updates: 95,350
Cumulative Timesteps: 795,207,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,471.22703
Policy Entropy: 3.62947
Value Function Loss: 0.06882

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.71634
Value Function Update Magnitude: 0.74993

Collected Steps per Second: 22,741.98697
Overall Steps per Second: 10,788.64955

Timestep Collection Time: 2.19963
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.63672

Cumulative Model Updates: 95,356
Cumulative Timesteps: 795,257,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 795257762...
Checkpoint 795257762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.83900
Policy Entropy: 3.62805
Value Function Loss: 0.07011

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.69850
Value Function Update Magnitude: 0.66854

Collected Steps per Second: 22,365.53840
Overall Steps per Second: 10,672.21720

Timestep Collection Time: 2.23666
Timestep Consumption Time: 2.45066
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.68731

Cumulative Model Updates: 95,362
Cumulative Timesteps: 795,307,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,197.80085
Policy Entropy: 3.63034
Value Function Loss: 0.07153

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.59371
Value Function Update Magnitude: 0.61273

Collected Steps per Second: 22,901.22705
Overall Steps per Second: 10,734.00145

Timestep Collection Time: 2.18460
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.66089

Cumulative Model Updates: 95,368
Cumulative Timesteps: 795,357,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 795357816...
Checkpoint 795357816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,556.19890
Policy Entropy: 3.63322
Value Function Loss: 0.07105

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.55424
Value Function Update Magnitude: 0.65913

Collected Steps per Second: 22,709.89835
Overall Steps per Second: 10,809.51816

Timestep Collection Time: 2.20256
Timestep Consumption Time: 2.42484
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62740

Cumulative Model Updates: 95,374
Cumulative Timesteps: 795,407,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,063.72252
Policy Entropy: 3.64413
Value Function Loss: 0.07484

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.16485
Policy Update Magnitude: 0.48409
Value Function Update Magnitude: 0.66583

Collected Steps per Second: 22,883.28996
Overall Steps per Second: 10,728.74985

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.66131

Cumulative Model Updates: 95,380
Cumulative Timesteps: 795,457,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 795457846...
Checkpoint 795457846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,986.87646
Policy Entropy: 3.65574
Value Function Loss: 0.07295

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.49762
Value Function Update Magnitude: 0.68784

Collected Steps per Second: 22,178.54000
Overall Steps per Second: 10,863.43617

Timestep Collection Time: 2.25497
Timestep Consumption Time: 2.34873
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60370

Cumulative Model Updates: 95,386
Cumulative Timesteps: 795,507,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609.06487
Policy Entropy: 3.66055
Value Function Loss: 0.07497

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.65029
Value Function Update Magnitude: 0.68960

Collected Steps per Second: 21,750.10383
Overall Steps per Second: 10,545.86694

Timestep Collection Time: 2.29884
Timestep Consumption Time: 2.44235
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.74119

Cumulative Model Updates: 95,392
Cumulative Timesteps: 795,557,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 795557858...
Checkpoint 795557858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,530.91538
Policy Entropy: 3.66195
Value Function Loss: 0.07514

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.62677
Value Function Update Magnitude: 0.65422

Collected Steps per Second: 22,077.48186
Overall Steps per Second: 10,652.40257

Timestep Collection Time: 2.26511
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.69453

Cumulative Model Updates: 95,398
Cumulative Timesteps: 795,607,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,387.95328
Policy Entropy: 3.64482
Value Function Loss: 0.07336

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.54298
Value Function Update Magnitude: 0.73256

Collected Steps per Second: 21,756.42366
Overall Steps per Second: 10,612.34054

Timestep Collection Time: 2.29909
Timestep Consumption Time: 2.41429
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.71338

Cumulative Model Updates: 95,404
Cumulative Timesteps: 795,657,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 795657886...
Checkpoint 795657886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.68400
Policy Entropy: 3.63696
Value Function Loss: 0.07533

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.48870
Value Function Update Magnitude: 0.78203

Collected Steps per Second: 21,823.35944
Overall Steps per Second: 10,790.74384

Timestep Collection Time: 2.29140
Timestep Consumption Time: 2.34276
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.63416

Cumulative Model Updates: 95,410
Cumulative Timesteps: 795,707,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.18925
Policy Entropy: 3.63735
Value Function Loss: 0.07319

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.51524
Value Function Update Magnitude: 0.82771

Collected Steps per Second: 21,977.97754
Overall Steps per Second: 10,658.67226

Timestep Collection Time: 2.27500
Timestep Consumption Time: 2.41601
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.69102

Cumulative Model Updates: 95,416
Cumulative Timesteps: 795,757,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 795757892...
Checkpoint 795757892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,003.42418
Policy Entropy: 3.64685
Value Function Loss: 0.07292

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.53135
Value Function Update Magnitude: 0.79654

Collected Steps per Second: 21,921.37340
Overall Steps per Second: 10,502.71511

Timestep Collection Time: 2.28143
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.76182

Cumulative Model Updates: 95,422
Cumulative Timesteps: 795,807,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,328.42286
Policy Entropy: 3.65836
Value Function Loss: 0.07406

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.60337
Value Function Update Magnitude: 0.68364

Collected Steps per Second: 22,873.07055
Overall Steps per Second: 10,832.21976

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.43105
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61807

Cumulative Model Updates: 95,428
Cumulative Timesteps: 795,857,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 795857928...
Checkpoint 795857928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,327.36465
Policy Entropy: 3.65558
Value Function Loss: 0.07457

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.57559
Value Function Update Magnitude: 0.70014

Collected Steps per Second: 22,713.13803
Overall Steps per Second: 10,741.94593

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.45348
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.65502

Cumulative Model Updates: 95,434
Cumulative Timesteps: 795,907,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.23554
Policy Entropy: 3.66342
Value Function Loss: 0.07721

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.78634

Collected Steps per Second: 22,766.32774
Overall Steps per Second: 10,865.74829

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.40645
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60364

Cumulative Model Updates: 95,440
Cumulative Timesteps: 795,957,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 795957954...
Checkpoint 795957954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,185.93717
Policy Entropy: 3.66866
Value Function Loss: 0.07585

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.58129
Value Function Update Magnitude: 0.83801

Collected Steps per Second: 22,389.12113
Overall Steps per Second: 10,710.69774

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.66916

Cumulative Model Updates: 95,446
Cumulative Timesteps: 796,007,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,781.29891
Policy Entropy: 3.65150
Value Function Loss: 0.07528

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.63854
Value Function Update Magnitude: 0.81238

Collected Steps per Second: 22,660.40885
Overall Steps per Second: 10,649.24942

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.69573

Cumulative Model Updates: 95,452
Cumulative Timesteps: 796,057,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 796057970...
Checkpoint 796057970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,025.21430
Policy Entropy: 3.63873
Value Function Loss: 0.07482

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.56602
Value Function Update Magnitude: 0.73797

Collected Steps per Second: 23,266.97700
Overall Steps per Second: 10,873.01710

Timestep Collection Time: 2.14974
Timestep Consumption Time: 2.45045
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.60020

Cumulative Model Updates: 95,458
Cumulative Timesteps: 796,107,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,912.11429
Policy Entropy: 3.62641
Value Function Loss: 0.07800

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.56039
Value Function Update Magnitude: 0.67250

Collected Steps per Second: 22,057.33461
Overall Steps per Second: 10,467.97762

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.51066
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.77838

Cumulative Model Updates: 95,464
Cumulative Timesteps: 796,158,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 796158008...
Checkpoint 796158008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,486.19227
Policy Entropy: 3.64139
Value Function Loss: 0.07684

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.59408
Value Function Update Magnitude: 0.64522

Collected Steps per Second: 22,140.88923
Overall Steps per Second: 10,693.79308

Timestep Collection Time: 2.25881
Timestep Consumption Time: 2.41792
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.67673

Cumulative Model Updates: 95,470
Cumulative Timesteps: 796,208,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,694.10481
Policy Entropy: 3.65464
Value Function Loss: 0.07930

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07639
Policy Update Magnitude: 0.68283
Value Function Update Magnitude: 0.67315

Collected Steps per Second: 22,599.98532
Overall Steps per Second: 10,744.94058

Timestep Collection Time: 2.21274
Timestep Consumption Time: 2.44135
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.65410

Cumulative Model Updates: 95,476
Cumulative Timesteps: 796,258,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 796258028...
Checkpoint 796258028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,309.85795
Policy Entropy: 3.65231
Value Function Loss: 0.08080

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.65796
Value Function Update Magnitude: 0.73188

Collected Steps per Second: 22,549.81080
Overall Steps per Second: 10,671.85706

Timestep Collection Time: 2.21856
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.68784

Cumulative Model Updates: 95,482
Cumulative Timesteps: 796,308,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,858.08705
Policy Entropy: 3.64002
Value Function Loss: 0.08297

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.81959

Collected Steps per Second: 22,586.97422
Overall Steps per Second: 10,699.34246

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.45962
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.67337

Cumulative Model Updates: 95,488
Cumulative Timesteps: 796,358,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 796358058...
Checkpoint 796358058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,221.80522
Policy Entropy: 3.63082
Value Function Loss: 0.08214

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.50554
Value Function Update Magnitude: 0.81449

Collected Steps per Second: 23,189.50134
Overall Steps per Second: 10,943.03369

Timestep Collection Time: 2.15684
Timestep Consumption Time: 2.41374
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.57058

Cumulative Model Updates: 95,494
Cumulative Timesteps: 796,408,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.45548
Policy Entropy: 3.62490
Value Function Loss: 0.08376

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.54474
Value Function Update Magnitude: 0.74099

Collected Steps per Second: 22,671.06311
Overall Steps per Second: 10,771.82233

Timestep Collection Time: 2.20554
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.64193

Cumulative Model Updates: 95,500
Cumulative Timesteps: 796,458,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 796458076...
Checkpoint 796458076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,048.96429
Policy Entropy: 3.61874
Value Function Loss: 0.08145

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.46742
Value Function Update Magnitude: 0.81559

Collected Steps per Second: 22,851.52307
Overall Steps per Second: 10,751.24375

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.46367
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.65267

Cumulative Model Updates: 95,506
Cumulative Timesteps: 796,508,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,448.75644
Policy Entropy: 3.61178
Value Function Loss: 0.08216

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.41855
Value Function Update Magnitude: 0.79830

Collected Steps per Second: 22,858.49911
Overall Steps per Second: 10,816.88251

Timestep Collection Time: 2.18755
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62277

Cumulative Model Updates: 95,512
Cumulative Timesteps: 796,558,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 796558102...
Checkpoint 796558102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,638.99458
Policy Entropy: 3.60877
Value Function Loss: 0.08478

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.45999
Value Function Update Magnitude: 0.75421

Collected Steps per Second: 22,233.49553
Overall Steps per Second: 10,701.96572

Timestep Collection Time: 2.24976
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.67391

Cumulative Model Updates: 95,518
Cumulative Timesteps: 796,608,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,622.28225
Policy Entropy: 3.61332
Value Function Loss: 0.08797

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.52067
Value Function Update Magnitude: 0.75091

Collected Steps per Second: 22,252.64779
Overall Steps per Second: 10,548.34830

Timestep Collection Time: 2.24701
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.74027

Cumulative Model Updates: 95,524
Cumulative Timesteps: 796,658,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 796658124...
Checkpoint 796658124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,889.28828
Policy Entropy: 3.61539
Value Function Loss: 0.08951

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.76094

Collected Steps per Second: 22,369.34791
Overall Steps per Second: 10,558.34536

Timestep Collection Time: 2.23520
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.73559

Cumulative Model Updates: 95,530
Cumulative Timesteps: 796,708,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,739.22234
Policy Entropy: 3.61648
Value Function Loss: 0.08714

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.61108
Value Function Update Magnitude: 0.75629

Collected Steps per Second: 22,443.12813
Overall Steps per Second: 10,559.04089

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.50863
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.73755

Cumulative Model Updates: 95,536
Cumulative Timesteps: 796,758,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 796758148...
Checkpoint 796758148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,007.76708
Policy Entropy: 3.62837
Value Function Loss: 0.08402

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.61227
Value Function Update Magnitude: 0.79671

Collected Steps per Second: 22,523.14640
Overall Steps per Second: 10,530.65922

Timestep Collection Time: 2.22020
Timestep Consumption Time: 2.52841
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74861

Cumulative Model Updates: 95,542
Cumulative Timesteps: 796,808,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,139.52603
Policy Entropy: 3.64899
Value Function Loss: 0.08157

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.63128
Value Function Update Magnitude: 0.78768

Collected Steps per Second: 22,972.89245
Overall Steps per Second: 10,848.19133

Timestep Collection Time: 2.17822
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.61275

Cumulative Model Updates: 95,548
Cumulative Timesteps: 796,858,194

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 796858194...
Checkpoint 796858194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,706.58843
Policy Entropy: 3.64236
Value Function Loss: 0.08507

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.62453
Value Function Update Magnitude: 0.75264

Collected Steps per Second: 22,760.58490
Overall Steps per Second: 10,674.66764

Timestep Collection Time: 2.19740
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.68530

Cumulative Model Updates: 95,554
Cumulative Timesteps: 796,908,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,400.62529
Policy Entropy: 3.63445
Value Function Loss: 0.08766

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.60398
Value Function Update Magnitude: 0.72284

Collected Steps per Second: 22,222.49272
Overall Steps per Second: 10,867.04234

Timestep Collection Time: 2.25096
Timestep Consumption Time: 2.35213
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60309

Cumulative Model Updates: 95,560
Cumulative Timesteps: 796,958,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 796958230...
Checkpoint 796958230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,179.61445
Policy Entropy: 3.64585
Value Function Loss: 0.08614

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.68339
Value Function Update Magnitude: 0.75289

Collected Steps per Second: 21,769.21740
Overall Steps per Second: 10,751.48546

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.35473
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.65257

Cumulative Model Updates: 95,566
Cumulative Timesteps: 797,008,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,286.26187
Policy Entropy: 3.66948
Value Function Loss: 0.07662

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.62248
Value Function Update Magnitude: 0.88869

Collected Steps per Second: 22,287.22763
Overall Steps per Second: 10,912.48645

Timestep Collection Time: 2.24487
Timestep Consumption Time: 2.33997
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.58484

Cumulative Model Updates: 95,572
Cumulative Timesteps: 797,058,284

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 797058284...
Checkpoint 797058284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,707.40356
Policy Entropy: 3.68057
Value Function Loss: 0.07240

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.58521
Value Function Update Magnitude: 0.92315

Collected Steps per Second: 21,674.35239
Overall Steps per Second: 10,582.20802

Timestep Collection Time: 2.30798
Timestep Consumption Time: 2.41920
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.72718

Cumulative Model Updates: 95,578
Cumulative Timesteps: 797,108,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,999.17615
Policy Entropy: 3.66651
Value Function Loss: 0.07571

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.62964
Value Function Update Magnitude: 0.91738

Collected Steps per Second: 21,941.50124
Overall Steps per Second: 10,709.00482

Timestep Collection Time: 2.27906
Timestep Consumption Time: 2.39047
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.66953

Cumulative Model Updates: 95,584
Cumulative Timesteps: 797,158,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 797158314...
Checkpoint 797158314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,600.09854
Policy Entropy: 3.65291
Value Function Loss: 0.07815

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.58553
Value Function Update Magnitude: 0.91189

Collected Steps per Second: 21,191.78361
Overall Steps per Second: 10,398.36750

Timestep Collection Time: 2.36016
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.80999

Cumulative Model Updates: 95,590
Cumulative Timesteps: 797,208,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,990.73145
Policy Entropy: 3.64041
Value Function Loss: 0.08089

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.60355
Value Function Update Magnitude: 0.89812

Collected Steps per Second: 22,700.04471
Overall Steps per Second: 10,835.49874

Timestep Collection Time: 2.20370
Timestep Consumption Time: 2.41298
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61668

Cumulative Model Updates: 95,596
Cumulative Timesteps: 797,258,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 797258354...
Checkpoint 797258354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,806.28015
Policy Entropy: 3.63280
Value Function Loss: 0.08218

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.54038
Value Function Update Magnitude: 0.93677

Collected Steps per Second: 22,367.85910
Overall Steps per Second: 10,747.09563

Timestep Collection Time: 2.23678
Timestep Consumption Time: 2.41862
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.65540

Cumulative Model Updates: 95,602
Cumulative Timesteps: 797,308,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,029.58872
Policy Entropy: 3.62763
Value Function Loss: 0.08445

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.53450
Value Function Update Magnitude: 0.93793

Collected Steps per Second: 22,657.39467
Overall Steps per Second: 10,824.51287

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.41323
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.62081

Cumulative Model Updates: 95,608
Cumulative Timesteps: 797,358,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 797358404...
Checkpoint 797358404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,822.35281
Policy Entropy: 3.62454
Value Function Loss: 0.08073

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.90982

Collected Steps per Second: 22,815.47546
Overall Steps per Second: 10,694.64000

Timestep Collection Time: 2.19255
Timestep Consumption Time: 2.48494
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.67748

Cumulative Model Updates: 95,614
Cumulative Timesteps: 797,408,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,154.85888
Policy Entropy: 3.62484
Value Function Loss: 0.07679

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.52059
Value Function Update Magnitude: 0.87198

Collected Steps per Second: 22,921.58956
Overall Steps per Second: 10,828.37127

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62027

Cumulative Model Updates: 95,620
Cumulative Timesteps: 797,458,458

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 797458458...
Checkpoint 797458458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,591.70510
Policy Entropy: 3.63249
Value Function Loss: 0.07489

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.49728
Value Function Update Magnitude: 0.74281

Collected Steps per Second: 22,778.42698
Overall Steps per Second: 10,732.64729

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.46412
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.65961

Cumulative Model Updates: 95,626
Cumulative Timesteps: 797,508,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,478.75840
Policy Entropy: 3.62751
Value Function Loss: 0.07601

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.54285
Value Function Update Magnitude: 0.74121

Collected Steps per Second: 22,768.21662
Overall Steps per Second: 10,814.75073

Timestep Collection Time: 2.19613
Timestep Consumption Time: 2.42737
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.62350

Cumulative Model Updates: 95,632
Cumulative Timesteps: 797,558,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 797558470...
Checkpoint 797558470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.16875
Policy Entropy: 3.64128
Value Function Loss: 0.07708

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.49898
Value Function Update Magnitude: 0.69558

Collected Steps per Second: 22,507.89680
Overall Steps per Second: 10,807.66991

Timestep Collection Time: 2.22242
Timestep Consumption Time: 2.40596
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.62838

Cumulative Model Updates: 95,638
Cumulative Timesteps: 797,608,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.90535
Policy Entropy: 3.63649
Value Function Loss: 0.07768

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.41624
Value Function Update Magnitude: 0.65014

Collected Steps per Second: 22,625.40147
Overall Steps per Second: 10,772.79073

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.64318

Cumulative Model Updates: 95,644
Cumulative Timesteps: 797,658,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 797658512...
Checkpoint 797658512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,602.21726
Policy Entropy: 3.63456
Value Function Loss: 0.07836

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.50386
Value Function Update Magnitude: 0.77463

Collected Steps per Second: 22,328.56973
Overall Steps per Second: 10,741.32824

Timestep Collection Time: 2.23928
Timestep Consumption Time: 2.41563
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.65492

Cumulative Model Updates: 95,650
Cumulative Timesteps: 797,708,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.45079
Policy Entropy: 3.62490
Value Function Loss: 0.07916

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.80223

Collected Steps per Second: 22,295.02321
Overall Steps per Second: 10,562.06981

Timestep Collection Time: 2.24310
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.73487

Cumulative Model Updates: 95,656
Cumulative Timesteps: 797,758,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 797758522...
Checkpoint 797758522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,865.42999
Policy Entropy: 3.61871
Value Function Loss: 0.08236

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.45424
Value Function Update Magnitude: 0.69729

Collected Steps per Second: 22,332.72418
Overall Steps per Second: 10,551.09768

Timestep Collection Time: 2.23914
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.73941

Cumulative Model Updates: 95,662
Cumulative Timesteps: 797,808,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,514.36312
Policy Entropy: 3.63416
Value Function Loss: 0.08310

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.48636
Value Function Update Magnitude: 0.67329

Collected Steps per Second: 22,996.49899
Overall Steps per Second: 10,796.93722

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.45768
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.63280

Cumulative Model Updates: 95,668
Cumulative Timesteps: 797,858,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 797858548...
Checkpoint 797858548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,276.93158
Policy Entropy: 3.63701
Value Function Loss: 0.08087

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.49759
Value Function Update Magnitude: 0.73256

Collected Steps per Second: 22,803.63737
Overall Steps per Second: 10,655.61110

Timestep Collection Time: 2.19333
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.69387

Cumulative Model Updates: 95,674
Cumulative Timesteps: 797,908,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,151.12155
Policy Entropy: 3.64095
Value Function Loss: 0.07977

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.80295

Collected Steps per Second: 22,769.44848
Overall Steps per Second: 10,692.38274

Timestep Collection Time: 2.19795
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.68053

Cumulative Model Updates: 95,680
Cumulative Timesteps: 797,958,610

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 797958610...
Checkpoint 797958610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,638.75077
Policy Entropy: 3.64319
Value Function Loss: 0.07768

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.52701
Value Function Update Magnitude: 0.72962

Collected Steps per Second: 22,989.00460
Overall Steps per Second: 10,872.91806

Timestep Collection Time: 2.17513
Timestep Consumption Time: 2.42382
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59895

Cumulative Model Updates: 95,686
Cumulative Timesteps: 798,008,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,488.41807
Policy Entropy: 3.64719
Value Function Loss: 0.08042

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.50082
Value Function Update Magnitude: 0.66105

Collected Steps per Second: 23,160.33705
Overall Steps per Second: 10,893.39134

Timestep Collection Time: 2.16024
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59288

Cumulative Model Updates: 95,692
Cumulative Timesteps: 798,058,646

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 798058646...
Checkpoint 798058646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,042.11726
Policy Entropy: 3.63815
Value Function Loss: 0.07954

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.45211
Value Function Update Magnitude: 0.72228

Collected Steps per Second: 22,839.74358
Overall Steps per Second: 10,693.01460

Timestep Collection Time: 2.18952
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.67670

Cumulative Model Updates: 95,698
Cumulative Timesteps: 798,108,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,396.71304
Policy Entropy: 3.64159
Value Function Loss: 0.07736

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.42710
Value Function Update Magnitude: 0.73953

Collected Steps per Second: 22,306.61658
Overall Steps per Second: 10,541.76869

Timestep Collection Time: 2.24149
Timestep Consumption Time: 2.50155
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.74304

Cumulative Model Updates: 95,704
Cumulative Timesteps: 798,158,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 798158654...
Checkpoint 798158654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,554.06928
Policy Entropy: 3.64058
Value Function Loss: 0.07614

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.52853
Value Function Update Magnitude: 0.79886

Collected Steps per Second: 22,489.31292
Overall Steps per Second: 10,601.74643

Timestep Collection Time: 2.22346
Timestep Consumption Time: 2.49313
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.71658

Cumulative Model Updates: 95,710
Cumulative Timesteps: 798,208,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,929.70338
Policy Entropy: 3.63866
Value Function Loss: 0.07746

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.85531

Collected Steps per Second: 22,710.93716
Overall Steps per Second: 10,795.62519

Timestep Collection Time: 2.20211
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.63262

Cumulative Model Updates: 95,716
Cumulative Timesteps: 798,258,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 798258670...
Checkpoint 798258670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,728.44720
Policy Entropy: 3.64451
Value Function Loss: 0.08010

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.52748
Value Function Update Magnitude: 0.85145

Collected Steps per Second: 22,177.98393
Overall Steps per Second: 10,683.05610

Timestep Collection Time: 2.25476
Timestep Consumption Time: 2.42611
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.68087

Cumulative Model Updates: 95,722
Cumulative Timesteps: 798,308,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,495.67209
Policy Entropy: 3.64125
Value Function Loss: 0.08043

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.85858

Collected Steps per Second: 21,724.42295
Overall Steps per Second: 10,576.77043

Timestep Collection Time: 2.30377
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.73188

Cumulative Model Updates: 95,728
Cumulative Timesteps: 798,358,724

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 798358724...
Checkpoint 798358724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360.72878
Policy Entropy: 3.64567
Value Function Loss: 0.07949

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.47064
Value Function Update Magnitude: 0.87131

Collected Steps per Second: 21,970.78504
Overall Steps per Second: 10,602.56333

Timestep Collection Time: 2.27648
Timestep Consumption Time: 2.44087
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.71735

Cumulative Model Updates: 95,734
Cumulative Timesteps: 798,408,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,255.06179
Policy Entropy: 3.64187
Value Function Loss: 0.07637

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.47241
Value Function Update Magnitude: 0.86702

Collected Steps per Second: 22,287.60530
Overall Steps per Second: 10,882.96295

Timestep Collection Time: 2.24394
Timestep Consumption Time: 2.35150
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.59544

Cumulative Model Updates: 95,740
Cumulative Timesteps: 798,458,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 798458752...
Checkpoint 798458752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,797.16918
Policy Entropy: 3.64515
Value Function Loss: 0.07872

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.48471
Value Function Update Magnitude: 0.85440

Collected Steps per Second: 20,844.72691
Overall Steps per Second: 10,357.48994

Timestep Collection Time: 2.39974
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.82955

Cumulative Model Updates: 95,746
Cumulative Timesteps: 798,508,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,515.03193
Policy Entropy: 3.63204
Value Function Loss: 0.08110

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.47021
Value Function Update Magnitude: 0.78004

Collected Steps per Second: 22,311.29387
Overall Steps per Second: 10,726.69198

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.66127

Cumulative Model Updates: 95,752
Cumulative Timesteps: 798,558,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 798558774...
Checkpoint 798558774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,272.72512
Policy Entropy: 3.61785
Value Function Loss: 0.08375

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.45087
Value Function Update Magnitude: 0.77877

Collected Steps per Second: 22,059.88889
Overall Steps per Second: 10,615.85821

Timestep Collection Time: 2.26656
Timestep Consumption Time: 2.44338
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.70993

Cumulative Model Updates: 95,758
Cumulative Timesteps: 798,608,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,725.45245
Policy Entropy: 3.61481
Value Function Loss: 0.08262

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.45115
Value Function Update Magnitude: 0.82044

Collected Steps per Second: 22,542.45744
Overall Steps per Second: 10,950.10882

Timestep Collection Time: 2.21848
Timestep Consumption Time: 2.34860
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.56708

Cumulative Model Updates: 95,764
Cumulative Timesteps: 798,658,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 798658784...
Checkpoint 798658784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,562.89769
Policy Entropy: 3.60868
Value Function Loss: 0.08223

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.46334
Value Function Update Magnitude: 0.85073

Collected Steps per Second: 21,957.67614
Overall Steps per Second: 10,571.06321

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.72989

Cumulative Model Updates: 95,770
Cumulative Timesteps: 798,708,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,305.21260
Policy Entropy: 3.61310
Value Function Loss: 0.08297

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.47693
Value Function Update Magnitude: 0.76222

Collected Steps per Second: 22,379.89236
Overall Steps per Second: 10,647.19436

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.69645

Cumulative Model Updates: 95,776
Cumulative Timesteps: 798,758,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 798758788...
Checkpoint 798758788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,075.97699
Policy Entropy: 3.60948
Value Function Loss: 0.08536

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.47591
Value Function Update Magnitude: 0.74564

Collected Steps per Second: 22,390.63162
Overall Steps per Second: 10,676.08383

Timestep Collection Time: 2.23424
Timestep Consumption Time: 2.45156
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.68580

Cumulative Model Updates: 95,782
Cumulative Timesteps: 798,808,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,270.69977
Policy Entropy: 3.60741
Value Function Loss: 0.08711

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.45071
Value Function Update Magnitude: 0.72708

Collected Steps per Second: 22,772.44136
Overall Steps per Second: 10,715.29616

Timestep Collection Time: 2.19581
Timestep Consumption Time: 2.47079
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.66660

Cumulative Model Updates: 95,788
Cumulative Timesteps: 798,858,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 798858818...
Checkpoint 798858818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,251.33342
Policy Entropy: 3.61815
Value Function Loss: 0.08723

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.46331
Value Function Update Magnitude: 0.73611

Collected Steps per Second: 22,542.65993
Overall Steps per Second: 10,647.00449

Timestep Collection Time: 2.21944
Timestep Consumption Time: 2.47973
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.69916

Cumulative Model Updates: 95,794
Cumulative Timesteps: 798,908,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.18485
Policy Entropy: 3.62799
Value Function Loss: 0.08754

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.45612
Value Function Update Magnitude: 0.79900

Collected Steps per Second: 22,939.99892
Overall Steps per Second: 10,803.65321

Timestep Collection Time: 2.18099
Timestep Consumption Time: 2.45003
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.63103

Cumulative Model Updates: 95,800
Cumulative Timesteps: 798,958,882

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 798958882...
Checkpoint 798958882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,733.37639
Policy Entropy: 3.63286
Value Function Loss: 0.08488

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.45794
Value Function Update Magnitude: 0.83000

Collected Steps per Second: 22,636.98933
Overall Steps per Second: 10,792.88433

Timestep Collection Time: 2.20983
Timestep Consumption Time: 2.42507
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.63491

Cumulative Model Updates: 95,806
Cumulative Timesteps: 799,008,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,592.80035
Policy Entropy: 3.62113
Value Function Loss: 0.08555

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.85875

Collected Steps per Second: 22,890.25495
Overall Steps per Second: 10,820.88197

Timestep Collection Time: 2.18451
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62107

Cumulative Model Updates: 95,812
Cumulative Timesteps: 799,058,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 799058910...
Checkpoint 799058910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.17777
Policy Entropy: 3.60957
Value Function Loss: 0.08726

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.51077
Value Function Update Magnitude: 0.87255

Collected Steps per Second: 22,680.65915
Overall Steps per Second: 10,651.87866

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.69664

Cumulative Model Updates: 95,818
Cumulative Timesteps: 799,108,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,894.27784
Policy Entropy: 3.60577
Value Function Loss: 0.08585

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.50051
Value Function Update Magnitude: 0.88859

Collected Steps per Second: 22,911.54185
Overall Steps per Second: 10,841.29790

Timestep Collection Time: 2.18239
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61218

Cumulative Model Updates: 95,824
Cumulative Timesteps: 799,158,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 799158940...
Checkpoint 799158940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,547.63859
Policy Entropy: 3.60160
Value Function Loss: 0.08742

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.88315

Collected Steps per Second: 22,579.97375
Overall Steps per Second: 10,733.46235

Timestep Collection Time: 2.21488
Timestep Consumption Time: 2.44456
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.65945

Cumulative Model Updates: 95,830
Cumulative Timesteps: 799,208,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,593.73546
Policy Entropy: 3.60559
Value Function Loss: 0.08683

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.57363
Value Function Update Magnitude: 0.83601

Collected Steps per Second: 22,267.80100
Overall Steps per Second: 10,501.29702

Timestep Collection Time: 2.24656
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.76379

Cumulative Model Updates: 95,836
Cumulative Timesteps: 799,258,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 799258978...
Checkpoint 799258978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,165.16182
Policy Entropy: 3.61061
Value Function Loss: 0.09049

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.57304
Value Function Update Magnitude: 0.77433

Collected Steps per Second: 22,388.40051
Overall Steps per Second: 10,590.90264

Timestep Collection Time: 2.23348
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.72141

Cumulative Model Updates: 95,842
Cumulative Timesteps: 799,308,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,302.59805
Policy Entropy: 3.61782
Value Function Loss: 0.09196

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.69363

Collected Steps per Second: 21,818.19546
Overall Steps per Second: 10,619.97929

Timestep Collection Time: 2.29313
Timestep Consumption Time: 2.41799
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71112

Cumulative Model Updates: 95,848
Cumulative Timesteps: 799,359,014

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 799359014...
Checkpoint 799359014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,282.83961
Policy Entropy: 3.60141
Value Function Loss: 0.09596

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.57174
Value Function Update Magnitude: 0.66872

Collected Steps per Second: 21,736.55794
Overall Steps per Second: 10,682.22190

Timestep Collection Time: 2.30110
Timestep Consumption Time: 2.38126
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.68236

Cumulative Model Updates: 95,854
Cumulative Timesteps: 799,409,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,516.39805
Policy Entropy: 3.59828
Value Function Loss: 0.09498

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11156
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.64880

Collected Steps per Second: 22,302.81467
Overall Steps per Second: 10,666.23508

Timestep Collection Time: 2.24223
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.68844

Cumulative Model Updates: 95,860
Cumulative Timesteps: 799,459,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 799459040...
Checkpoint 799459040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,554.43919
Policy Entropy: 3.59168
Value Function Loss: 0.09710

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.54382
Value Function Update Magnitude: 0.61119

Collected Steps per Second: 22,118.06402
Overall Steps per Second: 10,639.15766

Timestep Collection Time: 2.26105
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.70056

Cumulative Model Updates: 95,866
Cumulative Timesteps: 799,509,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,238.19460
Policy Entropy: 3.58751
Value Function Loss: 0.09698

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.57550
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 22,117.10046
Overall Steps per Second: 10,845.22042

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.35076
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61254

Cumulative Model Updates: 95,872
Cumulative Timesteps: 799,559,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 799559074...
Checkpoint 799559074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,709.26829
Policy Entropy: 3.58296
Value Function Loss: 0.09477

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.65339

Collected Steps per Second: 21,977.31509
Overall Steps per Second: 10,666.45489

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.41339
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.68928

Cumulative Model Updates: 95,878
Cumulative Timesteps: 799,609,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,052.18196
Policy Entropy: 3.58509
Value Function Loss: 0.09046

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.48052
Value Function Update Magnitude: 0.65192

Collected Steps per Second: 22,682.85958
Overall Steps per Second: 10,680.66401

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.47745
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.68211

Cumulative Model Updates: 95,884
Cumulative Timesteps: 799,659,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 799659100...
Checkpoint 799659100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,264.78438
Policy Entropy: 3.60223
Value Function Loss: 0.08639

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.46287
Value Function Update Magnitude: 0.71869

Collected Steps per Second: 23,021.24441
Overall Steps per Second: 10,973.72752

Timestep Collection Time: 2.17234
Timestep Consumption Time: 2.38491
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.55725

Cumulative Model Updates: 95,890
Cumulative Timesteps: 799,709,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,583.22883
Policy Entropy: 3.61064
Value Function Loss: 0.08569

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.47316
Value Function Update Magnitude: 0.72906

Collected Steps per Second: 22,789.13706
Overall Steps per Second: 10,910.67919

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.38959
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.58450

Cumulative Model Updates: 95,896
Cumulative Timesteps: 799,759,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 799759130...
Checkpoint 799759130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,152.31709
Policy Entropy: 3.60717
Value Function Loss: 0.08603

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.47291
Value Function Update Magnitude: 0.74321

Collected Steps per Second: 22,275.79303
Overall Steps per Second: 10,604.21502

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.47052
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.71511

Cumulative Model Updates: 95,902
Cumulative Timesteps: 799,809,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,279.39661
Policy Entropy: 3.58507
Value Function Loss: 0.08810

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.47836
Value Function Update Magnitude: 0.77894

Collected Steps per Second: 22,545.96712
Overall Steps per Second: 10,629.58499

Timestep Collection Time: 2.21867
Timestep Consumption Time: 2.48725
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.70592

Cumulative Model Updates: 95,908
Cumulative Timesteps: 799,859,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 799859152...
Checkpoint 799859152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,486.41211
Policy Entropy: 3.58201
Value Function Loss: 0.08945

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.46965
Value Function Update Magnitude: 0.68107

Collected Steps per Second: 22,467.28476
Overall Steps per Second: 10,606.33751

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.71661

Cumulative Model Updates: 95,914
Cumulative Timesteps: 799,909,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,847.52922
Policy Entropy: 3.57272
Value Function Loss: 0.09015

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.54152
Value Function Update Magnitude: 0.66368

Collected Steps per Second: 22,687.40506
Overall Steps per Second: 10,759.40714

Timestep Collection Time: 2.20439
Timestep Consumption Time: 2.44382
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.64821

Cumulative Model Updates: 95,920
Cumulative Timesteps: 799,959,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 799959190...
Checkpoint 799959190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,611.08340
Policy Entropy: 3.57638
Value Function Loss: 0.08911

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.58116
Value Function Update Magnitude: 0.69084

Collected Steps per Second: 22,564.55749
Overall Steps per Second: 10,634.57288

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.70428

Cumulative Model Updates: 95,926
Cumulative Timesteps: 800,009,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,886.47291
Policy Entropy: 3.58954
Value Function Loss: 0.08716

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.55469
Value Function Update Magnitude: 0.66534

Collected Steps per Second: 23,264.77360
Overall Steps per Second: 10,865.68428

Timestep Collection Time: 2.14917
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.60164

Cumulative Model Updates: 95,932
Cumulative Timesteps: 800,059,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 800059218...
Checkpoint 800059218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,813.74103
Policy Entropy: 3.59191
Value Function Loss: 0.08812

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.68667

Collected Steps per Second: 22,819.94853
Overall Steps per Second: 10,657.99840

Timestep Collection Time: 2.19124
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.69169

Cumulative Model Updates: 95,938
Cumulative Timesteps: 800,109,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,217.71465
Policy Entropy: 3.60522
Value Function Loss: 0.08627

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.50561
Value Function Update Magnitude: 0.66799

Collected Steps per Second: 22,957.06471
Overall Steps per Second: 10,939.73725

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.39357
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.57250

Cumulative Model Updates: 95,944
Cumulative Timesteps: 800,159,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 800159244...
Checkpoint 800159244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,754.33466
Policy Entropy: 3.60825
Value Function Loss: 0.08491

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.50880
Value Function Update Magnitude: 0.66808

Collected Steps per Second: 22,488.53825
Overall Steps per Second: 10,616.41555

Timestep Collection Time: 2.22433
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.71176

Cumulative Model Updates: 95,950
Cumulative Timesteps: 800,209,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,646.09770
Policy Entropy: 3.60640
Value Function Loss: 0.08261

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07111
Policy Update Magnitude: 0.72565
Value Function Update Magnitude: 0.71063

Collected Steps per Second: 22,972.46629
Overall Steps per Second: 10,828.08834

Timestep Collection Time: 2.17739
Timestep Consumption Time: 2.44208
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.61947

Cumulative Model Updates: 95,956
Cumulative Timesteps: 800,259,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 800259286...
Checkpoint 800259286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,905.19415
Policy Entropy: 3.60629
Value Function Loss: 0.08188

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.80416
Value Function Update Magnitude: 0.74950

Collected Steps per Second: 22,215.52299
Overall Steps per Second: 10,670.23709

Timestep Collection Time: 2.25167
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.68799

Cumulative Model Updates: 95,962
Cumulative Timesteps: 800,309,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,220.51761
Policy Entropy: 3.62139
Value Function Loss: 0.08046

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.79375
Value Function Update Magnitude: 0.73642

Collected Steps per Second: 22,120.22610
Overall Steps per Second: 10,496.17768

Timestep Collection Time: 2.26083
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.76459

Cumulative Model Updates: 95,968
Cumulative Timesteps: 800,359,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 800359318...
Checkpoint 800359318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,326.76472
Policy Entropy: 3.61967
Value Function Loss: 0.08161

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.78725
Value Function Update Magnitude: 0.79779

Collected Steps per Second: 22,162.51019
Overall Steps per Second: 10,611.40010

Timestep Collection Time: 2.25705
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.71399

Cumulative Model Updates: 95,974
Cumulative Timesteps: 800,409,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,867.14864
Policy Entropy: 3.61229
Value Function Loss: 0.08187

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.74899
Value Function Update Magnitude: 0.88108

Collected Steps per Second: 22,439.46272
Overall Steps per Second: 10,543.83602

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.51409
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.74249

Cumulative Model Updates: 95,980
Cumulative Timesteps: 800,459,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 800459344...
Checkpoint 800459344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,719.17619
Policy Entropy: 3.60674
Value Function Loss: 0.08298

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.70116
Value Function Update Magnitude: 0.83462

Collected Steps per Second: 22,340.80612
Overall Steps per Second: 10,563.93473

Timestep Collection Time: 2.23842
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.73384

Cumulative Model Updates: 95,986
Cumulative Timesteps: 800,509,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,080.52146
Policy Entropy: 3.60350
Value Function Loss: 0.08336

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.63530
Value Function Update Magnitude: 0.82543

Collected Steps per Second: 22,958.73120
Overall Steps per Second: 10,648.33695

Timestep Collection Time: 2.17852
Timestep Consumption Time: 2.51855
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.69707

Cumulative Model Updates: 95,992
Cumulative Timesteps: 800,559,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 800559368...
Checkpoint 800559368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,814.80636
Policy Entropy: 3.60734
Value Function Loss: 0.08471

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.63141
Value Function Update Magnitude: 0.77744

Collected Steps per Second: 22,997.82754
Overall Steps per Second: 10,868.99923

Timestep Collection Time: 2.17560
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60337

Cumulative Model Updates: 95,998
Cumulative Timesteps: 800,609,402

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,092.42274
Policy Entropy: 3.61269
Value Function Loss: 0.08575

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.60093
Value Function Update Magnitude: 0.85297

Collected Steps per Second: 22,939.87352
Overall Steps per Second: 10,848.21542

Timestep Collection Time: 2.18057
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61108

Cumulative Model Updates: 96,004
Cumulative Timesteps: 800,659,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 800659424...
Checkpoint 800659424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,938.57181
Policy Entropy: 3.59574
Value Function Loss: 0.08907

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.55876
Value Function Update Magnitude: 0.79824

Collected Steps per Second: 22,721.96839
Overall Steps per Second: 10,703.28471

Timestep Collection Time: 2.20060
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.67165

Cumulative Model Updates: 96,010
Cumulative Timesteps: 800,709,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,333.16627
Policy Entropy: 3.58703
Value Function Loss: 0.08896

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.53639
Value Function Update Magnitude: 0.75209

Collected Steps per Second: 23,047.12539
Overall Steps per Second: 10,875.99410

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.42898
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59949

Cumulative Model Updates: 96,016
Cumulative Timesteps: 800,759,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 800759450...
Checkpoint 800759450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,865.31022
Policy Entropy: 3.58389
Value Function Loss: 0.09045

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.62402
Value Function Update Magnitude: 0.75132

Collected Steps per Second: 22,504.92371
Overall Steps per Second: 10,710.69195

Timestep Collection Time: 2.22271
Timestep Consumption Time: 2.44757
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.67029

Cumulative Model Updates: 96,022
Cumulative Timesteps: 800,809,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,249.51744
Policy Entropy: 3.59301
Value Function Loss: 0.08745

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.78411

Collected Steps per Second: 22,603.97728
Overall Steps per Second: 10,609.78752

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.50213
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71546

Cumulative Model Updates: 96,028
Cumulative Timesteps: 800,859,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 800859502...
Checkpoint 800859502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,883.44056
Policy Entropy: 3.57619
Value Function Loss: 0.08669

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.50085
Value Function Update Magnitude: 0.84454

Collected Steps per Second: 22,694.26651
Overall Steps per Second: 10,702.36673

Timestep Collection Time: 2.20399
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.67355

Cumulative Model Updates: 96,034
Cumulative Timesteps: 800,909,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,748.12046
Policy Entropy: 3.57525
Value Function Loss: 0.08729

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.51056
Value Function Update Magnitude: 0.81789

Collected Steps per Second: 22,772.58810
Overall Steps per Second: 10,678.44712

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.68383

Cumulative Model Updates: 96,040
Cumulative Timesteps: 800,959,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 800959536...
Checkpoint 800959536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,926.38039
Policy Entropy: 3.56411
Value Function Loss: 0.08764

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.50095
Value Function Update Magnitude: 0.75266

Collected Steps per Second: 22,412.22030
Overall Steps per Second: 10,668.43259

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.45639
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.68785

Cumulative Model Updates: 96,046
Cumulative Timesteps: 801,009,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,994.22085
Policy Entropy: 3.56451
Value Function Loss: 0.08850

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.64860
Value Function Update Magnitude: 0.75768

Collected Steps per Second: 23,091.32865
Overall Steps per Second: 10,820.92030

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.45546
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.62086

Cumulative Model Updates: 96,052
Cumulative Timesteps: 801,059,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 801059550...
Checkpoint 801059550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,462.45744
Policy Entropy: 3.57344
Value Function Loss: 0.08808

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.58619
Value Function Update Magnitude: 0.72159

Collected Steps per Second: 22,781.49047
Overall Steps per Second: 10,682.05603

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.68299

Cumulative Model Updates: 96,058
Cumulative Timesteps: 801,109,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,794.62573
Policy Entropy: 3.56351
Value Function Loss: 0.08954

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.52917
Value Function Update Magnitude: 0.70311

Collected Steps per Second: 23,000.03968
Overall Steps per Second: 10,864.55586

Timestep Collection Time: 2.17469
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60378

Cumulative Model Updates: 96,064
Cumulative Timesteps: 801,159,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 801159592...
Checkpoint 801159592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,968.80834
Policy Entropy: 3.56903
Value Function Loss: 0.08989

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.59838
Value Function Update Magnitude: 0.71775

Collected Steps per Second: 22,565.66902
Overall Steps per Second: 10,717.98386

Timestep Collection Time: 2.21673
Timestep Consumption Time: 2.45038
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.66711

Cumulative Model Updates: 96,070
Cumulative Timesteps: 801,209,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,732.36596
Policy Entropy: 3.55195
Value Function Loss: 0.09180

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.15824
Policy Update Magnitude: 0.53731
Value Function Update Magnitude: 0.68480

Collected Steps per Second: 23,099.99407
Overall Steps per Second: 10,868.44510

Timestep Collection Time: 2.16459
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60066

Cumulative Model Updates: 96,076
Cumulative Timesteps: 801,259,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 801259616...
Checkpoint 801259616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,550.36236
Policy Entropy: 3.54643
Value Function Loss: 0.09337

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.18787
Policy Update Magnitude: 0.44215
Value Function Update Magnitude: 0.73603

Collected Steps per Second: 22,724.07392
Overall Steps per Second: 10,688.17916

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.47865
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.67975

Cumulative Model Updates: 96,082
Cumulative Timesteps: 801,309,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.97076
Policy Entropy: 3.55423
Value Function Loss: 0.09066

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.15926
Policy Update Magnitude: 0.42974
Value Function Update Magnitude: 0.80590

Collected Steps per Second: 22,833.57736
Overall Steps per Second: 10,829.56307

Timestep Collection Time: 2.18993
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61736

Cumulative Model Updates: 96,088
Cumulative Timesteps: 801,359,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 801359638...
Checkpoint 801359638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,647.40499
Policy Entropy: 3.57662
Value Function Loss: 0.08559

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.17512
Policy Update Magnitude: 0.44930
Value Function Update Magnitude: 0.80054

Collected Steps per Second: 22,077.43284
Overall Steps per Second: 10,648.73252

Timestep Collection Time: 2.26539
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.69671

Cumulative Model Updates: 96,094
Cumulative Timesteps: 801,409,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,458.65902
Policy Entropy: 3.57862
Value Function Loss: 0.08215

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.46556
Value Function Update Magnitude: 0.72194

Collected Steps per Second: 22,733.25220
Overall Steps per Second: 10,630.71841

Timestep Collection Time: 2.19995
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.70448

Cumulative Model Updates: 96,100
Cumulative Timesteps: 801,459,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 801459664...
Checkpoint 801459664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,192.51458
Policy Entropy: 3.59339
Value Function Loss: 0.08110

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.16442
Policy Update Magnitude: 0.46627
Value Function Update Magnitude: 0.65299

Collected Steps per Second: 22,552.90743
Overall Steps per Second: 10,500.13345

Timestep Collection Time: 2.21816
Timestep Consumption Time: 2.54616
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.76432

Cumulative Model Updates: 96,106
Cumulative Timesteps: 801,509,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,674.41596
Policy Entropy: 3.59537
Value Function Loss: 0.08077

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.51430
Value Function Update Magnitude: 0.70583

Collected Steps per Second: 23,127.56428
Overall Steps per Second: 10,857.00090

Timestep Collection Time: 2.16279
Timestep Consumption Time: 2.44438
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60717

Cumulative Model Updates: 96,112
Cumulative Timesteps: 801,559,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 801559710...
Checkpoint 801559710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,129.75487
Policy Entropy: 3.60507
Value Function Loss: 0.07658

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.17454
Policy Update Magnitude: 0.51198
Value Function Update Magnitude: 0.76654

Collected Steps per Second: 22,727.62598
Overall Steps per Second: 10,687.54913

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.67909

Cumulative Model Updates: 96,118
Cumulative Timesteps: 801,609,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,181.57452
Policy Entropy: 3.63658
Value Function Loss: 0.07703

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.46654
Value Function Update Magnitude: 0.78386

Collected Steps per Second: 23,089.94472
Overall Steps per Second: 10,857.72536

Timestep Collection Time: 2.16657
Timestep Consumption Time: 2.44084
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60741

Cumulative Model Updates: 96,124
Cumulative Timesteps: 801,659,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 801659744...
Checkpoint 801659744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.85997
Policy Entropy: 3.64745
Value Function Loss: 0.07603

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.47778
Value Function Update Magnitude: 0.78787

Collected Steps per Second: 22,694.70598
Overall Steps per Second: 10,711.03900

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.67032

Cumulative Model Updates: 96,130
Cumulative Timesteps: 801,709,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,058.55514
Policy Entropy: 3.63117
Value Function Loss: 0.07591

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.49191
Value Function Update Magnitude: 0.76152

Collected Steps per Second: 23,169.67143
Overall Steps per Second: 10,900.75570

Timestep Collection Time: 2.15981
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.59069

Cumulative Model Updates: 96,136
Cumulative Timesteps: 801,759,810

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 801759810...
Checkpoint 801759810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.78456
Policy Entropy: 3.63605
Value Function Loss: 0.06778

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.48301
Value Function Update Magnitude: 0.76057

Collected Steps per Second: 22,478.54627
Overall Steps per Second: 10,692.63608

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.67705

Cumulative Model Updates: 96,142
Cumulative Timesteps: 801,809,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.66804
Policy Entropy: 3.63632
Value Function Loss: 0.06726

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.53029
Value Function Update Magnitude: 0.73398

Collected Steps per Second: 22,717.10876
Overall Steps per Second: 10,810.53475

Timestep Collection Time: 2.20275
Timestep Consumption Time: 2.42607
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62882

Cumulative Model Updates: 96,148
Cumulative Timesteps: 801,859,860

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 801859860...
Checkpoint 801859860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,245.48339
Policy Entropy: 3.64285
Value Function Loss: 0.06483

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.58588
Value Function Update Magnitude: 0.73410

Collected Steps per Second: 22,026.40746
Overall Steps per Second: 10,645.38016

Timestep Collection Time: 2.27009
Timestep Consumption Time: 2.42697
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.69706

Cumulative Model Updates: 96,154
Cumulative Timesteps: 801,909,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,730.61979
Policy Entropy: 3.63136
Value Function Loss: 0.06985

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.52773
Value Function Update Magnitude: 0.73000

Collected Steps per Second: 22,314.79337
Overall Steps per Second: 10,517.02623

Timestep Collection Time: 2.24183
Timestep Consumption Time: 2.51484
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.75667

Cumulative Model Updates: 96,160
Cumulative Timesteps: 801,959,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 801959888...
Checkpoint 801959888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,875.15770
Policy Entropy: 3.62343
Value Function Loss: 0.07037

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.49770
Value Function Update Magnitude: 0.68557

Collected Steps per Second: 22,227.75664
Overall Steps per Second: 10,702.85528

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.67315

Cumulative Model Updates: 96,166
Cumulative Timesteps: 802,009,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,669.24253
Policy Entropy: 3.62173
Value Function Loss: 0.07278

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.63112

Collected Steps per Second: 23,119.81435
Overall Steps per Second: 10,788.01668

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.47341
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63718

Cumulative Model Updates: 96,172
Cumulative Timesteps: 802,059,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 802059930...
Checkpoint 802059930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,017.02150
Policy Entropy: 3.61062
Value Function Loss: 0.07705

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.62648
Value Function Update Magnitude: 0.57430

Collected Steps per Second: 22,723.72141
Overall Steps per Second: 10,677.82571

Timestep Collection Time: 2.20149
Timestep Consumption Time: 2.48355
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.68504

Cumulative Model Updates: 96,178
Cumulative Timesteps: 802,109,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,510.13409
Policy Entropy: 3.60218
Value Function Loss: 0.07949

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.65993
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 23,066.63334
Overall Steps per Second: 10,882.85709

Timestep Collection Time: 2.16781
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.59475

Cumulative Model Updates: 96,184
Cumulative Timesteps: 802,159,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 802159960...
Checkpoint 802159960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,584.38596
Policy Entropy: 3.58451
Value Function Loss: 0.07972

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.76450
Value Function Update Magnitude: 0.58236

Collected Steps per Second: 22,408.26446
Overall Steps per Second: 10,739.27360

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.65823

Cumulative Model Updates: 96,190
Cumulative Timesteps: 802,209,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,120.49017
Policy Entropy: 3.59417
Value Function Loss: 0.07807

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.73245
Value Function Update Magnitude: 0.56695

Collected Steps per Second: 22,620.42665
Overall Steps per Second: 10,849.50312

Timestep Collection Time: 2.21066
Timestep Consumption Time: 2.39840
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.60906

Cumulative Model Updates: 96,196
Cumulative Timesteps: 802,259,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 802259992...
Checkpoint 802259992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,146.81215
Policy Entropy: 3.60431
Value Function Loss: 0.07840

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.62849
Value Function Update Magnitude: 0.58977

Collected Steps per Second: 22,105.87782
Overall Steps per Second: 10,635.35330

Timestep Collection Time: 2.26311
Timestep Consumption Time: 2.44083
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.70393

Cumulative Model Updates: 96,202
Cumulative Timesteps: 802,310,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,003.29741
Policy Entropy: 3.63893
Value Function Loss: 0.07793

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.62688

Collected Steps per Second: 21,257.79886
Overall Steps per Second: 10,480.98673

Timestep Collection Time: 2.35292
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.77226

Cumulative Model Updates: 96,208
Cumulative Timesteps: 802,360,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 802360038...
Checkpoint 802360038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,399.15569
Policy Entropy: 3.63726
Value Function Loss: 0.07917

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.54713
Value Function Update Magnitude: 0.66723

Collected Steps per Second: 21,348.47318
Overall Steps per Second: 10,662.07662

Timestep Collection Time: 2.34246
Timestep Consumption Time: 2.34781
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.69027

Cumulative Model Updates: 96,214
Cumulative Timesteps: 802,410,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,992.12660
Policy Entropy: 3.62187
Value Function Loss: 0.08163

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.60990
Value Function Update Magnitude: 0.71664

Collected Steps per Second: 22,044.59206
Overall Steps per Second: 10,806.94390

Timestep Collection Time: 2.26895
Timestep Consumption Time: 2.35937
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.62832

Cumulative Model Updates: 96,220
Cumulative Timesteps: 802,460,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 802460064...
Checkpoint 802460064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,600.41211
Policy Entropy: 3.61247
Value Function Loss: 0.08291

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.61981
Value Function Update Magnitude: 0.66794

Collected Steps per Second: 21,936.10057
Overall Steps per Second: 10,624.87653

Timestep Collection Time: 2.27999
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.70725

Cumulative Model Updates: 96,226
Cumulative Timesteps: 802,510,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,817.25466
Policy Entropy: 3.62301
Value Function Loss: 0.08290

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.70587

Collected Steps per Second: 23,064.06644
Overall Steps per Second: 10,883.18758

Timestep Collection Time: 2.16883
Timestep Consumption Time: 2.42744
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59626

Cumulative Model Updates: 96,232
Cumulative Timesteps: 802,560,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 802560100...
Checkpoint 802560100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,888.90093
Policy Entropy: 3.62916
Value Function Loss: 0.08476

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.49912
Value Function Update Magnitude: 0.65746

Collected Steps per Second: 22,584.25122
Overall Steps per Second: 10,757.59037

Timestep Collection Time: 2.21446
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.64900

Cumulative Model Updates: 96,238
Cumulative Timesteps: 802,610,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,349.58080
Policy Entropy: 3.63008
Value Function Loss: 0.08767

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.43443
Value Function Update Magnitude: 0.60942

Collected Steps per Second: 22,922.35203
Overall Steps per Second: 10,907.44187

Timestep Collection Time: 2.18276
Timestep Consumption Time: 2.40438
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.58714

Cumulative Model Updates: 96,244
Cumulative Timesteps: 802,660,146

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 802660146...
Checkpoint 802660146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,534.83041
Policy Entropy: 3.61931
Value Function Loss: 0.08977

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.49640
Value Function Update Magnitude: 0.58946

Collected Steps per Second: 22,794.61943
Overall Steps per Second: 10,656.29136

Timestep Collection Time: 2.19350
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.69206

Cumulative Model Updates: 96,250
Cumulative Timesteps: 802,710,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,303.75513
Policy Entropy: 3.63005
Value Function Loss: 0.08941

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.51245
Value Function Update Magnitude: 0.60913

Collected Steps per Second: 23,021.34530
Overall Steps per Second: 10,857.55134

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60509

Cumulative Model Updates: 96,256
Cumulative Timesteps: 802,760,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 802760146...
Checkpoint 802760146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,305.71054
Policy Entropy: 3.64218
Value Function Loss: 0.09367

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.51268
Value Function Update Magnitude: 0.68011

Collected Steps per Second: 21,897.17207
Overall Steps per Second: 10,614.47627

Timestep Collection Time: 2.28422
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.71224

Cumulative Model Updates: 96,262
Cumulative Timesteps: 802,810,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,504.81691
Policy Entropy: 3.65134
Value Function Loss: 0.09454

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.50955
Value Function Update Magnitude: 0.67624

Collected Steps per Second: 22,615.25557
Overall Steps per Second: 10,609.92948

Timestep Collection Time: 2.21196
Timestep Consumption Time: 2.50287
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.71483

Cumulative Model Updates: 96,268
Cumulative Timesteps: 802,860,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 802860188...
Checkpoint 802860188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,390.17247
Policy Entropy: 3.63914
Value Function Loss: 0.09179

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.54098
Value Function Update Magnitude: 0.73039

Collected Steps per Second: 22,228.37652
Overall Steps per Second: 10,517.57236

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.75509

Cumulative Model Updates: 96,274
Cumulative Timesteps: 802,910,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,811.20193
Policy Entropy: 3.62710
Value Function Loss: 0.08935

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.57637
Value Function Update Magnitude: 0.75154

Collected Steps per Second: 22,676.12431
Overall Steps per Second: 10,616.00805

Timestep Collection Time: 2.20699
Timestep Consumption Time: 2.50721
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71420

Cumulative Model Updates: 96,280
Cumulative Timesteps: 802,960,246

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 802960246...
Checkpoint 802960246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,578.27102
Policy Entropy: 3.62266
Value Function Loss: 0.08897

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.52519
Value Function Update Magnitude: 0.74239

Collected Steps per Second: 22,692.02304
Overall Steps per Second: 10,604.55819

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.51244
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.71665

Cumulative Model Updates: 96,286
Cumulative Timesteps: 803,010,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,135.86904
Policy Entropy: 3.63403
Value Function Loss: 0.09138

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.71133

Collected Steps per Second: 23,247.97936
Overall Steps per Second: 10,727.21116

Timestep Collection Time: 2.15176
Timestep Consumption Time: 2.51152
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.66328

Cumulative Model Updates: 96,292
Cumulative Timesteps: 803,060,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 803060288...
Checkpoint 803060288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,662.18424
Policy Entropy: 3.62500
Value Function Loss: 0.09370

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.70450

Collected Steps per Second: 22,685.31006
Overall Steps per Second: 10,703.58840

Timestep Collection Time: 2.20407
Timestep Consumption Time: 2.46726
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.67133

Cumulative Model Updates: 96,298
Cumulative Timesteps: 803,110,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,057.46199
Policy Entropy: 3.62559
Value Function Loss: 0.09218

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.17828
Policy Update Magnitude: 0.53460
Value Function Update Magnitude: 0.70126

Collected Steps per Second: 23,106.54413
Overall Steps per Second: 10,922.75715

Timestep Collection Time: 2.16398
Timestep Consumption Time: 2.41381
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.57778

Cumulative Model Updates: 96,304
Cumulative Timesteps: 803,160,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 803160290...
Checkpoint 803160290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,287.48740
Policy Entropy: 3.61704
Value Function Loss: 0.09330

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.56519
Value Function Update Magnitude: 0.67209

Collected Steps per Second: 22,638.12897
Overall Steps per Second: 10,651.64084

Timestep Collection Time: 2.20981
Timestep Consumption Time: 2.48674
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.69655

Cumulative Model Updates: 96,310
Cumulative Timesteps: 803,210,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,731.41588
Policy Entropy: 3.61582
Value Function Loss: 0.09135

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.71415

Collected Steps per Second: 23,138.32308
Overall Steps per Second: 10,881.93697

Timestep Collection Time: 2.16213
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.59734

Cumulative Model Updates: 96,316
Cumulative Timesteps: 803,260,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 803260344...
Checkpoint 803260344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,306.54346
Policy Entropy: 3.60061
Value Function Loss: 0.09275

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.58852
Value Function Update Magnitude: 0.68731

Collected Steps per Second: 22,234.47146
Overall Steps per Second: 10,643.91832

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.44925
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.69846

Cumulative Model Updates: 96,322
Cumulative Timesteps: 803,310,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,658.08021
Policy Entropy: 3.60024
Value Function Loss: 0.08767

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.51617
Value Function Update Magnitude: 0.74258

Collected Steps per Second: 21,888.12108
Overall Steps per Second: 10,647.73826

Timestep Collection Time: 2.28535
Timestep Consumption Time: 2.41255
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69790

Cumulative Model Updates: 96,328
Cumulative Timesteps: 803,360,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 803360376...
Checkpoint 803360376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,738.54917
Policy Entropy: 3.59316
Value Function Loss: 0.08300

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.53920
Value Function Update Magnitude: 0.80099

Collected Steps per Second: 21,720.12086
Overall Steps per Second: 10,647.20618

Timestep Collection Time: 2.30330
Timestep Consumption Time: 2.39540
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.69870

Cumulative Model Updates: 96,334
Cumulative Timesteps: 803,410,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,112.67686
Policy Entropy: 3.59455
Value Function Loss: 0.08411

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.51475
Value Function Update Magnitude: 0.73019

Collected Steps per Second: 22,176.55620
Overall Steps per Second: 10,705.48546

Timestep Collection Time: 2.25590
Timestep Consumption Time: 2.41722
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.67312

Cumulative Model Updates: 96,340
Cumulative Timesteps: 803,460,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 803460432...
Checkpoint 803460432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,291.77422
Policy Entropy: 3.59386
Value Function Loss: 0.08737

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.43354
Value Function Update Magnitude: 0.69560

Collected Steps per Second: 21,694.88490
Overall Steps per Second: 10,657.92480

Timestep Collection Time: 2.30488
Timestep Consumption Time: 2.38684
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.69172

Cumulative Model Updates: 96,346
Cumulative Timesteps: 803,510,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,708.32090
Policy Entropy: 3.59784
Value Function Loss: 0.09181

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.43692
Value Function Update Magnitude: 0.69267

Collected Steps per Second: 22,226.32142
Overall Steps per Second: 10,830.58353

Timestep Collection Time: 2.25084
Timestep Consumption Time: 2.36830
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.61914

Cumulative Model Updates: 96,352
Cumulative Timesteps: 803,560,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 803560464...
Checkpoint 803560464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,003.91270
Policy Entropy: 3.58729
Value Function Loss: 0.09362

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.46762
Value Function Update Magnitude: 0.76647

Collected Steps per Second: 21,822.14520
Overall Steps per Second: 10,647.32660

Timestep Collection Time: 2.29263
Timestep Consumption Time: 2.40621
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.69883

Cumulative Model Updates: 96,358
Cumulative Timesteps: 803,610,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,387.73635
Policy Entropy: 3.59405
Value Function Loss: 0.09381

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.39620
Value Function Update Magnitude: 0.68660

Collected Steps per Second: 22,916.36421
Overall Steps per Second: 10,890.04077

Timestep Collection Time: 2.18211
Timestep Consumption Time: 2.40979
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59190

Cumulative Model Updates: 96,364
Cumulative Timesteps: 803,660,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 803660500...
Checkpoint 803660500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,197.62020
Policy Entropy: 3.58912
Value Function Loss: 0.09245

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15630
Policy Update Magnitude: 0.46007
Value Function Update Magnitude: 0.66562

Collected Steps per Second: 22,399.98108
Overall Steps per Second: 10,717.33121

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.66590

Cumulative Model Updates: 96,370
Cumulative Timesteps: 803,710,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,197.40028
Policy Entropy: 3.59996
Value Function Loss: 0.08772

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.15744
Policy Update Magnitude: 0.44883
Value Function Update Magnitude: 0.68952

Collected Steps per Second: 22,933.87125
Overall Steps per Second: 10,918.95151

Timestep Collection Time: 2.18114
Timestep Consumption Time: 2.40007
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.58121

Cumulative Model Updates: 96,376
Cumulative Timesteps: 803,760,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 803760528...
Checkpoint 803760528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,813.70654
Policy Entropy: 3.60991
Value Function Loss: 0.08253

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.47423
Value Function Update Magnitude: 0.78120

Collected Steps per Second: 22,450.57635
Overall Steps per Second: 10,661.57334

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.46400
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69237

Cumulative Model Updates: 96,382
Cumulative Timesteps: 803,810,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.31354
Policy Entropy: 3.62415
Value Function Loss: 0.07690

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.47881
Value Function Update Magnitude: 0.80148

Collected Steps per Second: 22,260.60049
Overall Steps per Second: 10,536.79624

Timestep Collection Time: 2.24612
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.74528

Cumulative Model Updates: 96,388
Cumulative Timesteps: 803,860,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 803860556...
Checkpoint 803860556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,802.45712
Policy Entropy: 3.62459
Value Function Loss: 0.07343

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.48730
Value Function Update Magnitude: 0.76829

Collected Steps per Second: 22,540.74220
Overall Steps per Second: 10,585.42124

Timestep Collection Time: 2.21892
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.72499

Cumulative Model Updates: 96,394
Cumulative Timesteps: 803,910,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.15540
Policy Entropy: 3.62583
Value Function Loss: 0.07439

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.48880
Value Function Update Magnitude: 0.78598

Collected Steps per Second: 22,973.20846
Overall Steps per Second: 10,844.86338

Timestep Collection Time: 2.17723
Timestep Consumption Time: 2.43491
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61214

Cumulative Model Updates: 96,400
Cumulative Timesteps: 803,960,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 803960590...
Checkpoint 803960590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,234.26781
Policy Entropy: 3.63069
Value Function Loss: 0.07719

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.75248

Collected Steps per Second: 22,386.64183
Overall Steps per Second: 10,636.10235

Timestep Collection Time: 2.23374
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.70153

Cumulative Model Updates: 96,406
Cumulative Timesteps: 804,010,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,570.43111
Policy Entropy: 3.63077
Value Function Loss: 0.07681

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.77383

Collected Steps per Second: 23,229.36703
Overall Steps per Second: 10,877.39095

Timestep Collection Time: 2.15253
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.59687

Cumulative Model Updates: 96,412
Cumulative Timesteps: 804,060,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 804060598...
Checkpoint 804060598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,716.61006
Policy Entropy: 3.63529
Value Function Loss: 0.07337

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.48961
Value Function Update Magnitude: 0.78065

Collected Steps per Second: 22,855.02414
Overall Steps per Second: 10,698.75363

Timestep Collection Time: 2.18893
Timestep Consumption Time: 2.48713
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.67606

Cumulative Model Updates: 96,418
Cumulative Timesteps: 804,110,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,748.19659
Policy Entropy: 3.64382
Value Function Loss: 0.07145

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.51042
Value Function Update Magnitude: 0.77454

Collected Steps per Second: 22,745.81540
Overall Steps per Second: 10,803.33762

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.63061

Cumulative Model Updates: 96,424
Cumulative Timesteps: 804,160,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 804160652...
Checkpoint 804160652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.52370
Policy Entropy: 3.63434
Value Function Loss: 0.07368

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.46192
Value Function Update Magnitude: 0.74777

Collected Steps per Second: 22,653.34078
Overall Steps per Second: 10,717.95889

Timestep Collection Time: 2.20903
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.66899

Cumulative Model Updates: 96,430
Cumulative Timesteps: 804,210,694

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,800.55883
Policy Entropy: 3.64813
Value Function Loss: 0.07337

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.46566
Value Function Update Magnitude: 0.74446

Collected Steps per Second: 21,662.40258
Overall Steps per Second: 10,489.70599

Timestep Collection Time: 2.30972
Timestep Consumption Time: 2.46010
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.76982

Cumulative Model Updates: 96,436
Cumulative Timesteps: 804,260,728

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 804260728...
Checkpoint 804260728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,334.26737
Policy Entropy: 3.63325
Value Function Loss: 0.07774

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.51567
Value Function Update Magnitude: 0.70271

Collected Steps per Second: 22,699.83773
Overall Steps per Second: 10,633.83579

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.50061
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.70442

Cumulative Model Updates: 96,442
Cumulative Timesteps: 804,310,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,710.61433
Policy Entropy: 3.63219
Value Function Loss: 0.07739

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.73222

Collected Steps per Second: 22,900.20720
Overall Steps per Second: 10,847.27128

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.61019

Cumulative Model Updates: 96,448
Cumulative Timesteps: 804,360,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 804360762...
Checkpoint 804360762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,605.14341
Policy Entropy: 3.62007
Value Function Loss: 0.07849

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.60642
Value Function Update Magnitude: 0.72014

Collected Steps per Second: 22,032.95959
Overall Steps per Second: 10,651.56917

Timestep Collection Time: 2.27051
Timestep Consumption Time: 2.42608
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.69658

Cumulative Model Updates: 96,454
Cumulative Timesteps: 804,410,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,797.24056
Policy Entropy: 3.63391
Value Function Loss: 0.07555

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.50264
Value Function Update Magnitude: 0.63992

Collected Steps per Second: 22,866.14874
Overall Steps per Second: 10,740.45619

Timestep Collection Time: 2.18778
Timestep Consumption Time: 2.46994
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.65772

Cumulative Model Updates: 96,460
Cumulative Timesteps: 804,460,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 804460814...
Checkpoint 804460814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,771.17619
Policy Entropy: 3.63730
Value Function Loss: 0.07684

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06243
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.63660

Collected Steps per Second: 22,490.27486
Overall Steps per Second: 10,773.01256

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.41824
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.64160

Cumulative Model Updates: 96,466
Cumulative Timesteps: 804,510,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,406.48873
Policy Entropy: 3.63966
Value Function Loss: 0.07658

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.67433
Value Function Update Magnitude: 0.63810

Collected Steps per Second: 22,407.22394
Overall Steps per Second: 10,533.59152

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.51560
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.74729

Cumulative Model Updates: 96,472
Cumulative Timesteps: 804,560,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 804560824...
Checkpoint 804560824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,276.46374
Policy Entropy: 3.64468
Value Function Loss: 0.07426

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.67417
Value Function Update Magnitude: 0.64040

Collected Steps per Second: 22,456.60296
Overall Steps per Second: 10,700.61726

Timestep Collection Time: 2.22750
Timestep Consumption Time: 2.44719
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.67468

Cumulative Model Updates: 96,478
Cumulative Timesteps: 804,610,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,586.20926
Policy Entropy: 3.64237
Value Function Loss: 0.07537

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.66659
Value Function Update Magnitude: 0.66871

Collected Steps per Second: 23,062.07549
Overall Steps per Second: 10,880.47308

Timestep Collection Time: 2.16850
Timestep Consumption Time: 2.42781
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.59631

Cumulative Model Updates: 96,484
Cumulative Timesteps: 804,660,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 804660856...
Checkpoint 804660856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,860.36119
Policy Entropy: 3.64704
Value Function Loss: 0.07674

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.74409
Value Function Update Magnitude: 0.69457

Collected Steps per Second: 22,821.30037
Overall Steps per Second: 10,666.22222

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.68957

Cumulative Model Updates: 96,490
Cumulative Timesteps: 804,710,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,912.55259
Policy Entropy: 3.64584
Value Function Loss: 0.08025

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.72813
Value Function Update Magnitude: 0.69731

Collected Steps per Second: 23,331.77984
Overall Steps per Second: 10,844.16235

Timestep Collection Time: 2.14334
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.61151

Cumulative Model Updates: 96,496
Cumulative Timesteps: 804,760,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 804760884...
Checkpoint 804760884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,492.22048
Policy Entropy: 3.64622
Value Function Loss: 0.07948

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.58507
Value Function Update Magnitude: 0.74303

Collected Steps per Second: 22,366.97590
Overall Steps per Second: 10,595.79675

Timestep Collection Time: 2.23624
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.72055

Cumulative Model Updates: 96,502
Cumulative Timesteps: 804,810,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,163.80352
Policy Entropy: 3.64435
Value Function Loss: 0.08135

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.49070
Value Function Update Magnitude: 0.76351

Collected Steps per Second: 22,963.80980
Overall Steps per Second: 10,857.21604

Timestep Collection Time: 2.17812
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.60689

Cumulative Model Updates: 96,508
Cumulative Timesteps: 804,860,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 804860920...
Checkpoint 804860920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,468.19778
Policy Entropy: 3.64305
Value Function Loss: 0.08283

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.45406
Value Function Update Magnitude: 0.71835

Collected Steps per Second: 22,387.95450
Overall Steps per Second: 10,741.28869

Timestep Collection Time: 2.23459
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.65754

Cumulative Model Updates: 96,514
Cumulative Timesteps: 804,910,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,759.27898
Policy Entropy: 3.63526
Value Function Loss: 0.08437

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.55631
Value Function Update Magnitude: 0.69682

Collected Steps per Second: 22,834.90691
Overall Steps per Second: 10,845.30257

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.61306

Cumulative Model Updates: 96,520
Cumulative Timesteps: 804,960,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 804960978...
Checkpoint 804960978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,274.92129
Policy Entropy: 3.62260
Value Function Loss: 0.08891

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.66020
Value Function Update Magnitude: 0.67502

Collected Steps per Second: 21,544.75952
Overall Steps per Second: 10,699.09849

Timestep Collection Time: 2.32270
Timestep Consumption Time: 2.35452
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.67722

Cumulative Model Updates: 96,526
Cumulative Timesteps: 805,011,020

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,672.45621
Policy Entropy: 3.62118
Value Function Loss: 0.08883

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.67312
Value Function Update Magnitude: 0.68140

Collected Steps per Second: 21,845.66798
Overall Steps per Second: 10,612.54239

Timestep Collection Time: 2.28897
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.71178

Cumulative Model Updates: 96,532
Cumulative Timesteps: 805,061,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 805061024...
Checkpoint 805061024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.97514
Policy Entropy: 3.62464
Value Function Loss: 0.08814

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.69661

Collected Steps per Second: 21,713.65480
Overall Steps per Second: 10,527.14216

Timestep Collection Time: 2.30288
Timestep Consumption Time: 2.44712
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.75001

Cumulative Model Updates: 96,538
Cumulative Timesteps: 805,111,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,070.87114
Policy Entropy: 3.63575
Value Function Loss: 0.08416

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.71448

Collected Steps per Second: 22,477.06838
Overall Steps per Second: 10,781.01837

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.41416
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.63945

Cumulative Model Updates: 96,544
Cumulative Timesteps: 805,161,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 805161046...
Checkpoint 805161046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,049.57961
Policy Entropy: 3.62646
Value Function Loss: 0.08800

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.51846
Value Function Update Magnitude: 0.70180

Collected Steps per Second: 21,855.04947
Overall Steps per Second: 10,711.08025

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.38093
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.66937

Cumulative Model Updates: 96,550
Cumulative Timesteps: 805,211,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,894.83900
Policy Entropy: 3.60861
Value Function Loss: 0.09090

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.44398
Value Function Update Magnitude: 0.68631

Collected Steps per Second: 22,639.64111
Overall Steps per Second: 10,812.98674

Timestep Collection Time: 2.20922
Timestep Consumption Time: 2.41633
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62555

Cumulative Model Updates: 96,556
Cumulative Timesteps: 805,261,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 805261076...
Checkpoint 805261076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,121.06985
Policy Entropy: 3.59790
Value Function Loss: 0.09277

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.44666
Value Function Update Magnitude: 0.69152

Collected Steps per Second: 22,570.20436
Overall Steps per Second: 10,724.72411

Timestep Collection Time: 2.21584
Timestep Consumption Time: 2.44740
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.66324

Cumulative Model Updates: 96,562
Cumulative Timesteps: 805,311,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,133.16546
Policy Entropy: 3.59875
Value Function Loss: 0.08967

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.49057
Value Function Update Magnitude: 0.71624

Collected Steps per Second: 22,853.74526
Overall Steps per Second: 10,869.72987

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.41278
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.60122

Cumulative Model Updates: 96,568
Cumulative Timesteps: 805,361,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 805361102...
Checkpoint 805361102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,697.52874
Policy Entropy: 3.61173
Value Function Loss: 0.08819

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.52895
Value Function Update Magnitude: 0.73466

Collected Steps per Second: 22,434.70916
Overall Steps per Second: 10,691.78184

Timestep Collection Time: 2.22931
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.67780

Cumulative Model Updates: 96,574
Cumulative Timesteps: 805,411,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,625.09178
Policy Entropy: 3.61509
Value Function Loss: 0.08949

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.51927
Value Function Update Magnitude: 0.67320

Collected Steps per Second: 22,757.24809
Overall Steps per Second: 10,794.90028

Timestep Collection Time: 2.19824
Timestep Consumption Time: 2.43598
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.63423

Cumulative Model Updates: 96,580
Cumulative Timesteps: 805,461,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 805461142...
Checkpoint 805461142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,197.12614
Policy Entropy: 3.60339
Value Function Loss: 0.09428

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.50405
Value Function Update Magnitude: 0.66577

Collected Steps per Second: 22,155.37897
Overall Steps per Second: 10,643.84338

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.70018

Cumulative Model Updates: 96,586
Cumulative Timesteps: 805,511,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,255.27169
Policy Entropy: 3.60775
Value Function Loss: 0.09401

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.51851
Value Function Update Magnitude: 0.67644

Collected Steps per Second: 22,756.04647
Overall Steps per Second: 10,633.46200

Timestep Collection Time: 2.19818
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.70421

Cumulative Model Updates: 96,592
Cumulative Timesteps: 805,561,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 805561192...
Checkpoint 805561192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,313.97845
Policy Entropy: 3.60933
Value Function Loss: 0.09400

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.51342
Value Function Update Magnitude: 0.67375

Collected Steps per Second: 22,043.50636
Overall Steps per Second: 10,584.57050

Timestep Collection Time: 2.26951
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.72650

Cumulative Model Updates: 96,598
Cumulative Timesteps: 805,611,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,754.27717
Policy Entropy: 3.62157
Value Function Loss: 0.09350

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.45284
Value Function Update Magnitude: 0.70527

Collected Steps per Second: 23,134.69683
Overall Steps per Second: 10,819.36409

Timestep Collection Time: 2.16143
Timestep Consumption Time: 2.46028
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.62171

Cumulative Model Updates: 96,604
Cumulative Timesteps: 805,661,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 805661224...
Checkpoint 805661224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,305.94704
Policy Entropy: 3.62110
Value Function Loss: 0.09476

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.42346
Value Function Update Magnitude: 0.70713

Collected Steps per Second: 22,640.38537
Overall Steps per Second: 10,645.06968

Timestep Collection Time: 2.20897
Timestep Consumption Time: 2.48916
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.69814

Cumulative Model Updates: 96,610
Cumulative Timesteps: 805,711,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.10503
Policy Entropy: 3.61110
Value Function Loss: 0.09702

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.43038
Value Function Update Magnitude: 0.70247

Collected Steps per Second: 23,009.08509
Overall Steps per Second: 10,750.77322

Timestep Collection Time: 2.17392
Timestep Consumption Time: 2.47876
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.65269

Cumulative Model Updates: 96,616
Cumulative Timesteps: 805,761,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 805761256...
Checkpoint 805761256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,530.35585
Policy Entropy: 3.60703
Value Function Loss: 0.09551

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.44666
Value Function Update Magnitude: 0.71786

Collected Steps per Second: 22,649.36642
Overall Steps per Second: 10,772.90662

Timestep Collection Time: 2.20854
Timestep Consumption Time: 2.43478
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.64332

Cumulative Model Updates: 96,622
Cumulative Timesteps: 805,811,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,548.61147
Policy Entropy: 3.61126
Value Function Loss: 0.09499

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.44642
Value Function Update Magnitude: 0.72497

Collected Steps per Second: 22,951.85442
Overall Steps per Second: 10,717.10342

Timestep Collection Time: 2.17934
Timestep Consumption Time: 2.48796
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.66731

Cumulative Model Updates: 96,628
Cumulative Timesteps: 805,861,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 805861298...
Checkpoint 805861298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,208.00044
Policy Entropy: 3.61343
Value Function Loss: 0.09168

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.44740
Value Function Update Magnitude: 0.69133

Collected Steps per Second: 22,830.17976
Overall Steps per Second: 10,837.84027

Timestep Collection Time: 2.19008
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.61347

Cumulative Model Updates: 96,634
Cumulative Timesteps: 805,911,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,664.01431
Policy Entropy: 3.61098
Value Function Loss: 0.09069

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.46310
Value Function Update Magnitude: 0.67893

Collected Steps per Second: 22,343.53706
Overall Steps per Second: 10,540.44341

Timestep Collection Time: 2.23886
Timestep Consumption Time: 2.50705
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.74591

Cumulative Model Updates: 96,640
Cumulative Timesteps: 805,961,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 805961322...
Checkpoint 805961322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,283.51001
Policy Entropy: 3.60185
Value Function Loss: 0.09010

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06524
Policy Update Magnitude: 0.61294
Value Function Update Magnitude: 0.68622

Collected Steps per Second: 22,175.39892
Overall Steps per Second: 10,720.05187

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.41008
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.66546

Cumulative Model Updates: 96,646
Cumulative Timesteps: 806,011,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,486.28127
Policy Entropy: 3.59567
Value Function Loss: 0.09065

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.74510
Value Function Update Magnitude: 0.68332

Collected Steps per Second: 22,672.93643
Overall Steps per Second: 10,761.56243

Timestep Collection Time: 2.20642
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.64858

Cumulative Model Updates: 96,652
Cumulative Timesteps: 806,061,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 806061362...
Checkpoint 806061362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,839.18886
Policy Entropy: 3.59939
Value Function Loss: 0.09073

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.61711
Value Function Update Magnitude: 0.63205

Collected Steps per Second: 22,187.56945
Overall Steps per Second: 10,666.20158

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.43546
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.69014

Cumulative Model Updates: 96,658
Cumulative Timesteps: 806,111,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,897.47371
Policy Entropy: 3.59803
Value Function Loss: 0.09299

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.50970
Value Function Update Magnitude: 0.62001

Collected Steps per Second: 22,905.95011
Overall Steps per Second: 10,613.63303

Timestep Collection Time: 2.18319
Timestep Consumption Time: 2.52849
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.71168

Cumulative Model Updates: 96,664
Cumulative Timesteps: 806,161,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 806161396...
Checkpoint 806161396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,926.60002
Policy Entropy: 3.60201
Value Function Loss: 0.09253

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.45283
Value Function Update Magnitude: 0.71395

Collected Steps per Second: 22,526.10352
Overall Steps per Second: 10,556.65389

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.73749

Cumulative Model Updates: 96,670
Cumulative Timesteps: 806,211,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,962.09409
Policy Entropy: 3.60946
Value Function Loss: 0.09156

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.42910
Value Function Update Magnitude: 0.78614

Collected Steps per Second: 23,048.01416
Overall Steps per Second: 10,837.07828

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61527

Cumulative Model Updates: 96,676
Cumulative Timesteps: 806,261,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 806261424...
Checkpoint 806261424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,050.62242
Policy Entropy: 3.59601
Value Function Loss: 0.09117

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.45574
Value Function Update Magnitude: 0.76086

Collected Steps per Second: 22,737.96777
Overall Steps per Second: 10,669.83864

Timestep Collection Time: 2.19940
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.68704

Cumulative Model Updates: 96,682
Cumulative Timesteps: 806,311,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,538.74062
Policy Entropy: 3.59082
Value Function Loss: 0.09361

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.49192
Value Function Update Magnitude: 0.64860

Collected Steps per Second: 23,086.66091
Overall Steps per Second: 10,877.27336

Timestep Collection Time: 2.16697
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.59931

Cumulative Model Updates: 96,688
Cumulative Timesteps: 806,361,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 806361462...
Checkpoint 806361462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,613.41077
Policy Entropy: 3.57778
Value Function Loss: 0.09545

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.50302
Value Function Update Magnitude: 0.59402

Collected Steps per Second: 23,072.51993
Overall Steps per Second: 10,710.96394

Timestep Collection Time: 2.16838
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.67091

Cumulative Model Updates: 96,694
Cumulative Timesteps: 806,411,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,990.92275
Policy Entropy: 3.58632
Value Function Loss: 0.09406

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.46099
Value Function Update Magnitude: 0.59911

Collected Steps per Second: 23,162.15631
Overall Steps per Second: 10,924.70185

Timestep Collection Time: 2.15913
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.57770

Cumulative Model Updates: 96,700
Cumulative Timesteps: 806,461,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 806461502...
Checkpoint 806461502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,116.86134
Policy Entropy: 3.59078
Value Function Loss: 0.09246

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.51246
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 22,306.57239
Overall Steps per Second: 10,582.10957

Timestep Collection Time: 2.24158
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.72514

Cumulative Model Updates: 96,706
Cumulative Timesteps: 806,511,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,839.01888
Policy Entropy: 3.59623
Value Function Loss: 0.09280

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.52873
Value Function Update Magnitude: 0.63274

Collected Steps per Second: 22,283.44913
Overall Steps per Second: 10,572.41569

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.73213

Cumulative Model Updates: 96,712
Cumulative Timesteps: 806,561,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 806561534...
Checkpoint 806561534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,195.81873
Policy Entropy: 3.60316
Value Function Loss: 0.09145

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.79638

Collected Steps per Second: 22,120.25115
Overall Steps per Second: 10,544.47616

Timestep Collection Time: 2.26119
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.74353

Cumulative Model Updates: 96,718
Cumulative Timesteps: 806,611,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,942.75968
Policy Entropy: 3.59814
Value Function Loss: 0.09088

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.50701
Value Function Update Magnitude: 0.79290

Collected Steps per Second: 22,626.93259
Overall Steps per Second: 10,634.43098

Timestep Collection Time: 2.21064
Timestep Consumption Time: 2.49295
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.70359

Cumulative Model Updates: 96,724
Cumulative Timesteps: 806,661,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 806661572...
Checkpoint 806661572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,501.97028
Policy Entropy: 3.58787
Value Function Loss: 0.09154

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.45582
Value Function Update Magnitude: 0.72060

Collected Steps per Second: 22,384.57414
Overall Steps per Second: 10,516.51032

Timestep Collection Time: 2.23502
Timestep Consumption Time: 2.52226
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.75728

Cumulative Model Updates: 96,730
Cumulative Timesteps: 806,711,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,062.30088
Policy Entropy: 3.60263
Value Function Loss: 0.08895

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.52665
Value Function Update Magnitude: 0.75183

Collected Steps per Second: 23,086.33369
Overall Steps per Second: 10,844.57883

Timestep Collection Time: 2.16613
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.61134

Cumulative Model Updates: 96,736
Cumulative Timesteps: 806,761,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 806761610...
Checkpoint 806761610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.56489
Policy Entropy: 3.60566
Value Function Loss: 0.08776

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.51754
Value Function Update Magnitude: 0.69493

Collected Steps per Second: 22,558.46629
Overall Steps per Second: 10,644.86936

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.48193
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69954

Cumulative Model Updates: 96,742
Cumulative Timesteps: 806,811,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,017.90983
Policy Entropy: 3.59987
Value Function Loss: 0.08764

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.54605
Value Function Update Magnitude: 0.72612

Collected Steps per Second: 23,138.01068
Overall Steps per Second: 10,877.56913

Timestep Collection Time: 2.16103
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.59680

Cumulative Model Updates: 96,748
Cumulative Timesteps: 806,861,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 806861638...
Checkpoint 806861638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,200.75174
Policy Entropy: 3.59148
Value Function Loss: 0.08976

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.52918
Value Function Update Magnitude: 0.71554

Collected Steps per Second: 22,660.84160
Overall Steps per Second: 10,638.63896

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.70023

Cumulative Model Updates: 96,754
Cumulative Timesteps: 806,911,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,207.60865
Policy Entropy: 3.58878
Value Function Loss: 0.09244

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.58324
Value Function Update Magnitude: 0.69966

Collected Steps per Second: 23,071.27142
Overall Steps per Second: 10,878.64367

Timestep Collection Time: 2.16737
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.59653

Cumulative Model Updates: 96,760
Cumulative Timesteps: 806,961,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 806961646...
Checkpoint 806961646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,297.60293
Policy Entropy: 3.59118
Value Function Loss: 0.09106

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10614
Policy Update Magnitude: 0.52585
Value Function Update Magnitude: 0.63313

Collected Steps per Second: 22,420.18607
Overall Steps per Second: 10,768.46317

Timestep Collection Time: 2.23111
Timestep Consumption Time: 2.41412
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.64523

Cumulative Model Updates: 96,766
Cumulative Timesteps: 807,011,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,384.84584
Policy Entropy: 3.58884
Value Function Loss: 0.09463

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.48171
Value Function Update Magnitude: 0.59845

Collected Steps per Second: 22,989.17335
Overall Steps per Second: 10,855.31036

Timestep Collection Time: 2.17624
Timestep Consumption Time: 2.43256
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.60880

Cumulative Model Updates: 96,772
Cumulative Timesteps: 807,061,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 807061698...
Checkpoint 807061698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,409.89185
Policy Entropy: 3.59163
Value Function Loss: 0.09264

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.45781
Value Function Update Magnitude: 0.63230

Collected Steps per Second: 22,312.11015
Overall Steps per Second: 10,621.90793

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.46681
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.70819

Cumulative Model Updates: 96,778
Cumulative Timesteps: 807,111,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,324.43549
Policy Entropy: 3.58715
Value Function Loss: 0.09448

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.58318
Value Function Update Magnitude: 0.60704

Collected Steps per Second: 22,902.26568
Overall Steps per Second: 10,839.83171

Timestep Collection Time: 2.18441
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.61520

Cumulative Model Updates: 96,784
Cumulative Timesteps: 807,161,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 807161736...
Checkpoint 807161736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,300.52719
Policy Entropy: 3.59236
Value Function Loss: 0.09211

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.59115
Value Function Update Magnitude: 0.59171

Collected Steps per Second: 22,210.08860
Overall Steps per Second: 10,662.43695

Timestep Collection Time: 2.25123
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.68936

Cumulative Model Updates: 96,790
Cumulative Timesteps: 807,211,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,627.72446
Policy Entropy: 3.58971
Value Function Loss: 0.09369

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.52093
Value Function Update Magnitude: 0.61531

Collected Steps per Second: 22,969.25287
Overall Steps per Second: 10,625.31195

Timestep Collection Time: 2.17743
Timestep Consumption Time: 2.52963
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.70706

Cumulative Model Updates: 96,796
Cumulative Timesteps: 807,261,750

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 807261750...
Checkpoint 807261750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,539.14309
Policy Entropy: 3.60977
Value Function Loss: 0.09003

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.69000

Collected Steps per Second: 22,406.15173
Overall Steps per Second: 10,555.37911

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.73844

Cumulative Model Updates: 96,802
Cumulative Timesteps: 807,311,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,453.79803
Policy Entropy: 3.61448
Value Function Loss: 0.09221

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.62907
Value Function Update Magnitude: 0.66333

Collected Steps per Second: 23,117.45274
Overall Steps per Second: 10,910.77081

Timestep Collection Time: 2.16373
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.58446

Cumulative Model Updates: 96,808
Cumulative Timesteps: 807,361,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 807361786...
Checkpoint 807361786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,411.03818
Policy Entropy: 3.61197
Value Function Loss: 0.09272

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.59669
Value Function Update Magnitude: 0.68927

Collected Steps per Second: 22,528.50917
Overall Steps per Second: 10,609.07759

Timestep Collection Time: 2.22003
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.71426

Cumulative Model Updates: 96,814
Cumulative Timesteps: 807,411,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,936.95511
Policy Entropy: 3.58615
Value Function Loss: 0.09647

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.54070
Value Function Update Magnitude: 0.75138

Collected Steps per Second: 23,078.34736
Overall Steps per Second: 10,874.63401

Timestep Collection Time: 2.16844
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.60190

Cumulative Model Updates: 96,820
Cumulative Timesteps: 807,461,844

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 807461844...
Checkpoint 807461844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,179.77373
Policy Entropy: 3.58417
Value Function Loss: 0.09450

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.52010
Value Function Update Magnitude: 0.75031

Collected Steps per Second: 22,742.43441
Overall Steps per Second: 10,679.71138

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.68346

Cumulative Model Updates: 96,826
Cumulative Timesteps: 807,511,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,305.31888
Policy Entropy: 3.57444
Value Function Loss: 0.09592

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06647
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.67166

Collected Steps per Second: 22,615.90482
Overall Steps per Second: 10,683.07802

Timestep Collection Time: 2.21189
Timestep Consumption Time: 2.47065
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.68255

Cumulative Model Updates: 96,832
Cumulative Timesteps: 807,561,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 807561886...
Checkpoint 807561886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,084.37625
Policy Entropy: 3.56378
Value Function Loss: 0.09263

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.63791
Value Function Update Magnitude: 0.64946

Collected Steps per Second: 21,901.85181
Overall Steps per Second: 10,477.58858

Timestep Collection Time: 2.28410
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.77457

Cumulative Model Updates: 96,838
Cumulative Timesteps: 807,611,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,225.14670
Policy Entropy: 3.55707
Value Function Loss: 0.09398

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.52709
Value Function Update Magnitude: 0.60105

Collected Steps per Second: 22,745.92957
Overall Steps per Second: 10,810.73490

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.62836

Cumulative Model Updates: 96,844
Cumulative Timesteps: 807,661,948

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 807661948...
Checkpoint 807661948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,062.37336
Policy Entropy: 3.55704
Value Function Loss: 0.09518

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.45387
Value Function Update Magnitude: 0.54226

Collected Steps per Second: 22,442.39845
Overall Steps per Second: 10,681.34799

Timestep Collection Time: 2.22810
Timestep Consumption Time: 2.45333
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.68143

Cumulative Model Updates: 96,850
Cumulative Timesteps: 807,711,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,781.16556
Policy Entropy: 3.57595
Value Function Loss: 0.09234

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.40696
Value Function Update Magnitude: 0.58367

Collected Steps per Second: 22,407.29091
Overall Steps per Second: 10,559.48529

Timestep Collection Time: 2.23195
Timestep Consumption Time: 2.50426
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.73622

Cumulative Model Updates: 96,856
Cumulative Timesteps: 807,761,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 807761964...
Checkpoint 807761964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,989.84249
Policy Entropy: 3.57696
Value Function Loss: 0.09262

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.39782
Value Function Update Magnitude: 0.56061

Collected Steps per Second: 22,571.22528
Overall Steps per Second: 10,592.60363

Timestep Collection Time: 2.21601
Timestep Consumption Time: 2.50597
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.72197

Cumulative Model Updates: 96,862
Cumulative Timesteps: 807,811,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,679.65885
Policy Entropy: 3.58152
Value Function Loss: 0.09087

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.43733
Value Function Update Magnitude: 0.55051

Collected Steps per Second: 23,112.96030
Overall Steps per Second: 10,816.25836

Timestep Collection Time: 2.16398
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.62415

Cumulative Model Updates: 96,868
Cumulative Timesteps: 807,861,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 807861998...
Checkpoint 807861998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.06071
Policy Entropy: 3.58003
Value Function Loss: 0.09431

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.43747
Value Function Update Magnitude: 0.52841

Collected Steps per Second: 22,863.84037
Overall Steps per Second: 10,679.80930

Timestep Collection Time: 2.18896
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68623

Cumulative Model Updates: 96,874
Cumulative Timesteps: 807,912,046

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,081.37440
Policy Entropy: 3.57964
Value Function Loss: 0.09426

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.42593
Value Function Update Magnitude: 0.56763

Collected Steps per Second: 22,388.05636
Overall Steps per Second: 10,897.70190

Timestep Collection Time: 2.23476
Timestep Consumption Time: 2.35630
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59106

Cumulative Model Updates: 96,880
Cumulative Timesteps: 807,962,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 807962078...
Checkpoint 807962078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,617.08239
Policy Entropy: 3.59288
Value Function Loss: 0.09022

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.47554
Value Function Update Magnitude: 0.73620

Collected Steps per Second: 21,948.01416
Overall Steps per Second: 10,689.46836

Timestep Collection Time: 2.27911
Timestep Consumption Time: 2.40045
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.67956

Cumulative Model Updates: 96,886
Cumulative Timesteps: 808,012,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,287.07490
Policy Entropy: 3.58201
Value Function Loss: 0.08655

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.48290
Value Function Update Magnitude: 0.74785

Collected Steps per Second: 22,383.93470
Overall Steps per Second: 10,882.99753

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.36114
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59543

Cumulative Model Updates: 96,892
Cumulative Timesteps: 808,062,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 808062112...
Checkpoint 808062112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,654.90026
Policy Entropy: 3.59182
Value Function Loss: 0.08538

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.52354
Value Function Update Magnitude: 0.68862

Collected Steps per Second: 20,595.67966
Overall Steps per Second: 10,290.03639

Timestep Collection Time: 2.42876
Timestep Consumption Time: 2.43245
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.86121

Cumulative Model Updates: 96,898
Cumulative Timesteps: 808,112,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,646.30316
Policy Entropy: 3.58770
Value Function Loss: 0.08984

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.49682
Value Function Update Magnitude: 0.65316

Collected Steps per Second: 22,014.53408
Overall Steps per Second: 10,830.73608

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.34620
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61834

Cumulative Model Updates: 96,904
Cumulative Timesteps: 808,162,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 808162154...
Checkpoint 808162154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,333.34216
Policy Entropy: 3.58109
Value Function Loss: 0.09335

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.51911
Value Function Update Magnitude: 0.62568

Collected Steps per Second: 21,984.26008
Overall Steps per Second: 10,710.41630

Timestep Collection Time: 2.27563
Timestep Consumption Time: 2.39534
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.67097

Cumulative Model Updates: 96,910
Cumulative Timesteps: 808,212,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,862.28727
Policy Entropy: 3.58649
Value Function Loss: 0.09600

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.50365
Value Function Update Magnitude: 0.63981

Collected Steps per Second: 22,767.81765
Overall Steps per Second: 10,775.77848

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.44454
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.64115

Cumulative Model Updates: 96,916
Cumulative Timesteps: 808,262,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 808262194...
Checkpoint 808262194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,235.65262
Policy Entropy: 3.59339
Value Function Loss: 0.09361

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.52531
Value Function Update Magnitude: 0.64742

Collected Steps per Second: 22,831.11590
Overall Steps per Second: 10,681.28922

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68164

Cumulative Model Updates: 96,922
Cumulative Timesteps: 808,312,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,685.64984
Policy Entropy: 3.59476
Value Function Loss: 0.09123

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.70745

Collected Steps per Second: 23,114.71982
Overall Steps per Second: 10,941.12459

Timestep Collection Time: 2.16425
Timestep Consumption Time: 2.40804
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.57229

Cumulative Model Updates: 96,928
Cumulative Timesteps: 808,362,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 808362226...
Checkpoint 808362226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,534.49181
Policy Entropy: 3.58231
Value Function Loss: 0.09202

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.54789
Value Function Update Magnitude: 0.68906

Collected Steps per Second: 22,649.18904
Overall Steps per Second: 10,619.16522

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.50208
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71073

Cumulative Model Updates: 96,934
Cumulative Timesteps: 808,412,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,401.43827
Policy Entropy: 3.58233
Value Function Loss: 0.09309

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.45881
Value Function Update Magnitude: 0.70644

Collected Steps per Second: 23,044.35845
Overall Steps per Second: 10,860.09060

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.43467
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60475

Cumulative Model Updates: 96,940
Cumulative Timesteps: 808,462,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 808462258...
Checkpoint 808462258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,119.93044
Policy Entropy: 3.58822
Value Function Loss: 0.09367

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.42506
Value Function Update Magnitude: 0.65321

Collected Steps per Second: 22,684.80514
Overall Steps per Second: 10,710.91613

Timestep Collection Time: 2.20526
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.67056

Cumulative Model Updates: 96,946
Cumulative Timesteps: 808,512,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,741.84334
Policy Entropy: 3.59001
Value Function Loss: 0.08863

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.49379
Value Function Update Magnitude: 0.65861

Collected Steps per Second: 22,581.16132
Overall Steps per Second: 10,835.70458

Timestep Collection Time: 2.21424
Timestep Consumption Time: 2.40014
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61437

Cumulative Model Updates: 96,952
Cumulative Timesteps: 808,562,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 808562284...
Checkpoint 808562284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,049.51388
Policy Entropy: 3.60222
Value Function Loss: 0.08468

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.48964
Value Function Update Magnitude: 0.79543

Collected Steps per Second: 21,859.51554
Overall Steps per Second: 10,631.06829

Timestep Collection Time: 2.28733
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.70320

Cumulative Model Updates: 96,958
Cumulative Timesteps: 808,612,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.91818
Policy Entropy: 3.61153
Value Function Loss: 0.08409

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.46229
Value Function Update Magnitude: 0.88215

Collected Steps per Second: 22,352.53379
Overall Steps per Second: 10,506.09203

Timestep Collection Time: 2.23751
Timestep Consumption Time: 2.52297
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.76048

Cumulative Model Updates: 96,964
Cumulative Timesteps: 808,662,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 808662298...
Checkpoint 808662298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,934.68890
Policy Entropy: 3.62310
Value Function Loss: 0.08208

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.47505
Value Function Update Magnitude: 0.90151

Collected Steps per Second: 21,861.56751
Overall Steps per Second: 10,401.69675

Timestep Collection Time: 2.28776
Timestep Consumption Time: 2.52049
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.80825

Cumulative Model Updates: 96,970
Cumulative Timesteps: 808,712,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,352.06434
Policy Entropy: 3.61170
Value Function Loss: 0.08365

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.50721
Value Function Update Magnitude: 0.78754

Collected Steps per Second: 23,175.32199
Overall Steps per Second: 10,912.26058

Timestep Collection Time: 2.15928
Timestep Consumption Time: 2.42657
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.58585

Cumulative Model Updates: 96,976
Cumulative Timesteps: 808,762,354

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 808762354...
Checkpoint 808762354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,437.97405
Policy Entropy: 3.62167
Value Function Loss: 0.08095

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.48684
Value Function Update Magnitude: 0.74156

Collected Steps per Second: 22,639.07706
Overall Steps per Second: 10,615.92425

Timestep Collection Time: 2.20857
Timestep Consumption Time: 2.50133
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.70991

Cumulative Model Updates: 96,982
Cumulative Timesteps: 808,812,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.05034
Policy Entropy: 3.62080
Value Function Loss: 0.07605

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.47243
Value Function Update Magnitude: 0.80448

Collected Steps per Second: 23,040.45882
Overall Steps per Second: 10,835.86146

Timestep Collection Time: 2.17070
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.61560

Cumulative Model Updates: 96,988
Cumulative Timesteps: 808,862,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 808862368...
Checkpoint 808862368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.30952
Policy Entropy: 3.62989
Value Function Loss: 0.06904

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.51221
Value Function Update Magnitude: 0.79742

Collected Steps per Second: 22,426.86252
Overall Steps per Second: 10,736.99367

Timestep Collection Time: 2.23045
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.65885

Cumulative Model Updates: 96,994
Cumulative Timesteps: 808,912,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,358.60884
Policy Entropy: 3.64041
Value Function Loss: 0.06332

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.53017
Value Function Update Magnitude: 0.84403

Collected Steps per Second: 23,214.50852
Overall Steps per Second: 10,921.86961

Timestep Collection Time: 2.15434
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.57907

Cumulative Model Updates: 97,000
Cumulative Timesteps: 808,962,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 808962402...
Checkpoint 808962402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,146.80969
Policy Entropy: 3.64604
Value Function Loss: 0.06188

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.59811
Value Function Update Magnitude: 0.88099

Collected Steps per Second: 22,697.92925
Overall Steps per Second: 10,621.00209

Timestep Collection Time: 2.20399
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.71010

Cumulative Model Updates: 97,006
Cumulative Timesteps: 809,012,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,205.20757
Policy Entropy: 3.64754
Value Function Loss: 0.05986

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.61715
Value Function Update Magnitude: 0.88327

Collected Steps per Second: 22,415.34908
Overall Steps per Second: 10,602.69854

Timestep Collection Time: 2.23177
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.71823

Cumulative Model Updates: 97,012
Cumulative Timesteps: 809,062,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 809062454...
Checkpoint 809062454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,015.00412
Policy Entropy: 3.64571
Value Function Loss: 0.05981

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.62128
Value Function Update Magnitude: 0.86858

Collected Steps per Second: 22,341.80924
Overall Steps per Second: 10,578.77472

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.73136

Cumulative Model Updates: 97,018
Cumulative Timesteps: 809,112,506

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,538.13794
Policy Entropy: 3.65549
Value Function Loss: 0.06392

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.58689
Value Function Update Magnitude: 0.87103

Collected Steps per Second: 22,431.34517
Overall Steps per Second: 10,738.81478

Timestep Collection Time: 2.22902
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.65601

Cumulative Model Updates: 97,024
Cumulative Timesteps: 809,162,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 809162506...
Checkpoint 809162506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,261.03158
Policy Entropy: 3.66903
Value Function Loss: 0.06567

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.60973
Value Function Update Magnitude: 0.88759

Collected Steps per Second: 22,335.87173
Overall Steps per Second: 10,751.70638

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.41293
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.65247

Cumulative Model Updates: 97,030
Cumulative Timesteps: 809,212,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.82133
Policy Entropy: 3.65994
Value Function Loss: 0.06791

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.57351
Value Function Update Magnitude: 0.90121

Collected Steps per Second: 23,019.28935
Overall Steps per Second: 10,777.12070

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.46786
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.64039

Cumulative Model Updates: 97,036
Cumulative Timesteps: 809,262,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 809262538...
Checkpoint 809262538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,974.11284
Policy Entropy: 3.67410
Value Function Loss: 0.06782

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.60006
Value Function Update Magnitude: 0.91404

Collected Steps per Second: 22,871.14351
Overall Steps per Second: 10,689.01482

Timestep Collection Time: 2.18651
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.67845

Cumulative Model Updates: 97,042
Cumulative Timesteps: 809,312,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,879.89004
Policy Entropy: 3.66390
Value Function Loss: 0.07035

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.62781
Value Function Update Magnitude: 0.93722

Collected Steps per Second: 22,894.81750
Overall Steps per Second: 10,848.64699

Timestep Collection Time: 2.18460
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61034

Cumulative Model Updates: 97,048
Cumulative Timesteps: 809,362,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 809362562...
Checkpoint 809362562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,661.64963
Policy Entropy: 3.65787
Value Function Loss: 0.07160

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.61953
Value Function Update Magnitude: 0.93099

Collected Steps per Second: 22,434.05356
Overall Steps per Second: 10,761.81000

Timestep Collection Time: 2.23000
Timestep Consumption Time: 2.41866
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.64866

Cumulative Model Updates: 97,054
Cumulative Timesteps: 809,412,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,629.09408
Policy Entropy: 3.64751
Value Function Loss: 0.07369

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.61067
Value Function Update Magnitude: 0.93447

Collected Steps per Second: 23,016.11846
Overall Steps per Second: 10,816.16546

Timestep Collection Time: 2.17291
Timestep Consumption Time: 2.45091
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.62382

Cumulative Model Updates: 97,060
Cumulative Timesteps: 809,462,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 809462602...
Checkpoint 809462602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,499.54855
Policy Entropy: 3.64922
Value Function Loss: 0.07413

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.95760

Collected Steps per Second: 22,729.30382
Overall Steps per Second: 10,685.54679

Timestep Collection Time: 2.19989
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.67940

Cumulative Model Updates: 97,066
Cumulative Timesteps: 809,512,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.26707
Policy Entropy: 3.63738
Value Function Loss: 0.07562

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.58344
Value Function Update Magnitude: 0.96098

Collected Steps per Second: 22,815.70274
Overall Steps per Second: 10,837.18101

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.61578

Cumulative Model Updates: 97,072
Cumulative Timesteps: 809,562,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 809562626...
Checkpoint 809562626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.27085
Policy Entropy: 3.63429
Value Function Loss: 0.07449

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.56564
Value Function Update Magnitude: 0.97703

Collected Steps per Second: 22,319.79291
Overall Steps per Second: 10,681.77530

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.68218

Cumulative Model Updates: 97,078
Cumulative Timesteps: 809,612,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,343.33060
Policy Entropy: 3.63369
Value Function Loss: 0.07576

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.54878
Value Function Update Magnitude: 0.91040

Collected Steps per Second: 22,678.03498
Overall Steps per Second: 10,629.20837

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.49994
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.70534

Cumulative Model Updates: 97,084
Cumulative Timesteps: 809,662,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 809662654...
Checkpoint 809662654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,532.33796
Policy Entropy: 3.62035
Value Function Loss: 0.07646

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.59817
Value Function Update Magnitude: 0.89903

Collected Steps per Second: 22,389.41525
Overall Steps per Second: 10,497.47055

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.53269
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.76839

Cumulative Model Updates: 97,090
Cumulative Timesteps: 809,712,710

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,319.66129
Policy Entropy: 3.62807
Value Function Loss: 0.07869

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.16951
Policy Update Magnitude: 0.51817
Value Function Update Magnitude: 0.87260

Collected Steps per Second: 23,124.22815
Overall Steps per Second: 10,883.98027

Timestep Collection Time: 2.16249
Timestep Consumption Time: 2.43197
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.59446

Cumulative Model Updates: 97,096
Cumulative Timesteps: 809,762,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 809762716...
Checkpoint 809762716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,296.71527
Policy Entropy: 3.64116
Value Function Loss: 0.07577

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.44558
Value Function Update Magnitude: 0.87907

Collected Steps per Second: 22,952.86555
Overall Steps per Second: 10,654.69236

Timestep Collection Time: 2.17951
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.69521

Cumulative Model Updates: 97,102
Cumulative Timesteps: 809,812,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,763.81029
Policy Entropy: 3.65714
Value Function Loss: 0.07612

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.50669
Value Function Update Magnitude: 0.87986

Collected Steps per Second: 22,677.49768
Overall Steps per Second: 10,662.43036

Timestep Collection Time: 2.20483
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.68936

Cumulative Model Updates: 97,108
Cumulative Timesteps: 809,862,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 809862742...
Checkpoint 809862742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,426.94192
Policy Entropy: 3.65863
Value Function Loss: 0.07925

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.57061
Value Function Update Magnitude: 0.89199

Collected Steps per Second: 22,929.66415
Overall Steps per Second: 10,864.76646

Timestep Collection Time: 2.18119
Timestep Consumption Time: 2.42213
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60332

Cumulative Model Updates: 97,114
Cumulative Timesteps: 809,912,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,018.06992
Policy Entropy: 3.65652
Value Function Loss: 0.07776

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.48968
Value Function Update Magnitude: 0.96351

Collected Steps per Second: 22,854.76824
Overall Steps per Second: 10,710.14083

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.67090

Cumulative Model Updates: 97,120
Cumulative Timesteps: 809,962,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 809962782...
Checkpoint 809962782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,955.32663
Policy Entropy: 3.66002
Value Function Loss: 0.07546

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.47526
Value Function Update Magnitude: 0.98335

Collected Steps per Second: 22,136.97747
Overall Steps per Second: 10,427.62391

Timestep Collection Time: 2.25912
Timestep Consumption Time: 2.53680
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.79592

Cumulative Model Updates: 97,126
Cumulative Timesteps: 810,012,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,258.03854
Policy Entropy: 3.66396
Value Function Loss: 0.07441

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.53136
Value Function Update Magnitude: 0.91783

Collected Steps per Second: 22,322.08305
Overall Steps per Second: 10,576.56779

Timestep Collection Time: 2.24074
Timestep Consumption Time: 2.48839
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.72913

Cumulative Model Updates: 97,132
Cumulative Timesteps: 810,062,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 810062810...
Checkpoint 810062810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,135.38266
Policy Entropy: 3.66895
Value Function Loss: 0.07020

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.89739

Collected Steps per Second: 22,370.32175
Overall Steps per Second: 10,570.33938

Timestep Collection Time: 2.23519
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.73041

Cumulative Model Updates: 97,138
Cumulative Timesteps: 810,112,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.50379
Policy Entropy: 3.68024
Value Function Loss: 0.06813

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.92157

Collected Steps per Second: 22,887.01160
Overall Steps per Second: 10,852.42139

Timestep Collection Time: 2.18587
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.60985

Cumulative Model Updates: 97,144
Cumulative Timesteps: 810,162,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 810162840...
Checkpoint 810162840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.04734
Policy Entropy: 3.67602
Value Function Loss: 0.06553

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.61183
Value Function Update Magnitude: 0.90674

Collected Steps per Second: 22,325.03971
Overall Steps per Second: 10,644.89431

Timestep Collection Time: 2.24071
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.69934

Cumulative Model Updates: 97,150
Cumulative Timesteps: 810,212,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,930.16822
Policy Entropy: 3.66971
Value Function Loss: 0.06507

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.58689
Value Function Update Magnitude: 0.92868

Collected Steps per Second: 22,529.53201
Overall Steps per Second: 10,622.51298

Timestep Collection Time: 2.22029
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.70906

Cumulative Model Updates: 97,156
Cumulative Timesteps: 810,262,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 810262886...
Checkpoint 810262886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,513.36776
Policy Entropy: 3.66458
Value Function Loss: 0.06713

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.53677
Value Function Update Magnitude: 0.91215

Collected Steps per Second: 23,198.90697
Overall Steps per Second: 10,879.79153

Timestep Collection Time: 2.15562
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59641

Cumulative Model Updates: 97,162
Cumulative Timesteps: 810,312,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,008.80214
Policy Entropy: 3.66292
Value Function Loss: 0.06991

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.85580

Collected Steps per Second: 22,997.61477
Overall Steps per Second: 10,872.68394

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.42571
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60089

Cumulative Model Updates: 97,168
Cumulative Timesteps: 810,362,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 810362918...
Checkpoint 810362918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,473.94757
Policy Entropy: 3.66119
Value Function Loss: 0.07223

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.55145
Value Function Update Magnitude: 0.80461

Collected Steps per Second: 22,100.67772
Overall Steps per Second: 10,695.75497

Timestep Collection Time: 2.26346
Timestep Consumption Time: 2.41354
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.67700

Cumulative Model Updates: 97,174
Cumulative Timesteps: 810,412,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,169.58623
Policy Entropy: 3.66214
Value Function Loss: 0.07349

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.74566

Collected Steps per Second: 22,255.37248
Overall Steps per Second: 10,844.45113

Timestep Collection Time: 2.24701
Timestep Consumption Time: 2.36438
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.61139

Cumulative Model Updates: 97,180
Cumulative Timesteps: 810,462,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 810462950...
Checkpoint 810462950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,712.70871
Policy Entropy: 3.66578
Value Function Loss: 0.07376

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.58626
Value Function Update Magnitude: 0.77048

Collected Steps per Second: 22,055.02346
Overall Steps per Second: 10,720.54772

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.39803
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.66618

Cumulative Model Updates: 97,186
Cumulative Timesteps: 810,512,974

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,128.03582
Policy Entropy: 3.68281
Value Function Loss: 0.06877

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.62525
Value Function Update Magnitude: 0.87652

Collected Steps per Second: 22,339.28786
Overall Steps per Second: 10,896.49560

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.35202
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.59175

Cumulative Model Updates: 97,192
Cumulative Timesteps: 810,563,008

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 810563008...
Checkpoint 810563008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.87931
Policy Entropy: 3.67470
Value Function Loss: 0.07124

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.60997
Value Function Update Magnitude: 0.87577

Collected Steps per Second: 21,491.85090
Overall Steps per Second: 10,670.79656

Timestep Collection Time: 2.32711
Timestep Consumption Time: 2.35988
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.68700

Cumulative Model Updates: 97,198
Cumulative Timesteps: 810,613,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,108.35654
Policy Entropy: 3.65059
Value Function Loss: 0.07438

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.64428
Value Function Update Magnitude: 0.87076

Collected Steps per Second: 21,727.35891
Overall Steps per Second: 10,622.89123

Timestep Collection Time: 2.30235
Timestep Consumption Time: 2.40673
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.70908

Cumulative Model Updates: 97,204
Cumulative Timesteps: 810,663,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 810663046...
Checkpoint 810663046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.10736
Policy Entropy: 3.64795
Value Function Loss: 0.07714

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.59478
Value Function Update Magnitude: 0.87289

Collected Steps per Second: 21,962.26653
Overall Steps per Second: 10,820.17521

Timestep Collection Time: 2.27809
Timestep Consumption Time: 2.34587
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62395

Cumulative Model Updates: 97,210
Cumulative Timesteps: 810,713,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.03350
Policy Entropy: 3.63794
Value Function Loss: 0.07821

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.62031
Value Function Update Magnitude: 0.84844

Collected Steps per Second: 22,132.82296
Overall Steps per Second: 10,539.91640

Timestep Collection Time: 2.25918
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.74406

Cumulative Model Updates: 97,216
Cumulative Timesteps: 810,763,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 810763080...
Checkpoint 810763080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,737.30443
Policy Entropy: 3.64861
Value Function Loss: 0.07955

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.61362
Value Function Update Magnitude: 0.80286

Collected Steps per Second: 22,741.79938
Overall Steps per Second: 10,649.97939

Timestep Collection Time: 2.19956
Timestep Consumption Time: 2.49735
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.69691

Cumulative Model Updates: 97,222
Cumulative Timesteps: 810,813,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,644.13764
Policy Entropy: 3.65125
Value Function Loss: 0.08021

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.79411

Collected Steps per Second: 22,913.19098
Overall Steps per Second: 10,869.06048

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.41903
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.60205

Cumulative Model Updates: 97,228
Cumulative Timesteps: 810,863,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 810863122...
Checkpoint 810863122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,056.24976
Policy Entropy: 3.65811
Value Function Loss: 0.07946

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.58955
Value Function Update Magnitude: 0.79677

Collected Steps per Second: 22,996.47466
Overall Steps per Second: 10,776.42181

Timestep Collection Time: 2.17599
Timestep Consumption Time: 2.46749
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.64347

Cumulative Model Updates: 97,234
Cumulative Timesteps: 810,913,162

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,150.27162
Policy Entropy: 3.65471
Value Function Loss: 0.08057

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.60071
Value Function Update Magnitude: 0.86301

Collected Steps per Second: 23,065.98290
Overall Steps per Second: 10,802.18290

Timestep Collection Time: 2.16865
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.63073

Cumulative Model Updates: 97,240
Cumulative Timesteps: 810,963,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 810963184...
Checkpoint 810963184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,566.28027
Policy Entropy: 3.66139
Value Function Loss: 0.08385

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.51023
Value Function Update Magnitude: 0.85210

Collected Steps per Second: 22,975.35223
Overall Steps per Second: 10,713.04300

Timestep Collection Time: 2.17625
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.66721

Cumulative Model Updates: 97,246
Cumulative Timesteps: 811,013,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,389.63396
Policy Entropy: 3.66119
Value Function Loss: 0.08470

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.51771
Value Function Update Magnitude: 0.78727

Collected Steps per Second: 22,922.35516
Overall Steps per Second: 10,839.09759

Timestep Collection Time: 2.18259
Timestep Consumption Time: 2.43311
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.61570

Cumulative Model Updates: 97,252
Cumulative Timesteps: 811,063,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 811063214...
Checkpoint 811063214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,794.90962
Policy Entropy: 3.65281
Value Function Loss: 0.08412

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.57579
Value Function Update Magnitude: 0.76284

Collected Steps per Second: 22,371.36265
Overall Steps per Second: 10,637.76216

Timestep Collection Time: 2.23509
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.70042

Cumulative Model Updates: 97,258
Cumulative Timesteps: 811,113,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,620.09014
Policy Entropy: 3.65802
Value Function Loss: 0.08060

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.77350

Collected Steps per Second: 22,855.21259
Overall Steps per Second: 10,837.03636

Timestep Collection Time: 2.18830
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61510

Cumulative Model Updates: 97,264
Cumulative Timesteps: 811,163,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 811163230...
Checkpoint 811163230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,305.17100
Policy Entropy: 3.67473
Value Function Loss: 0.07609

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.67022
Value Function Update Magnitude: 0.79757

Collected Steps per Second: 22,380.08903
Overall Steps per Second: 10,719.59224

Timestep Collection Time: 2.23422
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.66454

Cumulative Model Updates: 97,270
Cumulative Timesteps: 811,213,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,258.89277
Policy Entropy: 3.68035
Value Function Loss: 0.07723

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.74790
Value Function Update Magnitude: 0.77675

Collected Steps per Second: 22,821.66463
Overall Steps per Second: 10,639.52032

Timestep Collection Time: 2.19125
Timestep Consumption Time: 2.50896
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.70021

Cumulative Model Updates: 97,276
Cumulative Timesteps: 811,263,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 811263240...
Checkpoint 811263240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,214.80020
Policy Entropy: 3.67068
Value Function Loss: 0.07957

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.73440
Value Function Update Magnitude: 0.76724

Collected Steps per Second: 22,428.99607
Overall Steps per Second: 10,606.36975

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.71641

Cumulative Model Updates: 97,282
Cumulative Timesteps: 811,313,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,969.70868
Policy Entropy: 3.65655
Value Function Loss: 0.08048

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.74388
Value Function Update Magnitude: 0.80045

Collected Steps per Second: 23,108.87213
Overall Steps per Second: 10,736.19388

Timestep Collection Time: 2.16376
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.65733

Cumulative Model Updates: 97,288
Cumulative Timesteps: 811,363,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 811363266...
Checkpoint 811363266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.65169
Policy Entropy: 3.66006
Value Function Loss: 0.07626

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.64941
Value Function Update Magnitude: 0.80867

Collected Steps per Second: 22,663.99896
Overall Steps per Second: 10,605.57966

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.50836
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.71450

Cumulative Model Updates: 97,294
Cumulative Timesteps: 811,413,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.39482
Policy Entropy: 3.67351
Value Function Loss: 0.07235

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.64504
Value Function Update Magnitude: 0.88074

Collected Steps per Second: 23,104.91703
Overall Steps per Second: 10,826.99779

Timestep Collection Time: 2.16456
Timestep Consumption Time: 2.45463
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61919

Cumulative Model Updates: 97,300
Cumulative Timesteps: 811,463,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 811463278...
Checkpoint 811463278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,221.20882
Policy Entropy: 3.68080
Value Function Loss: 0.07123

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.68586
Value Function Update Magnitude: 0.92250

Collected Steps per Second: 23,003.46735
Overall Steps per Second: 10,707.80702

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.67136

Cumulative Model Updates: 97,306
Cumulative Timesteps: 811,513,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,168.47214
Policy Entropy: 3.68332
Value Function Loss: 0.07209

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.66984
Value Function Update Magnitude: 0.91894

Collected Steps per Second: 23,003.01083
Overall Steps per Second: 10,853.69254

Timestep Collection Time: 2.17458
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60875

Cumulative Model Updates: 97,312
Cumulative Timesteps: 811,563,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 811563320...
Checkpoint 811563320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,118.96230
Policy Entropy: 3.67898
Value Function Loss: 0.07208

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.69416
Value Function Update Magnitude: 0.92000

Collected Steps per Second: 22,794.37112
Overall Steps per Second: 10,707.54200

Timestep Collection Time: 2.19396
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.67054

Cumulative Model Updates: 97,318
Cumulative Timesteps: 811,613,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,306.71304
Policy Entropy: 3.67797
Value Function Loss: 0.07225

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.78051
Value Function Update Magnitude: 0.93358

Collected Steps per Second: 22,631.19140
Overall Steps per Second: 10,629.46623

Timestep Collection Time: 2.20987
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.70503

Cumulative Model Updates: 97,324
Cumulative Timesteps: 811,663,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 811663342...
Checkpoint 811663342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,552.58764
Policy Entropy: 3.67178
Value Function Loss: 0.07293

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.82859
Value Function Update Magnitude: 0.94843

Collected Steps per Second: 22,511.82514
Overall Steps per Second: 10,611.13232

Timestep Collection Time: 2.22185
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.71373

Cumulative Model Updates: 97,330
Cumulative Timesteps: 811,713,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,107.81605
Policy Entropy: 3.68160
Value Function Loss: 0.07323

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.80822
Value Function Update Magnitude: 0.96328

Collected Steps per Second: 22,779.83393
Overall Steps per Second: 10,798.64755

Timestep Collection Time: 2.19536
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.63114

Cumulative Model Updates: 97,336
Cumulative Timesteps: 811,763,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 811763370...
Checkpoint 811763370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.65619
Policy Entropy: 3.66951
Value Function Loss: 0.07585

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.72291
Value Function Update Magnitude: 0.94628

Collected Steps per Second: 22,493.95978
Overall Steps per Second: 10,608.98307

Timestep Collection Time: 2.22389
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.71525

Cumulative Model Updates: 97,342
Cumulative Timesteps: 811,813,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,035.39895
Policy Entropy: 3.66073
Value Function Loss: 0.07546

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.70121
Value Function Update Magnitude: 0.96926

Collected Steps per Second: 23,054.90062
Overall Steps per Second: 10,663.30171

Timestep Collection Time: 2.16960
Timestep Consumption Time: 2.52125
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.69085

Cumulative Model Updates: 97,348
Cumulative Timesteps: 811,863,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 811863414...
Checkpoint 811863414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,210.16908
Policy Entropy: 3.65855
Value Function Loss: 0.07693

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.65057
Value Function Update Magnitude: 0.98106

Collected Steps per Second: 22,852.30519
Overall Steps per Second: 10,804.12831

Timestep Collection Time: 2.18901
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.63008

Cumulative Model Updates: 97,354
Cumulative Timesteps: 811,913,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,549.78192
Policy Entropy: 3.66087
Value Function Loss: 0.07699

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.62507
Value Function Update Magnitude: 0.97591

Collected Steps per Second: 23,087.97594
Overall Steps per Second: 10,766.24551

Timestep Collection Time: 2.16693
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.64693

Cumulative Model Updates: 97,360
Cumulative Timesteps: 811,963,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 811963468...
Checkpoint 811963468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,970.24028
Policy Entropy: 3.66211
Value Function Loss: 0.07638

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11217
Policy Update Magnitude: 0.59726
Value Function Update Magnitude: 0.97285

Collected Steps per Second: 23,011.62477
Overall Steps per Second: 10,888.00799

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.42055
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.59441

Cumulative Model Updates: 97,366
Cumulative Timesteps: 812,013,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,098.31718
Policy Entropy: 3.66312
Value Function Loss: 0.07711

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.57707
Value Function Update Magnitude: 0.95601

Collected Steps per Second: 23,209.81658
Overall Steps per Second: 10,869.06999

Timestep Collection Time: 2.15538
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60260

Cumulative Model Updates: 97,372
Cumulative Timesteps: 812,063,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 812063518...
Checkpoint 812063518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,045.40993
Policy Entropy: 3.66658
Value Function Loss: 0.07809

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.54321
Value Function Update Magnitude: 0.94601

Collected Steps per Second: 22,724.16918
Overall Steps per Second: 10,681.46810

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.68157

Cumulative Model Updates: 97,378
Cumulative Timesteps: 812,113,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,964.85713
Policy Entropy: 3.66885
Value Function Loss: 0.07737

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.52231
Value Function Update Magnitude: 0.93842

Collected Steps per Second: 22,461.05902
Overall Steps per Second: 10,586.78961

Timestep Collection Time: 2.22688
Timestep Consumption Time: 2.49769
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.72457

Cumulative Model Updates: 97,384
Cumulative Timesteps: 812,163,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 812163542...
Checkpoint 812163542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,208.57707
Policy Entropy: 3.66321
Value Function Loss: 0.07650

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.57727
Value Function Update Magnitude: 0.89699

Collected Steps per Second: 22,629.13648
Overall Steps per Second: 10,657.96480

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.48387
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.69527

Cumulative Model Updates: 97,390
Cumulative Timesteps: 812,213,584

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,001.44103
Policy Entropy: 3.68311
Value Function Loss: 0.07860

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.57238
Value Function Update Magnitude: 0.81438

Collected Steps per Second: 22,615.98455
Overall Steps per Second: 10,770.69330

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.43315
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.64557

Cumulative Model Updates: 97,396
Cumulative Timesteps: 812,263,620

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 812263620...
Checkpoint 812263620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.59087
Policy Entropy: 3.67924
Value Function Loss: 0.08252

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.58665
Value Function Update Magnitude: 0.79586

Collected Steps per Second: 22,598.37674
Overall Steps per Second: 10,613.79904

Timestep Collection Time: 2.21264
Timestep Consumption Time: 2.49840
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.71104

Cumulative Model Updates: 97,402
Cumulative Timesteps: 812,313,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,926.70122
Policy Entropy: 3.67307
Value Function Loss: 0.08715

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.60287
Value Function Update Magnitude: 0.82629

Collected Steps per Second: 22,848.07065
Overall Steps per Second: 10,807.07698

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.43940
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.62882

Cumulative Model Updates: 97,408
Cumulative Timesteps: 812,363,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 812363646...
Checkpoint 812363646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,758.67656
Policy Entropy: 3.64554
Value Function Loss: 0.08882

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.59834
Value Function Update Magnitude: 0.82105

Collected Steps per Second: 22,923.20762
Overall Steps per Second: 10,737.62291

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.65801

Cumulative Model Updates: 97,414
Cumulative Timesteps: 812,413,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,833.08038
Policy Entropy: 3.63379
Value Function Loss: 0.09210

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.58083
Value Function Update Magnitude: 0.74299

Collected Steps per Second: 22,916.33942
Overall Steps per Second: 10,841.22802

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.61442

Cumulative Model Updates: 97,420
Cumulative Timesteps: 812,463,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 812463688...
Checkpoint 812463688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,700.71631
Policy Entropy: 3.62633
Value Function Loss: 0.09372

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.70314

Collected Steps per Second: 22,835.76764
Overall Steps per Second: 10,715.54353

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.47816
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.66911

Cumulative Model Updates: 97,426
Cumulative Timesteps: 812,513,720

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,799.82743
Policy Entropy: 3.60586
Value Function Loss: 0.09415

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.52836
Value Function Update Magnitude: 0.70830

Collected Steps per Second: 23,010.29081
Overall Steps per Second: 10,860.03320

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.43158
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.60496

Cumulative Model Updates: 97,432
Cumulative Timesteps: 812,563,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 812563730...
Checkpoint 812563730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.27771
Policy Entropy: 3.61458
Value Function Loss: 0.09290

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.60975
Value Function Update Magnitude: 0.65055

Collected Steps per Second: 22,738.67046
Overall Steps per Second: 10,768.23948

Timestep Collection Time: 2.19960
Timestep Consumption Time: 2.44517
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.64477

Cumulative Model Updates: 97,438
Cumulative Timesteps: 812,613,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,701.36181
Policy Entropy: 3.61580
Value Function Loss: 0.09278

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.74611
Value Function Update Magnitude: 0.67119

Collected Steps per Second: 22,468.33234
Overall Steps per Second: 10,624.39601

Timestep Collection Time: 2.22598
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.70747

Cumulative Model Updates: 97,444
Cumulative Timesteps: 812,663,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 812663760...
Checkpoint 812663760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837.01383
Policy Entropy: 3.60326
Value Function Loss: 0.09350

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.69412
Value Function Update Magnitude: 0.67117

Collected Steps per Second: 22,676.83596
Overall Steps per Second: 10,817.94949

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.41792
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.62361

Cumulative Model Updates: 97,450
Cumulative Timesteps: 812,713,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,166.55694
Policy Entropy: 3.59556
Value Function Loss: 0.09447

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.70224

Collected Steps per Second: 22,470.98913
Overall Steps per Second: 10,543.06016

Timestep Collection Time: 2.22527
Timestep Consumption Time: 2.51757
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.74284

Cumulative Model Updates: 97,456
Cumulative Timesteps: 812,763,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 812763782...
Checkpoint 812763782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,989.13876
Policy Entropy: 3.58000
Value Function Loss: 0.09114

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.16513
Policy Update Magnitude: 0.46385
Value Function Update Magnitude: 0.69555

Collected Steps per Second: 22,457.93168
Overall Steps per Second: 10,622.34546

Timestep Collection Time: 2.22719
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.70875

Cumulative Model Updates: 97,462
Cumulative Timesteps: 812,813,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,056.86833
Policy Entropy: 3.58243
Value Function Loss: 0.08790

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.49295
Value Function Update Magnitude: 0.78090

Collected Steps per Second: 22,668.27336
Overall Steps per Second: 10,506.71690

Timestep Collection Time: 2.20784
Timestep Consumption Time: 2.55559
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.76343

Cumulative Model Updates: 97,468
Cumulative Timesteps: 812,863,848

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 812863848...
Checkpoint 812863848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,032.47826
Policy Entropy: 3.59290
Value Function Loss: 0.08504

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.51999
Value Function Update Magnitude: 0.82462

Collected Steps per Second: 22,772.16590
Overall Steps per Second: 10,621.29073

Timestep Collection Time: 2.19663
Timestep Consumption Time: 2.51297
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.70960

Cumulative Model Updates: 97,474
Cumulative Timesteps: 812,913,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,410.57757
Policy Entropy: 3.59436
Value Function Loss: 0.08732

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.48423
Value Function Update Magnitude: 0.77372

Collected Steps per Second: 22,666.45702
Overall Steps per Second: 10,814.00727

Timestep Collection Time: 2.20626
Timestep Consumption Time: 2.41812
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.62437

Cumulative Model Updates: 97,480
Cumulative Timesteps: 812,963,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 812963878...
Checkpoint 812963878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,648.78314
Policy Entropy: 3.60569
Value Function Loss: 0.08774

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.47866
Value Function Update Magnitude: 0.71286

Collected Steps per Second: 22,487.73590
Overall Steps per Second: 10,762.82027

Timestep Collection Time: 2.22450
Timestep Consumption Time: 2.42335
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.64785

Cumulative Model Updates: 97,486
Cumulative Timesteps: 813,013,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,959.11755
Policy Entropy: 3.62048
Value Function Loss: 0.08609

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.65126

Collected Steps per Second: 22,654.69915
Overall Steps per Second: 10,609.65823

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.71401

Cumulative Model Updates: 97,492
Cumulative Timesteps: 813,063,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 813063916...
Checkpoint 813063916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,860.90206
Policy Entropy: 3.63954
Value Function Loss: 0.08561

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.65142
Value Function Update Magnitude: 0.67424

Collected Steps per Second: 23,013.56171
Overall Steps per Second: 10,863.54259

Timestep Collection Time: 2.17307
Timestep Consumption Time: 2.43040
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60347

Cumulative Model Updates: 97,498
Cumulative Timesteps: 813,113,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,948.64243
Policy Entropy: 3.63839
Value Function Loss: 0.08183

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.61489
Value Function Update Magnitude: 0.68141

Collected Steps per Second: 22,411.23934
Overall Steps per Second: 10,576.43427

Timestep Collection Time: 2.23227
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.73014

Cumulative Model Updates: 97,504
Cumulative Timesteps: 813,163,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 813163954...
Checkpoint 813163954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.41138
Policy Entropy: 3.63105
Value Function Loss: 0.08061

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.60971
Value Function Update Magnitude: 0.68177

Collected Steps per Second: 22,613.83394
Overall Steps per Second: 10,641.82063

Timestep Collection Time: 2.21112
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.69863

Cumulative Model Updates: 97,510
Cumulative Timesteps: 813,213,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,614.60123
Policy Entropy: 3.63393
Value Function Loss: 0.08187

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.60121
Value Function Update Magnitude: 0.67405

Collected Steps per Second: 22,425.12748
Overall Steps per Second: 10,709.02372

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.66933

Cumulative Model Updates: 97,516
Cumulative Timesteps: 813,263,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 813263960...
Checkpoint 813263960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,782.13011
Policy Entropy: 3.62163
Value Function Loss: 0.08585

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.66509
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 21,969.30974
Overall Steps per Second: 10,486.38395

Timestep Collection Time: 2.27645
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.76923

Cumulative Model Updates: 97,522
Cumulative Timesteps: 813,313,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,442.23431
Policy Entropy: 3.63493
Value Function Loss: 0.08493

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.61585
Value Function Update Magnitude: 0.66540

Collected Steps per Second: 23,289.45831
Overall Steps per Second: 10,690.49626

Timestep Collection Time: 2.14715
Timestep Consumption Time: 2.53046
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.67761

Cumulative Model Updates: 97,528
Cumulative Timesteps: 813,363,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 813363978...
Checkpoint 813363978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,175.63282
Policy Entropy: 3.62832
Value Function Loss: 0.08336

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.59531
Value Function Update Magnitude: 0.71991

Collected Steps per Second: 22,787.94275
Overall Steps per Second: 10,637.86078

Timestep Collection Time: 2.19511
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.70226

Cumulative Model Updates: 97,534
Cumulative Timesteps: 813,414,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.40056
Policy Entropy: 3.62374
Value Function Loss: 0.08555

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.57465
Value Function Update Magnitude: 0.80270

Collected Steps per Second: 23,198.83653
Overall Steps per Second: 10,889.01703

Timestep Collection Time: 2.15528
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.59178

Cumulative Model Updates: 97,540
Cumulative Timesteps: 813,464,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 813464000...
Checkpoint 813464000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.76773
Policy Entropy: 3.61267
Value Function Loss: 0.08675

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.58530
Value Function Update Magnitude: 0.86564

Collected Steps per Second: 22,692.33711
Overall Steps per Second: 10,654.78493

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.49054
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69498

Cumulative Model Updates: 97,546
Cumulative Timesteps: 813,514,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,432.84181
Policy Entropy: 3.61877
Value Function Loss: 0.08911

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.55944
Value Function Update Magnitude: 0.85557

Collected Steps per Second: 22,765.80921
Overall Steps per Second: 10,834.51210

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.61784

Cumulative Model Updates: 97,552
Cumulative Timesteps: 813,564,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 813564056...
Checkpoint 813564056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,730.94510
Policy Entropy: 3.63177
Value Function Loss: 0.08712

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.55458
Value Function Update Magnitude: 0.81953

Collected Steps per Second: 22,835.19479
Overall Steps per Second: 10,747.08845

Timestep Collection Time: 2.19135
Timestep Consumption Time: 2.46479
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.65614

Cumulative Model Updates: 97,558
Cumulative Timesteps: 813,614,096

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,620.57072
Policy Entropy: 3.62635
Value Function Loss: 0.08993

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.60909
Value Function Update Magnitude: 0.74938

Collected Steps per Second: 22,268.19890
Overall Steps per Second: 10,521.85989

Timestep Collection Time: 2.24616
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.75372

Cumulative Model Updates: 97,564
Cumulative Timesteps: 813,664,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 813664114...
Checkpoint 813664114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,615.70657
Policy Entropy: 3.62689
Value Function Loss: 0.08854

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.68260

Collected Steps per Second: 22,318.85029
Overall Steps per Second: 10,550.40439

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.50020
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.74162

Cumulative Model Updates: 97,570
Cumulative Timesteps: 813,714,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,942.53845
Policy Entropy: 3.63638
Value Function Loss: 0.08589

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.62035
Value Function Update Magnitude: 0.65678

Collected Steps per Second: 22,475.26339
Overall Steps per Second: 10,594.28518

Timestep Collection Time: 2.22556
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.72141

Cumulative Model Updates: 97,576
Cumulative Timesteps: 813,764,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 813764160...
Checkpoint 813764160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,893.40047
Policy Entropy: 3.64619
Value Function Loss: 0.08371

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.63007
Value Function Update Magnitude: 0.67792

Collected Steps per Second: 22,576.20757
Overall Steps per Second: 10,617.07452

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.71034

Cumulative Model Updates: 97,582
Cumulative Timesteps: 813,814,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,573.68948
Policy Entropy: 3.64173
Value Function Loss: 0.08356

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.69062
Value Function Update Magnitude: 0.70082

Collected Steps per Second: 21,831.18183
Overall Steps per Second: 10,419.26695

Timestep Collection Time: 2.29085
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.79995

Cumulative Model Updates: 97,588
Cumulative Timesteps: 813,864,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 813864182...
Checkpoint 813864182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,076.00884
Policy Entropy: 3.64157
Value Function Loss: 0.08475

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.66846
Value Function Update Magnitude: 0.67433

Collected Steps per Second: 22,161.08162
Overall Steps per Second: 10,578.19396

Timestep Collection Time: 2.25702
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.72841

Cumulative Model Updates: 97,594
Cumulative Timesteps: 813,914,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,404.29066
Policy Entropy: 3.64582
Value Function Loss: 0.08475

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.67517
Value Function Update Magnitude: 0.63283

Collected Steps per Second: 22,839.57814
Overall Steps per Second: 10,840.33929

Timestep Collection Time: 2.19050
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.61517

Cumulative Model Updates: 97,600
Cumulative Timesteps: 813,964,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 813964230...
Checkpoint 813964230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,783.93967
Policy Entropy: 3.64994
Value Function Loss: 0.08538

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.70053
Value Function Update Magnitude: 0.70268

Collected Steps per Second: 22,999.17165
Overall Steps per Second: 10,689.43796

Timestep Collection Time: 2.17408
Timestep Consumption Time: 2.50362
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.67770

Cumulative Model Updates: 97,606
Cumulative Timesteps: 814,014,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,198.37657
Policy Entropy: 3.64921
Value Function Loss: 0.08729

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.80460
Value Function Update Magnitude: 0.67631

Collected Steps per Second: 22,509.69759
Overall Steps per Second: 10,607.29714

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.71430

Cumulative Model Updates: 97,612
Cumulative Timesteps: 814,064,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 814064238...
Checkpoint 814064238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,866.83441
Policy Entropy: 3.66481
Value Function Loss: 0.08702

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.81967
Value Function Update Magnitude: 0.55476

Collected Steps per Second: 22,944.81914
Overall Steps per Second: 10,868.74493

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.42140
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60072

Cumulative Model Updates: 97,618
Cumulative Timesteps: 814,114,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,521.00329
Policy Entropy: 3.66001
Value Function Loss: 0.09022

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.82079
Value Function Update Magnitude: 0.59398

Collected Steps per Second: 23,088.25896
Overall Steps per Second: 10,897.83259

Timestep Collection Time: 2.16569
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.58825

Cumulative Model Updates: 97,624
Cumulative Timesteps: 814,164,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 814164244...
Checkpoint 814164244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,707.70944
Policy Entropy: 3.64087
Value Function Loss: 0.09008

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.69515
Value Function Update Magnitude: 0.59582

Collected Steps per Second: 22,805.48408
Overall Steps per Second: 10,722.45402

Timestep Collection Time: 2.19272
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.66367

Cumulative Model Updates: 97,630
Cumulative Timesteps: 814,214,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,070.52216
Policy Entropy: 3.63707
Value Function Loss: 0.08791

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.62324
Value Function Update Magnitude: 0.67108

Collected Steps per Second: 22,481.24832
Overall Steps per Second: 10,649.83523

Timestep Collection Time: 2.22452
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.69585

Cumulative Model Updates: 97,636
Cumulative Timesteps: 814,264,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 814264260...
Checkpoint 814264260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,705.47373
Policy Entropy: 3.63368
Value Function Loss: 0.08230

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.56740
Value Function Update Magnitude: 0.74662

Collected Steps per Second: 22,902.52836
Overall Steps per Second: 10,856.70926

Timestep Collection Time: 2.18325
Timestep Consumption Time: 2.42238
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.60563

Cumulative Model Updates: 97,642
Cumulative Timesteps: 814,314,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,224.88316
Policy Entropy: 3.64684
Value Function Loss: 0.08329

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.80480

Collected Steps per Second: 21,737.91498
Overall Steps per Second: 10,596.53485

Timestep Collection Time: 2.30188
Timestep Consumption Time: 2.42023
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.72211

Cumulative Model Updates: 97,648
Cumulative Timesteps: 814,364,300

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 814364300...
Checkpoint 814364300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.08257
Policy Entropy: 3.63855
Value Function Loss: 0.08186

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.52720
Value Function Update Magnitude: 0.86343

Collected Steps per Second: 21,545.24566
Overall Steps per Second: 10,574.12528

Timestep Collection Time: 2.32135
Timestep Consumption Time: 2.40850
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.72985

Cumulative Model Updates: 97,654
Cumulative Timesteps: 814,414,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,431.57792
Policy Entropy: 3.64658
Value Function Loss: 0.08192

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.61564
Value Function Update Magnitude: 0.91463

Collected Steps per Second: 21,678.38670
Overall Steps per Second: 10,584.82189

Timestep Collection Time: 2.30709
Timestep Consumption Time: 2.41798
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.72507

Cumulative Model Updates: 97,660
Cumulative Timesteps: 814,464,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 814464328...
Checkpoint 814464328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,232.49636
Policy Entropy: 3.65121
Value Function Loss: 0.08206

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.63405
Value Function Update Magnitude: 0.90829

Collected Steps per Second: 21,919.24945
Overall Steps per Second: 10,674.35262

Timestep Collection Time: 2.28192
Timestep Consumption Time: 2.40389
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.68581

Cumulative Model Updates: 97,666
Cumulative Timesteps: 814,514,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,416.54179
Policy Entropy: 3.64478
Value Function Loss: 0.08407

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.89301

Collected Steps per Second: 22,587.60532
Overall Steps per Second: 10,727.14876

Timestep Collection Time: 2.21440
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.66275

Cumulative Model Updates: 97,672
Cumulative Timesteps: 814,564,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 814564364...
Checkpoint 814564364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.02408
Policy Entropy: 3.63812
Value Function Loss: 0.08592

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.54657
Value Function Update Magnitude: 0.90042

Collected Steps per Second: 22,114.27302
Overall Steps per Second: 10,633.83479

Timestep Collection Time: 2.26234
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70479

Cumulative Model Updates: 97,678
Cumulative Timesteps: 814,614,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,243.17257
Policy Entropy: 3.63720
Value Function Loss: 0.08657

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.65978
Value Function Update Magnitude: 0.89524

Collected Steps per Second: 22,119.07946
Overall Steps per Second: 10,528.45231

Timestep Collection Time: 2.26094
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.74999

Cumulative Model Updates: 97,684
Cumulative Timesteps: 814,664,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 814664404...
Checkpoint 814664404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.42191
Policy Entropy: 3.64067
Value Function Loss: 0.08710

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.74419
Value Function Update Magnitude: 0.91487

Collected Steps per Second: 22,730.54514
Overall Steps per Second: 10,710.91480

Timestep Collection Time: 2.20021
Timestep Consumption Time: 2.46904
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.66926

Cumulative Model Updates: 97,690
Cumulative Timesteps: 814,714,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,109.22155
Policy Entropy: 3.63459
Value Function Loss: 0.08691

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.70273
Value Function Update Magnitude: 0.87495

Collected Steps per Second: 22,780.98633
Overall Steps per Second: 10,774.59220

Timestep Collection Time: 2.19578
Timestep Consumption Time: 2.44681
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.64259

Cumulative Model Updates: 97,696
Cumulative Timesteps: 814,764,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 814764438...
Checkpoint 814764438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,661.21067
Policy Entropy: 3.63279
Value Function Loss: 0.08860

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.16099
Policy Update Magnitude: 0.62680
Value Function Update Magnitude: 0.74199

Collected Steps per Second: 23,107.72250
Overall Steps per Second: 10,875.69271

Timestep Collection Time: 2.16395
Timestep Consumption Time: 2.43382
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.59778

Cumulative Model Updates: 97,702
Cumulative Timesteps: 814,814,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,626.54258
Policy Entropy: 3.63598
Value Function Loss: 0.08797

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.53432
Value Function Update Magnitude: 0.68983

Collected Steps per Second: 22,527.13376
Overall Steps per Second: 10,670.24178

Timestep Collection Time: 2.22185
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.69080

Cumulative Model Updates: 97,708
Cumulative Timesteps: 814,864,494

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 814864494...
Checkpoint 814864494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,175.99505
Policy Entropy: 3.63575
Value Function Loss: 0.09161

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.66664

Collected Steps per Second: 22,516.61573
Overall Steps per Second: 10,617.61076

Timestep Collection Time: 2.22183
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.71179

Cumulative Model Updates: 97,714
Cumulative Timesteps: 814,914,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,253.64584
Policy Entropy: 3.62975
Value Function Loss: 0.09285

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.68879

Collected Steps per Second: 22,543.69159
Overall Steps per Second: 10,848.64299

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.39172
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61035

Cumulative Model Updates: 97,720
Cumulative Timesteps: 814,964,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 814964538...
Checkpoint 814964538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.48786
Policy Entropy: 3.61596
Value Function Loss: 0.09296

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.70696

Collected Steps per Second: 22,723.82587
Overall Steps per Second: 10,760.09136

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.44715
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.64810

Cumulative Model Updates: 97,726
Cumulative Timesteps: 815,014,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,302.40701
Policy Entropy: 3.61865
Value Function Loss: 0.08770

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.70450

Collected Steps per Second: 22,908.78645
Overall Steps per Second: 10,784.17176

Timestep Collection Time: 2.18292
Timestep Consumption Time: 2.45425
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.63717

Cumulative Model Updates: 97,732
Cumulative Timesteps: 815,064,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 815064560...
Checkpoint 815064560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,219.06813
Policy Entropy: 3.60591
Value Function Loss: 0.08758

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.16025
Policy Update Magnitude: 0.56672
Value Function Update Magnitude: 0.72874

Collected Steps per Second: 22,629.38669
Overall Steps per Second: 10,698.92155

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.46464
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.67486

Cumulative Model Updates: 97,738
Cumulative Timesteps: 815,114,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,099.31487
Policy Entropy: 3.60524
Value Function Loss: 0.08582

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.42796
Value Function Update Magnitude: 0.76946

Collected Steps per Second: 22,742.78165
Overall Steps per Second: 10,844.19519

Timestep Collection Time: 2.19991
Timestep Consumption Time: 2.41381
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61371

Cumulative Model Updates: 97,744
Cumulative Timesteps: 815,164,608

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 815164608...
Checkpoint 815164608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.58461
Policy Entropy: 3.62359
Value Function Loss: 0.08474

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.49517
Value Function Update Magnitude: 0.75314

Collected Steps per Second: 22,536.20760
Overall Steps per Second: 10,784.17554

Timestep Collection Time: 2.21998
Timestep Consumption Time: 2.41922
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.63920

Cumulative Model Updates: 97,750
Cumulative Timesteps: 815,214,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,834.39997
Policy Entropy: 3.64138
Value Function Loss: 0.08274

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.79332

Collected Steps per Second: 22,785.48292
Overall Steps per Second: 10,794.16821

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.63324

Cumulative Model Updates: 97,756
Cumulative Timesteps: 815,264,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 815264650...
Checkpoint 815264650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,440.58275
Policy Entropy: 3.65155
Value Function Loss: 0.08345

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.58280
Value Function Update Magnitude: 0.76880

Collected Steps per Second: 22,223.93975
Overall Steps per Second: 10,669.66987

Timestep Collection Time: 2.25001
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.68656

Cumulative Model Updates: 97,762
Cumulative Timesteps: 815,314,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,683.93434
Policy Entropy: 3.64070
Value Function Loss: 0.08811

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.61350
Value Function Update Magnitude: 0.74958

Collected Steps per Second: 22,505.50957
Overall Steps per Second: 10,597.57455

Timestep Collection Time: 2.22168
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.71806

Cumulative Model Updates: 97,768
Cumulative Timesteps: 815,364,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 815364654...
Checkpoint 815364654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,083.02439
Policy Entropy: 3.63382
Value Function Loss: 0.09110

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.50864
Value Function Update Magnitude: 0.83403

Collected Steps per Second: 22,285.73545
Overall Steps per Second: 10,554.64085

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.73763

Cumulative Model Updates: 97,774
Cumulative Timesteps: 815,414,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,341.96668
Policy Entropy: 3.62467
Value Function Loss: 0.08973

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.79469

Collected Steps per Second: 22,635.36053
Overall Steps per Second: 10,754.35016

Timestep Collection Time: 2.20920
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.64984

Cumulative Model Updates: 97,780
Cumulative Timesteps: 815,464,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 815464664...
Checkpoint 815464664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,760.13555
Policy Entropy: 3.62388
Value Function Loss: 0.08796

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.69553
Value Function Update Magnitude: 0.76861

Collected Steps per Second: 22,792.05395
Overall Steps per Second: 10,689.07794

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.67917

Cumulative Model Updates: 97,786
Cumulative Timesteps: 815,514,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,899.06845
Policy Entropy: 3.62560
Value Function Loss: 0.08705

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.71335
Value Function Update Magnitude: 0.78377

Collected Steps per Second: 22,960.87196
Overall Steps per Second: 10,849.66013

Timestep Collection Time: 2.17858
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61047

Cumulative Model Updates: 97,792
Cumulative Timesteps: 815,564,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 815564702...
Checkpoint 815564702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,600.06336
Policy Entropy: 3.64204
Value Function Loss: 0.08363

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.63199
Value Function Update Magnitude: 0.84353

Collected Steps per Second: 22,785.68301
Overall Steps per Second: 10,746.66041

Timestep Collection Time: 2.19497
Timestep Consumption Time: 2.45894
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.65391

Cumulative Model Updates: 97,798
Cumulative Timesteps: 815,614,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,740.94225
Policy Entropy: 3.65636
Value Function Loss: 0.08464

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.62961
Value Function Update Magnitude: 0.83712

Collected Steps per Second: 22,553.53229
Overall Steps per Second: 10,627.65986

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70753

Cumulative Model Updates: 97,804
Cumulative Timesteps: 815,664,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 815664746...
Checkpoint 815664746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,155.05399
Policy Entropy: 3.65910
Value Function Loss: 0.08073

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.64348
Value Function Update Magnitude: 0.79662

Collected Steps per Second: 22,856.72595
Overall Steps per Second: 10,833.65612

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.61525

Cumulative Model Updates: 97,810
Cumulative Timesteps: 815,714,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,961.03585
Policy Entropy: 3.65636
Value Function Loss: 0.08314

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.56997
Value Function Update Magnitude: 0.78657

Collected Steps per Second: 22,394.18974
Overall Steps per Second: 10,526.25800

Timestep Collection Time: 2.23478
Timestep Consumption Time: 2.51962
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.75440

Cumulative Model Updates: 97,816
Cumulative Timesteps: 815,764,792

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 815764792...
Checkpoint 815764792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,997.31729
Policy Entropy: 3.66426
Value Function Loss: 0.08551

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.51614
Value Function Update Magnitude: 0.80680

Collected Steps per Second: 22,267.73300
Overall Steps per Second: 10,716.00765

Timestep Collection Time: 2.24567
Timestep Consumption Time: 2.42081
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.66648

Cumulative Model Updates: 97,822
Cumulative Timesteps: 815,814,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,236.15948
Policy Entropy: 3.65345
Value Function Loss: 0.08584

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.50929
Value Function Update Magnitude: 0.77156

Collected Steps per Second: 22,430.48465
Overall Steps per Second: 10,604.75743

Timestep Collection Time: 2.22964
Timestep Consumption Time: 2.48635
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.71600

Cumulative Model Updates: 97,828
Cumulative Timesteps: 815,864,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 815864810...
Checkpoint 815864810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,968.17094
Policy Entropy: 3.65393
Value Function Loss: 0.08155

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.48920
Value Function Update Magnitude: 0.75370

Collected Steps per Second: 22,482.79926
Overall Steps per Second: 10,649.83380

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69735

Cumulative Model Updates: 97,834
Cumulative Timesteps: 815,914,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,905.72752
Policy Entropy: 3.65234
Value Function Loss: 0.08000

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.50985
Value Function Update Magnitude: 0.81049

Collected Steps per Second: 22,212.24963
Overall Steps per Second: 10,647.35542

Timestep Collection Time: 2.25128
Timestep Consumption Time: 2.44529
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.69657

Cumulative Model Updates: 97,840
Cumulative Timesteps: 815,964,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 815964842...
Checkpoint 815964842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.49176
Policy Entropy: 3.66015
Value Function Loss: 0.07979

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.55312
Value Function Update Magnitude: 0.90733

Collected Steps per Second: 22,341.88569
Overall Steps per Second: 10,732.69398

Timestep Collection Time: 2.23911
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.66109

Cumulative Model Updates: 97,846
Cumulative Timesteps: 816,014,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,764.78297
Policy Entropy: 3.66283
Value Function Loss: 0.08068

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.54038
Value Function Update Magnitude: 0.92829

Collected Steps per Second: 22,897.39945
Overall Steps per Second: 10,807.62904

Timestep Collection Time: 2.18461
Timestep Consumption Time: 2.44378
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.62840

Cumulative Model Updates: 97,852
Cumulative Timesteps: 816,064,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 816064890...
Checkpoint 816064890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,011.28230
Policy Entropy: 3.66104
Value Function Loss: 0.08261

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.92164

Collected Steps per Second: 22,629.09481
Overall Steps per Second: 10,694.26123

Timestep Collection Time: 2.21078
Timestep Consumption Time: 2.46724
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.67802

Cumulative Model Updates: 97,858
Cumulative Timesteps: 816,114,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,618.55747
Policy Entropy: 3.64983
Value Function Loss: 0.08420

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.56716
Value Function Update Magnitude: 0.92546

Collected Steps per Second: 23,125.47061
Overall Steps per Second: 10,944.61878

Timestep Collection Time: 2.16246
Timestep Consumption Time: 2.40672
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.56919

Cumulative Model Updates: 97,864
Cumulative Timesteps: 816,164,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 816164926...
Checkpoint 816164926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,783.48400
Policy Entropy: 3.63069
Value Function Loss: 0.08531

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.53450
Value Function Update Magnitude: 0.82467

Collected Steps per Second: 22,911.41339
Overall Steps per Second: 10,737.58644

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.47482
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.65766

Cumulative Model Updates: 97,870
Cumulative Timesteps: 816,214,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,181.76770
Policy Entropy: 3.62394
Value Function Loss: 0.08581

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.49207
Value Function Update Magnitude: 0.69851

Collected Steps per Second: 22,065.92145
Overall Steps per Second: 10,747.09434

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.38686
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.65316

Cumulative Model Updates: 97,876
Cumulative Timesteps: 816,264,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 816264946...
Checkpoint 816264946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.20568
Policy Entropy: 3.62038
Value Function Loss: 0.08474

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.49581
Value Function Update Magnitude: 0.69779

Collected Steps per Second: 21,540.55355
Overall Steps per Second: 10,714.70529

Timestep Collection Time: 2.32195
Timestep Consumption Time: 2.34603
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.66798

Cumulative Model Updates: 97,882
Cumulative Timesteps: 816,314,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,555.26966
Policy Entropy: 3.62920
Value Function Loss: 0.08209

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.69853

Collected Steps per Second: 21,848.16287
Overall Steps per Second: 10,661.29310

Timestep Collection Time: 2.28889
Timestep Consumption Time: 2.40172
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.69061

Cumulative Model Updates: 97,888
Cumulative Timesteps: 816,364,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 816364970...
Checkpoint 816364970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,994.56275
Policy Entropy: 3.64031
Value Function Loss: 0.08155

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.58047
Value Function Update Magnitude: 0.80284

Collected Steps per Second: 21,688.65983
Overall Steps per Second: 10,755.19180

Timestep Collection Time: 2.30591
Timestep Consumption Time: 2.34413
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.65003

Cumulative Model Updates: 97,894
Cumulative Timesteps: 816,414,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,528.95460
Policy Entropy: 3.64733
Value Function Loss: 0.07969

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.48837
Value Function Update Magnitude: 0.90768

Collected Steps per Second: 21,805.75763
Overall Steps per Second: 10,581.12606

Timestep Collection Time: 2.29306
Timestep Consumption Time: 2.43252
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.72558

Cumulative Model Updates: 97,900
Cumulative Timesteps: 816,464,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 816464984...
Checkpoint 816464984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,453.72101
Policy Entropy: 3.66749
Value Function Loss: 0.07568

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.51605
Value Function Update Magnitude: 0.92071

Collected Steps per Second: 21,687.61766
Overall Steps per Second: 10,575.57697

Timestep Collection Time: 2.30648
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.72995

Cumulative Model Updates: 97,906
Cumulative Timesteps: 816,515,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,151.28763
Policy Entropy: 3.65454
Value Function Loss: 0.07687

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.45600
Value Function Update Magnitude: 0.91145

Collected Steps per Second: 22,035.43453
Overall Steps per Second: 10,485.48381

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.77193

Cumulative Model Updates: 97,912
Cumulative Timesteps: 816,565,042

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 816565042...
Checkpoint 816565042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.66849
Policy Entropy: 3.65432
Value Function Loss: 0.07768

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.50277
Value Function Update Magnitude: 0.88105

Collected Steps per Second: 22,660.66001
Overall Steps per Second: 10,670.88905

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.68639

Cumulative Model Updates: 97,918
Cumulative Timesteps: 816,615,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,330.60439
Policy Entropy: 3.63805
Value Function Loss: 0.07788

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.46530
Value Function Update Magnitude: 0.87916

Collected Steps per Second: 22,999.13822
Overall Steps per Second: 10,851.20262

Timestep Collection Time: 2.17399
Timestep Consumption Time: 2.43379
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.60778

Cumulative Model Updates: 97,924
Cumulative Timesteps: 816,665,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 816665050...
Checkpoint 816665050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,915.37811
Policy Entropy: 3.64119
Value Function Loss: 0.07556

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.47270
Value Function Update Magnitude: 0.87809

Collected Steps per Second: 22,633.10321
Overall Steps per Second: 10,650.53894

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.48614
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.69591

Cumulative Model Updates: 97,930
Cumulative Timesteps: 816,715,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.34211
Policy Entropy: 3.64319
Value Function Loss: 0.07338

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.49547
Value Function Update Magnitude: 0.82823

Collected Steps per Second: 22,865.58430
Overall Steps per Second: 10,834.73588

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61608

Cumulative Model Updates: 97,936
Cumulative Timesteps: 816,765,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 816765078...
Checkpoint 816765078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,965.14795
Policy Entropy: 3.65334
Value Function Loss: 0.07355

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.78965

Collected Steps per Second: 22,667.89557
Overall Steps per Second: 10,745.62944

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.44837
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.65510

Cumulative Model Updates: 97,942
Cumulative Timesteps: 816,815,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,925.72118
Policy Entropy: 3.65633
Value Function Loss: 0.07363

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.52693
Value Function Update Magnitude: 0.77728

Collected Steps per Second: 22,453.50677
Overall Steps per Second: 10,798.15265

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.40379
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.63079

Cumulative Model Updates: 97,948
Cumulative Timesteps: 816,865,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 816865104...
Checkpoint 816865104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,041.87409
Policy Entropy: 3.66847
Value Function Loss: 0.07198

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.46479
Value Function Update Magnitude: 0.79109

Collected Steps per Second: 21,840.30960
Overall Steps per Second: 10,620.01160

Timestep Collection Time: 2.29017
Timestep Consumption Time: 2.41962
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.70979

Cumulative Model Updates: 97,954
Cumulative Timesteps: 816,915,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,654.91063
Policy Entropy: 3.66647
Value Function Loss: 0.07188

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.46034
Value Function Update Magnitude: 0.76250

Collected Steps per Second: 22,680.77756
Overall Steps per Second: 10,726.42657

Timestep Collection Time: 2.20477
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.66194

Cumulative Model Updates: 97,960
Cumulative Timesteps: 816,965,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 816965128...
Checkpoint 816965128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,385.92218
Policy Entropy: 3.66381
Value Function Loss: 0.07053

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.44445
Value Function Update Magnitude: 0.72342

Collected Steps per Second: 23,041.59888
Overall Steps per Second: 10,848.25373

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.60922

Cumulative Model Updates: 97,966
Cumulative Timesteps: 817,015,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,352.44255
Policy Entropy: 3.65929
Value Function Loss: 0.07497

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.47505
Value Function Update Magnitude: 0.71281

Collected Steps per Second: 23,312.42264
Overall Steps per Second: 10,874.80604

Timestep Collection Time: 2.14512
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.59852

Cumulative Model Updates: 97,972
Cumulative Timesteps: 817,065,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 817065138...
Checkpoint 817065138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,883.32554
Policy Entropy: 3.64181
Value Function Loss: 0.07384

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.48941
Value Function Update Magnitude: 0.70750

Collected Steps per Second: 22,743.60203
Overall Steps per Second: 10,750.24661

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.45381
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.65329

Cumulative Model Updates: 97,978
Cumulative Timesteps: 817,115,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,184.01309
Policy Entropy: 3.64838
Value Function Loss: 0.07379

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.48104
Value Function Update Magnitude: 0.69757

Collected Steps per Second: 23,055.88545
Overall Steps per Second: 10,881.64723

Timestep Collection Time: 2.17003
Timestep Consumption Time: 2.42780
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59783

Cumulative Model Updates: 97,984
Cumulative Timesteps: 817,165,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 817165194...
Checkpoint 817165194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,488.08864
Policy Entropy: 3.65005
Value Function Loss: 0.07647

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.49621
Value Function Update Magnitude: 0.70908

Collected Steps per Second: 22,640.05740
Overall Steps per Second: 10,682.41612

Timestep Collection Time: 2.20901
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.68171

Cumulative Model Updates: 97,990
Cumulative Timesteps: 817,215,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.20245
Policy Entropy: 3.66383
Value Function Loss: 0.07967

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.73198

Collected Steps per Second: 22,824.08190
Overall Steps per Second: 10,794.05345

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.63274

Cumulative Model Updates: 97,996
Cumulative Timesteps: 817,265,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 817265212...
Checkpoint 817265212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,952.77669
Policy Entropy: 3.65970
Value Function Loss: 0.08105

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.50264
Value Function Update Magnitude: 0.81637

Collected Steps per Second: 22,445.84200
Overall Steps per Second: 10,752.19284

Timestep Collection Time: 2.22848
Timestep Consumption Time: 2.42360
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.65207

Cumulative Model Updates: 98,002
Cumulative Timesteps: 817,315,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,056.57074
Policy Entropy: 3.65289
Value Function Loss: 0.07762

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.48053
Value Function Update Magnitude: 0.85281

Collected Steps per Second: 22,311.35005
Overall Steps per Second: 10,560.03712

Timestep Collection Time: 2.24155
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73597

Cumulative Model Updates: 98,008
Cumulative Timesteps: 817,365,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 817365244...
Checkpoint 817365244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,426.75240
Policy Entropy: 3.65092
Value Function Loss: 0.07622

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.46037
Value Function Update Magnitude: 0.84646

Collected Steps per Second: 22,354.99961
Overall Steps per Second: 10,549.84863

Timestep Collection Time: 2.23699
Timestep Consumption Time: 2.50317
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.74016

Cumulative Model Updates: 98,014
Cumulative Timesteps: 817,415,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,335.02089
Policy Entropy: 3.64554
Value Function Loss: 0.07898

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.51952
Value Function Update Magnitude: 0.79183

Collected Steps per Second: 22,445.16642
Overall Steps per Second: 10,564.75620

Timestep Collection Time: 2.22890
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.73537

Cumulative Model Updates: 98,020
Cumulative Timesteps: 817,465,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 817465280...
Checkpoint 817465280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,742.28843
Policy Entropy: 3.64392
Value Function Loss: 0.08125

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.77495

Collected Steps per Second: 23,056.62556
Overall Steps per Second: 10,668.26771

Timestep Collection Time: 2.16988
Timestep Consumption Time: 2.51973
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.68961

Cumulative Model Updates: 98,026
Cumulative Timesteps: 817,515,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,194.61273
Policy Entropy: 3.63908
Value Function Loss: 0.08117

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.57278
Value Function Update Magnitude: 0.71221

Collected Steps per Second: 22,732.85437
Overall Steps per Second: 10,685.32475

Timestep Collection Time: 2.19999
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.68044

Cumulative Model Updates: 98,032
Cumulative Timesteps: 817,565,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 817565322...
Checkpoint 817565322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,918.98056
Policy Entropy: 3.64879
Value Function Loss: 0.08093

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.48640
Value Function Update Magnitude: 0.72786

Collected Steps per Second: 22,480.39271
Overall Steps per Second: 10,774.22951

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.41664
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.64089

Cumulative Model Updates: 98,038
Cumulative Timesteps: 817,615,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,924.78861
Policy Entropy: 3.65468
Value Function Loss: 0.07831

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.49442
Value Function Update Magnitude: 0.83260

Collected Steps per Second: 22,574.80171
Overall Steps per Second: 10,782.75011

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.42353
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.63963

Cumulative Model Updates: 98,044
Cumulative Timesteps: 817,665,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 817665352...
Checkpoint 817665352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,538.82084
Policy Entropy: 3.66259
Value Function Loss: 0.07616

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.46431
Value Function Update Magnitude: 0.90177

Collected Steps per Second: 22,386.08774
Overall Steps per Second: 10,748.60236

Timestep Collection Time: 2.23469
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.65419

Cumulative Model Updates: 98,050
Cumulative Timesteps: 817,715,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,754.86417
Policy Entropy: 3.65734
Value Function Loss: 0.07441

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.52952
Value Function Update Magnitude: 0.92058

Collected Steps per Second: 22,578.20575
Overall Steps per Second: 10,637.14128

Timestep Collection Time: 2.21523
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.70202

Cumulative Model Updates: 98,056
Cumulative Timesteps: 817,765,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 817765394...
Checkpoint 817765394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,924.98451
Policy Entropy: 3.65511
Value Function Loss: 0.07370

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06874
Policy Update Magnitude: 0.63888
Value Function Update Magnitude: 0.91191

Collected Steps per Second: 22,396.17688
Overall Steps per Second: 10,621.86773

Timestep Collection Time: 2.23315
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.70859

Cumulative Model Updates: 98,062
Cumulative Timesteps: 817,815,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.72929
Policy Entropy: 3.64541
Value Function Loss: 0.07686

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.73397
Value Function Update Magnitude: 0.87133

Collected Steps per Second: 22,488.15840
Overall Steps per Second: 10,679.65164

Timestep Collection Time: 2.22419
Timestep Consumption Time: 2.45929
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.68349

Cumulative Model Updates: 98,068
Cumulative Timesteps: 817,865,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 817865426...
Checkpoint 817865426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,762.53260
Policy Entropy: 3.65992
Value Function Loss: 0.07346

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.61724
Value Function Update Magnitude: 0.85640

Collected Steps per Second: 22,549.43772
Overall Steps per Second: 10,661.95435

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.69239

Cumulative Model Updates: 98,074
Cumulative Timesteps: 817,915,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,233.26470
Policy Entropy: 3.67294
Value Function Loss: 0.07353

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.53171
Value Function Update Magnitude: 0.90310

Collected Steps per Second: 23,019.50656
Overall Steps per Second: 10,849.76906

Timestep Collection Time: 2.17251
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60931

Cumulative Model Updates: 98,080
Cumulative Timesteps: 817,965,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 817965466...
Checkpoint 817965466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,194.16487
Policy Entropy: 3.66613
Value Function Loss: 0.07625

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.60795
Value Function Update Magnitude: 0.82174

Collected Steps per Second: 22,021.01313
Overall Steps per Second: 10,714.65520

Timestep Collection Time: 2.27110
Timestep Consumption Time: 2.39652
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.66763

Cumulative Model Updates: 98,086
Cumulative Timesteps: 818,015,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,922.78000
Policy Entropy: 3.65141
Value Function Loss: 0.08340

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.73327

Collected Steps per Second: 22,189.33041
Overall Steps per Second: 10,846.29295

Timestep Collection Time: 2.25433
Timestep Consumption Time: 2.35757
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61190

Cumulative Model Updates: 98,092
Cumulative Timesteps: 818,065,500

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 818065500...
Checkpoint 818065500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.04955
Policy Entropy: 3.64944
Value Function Loss: 0.08330

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.50471
Value Function Update Magnitude: 0.72537

Collected Steps per Second: 21,836.22309
Overall Steps per Second: 10,671.39972

Timestep Collection Time: 2.29051
Timestep Consumption Time: 2.39641
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.68692

Cumulative Model Updates: 98,098
Cumulative Timesteps: 818,115,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,100.32721
Policy Entropy: 3.64598
Value Function Loss: 0.08361

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.52933
Value Function Update Magnitude: 0.82111

Collected Steps per Second: 22,282.35416
Overall Steps per Second: 10,865.82359

Timestep Collection Time: 2.24492
Timestep Consumption Time: 2.35869
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.60361

Cumulative Model Updates: 98,104
Cumulative Timesteps: 818,165,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 818165538...
Checkpoint 818165538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,559.43892
Policy Entropy: 3.64983
Value Function Loss: 0.08143

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.89603

Collected Steps per Second: 21,758.61140
Overall Steps per Second: 10,646.54744

Timestep Collection Time: 2.29868
Timestep Consumption Time: 2.39918
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.69786

Cumulative Model Updates: 98,110
Cumulative Timesteps: 818,215,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.19535
Policy Entropy: 3.63908
Value Function Loss: 0.07994

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.51785
Value Function Update Magnitude: 0.81009

Collected Steps per Second: 22,118.25417
Overall Steps per Second: 10,513.44834

Timestep Collection Time: 2.26157
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.75791

Cumulative Model Updates: 98,116
Cumulative Timesteps: 818,265,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 818265576...
Checkpoint 818265576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,808.68321
Policy Entropy: 3.64002
Value Function Loss: 0.08058

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.53794
Value Function Update Magnitude: 0.74306

Collected Steps per Second: 22,227.73788
Overall Steps per Second: 10,652.20611

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.69537

Cumulative Model Updates: 98,122
Cumulative Timesteps: 818,315,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,105.85106
Policy Entropy: 3.63845
Value Function Loss: 0.08208

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.74409

Collected Steps per Second: 22,801.40669
Overall Steps per Second: 10,889.65386

Timestep Collection Time: 2.19434
Timestep Consumption Time: 2.40030
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.59464

Cumulative Model Updates: 98,128
Cumulative Timesteps: 818,365,626

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 818365626...
Checkpoint 818365626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,323.39874
Policy Entropy: 3.64960
Value Function Loss: 0.08448

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.54727
Value Function Update Magnitude: 0.78937

Collected Steps per Second: 22,454.77561
Overall Steps per Second: 10,672.20715

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.45906
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.68638

Cumulative Model Updates: 98,134
Cumulative Timesteps: 818,415,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,371.51877
Policy Entropy: 3.65244
Value Function Loss: 0.08474

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.56011
Value Function Update Magnitude: 0.75953

Collected Steps per Second: 22,960.49874
Overall Steps per Second: 10,800.41486

Timestep Collection Time: 2.17844
Timestep Consumption Time: 2.45268
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.63112

Cumulative Model Updates: 98,140
Cumulative Timesteps: 818,465,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 818465658...
Checkpoint 818465658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,493.76163
Policy Entropy: 3.64855
Value Function Loss: 0.08445

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.57402
Value Function Update Magnitude: 0.75553

Collected Steps per Second: 22,413.53149
Overall Steps per Second: 10,680.29110

Timestep Collection Time: 2.23088
Timestep Consumption Time: 2.45082
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.68171

Cumulative Model Updates: 98,146
Cumulative Timesteps: 818,515,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,144.11808
Policy Entropy: 3.64666
Value Function Loss: 0.08550

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.57978
Value Function Update Magnitude: 0.75478

Collected Steps per Second: 22,815.55978
Overall Steps per Second: 10,679.97286

Timestep Collection Time: 2.19210
Timestep Consumption Time: 2.49087
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.68297

Cumulative Model Updates: 98,152
Cumulative Timesteps: 818,565,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 818565674...
Checkpoint 818565674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.40790
Policy Entropy: 3.64391
Value Function Loss: 0.08224

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10596
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.80334

Collected Steps per Second: 23,222.66476
Overall Steps per Second: 11,018.63122

Timestep Collection Time: 2.15376
Timestep Consumption Time: 2.38546
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.53922

Cumulative Model Updates: 98,158
Cumulative Timesteps: 818,615,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,649.79085
Policy Entropy: 3.66614
Value Function Loss: 0.07778

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.56226
Value Function Update Magnitude: 0.86790

Collected Steps per Second: 22,932.59628
Overall Steps per Second: 10,805.68186

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62979

Cumulative Model Updates: 98,164
Cumulative Timesteps: 818,665,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 818665718...
Checkpoint 818665718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,634.82958
Policy Entropy: 3.66852
Value Function Loss: 0.07447

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.88186

Collected Steps per Second: 22,842.60957
Overall Steps per Second: 10,737.89421

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.65752

Cumulative Model Updates: 98,170
Cumulative Timesteps: 818,715,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,726.59167
Policy Entropy: 3.66669
Value Function Loss: 0.07422

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.59091
Value Function Update Magnitude: 0.89961

Collected Steps per Second: 22,619.79533
Overall Steps per Second: 10,777.10524

Timestep Collection Time: 2.21072
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.64002

Cumulative Model Updates: 98,176
Cumulative Timesteps: 818,765,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 818765736...
Checkpoint 818765736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.78868
Policy Entropy: 3.65297
Value Function Loss: 0.07525

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.62393
Value Function Update Magnitude: 0.90323

Collected Steps per Second: 22,384.93424
Overall Steps per Second: 10,692.79126

Timestep Collection Time: 2.23490
Timestep Consumption Time: 2.44377
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.67867

Cumulative Model Updates: 98,182
Cumulative Timesteps: 818,815,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.46219
Policy Entropy: 3.64818
Value Function Loss: 0.07584

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.55397
Value Function Update Magnitude: 0.85373

Collected Steps per Second: 22,332.02532
Overall Steps per Second: 10,539.82918

Timestep Collection Time: 2.23894
Timestep Consumption Time: 2.50497
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.74391

Cumulative Model Updates: 98,188
Cumulative Timesteps: 818,865,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 818865764...
Checkpoint 818865764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.65541
Policy Entropy: 3.63519
Value Function Loss: 0.07773

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.76458

Collected Steps per Second: 22,673.75672
Overall Steps per Second: 10,628.49269

Timestep Collection Time: 2.20660
Timestep Consumption Time: 2.50074
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.70735

Cumulative Model Updates: 98,194
Cumulative Timesteps: 818,915,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,491.01301
Policy Entropy: 3.63939
Value Function Loss: 0.07992

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06756
Policy Update Magnitude: 0.63348
Value Function Update Magnitude: 0.78303

Collected Steps per Second: 23,459.65661
Overall Steps per Second: 10,909.28226

Timestep Collection Time: 2.13149
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.58362

Cumulative Model Updates: 98,200
Cumulative Timesteps: 818,965,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 818965800...
Checkpoint 818965800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,816.07590
Policy Entropy: 3.64203
Value Function Loss: 0.07974

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.62369
Value Function Update Magnitude: 0.88495

Collected Steps per Second: 22,836.45773
Overall Steps per Second: 10,752.67014

Timestep Collection Time: 2.19001
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.65112

Cumulative Model Updates: 98,206
Cumulative Timesteps: 819,015,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,256.11107
Policy Entropy: 3.65242
Value Function Loss: 0.08003

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.57677
Value Function Update Magnitude: 0.78466

Collected Steps per Second: 23,023.39213
Overall Steps per Second: 10,711.85715

Timestep Collection Time: 2.17283
Timestep Consumption Time: 2.49732
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.67015

Cumulative Model Updates: 98,212
Cumulative Timesteps: 819,065,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 819065838...
Checkpoint 819065838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.07534
Policy Entropy: 3.65182
Value Function Loss: 0.07761

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.61284
Value Function Update Magnitude: 0.77224

Collected Steps per Second: 23,001.73676
Overall Steps per Second: 10,688.72096

Timestep Collection Time: 2.17462
Timestep Consumption Time: 2.50508
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.67970

Cumulative Model Updates: 98,218
Cumulative Timesteps: 819,115,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,375.77691
Policy Entropy: 3.64303
Value Function Loss: 0.07996

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.67704
Value Function Update Magnitude: 0.69259

Collected Steps per Second: 22,839.14577
Overall Steps per Second: 10,817.56935

Timestep Collection Time: 2.19045
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.62470

Cumulative Model Updates: 98,224
Cumulative Timesteps: 819,165,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 819165886...
Checkpoint 819165886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,892.49630
Policy Entropy: 3.63206
Value Function Loss: 0.08136

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.16585
Policy Update Magnitude: 0.63769
Value Function Update Magnitude: 0.70930

Collected Steps per Second: 22,759.28144
Overall Steps per Second: 10,709.25624

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.47284
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.67054

Cumulative Model Updates: 98,230
Cumulative Timesteps: 819,215,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,532.90218
Policy Entropy: 3.64234
Value Function Loss: 0.08295

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.44181
Value Function Update Magnitude: 0.67880

Collected Steps per Second: 22,435.35888
Overall Steps per Second: 10,574.34861

Timestep Collection Time: 2.22996
Timestep Consumption Time: 2.50130
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.73126

Cumulative Model Updates: 98,236
Cumulative Timesteps: 819,265,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 819265934...
Checkpoint 819265934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.87633
Policy Entropy: 3.64830
Value Function Loss: 0.07720

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.42549
Value Function Update Magnitude: 0.73862

Collected Steps per Second: 22,312.68371
Overall Steps per Second: 10,540.94664

Timestep Collection Time: 2.24213
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.74606

Cumulative Model Updates: 98,242
Cumulative Timesteps: 819,315,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,076.52722
Policy Entropy: 3.65380
Value Function Loss: 0.07589

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.58013
Value Function Update Magnitude: 0.79518

Collected Steps per Second: 22,723.79146
Overall Steps per Second: 10,816.31408

Timestep Collection Time: 2.20139
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.62487

Cumulative Model Updates: 98,248
Cumulative Timesteps: 819,365,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 819365986...
Checkpoint 819365986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,941.91325
Policy Entropy: 3.65374
Value Function Loss: 0.07627

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.60597
Value Function Update Magnitude: 0.80862

Collected Steps per Second: 22,233.90890
Overall Steps per Second: 10,687.41820

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.43152
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.68214

Cumulative Model Updates: 98,254
Cumulative Timesteps: 819,416,026

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,720.72478
Policy Entropy: 3.65591
Value Function Loss: 0.07593

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.63151
Value Function Update Magnitude: 0.79644

Collected Steps per Second: 22,493.50101
Overall Steps per Second: 10,582.82201

Timestep Collection Time: 2.22358
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.72615

Cumulative Model Updates: 98,260
Cumulative Timesteps: 819,466,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 819466042...
Checkpoint 819466042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,081.92354
Policy Entropy: 3.65388
Value Function Loss: 0.07610

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.68003
Value Function Update Magnitude: 0.81583

Collected Steps per Second: 22,870.77041
Overall Steps per Second: 10,640.21936

Timestep Collection Time: 2.18733
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.70159

Cumulative Model Updates: 98,266
Cumulative Timesteps: 819,516,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,974.32476
Policy Entropy: 3.65330
Value Function Loss: 0.07493

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.82128

Collected Steps per Second: 23,205.97905
Overall Steps per Second: 10,778.14853

Timestep Collection Time: 2.15479
Timestep Consumption Time: 2.48460
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.63939

Cumulative Model Updates: 98,272
Cumulative Timesteps: 819,566,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 819566072...
Checkpoint 819566072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,312.94394
Policy Entropy: 3.64585
Value Function Loss: 0.08055

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.51139
Value Function Update Magnitude: 0.70891

Collected Steps per Second: 21,592.31956
Overall Steps per Second: 10,388.28911

Timestep Collection Time: 2.31564
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.81311

Cumulative Model Updates: 98,278
Cumulative Timesteps: 819,616,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,428.03324
Policy Entropy: 3.64861
Value Function Loss: 0.08386

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.50238
Value Function Update Magnitude: 0.66914

Collected Steps per Second: 22,631.12167
Overall Steps per Second: 10,809.78066

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.41745
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.62803

Cumulative Model Updates: 98,284
Cumulative Timesteps: 819,666,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 819666100...
Checkpoint 819666100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,755.56801
Policy Entropy: 3.64457
Value Function Loss: 0.08727

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.51874
Value Function Update Magnitude: 0.70866

Collected Steps per Second: 22,562.61701
Overall Steps per Second: 10,582.14784

Timestep Collection Time: 2.21650
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.72588

Cumulative Model Updates: 98,290
Cumulative Timesteps: 819,716,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,590.48926
Policy Entropy: 3.64266
Value Function Loss: 0.08467

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.51911
Value Function Update Magnitude: 0.71427

Collected Steps per Second: 22,919.86045
Overall Steps per Second: 10,811.45529

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.62639

Cumulative Model Updates: 98,296
Cumulative Timesteps: 819,766,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 819766128...
Checkpoint 819766128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,540.69340
Policy Entropy: 3.64636
Value Function Loss: 0.08402

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.53246
Value Function Update Magnitude: 0.66236

Collected Steps per Second: 22,581.36413
Overall Steps per Second: 10,760.93955

Timestep Collection Time: 2.21510
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.64829

Cumulative Model Updates: 98,302
Cumulative Timesteps: 819,816,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,592.78592
Policy Entropy: 3.65084
Value Function Loss: 0.08223

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.50088
Value Function Update Magnitude: 0.58609

Collected Steps per Second: 22,904.56251
Overall Steps per Second: 10,809.56374

Timestep Collection Time: 2.18350
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62664

Cumulative Model Updates: 98,308
Cumulative Timesteps: 819,866,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 819866160...
Checkpoint 819866160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,107.53939
Policy Entropy: 3.65522
Value Function Loss: 0.08347

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.48968
Value Function Update Magnitude: 0.58816

Collected Steps per Second: 22,679.75426
Overall Steps per Second: 10,713.56278

Timestep Collection Time: 2.20531
Timestep Consumption Time: 2.46316
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.66848

Cumulative Model Updates: 98,314
Cumulative Timesteps: 819,916,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,852.11348
Policy Entropy: 3.65640
Value Function Loss: 0.08216

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.49229
Value Function Update Magnitude: 0.63219

Collected Steps per Second: 22,634.33367
Overall Steps per Second: 10,809.84933

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.41773
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62800

Cumulative Model Updates: 98,320
Cumulative Timesteps: 819,966,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 819966204...
Checkpoint 819966204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,574.89579
Policy Entropy: 3.64745
Value Function Loss: 0.08159

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.53394
Value Function Update Magnitude: 0.62943

Collected Steps per Second: 22,678.15985
Overall Steps per Second: 10,757.56795

Timestep Collection Time: 2.20591
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.65031

Cumulative Model Updates: 98,326
Cumulative Timesteps: 820,016,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,340.02034
Policy Entropy: 3.65219
Value Function Loss: 0.08282

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.58883

Collected Steps per Second: 22,751.14018
Overall Steps per Second: 10,793.79268

Timestep Collection Time: 2.19822
Timestep Consumption Time: 2.43518
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.63340

Cumulative Model Updates: 98,332
Cumulative Timesteps: 820,066,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 820066242...
Checkpoint 820066242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.11278
Policy Entropy: 3.64752
Value Function Loss: 0.08264

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14183
Policy Update Magnitude: 0.50996
Value Function Update Magnitude: 0.58073

Collected Steps per Second: 22,104.57856
Overall Steps per Second: 10,661.33408

Timestep Collection Time: 2.26333
Timestep Consumption Time: 2.42933
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.69266

Cumulative Model Updates: 98,338
Cumulative Timesteps: 820,116,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,288.99143
Policy Entropy: 3.65481
Value Function Loss: 0.08123

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.46244
Value Function Update Magnitude: 0.60522

Collected Steps per Second: 22,485.41685
Overall Steps per Second: 10,556.85433

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.51310
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.73721

Cumulative Model Updates: 98,344
Cumulative Timesteps: 820,166,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 820166282...
Checkpoint 820166282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,021.44494
Policy Entropy: 3.65916
Value Function Loss: 0.08236

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.45403
Value Function Update Magnitude: 0.69744

Collected Steps per Second: 22,284.51381
Overall Steps per Second: 10,615.90258

Timestep Collection Time: 2.24407
Timestep Consumption Time: 2.46660
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.71067

Cumulative Model Updates: 98,350
Cumulative Timesteps: 820,216,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,285.84685
Policy Entropy: 3.64768
Value Function Loss: 0.08134

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.52092
Value Function Update Magnitude: 0.70827

Collected Steps per Second: 22,344.48137
Overall Steps per Second: 10,546.02052

Timestep Collection Time: 2.23778
Timestep Consumption Time: 2.50354
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.74131

Cumulative Model Updates: 98,356
Cumulative Timesteps: 820,266,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 820266292...
Checkpoint 820266292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.13885
Policy Entropy: 3.64937
Value Function Loss: 0.08063

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.68902

Collected Steps per Second: 22,560.74463
Overall Steps per Second: 10,501.22219

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.54654
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.76402

Cumulative Model Updates: 98,362
Cumulative Timesteps: 820,316,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,922.82128
Policy Entropy: 3.64719
Value Function Loss: 0.07938

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.66825
Value Function Update Magnitude: 0.70944

Collected Steps per Second: 22,820.70564
Overall Steps per Second: 10,832.52376

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.61795

Cumulative Model Updates: 98,368
Cumulative Timesteps: 820,366,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 820366344...
Checkpoint 820366344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,607.86459
Policy Entropy: 3.65078
Value Function Loss: 0.08006

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.73641
Value Function Update Magnitude: 0.75705

Collected Steps per Second: 22,749.33338
Overall Steps per Second: 10,728.14057

Timestep Collection Time: 2.19787
Timestep Consumption Time: 2.46277
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.66064

Cumulative Model Updates: 98,374
Cumulative Timesteps: 820,416,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,187.73579
Policy Entropy: 3.65540
Value Function Loss: 0.08163

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.63177
Value Function Update Magnitude: 0.72595

Collected Steps per Second: 23,057.00368
Overall Steps per Second: 10,846.31584

Timestep Collection Time: 2.16897
Timestep Consumption Time: 2.44181
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61078

Cumulative Model Updates: 98,380
Cumulative Timesteps: 820,466,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 820466354...
Checkpoint 820466354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.32331
Policy Entropy: 3.64604
Value Function Loss: 0.08395

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.53360
Value Function Update Magnitude: 0.68623

Collected Steps per Second: 22,731.28829
Overall Steps per Second: 10,694.61444

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.67600

Cumulative Model Updates: 98,386
Cumulative Timesteps: 820,516,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,253.78431
Policy Entropy: 3.63993
Value Function Loss: 0.08395

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.71000

Collected Steps per Second: 22,748.72497
Overall Steps per Second: 10,830.03794

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.41954
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.61808

Cumulative Model Updates: 98,392
Cumulative Timesteps: 820,566,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 820566376...
Checkpoint 820566376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,045.47965
Policy Entropy: 3.63559
Value Function Loss: 0.08631

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.72928

Collected Steps per Second: 22,450.68029
Overall Steps per Second: 10,784.80811

Timestep Collection Time: 2.22826
Timestep Consumption Time: 2.41030
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.63856

Cumulative Model Updates: 98,398
Cumulative Timesteps: 820,616,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,671.21780
Policy Entropy: 3.63790
Value Function Loss: 0.08706

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.53158
Value Function Update Magnitude: 0.68269

Collected Steps per Second: 22,470.40216
Overall Steps per Second: 10,766.71525

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.64654

Cumulative Model Updates: 98,404
Cumulative Timesteps: 820,666,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 820666430...
Checkpoint 820666430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,801.58233
Policy Entropy: 3.64583
Value Function Loss: 0.08580

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.52608
Value Function Update Magnitude: 0.62412

Collected Steps per Second: 22,457.31713
Overall Steps per Second: 10,757.59143

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.42173
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.64844

Cumulative Model Updates: 98,410
Cumulative Timesteps: 820,716,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,798.05787
Policy Entropy: 3.65187
Value Function Loss: 0.08896

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.55593
Value Function Update Magnitude: 0.63026

Collected Steps per Second: 22,818.89647
Overall Steps per Second: 10,831.28628

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61810

Cumulative Model Updates: 98,416
Cumulative Timesteps: 820,766,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 820766456...
Checkpoint 820766456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,094.17792
Policy Entropy: 3.64835
Value Function Loss: 0.08912

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.58235
Value Function Update Magnitude: 0.68503

Collected Steps per Second: 21,779.86601
Overall Steps per Second: 10,429.12886

Timestep Collection Time: 2.29689
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.79676

Cumulative Model Updates: 98,422
Cumulative Timesteps: 820,816,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,512.52028
Policy Entropy: 3.63017
Value Function Loss: 0.09375

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.63099
Value Function Update Magnitude: 0.75703

Collected Steps per Second: 23,014.05841
Overall Steps per Second: 10,710.62961

Timestep Collection Time: 2.17302
Timestep Consumption Time: 2.49617
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.66919

Cumulative Model Updates: 98,428
Cumulative Timesteps: 820,866,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 820866492...
Checkpoint 820866492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.17148
Policy Entropy: 3.62952
Value Function Loss: 0.09398

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.66697
Value Function Update Magnitude: 0.68591

Collected Steps per Second: 22,872.02010
Overall Steps per Second: 10,698.70539

Timestep Collection Time: 2.18643
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.67421

Cumulative Model Updates: 98,434
Cumulative Timesteps: 820,916,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,998.49672
Policy Entropy: 3.63029
Value Function Loss: 0.09567

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.73305
Value Function Update Magnitude: 0.61179

Collected Steps per Second: 22,938.62823
Overall Steps per Second: 10,857.62377

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60672

Cumulative Model Updates: 98,440
Cumulative Timesteps: 820,966,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 820966518...
Checkpoint 820966518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,194.53974
Policy Entropy: 3.62978
Value Function Loss: 0.09266

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.75458
Value Function Update Magnitude: 0.72545

Collected Steps per Second: 22,945.40433
Overall Steps per Second: 10,681.32142

Timestep Collection Time: 2.17978
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.68257

Cumulative Model Updates: 98,446
Cumulative Timesteps: 821,016,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,909.12474
Policy Entropy: 3.63723
Value Function Loss: 0.08820

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.60137
Value Function Update Magnitude: 0.85341

Collected Steps per Second: 22,679.31217
Overall Steps per Second: 10,791.76970

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.63316

Cumulative Model Updates: 98,452
Cumulative Timesteps: 821,066,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 821066534...
Checkpoint 821066534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,704.33153
Policy Entropy: 3.64955
Value Function Loss: 0.08468

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.61402
Value Function Update Magnitude: 0.80748

Collected Steps per Second: 22,576.84920
Overall Steps per Second: 10,774.68944

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.64069

Cumulative Model Updates: 98,458
Cumulative Timesteps: 821,116,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,547.49856
Policy Entropy: 3.65143
Value Function Loss: 0.08501

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.58542
Value Function Update Magnitude: 0.79181

Collected Steps per Second: 22,309.33009
Overall Steps per Second: 10,613.67887

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.71297

Cumulative Model Updates: 98,464
Cumulative Timesteps: 821,166,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 821166558...
Checkpoint 821166558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,347.75873
Policy Entropy: 3.65330
Value Function Loss: 0.08343

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.69284
Value Function Update Magnitude: 0.87816

Collected Steps per Second: 22,552.41540
Overall Steps per Second: 10,803.99394

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.41154
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.62921

Cumulative Model Updates: 98,470
Cumulative Timesteps: 821,216,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,242.52284
Policy Entropy: 3.65911
Value Function Loss: 0.08144

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.66185
Value Function Update Magnitude: 0.89538

Collected Steps per Second: 22,609.48512
Overall Steps per Second: 10,672.23246

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.47488
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.68749

Cumulative Model Updates: 98,476
Cumulative Timesteps: 821,266,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 821266598...
Checkpoint 821266598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,502.12547
Policy Entropy: 3.66441
Value Function Loss: 0.07990

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.70971
Value Function Update Magnitude: 0.89459

Collected Steps per Second: 22,296.75481
Overall Steps per Second: 10,506.12250

Timestep Collection Time: 2.24257
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.75932

Cumulative Model Updates: 98,482
Cumulative Timesteps: 821,316,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.30053
Policy Entropy: 3.66385
Value Function Loss: 0.08200

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.62035
Value Function Update Magnitude: 0.87812

Collected Steps per Second: 22,793.48861
Overall Steps per Second: 10,602.71741

Timestep Collection Time: 2.19475
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.71822

Cumulative Model Updates: 98,488
Cumulative Timesteps: 821,366,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 821366626...
Checkpoint 821366626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,897.77942
Policy Entropy: 3.65496
Value Function Loss: 0.08191

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.70943
Value Function Update Magnitude: 0.86887

Collected Steps per Second: 22,708.16606
Overall Steps per Second: 10,628.59939

Timestep Collection Time: 2.20247
Timestep Consumption Time: 2.50314
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.70561

Cumulative Model Updates: 98,494
Cumulative Timesteps: 821,416,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,103.62824
Policy Entropy: 3.65065
Value Function Loss: 0.08314

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.80677
Value Function Update Magnitude: 0.87064

Collected Steps per Second: 23,157.85526
Overall Steps per Second: 10,768.85898

Timestep Collection Time: 2.15979
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.64450

Cumulative Model Updates: 98,500
Cumulative Timesteps: 821,466,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 821466656...
Checkpoint 821466656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,934.97602
Policy Entropy: 3.64911
Value Function Loss: 0.08607

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.80079
Value Function Update Magnitude: 0.83125

Collected Steps per Second: 22,457.17098
Overall Steps per Second: 10,673.17931

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.45916
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.68651

Cumulative Model Updates: 98,506
Cumulative Timesteps: 821,516,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,201.20563
Policy Entropy: 3.63117
Value Function Loss: 0.08933

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.69318
Value Function Update Magnitude: 0.77755

Collected Steps per Second: 22,880.26663
Overall Steps per Second: 10,843.81413

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61221

Cumulative Model Updates: 98,512
Cumulative Timesteps: 821,566,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 821566690...
Checkpoint 821566690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.68798
Policy Entropy: 3.63525
Value Function Loss: 0.08938

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.72856
Value Function Update Magnitude: 0.68484

Collected Steps per Second: 22,558.37402
Overall Steps per Second: 10,685.73738

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.68007

Cumulative Model Updates: 98,518
Cumulative Timesteps: 821,616,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,921.39285
Policy Entropy: 3.62460
Value Function Loss: 0.08969

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.69049
Value Function Update Magnitude: 0.60497

Collected Steps per Second: 22,802.05289
Overall Steps per Second: 10,818.49810

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62301

Cumulative Model Updates: 98,524
Cumulative Timesteps: 821,666,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 821666714...
Checkpoint 821666714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,028.15837
Policy Entropy: 3.63534
Value Function Loss: 0.09032

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.65714

Collected Steps per Second: 22,266.07708
Overall Steps per Second: 10,685.74590

Timestep Collection Time: 2.24620
Timestep Consumption Time: 2.43424
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.68044

Cumulative Model Updates: 98,530
Cumulative Timesteps: 821,716,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,778.89168
Policy Entropy: 3.63707
Value Function Loss: 0.09163

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.53577
Value Function Update Magnitude: 0.71278

Collected Steps per Second: 22,279.73665
Overall Steps per Second: 10,556.30610

Timestep Collection Time: 2.24446
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.73707

Cumulative Model Updates: 98,536
Cumulative Timesteps: 821,766,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 821766734...
Checkpoint 821766734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,518.45803
Policy Entropy: 3.64217
Value Function Loss: 0.08991

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.50706
Value Function Update Magnitude: 0.73273

Collected Steps per Second: 22,248.58960
Overall Steps per Second: 10,576.69258

Timestep Collection Time: 2.24823
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.72927

Cumulative Model Updates: 98,542
Cumulative Timesteps: 821,816,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,900.86146
Policy Entropy: 3.62970
Value Function Loss: 0.08883

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.50620
Value Function Update Magnitude: 0.79201

Collected Steps per Second: 22,657.83386
Overall Steps per Second: 10,653.97404

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.69421

Cumulative Model Updates: 98,548
Cumulative Timesteps: 821,866,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 821866766...
Checkpoint 821866766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,535.92196
Policy Entropy: 3.63308
Value Function Loss: 0.08544

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.47824
Value Function Update Magnitude: 0.85340

Collected Steps per Second: 22,832.97819
Overall Steps per Second: 10,601.43059

Timestep Collection Time: 2.19078
Timestep Consumption Time: 2.52764
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.71842

Cumulative Model Updates: 98,554
Cumulative Timesteps: 821,916,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,597.04847
Policy Entropy: 3.63711
Value Function Loss: 0.08541

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.71625

Collected Steps per Second: 23,462.57518
Overall Steps per Second: 10,801.27251

Timestep Collection Time: 2.13131
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.62964

Cumulative Model Updates: 98,560
Cumulative Timesteps: 821,966,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 821966794...
Checkpoint 821966794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.33648
Policy Entropy: 3.64393
Value Function Loss: 0.08859

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.51024
Value Function Update Magnitude: 0.64490

Collected Steps per Second: 22,503.13453
Overall Steps per Second: 10,599.10047

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.71965

Cumulative Model Updates: 98,566
Cumulative Timesteps: 822,016,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,872.68834
Policy Entropy: 3.64146
Value Function Loss: 0.09030

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.69570

Collected Steps per Second: 23,224.36649
Overall Steps per Second: 10,919.35434

Timestep Collection Time: 2.15472
Timestep Consumption Time: 2.42815
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.58287

Cumulative Model Updates: 98,572
Cumulative Timesteps: 822,066,860

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 822066860...
Checkpoint 822066860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.93660
Policy Entropy: 3.62691
Value Function Loss: 0.08994

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.78878

Collected Steps per Second: 22,539.48128
Overall Steps per Second: 10,568.53886

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.51279
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.73121

Cumulative Model Updates: 98,578
Cumulative Timesteps: 822,116,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,587.81961
Policy Entropy: 3.61633
Value Function Loss: 0.08817

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.84736

Collected Steps per Second: 22,967.96869
Overall Steps per Second: 10,869.40997

Timestep Collection Time: 2.17694
Timestep Consumption Time: 2.42312
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.60007

Cumulative Model Updates: 98,584
Cumulative Timesteps: 822,166,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 822166862...
Checkpoint 822166862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,968.81702
Policy Entropy: 3.61691
Value Function Loss: 0.08988

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.50746
Value Function Update Magnitude: 0.83825

Collected Steps per Second: 22,605.53109
Overall Steps per Second: 10,802.93345

Timestep Collection Time: 2.21238
Timestep Consumption Time: 2.41710
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.62948

Cumulative Model Updates: 98,590
Cumulative Timesteps: 822,216,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,768.29335
Policy Entropy: 3.62523
Value Function Loss: 0.09017

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.74424

Collected Steps per Second: 22,333.75257
Overall Steps per Second: 10,586.86535

Timestep Collection Time: 2.23957
Timestep Consumption Time: 2.48496
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.72453

Cumulative Model Updates: 98,596
Cumulative Timesteps: 822,266,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 822266892...
Checkpoint 822266892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.03839
Policy Entropy: 3.63514
Value Function Loss: 0.09550

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.50333
Value Function Update Magnitude: 0.55762

Collected Steps per Second: 22,452.04226
Overall Steps per Second: 10,639.72671

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.47289
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.70031

Cumulative Model Updates: 98,602
Cumulative Timesteps: 822,316,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,761.00002
Policy Entropy: 3.64489
Value Function Loss: 0.09138

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.56699

Collected Steps per Second: 22,735.98023
Overall Steps per Second: 10,685.38111

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.48112
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.68116

Cumulative Model Updates: 98,608
Cumulative Timesteps: 822,366,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 822366922...
Checkpoint 822366922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,742.16769
Policy Entropy: 3.64749
Value Function Loss: 0.09157

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.59321

Collected Steps per Second: 22,485.11804
Overall Steps per Second: 10,667.80238

Timestep Collection Time: 2.22440
Timestep Consumption Time: 2.46410
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.68850

Cumulative Model Updates: 98,614
Cumulative Timesteps: 822,416,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,327.40548
Policy Entropy: 3.65134
Value Function Loss: 0.08549

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.59248

Collected Steps per Second: 22,914.49552
Overall Steps per Second: 10,651.17129

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.51340
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.69638

Cumulative Model Updates: 98,620
Cumulative Timesteps: 822,466,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 822466960...
Checkpoint 822466960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,600.60485
Policy Entropy: 3.64600
Value Function Loss: 0.08412

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.53674
Value Function Update Magnitude: 0.66745

Collected Steps per Second: 23,071.53573
Overall Steps per Second: 10,872.18573

Timestep Collection Time: 2.16847
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.60165

Cumulative Model Updates: 98,626
Cumulative Timesteps: 822,516,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.91562
Policy Entropy: 3.64329
Value Function Loss: 0.08331

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.50603
Value Function Update Magnitude: 0.76361

Collected Steps per Second: 22,831.68509
Overall Steps per Second: 10,843.16681

Timestep Collection Time: 2.19011
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61157

Cumulative Model Updates: 98,632
Cumulative Timesteps: 822,566,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 822566994...
Checkpoint 822566994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,944.11429
Policy Entropy: 3.64415
Value Function Loss: 0.08363

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.81094

Collected Steps per Second: 22,124.63076
Overall Steps per Second: 10,728.75291

Timestep Collection Time: 2.26056
Timestep Consumption Time: 2.40112
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.66168

Cumulative Model Updates: 98,638
Cumulative Timesteps: 822,617,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,012.82712
Policy Entropy: 3.65039
Value Function Loss: 0.08511

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.75664

Collected Steps per Second: 22,305.69839
Overall Steps per Second: 10,873.75987

Timestep Collection Time: 2.24248
Timestep Consumption Time: 2.35759
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60006

Cumulative Model Updates: 98,644
Cumulative Timesteps: 822,667,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 822667028...
Checkpoint 822667028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,909.51184
Policy Entropy: 3.64510
Value Function Loss: 0.08595

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.56178
Value Function Update Magnitude: 0.68727

Collected Steps per Second: 21,957.93071
Overall Steps per Second: 10,656.37082

Timestep Collection Time: 2.27763
Timestep Consumption Time: 2.41553
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.69315

Cumulative Model Updates: 98,650
Cumulative Timesteps: 822,717,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,872.93674
Policy Entropy: 3.65559
Value Function Loss: 0.08875

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.58977
Value Function Update Magnitude: 0.58541

Collected Steps per Second: 21,680.91142
Overall Steps per Second: 10,580.98221

Timestep Collection Time: 2.30655
Timestep Consumption Time: 2.41967
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.72622

Cumulative Model Updates: 98,656
Cumulative Timesteps: 822,767,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 822767048...
Checkpoint 822767048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.73828
Policy Entropy: 3.65065
Value Function Loss: 0.08734

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.68905
Value Function Update Magnitude: 0.56393

Collected Steps per Second: 21,668.27435
Overall Steps per Second: 10,563.45864

Timestep Collection Time: 2.30891
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.73614

Cumulative Model Updates: 98,662
Cumulative Timesteps: 822,817,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,446.25512
Policy Entropy: 3.64651
Value Function Loss: 0.08513

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.65846
Value Function Update Magnitude: 0.76792

Collected Steps per Second: 21,884.24649
Overall Steps per Second: 10,773.96408

Timestep Collection Time: 2.28502
Timestep Consumption Time: 2.35635
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.64137

Cumulative Model Updates: 98,668
Cumulative Timesteps: 822,867,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 822867084...
Checkpoint 822867084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.24409
Policy Entropy: 3.64960
Value Function Loss: 0.08491

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.64590
Value Function Update Magnitude: 0.81365

Collected Steps per Second: 21,931.15508
Overall Steps per Second: 10,748.15684

Timestep Collection Time: 2.28114
Timestep Consumption Time: 2.37343
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.65457

Cumulative Model Updates: 98,674
Cumulative Timesteps: 822,917,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,882.28173
Policy Entropy: 3.64750
Value Function Loss: 0.08596

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.59470
Value Function Update Magnitude: 0.74142

Collected Steps per Second: 22,098.65752
Overall Steps per Second: 10,670.13081

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.68710

Cumulative Model Updates: 98,680
Cumulative Timesteps: 822,967,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 822967124...
Checkpoint 822967124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,240.53073
Policy Entropy: 3.64726
Value Function Loss: 0.08588

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.62404
Value Function Update Magnitude: 0.83193

Collected Steps per Second: 22,091.71322
Overall Steps per Second: 10,525.81720

Timestep Collection Time: 2.26329
Timestep Consumption Time: 2.48693
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.75022

Cumulative Model Updates: 98,686
Cumulative Timesteps: 823,017,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,635.59208
Policy Entropy: 3.64618
Value Function Loss: 0.08432

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.61475
Value Function Update Magnitude: 0.82471

Collected Steps per Second: 23,006.73963
Overall Steps per Second: 10,758.76414

Timestep Collection Time: 2.17380
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.64849

Cumulative Model Updates: 98,692
Cumulative Timesteps: 823,067,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 823067136...
Checkpoint 823067136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,866.48952
Policy Entropy: 3.65072
Value Function Loss: 0.08667

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.62330
Value Function Update Magnitude: 0.70148

Collected Steps per Second: 22,654.79240
Overall Steps per Second: 10,651.14827

Timestep Collection Time: 2.20916
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.69884

Cumulative Model Updates: 98,698
Cumulative Timesteps: 823,117,184

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,932.86784
Policy Entropy: 3.64656
Value Function Loss: 0.09044

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.62541
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 23,149.17107
Overall Steps per Second: 10,911.53333

Timestep Collection Time: 2.16111
Timestep Consumption Time: 2.42376
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.58487

Cumulative Model Updates: 98,704
Cumulative Timesteps: 823,167,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 823167212...
Checkpoint 823167212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.40650
Policy Entropy: 3.65658
Value Function Loss: 0.09057

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.59944

Collected Steps per Second: 22,786.69262
Overall Steps per Second: 10,730.07541

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.66204

Cumulative Model Updates: 98,710
Cumulative Timesteps: 823,217,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,695.02294
Policy Entropy: 3.64755
Value Function Loss: 0.08937

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.54164
Value Function Update Magnitude: 0.61353

Collected Steps per Second: 22,898.67822
Overall Steps per Second: 10,838.65778

Timestep Collection Time: 2.18449
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.61515

Cumulative Model Updates: 98,716
Cumulative Timesteps: 823,267,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 823267258...
Checkpoint 823267258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.21135
Policy Entropy: 3.63940
Value Function Loss: 0.08833

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.63763

Collected Steps per Second: 22,368.24949
Overall Steps per Second: 10,639.67272

Timestep Collection Time: 2.23558
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.69996

Cumulative Model Updates: 98,722
Cumulative Timesteps: 823,317,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.53224
Policy Entropy: 3.63086
Value Function Loss: 0.08660

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.15088
Policy Update Magnitude: 0.54358
Value Function Update Magnitude: 0.63939

Collected Steps per Second: 22,601.97113
Overall Steps per Second: 10,832.73950

Timestep Collection Time: 2.21246
Timestep Consumption Time: 2.40373
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.61619

Cumulative Model Updates: 98,728
Cumulative Timesteps: 823,367,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 823367270...
Checkpoint 823367270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,868.44965
Policy Entropy: 3.63453
Value Function Loss: 0.08890

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.44682
Value Function Update Magnitude: 0.63244

Collected Steps per Second: 22,158.71824
Overall Steps per Second: 10,656.94175

Timestep Collection Time: 2.25753
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.69403

Cumulative Model Updates: 98,734
Cumulative Timesteps: 823,417,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,038.90306
Policy Entropy: 3.63784
Value Function Loss: 0.08863

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.43932
Value Function Update Magnitude: 0.60625

Collected Steps per Second: 22,540.66152
Overall Steps per Second: 10,568.55222

Timestep Collection Time: 2.21848
Timestep Consumption Time: 2.51310
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.73158

Cumulative Model Updates: 98,740
Cumulative Timesteps: 823,467,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 823467300...
Checkpoint 823467300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,404.79523
Policy Entropy: 3.63466
Value Function Loss: 0.08736

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.48305
Value Function Update Magnitude: 0.58292

Collected Steps per Second: 22,643.16772
Overall Steps per Second: 10,549.61975

Timestep Collection Time: 2.20914
Timestep Consumption Time: 2.53245
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.74159

Cumulative Model Updates: 98,746
Cumulative Timesteps: 823,517,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,078.66828
Policy Entropy: 3.63384
Value Function Loss: 0.08775

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.54308
Value Function Update Magnitude: 0.60538

Collected Steps per Second: 23,101.37241
Overall Steps per Second: 10,868.88834

Timestep Collection Time: 2.16533
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.60231

Cumulative Model Updates: 98,752
Cumulative Timesteps: 823,567,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 823567344...
Checkpoint 823567344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,481.33350
Policy Entropy: 3.64061
Value Function Loss: 0.08709

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.57551

Collected Steps per Second: 22,673.09004
Overall Steps per Second: 10,720.68506

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.45941
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.66537

Cumulative Model Updates: 98,758
Cumulative Timesteps: 823,617,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,473.41847
Policy Entropy: 3.64323
Value Function Loss: 0.08597

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.52970
Value Function Update Magnitude: 0.59488

Collected Steps per Second: 23,108.53571
Overall Steps per Second: 10,859.43000

Timestep Collection Time: 2.16379
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60448

Cumulative Model Updates: 98,764
Cumulative Timesteps: 823,667,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 823667362...
Checkpoint 823667362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,256.70238
Policy Entropy: 3.64826
Value Function Loss: 0.08642

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.49969
Value Function Update Magnitude: 0.59110

Collected Steps per Second: 22,206.12551
Overall Steps per Second: 10,695.91503

Timestep Collection Time: 2.25208
Timestep Consumption Time: 2.42354
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.67562

Cumulative Model Updates: 98,770
Cumulative Timesteps: 823,717,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,363.34556
Policy Entropy: 3.63880
Value Function Loss: 0.08488

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.49537
Value Function Update Magnitude: 0.58118

Collected Steps per Second: 23,225.56088
Overall Steps per Second: 10,923.83060

Timestep Collection Time: 2.15323
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.57806

Cumulative Model Updates: 98,776
Cumulative Timesteps: 823,767,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 823767382...
Checkpoint 823767382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,406.55225
Policy Entropy: 3.63994
Value Function Loss: 0.08535

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.46678
Value Function Update Magnitude: 0.56485

Collected Steps per Second: 22,301.16681
Overall Steps per Second: 10,629.86284

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.46199
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.70429

Cumulative Model Updates: 98,782
Cumulative Timesteps: 823,817,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,965.47181
Policy Entropy: 3.63844
Value Function Loss: 0.08292

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.45284
Value Function Update Magnitude: 0.53885

Collected Steps per Second: 22,770.95667
Overall Steps per Second: 10,819.57467

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.42577
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.62181

Cumulative Model Updates: 98,788
Cumulative Timesteps: 823,867,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 823867394...
Checkpoint 823867394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,819.99759
Policy Entropy: 3.62585
Value Function Loss: 0.08480

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.55724

Collected Steps per Second: 22,361.30037
Overall Steps per Second: 10,739.58000

Timestep Collection Time: 2.23618
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.65605

Cumulative Model Updates: 98,794
Cumulative Timesteps: 823,917,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,667.95590
Policy Entropy: 3.62899
Value Function Loss: 0.08386

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.68633
Value Function Update Magnitude: 0.53764

Collected Steps per Second: 23,212.99229
Overall Steps per Second: 10,827.24406

Timestep Collection Time: 2.15431
Timestep Consumption Time: 2.46441
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.61872

Cumulative Model Updates: 98,800
Cumulative Timesteps: 823,967,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 823967406...
Checkpoint 823967406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,368.62110
Policy Entropy: 3.62194
Value Function Loss: 0.08678

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.73908
Value Function Update Magnitude: 0.72788

Collected Steps per Second: 22,400.00946
Overall Steps per Second: 10,725.82854

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.42960
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.66183

Cumulative Model Updates: 98,806
Cumulative Timesteps: 824,017,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,012.81471
Policy Entropy: 3.61891
Value Function Loss: 0.08757

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.63385
Value Function Update Magnitude: 0.79195

Collected Steps per Second: 22,105.53643
Overall Steps per Second: 10,783.99827

Timestep Collection Time: 2.26224
Timestep Consumption Time: 2.37500
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.63724

Cumulative Model Updates: 98,812
Cumulative Timesteps: 824,067,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 824067416...
Checkpoint 824067416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,313.72332
Policy Entropy: 3.61303
Value Function Loss: 0.09008

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.70238

Collected Steps per Second: 21,948.31469
Overall Steps per Second: 10,688.31542

Timestep Collection Time: 2.27872
Timestep Consumption Time: 2.40060
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.67932

Cumulative Model Updates: 98,818
Cumulative Timesteps: 824,117,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,350.11115
Policy Entropy: 3.61726
Value Function Loss: 0.08983

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.66030
Value Function Update Magnitude: 0.63982

Collected Steps per Second: 22,342.56238
Overall Steps per Second: 10,879.50849

Timestep Collection Time: 2.23913
Timestep Consumption Time: 2.35924
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59837

Cumulative Model Updates: 98,824
Cumulative Timesteps: 824,167,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 824167458...
Checkpoint 824167458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,900.53818
Policy Entropy: 3.62465
Value Function Loss: 0.08708

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.66884

Collected Steps per Second: 22,119.10586
Overall Steps per Second: 10,711.82910

Timestep Collection Time: 2.26139
Timestep Consumption Time: 2.40821
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.66960

Cumulative Model Updates: 98,830
Cumulative Timesteps: 824,217,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,035.23461
Policy Entropy: 3.61516
Value Function Loss: 0.08653

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.64084

Collected Steps per Second: 22,151.42898
Overall Steps per Second: 10,547.62880

Timestep Collection Time: 2.25809
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.74230

Cumulative Model Updates: 98,836
Cumulative Timesteps: 824,267,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 824267498...
Checkpoint 824267498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,902.16600
Policy Entropy: 3.61657
Value Function Loss: 0.08832

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.56726
Value Function Update Magnitude: 0.60822

Collected Steps per Second: 22,249.58816
Overall Steps per Second: 10,596.07587

Timestep Collection Time: 2.24813
Timestep Consumption Time: 2.47248
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.72062

Cumulative Model Updates: 98,842
Cumulative Timesteps: 824,317,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,122.23808
Policy Entropy: 3.60010
Value Function Loss: 0.09237

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.66912
Value Function Update Magnitude: 0.56495

Collected Steps per Second: 22,798.30395
Overall Steps per Second: 10,864.05431

Timestep Collection Time: 2.19315
Timestep Consumption Time: 2.40919
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.60233

Cumulative Model Updates: 98,848
Cumulative Timesteps: 824,367,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 824367518...
Checkpoint 824367518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,725.37178
Policy Entropy: 3.60754
Value Function Loss: 0.09193

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.68601
Value Function Update Magnitude: 0.54407

Collected Steps per Second: 22,772.39586
Overall Steps per Second: 10,640.97116

Timestep Collection Time: 2.19757
Timestep Consumption Time: 2.50538
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.70295

Cumulative Model Updates: 98,854
Cumulative Timesteps: 824,417,562

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,427.35045
Policy Entropy: 3.62540
Value Function Loss: 0.08885

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.15596
Policy Update Magnitude: 0.56097
Value Function Update Magnitude: 0.54357

Collected Steps per Second: 23,264.14368
Overall Steps per Second: 10,848.96244

Timestep Collection Time: 2.14949
Timestep Consumption Time: 2.45980
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60929

Cumulative Model Updates: 98,860
Cumulative Timesteps: 824,467,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 824467568...
Checkpoint 824467568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,093.25693
Policy Entropy: 3.63876
Value Function Loss: 0.08440

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.59559
Value Function Update Magnitude: 0.56941

Collected Steps per Second: 22,495.03720
Overall Steps per Second: 10,690.55184

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.45451
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.67740

Cumulative Model Updates: 98,866
Cumulative Timesteps: 824,517,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.11591
Policy Entropy: 3.62686
Value Function Loss: 0.08441

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.64892
Value Function Update Magnitude: 0.73219

Collected Steps per Second: 23,202.90452
Overall Steps per Second: 10,935.20584

Timestep Collection Time: 2.15559
Timestep Consumption Time: 2.41826
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.57385

Cumulative Model Updates: 98,872
Cumulative Timesteps: 824,567,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 824567588...
Checkpoint 824567588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,500.14154
Policy Entropy: 3.61713
Value Function Loss: 0.08788

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.59572
Value Function Update Magnitude: 0.78767

Collected Steps per Second: 22,615.99620
Overall Steps per Second: 10,628.22001

Timestep Collection Time: 2.21091
Timestep Consumption Time: 2.49373
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.70464

Cumulative Model Updates: 98,878
Cumulative Timesteps: 824,617,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,376.17520
Policy Entropy: 3.60306
Value Function Loss: 0.09068

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.73229
Value Function Update Magnitude: 0.69530

Collected Steps per Second: 23,013.33031
Overall Steps per Second: 10,862.11626

Timestep Collection Time: 2.17378
Timestep Consumption Time: 2.43176
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60555

Cumulative Model Updates: 98,884
Cumulative Timesteps: 824,667,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 824667616...
Checkpoint 824667616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,638.86146
Policy Entropy: 3.57868
Value Function Loss: 0.09610

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.69175
Value Function Update Magnitude: 0.61799

Collected Steps per Second: 22,231.81907
Overall Steps per Second: 10,680.33216

Timestep Collection Time: 2.24912
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.68169

Cumulative Model Updates: 98,890
Cumulative Timesteps: 824,717,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,558.36930
Policy Entropy: 3.57161
Value Function Loss: 0.09381

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.70562
Value Function Update Magnitude: 0.58748

Collected Steps per Second: 22,650.27806
Overall Steps per Second: 10,635.28169

Timestep Collection Time: 2.20942
Timestep Consumption Time: 2.49605
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.70547

Cumulative Model Updates: 98,896
Cumulative Timesteps: 824,767,662

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 824767662...
Checkpoint 824767662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,730.81734
Policy Entropy: 3.55040
Value Function Loss: 0.09463

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.63662
Value Function Update Magnitude: 0.53966

Collected Steps per Second: 22,084.59495
Overall Steps per Second: 10,495.65456

Timestep Collection Time: 2.26402
Timestep Consumption Time: 2.49985
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.76388

Cumulative Model Updates: 98,902
Cumulative Timesteps: 824,817,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,522.94752
Policy Entropy: 3.57909
Value Function Loss: 0.09418

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.49479

Collected Steps per Second: 22,896.90625
Overall Steps per Second: 10,800.45098

Timestep Collection Time: 2.18492
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.63203

Cumulative Model Updates: 98,908
Cumulative Timesteps: 824,867,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 824867690...
Checkpoint 824867690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,939.38644
Policy Entropy: 3.57206
Value Function Loss: 0.09594

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15748
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.48244

Collected Steps per Second: 22,364.98444
Overall Steps per Second: 10,643.86262

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.69980

Cumulative Model Updates: 98,914
Cumulative Timesteps: 824,917,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,415.63592
Policy Entropy: 3.57861
Value Function Loss: 0.08946

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.47922

Collected Steps per Second: 22,985.47800
Overall Steps per Second: 10,740.78277

Timestep Collection Time: 2.17529
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.65515

Cumulative Model Updates: 98,920
Cumulative Timesteps: 824,967,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 824967714...
Checkpoint 824967714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.26783
Policy Entropy: 3.57471
Value Function Loss: 0.08166

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.59618
Value Function Update Magnitude: 0.47681

Collected Steps per Second: 22,385.94191
Overall Steps per Second: 10,774.05750

Timestep Collection Time: 2.23480
Timestep Consumption Time: 2.40858
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.64338

Cumulative Model Updates: 98,926
Cumulative Timesteps: 825,017,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,872.93304
Policy Entropy: 3.59013
Value Function Loss: 0.07675

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.59638
Value Function Update Magnitude: 0.48998

Collected Steps per Second: 23,061.72479
Overall Steps per Second: 10,745.33112

Timestep Collection Time: 2.16861
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.65430

Cumulative Model Updates: 98,932
Cumulative Timesteps: 825,067,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 825067754...
Checkpoint 825067754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,452.05211
Policy Entropy: 3.58833
Value Function Loss: 0.07776

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.58234
Value Function Update Magnitude: 0.50433

Collected Steps per Second: 22,563.24304
Overall Steps per Second: 10,800.78016

Timestep Collection Time: 2.21732
Timestep Consumption Time: 2.41475
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.63207

Cumulative Model Updates: 98,938
Cumulative Timesteps: 825,117,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,720.76860
Policy Entropy: 3.60459
Value Function Loss: 0.08051

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.50929

Collected Steps per Second: 22,999.42391
Overall Steps per Second: 10,757.51332

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.65015

Cumulative Model Updates: 98,944
Cumulative Timesteps: 825,167,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 825167808...
Checkpoint 825167808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,206.08469
Policy Entropy: 3.58643
Value Function Loss: 0.08184

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.51560
Value Function Update Magnitude: 0.50379

Collected Steps per Second: 22,067.78693
Overall Steps per Second: 10,515.78230

Timestep Collection Time: 2.26665
Timestep Consumption Time: 2.49001
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.75666

Cumulative Model Updates: 98,950
Cumulative Timesteps: 825,217,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,060.86322
Policy Entropy: 3.59189
Value Function Loss: 0.08432

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.51318
Value Function Update Magnitude: 0.50519

Collected Steps per Second: 22,657.73758
Overall Steps per Second: 10,775.43822

Timestep Collection Time: 2.20781
Timestep Consumption Time: 2.43460
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.64241

Cumulative Model Updates: 98,956
Cumulative Timesteps: 825,267,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 825267852...
Checkpoint 825267852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,710.73067
Policy Entropy: 3.58348
Value Function Loss: 0.08453

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.53434
Value Function Update Magnitude: 0.57521

Collected Steps per Second: 22,046.06974
Overall Steps per Second: 10,646.77520

Timestep Collection Time: 2.26870
Timestep Consumption Time: 2.42906
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.69776

Cumulative Model Updates: 98,962
Cumulative Timesteps: 825,317,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,903.52220
Policy Entropy: 3.59138
Value Function Loss: 0.08710

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.47085
Value Function Update Magnitude: 0.59036

Collected Steps per Second: 21,503.36369
Overall Steps per Second: 10,503.72016

Timestep Collection Time: 2.32615
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.76212

Cumulative Model Updates: 98,968
Cumulative Timesteps: 825,367,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 825367888...
Checkpoint 825367888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,158.58977
Policy Entropy: 3.60235
Value Function Loss: 0.08948

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.43250
Value Function Update Magnitude: 0.53291

Collected Steps per Second: 22,579.67710
Overall Steps per Second: 10,615.31677

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.71206

Cumulative Model Updates: 98,974
Cumulative Timesteps: 825,417,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,164.15106
Policy Entropy: 3.60078
Value Function Loss: 0.09019

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.41572
Value Function Update Magnitude: 0.47524

Collected Steps per Second: 23,205.88735
Overall Steps per Second: 10,858.35060

Timestep Collection Time: 2.15488
Timestep Consumption Time: 2.45042
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60530

Cumulative Model Updates: 98,980
Cumulative Timesteps: 825,467,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 825467914...
Checkpoint 825467914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,636.86355
Policy Entropy: 3.60554
Value Function Loss: 0.08756

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.58714

Collected Steps per Second: 22,439.68488
Overall Steps per Second: 10,662.18362

Timestep Collection Time: 2.22953
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.69228

Cumulative Model Updates: 98,986
Cumulative Timesteps: 825,517,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,345.85316
Policy Entropy: 3.61156
Value Function Loss: 0.08666

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.16675
Policy Update Magnitude: 0.55876
Value Function Update Magnitude: 0.59557

Collected Steps per Second: 23,173.21641
Overall Steps per Second: 10,898.67000

Timestep Collection Time: 2.15818
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.58882

Cumulative Model Updates: 98,992
Cumulative Timesteps: 825,567,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 825567956...
Checkpoint 825567956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,138.33952
Policy Entropy: 3.61802
Value Function Loss: 0.08584

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.40409
Value Function Update Magnitude: 0.59048

Collected Steps per Second: 22,245.78075
Overall Steps per Second: 10,694.70318

Timestep Collection Time: 2.24906
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.67820

Cumulative Model Updates: 98,998
Cumulative Timesteps: 825,617,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,395.75146
Policy Entropy: 3.62859
Value Function Loss: 0.08637

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.42121
Value Function Update Magnitude: 0.59623

Collected Steps per Second: 23,296.07294
Overall Steps per Second: 10,889.46598

Timestep Collection Time: 2.14697
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.59306

Cumulative Model Updates: 99,004
Cumulative Timesteps: 825,668,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 825668004...
Checkpoint 825668004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,314.30256
Policy Entropy: 3.62930
Value Function Loss: 0.08464

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.47719
Value Function Update Magnitude: 0.53829

Collected Steps per Second: 22,091.54174
Overall Steps per Second: 10,674.66432

Timestep Collection Time: 2.26340
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.68418

Cumulative Model Updates: 99,010
Cumulative Timesteps: 825,718,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.05543
Policy Entropy: 3.63640
Value Function Loss: 0.08565

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.44428
Value Function Update Magnitude: 0.47774

Collected Steps per Second: 22,461.74330
Overall Steps per Second: 10,617.17340

Timestep Collection Time: 2.22690
Timestep Consumption Time: 2.48434
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.71124

Cumulative Model Updates: 99,016
Cumulative Timesteps: 825,768,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 825768026...
Checkpoint 825768026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,598.67366
Policy Entropy: 3.62159
Value Function Loss: 0.08742

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.49639
Value Function Update Magnitude: 0.45433

Collected Steps per Second: 22,229.02921
Overall Steps per Second: 10,554.64978

Timestep Collection Time: 2.25030
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.73933

Cumulative Model Updates: 99,022
Cumulative Timesteps: 825,818,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,017.28735
Policy Entropy: 3.63173
Value Function Loss: 0.08746

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.51145
Value Function Update Magnitude: 0.45234

Collected Steps per Second: 22,621.19041
Overall Steps per Second: 10,754.32267

Timestep Collection Time: 2.21085
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.65041

Cumulative Model Updates: 99,028
Cumulative Timesteps: 825,868,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 825868060...
Checkpoint 825868060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,425.89478
Policy Entropy: 3.63929
Value Function Loss: 0.08782

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.62020
Value Function Update Magnitude: 0.46814

Collected Steps per Second: 22,063.21700
Overall Steps per Second: 10,613.02621

Timestep Collection Time: 2.26640
Timestep Consumption Time: 2.44517
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.71157

Cumulative Model Updates: 99,034
Cumulative Timesteps: 825,918,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,929.79520
Policy Entropy: 3.64634
Value Function Loss: 0.08832

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.59376
Value Function Update Magnitude: 0.51210

Collected Steps per Second: 23,077.26695
Overall Steps per Second: 10,695.90433

Timestep Collection Time: 2.16759
Timestep Consumption Time: 2.50916
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67674

Cumulative Model Updates: 99,040
Cumulative Timesteps: 825,968,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 825968086...
Checkpoint 825968086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,148.23458
Policy Entropy: 3.64367
Value Function Loss: 0.08554

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.63227
Value Function Update Magnitude: 0.62670

Collected Steps per Second: 22,922.66709
Overall Steps per Second: 10,864.97712

Timestep Collection Time: 2.18203
Timestep Consumption Time: 2.42157
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.60360

Cumulative Model Updates: 99,046
Cumulative Timesteps: 826,018,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.75785
Policy Entropy: 3.65021
Value Function Loss: 0.08325

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.14968
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.77367

Collected Steps per Second: 23,038.05107
Overall Steps per Second: 10,896.28005

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.41859
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.58909

Cumulative Model Updates: 99,052
Cumulative Timesteps: 826,068,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 826068108...
Checkpoint 826068108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,545.79576
Policy Entropy: 3.65874
Value Function Loss: 0.08401

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.17963
Policy Update Magnitude: 0.49970
Value Function Update Magnitude: 0.71083

Collected Steps per Second: 22,225.10161
Overall Steps per Second: 10,674.32144

Timestep Collection Time: 2.24971
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.68414

Cumulative Model Updates: 99,058
Cumulative Timesteps: 826,118,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,156.36069
Policy Entropy: 3.64231
Value Function Loss: 0.08820

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.46890
Value Function Update Magnitude: 0.65059

Collected Steps per Second: 23,126.99867
Overall Steps per Second: 10,889.67940

Timestep Collection Time: 2.16241
Timestep Consumption Time: 2.43001
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59242

Cumulative Model Updates: 99,064
Cumulative Timesteps: 826,168,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 826168118...
Checkpoint 826168118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,631.81852
Policy Entropy: 3.63165
Value Function Loss: 0.09017

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.45573
Value Function Update Magnitude: 0.61549

Collected Steps per Second: 22,571.68541
Overall Steps per Second: 10,699.93584

Timestep Collection Time: 2.21561
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.67386

Cumulative Model Updates: 99,070
Cumulative Timesteps: 826,218,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,573.03460
Policy Entropy: 3.63337
Value Function Loss: 0.09398

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.51614
Value Function Update Magnitude: 0.60513

Collected Steps per Second: 22,864.78278
Overall Steps per Second: 10,824.49639

Timestep Collection Time: 2.18791
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62155

Cumulative Model Updates: 99,076
Cumulative Timesteps: 826,268,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 826268154...
Checkpoint 826268154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.57251
Policy Entropy: 3.63849
Value Function Loss: 0.09143

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.66779

Collected Steps per Second: 21,888.76973
Overall Steps per Second: 10,425.09031

Timestep Collection Time: 2.28647
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.80073

Cumulative Model Updates: 99,082
Cumulative Timesteps: 826,318,202

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,263.39072
Policy Entropy: 3.64053
Value Function Loss: 0.08916

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.74246

Collected Steps per Second: 22,755.09665
Overall Steps per Second: 10,785.00192

Timestep Collection Time: 2.19775
Timestep Consumption Time: 2.43925
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.63700

Cumulative Model Updates: 99,088
Cumulative Timesteps: 826,368,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 826368212...
Checkpoint 826368212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,703.53085
Policy Entropy: 3.65135
Value Function Loss: 0.08748

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.48273
Value Function Update Magnitude: 0.69924

Collected Steps per Second: 22,315.22015
Overall Steps per Second: 10,622.20067

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.46729
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.70863

Cumulative Model Updates: 99,094
Cumulative Timesteps: 826,418,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,905.36210
Policy Entropy: 3.64508
Value Function Loss: 0.08863

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.48453
Value Function Update Magnitude: 0.71970

Collected Steps per Second: 22,848.85478
Overall Steps per Second: 10,779.71381

Timestep Collection Time: 2.18917
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.64020

Cumulative Model Updates: 99,100
Cumulative Timesteps: 826,468,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 826468248...
Checkpoint 826468248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,953.38178
Policy Entropy: 3.63295
Value Function Loss: 0.08735

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.49963
Value Function Update Magnitude: 0.68758

Collected Steps per Second: 22,570.65411
Overall Steps per Second: 10,793.42087

Timestep Collection Time: 2.21624
Timestep Consumption Time: 2.41825
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.63449

Cumulative Model Updates: 99,106
Cumulative Timesteps: 826,518,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,578.53717
Policy Entropy: 3.62922
Value Function Loss: 0.08656

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.63539
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 22,964.20517
Overall Steps per Second: 10,847.10518

Timestep Collection Time: 2.17809
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61118

Cumulative Model Updates: 99,112
Cumulative Timesteps: 826,568,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 826568288...
Checkpoint 826568288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,377.23959
Policy Entropy: 3.62335
Value Function Loss: 0.08802

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.58522
Value Function Update Magnitude: 0.59431

Collected Steps per Second: 22,620.46042
Overall Steps per Second: 10,677.78253

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.47253
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.68318

Cumulative Model Updates: 99,118
Cumulative Timesteps: 826,618,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,524.77156
Policy Entropy: 3.62553
Value Function Loss: 0.09029

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.48495
Value Function Update Magnitude: 0.63548

Collected Steps per Second: 22,854.20883
Overall Steps per Second: 10,822.87980

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62261

Cumulative Model Updates: 99,124
Cumulative Timesteps: 826,668,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 826668324...
Checkpoint 826668324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,692.02476
Policy Entropy: 3.62840
Value Function Loss: 0.09652

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.46057
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,332.45779
Overall Steps per Second: 10,738.64233

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.41816
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.65794

Cumulative Model Updates: 99,130
Cumulative Timesteps: 826,718,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,835.55383
Policy Entropy: 3.63516
Value Function Loss: 0.09901

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.48561
Value Function Update Magnitude: 0.51060

Collected Steps per Second: 22,335.60601
Overall Steps per Second: 10,599.92952

Timestep Collection Time: 2.23947
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.71890

Cumulative Model Updates: 99,136
Cumulative Timesteps: 826,768,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 826768364...
Checkpoint 826768364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,821.23084
Policy Entropy: 3.62629
Value Function Loss: 0.09605

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.49665

Collected Steps per Second: 22,146.00453
Overall Steps per Second: 10,500.63521

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.76162

Cumulative Model Updates: 99,142
Cumulative Timesteps: 826,818,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.33756
Policy Entropy: 3.62848
Value Function Loss: 0.08923

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.56584

Collected Steps per Second: 22,706.03778
Overall Steps per Second: 10,805.11637

Timestep Collection Time: 2.20338
Timestep Consumption Time: 2.42684
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.63021

Cumulative Model Updates: 99,148
Cumulative Timesteps: 826,868,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 826868394...
Checkpoint 826868394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,947.55269
Policy Entropy: 3.62227
Value Function Loss: 0.08851

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.64364

Collected Steps per Second: 22,188.44337
Overall Steps per Second: 10,617.04093

Timestep Collection Time: 2.25388
Timestep Consumption Time: 2.45648
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.71035

Cumulative Model Updates: 99,154
Cumulative Timesteps: 826,918,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,256.33064
Policy Entropy: 3.61069
Value Function Loss: 0.08588

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.52018
Value Function Update Magnitude: 0.67194

Collected Steps per Second: 23,023.51220
Overall Steps per Second: 10,750.52616

Timestep Collection Time: 2.17274
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.65317

Cumulative Model Updates: 99,160
Cumulative Timesteps: 826,968,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 826968428...
Checkpoint 826968428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,607.62500
Policy Entropy: 3.59789
Value Function Loss: 0.08589

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.53936
Value Function Update Magnitude: 0.74925

Collected Steps per Second: 22,424.63872
Overall Steps per Second: 10,953.85146

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.33510
PPO Batch Consumption Time: 0.27651
Total Iteration Time: 4.56497

Cumulative Model Updates: 99,166
Cumulative Timesteps: 827,018,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,205.25532
Policy Entropy: 3.60205
Value Function Loss: 0.08209

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.75879

Collected Steps per Second: 22,350.98835
Overall Steps per Second: 10,854.87394

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.37042
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.60862

Cumulative Model Updates: 99,172
Cumulative Timesteps: 827,068,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 827068458...
Checkpoint 827068458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,262.62959
Policy Entropy: 3.60653
Value Function Loss: 0.08438

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.56269
Value Function Update Magnitude: 0.84169

Collected Steps per Second: 22,128.00868
Overall Steps per Second: 10,666.26664

Timestep Collection Time: 2.26085
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.69030

Cumulative Model Updates: 99,178
Cumulative Timesteps: 827,118,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,544.83387
Policy Entropy: 3.60651
Value Function Loss: 0.08500

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.69148
Value Function Update Magnitude: 0.86933

Collected Steps per Second: 21,946.10822
Overall Steps per Second: 10,620.34560

Timestep Collection Time: 2.27922
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.70983

Cumulative Model Updates: 99,184
Cumulative Timesteps: 827,168,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 827168506...
Checkpoint 827168506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,238.14522
Policy Entropy: 3.60222
Value Function Loss: 0.09006

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.77258
Value Function Update Magnitude: 0.81956

Collected Steps per Second: 21,795.55876
Overall Steps per Second: 10,685.54826

Timestep Collection Time: 2.29606
Timestep Consumption Time: 2.38727
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.68333

Cumulative Model Updates: 99,190
Cumulative Timesteps: 827,218,550

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,319.33703
Policy Entropy: 3.60742
Value Function Loss: 0.09168

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.76022
Value Function Update Magnitude: 0.78475

Collected Steps per Second: 21,777.11289
Overall Steps per Second: 10,647.13609

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.40117
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.69816

Cumulative Model Updates: 99,196
Cumulative Timesteps: 827,268,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 827268572...
Checkpoint 827268572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,856.79985
Policy Entropy: 3.59966
Value Function Loss: 0.09351

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.70662
Value Function Update Magnitude: 0.65119

Collected Steps per Second: 21,349.63362
Overall Steps per Second: 10,413.50373

Timestep Collection Time: 2.34224
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.80203

Cumulative Model Updates: 99,202
Cumulative Timesteps: 827,318,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,637.33734
Policy Entropy: 3.58720
Value Function Loss: 0.09639

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.53297
Value Function Update Magnitude: 0.60897

Collected Steps per Second: 22,572.19675
Overall Steps per Second: 10,747.15925

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.65295

Cumulative Model Updates: 99,208
Cumulative Timesteps: 827,368,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 827368584...
Checkpoint 827368584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,714.07424
Policy Entropy: 3.59845
Value Function Loss: 0.09594

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.57635

Collected Steps per Second: 22,657.71725
Overall Steps per Second: 10,697.42273

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.67552

Cumulative Model Updates: 99,214
Cumulative Timesteps: 827,418,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,525.95351
Policy Entropy: 3.60129
Value Function Loss: 0.09397

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.55889
Value Function Update Magnitude: 0.57928

Collected Steps per Second: 22,915.37252
Overall Steps per Second: 10,787.31266

Timestep Collection Time: 2.18194
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.63507

Cumulative Model Updates: 99,220
Cumulative Timesteps: 827,468,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 827468600...
Checkpoint 827468600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,320.76380
Policy Entropy: 3.61075
Value Function Loss: 0.09283

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.52325
Value Function Update Magnitude: 0.57925

Collected Steps per Second: 22,235.17683
Overall Steps per Second: 10,592.04575

Timestep Collection Time: 2.24905
Timestep Consumption Time: 2.47223
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.72128

Cumulative Model Updates: 99,226
Cumulative Timesteps: 827,518,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,139.34407
Policy Entropy: 3.61369
Value Function Loss: 0.09625

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.59653
Value Function Update Magnitude: 0.58899

Collected Steps per Second: 22,792.27874
Overall Steps per Second: 10,740.05805

Timestep Collection Time: 2.19504
Timestep Consumption Time: 2.46322
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.65826

Cumulative Model Updates: 99,232
Cumulative Timesteps: 827,568,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 827568638...
Checkpoint 827568638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,244.63333
Policy Entropy: 3.60664
Value Function Loss: 0.10030

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.70274
Value Function Update Magnitude: 0.60694

Collected Steps per Second: 22,439.57953
Overall Steps per Second: 10,625.03098

Timestep Collection Time: 2.22838
Timestep Consumption Time: 2.47786
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.70625

Cumulative Model Updates: 99,238
Cumulative Timesteps: 827,618,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.34960
Policy Entropy: 3.59572
Value Function Loss: 0.10286

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.66576
Value Function Update Magnitude: 0.63157

Collected Steps per Second: 23,137.30323
Overall Steps per Second: 10,697.16205

Timestep Collection Time: 2.16179
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.67582

Cumulative Model Updates: 99,244
Cumulative Timesteps: 827,668,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 827668660...
Checkpoint 827668660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,996.17939
Policy Entropy: 3.59092
Value Function Loss: 0.10061

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.18653
Policy Update Magnitude: 0.50553
Value Function Update Magnitude: 0.61170

Collected Steps per Second: 22,365.69189
Overall Steps per Second: 10,731.19870

Timestep Collection Time: 2.23762
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.66360

Cumulative Model Updates: 99,250
Cumulative Timesteps: 827,718,706

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,979.90474
Policy Entropy: 3.59828
Value Function Loss: 0.09761

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.43742
Value Function Update Magnitude: 0.59474

Collected Steps per Second: 22,528.62542
Overall Steps per Second: 10,638.65601

Timestep Collection Time: 2.22055
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.70229

Cumulative Model Updates: 99,256
Cumulative Timesteps: 827,768,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 827768732...
Checkpoint 827768732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,918.24576
Policy Entropy: 3.61009
Value Function Loss: 0.08968

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.57482
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,390.11400
Overall Steps per Second: 10,645.80340

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.46385
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.69725

Cumulative Model Updates: 99,262
Cumulative Timesteps: 827,818,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,774.76561
Policy Entropy: 3.60081
Value Function Loss: 0.08873

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.17542
Policy Update Magnitude: 0.60690
Value Function Update Magnitude: 0.67976

Collected Steps per Second: 22,569.96276
Overall Steps per Second: 10,701.43197

Timestep Collection Time: 2.21640
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.67451

Cumulative Model Updates: 99,268
Cumulative Timesteps: 827,868,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 827868762...
Checkpoint 827868762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,873.51038
Policy Entropy: 3.60395
Value Function Loss: 0.08810

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.17826
Policy Update Magnitude: 0.49606
Value Function Update Magnitude: 0.63714

Collected Steps per Second: 22,253.32957
Overall Steps per Second: 10,685.91222

Timestep Collection Time: 2.24784
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.68112

Cumulative Model Updates: 99,274
Cumulative Timesteps: 827,918,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,821.29377
Policy Entropy: 3.59222
Value Function Loss: 0.09040

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.50882
Value Function Update Magnitude: 0.59686

Collected Steps per Second: 22,790.04159
Overall Steps per Second: 10,771.71509

Timestep Collection Time: 2.19499
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.64401

Cumulative Model Updates: 99,280
Cumulative Timesteps: 827,968,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 827968808...
Checkpoint 827968808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,966.27290
Policy Entropy: 3.59004
Value Function Loss: 0.08997

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.66178
Value Function Update Magnitude: 0.55499

Collected Steps per Second: 22,610.02441
Overall Steps per Second: 10,733.83158

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.44764
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.65985

Cumulative Model Updates: 99,286
Cumulative Timesteps: 828,018,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,102.51307
Policy Entropy: 3.59753
Value Function Loss: 0.08832

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.69059
Value Function Update Magnitude: 0.59784

Collected Steps per Second: 22,872.28922
Overall Steps per Second: 10,849.84101

Timestep Collection Time: 2.18666
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60965

Cumulative Model Updates: 99,292
Cumulative Timesteps: 828,068,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 828068840...
Checkpoint 828068840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.72801
Policy Entropy: 3.60146
Value Function Loss: 0.08770

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.64029
Value Function Update Magnitude: 0.66149

Collected Steps per Second: 22,648.37457
Overall Steps per Second: 10,670.39573

Timestep Collection Time: 2.20837
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.68736

Cumulative Model Updates: 99,298
Cumulative Timesteps: 828,118,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,060.50842
Policy Entropy: 3.61266
Value Function Loss: 0.08824

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.53195
Value Function Update Magnitude: 0.68859

Collected Steps per Second: 23,006.26794
Overall Steps per Second: 10,873.47101

Timestep Collection Time: 2.17419
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60019

Cumulative Model Updates: 99,304
Cumulative Timesteps: 828,168,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 828168876...
Checkpoint 828168876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.23115
Policy Entropy: 3.60182
Value Function Loss: 0.08876

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.49909
Value Function Update Magnitude: 0.71505

Collected Steps per Second: 22,231.58579
Overall Steps per Second: 10,721.47379

Timestep Collection Time: 2.24914
Timestep Consumption Time: 2.41458
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.66372

Cumulative Model Updates: 99,310
Cumulative Timesteps: 828,218,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,900.53304
Policy Entropy: 3.60526
Value Function Loss: 0.08844

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.48342
Value Function Update Magnitude: 0.76010

Collected Steps per Second: 22,926.30436
Overall Steps per Second: 10,888.89520

Timestep Collection Time: 2.18212
Timestep Consumption Time: 2.41228
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.59441

Cumulative Model Updates: 99,316
Cumulative Timesteps: 828,268,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 828268906...
Checkpoint 828268906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,020.85235
Policy Entropy: 3.60423
Value Function Loss: 0.08860

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.53444
Value Function Update Magnitude: 0.69196

Collected Steps per Second: 21,575.14523
Overall Steps per Second: 10,603.27122

Timestep Collection Time: 2.31794
Timestep Consumption Time: 2.39852
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.71647

Cumulative Model Updates: 99,322
Cumulative Timesteps: 828,318,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,401.71326
Policy Entropy: 3.60825
Value Function Loss: 0.09174

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.52620
Value Function Update Magnitude: 0.77060

Collected Steps per Second: 21,698.70373
Overall Steps per Second: 10,566.35498

Timestep Collection Time: 2.30465
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.73276

Cumulative Model Updates: 99,328
Cumulative Timesteps: 828,368,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 828368924...
Checkpoint 828368924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.36130
Policy Entropy: 3.60827
Value Function Loss: 0.09236

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.51126
Value Function Update Magnitude: 0.78389

Collected Steps per Second: 21,577.96903
Overall Steps per Second: 10,540.94145

Timestep Collection Time: 2.31736
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.74379

Cumulative Model Updates: 99,334
Cumulative Timesteps: 828,418,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,149.20886
Policy Entropy: 3.60505
Value Function Loss: 0.09696

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.56930
Value Function Update Magnitude: 0.74049

Collected Steps per Second: 22,379.14116
Overall Steps per Second: 10,838.68380

Timestep Collection Time: 2.23440
Timestep Consumption Time: 2.37907
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61348

Cumulative Model Updates: 99,340
Cumulative Timesteps: 828,468,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 828468932...
Checkpoint 828468932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,025.24737
Policy Entropy: 3.60466
Value Function Loss: 0.09810

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.70159
Value Function Update Magnitude: 0.81134

Collected Steps per Second: 22,002.92613
Overall Steps per Second: 10,722.03304

Timestep Collection Time: 2.27324
Timestep Consumption Time: 2.39173
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.66497

Cumulative Model Updates: 99,346
Cumulative Timesteps: 828,518,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,189.12459
Policy Entropy: 3.59919
Value Function Loss: 0.09734

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.69021
Value Function Update Magnitude: 0.81654

Collected Steps per Second: 22,823.98502
Overall Steps per Second: 10,912.13689

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.39166
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.58260

Cumulative Model Updates: 99,352
Cumulative Timesteps: 828,568,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 828568956...
Checkpoint 828568956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,845.16986
Policy Entropy: 3.59534
Value Function Loss: 0.09470

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.65623

Collected Steps per Second: 22,267.30138
Overall Steps per Second: 10,638.54272

Timestep Collection Time: 2.24607
Timestep Consumption Time: 2.45513
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.70121

Cumulative Model Updates: 99,358
Cumulative Timesteps: 828,618,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,974.68577
Policy Entropy: 3.58887
Value Function Loss: 0.09217

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.49319
Value Function Update Magnitude: 0.62276

Collected Steps per Second: 23,002.64397
Overall Steps per Second: 10,947.90478

Timestep Collection Time: 2.17540
Timestep Consumption Time: 2.39534
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.57074

Cumulative Model Updates: 99,364
Cumulative Timesteps: 828,669,010

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 828669010...
Checkpoint 828669010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,895.48665
Policy Entropy: 3.58588
Value Function Loss: 0.08742

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.48460
Value Function Update Magnitude: 0.72257

Collected Steps per Second: 22,485.94539
Overall Steps per Second: 10,655.71097

Timestep Collection Time: 2.22441
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.69401

Cumulative Model Updates: 99,370
Cumulative Timesteps: 828,719,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,251.02652
Policy Entropy: 3.59963
Value Function Loss: 0.08726

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.48239
Value Function Update Magnitude: 0.68417

Collected Steps per Second: 22,643.95059
Overall Steps per Second: 10,841.26011

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.40488
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61385

Cumulative Model Updates: 99,376
Cumulative Timesteps: 828,769,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 828769048...
Checkpoint 828769048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,375.32100
Policy Entropy: 3.60001
Value Function Loss: 0.08687

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.51394
Value Function Update Magnitude: 0.74604

Collected Steps per Second: 21,952.49674
Overall Steps per Second: 10,689.38520

Timestep Collection Time: 2.27837
Timestep Consumption Time: 2.40066
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.67903

Cumulative Model Updates: 99,382
Cumulative Timesteps: 828,819,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,829.56998
Policy Entropy: 3.60608
Value Function Loss: 0.08653

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.63048
Value Function Update Magnitude: 0.85788

Collected Steps per Second: 22,792.79341
Overall Steps per Second: 10,818.15627

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.62371

Cumulative Model Updates: 99,388
Cumulative Timesteps: 828,869,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 828869084...
Checkpoint 828869084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,375.88101
Policy Entropy: 3.59562
Value Function Loss: 0.08605

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.61364
Value Function Update Magnitude: 0.79719

Collected Steps per Second: 22,482.41378
Overall Steps per Second: 10,740.61425

Timestep Collection Time: 2.22458
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.65653

Cumulative Model Updates: 99,394
Cumulative Timesteps: 828,919,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,246.00309
Policy Entropy: 3.58418
Value Function Loss: 0.09078

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.75782

Collected Steps per Second: 22,751.37237
Overall Steps per Second: 10,757.36083

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.45139
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.65003

Cumulative Model Updates: 99,400
Cumulative Timesteps: 828,969,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 828969120...
Checkpoint 828969120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,196.88219
Policy Entropy: 3.59546
Value Function Loss: 0.08996

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.62477
Value Function Update Magnitude: 0.73014

Collected Steps per Second: 22,753.76063
Overall Steps per Second: 10,776.46444

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.44455
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.64401

Cumulative Model Updates: 99,406
Cumulative Timesteps: 829,019,166

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,692.46131
Policy Entropy: 3.59985
Value Function Loss: 0.09127

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.68489
Value Function Update Magnitude: 0.66035

Collected Steps per Second: 23,021.05438
Overall Steps per Second: 10,845.14955

Timestep Collection Time: 2.17210
Timestep Consumption Time: 2.43863
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61072

Cumulative Model Updates: 99,412
Cumulative Timesteps: 829,069,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 829069170...
Checkpoint 829069170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,987.78312
Policy Entropy: 3.59484
Value Function Loss: 0.09725

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.60590

Collected Steps per Second: 22,340.31009
Overall Steps per Second: 10,646.62356

Timestep Collection Time: 2.23846
Timestep Consumption Time: 2.45861
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.69708

Cumulative Model Updates: 99,418
Cumulative Timesteps: 829,119,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,834.04607
Policy Entropy: 3.60144
Value Function Loss: 0.09529

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.51732
Value Function Update Magnitude: 0.61533

Collected Steps per Second: 22,941.47813
Overall Steps per Second: 10,844.63581

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.61076

Cumulative Model Updates: 99,424
Cumulative Timesteps: 829,169,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 829169180...
Checkpoint 829169180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,313.35724
Policy Entropy: 3.60104
Value Function Loss: 0.09270

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.48538
Value Function Update Magnitude: 0.61486

Collected Steps per Second: 21,401.37925
Overall Steps per Second: 10,337.31017

Timestep Collection Time: 2.33770
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.83975

Cumulative Model Updates: 99,430
Cumulative Timesteps: 829,219,210

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,748.35037
Policy Entropy: 3.61601
Value Function Loss: 0.08735

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.53887
Value Function Update Magnitude: 0.67963

Collected Steps per Second: 22,336.41849
Overall Steps per Second: 10,572.79331

Timestep Collection Time: 2.23930
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.73082

Cumulative Model Updates: 99,436
Cumulative Timesteps: 829,269,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 829269228...
Checkpoint 829269228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,265.17208
Policy Entropy: 3.60594
Value Function Loss: 0.09011

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.73844

Collected Steps per Second: 22,194.12132
Overall Steps per Second: 10,524.49633

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.75329

Cumulative Model Updates: 99,442
Cumulative Timesteps: 829,319,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,746.39498
Policy Entropy: 3.61090
Value Function Loss: 0.09045

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.16853
Policy Update Magnitude: 0.54152
Value Function Update Magnitude: 0.80348

Collected Steps per Second: 23,020.64922
Overall Steps per Second: 10,766.74458

Timestep Collection Time: 2.17266
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.64542

Cumulative Model Updates: 99,448
Cumulative Timesteps: 829,369,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 829369270...
Checkpoint 829369270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,220.03773
Policy Entropy: 3.61722
Value Function Loss: 0.09195

Mean KL Divergence: 0.02511
SB3 Clip Fraction: 0.18774
Policy Update Magnitude: 0.51789
Value Function Update Magnitude: 0.74145

Collected Steps per Second: 22,677.99085
Overall Steps per Second: 10,752.73857

Timestep Collection Time: 2.20531
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.65109

Cumulative Model Updates: 99,454
Cumulative Timesteps: 829,419,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.85712
Policy Entropy: 3.64117
Value Function Loss: 0.08872

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.72458

Collected Steps per Second: 22,858.41949
Overall Steps per Second: 10,819.74589

Timestep Collection Time: 2.18790
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62229

Cumulative Model Updates: 99,460
Cumulative Timesteps: 829,469,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 829469294...
Checkpoint 829469294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,391.01724
Policy Entropy: 3.63908
Value Function Loss: 0.08279

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.60700
Value Function Update Magnitude: 0.73884

Collected Steps per Second: 22,615.16198
Overall Steps per Second: 10,697.39279

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.46362
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.67497

Cumulative Model Updates: 99,466
Cumulative Timesteps: 829,519,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.40641
Policy Entropy: 3.62346
Value Function Loss: 0.07945

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.62575
Value Function Update Magnitude: 0.70427

Collected Steps per Second: 22,922.14496
Overall Steps per Second: 10,864.22246

Timestep Collection Time: 2.18191
Timestep Consumption Time: 2.42164
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.60355

Cumulative Model Updates: 99,472
Cumulative Timesteps: 829,569,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 829569318...
Checkpoint 829569318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,301.53283
Policy Entropy: 3.62511
Value Function Loss: 0.07936

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11720
Policy Update Magnitude: 0.64029
Value Function Update Magnitude: 0.63543

Collected Steps per Second: 22,593.91131
Overall Steps per Second: 10,712.83218

Timestep Collection Time: 2.21352
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.66842

Cumulative Model Updates: 99,478
Cumulative Timesteps: 829,619,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,325.76635
Policy Entropy: 3.62026
Value Function Loss: 0.08256

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.56874
Value Function Update Magnitude: 0.59369

Collected Steps per Second: 22,616.03163
Overall Steps per Second: 10,799.48026

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.41961
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.63096

Cumulative Model Updates: 99,484
Cumulative Timesteps: 829,669,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 829669342...
Checkpoint 829669342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,417.05683
Policy Entropy: 3.63028
Value Function Loss: 0.08509

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.57254
Value Function Update Magnitude: 0.61016

Collected Steps per Second: 21,976.71207
Overall Steps per Second: 10,652.36284

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.41866
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.69379

Cumulative Model Updates: 99,490
Cumulative Timesteps: 829,719,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,290.56989
Policy Entropy: 3.63149
Value Function Loss: 0.08163

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.51036
Value Function Update Magnitude: 0.68932

Collected Steps per Second: 22,015.00183
Overall Steps per Second: 10,559.83291

Timestep Collection Time: 2.27127
Timestep Consumption Time: 2.46384
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.73511

Cumulative Model Updates: 99,496
Cumulative Timesteps: 829,769,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 829769344...
Checkpoint 829769344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.73761
Policy Entropy: 3.64350
Value Function Loss: 0.07975

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.47641
Value Function Update Magnitude: 0.71284

Collected Steps per Second: 22,375.96244
Overall Steps per Second: 10,620.41727

Timestep Collection Time: 2.23481
Timestep Consumption Time: 2.47367
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.70848

Cumulative Model Updates: 99,502
Cumulative Timesteps: 829,819,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,781.69790
Policy Entropy: 3.64924
Value Function Loss: 0.07907

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.49865
Value Function Update Magnitude: 0.71125

Collected Steps per Second: 22,980.05576
Overall Steps per Second: 10,826.48998

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61849

Cumulative Model Updates: 99,508
Cumulative Timesteps: 829,869,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 829869352...
Checkpoint 829869352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.04213
Policy Entropy: 3.64482
Value Function Loss: 0.08527

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.67493

Collected Steps per Second: 22,427.61636
Overall Steps per Second: 10,691.61182

Timestep Collection Time: 2.22975
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.67731

Cumulative Model Updates: 99,514
Cumulative Timesteps: 829,919,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,885.85383
Policy Entropy: 3.62975
Value Function Loss: 0.08990

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.57393

Collected Steps per Second: 22,267.66504
Overall Steps per Second: 10,875.88084

Timestep Collection Time: 2.24649
Timestep Consumption Time: 2.35305
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.59954

Cumulative Model Updates: 99,520
Cumulative Timesteps: 829,969,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 829969384...
Checkpoint 829969384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,372.02386
Policy Entropy: 3.63701
Value Function Loss: 0.08968

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.49495
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 22,064.04070
Overall Steps per Second: 10,660.38847

Timestep Collection Time: 2.26613
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.69026

Cumulative Model Updates: 99,526
Cumulative Timesteps: 830,019,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.33069
Policy Entropy: 3.64854
Value Function Loss: 0.08658

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.49946
Value Function Update Magnitude: 0.70929

Collected Steps per Second: 22,720.86232
Overall Steps per Second: 10,956.21419

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.36413
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.56581

Cumulative Model Updates: 99,532
Cumulative Timesteps: 830,069,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 830069408...
Checkpoint 830069408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,092.07933
Policy Entropy: 3.65316
Value Function Loss: 0.08575

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.49572
Value Function Update Magnitude: 0.77147

Collected Steps per Second: 21,771.69023
Overall Steps per Second: 10,614.62977

Timestep Collection Time: 2.29711
Timestep Consumption Time: 2.41450
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.71161

Cumulative Model Updates: 99,538
Cumulative Timesteps: 830,119,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,387.91543
Policy Entropy: 3.65786
Value Function Loss: 0.08559

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.47970
Value Function Update Magnitude: 0.78839

Collected Steps per Second: 22,146.07753
Overall Steps per Second: 10,856.64907

Timestep Collection Time: 2.25909
Timestep Consumption Time: 2.34915
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.60824

Cumulative Model Updates: 99,544
Cumulative Timesteps: 830,169,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 830169450...
Checkpoint 830169450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,587.52797
Policy Entropy: 3.63738
Value Function Loss: 0.08651

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.52544
Value Function Update Magnitude: 0.78295

Collected Steps per Second: 21,764.64041
Overall Steps per Second: 10,707.99273

Timestep Collection Time: 2.29740
Timestep Consumption Time: 2.37220
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.66960

Cumulative Model Updates: 99,550
Cumulative Timesteps: 830,219,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,596.20111
Policy Entropy: 3.64044
Value Function Loss: 0.08854

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.75886

Collected Steps per Second: 21,707.48001
Overall Steps per Second: 10,635.41512

Timestep Collection Time: 2.30363
Timestep Consumption Time: 2.39821
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.70184

Cumulative Model Updates: 99,556
Cumulative Timesteps: 830,269,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 830269458...
Checkpoint 830269458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.44142
Policy Entropy: 3.64714
Value Function Loss: 0.09362

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.51070
Value Function Update Magnitude: 0.62406

Collected Steps per Second: 21,630.86761
Overall Steps per Second: 10,543.07679

Timestep Collection Time: 2.31253
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74454

Cumulative Model Updates: 99,562
Cumulative Timesteps: 830,319,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.30576
Policy Entropy: 3.64486
Value Function Loss: 0.09293

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.52373
Value Function Update Magnitude: 0.60285

Collected Steps per Second: 22,514.71617
Overall Steps per Second: 10,824.16056

Timestep Collection Time: 2.22157
Timestep Consumption Time: 2.39939
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.62096

Cumulative Model Updates: 99,568
Cumulative Timesteps: 830,369,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 830369498...
Checkpoint 830369498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796.35541
Policy Entropy: 3.65651
Value Function Loss: 0.09218

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.62175
Value Function Update Magnitude: 0.64825

Collected Steps per Second: 22,214.87944
Overall Steps per Second: 10,612.53350

Timestep Collection Time: 2.25164
Timestep Consumption Time: 2.46165
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.71329

Cumulative Model Updates: 99,574
Cumulative Timesteps: 830,419,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,435.02088
Policy Entropy: 3.64201
Value Function Loss: 0.08911

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.67817
Value Function Update Magnitude: 0.64012

Collected Steps per Second: 23,069.00616
Overall Steps per Second: 10,890.94497

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.42443
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.59262

Cumulative Model Updates: 99,580
Cumulative Timesteps: 830,469,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 830469536...
Checkpoint 830469536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,705.64563
Policy Entropy: 3.64046
Value Function Loss: 0.08638

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.69605
Value Function Update Magnitude: 0.70101

Collected Steps per Second: 22,405.95122
Overall Steps per Second: 10,655.62787

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.69423

Cumulative Model Updates: 99,586
Cumulative Timesteps: 830,519,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,241.06029
Policy Entropy: 3.62453
Value Function Loss: 0.09023

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.68936
Value Function Update Magnitude: 0.65884

Collected Steps per Second: 23,056.44015
Overall Steps per Second: 10,926.24301

Timestep Collection Time: 2.16920
Timestep Consumption Time: 2.40822
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.57742

Cumulative Model Updates: 99,592
Cumulative Timesteps: 830,569,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 830569570...
Checkpoint 830569570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,547.17923
Policy Entropy: 3.62757
Value Function Loss: 0.09137

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.79625
Value Function Update Magnitude: 0.69505

Collected Steps per Second: 22,769.65598
Overall Steps per Second: 10,734.90812

Timestep Collection Time: 2.19678
Timestep Consumption Time: 2.46278
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.65956

Cumulative Model Updates: 99,598
Cumulative Timesteps: 830,619,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.11396
Policy Entropy: 3.62504
Value Function Loss: 0.08935

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.80807
Value Function Update Magnitude: 0.77599

Collected Steps per Second: 22,425.02479
Overall Steps per Second: 10,710.05823

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.43983
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.67038

Cumulative Model Updates: 99,604
Cumulative Timesteps: 830,669,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 830669610...
Checkpoint 830669610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,977.71696
Policy Entropy: 3.64714
Value Function Loss: 0.08304

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11314
Policy Update Magnitude: 0.79247
Value Function Update Magnitude: 0.78980

Collected Steps per Second: 22,029.71506
Overall Steps per Second: 10,698.48653

Timestep Collection Time: 2.27084
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.67599

Cumulative Model Updates: 99,610
Cumulative Timesteps: 830,719,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,962.93551
Policy Entropy: 3.65833
Value Function Loss: 0.08005

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.67478
Value Function Update Magnitude: 0.81390

Collected Steps per Second: 22,611.96028
Overall Steps per Second: 10,690.11429

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.46748
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.68002

Cumulative Model Updates: 99,616
Cumulative Timesteps: 830,769,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 830769666...
Checkpoint 830769666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,622.71129
Policy Entropy: 3.66491
Value Function Loss: 0.07849

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.59205
Value Function Update Magnitude: 0.83966

Collected Steps per Second: 22,558.14995
Overall Steps per Second: 10,678.39103

Timestep Collection Time: 2.21720
Timestep Consumption Time: 2.46665
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.68385

Cumulative Model Updates: 99,622
Cumulative Timesteps: 830,819,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,208.99678
Policy Entropy: 3.66267
Value Function Loss: 0.08144

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.58996
Value Function Update Magnitude: 0.84983

Collected Steps per Second: 23,396.88755
Overall Steps per Second: 10,645.72426

Timestep Collection Time: 2.13789
Timestep Consumption Time: 2.56071
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.69860

Cumulative Model Updates: 99,628
Cumulative Timesteps: 830,869,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 830869702...
Checkpoint 830869702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,121.19199
Policy Entropy: 3.65854
Value Function Loss: 0.08326

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.68290
Value Function Update Magnitude: 0.90563

Collected Steps per Second: 22,798.42975
Overall Steps per Second: 10,623.16003

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.51397
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.70745

Cumulative Model Updates: 99,634
Cumulative Timesteps: 830,919,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,660.82451
Policy Entropy: 3.65636
Value Function Loss: 0.08168

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.71108
Value Function Update Magnitude: 0.92864

Collected Steps per Second: 23,087.93487
Overall Steps per Second: 10,900.08376

Timestep Collection Time: 2.16572
Timestep Consumption Time: 2.42158
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.58730

Cumulative Model Updates: 99,640
Cumulative Timesteps: 830,969,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 830969712...
Checkpoint 830969712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,914.96870
Policy Entropy: 3.63873
Value Function Loss: 0.08249

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.61061
Value Function Update Magnitude: 0.95324

Collected Steps per Second: 22,796.61506
Overall Steps per Second: 10,715.83036

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.47397
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.66842

Cumulative Model Updates: 99,646
Cumulative Timesteps: 831,019,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,139.68333
Policy Entropy: 3.64463
Value Function Loss: 0.08052

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14185
Policy Update Magnitude: 0.47238
Value Function Update Magnitude: 0.99385

Collected Steps per Second: 23,116.80836
Overall Steps per Second: 10,841.65339

Timestep Collection Time: 2.16423
Timestep Consumption Time: 2.45038
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61461

Cumulative Model Updates: 99,652
Cumulative Timesteps: 831,069,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 831069768...
Checkpoint 831069768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,303.16644
Policy Entropy: 3.63956
Value Function Loss: 0.08444

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.46141
Value Function Update Magnitude: 0.98514

Collected Steps per Second: 22,254.74644
Overall Steps per Second: 10,580.15981

Timestep Collection Time: 2.24824
Timestep Consumption Time: 2.48080
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.72904

Cumulative Model Updates: 99,658
Cumulative Timesteps: 831,119,802

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,611.90024
Policy Entropy: 3.63596
Value Function Loss: 0.08850

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10294
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.82302

Collected Steps per Second: 22,820.83183
Overall Steps per Second: 10,644.52039

Timestep Collection Time: 2.19186
Timestep Consumption Time: 2.50727
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.69913

Cumulative Model Updates: 99,664
Cumulative Timesteps: 831,169,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831169822...
Checkpoint 831169822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,087.35637
Policy Entropy: 3.61749
Value Function Loss: 0.09462

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.66095

Collected Steps per Second: 22,365.29669
Overall Steps per Second: 10,565.36779

Timestep Collection Time: 2.23641
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.73415

Cumulative Model Updates: 99,670
Cumulative Timesteps: 831,219,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,268.00471
Policy Entropy: 3.60237
Value Function Loss: 0.09694

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.61323

Collected Steps per Second: 22,674.09946
Overall Steps per Second: 10,618.37751

Timestep Collection Time: 2.20595
Timestep Consumption Time: 2.50456
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.71051

Cumulative Model Updates: 99,676
Cumulative Timesteps: 831,269,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 831269858...
Checkpoint 831269858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,291.10358
Policy Entropy: 3.60373
Value Function Loss: 0.09592

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11417
Policy Update Magnitude: 0.49318
Value Function Update Magnitude: 0.57723

Collected Steps per Second: 22,507.90911
Overall Steps per Second: 10,624.60287

Timestep Collection Time: 2.22260
Timestep Consumption Time: 2.48591
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.70851

Cumulative Model Updates: 99,682
Cumulative Timesteps: 831,319,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,745.71561
Policy Entropy: 3.60459
Value Function Loss: 0.09127

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.49798
Value Function Update Magnitude: 0.65780

Collected Steps per Second: 22,396.45969
Overall Steps per Second: 10,719.68978

Timestep Collection Time: 2.23375
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.66693

Cumulative Model Updates: 99,688
Cumulative Timesteps: 831,369,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 831369912...
Checkpoint 831369912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,943.03590
Policy Entropy: 3.61195
Value Function Loss: 0.08756

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.57200
Value Function Update Magnitude: 0.68739

Collected Steps per Second: 22,493.09504
Overall Steps per Second: 10,664.19476

Timestep Collection Time: 2.22344
Timestep Consumption Time: 2.46627
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.68971

Cumulative Model Updates: 99,694
Cumulative Timesteps: 831,419,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,050.37956
Policy Entropy: 3.59990
Value Function Loss: 0.08508

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.52561
Value Function Update Magnitude: 0.70290

Collected Steps per Second: 23,043.21653
Overall Steps per Second: 10,840.93562

Timestep Collection Time: 2.17070
Timestep Consumption Time: 2.44329
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.61399

Cumulative Model Updates: 99,700
Cumulative Timesteps: 831,469,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831469944...
Checkpoint 831469944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,980.32846
Policy Entropy: 3.59597
Value Function Loss: 0.08461

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.52018
Value Function Update Magnitude: 0.69316

Collected Steps per Second: 22,554.61777
Overall Steps per Second: 10,780.69747

Timestep Collection Time: 2.21764
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.63959

Cumulative Model Updates: 99,706
Cumulative Timesteps: 831,519,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,744.55990
Policy Entropy: 3.60662
Value Function Loss: 0.08418

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.48994
Value Function Update Magnitude: 0.75799

Collected Steps per Second: 23,025.11247
Overall Steps per Second: 10,869.18722

Timestep Collection Time: 2.17189
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.60090

Cumulative Model Updates: 99,712
Cumulative Timesteps: 831,569,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 831569970...
Checkpoint 831569970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,498.18618
Policy Entropy: 3.61476
Value Function Loss: 0.08259

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.52208
Value Function Update Magnitude: 0.76492

Collected Steps per Second: 22,771.18655
Overall Steps per Second: 10,670.54736

Timestep Collection Time: 2.19593
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.68617

Cumulative Model Updates: 99,718
Cumulative Timesteps: 831,619,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,298.82369
Policy Entropy: 3.62203
Value Function Loss: 0.08387

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.68876

Collected Steps per Second: 23,104.23771
Overall Steps per Second: 10,838.07882

Timestep Collection Time: 2.16497
Timestep Consumption Time: 2.45024
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61521

Cumulative Model Updates: 99,724
Cumulative Timesteps: 831,669,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831669994...
Checkpoint 831669994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,234.00688
Policy Entropy: 3.61784
Value Function Loss: 0.08347

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.49424
Value Function Update Magnitude: 0.64879

Collected Steps per Second: 22,210.38403
Overall Steps per Second: 10,708.23590

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.41839
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.66986

Cumulative Model Updates: 99,730
Cumulative Timesteps: 831,720,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,774.75078
Policy Entropy: 3.62798
Value Function Loss: 0.08582

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.45844
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 22,677.20499
Overall Steps per Second: 10,813.39564

Timestep Collection Time: 2.20574
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62574

Cumulative Model Updates: 99,736
Cumulative Timesteps: 831,770,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831770020...
Checkpoint 831770020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,981.12800
Policy Entropy: 3.63210
Value Function Loss: 0.08600

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.61907
Value Function Update Magnitude: 0.66608

Collected Steps per Second: 22,772.69750
Overall Steps per Second: 10,675.40007

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.48865
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.68479

Cumulative Model Updates: 99,742
Cumulative Timesteps: 831,820,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,805.09907
Policy Entropy: 3.63050
Value Function Loss: 0.08910

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16803
Policy Update Magnitude: 0.47797
Value Function Update Magnitude: 0.75235

Collected Steps per Second: 21,897.82524
Overall Steps per Second: 10,561.86325

Timestep Collection Time: 2.28425
Timestep Consumption Time: 2.45166
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.73591

Cumulative Model Updates: 99,748
Cumulative Timesteps: 831,870,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831870052...
Checkpoint 831870052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,256.02405
Policy Entropy: 3.61331
Value Function Loss: 0.09097

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.36762
Value Function Update Magnitude: 0.76359

Collected Steps per Second: 21,947.46532
Overall Steps per Second: 10,594.29324

Timestep Collection Time: 2.27817
Timestep Consumption Time: 2.44135
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.71952

Cumulative Model Updates: 99,754
Cumulative Timesteps: 831,920,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,166.15554
Policy Entropy: 3.61786
Value Function Loss: 0.08940

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.41872
Value Function Update Magnitude: 0.71792

Collected Steps per Second: 22,269.30010
Overall Steps per Second: 10,843.31208

Timestep Collection Time: 2.24578
Timestep Consumption Time: 2.36646
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61224

Cumulative Model Updates: 99,760
Cumulative Timesteps: 831,970,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 831970064...
Checkpoint 831970064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,958.47423
Policy Entropy: 3.61758
Value Function Loss: 0.08866

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.45017
Value Function Update Magnitude: 0.67315

Collected Steps per Second: 21,955.56414
Overall Steps per Second: 10,657.37374

Timestep Collection Time: 2.27924
Timestep Consumption Time: 2.41629
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.69553

Cumulative Model Updates: 99,766
Cumulative Timesteps: 832,020,106

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,165.73114
Policy Entropy: 3.63245
Value Function Loss: 0.09094

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.52432
Value Function Update Magnitude: 0.71283

Collected Steps per Second: 22,366.23095
Overall Steps per Second: 10,863.52630

Timestep Collection Time: 2.23596
Timestep Consumption Time: 2.36752
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60348

Cumulative Model Updates: 99,772
Cumulative Timesteps: 832,070,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 832070116...
Checkpoint 832070116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,077.03099
Policy Entropy: 3.61745
Value Function Loss: 0.09692

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.51315
Value Function Update Magnitude: 0.74196

Collected Steps per Second: 21,922.02387
Overall Steps per Second: 10,675.82355

Timestep Collection Time: 2.28191
Timestep Consumption Time: 2.40382
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.68573

Cumulative Model Updates: 99,778
Cumulative Timesteps: 832,120,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,769.17700
Policy Entropy: 3.61980
Value Function Loss: 0.10143

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.66837
Value Function Update Magnitude: 0.75581

Collected Steps per Second: 22,430.47626
Overall Steps per Second: 10,677.08444

Timestep Collection Time: 2.23098
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.68686

Cumulative Model Updates: 99,784
Cumulative Timesteps: 832,170,182

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 832170182...
Checkpoint 832170182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.22192
Policy Entropy: 3.61381
Value Function Loss: 0.10060

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.70300
Value Function Update Magnitude: 0.66463

Collected Steps per Second: 22,521.94546
Overall Steps per Second: 10,864.43979

Timestep Collection Time: 2.22077
Timestep Consumption Time: 2.38288
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.60364

Cumulative Model Updates: 99,790
Cumulative Timesteps: 832,220,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.50095
Policy Entropy: 3.62685
Value Function Loss: 0.09377

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.58976
Value Function Update Magnitude: 0.65973

Collected Steps per Second: 22,400.12141
Overall Steps per Second: 10,644.79401

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.46540
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69788

Cumulative Model Updates: 99,796
Cumulative Timesteps: 832,270,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 832270206...
Checkpoint 832270206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,132.80294
Policy Entropy: 3.62548
Value Function Loss: 0.08895

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.60943
Value Function Update Magnitude: 0.68057

Collected Steps per Second: 22,254.82045
Overall Steps per Second: 10,611.39941

Timestep Collection Time: 2.24886
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.71644

Cumulative Model Updates: 99,802
Cumulative Timesteps: 832,320,254

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,062.49117
Policy Entropy: 3.61720
Value Function Loss: 0.09147

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.57427
Value Function Update Magnitude: 0.65767

Collected Steps per Second: 22,333.59243
Overall Steps per Second: 10,738.21237

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.41768
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.65664

Cumulative Model Updates: 99,808
Cumulative Timesteps: 832,370,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 832370258...
Checkpoint 832370258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.71928
Policy Entropy: 3.60817
Value Function Loss: 0.09206

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.60019
Value Function Update Magnitude: 0.67793

Collected Steps per Second: 22,857.80826
Overall Steps per Second: 10,726.23214

Timestep Collection Time: 2.18814
Timestep Consumption Time: 2.47482
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.66296

Cumulative Model Updates: 99,814
Cumulative Timesteps: 832,420,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,744.32571
Policy Entropy: 3.60315
Value Function Loss: 0.09270

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.55184
Value Function Update Magnitude: 0.68367

Collected Steps per Second: 22,872.32792
Overall Steps per Second: 10,784.34284

Timestep Collection Time: 2.18666
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.63765

Cumulative Model Updates: 99,820
Cumulative Timesteps: 832,470,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 832470288...
Checkpoint 832470288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,946.44710
Policy Entropy: 3.61090
Value Function Loss: 0.08737

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.60501
Value Function Update Magnitude: 0.67984

Collected Steps per Second: 22,846.27151
Overall Steps per Second: 10,741.52389

Timestep Collection Time: 2.18872
Timestep Consumption Time: 2.46649
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.65521

Cumulative Model Updates: 99,826
Cumulative Timesteps: 832,520,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,844.24869
Policy Entropy: 3.61098
Value Function Loss: 0.08785

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.67502

Collected Steps per Second: 22,742.63644
Overall Steps per Second: 10,802.84306

Timestep Collection Time: 2.19895
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62934

Cumulative Model Updates: 99,832
Cumulative Timesteps: 832,570,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 832570302...
Checkpoint 832570302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,712.70700
Policy Entropy: 3.61315
Value Function Loss: 0.08583

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.55742
Value Function Update Magnitude: 0.80547

Collected Steps per Second: 22,531.96466
Overall Steps per Second: 10,790.37001

Timestep Collection Time: 2.21978
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.63524

Cumulative Model Updates: 99,838
Cumulative Timesteps: 832,620,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,677.20398
Policy Entropy: 3.61085
Value Function Loss: 0.08117

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.57289
Value Function Update Magnitude: 0.90292

Collected Steps per Second: 23,189.73389
Overall Steps per Second: 10,885.62496

Timestep Collection Time: 2.15630
Timestep Consumption Time: 2.43728
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.59358

Cumulative Model Updates: 99,844
Cumulative Timesteps: 832,670,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 832670322...
Checkpoint 832670322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.82045
Policy Entropy: 3.61533
Value Function Loss: 0.07590

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.61358
Value Function Update Magnitude: 0.90866

Collected Steps per Second: 22,307.88485
Overall Steps per Second: 10,636.09148

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.70248

Cumulative Model Updates: 99,850
Cumulative Timesteps: 832,720,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,964.10077
Policy Entropy: 3.62194
Value Function Loss: 0.07555

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.67885
Value Function Update Magnitude: 0.87965

Collected Steps per Second: 22,292.51861
Overall Steps per Second: 10,587.49795

Timestep Collection Time: 2.24326
Timestep Consumption Time: 2.48004
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.72331

Cumulative Model Updates: 99,856
Cumulative Timesteps: 832,770,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 832770346...
Checkpoint 832770346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.09822
Policy Entropy: 3.61876
Value Function Loss: 0.07639

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.67227
Value Function Update Magnitude: 0.81410

Collected Steps per Second: 22,434.08625
Overall Steps per Second: 10,621.33470

Timestep Collection Time: 2.22955
Timestep Consumption Time: 2.47965
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.70920

Cumulative Model Updates: 99,862
Cumulative Timesteps: 832,820,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,291.10430
Policy Entropy: 3.61198
Value Function Loss: 0.08034

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.80994

Collected Steps per Second: 22,620.77749
Overall Steps per Second: 10,717.22575

Timestep Collection Time: 2.21053
Timestep Consumption Time: 2.45523
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.66576

Cumulative Model Updates: 99,868
Cumulative Timesteps: 832,870,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 832870368...
Checkpoint 832870368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,732.20774
Policy Entropy: 3.61234
Value Function Loss: 0.07780

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.61504
Value Function Update Magnitude: 0.82315

Collected Steps per Second: 21,228.49522
Overall Steps per Second: 10,228.38529

Timestep Collection Time: 2.35721
Timestep Consumption Time: 2.53506
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.89227

Cumulative Model Updates: 99,874
Cumulative Timesteps: 832,920,408

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,591.21729
Policy Entropy: 3.63212
Value Function Loss: 0.07724

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.63132
Value Function Update Magnitude: 0.89230

Collected Steps per Second: 22,567.24014
Overall Steps per Second: 10,490.81761

Timestep Collection Time: 2.21631
Timestep Consumption Time: 2.55129
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.76760

Cumulative Model Updates: 99,880
Cumulative Timesteps: 832,970,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 832970424...
Checkpoint 832970424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,437.46562
Policy Entropy: 3.63238
Value Function Loss: 0.07699

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.93515

Collected Steps per Second: 22,667.83323
Overall Steps per Second: 10,594.02079

Timestep Collection Time: 2.20683
Timestep Consumption Time: 2.51508
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.72191

Cumulative Model Updates: 99,886
Cumulative Timesteps: 833,020,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,940.65334
Policy Entropy: 3.62975
Value Function Loss: 0.07548

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.60842
Value Function Update Magnitude: 0.89607

Collected Steps per Second: 22,753.70628
Overall Steps per Second: 10,853.67223

Timestep Collection Time: 2.19762
Timestep Consumption Time: 2.40948
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60710

Cumulative Model Updates: 99,892
Cumulative Timesteps: 833,070,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 833070452...
Checkpoint 833070452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,526.85529
Policy Entropy: 3.60839
Value Function Loss: 0.08040

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.65987
Value Function Update Magnitude: 0.77861

Collected Steps per Second: 22,665.89869
Overall Steps per Second: 10,787.31900

Timestep Collection Time: 2.20666
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.63656

Cumulative Model Updates: 99,898
Cumulative Timesteps: 833,120,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.87146
Policy Entropy: 3.60952
Value Function Loss: 0.08113

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.67810

Collected Steps per Second: 22,820.14720
Overall Steps per Second: 10,834.27162

Timestep Collection Time: 2.19201
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.61702

Cumulative Model Updates: 99,904
Cumulative Timesteps: 833,170,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 833170490...
Checkpoint 833170490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,399.64912
Policy Entropy: 3.60726
Value Function Loss: 0.08474

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.50408
Value Function Update Magnitude: 0.65655

Collected Steps per Second: 22,813.60011
Overall Steps per Second: 10,772.56134

Timestep Collection Time: 2.19229
Timestep Consumption Time: 2.45043
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.64272

Cumulative Model Updates: 99,910
Cumulative Timesteps: 833,220,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,044.42554
Policy Entropy: 3.61823
Value Function Loss: 0.08618

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.55210
Value Function Update Magnitude: 0.71668

Collected Steps per Second: 22,695.70623
Overall Steps per Second: 10,671.08219

Timestep Collection Time: 2.20429
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.68818

Cumulative Model Updates: 99,916
Cumulative Timesteps: 833,270,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 833270532...
Checkpoint 833270532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,044.85506
Policy Entropy: 3.60340
Value Function Loss: 0.08762

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.72607

Collected Steps per Second: 22,704.83618
Overall Steps per Second: 10,805.19297

Timestep Collection Time: 2.20288
Timestep Consumption Time: 2.42601
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62889

Cumulative Model Updates: 99,922
Cumulative Timesteps: 833,320,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,364.96606
Policy Entropy: 3.60403
Value Function Loss: 0.08772

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.74198

Collected Steps per Second: 22,560.91209
Overall Steps per Second: 10,570.11962

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.51460
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.73126

Cumulative Model Updates: 99,928
Cumulative Timesteps: 833,370,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 833370558...
Checkpoint 833370558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,308.93785
Policy Entropy: 3.59802
Value Function Loss: 0.08488

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.19571
Policy Update Magnitude: 0.49746
Value Function Update Magnitude: 0.77493

Collected Steps per Second: 22,751.00426
Overall Steps per Second: 10,601.55425

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.51879
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.71667

Cumulative Model Updates: 99,934
Cumulative Timesteps: 833,420,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,233.45813
Policy Entropy: 3.59943
Value Function Loss: 0.08337

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.16799
Policy Update Magnitude: 0.52035
Value Function Update Magnitude: 0.78730

Collected Steps per Second: 22,910.74121
Overall Steps per Second: 10,883.44819

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.41320
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.59689

Cumulative Model Updates: 99,940
Cumulative Timesteps: 833,470,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 833470592...
Checkpoint 833470592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.53501
Policy Entropy: 3.61235
Value Function Loss: 0.08274

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.57515
Value Function Update Magnitude: 0.80787

Collected Steps per Second: 22,713.28930
Overall Steps per Second: 10,685.36020

Timestep Collection Time: 2.20179
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.68024

Cumulative Model Updates: 99,946
Cumulative Timesteps: 833,520,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,393.88629
Policy Entropy: 3.60574
Value Function Loss: 0.07898

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.66611
Value Function Update Magnitude: 0.81833

Collected Steps per Second: 22,796.71974
Overall Steps per Second: 10,811.57690

Timestep Collection Time: 2.19382
Timestep Consumption Time: 2.43196
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.62578

Cumulative Model Updates: 99,952
Cumulative Timesteps: 833,570,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 833570614...
Checkpoint 833570614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,619.44173
Policy Entropy: 3.61213
Value Function Loss: 0.07907

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.76887
Value Function Update Magnitude: 0.74043

Collected Steps per Second: 22,699.25001
Overall Steps per Second: 10,706.71169

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.67109

Cumulative Model Updates: 99,958
Cumulative Timesteps: 833,620,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,626.72762
Policy Entropy: 3.60707
Value Function Loss: 0.07950

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.83130
Value Function Update Magnitude: 0.70399

Collected Steps per Second: 22,564.90931
Overall Steps per Second: 10,640.13945

Timestep Collection Time: 2.21592
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.69937

Cumulative Model Updates: 99,964
Cumulative Timesteps: 833,670,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 833670628...
Checkpoint 833670628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,595.35107
Policy Entropy: 3.60656
Value Function Loss: 0.08557

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.69569
Value Function Update Magnitude: 0.66175

Collected Steps per Second: 22,662.07866
Overall Steps per Second: 10,806.14031

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62755

Cumulative Model Updates: 99,970
Cumulative Timesteps: 833,720,634

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,596.22699
Policy Entropy: 3.60720
Value Function Loss: 0.08781

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.65979

Collected Steps per Second: 22,510.84621
Overall Steps per Second: 10,573.17681

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.72933

Cumulative Model Updates: 99,976
Cumulative Timesteps: 833,770,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 833770638...
Checkpoint 833770638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,765.48725
Policy Entropy: 3.61047
Value Function Loss: 0.09043

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.47470
Value Function Update Magnitude: 0.75176

Collected Steps per Second: 22,429.16843
Overall Steps per Second: 10,656.30579

Timestep Collection Time: 2.23049
Timestep Consumption Time: 2.46420
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.69469

Cumulative Model Updates: 99,982
Cumulative Timesteps: 833,820,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,113.04835
Policy Entropy: 3.60325
Value Function Loss: 0.08666

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.47264
Value Function Update Magnitude: 0.76875

Collected Steps per Second: 22,646.91923
Overall Steps per Second: 10,770.19185

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.64523

Cumulative Model Updates: 99,988
Cumulative Timesteps: 833,870,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 833870696...
Checkpoint 833870696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,486.33692
Policy Entropy: 3.60786
Value Function Loss: 0.08638

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.49229
Value Function Update Magnitude: 0.68185

Collected Steps per Second: 22,338.66395
Overall Steps per Second: 10,695.83798

Timestep Collection Time: 2.23935
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.67696

Cumulative Model Updates: 99,994
Cumulative Timesteps: 833,920,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,672.86891
Policy Entropy: 3.60432
Value Function Loss: 0.08489

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.48926
Value Function Update Magnitude: 0.67503

Collected Steps per Second: 22,517.12651
Overall Steps per Second: 10,476.61477

Timestep Collection Time: 2.22178
Timestep Consumption Time: 2.55343
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.77521

Cumulative Model Updates: 100,000
Cumulative Timesteps: 833,970,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 833970748...
Checkpoint 833970748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,529.28719
Policy Entropy: 3.62569
Value Function Loss: 0.08725

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.49508
Value Function Update Magnitude: 0.65297

Collected Steps per Second: 22,652.43049
Overall Steps per Second: 10,627.21430

Timestep Collection Time: 2.20789
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.70622

Cumulative Model Updates: 100,006
Cumulative Timesteps: 834,020,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.77894
Policy Entropy: 3.60510
Value Function Loss: 0.08751

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.62336

Collected Steps per Second: 22,660.84242
Overall Steps per Second: 10,628.13073

Timestep Collection Time: 2.20751
Timestep Consumption Time: 2.49925
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70675

Cumulative Model Updates: 100,012
Cumulative Timesteps: 834,070,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 834070786...
Checkpoint 834070786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,558.79955
Policy Entropy: 3.60610
Value Function Loss: 0.08820

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.52177
Value Function Update Magnitude: 0.61264

Collected Steps per Second: 22,904.88677
Overall Steps per Second: 10,838.21599

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.61349

Cumulative Model Updates: 100,018
Cumulative Timesteps: 834,120,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,876.45500
Policy Entropy: 3.59232
Value Function Loss: 0.08697

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.63522

Collected Steps per Second: 22,675.69275
Overall Steps per Second: 10,604.70077

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.71602

Cumulative Model Updates: 100,024
Cumulative Timesteps: 834,170,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 834170800...
Checkpoint 834170800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,470.22503
Policy Entropy: 3.59450
Value Function Loss: 0.08731

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.64237

Collected Steps per Second: 22,766.66602
Overall Steps per Second: 10,744.06933

Timestep Collection Time: 2.19725
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.65596

Cumulative Model Updates: 100,030
Cumulative Timesteps: 834,220,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,010.78964
Policy Entropy: 3.59499
Value Function Loss: 0.08852

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.57819
Value Function Update Magnitude: 0.66146

Collected Steps per Second: 22,823.71310
Overall Steps per Second: 10,768.05232

Timestep Collection Time: 2.19158
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.64522

Cumulative Model Updates: 100,036
Cumulative Timesteps: 834,270,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 834270844...
Checkpoint 834270844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,605.12952
Policy Entropy: 3.59609
Value Function Loss: 0.08542

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.51824
Value Function Update Magnitude: 0.76545

Collected Steps per Second: 22,417.11935
Overall Steps per Second: 10,598.81369

Timestep Collection Time: 2.23080
Timestep Consumption Time: 2.48747
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.71826

Cumulative Model Updates: 100,042
Cumulative Timesteps: 834,320,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,235.67988
Policy Entropy: 3.61456
Value Function Loss: 0.08348

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.51590
Value Function Update Magnitude: 0.78076

Collected Steps per Second: 22,526.20295
Overall Steps per Second: 10,593.55512

Timestep Collection Time: 2.22017
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.72098

Cumulative Model Updates: 100,048
Cumulative Timesteps: 834,370,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 834370864...
Checkpoint 834370864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,422.02138
Policy Entropy: 3.61711
Value Function Loss: 0.08241

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.57547
Value Function Update Magnitude: 0.75594

Collected Steps per Second: 22,385.09308
Overall Steps per Second: 10,557.42882

Timestep Collection Time: 2.23381
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.73638

Cumulative Model Updates: 100,054
Cumulative Timesteps: 834,420,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.53544
Policy Entropy: 3.61092
Value Function Loss: 0.08641

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.64652
Value Function Update Magnitude: 0.69992

Collected Steps per Second: 22,669.06715
Overall Steps per Second: 10,782.12948

Timestep Collection Time: 2.20644
Timestep Consumption Time: 2.43253
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.63897

Cumulative Model Updates: 100,060
Cumulative Timesteps: 834,470,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 834470886...
Checkpoint 834470886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,362.15338
Policy Entropy: 3.60128
Value Function Loss: 0.08915

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.72871
Value Function Update Magnitude: 0.80608

Collected Steps per Second: 22,888.76828
Overall Steps per Second: 10,774.43648

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.64266

Cumulative Model Updates: 100,066
Cumulative Timesteps: 834,520,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,486.55687
Policy Entropy: 3.60558
Value Function Loss: 0.08965

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.66894
Value Function Update Magnitude: 0.88788

Collected Steps per Second: 22,820.70751
Overall Steps per Second: 10,802.18977

Timestep Collection Time: 2.19222
Timestep Consumption Time: 2.43906
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.63128

Cumulative Model Updates: 100,072
Cumulative Timesteps: 834,570,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 834570936...
Checkpoint 834570936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,287.44222
Policy Entropy: 3.60341
Value Function Loss: 0.09239

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.79339

Collected Steps per Second: 22,711.68963
Overall Steps per Second: 10,669.93806

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68644

Cumulative Model Updates: 100,078
Cumulative Timesteps: 834,620,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,954.13436
Policy Entropy: 3.59909
Value Function Loss: 0.09290

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.67995

Collected Steps per Second: 23,270.63276
Overall Steps per Second: 10,902.91744

Timestep Collection Time: 2.14906
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.58685

Cumulative Model Updates: 100,084
Cumulative Timesteps: 834,670,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 834670950...
Checkpoint 834670950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,756.13239
Policy Entropy: 3.59846
Value Function Loss: 0.09522

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.67064

Collected Steps per Second: 22,661.25728
Overall Steps per Second: 10,662.50999

Timestep Collection Time: 2.20764
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.69195

Cumulative Model Updates: 100,090
Cumulative Timesteps: 834,720,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.21093
Policy Entropy: 3.59992
Value Function Loss: 0.09020

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.79220
Value Function Update Magnitude: 0.73832

Collected Steps per Second: 22,610.67595
Overall Steps per Second: 10,665.23758

Timestep Collection Time: 2.21205
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.68963

Cumulative Model Updates: 100,096
Cumulative Timesteps: 834,770,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 834770994...
Checkpoint 834770994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,979.45308
Policy Entropy: 3.59739
Value Function Loss: 0.09291

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.74852
Value Function Update Magnitude: 0.68746

Collected Steps per Second: 22,536.35913
Overall Steps per Second: 10,664.43728

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.69223

Cumulative Model Updates: 100,102
Cumulative Timesteps: 834,821,034

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,844.40297
Policy Entropy: 3.60659
Value Function Loss: 0.09161

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.17595
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.67354

Collected Steps per Second: 22,845.38608
Overall Steps per Second: 10,673.05821

Timestep Collection Time: 2.18933
Timestep Consumption Time: 2.49687
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68619

Cumulative Model Updates: 100,108
Cumulative Timesteps: 834,871,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 834871050...
Checkpoint 834871050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.71238
Policy Entropy: 3.60950
Value Function Loss: 0.09037

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.50968
Value Function Update Magnitude: 0.76217

Collected Steps per Second: 22,362.37304
Overall Steps per Second: 10,657.15325

Timestep Collection Time: 2.23599
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.69187

Cumulative Model Updates: 100,114
Cumulative Timesteps: 834,921,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,964.93945
Policy Entropy: 3.63276
Value Function Loss: 0.08700

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.80034

Collected Steps per Second: 21,415.68576
Overall Steps per Second: 10,449.76725

Timestep Collection Time: 2.33548
Timestep Consumption Time: 2.45084
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.78633

Cumulative Model Updates: 100,120
Cumulative Timesteps: 834,971,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 834971068...
Checkpoint 834971068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.13141
Policy Entropy: 3.61500
Value Function Loss: 0.08520

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.55568
Value Function Update Magnitude: 0.76821

Collected Steps per Second: 22,209.78425
Overall Steps per Second: 10,659.89168

Timestep Collection Time: 2.25135
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.69067

Cumulative Model Updates: 100,126
Cumulative Timesteps: 835,021,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,297.06027
Policy Entropy: 3.61926
Value Function Loss: 0.08572

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.77539

Collected Steps per Second: 23,200.12887
Overall Steps per Second: 10,810.06524

Timestep Collection Time: 2.15594
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.62698

Cumulative Model Updates: 100,132
Cumulative Timesteps: 835,071,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 835071088...
Checkpoint 835071088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,576.87905
Policy Entropy: 3.62669
Value Function Loss: 0.08635

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.61073
Value Function Update Magnitude: 0.82241

Collected Steps per Second: 22,950.06065
Overall Steps per Second: 10,680.30333

Timestep Collection Time: 2.17925
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.68283

Cumulative Model Updates: 100,138
Cumulative Timesteps: 835,121,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,340.40991
Policy Entropy: 3.62015
Value Function Loss: 0.08649

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.66671
Value Function Update Magnitude: 0.77583

Collected Steps per Second: 22,923.62270
Overall Steps per Second: 10,864.61498

Timestep Collection Time: 2.18168
Timestep Consumption Time: 2.42152
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.60320

Cumulative Model Updates: 100,144
Cumulative Timesteps: 835,171,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 835171114...
Checkpoint 835171114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,710.35939
Policy Entropy: 3.61812
Value Function Loss: 0.09022

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.56400
Value Function Update Magnitude: 0.73256

Collected Steps per Second: 22,510.39407
Overall Steps per Second: 10,708.68318

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.67098

Cumulative Model Updates: 100,150
Cumulative Timesteps: 835,221,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.47818
Policy Entropy: 3.59423
Value Function Loss: 0.09122

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.55567
Value Function Update Magnitude: 0.68875

Collected Steps per Second: 22,788.42405
Overall Steps per Second: 10,662.76954

Timestep Collection Time: 2.19418
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.68940

Cumulative Model Updates: 100,156
Cumulative Timesteps: 835,271,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 835271136...
Checkpoint 835271136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,698.40643
Policy Entropy: 3.59482
Value Function Loss: 0.08940

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.48473
Value Function Update Magnitude: 0.68599

Collected Steps per Second: 22,986.55424
Overall Steps per Second: 10,866.40656

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.60502

Cumulative Model Updates: 100,162
Cumulative Timesteps: 835,321,176

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,829.72919
Policy Entropy: 3.59647
Value Function Loss: 0.09099

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.51093
Value Function Update Magnitude: 0.69500

Collected Steps per Second: 22,263.49280
Overall Steps per Second: 10,502.35715

Timestep Collection Time: 2.24610
Timestep Consumption Time: 2.51531
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.76141

Cumulative Model Updates: 100,168
Cumulative Timesteps: 835,371,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 835371182...
Checkpoint 835371182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,124.56680
Policy Entropy: 3.59653
Value Function Loss: 0.09235

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.64476
Value Function Update Magnitude: 0.72295

Collected Steps per Second: 22,605.91500
Overall Steps per Second: 10,627.22176

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.70622

Cumulative Model Updates: 100,174
Cumulative Timesteps: 835,421,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,572.80046
Policy Entropy: 3.58545
Value Function Loss: 0.09304

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.60903
Value Function Update Magnitude: 0.68357

Collected Steps per Second: 22,595.20188
Overall Steps per Second: 10,664.76169

Timestep Collection Time: 2.21419
Timestep Consumption Time: 2.47696
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69115

Cumulative Model Updates: 100,180
Cumulative Timesteps: 835,471,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 835471226...
Checkpoint 835471226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,185.24083
Policy Entropy: 3.59168
Value Function Loss: 0.09091

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.59294
Value Function Update Magnitude: 0.68048

Collected Steps per Second: 22,664.78032
Overall Steps per Second: 10,608.43800

Timestep Collection Time: 2.20660
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.71436

Cumulative Model Updates: 100,186
Cumulative Timesteps: 835,521,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.31854
Policy Entropy: 3.58962
Value Function Loss: 0.08875

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.57773
Value Function Update Magnitude: 0.75444

Collected Steps per Second: 22,971.74957
Overall Steps per Second: 10,738.01958

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.47977
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.65635

Cumulative Model Updates: 100,192
Cumulative Timesteps: 835,571,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 835571238...
Checkpoint 835571238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,789.77735
Policy Entropy: 3.58175
Value Function Loss: 0.08916

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.57602
Value Function Update Magnitude: 0.76096

Collected Steps per Second: 22,957.22497
Overall Steps per Second: 10,699.71093

Timestep Collection Time: 2.17944
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.67620

Cumulative Model Updates: 100,198
Cumulative Timesteps: 835,621,272

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,425.60950
Policy Entropy: 3.58820
Value Function Loss: 0.08942

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.82883

Collected Steps per Second: 22,831.76327
Overall Steps per Second: 10,804.51456

Timestep Collection Time: 2.19011
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62807

Cumulative Model Updates: 100,204
Cumulative Timesteps: 835,671,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 835671276...
Checkpoint 835671276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.12832
Policy Entropy: 3.59571
Value Function Loss: 0.08802

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.18048
Policy Update Magnitude: 0.49368
Value Function Update Magnitude: 0.88180

Collected Steps per Second: 23,005.36701
Overall Steps per Second: 10,800.67579

Timestep Collection Time: 2.17393
Timestep Consumption Time: 2.45652
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.63045

Cumulative Model Updates: 100,210
Cumulative Timesteps: 835,721,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,853.19987
Policy Entropy: 3.60949
Value Function Loss: 0.08380

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.57024
Value Function Update Magnitude: 0.85375

Collected Steps per Second: 22,883.50981
Overall Steps per Second: 10,788.58937

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.63638

Cumulative Model Updates: 100,216
Cumulative Timesteps: 835,771,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 835771308...
Checkpoint 835771308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,008.12070
Policy Entropy: 3.61860
Value Function Loss: 0.08174

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.64114
Value Function Update Magnitude: 0.77407

Collected Steps per Second: 22,772.14309
Overall Steps per Second: 10,670.22184

Timestep Collection Time: 2.19663
Timestep Consumption Time: 2.49137
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.68800

Cumulative Model Updates: 100,222
Cumulative Timesteps: 835,821,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,814.63512
Policy Entropy: 3.61428
Value Function Loss: 0.07951

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.55638
Value Function Update Magnitude: 0.71996

Collected Steps per Second: 22,441.08587
Overall Steps per Second: 10,563.02418

Timestep Collection Time: 2.22895
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.73539

Cumulative Model Updates: 100,228
Cumulative Timesteps: 835,871,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 835871350...
Checkpoint 835871350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,160.16498
Policy Entropy: 3.61424
Value Function Loss: 0.08074

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.58535
Value Function Update Magnitude: 0.68858

Collected Steps per Second: 22,313.17535
Overall Steps per Second: 10,548.12223

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.74056

Cumulative Model Updates: 100,234
Cumulative Timesteps: 835,921,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.00471
Policy Entropy: 3.61303
Value Function Loss: 0.07880

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.59205
Value Function Update Magnitude: 0.77716

Collected Steps per Second: 22,434.79110
Overall Steps per Second: 10,612.82554

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.71317

Cumulative Model Updates: 100,240
Cumulative Timesteps: 835,971,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 835971374...
Checkpoint 835971374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,473.53123
Policy Entropy: 3.60999
Value Function Loss: 0.07918

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.61195
Value Function Update Magnitude: 0.80784

Collected Steps per Second: 22,579.12342
Overall Steps per Second: 10,663.45664

Timestep Collection Time: 2.21541
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.69097

Cumulative Model Updates: 100,246
Cumulative Timesteps: 836,021,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,273.74842
Policy Entropy: 3.61893
Value Function Loss: 0.07549

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.62666
Value Function Update Magnitude: 0.67185

Collected Steps per Second: 23,095.67910
Overall Steps per Second: 10,677.25294

Timestep Collection Time: 2.16525
Timestep Consumption Time: 2.51835
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.68360

Cumulative Model Updates: 100,252
Cumulative Timesteps: 836,071,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 836071404...
Checkpoint 836071404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,078.17092
Policy Entropy: 3.62525
Value Function Loss: 0.07695

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.59842
Value Function Update Magnitude: 0.59426

Collected Steps per Second: 22,732.70139
Overall Steps per Second: 10,602.34962

Timestep Collection Time: 2.20044
Timestep Consumption Time: 2.51757
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.71801

Cumulative Model Updates: 100,258
Cumulative Timesteps: 836,121,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,829.03246
Policy Entropy: 3.63448
Value Function Loss: 0.07244

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.58007
Value Function Update Magnitude: 0.62184

Collected Steps per Second: 22,737.85508
Overall Steps per Second: 10,675.97357

Timestep Collection Time: 2.19942
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68435

Cumulative Model Updates: 100,264
Cumulative Timesteps: 836,171,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836171436...
Checkpoint 836171436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.11542
Policy Entropy: 3.65163
Value Function Loss: 0.07275

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.61536

Collected Steps per Second: 23,125.22679
Overall Steps per Second: 10,884.56956

Timestep Collection Time: 2.16249
Timestep Consumption Time: 2.43191
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.59439

Cumulative Model Updates: 100,270
Cumulative Timesteps: 836,221,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,767.17741
Policy Entropy: 3.63843
Value Function Loss: 0.06973

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.59724
Value Function Update Magnitude: 0.66577

Collected Steps per Second: 22,831.66950
Overall Steps per Second: 10,666.78158

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.68745

Cumulative Model Updates: 100,276
Cumulative Timesteps: 836,271,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 836271444...
Checkpoint 836271444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,345.94554
Policy Entropy: 3.61756
Value Function Loss: 0.07480

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.63066
Value Function Update Magnitude: 0.67812

Collected Steps per Second: 22,882.99257
Overall Steps per Second: 10,853.08772

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.42225
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.60754

Cumulative Model Updates: 100,282
Cumulative Timesteps: 836,321,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,666.43248
Policy Entropy: 3.61766
Value Function Loss: 0.07890

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.67900

Collected Steps per Second: 22,751.87648
Overall Steps per Second: 10,677.37016

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.48657
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.68542

Cumulative Model Updates: 100,288
Cumulative Timesteps: 836,371,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 836371478...
Checkpoint 836371478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,120.29967
Policy Entropy: 3.61360
Value Function Loss: 0.08247

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.68327

Collected Steps per Second: 22,531.23118
Overall Steps per Second: 10,625.75561

Timestep Collection Time: 2.21950
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70630

Cumulative Model Updates: 100,294
Cumulative Timesteps: 836,421,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,687.09642
Policy Entropy: 3.61491
Value Function Loss: 0.08357

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.52035
Value Function Update Magnitude: 0.66101

Collected Steps per Second: 22,705.88323
Overall Steps per Second: 10,792.95391

Timestep Collection Time: 2.20287
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.63432

Cumulative Model Updates: 100,300
Cumulative Timesteps: 836,471,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 836471504...
Checkpoint 836471504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,499.44659
Policy Entropy: 3.60915
Value Function Loss: 0.08578

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.47642
Value Function Update Magnitude: 0.64942

Collected Steps per Second: 22,283.83760
Overall Steps per Second: 10,599.14388

Timestep Collection Time: 2.24432
Timestep Consumption Time: 2.47418
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.71849

Cumulative Model Updates: 100,306
Cumulative Timesteps: 836,521,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,577.77950
Policy Entropy: 3.60731
Value Function Loss: 0.08437

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.46359
Value Function Update Magnitude: 0.63575

Collected Steps per Second: 22,475.60042
Overall Steps per Second: 10,593.72838

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.72072

Cumulative Model Updates: 100,312
Cumulative Timesteps: 836,571,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836571526...
Checkpoint 836571526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,230.10779
Policy Entropy: 3.60497
Value Function Loss: 0.08509

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.46261
Value Function Update Magnitude: 0.61592

Collected Steps per Second: 22,824.19063
Overall Steps per Second: 10,634.07749

Timestep Collection Time: 2.19171
Timestep Consumption Time: 2.51241
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.70412

Cumulative Model Updates: 100,318
Cumulative Timesteps: 836,621,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,579.54978
Policy Entropy: 3.61007
Value Function Loss: 0.08313

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.46810
Value Function Update Magnitude: 0.59625

Collected Steps per Second: 22,851.33795
Overall Steps per Second: 10,667.65119

Timestep Collection Time: 2.18849
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.68800

Cumulative Model Updates: 100,324
Cumulative Timesteps: 836,671,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836671560...
Checkpoint 836671560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,187.55220
Policy Entropy: 3.60779
Value Function Loss: 0.08597

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.56817
Value Function Update Magnitude: 0.61042

Collected Steps per Second: 22,817.01444
Overall Steps per Second: 10,697.43119

Timestep Collection Time: 2.19205
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.67552

Cumulative Model Updates: 100,330
Cumulative Timesteps: 836,721,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,915.49609
Policy Entropy: 3.61637
Value Function Loss: 0.08442

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.71854

Collected Steps per Second: 22,915.16944
Overall Steps per Second: 10,838.20313

Timestep Collection Time: 2.18292
Timestep Consumption Time: 2.43242
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.61534

Cumulative Model Updates: 100,336
Cumulative Timesteps: 836,771,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 836771598...
Checkpoint 836771598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.55131
Policy Entropy: 3.61347
Value Function Loss: 0.08611

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.18309
Policy Update Magnitude: 0.47240
Value Function Update Magnitude: 0.74154

Collected Steps per Second: 20,434.53004
Overall Steps per Second: 9,961.03674

Timestep Collection Time: 2.44703
Timestep Consumption Time: 2.57292
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 5.01996

Cumulative Model Updates: 100,342
Cumulative Timesteps: 836,821,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,042.72650
Policy Entropy: 3.62338
Value Function Loss: 0.08442

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.16291
Policy Update Magnitude: 0.42820
Value Function Update Magnitude: 0.67292

Collected Steps per Second: 21,793.46266
Overall Steps per Second: 10,398.03052

Timestep Collection Time: 2.29546
Timestep Consumption Time: 2.51564
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.81110

Cumulative Model Updates: 100,348
Cumulative Timesteps: 836,871,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 836871628...
Checkpoint 836871628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,068.39652
Policy Entropy: 3.62640
Value Function Loss: 0.08081

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.44038
Value Function Update Magnitude: 0.71666

Collected Steps per Second: 22,861.66484
Overall Steps per Second: 10,675.08365

Timestep Collection Time: 2.18715
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.68399

Cumulative Model Updates: 100,354
Cumulative Timesteps: 836,921,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,762.89872
Policy Entropy: 3.62834
Value Function Loss: 0.07658

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.77078

Collected Steps per Second: 22,032.11030
Overall Steps per Second: 10,813.77365

Timestep Collection Time: 2.27069
Timestep Consumption Time: 2.35564
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62632

Cumulative Model Updates: 100,360
Cumulative Timesteps: 836,971,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 836971658...
Checkpoint 836971658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,724.26388
Policy Entropy: 3.62299
Value Function Loss: 0.07674

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.84400

Collected Steps per Second: 21,780.41094
Overall Steps per Second: 10,658.33077

Timestep Collection Time: 2.29564
Timestep Consumption Time: 2.39553
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.69117

Cumulative Model Updates: 100,366
Cumulative Timesteps: 837,021,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,491.15889
Policy Entropy: 3.61474
Value Function Loss: 0.08329

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.52252
Value Function Update Magnitude: 0.84199

Collected Steps per Second: 21,962.10459
Overall Steps per Second: 10,697.94820

Timestep Collection Time: 2.27783
Timestep Consumption Time: 2.39839
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.67622

Cumulative Model Updates: 100,372
Cumulative Timesteps: 837,071,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 837071684...
Checkpoint 837071684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,651.30726
Policy Entropy: 3.62083
Value Function Loss: 0.08207

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.55105
Value Function Update Magnitude: 0.90231

Collected Steps per Second: 21,748.14065
Overall Steps per Second: 10,627.29294

Timestep Collection Time: 2.29932
Timestep Consumption Time: 2.40611
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.70543

Cumulative Model Updates: 100,378
Cumulative Timesteps: 837,121,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,930.19853
Policy Entropy: 3.62156
Value Function Loss: 0.08298

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.60774
Value Function Update Magnitude: 0.78339

Collected Steps per Second: 22,387.13006
Overall Steps per Second: 10,734.79328

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.66241

Cumulative Model Updates: 100,384
Cumulative Timesteps: 837,171,740

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 837171740...
Checkpoint 837171740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,255.52440
Policy Entropy: 3.61850
Value Function Loss: 0.08295

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.60419
Value Function Update Magnitude: 0.69872

Collected Steps per Second: 22,331.83612
Overall Steps per Second: 10,760.65197

Timestep Collection Time: 2.24039
Timestep Consumption Time: 2.40914
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.64953

Cumulative Model Updates: 100,390
Cumulative Timesteps: 837,221,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.29869
Policy Entropy: 3.60966
Value Function Loss: 0.08077

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.56608
Value Function Update Magnitude: 0.68005

Collected Steps per Second: 22,280.28908
Overall Steps per Second: 10,726.44869

Timestep Collection Time: 2.24557
Timestep Consumption Time: 2.41879
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.66436

Cumulative Model Updates: 100,396
Cumulative Timesteps: 837,271,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 837271804...
Checkpoint 837271804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,244.65048
Policy Entropy: 3.61344
Value Function Loss: 0.08188

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.53280
Value Function Update Magnitude: 0.71582

Collected Steps per Second: 22,902.71671
Overall Steps per Second: 10,685.51691

Timestep Collection Time: 2.18376
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.68054

Cumulative Model Updates: 100,402
Cumulative Timesteps: 837,321,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,189.55652
Policy Entropy: 3.61747
Value Function Loss: 0.08215

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.60795
Value Function Update Magnitude: 0.74093

Collected Steps per Second: 22,679.71424
Overall Steps per Second: 10,832.25125

Timestep Collection Time: 2.20470
Timestep Consumption Time: 2.41133
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61603

Cumulative Model Updates: 100,408
Cumulative Timesteps: 837,371,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 837371820...
Checkpoint 837371820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,454.81926
Policy Entropy: 3.61725
Value Function Loss: 0.08037

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.61054
Value Function Update Magnitude: 0.79881

Collected Steps per Second: 22,657.71355
Overall Steps per Second: 10,697.68573

Timestep Collection Time: 2.20675
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.67391

Cumulative Model Updates: 100,414
Cumulative Timesteps: 837,421,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,243.26138
Policy Entropy: 3.60915
Value Function Loss: 0.08252

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.83545

Collected Steps per Second: 22,506.11935
Overall Steps per Second: 10,635.08126

Timestep Collection Time: 2.22188
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.70199

Cumulative Model Updates: 100,420
Cumulative Timesteps: 837,471,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 837471826...
Checkpoint 837471826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,695.84794
Policy Entropy: 3.61443
Value Function Loss: 0.08540

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.52406
Value Function Update Magnitude: 0.77362

Collected Steps per Second: 22,523.79836
Overall Steps per Second: 10,661.44118

Timestep Collection Time: 2.22076
Timestep Consumption Time: 2.47091
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.69167

Cumulative Model Updates: 100,426
Cumulative Timesteps: 837,521,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.31585
Policy Entropy: 3.62908
Value Function Loss: 0.08782

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.16232
Policy Update Magnitude: 0.50071
Value Function Update Magnitude: 0.69330

Collected Steps per Second: 22,721.49114
Overall Steps per Second: 10,708.49823

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.46863
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.66919

Cumulative Model Updates: 100,432
Cumulative Timesteps: 837,571,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 837571846...
Checkpoint 837571846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,704.54048
Policy Entropy: 3.64867
Value Function Loss: 0.08525

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.48282
Value Function Update Magnitude: 0.70836

Collected Steps per Second: 22,475.23605
Overall Steps per Second: 10,616.20256

Timestep Collection Time: 2.22494
Timestep Consumption Time: 2.48541
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.71035

Cumulative Model Updates: 100,438
Cumulative Timesteps: 837,621,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,514.46762
Policy Entropy: 3.65169
Value Function Loss: 0.07884

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.49231
Value Function Update Magnitude: 0.82731

Collected Steps per Second: 22,888.40338
Overall Steps per Second: 10,619.77185

Timestep Collection Time: 2.18521
Timestep Consumption Time: 2.52449
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.70971

Cumulative Model Updates: 100,444
Cumulative Timesteps: 837,671,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 837671868...
Checkpoint 837671868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,039.20372
Policy Entropy: 3.65890
Value Function Loss: 0.07884

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.50836
Value Function Update Magnitude: 0.73217

Collected Steps per Second: 22,666.15897
Overall Steps per Second: 10,693.92590

Timestep Collection Time: 2.20602
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.67574

Cumulative Model Updates: 100,450
Cumulative Timesteps: 837,721,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.99088
Policy Entropy: 3.64548
Value Function Loss: 0.08006

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.58397
Value Function Update Magnitude: 0.65372

Collected Steps per Second: 23,026.24464
Overall Steps per Second: 10,702.92381

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.67461

Cumulative Model Updates: 100,456
Cumulative Timesteps: 837,771,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 837771902...
Checkpoint 837771902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,388.70648
Policy Entropy: 3.64167
Value Function Loss: 0.08101

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.54565
Value Function Update Magnitude: 0.80644

Collected Steps per Second: 22,625.25291
Overall Steps per Second: 10,636.47899

Timestep Collection Time: 2.21125
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.70362

Cumulative Model Updates: 100,462
Cumulative Timesteps: 837,821,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.92204
Policy Entropy: 3.63521
Value Function Loss: 0.08405

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.56836
Value Function Update Magnitude: 0.79334

Collected Steps per Second: 23,143.39299
Overall Steps per Second: 10,888.65125

Timestep Collection Time: 2.16139
Timestep Consumption Time: 2.43256
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59396

Cumulative Model Updates: 100,468
Cumulative Timesteps: 837,871,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 837871954...
Checkpoint 837871954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,404.55424
Policy Entropy: 3.63507
Value Function Loss: 0.08331

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.63497
Value Function Update Magnitude: 0.70551

Collected Steps per Second: 23,049.81134
Overall Steps per Second: 10,721.84725

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.66487

Cumulative Model Updates: 100,474
Cumulative Timesteps: 837,921,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,954.98741
Policy Entropy: 3.63182
Value Function Loss: 0.08044

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.65092
Value Function Update Magnitude: 0.71258

Collected Steps per Second: 22,992.79094
Overall Steps per Second: 10,874.59335

Timestep Collection Time: 2.17590
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.60063

Cumulative Model Updates: 100,480
Cumulative Timesteps: 837,972,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 837972000...
Checkpoint 837972000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,513.04498
Policy Entropy: 3.62622
Value Function Loss: 0.08037

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.64202
Value Function Update Magnitude: 0.71332

Collected Steps per Second: 22,378.81776
Overall Steps per Second: 10,605.64758

Timestep Collection Time: 2.23470
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.71541

Cumulative Model Updates: 100,486
Cumulative Timesteps: 838,022,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,716.49488
Policy Entropy: 3.62637
Value Function Loss: 0.08008

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.63954
Value Function Update Magnitude: 0.70505

Collected Steps per Second: 22,467.94182
Overall Steps per Second: 10,642.93288

Timestep Collection Time: 2.22664
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.70058

Cumulative Model Updates: 100,492
Cumulative Timesteps: 838,072,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 838072038...
Checkpoint 838072038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,949.90979
Policy Entropy: 3.64257
Value Function Loss: 0.08473

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.56198
Value Function Update Magnitude: 0.69661

Collected Steps per Second: 22,463.09685
Overall Steps per Second: 10,651.71782

Timestep Collection Time: 2.22596
Timestep Consumption Time: 2.46830
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.69427

Cumulative Model Updates: 100,498
Cumulative Timesteps: 838,122,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,345.96825
Policy Entropy: 3.63818
Value Function Loss: 0.08334

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.51738
Value Function Update Magnitude: 0.79237

Collected Steps per Second: 23,108.20244
Overall Steps per Second: 10,702.38470

Timestep Collection Time: 2.16469
Timestep Consumption Time: 2.50923
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.67391

Cumulative Model Updates: 100,504
Cumulative Timesteps: 838,172,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 838172062...
Checkpoint 838172062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,269.60006
Policy Entropy: 3.64316
Value Function Loss: 0.08436

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.85522

Collected Steps per Second: 22,161.47235
Overall Steps per Second: 10,659.38692

Timestep Collection Time: 2.25716
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.69277

Cumulative Model Updates: 100,510
Cumulative Timesteps: 838,222,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,998.40256
Policy Entropy: 3.62972
Value Function Loss: 0.08134

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.88355

Collected Steps per Second: 22,248.22153
Overall Steps per Second: 10,778.97965

Timestep Collection Time: 2.24818
Timestep Consumption Time: 2.39215
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.64033

Cumulative Model Updates: 100,516
Cumulative Timesteps: 838,272,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 838272102...
Checkpoint 838272102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,325.06770
Policy Entropy: 3.62142
Value Function Loss: 0.08569

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.53970
Value Function Update Magnitude: 0.84098

Collected Steps per Second: 22,072.51880
Overall Steps per Second: 10,735.07287

Timestep Collection Time: 2.26635
Timestep Consumption Time: 2.39352
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.65987

Cumulative Model Updates: 100,522
Cumulative Timesteps: 838,322,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,871.75583
Policy Entropy: 3.61289
Value Function Loss: 0.08768

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.47508
Value Function Update Magnitude: 0.79751

Collected Steps per Second: 22,066.89971
Overall Steps per Second: 10,860.33216

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.33948
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.60667

Cumulative Model Updates: 100,528
Cumulative Timesteps: 838,372,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 838372156...
Checkpoint 838372156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,831.29827
Policy Entropy: 3.61476
Value Function Loss: 0.08982

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.48373
Value Function Update Magnitude: 0.69865

Collected Steps per Second: 21,865.18185
Overall Steps per Second: 10,724.00821

Timestep Collection Time: 2.28747
Timestep Consumption Time: 2.37646
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.66393

Cumulative Model Updates: 100,534
Cumulative Timesteps: 838,422,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,471.49631
Policy Entropy: 3.61501
Value Function Loss: 0.09102

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.54359
Value Function Update Magnitude: 0.65423

Collected Steps per Second: 22,302.90415
Overall Steps per Second: 10,637.67327

Timestep Collection Time: 2.24294
Timestep Consumption Time: 2.45960
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.70253

Cumulative Model Updates: 100,540
Cumulative Timesteps: 838,472,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 838472196...
Checkpoint 838472196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.65262
Policy Entropy: 3.62303
Value Function Loss: 0.09147

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.53186
Value Function Update Magnitude: 0.66964

Collected Steps per Second: 22,536.61626
Overall Steps per Second: 10,845.24023

Timestep Collection Time: 2.21985
Timestep Consumption Time: 2.39305
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.61290

Cumulative Model Updates: 100,546
Cumulative Timesteps: 838,522,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.40182
Policy Entropy: 3.60955
Value Function Loss: 0.09508

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.57373
Value Function Update Magnitude: 0.69207

Collected Steps per Second: 22,451.63002
Overall Steps per Second: 10,660.92014

Timestep Collection Time: 2.22790
Timestep Consumption Time: 2.46400
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.69190

Cumulative Model Updates: 100,552
Cumulative Timesteps: 838,572,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 838572244...
Checkpoint 838572244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,242.15038
Policy Entropy: 3.59757
Value Function Loss: 0.09616

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.58127
Value Function Update Magnitude: 0.74464

Collected Steps per Second: 22,583.68043
Overall Steps per Second: 10,871.62286

Timestep Collection Time: 2.21620
Timestep Consumption Time: 2.38753
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60373

Cumulative Model Updates: 100,558
Cumulative Timesteps: 838,622,294

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,991.38363
Policy Entropy: 3.58925
Value Function Loss: 0.09866

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.70443

Collected Steps per Second: 22,985.69763
Overall Steps per Second: 10,682.74638

Timestep Collection Time: 2.17596
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.68194

Cumulative Model Updates: 100,564
Cumulative Timesteps: 838,672,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 838672310...
Checkpoint 838672310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,139.09543
Policy Entropy: 3.57579
Value Function Loss: 0.09886

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.67971

Collected Steps per Second: 22,821.43885
Overall Steps per Second: 10,841.72138

Timestep Collection Time: 2.19180
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61366

Cumulative Model Updates: 100,570
Cumulative Timesteps: 838,722,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,092.87168
Policy Entropy: 3.57080
Value Function Loss: 0.09801

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.64021

Collected Steps per Second: 22,687.79210
Overall Steps per Second: 10,604.06964

Timestep Collection Time: 2.20453
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.71668

Cumulative Model Updates: 100,576
Cumulative Timesteps: 838,772,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 838772346...
Checkpoint 838772346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.14273
Policy Entropy: 3.57640
Value Function Loss: 0.09549

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.49769
Value Function Update Magnitude: 0.64365

Collected Steps per Second: 22,582.88955
Overall Steps per Second: 10,610.38586

Timestep Collection Time: 2.21513
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.71463

Cumulative Model Updates: 100,582
Cumulative Timesteps: 838,822,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,363.52888
Policy Entropy: 3.58431
Value Function Loss: 0.09262

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.18651
Policy Update Magnitude: 0.49921
Value Function Update Magnitude: 0.72508

Collected Steps per Second: 22,417.51689
Overall Steps per Second: 10,791.56268

Timestep Collection Time: 2.23165
Timestep Consumption Time: 2.40420
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.63584

Cumulative Model Updates: 100,588
Cumulative Timesteps: 838,872,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 838872398...
Checkpoint 838872398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,400.28147
Policy Entropy: 3.57946
Value Function Loss: 0.09014

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.41508
Value Function Update Magnitude: 0.74989

Collected Steps per Second: 22,752.45585
Overall Steps per Second: 10,715.09771

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.66837

Cumulative Model Updates: 100,594
Cumulative Timesteps: 838,922,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,131.37405
Policy Entropy: 3.57549
Value Function Loss: 0.09010

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.46030
Value Function Update Magnitude: 0.66306

Collected Steps per Second: 22,412.90834
Overall Steps per Second: 10,587.96280

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.72404

Cumulative Model Updates: 100,600
Cumulative Timesteps: 838,972,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 838972438...
Checkpoint 838972438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,347.69581
Policy Entropy: 3.56880
Value Function Loss: 0.09075

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.49585
Value Function Update Magnitude: 0.67400

Collected Steps per Second: 22,378.04603
Overall Steps per Second: 10,563.63768

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.49889
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.73322

Cumulative Model Updates: 100,606
Cumulative Timesteps: 839,022,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,630.13320
Policy Entropy: 3.56988
Value Function Loss: 0.08835

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.46564
Value Function Update Magnitude: 0.69649

Collected Steps per Second: 22,238.01047
Overall Steps per Second: 10,547.21685

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.49308
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.74229

Cumulative Model Updates: 100,612
Cumulative Timesteps: 839,072,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 839072456...
Checkpoint 839072456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,798.34036
Policy Entropy: 3.56629
Value Function Loss: 0.08689

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.43556
Value Function Update Magnitude: 0.74150

Collected Steps per Second: 22,532.23840
Overall Steps per Second: 10,590.83570

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.72125

Cumulative Model Updates: 100,618
Cumulative Timesteps: 839,122,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,986.83705
Policy Entropy: 3.57132
Value Function Loss: 0.08604

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.44652
Value Function Update Magnitude: 0.67175

Collected Steps per Second: 22,642.69669
Overall Steps per Second: 10,600.79708

Timestep Collection Time: 2.20963
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.71965

Cumulative Model Updates: 100,624
Cumulative Timesteps: 839,172,490

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 839172490...
Checkpoint 839172490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,370.27902
Policy Entropy: 3.56575
Value Function Loss: 0.08647

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.45366
Value Function Update Magnitude: 0.64406

Collected Steps per Second: 22,929.87429
Overall Steps per Second: 10,901.06610

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.58873

Cumulative Model Updates: 100,630
Cumulative Timesteps: 839,222,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,559.08173
Policy Entropy: 3.56204
Value Function Loss: 0.08631

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.44247
Value Function Update Magnitude: 0.68759

Collected Steps per Second: 23,149.29266
Overall Steps per Second: 10,862.41431

Timestep Collection Time: 2.16007
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60340

Cumulative Model Updates: 100,636
Cumulative Timesteps: 839,272,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 839272516...
Checkpoint 839272516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,891.20088
Policy Entropy: 3.57207
Value Function Loss: 0.08579

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.56405
Value Function Update Magnitude: 0.71539

Collected Steps per Second: 22,661.81742
Overall Steps per Second: 10,652.39168

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.48802
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.69491

Cumulative Model Updates: 100,642
Cumulative Timesteps: 839,322,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,987.48878
Policy Entropy: 3.57469
Value Function Loss: 0.08777

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.68367

Collected Steps per Second: 22,839.00234
Overall Steps per Second: 10,839.82998

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.42396
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.61373

Cumulative Model Updates: 100,648
Cumulative Timesteps: 839,372,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 839372540...
Checkpoint 839372540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,630.05883
Policy Entropy: 3.58286
Value Function Loss: 0.08896

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.64176
Value Function Update Magnitude: 0.68793

Collected Steps per Second: 22,890.03484
Overall Steps per Second: 10,706.76691

Timestep Collection Time: 2.18523
Timestep Consumption Time: 2.48658
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.67181

Cumulative Model Updates: 100,654
Cumulative Timesteps: 839,422,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,906.58948
Policy Entropy: 3.57726
Value Function Loss: 0.08861

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.48268
Value Function Update Magnitude: 0.73454

Collected Steps per Second: 22,386.33857
Overall Steps per Second: 10,550.37635

Timestep Collection Time: 2.23386
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73993

Cumulative Model Updates: 100,660
Cumulative Timesteps: 839,472,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 839472568...
Checkpoint 839472568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,375.81136
Policy Entropy: 3.57987
Value Function Loss: 0.08471

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.49207
Value Function Update Magnitude: 0.81103

Collected Steps per Second: 22,650.17049
Overall Steps per Second: 10,624.15656

Timestep Collection Time: 2.20811
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.70757

Cumulative Model Updates: 100,666
Cumulative Timesteps: 839,522,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,113.65677
Policy Entropy: 3.58541
Value Function Loss: 0.08145

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.76034

Collected Steps per Second: 22,595.79160
Overall Steps per Second: 10,763.91362

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.64775

Cumulative Model Updates: 100,672
Cumulative Timesteps: 839,572,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 839572610...
Checkpoint 839572610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,242.98160
Policy Entropy: 3.58103
Value Function Loss: 0.08163

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.60934
Value Function Update Magnitude: 0.75884

Collected Steps per Second: 22,436.04393
Overall Steps per Second: 10,667.73813

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.45946
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.68890

Cumulative Model Updates: 100,678
Cumulative Timesteps: 839,622,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,813.42029
Policy Entropy: 3.58838
Value Function Loss: 0.07952

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.60122
Value Function Update Magnitude: 0.71235

Collected Steps per Second: 23,102.78862
Overall Steps per Second: 10,865.31819

Timestep Collection Time: 2.16623
Timestep Consumption Time: 2.43980
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60603

Cumulative Model Updates: 100,684
Cumulative Timesteps: 839,672,676

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 839672676...
Checkpoint 839672676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,300.69309
Policy Entropy: 3.59073
Value Function Loss: 0.07990

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.68952
Value Function Update Magnitude: 0.64547

Collected Steps per Second: 22,898.82498
Overall Steps per Second: 10,705.74216

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.48797
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.67245

Cumulative Model Updates: 100,690
Cumulative Timesteps: 839,722,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,759.38966
Policy Entropy: 3.58892
Value Function Loss: 0.07755

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.76216
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 22,716.53529
Overall Steps per Second: 10,712.24245

Timestep Collection Time: 2.20130
Timestep Consumption Time: 2.46681
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.66812

Cumulative Model Updates: 100,696
Cumulative Timesteps: 839,772,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 839772704...
Checkpoint 839772704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,648.29952
Policy Entropy: 3.57965
Value Function Loss: 0.08168

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.75318
Value Function Update Magnitude: 0.64135

Collected Steps per Second: 22,619.08718
Overall Steps per Second: 10,799.54779

Timestep Collection Time: 2.21158
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.63205

Cumulative Model Updates: 100,702
Cumulative Timesteps: 839,822,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,510.35556
Policy Entropy: 3.57122
Value Function Loss: 0.08036

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.64662
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 22,970.54420
Overall Steps per Second: 10,858.56979

Timestep Collection Time: 2.17783
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.60705

Cumulative Model Updates: 100,708
Cumulative Timesteps: 839,872,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 839872754...
Checkpoint 839872754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,966.94033
Policy Entropy: 3.56348
Value Function Loss: 0.08347

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.62635
Value Function Update Magnitude: 0.63225

Collected Steps per Second: 22,396.43162
Overall Steps per Second: 10,728.35592

Timestep Collection Time: 2.23312
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.66185

Cumulative Model Updates: 100,714
Cumulative Timesteps: 839,922,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,301.28878
Policy Entropy: 3.56529
Value Function Loss: 0.08045

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.60641
Value Function Update Magnitude: 0.72176

Collected Steps per Second: 22,617.55902
Overall Steps per Second: 10,649.67828

Timestep Collection Time: 2.21164
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.69704

Cumulative Model Updates: 100,720
Cumulative Timesteps: 839,972,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 839972790...
Checkpoint 839972790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,581.81342
Policy Entropy: 3.56605
Value Function Loss: 0.08076

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.69772

Collected Steps per Second: 20,580.84862
Overall Steps per Second: 10,112.66401

Timestep Collection Time: 2.42973
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.94489

Cumulative Model Updates: 100,726
Cumulative Timesteps: 840,022,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,123.62319
Policy Entropy: 3.57565
Value Function Loss: 0.07873

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.58777
Value Function Update Magnitude: 0.72548

Collected Steps per Second: 22,416.47002
Overall Steps per Second: 10,746.04341

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.42363
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.65529

Cumulative Model Updates: 100,732
Cumulative Timesteps: 840,072,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 840072822...
Checkpoint 840072822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,181.18792
Policy Entropy: 3.59018
Value Function Loss: 0.07918

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.70780

Collected Steps per Second: 22,146.59493
Overall Steps per Second: 10,659.36473

Timestep Collection Time: 2.25877
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.69296

Cumulative Model Updates: 100,738
Cumulative Timesteps: 840,122,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,259.69772
Policy Entropy: 3.59015
Value Function Loss: 0.08128

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.52242
Value Function Update Magnitude: 0.74021

Collected Steps per Second: 22,801.41120
Overall Steps per Second: 10,539.73252

Timestep Collection Time: 2.19329
Timestep Consumption Time: 2.55162
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.74490

Cumulative Model Updates: 100,744
Cumulative Timesteps: 840,172,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 840172856...
Checkpoint 840172856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,558.04017
Policy Entropy: 3.58399
Value Function Loss: 0.08304

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.50146
Value Function Update Magnitude: 0.78945

Collected Steps per Second: 23,042.08309
Overall Steps per Second: 10,677.09047

Timestep Collection Time: 2.16994
Timestep Consumption Time: 2.51298
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.68292

Cumulative Model Updates: 100,750
Cumulative Timesteps: 840,222,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,766.39275
Policy Entropy: 3.55779
Value Function Loss: 0.08845

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.47811
Value Function Update Magnitude: 0.70354

Collected Steps per Second: 23,113.77405
Overall Steps per Second: 10,827.31344

Timestep Collection Time: 2.16356
Timestep Consumption Time: 2.45513
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.61869

Cumulative Model Updates: 100,756
Cumulative Timesteps: 840,272,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 840272864...
Checkpoint 840272864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,159.48066
Policy Entropy: 3.55401
Value Function Loss: 0.09283

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.69298

Collected Steps per Second: 22,774.43665
Overall Steps per Second: 10,650.57595

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.69684

Cumulative Model Updates: 100,762
Cumulative Timesteps: 840,322,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,658.98753
Policy Entropy: 3.55266
Value Function Loss: 0.09370

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.53235
Value Function Update Magnitude: 0.70746

Collected Steps per Second: 22,738.89282
Overall Steps per Second: 10,682.72022

Timestep Collection Time: 2.19976
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68233

Cumulative Model Updates: 100,768
Cumulative Timesteps: 840,372,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 840372908...
Checkpoint 840372908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,267.39004
Policy Entropy: 3.56174
Value Function Loss: 0.09016

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.51376
Value Function Update Magnitude: 0.80312

Collected Steps per Second: 22,905.57120
Overall Steps per Second: 10,850.32871

Timestep Collection Time: 2.18314
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.60871

Cumulative Model Updates: 100,774
Cumulative Timesteps: 840,422,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.89947
Policy Entropy: 3.58266
Value Function Loss: 0.08654

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.55803
Value Function Update Magnitude: 0.92401

Collected Steps per Second: 23,169.32470
Overall Steps per Second: 10,867.20963

Timestep Collection Time: 2.15975
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.60468

Cumulative Model Updates: 100,780
Cumulative Timesteps: 840,472,954

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 840472954...
Checkpoint 840472954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,715.61557
Policy Entropy: 3.57902
Value Function Loss: 0.08725

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.65444
Value Function Update Magnitude: 0.84512

Collected Steps per Second: 22,500.17068
Overall Steps per Second: 10,766.72452

Timestep Collection Time: 2.22345
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.64654

Cumulative Model Updates: 100,786
Cumulative Timesteps: 840,522,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,167.33578
Policy Entropy: 3.57443
Value Function Loss: 0.08981

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.71444
Value Function Update Magnitude: 0.80266

Collected Steps per Second: 22,465.95707
Overall Steps per Second: 10,812.24195

Timestep Collection Time: 2.22603
Timestep Consumption Time: 2.39928
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62531

Cumulative Model Updates: 100,792
Cumulative Timesteps: 840,572,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 840572992...
Checkpoint 840572992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,481.89518
Policy Entropy: 3.57193
Value Function Loss: 0.08982

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.18501
Policy Update Magnitude: 0.60061
Value Function Update Magnitude: 0.79635

Collected Steps per Second: 22,349.12275
Overall Steps per Second: 10,737.40078

Timestep Collection Time: 2.23785
Timestep Consumption Time: 2.42007
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.65792

Cumulative Model Updates: 100,798
Cumulative Timesteps: 840,623,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,764.54157
Policy Entropy: 3.55541
Value Function Loss: 0.09020

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.18149
Policy Update Magnitude: 0.51742
Value Function Update Magnitude: 0.83296

Collected Steps per Second: 22,472.67962
Overall Steps per Second: 10,583.11105

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.72526

Cumulative Model Updates: 100,804
Cumulative Timesteps: 840,673,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 840673014...
Checkpoint 840673014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,097.12024
Policy Entropy: 3.58163
Value Function Loss: 0.08853

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.85380

Collected Steps per Second: 22,208.10888
Overall Steps per Second: 10,494.18344

Timestep Collection Time: 2.25350
Timestep Consumption Time: 2.51543
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.76893

Cumulative Model Updates: 100,810
Cumulative Timesteps: 840,723,060

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,318.79196
Policy Entropy: 3.58776
Value Function Loss: 0.09036

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.19859
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.78854

Collected Steps per Second: 22,528.00368
Overall Steps per Second: 10,631.81550

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.48370
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.70343

Cumulative Model Updates: 100,816
Cumulative Timesteps: 840,773,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 840773066...
Checkpoint 840773066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,807.78803
Policy Entropy: 3.57904
Value Function Loss: 0.09205

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.17032
Policy Update Magnitude: 0.43399
Value Function Update Magnitude: 0.80742

Collected Steps per Second: 22,421.48346
Overall Steps per Second: 10,642.29814

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.46941
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.70049

Cumulative Model Updates: 100,822
Cumulative Timesteps: 840,823,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.24231
Policy Entropy: 3.60467
Value Function Loss: 0.09290

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.42332
Value Function Update Magnitude: 0.75045

Collected Steps per Second: 22,610.67375
Overall Steps per Second: 10,667.62666

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.47613
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.68783

Cumulative Model Updates: 100,828
Cumulative Timesteps: 840,873,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 840873098...
Checkpoint 840873098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,926.10084
Policy Entropy: 3.59736
Value Function Loss: 0.09528

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.46589
Value Function Update Magnitude: 0.74498

Collected Steps per Second: 22,547.45384
Overall Steps per Second: 10,594.89104

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.72058

Cumulative Model Updates: 100,834
Cumulative Timesteps: 840,923,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,449.43063
Policy Entropy: 3.58828
Value Function Loss: 0.09028

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.46911
Value Function Update Magnitude: 0.79459

Collected Steps per Second: 22,737.13256
Overall Steps per Second: 10,641.50217

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.50054
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.70046

Cumulative Model Updates: 100,840
Cumulative Timesteps: 840,973,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 840973132...
Checkpoint 840973132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,121.58951
Policy Entropy: 3.57545
Value Function Loss: 0.09132

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.46870
Value Function Update Magnitude: 0.75445

Collected Steps per Second: 22,885.83927
Overall Steps per Second: 10,866.41581

Timestep Collection Time: 2.18572
Timestep Consumption Time: 2.41764
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60336

Cumulative Model Updates: 100,846
Cumulative Timesteps: 841,023,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,241.05937
Policy Entropy: 3.57199
Value Function Loss: 0.09183

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.47342
Value Function Update Magnitude: 0.67410

Collected Steps per Second: 22,721.35889
Overall Steps per Second: 10,604.53325

Timestep Collection Time: 2.20092
Timestep Consumption Time: 2.51479
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.71572

Cumulative Model Updates: 100,852
Cumulative Timesteps: 841,073,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 841073162...
Checkpoint 841073162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,272.01549
Policy Entropy: 3.56998
Value Function Loss: 0.09507

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.51369
Value Function Update Magnitude: 0.63920

Collected Steps per Second: 22,932.34098
Overall Steps per Second: 10,731.71966

Timestep Collection Time: 2.18164
Timestep Consumption Time: 2.48025
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.66188

Cumulative Model Updates: 100,858
Cumulative Timesteps: 841,123,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,894.81742
Policy Entropy: 3.57064
Value Function Loss: 0.09279

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.53249
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 23,045.60889
Overall Steps per Second: 10,765.85973

Timestep Collection Time: 2.16970
Timestep Consumption Time: 2.47480
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.64450

Cumulative Model Updates: 100,864
Cumulative Timesteps: 841,173,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841173194...
Checkpoint 841173194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,640.66292
Policy Entropy: 3.57823
Value Function Loss: 0.09063

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.45733
Value Function Update Magnitude: 0.64952

Collected Steps per Second: 21,870.94759
Overall Steps per Second: 10,637.12627

Timestep Collection Time: 2.28714
Timestep Consumption Time: 2.41544
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.70259

Cumulative Model Updates: 100,870
Cumulative Timesteps: 841,223,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.09634
Policy Entropy: 3.57741
Value Function Loss: 0.08803

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.45452
Value Function Update Magnitude: 0.75243

Collected Steps per Second: 22,002.25444
Overall Steps per Second: 10,812.01329

Timestep Collection Time: 2.27259
Timestep Consumption Time: 2.35209
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62467

Cumulative Model Updates: 100,876
Cumulative Timesteps: 841,273,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841273218...
Checkpoint 841273218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,026.40745
Policy Entropy: 3.56853
Value Function Loss: 0.08800

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.44111
Value Function Update Magnitude: 0.71316

Collected Steps per Second: 21,861.17146
Overall Steps per Second: 10,726.01106

Timestep Collection Time: 2.28743
Timestep Consumption Time: 2.37469
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.66212

Cumulative Model Updates: 100,882
Cumulative Timesteps: 841,323,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,998.80600
Policy Entropy: 3.57614
Value Function Loss: 0.09032

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.44231
Value Function Update Magnitude: 0.68175

Collected Steps per Second: 21,892.65299
Overall Steps per Second: 10,667.08481

Timestep Collection Time: 2.28451
Timestep Consumption Time: 2.40412
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.68863

Cumulative Model Updates: 100,888
Cumulative Timesteps: 841,373,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 841373238...
Checkpoint 841373238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,423.03415
Policy Entropy: 3.57784
Value Function Loss: 0.09015

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.48508
Value Function Update Magnitude: 0.67944

Collected Steps per Second: 21,846.18002
Overall Steps per Second: 10,797.36719

Timestep Collection Time: 2.28900
Timestep Consumption Time: 2.34231
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.63131

Cumulative Model Updates: 100,894
Cumulative Timesteps: 841,423,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,356.56830
Policy Entropy: 3.58060
Value Function Loss: 0.08925

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.77379

Collected Steps per Second: 22,361.20397
Overall Steps per Second: 10,581.56629

Timestep Collection Time: 2.23610
Timestep Consumption Time: 2.48928
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.72539

Cumulative Model Updates: 100,900
Cumulative Timesteps: 841,473,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841473246...
Checkpoint 841473246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,885.30632
Policy Entropy: 3.57184
Value Function Loss: 0.09251

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.53562
Value Function Update Magnitude: 0.77584

Collected Steps per Second: 22,673.35082
Overall Steps per Second: 10,720.58609

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.45918
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.66486

Cumulative Model Updates: 100,906
Cumulative Timesteps: 841,523,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,678.43914
Policy Entropy: 3.57026
Value Function Loss: 0.09235

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.53513
Value Function Update Magnitude: 0.74475

Collected Steps per Second: 23,013.90146
Overall Steps per Second: 10,764.47585

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.47231
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.64491

Cumulative Model Updates: 100,912
Cumulative Timesteps: 841,573,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841573256...
Checkpoint 841573256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,062.47014
Policy Entropy: 3.56840
Value Function Loss: 0.09806

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.65827
Value Function Update Magnitude: 0.70604

Collected Steps per Second: 22,451.30893
Overall Steps per Second: 10,612.03111

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.71314

Cumulative Model Updates: 100,918
Cumulative Timesteps: 841,623,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,415.84912
Policy Entropy: 3.56452
Value Function Loss: 0.09749

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.64900
Value Function Update Magnitude: 0.72240

Collected Steps per Second: 23,105.95892
Overall Steps per Second: 10,967.83985

Timestep Collection Time: 2.16507
Timestep Consumption Time: 2.39608
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.56115

Cumulative Model Updates: 100,924
Cumulative Timesteps: 841,673,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 841673298...
Checkpoint 841673298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,319.67285
Policy Entropy: 3.55890
Value Function Loss: 0.10110

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 0.75347

Collected Steps per Second: 22,956.21309
Overall Steps per Second: 10,724.93329

Timestep Collection Time: 2.17928
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.66464

Cumulative Model Updates: 100,930
Cumulative Timesteps: 841,723,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,963.42850
Policy Entropy: 3.55528
Value Function Loss: 0.09843

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.66081
Value Function Update Magnitude: 0.70190

Collected Steps per Second: 22,588.56237
Overall Steps per Second: 10,761.66094

Timestep Collection Time: 2.21457
Timestep Consumption Time: 2.43378
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.64835

Cumulative Model Updates: 100,936
Cumulative Timesteps: 841,773,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 841773350...
Checkpoint 841773350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,149.58744
Policy Entropy: 3.57656
Value Function Loss: 0.09371

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.64289
Value Function Update Magnitude: 0.80676

Collected Steps per Second: 22,433.90159
Overall Steps per Second: 10,685.18572

Timestep Collection Time: 2.22930
Timestep Consumption Time: 2.45119
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.68050

Cumulative Model Updates: 100,942
Cumulative Timesteps: 841,823,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,623.73697
Policy Entropy: 3.59237
Value Function Loss: 0.08605

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.66451
Value Function Update Magnitude: 0.91788

Collected Steps per Second: 22,776.08418
Overall Steps per Second: 10,807.40436

Timestep Collection Time: 2.19546
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.62683

Cumulative Model Updates: 100,948
Cumulative Timesteps: 841,873,366

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 841873366...
Checkpoint 841873366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.06350
Policy Entropy: 3.60026
Value Function Loss: 0.08381

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.73821
Value Function Update Magnitude: 0.89472

Collected Steps per Second: 22,428.61177
Overall Steps per Second: 10,680.13211

Timestep Collection Time: 2.23010
Timestep Consumption Time: 2.45318
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.68328

Cumulative Model Updates: 100,954
Cumulative Timesteps: 841,923,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,009.87548
Policy Entropy: 3.59661
Value Function Loss: 0.08715

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.61864
Value Function Update Magnitude: 0.82065

Collected Steps per Second: 22,966.56306
Overall Steps per Second: 10,717.61741

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.66783

Cumulative Model Updates: 100,960
Cumulative Timesteps: 841,973,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 841973412...
Checkpoint 841973412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,418.02690
Policy Entropy: 3.60349
Value Function Loss: 0.08864

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.71774

Collected Steps per Second: 22,758.68044
Overall Steps per Second: 10,756.08489

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.45216
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.64965

Cumulative Model Updates: 100,966
Cumulative Timesteps: 842,023,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,226.46391
Policy Entropy: 3.59810
Value Function Loss: 0.09054

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.74983

Collected Steps per Second: 22,986.19202
Overall Steps per Second: 10,680.93205

Timestep Collection Time: 2.17592
Timestep Consumption Time: 2.50682
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.68274

Cumulative Model Updates: 100,972
Cumulative Timesteps: 842,073,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 842073440...
Checkpoint 842073440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,215.89317
Policy Entropy: 3.60876
Value Function Loss: 0.09099

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.65882
Value Function Update Magnitude: 0.75389

Collected Steps per Second: 22,965.39346
Overall Steps per Second: 10,875.81089

Timestep Collection Time: 2.17797
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.59901

Cumulative Model Updates: 100,978
Cumulative Timesteps: 842,123,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,572.73083
Policy Entropy: 3.60346
Value Function Loss: 0.09129

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.67378
Value Function Update Magnitude: 0.75573

Collected Steps per Second: 22,724.20193
Overall Steps per Second: 10,640.34891

Timestep Collection Time: 2.20109
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.70079

Cumulative Model Updates: 100,984
Cumulative Timesteps: 842,173,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 842173476...
Checkpoint 842173476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,106.71030
Policy Entropy: 3.61257
Value Function Loss: 0.08689

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.17463
Policy Update Magnitude: 0.51138
Value Function Update Magnitude: 0.78842

Collected Steps per Second: 23,145.21975
Overall Steps per Second: 10,982.99930

Timestep Collection Time: 2.16036
Timestep Consumption Time: 2.39231
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.55267

Cumulative Model Updates: 100,990
Cumulative Timesteps: 842,223,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,911.16342
Policy Entropy: 3.61655
Value Function Loss: 0.08342

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.45549
Value Function Update Magnitude: 0.77726

Collected Steps per Second: 22,497.53802
Overall Steps per Second: 10,591.47377

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.72172

Cumulative Model Updates: 100,996
Cumulative Timesteps: 842,273,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 842273488...
Checkpoint 842273488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,063.30352
Policy Entropy: 3.61245
Value Function Loss: 0.08341

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.74078

Collected Steps per Second: 22,577.82306
Overall Steps per Second: 10,625.67867

Timestep Collection Time: 2.21501
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.70652

Cumulative Model Updates: 101,002
Cumulative Timesteps: 842,323,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,715.81485
Policy Entropy: 3.60253
Value Function Loss: 0.08659

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.63978
Value Function Update Magnitude: 0.74974

Collected Steps per Second: 22,307.02733
Overall Steps per Second: 10,725.87072

Timestep Collection Time: 2.24172
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.66219

Cumulative Model Updates: 101,008
Cumulative Timesteps: 842,373,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 842373504...
Checkpoint 842373504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,079.76700
Policy Entropy: 3.61715
Value Function Loss: 0.08627

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.56980
Value Function Update Magnitude: 0.72814

Collected Steps per Second: 22,168.29907
Overall Steps per Second: 10,728.53351

Timestep Collection Time: 2.25547
Timestep Consumption Time: 2.40500
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.66047

Cumulative Model Updates: 101,014
Cumulative Timesteps: 842,423,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,101.30730
Policy Entropy: 3.62559
Value Function Loss: 0.08489

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.55517
Value Function Update Magnitude: 0.85003

Collected Steps per Second: 22,910.13093
Overall Steps per Second: 10,659.66925

Timestep Collection Time: 2.18262
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.69095

Cumulative Model Updates: 101,020
Cumulative Timesteps: 842,473,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 842473508...
Checkpoint 842473508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,966.63518
Policy Entropy: 3.63570
Value Function Loss: 0.08223

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.51876
Value Function Update Magnitude: 0.90980

Collected Steps per Second: 22,926.98940
Overall Steps per Second: 10,818.18340

Timestep Collection Time: 2.18206
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.62444

Cumulative Model Updates: 101,026
Cumulative Timesteps: 842,523,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,480.29547
Policy Entropy: 3.61610
Value Function Loss: 0.08245

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.51814
Value Function Update Magnitude: 0.89317

Collected Steps per Second: 22,675.19716
Overall Steps per Second: 10,654.70304

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.69351

Cumulative Model Updates: 101,032
Cumulative Timesteps: 842,573,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 842573544...
Checkpoint 842573544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,445.42535
Policy Entropy: 3.59975
Value Function Loss: 0.08350

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.52295
Value Function Update Magnitude: 0.89115

Collected Steps per Second: 21,549.15052
Overall Steps per Second: 10,543.43062

Timestep Collection Time: 2.32213
Timestep Consumption Time: 2.42395
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.74608

Cumulative Model Updates: 101,038
Cumulative Timesteps: 842,623,584

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,592.03297
Policy Entropy: 3.60343
Value Function Loss: 0.08648

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.59959
Value Function Update Magnitude: 0.85921

Collected Steps per Second: 23,107.55073
Overall Steps per Second: 10,893.59066

Timestep Collection Time: 2.16466
Timestep Consumption Time: 2.42703
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.59169

Cumulative Model Updates: 101,044
Cumulative Timesteps: 842,673,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 842673604...
Checkpoint 842673604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,168.41704
Policy Entropy: 3.59088
Value Function Loss: 0.08567

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.17674
Policy Update Magnitude: 0.51767
Value Function Update Magnitude: 0.89281

Collected Steps per Second: 23,110.77437
Overall Steps per Second: 10,787.29781

Timestep Collection Time: 2.16401
Timestep Consumption Time: 2.47218
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.63619

Cumulative Model Updates: 101,050
Cumulative Timesteps: 842,723,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,643.58809
Policy Entropy: 3.61973
Value Function Loss: 0.07847

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.42819
Value Function Update Magnitude: 0.92963

Collected Steps per Second: 23,229.12747
Overall Steps per Second: 10,780.38123

Timestep Collection Time: 2.15247
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.63805

Cumulative Model Updates: 101,056
Cumulative Timesteps: 842,773,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 842773616...
Checkpoint 842773616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,011.32533
Policy Entropy: 3.62009
Value Function Loss: 0.07438

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.47517
Value Function Update Magnitude: 0.95692

Collected Steps per Second: 22,480.57322
Overall Steps per Second: 10,635.85015

Timestep Collection Time: 2.22485
Timestep Consumption Time: 2.47773
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.70259

Cumulative Model Updates: 101,062
Cumulative Timesteps: 842,823,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,008.70149
Policy Entropy: 3.63600
Value Function Loss: 0.07375

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.95248

Collected Steps per Second: 21,704.58620
Overall Steps per Second: 10,747.99870

Timestep Collection Time: 2.30486
Timestep Consumption Time: 2.34959
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.65445

Cumulative Model Updates: 101,068
Cumulative Timesteps: 842,873,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 842873658...
Checkpoint 842873658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,736.76952
Policy Entropy: 3.63023
Value Function Loss: 0.07860

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.53364
Value Function Update Magnitude: 0.96621

Collected Steps per Second: 21,639.24762
Overall Steps per Second: 10,703.89939

Timestep Collection Time: 2.31182
Timestep Consumption Time: 2.36181
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.67362

Cumulative Model Updates: 101,074
Cumulative Timesteps: 842,923,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,373.77497
Policy Entropy: 3.61381
Value Function Loss: 0.08272

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.96621

Collected Steps per Second: 21,610.99348
Overall Steps per Second: 10,561.44357

Timestep Collection Time: 2.31512
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.73723

Cumulative Model Updates: 101,080
Cumulative Timesteps: 842,973,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 842973716...
Checkpoint 842973716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,756.76888
Policy Entropy: 3.61196
Value Function Loss: 0.08212

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.89578

Collected Steps per Second: 21,860.33658
Overall Steps per Second: 10,571.19874

Timestep Collection Time: 2.28807
Timestep Consumption Time: 2.44346
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.73154

Cumulative Model Updates: 101,086
Cumulative Timesteps: 843,023,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,128.43420
Policy Entropy: 3.59803
Value Function Loss: 0.08267

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.84992

Collected Steps per Second: 22,329.82252
Overall Steps per Second: 10,824.12728

Timestep Collection Time: 2.23934
Timestep Consumption Time: 2.38034
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.61968

Cumulative Model Updates: 101,092
Cumulative Timesteps: 843,073,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 843073738...
Checkpoint 843073738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,637.23408
Policy Entropy: 3.60126
Value Function Loss: 0.08616

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.62149
Value Function Update Magnitude: 0.79449

Collected Steps per Second: 22,157.42464
Overall Steps per Second: 10,722.07325

Timestep Collection Time: 2.25766
Timestep Consumption Time: 2.40785
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.66552

Cumulative Model Updates: 101,098
Cumulative Timesteps: 843,123,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,110.69598
Policy Entropy: 3.59367
Value Function Loss: 0.09171

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.68056
Value Function Update Magnitude: 0.69477

Collected Steps per Second: 22,681.53312
Overall Steps per Second: 10,832.08253

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.41158
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61610

Cumulative Model Updates: 101,104
Cumulative Timesteps: 843,173,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 843173764...
Checkpoint 843173764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,288.39809
Policy Entropy: 3.59209
Value Function Loss: 0.09096

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.59398
Value Function Update Magnitude: 0.69288

Collected Steps per Second: 22,560.48009
Overall Steps per Second: 10,721.11799

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.44860
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.66593

Cumulative Model Updates: 101,110
Cumulative Timesteps: 843,223,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,909.95939
Policy Entropy: 3.59067
Value Function Loss: 0.08911

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.53792
Value Function Update Magnitude: 0.77249

Collected Steps per Second: 23,077.17652
Overall Steps per Second: 10,879.01435

Timestep Collection Time: 2.16708
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.59692

Cumulative Model Updates: 101,116
Cumulative Timesteps: 843,273,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 843273798...
Checkpoint 843273798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,751.26753
Policy Entropy: 3.59517
Value Function Loss: 0.08605

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.58808
Value Function Update Magnitude: 0.76403

Collected Steps per Second: 22,324.83935
Overall Steps per Second: 10,633.80247

Timestep Collection Time: 2.24145
Timestep Consumption Time: 2.46430
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.70575

Cumulative Model Updates: 101,122
Cumulative Timesteps: 843,323,838

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,666.52480
Policy Entropy: 3.60226
Value Function Loss: 0.08379

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.59816
Value Function Update Magnitude: 0.77220

Collected Steps per Second: 22,362.79486
Overall Steps per Second: 10,675.67956

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.68579

Cumulative Model Updates: 101,128
Cumulative Timesteps: 843,373,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 843373862...
Checkpoint 843373862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,438.31202
Policy Entropy: 3.60598
Value Function Loss: 0.08284

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.59402
Value Function Update Magnitude: 0.75077

Collected Steps per Second: 22,369.45591
Overall Steps per Second: 10,618.65218

Timestep Collection Time: 2.23626
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.71096

Cumulative Model Updates: 101,134
Cumulative Timesteps: 843,423,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.87585
Policy Entropy: 3.61337
Value Function Loss: 0.08550

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.70754
Value Function Update Magnitude: 0.71612

Collected Steps per Second: 22,448.99846
Overall Steps per Second: 10,682.77619

Timestep Collection Time: 2.22781
Timestep Consumption Time: 2.45375
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.68155

Cumulative Model Updates: 101,140
Cumulative Timesteps: 843,473,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 843473898...
Checkpoint 843473898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,018.16336
Policy Entropy: 3.61134
Value Function Loss: 0.08856

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.72305
Value Function Update Magnitude: 0.71420

Collected Steps per Second: 22,757.73407
Overall Steps per Second: 10,646.25084

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.69743

Cumulative Model Updates: 101,146
Cumulative Timesteps: 843,523,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,183.48565
Policy Entropy: 3.61976
Value Function Loss: 0.08628

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.65124
Value Function Update Magnitude: 0.78029

Collected Steps per Second: 23,017.77003
Overall Steps per Second: 10,837.03541

Timestep Collection Time: 2.17267
Timestep Consumption Time: 2.44206
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61473

Cumulative Model Updates: 101,152
Cumulative Timesteps: 843,573,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 843573918...
Checkpoint 843573918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,947.57683
Policy Entropy: 3.60863
Value Function Loss: 0.08308

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.65960
Value Function Update Magnitude: 0.81845

Collected Steps per Second: 22,687.73214
Overall Steps per Second: 10,732.51958

Timestep Collection Time: 2.20383
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.65874

Cumulative Model Updates: 101,158
Cumulative Timesteps: 843,623,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,784.91402
Policy Entropy: 3.60745
Value Function Loss: 0.08198

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.80330

Collected Steps per Second: 23,002.66402
Overall Steps per Second: 10,860.69121

Timestep Collection Time: 2.17427
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60505

Cumulative Model Updates: 101,164
Cumulative Timesteps: 843,673,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 843673932...
Checkpoint 843673932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,085.49863
Policy Entropy: 3.60022
Value Function Loss: 0.08399

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.68673
Value Function Update Magnitude: 0.80976

Collected Steps per Second: 22,499.64082
Overall Steps per Second: 10,660.01157

Timestep Collection Time: 2.22315
Timestep Consumption Time: 2.46916
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.69230

Cumulative Model Updates: 101,170
Cumulative Timesteps: 843,723,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.38074
Policy Entropy: 3.61444
Value Function Loss: 0.08459

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.17115
Policy Update Magnitude: 0.70904
Value Function Update Magnitude: 0.77176

Collected Steps per Second: 22,769.48217
Overall Steps per Second: 10,822.86339

Timestep Collection Time: 2.19592
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.61985

Cumulative Model Updates: 101,176
Cumulative Timesteps: 843,773,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 843773952...
Checkpoint 843773952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,610.44773
Policy Entropy: 3.60237
Value Function Loss: 0.08764

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.66015
Value Function Update Magnitude: 0.75768

Collected Steps per Second: 22,382.03121
Overall Steps per Second: 10,701.13742

Timestep Collection Time: 2.23429
Timestep Consumption Time: 2.43886
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.67315

Cumulative Model Updates: 101,182
Cumulative Timesteps: 843,823,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,245.95934
Policy Entropy: 3.59935
Value Function Loss: 0.09048

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.61219
Value Function Update Magnitude: 0.83737

Collected Steps per Second: 22,635.85109
Overall Steps per Second: 10,646.27006

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.48839
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.69798

Cumulative Model Updates: 101,188
Cumulative Timesteps: 843,873,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 843873976...
Checkpoint 843873976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.16975
Policy Entropy: 3.58943
Value Function Loss: 0.09150

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.58207
Value Function Update Magnitude: 0.77167

Collected Steps per Second: 22,488.41992
Overall Steps per Second: 10,642.11083

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69982

Cumulative Model Updates: 101,194
Cumulative Timesteps: 843,923,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,994.87652
Policy Entropy: 3.59450
Value Function Loss: 0.08912

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.72426

Collected Steps per Second: 23,004.32217
Overall Steps per Second: 10,752.10698

Timestep Collection Time: 2.17481
Timestep Consumption Time: 2.47823
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.65304

Cumulative Model Updates: 101,200
Cumulative Timesteps: 843,974,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 843974022...
Checkpoint 843974022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,908.73792
Policy Entropy: 3.60824
Value Function Loss: 0.08408

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.56313
Value Function Update Magnitude: 0.81293

Collected Steps per Second: 22,291.83530
Overall Steps per Second: 10,618.90450

Timestep Collection Time: 2.24351
Timestep Consumption Time: 2.46620
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.70971

Cumulative Model Updates: 101,206
Cumulative Timesteps: 844,024,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,928.95347
Policy Entropy: 3.60499
Value Function Loss: 0.08266

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.48946
Value Function Update Magnitude: 0.79213

Collected Steps per Second: 22,486.03737
Overall Steps per Second: 10,608.21928

Timestep Collection Time: 2.22440
Timestep Consumption Time: 2.49062
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.71502

Cumulative Model Updates: 101,212
Cumulative Timesteps: 844,074,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 844074052...
Checkpoint 844074052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,953.42023
Policy Entropy: 3.60671
Value Function Loss: 0.08418

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.46002
Value Function Update Magnitude: 0.74032

Collected Steps per Second: 22,635.05001
Overall Steps per Second: 10,614.07572

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.50256
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.71223

Cumulative Model Updates: 101,218
Cumulative Timesteps: 844,124,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,219.84663
Policy Entropy: 3.60744
Value Function Loss: 0.08826

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.45616
Value Function Update Magnitude: 0.68723

Collected Steps per Second: 23,033.16342
Overall Steps per Second: 10,776.56647

Timestep Collection Time: 2.17156
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.64137

Cumulative Model Updates: 101,224
Cumulative Timesteps: 844,174,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 844174086...
Checkpoint 844174086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,754.47562
Policy Entropy: 3.61008
Value Function Loss: 0.08577

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.46615
Value Function Update Magnitude: 0.81431

Collected Steps per Second: 22,938.66669
Overall Steps per Second: 10,691.02886

Timestep Collection Time: 2.18086
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67925

Cumulative Model Updates: 101,230
Cumulative Timesteps: 844,224,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,307.55097
Policy Entropy: 3.60489
Value Function Loss: 0.08616

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.51428
Value Function Update Magnitude: 0.82497

Collected Steps per Second: 22,834.01040
Overall Steps per Second: 10,807.16932

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.62804

Cumulative Model Updates: 101,236
Cumulative Timesteps: 844,274,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 844274128...
Checkpoint 844274128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.72261
Policy Entropy: 3.60867
Value Function Loss: 0.08520

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.57946
Value Function Update Magnitude: 0.80109

Collected Steps per Second: 22,669.51720
Overall Steps per Second: 10,654.97728

Timestep Collection Time: 2.20605
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.69358

Cumulative Model Updates: 101,242
Cumulative Timesteps: 844,324,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,117.99345
Policy Entropy: 3.59152
Value Function Loss: 0.08701

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.72374
Value Function Update Magnitude: 0.70925

Collected Steps per Second: 23,027.33304
Overall Steps per Second: 10,881.70380

Timestep Collection Time: 2.17272
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.59781

Cumulative Model Updates: 101,248
Cumulative Timesteps: 844,374,170

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 844374170...
Checkpoint 844374170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,528.79962
Policy Entropy: 3.60130
Value Function Loss: 0.08984

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.17633
Policy Update Magnitude: 0.63251
Value Function Update Magnitude: 0.72062

Collected Steps per Second: 22,717.35763
Overall Steps per Second: 10,702.44835

Timestep Collection Time: 2.20096
Timestep Consumption Time: 2.47087
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.67183

Cumulative Model Updates: 101,254
Cumulative Timesteps: 844,424,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,272.97575
Policy Entropy: 3.57628
Value Function Loss: 0.09481

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.59269
Value Function Update Magnitude: 0.70043

Collected Steps per Second: 22,188.76192
Overall Steps per Second: 10,511.56971

Timestep Collection Time: 2.25475
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.75952

Cumulative Model Updates: 101,260
Cumulative Timesteps: 844,474,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 844474200...
Checkpoint 844474200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,975.81171
Policy Entropy: 3.57410
Value Function Loss: 0.09950

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.63264
Value Function Update Magnitude: 0.69098

Collected Steps per Second: 22,183.16476
Overall Steps per Second: 10,520.99023

Timestep Collection Time: 2.25576
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.75621

Cumulative Model Updates: 101,266
Cumulative Timesteps: 844,524,240

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,995.26637
Policy Entropy: 3.55612
Value Function Loss: 0.09840

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.64020
Value Function Update Magnitude: 0.66860

Collected Steps per Second: 21,933.27328
Overall Steps per Second: 10,492.83767

Timestep Collection Time: 2.27964
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.76516

Cumulative Model Updates: 101,272
Cumulative Timesteps: 844,574,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 844574240...
Checkpoint 844574240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,344.01521
Policy Entropy: 3.54724
Value Function Loss: 0.09817

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.67254

Collected Steps per Second: 22,321.53815
Overall Steps per Second: 10,647.32550

Timestep Collection Time: 2.24071
Timestep Consumption Time: 2.45681
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.69752

Cumulative Model Updates: 101,278
Cumulative Timesteps: 844,624,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,864.20307
Policy Entropy: 3.54762
Value Function Loss: 0.09525

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.53202
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 22,563.24815
Overall Steps per Second: 10,612.15070

Timestep Collection Time: 2.21644
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.71252

Cumulative Model Updates: 101,284
Cumulative Timesteps: 844,674,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 844674266...
Checkpoint 844674266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,839.32023
Policy Entropy: 3.55527
Value Function Loss: 0.09177

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.73269

Collected Steps per Second: 23,084.92868
Overall Steps per Second: 10,843.19561

Timestep Collection Time: 2.16618
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61174

Cumulative Model Updates: 101,290
Cumulative Timesteps: 844,724,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,075.40162
Policy Entropy: 3.56467
Value Function Loss: 0.09169

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.69461

Collected Steps per Second: 23,002.95091
Overall Steps per Second: 10,788.24860

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.46242
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.63727

Cumulative Model Updates: 101,296
Cumulative Timesteps: 844,774,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 844774300...
Checkpoint 844774300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,577.25541
Policy Entropy: 3.56991
Value Function Loss: 0.09242

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.17344
Policy Update Magnitude: 0.49437
Value Function Update Magnitude: 0.66583

Collected Steps per Second: 22,605.36116
Overall Steps per Second: 10,813.72701

Timestep Collection Time: 2.21355
Timestep Consumption Time: 2.41372
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.62727

Cumulative Model Updates: 101,302
Cumulative Timesteps: 844,824,338

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,350.71305
Policy Entropy: 3.57667
Value Function Loss: 0.09346

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.76765

Collected Steps per Second: 22,943.68875
Overall Steps per Second: 10,851.99437

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60948

Cumulative Model Updates: 101,308
Cumulative Timesteps: 844,874,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 844874360...
Checkpoint 844874360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856.59578
Policy Entropy: 3.58392
Value Function Loss: 0.08757

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.60261
Value Function Update Magnitude: 0.72517

Collected Steps per Second: 22,863.93387
Overall Steps per Second: 10,751.90663

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.65443

Cumulative Model Updates: 101,314
Cumulative Timesteps: 844,924,404

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,993.58888
Policy Entropy: 3.58129
Value Function Loss: 0.08537

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.61538
Value Function Update Magnitude: 0.71202

Collected Steps per Second: 22,170.84327
Overall Steps per Second: 10,854.33205

Timestep Collection Time: 2.25548
Timestep Consumption Time: 2.35152
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.60701

Cumulative Model Updates: 101,320
Cumulative Timesteps: 844,974,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 844974410...
Checkpoint 844974410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,756.12949
Policy Entropy: 3.59823
Value Function Loss: 0.07829

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.56750
Value Function Update Magnitude: 0.81852

Collected Steps per Second: 21,721.65416
Overall Steps per Second: 10,698.96305

Timestep Collection Time: 2.30213
Timestep Consumption Time: 2.37178
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.67391

Cumulative Model Updates: 101,326
Cumulative Timesteps: 845,024,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,092.20749
Policy Entropy: 3.58017
Value Function Loss: 0.07982

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.50712
Value Function Update Magnitude: 0.81985

Collected Steps per Second: 22,205.38517
Overall Steps per Second: 10,853.97466

Timestep Collection Time: 2.25297
Timestep Consumption Time: 2.35622
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.60919

Cumulative Model Updates: 101,332
Cumulative Timesteps: 845,074,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 845074444...
Checkpoint 845074444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,002.72085
Policy Entropy: 3.58178
Value Function Loss: 0.08217

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.47082
Value Function Update Magnitude: 0.76099

Collected Steps per Second: 21,790.48205
Overall Steps per Second: 10,654.71086

Timestep Collection Time: 2.29623
Timestep Consumption Time: 2.39991
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.69614

Cumulative Model Updates: 101,338
Cumulative Timesteps: 845,124,480

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,191.43460
Policy Entropy: 3.57541
Value Function Loss: 0.08227

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.43682
Value Function Update Magnitude: 0.71804

Collected Steps per Second: 21,794.45771
Overall Steps per Second: 10,599.24275

Timestep Collection Time: 2.29453
Timestep Consumption Time: 2.42354
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.71807

Cumulative Model Updates: 101,344
Cumulative Timesteps: 845,174,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 845174488...
Checkpoint 845174488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,805.49506
Policy Entropy: 3.56975
Value Function Loss: 0.08154

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.62241
Value Function Update Magnitude: 0.68033

Collected Steps per Second: 22,141.33340
Overall Steps per Second: 10,506.07511

Timestep Collection Time: 2.25849
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.75972

Cumulative Model Updates: 101,350
Cumulative Timesteps: 845,224,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,101.75716
Policy Entropy: 3.57987
Value Function Loss: 0.08138

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.73597
Value Function Update Magnitude: 0.68380

Collected Steps per Second: 22,772.47611
Overall Steps per Second: 10,830.86144

Timestep Collection Time: 2.19598
Timestep Consumption Time: 2.42119
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.61718

Cumulative Model Updates: 101,356
Cumulative Timesteps: 845,274,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 845274502...
Checkpoint 845274502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.71669
Policy Entropy: 3.57734
Value Function Loss: 0.08127

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.65213
Value Function Update Magnitude: 0.69140

Collected Steps per Second: 22,808.74750
Overall Steps per Second: 10,695.26014

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.67516

Cumulative Model Updates: 101,362
Cumulative Timesteps: 845,324,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,453.37139
Policy Entropy: 3.57690
Value Function Loss: 0.07912

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.59948
Value Function Update Magnitude: 0.70494

Collected Steps per Second: 22,883.51712
Overall Steps per Second: 10,890.34918

Timestep Collection Time: 2.18603
Timestep Consumption Time: 2.40740
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59342

Cumulative Model Updates: 101,368
Cumulative Timesteps: 845,374,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 845374528...
Checkpoint 845374528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,089.59061
Policy Entropy: 3.57776
Value Function Loss: 0.07607

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.62105
Value Function Update Magnitude: 0.76738

Collected Steps per Second: 22,844.79206
Overall Steps per Second: 10,764.07670

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.64842

Cumulative Model Updates: 101,374
Cumulative Timesteps: 845,424,564

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,314.82577
Policy Entropy: 3.57600
Value Function Loss: 0.07673

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.68517
Value Function Update Magnitude: 0.82036

Collected Steps per Second: 23,023.11272
Overall Steps per Second: 10,794.61173

Timestep Collection Time: 2.17277
Timestep Consumption Time: 2.46139
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.63416

Cumulative Model Updates: 101,380
Cumulative Timesteps: 845,474,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 845474588...
Checkpoint 845474588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,436.03551
Policy Entropy: 3.59464
Value Function Loss: 0.07589

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.78303
Value Function Update Magnitude: 0.87926

Collected Steps per Second: 22,585.24698
Overall Steps per Second: 10,679.19893

Timestep Collection Time: 2.21392
Timestep Consumption Time: 2.46826
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.68219

Cumulative Model Updates: 101,386
Cumulative Timesteps: 845,524,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,599.35669
Policy Entropy: 3.59394
Value Function Loss: 0.08044

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.78874
Value Function Update Magnitude: 0.89842

Collected Steps per Second: 22,505.65881
Overall Steps per Second: 10,615.36631

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.71166

Cumulative Model Updates: 101,392
Cumulative Timesteps: 845,574,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 845574606...
Checkpoint 845574606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,713.42324
Policy Entropy: 3.58538
Value Function Loss: 0.08331

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.76695
Value Function Update Magnitude: 0.93513

Collected Steps per Second: 22,261.10198
Overall Steps per Second: 10,564.08951

Timestep Collection Time: 2.24670
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.73434

Cumulative Model Updates: 101,398
Cumulative Timesteps: 845,624,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,797.98847
Policy Entropy: 3.57234
Value Function Loss: 0.08657

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.69909
Value Function Update Magnitude: 0.90529

Collected Steps per Second: 22,577.46756
Overall Steps per Second: 10,721.09201

Timestep Collection Time: 2.21601
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.66669

Cumulative Model Updates: 101,404
Cumulative Timesteps: 845,674,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 845674652...
Checkpoint 845674652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,425.52186
Policy Entropy: 3.56596
Value Function Loss: 0.08744

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.53386
Value Function Update Magnitude: 0.87881

Collected Steps per Second: 22,506.76776
Overall Steps per Second: 10,684.03295

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.45911
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.68138

Cumulative Model Updates: 101,410
Cumulative Timesteps: 845,724,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,203.15391
Policy Entropy: 3.57449
Value Function Loss: 0.08447

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.84737

Collected Steps per Second: 22,919.42787
Overall Steps per Second: 10,845.71752

Timestep Collection Time: 2.18278
Timestep Consumption Time: 2.42992
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61270

Cumulative Model Updates: 101,416
Cumulative Timesteps: 845,774,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 845774696...
Checkpoint 845774696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,323.46569
Policy Entropy: 3.57802
Value Function Loss: 0.08654

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.53425
Value Function Update Magnitude: 0.77969

Collected Steps per Second: 22,672.55175
Overall Steps per Second: 10,736.97719

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.45169
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.65718

Cumulative Model Updates: 101,422
Cumulative Timesteps: 845,824,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,647.45044
Policy Entropy: 3.57902
Value Function Loss: 0.08473

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.75323

Collected Steps per Second: 22,837.88453
Overall Steps per Second: 10,828.90789

Timestep Collection Time: 2.19013
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61893

Cumulative Model Updates: 101,428
Cumulative Timesteps: 845,874,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 845874718...
Checkpoint 845874718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,453.50983
Policy Entropy: 3.59136
Value Function Loss: 0.08251

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.77255

Collected Steps per Second: 22,615.12108
Overall Steps per Second: 10,797.19653

Timestep Collection Time: 2.21330
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.63583

Cumulative Model Updates: 101,434
Cumulative Timesteps: 845,924,772

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,726.69388
Policy Entropy: 3.59721
Value Function Loss: 0.08064

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.53195
Value Function Update Magnitude: 0.78341

Collected Steps per Second: 22,943.01881
Overall Steps per Second: 10,877.44687

Timestep Collection Time: 2.17984
Timestep Consumption Time: 2.41793
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.59777

Cumulative Model Updates: 101,440
Cumulative Timesteps: 845,974,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 845974784...
Checkpoint 845974784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.32230
Policy Entropy: 3.59386
Value Function Loss: 0.08050

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.81708

Collected Steps per Second: 22,344.40041
Overall Steps per Second: 10,630.70303

Timestep Collection Time: 2.23770
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.70336

Cumulative Model Updates: 101,446
Cumulative Timesteps: 846,024,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,245.34944
Policy Entropy: 3.59823
Value Function Loss: 0.08262

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.49686
Value Function Update Magnitude: 0.89100

Collected Steps per Second: 22,846.33828
Overall Steps per Second: 10,829.40637

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.61964

Cumulative Model Updates: 101,452
Cumulative Timesteps: 846,074,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 846074812...
Checkpoint 846074812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,107.93825
Policy Entropy: 3.58759
Value Function Loss: 0.08411

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.47940
Value Function Update Magnitude: 0.93463

Collected Steps per Second: 22,286.90724
Overall Steps per Second: 10,727.50559

Timestep Collection Time: 2.24428
Timestep Consumption Time: 2.41832
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.66259

Cumulative Model Updates: 101,458
Cumulative Timesteps: 846,124,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,863.28413
Policy Entropy: 3.58779
Value Function Loss: 0.09028

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.45541
Value Function Update Magnitude: 0.99934

Collected Steps per Second: 21,848.16300
Overall Steps per Second: 10,607.87819

Timestep Collection Time: 2.29026
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.71706

Cumulative Model Updates: 101,464
Cumulative Timesteps: 846,174,868

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 846174868...
Checkpoint 846174868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,646.41372
Policy Entropy: 3.57854
Value Function Loss: 0.09346

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.51419
Value Function Update Magnitude: 0.95904

Collected Steps per Second: 22,083.25763
Overall Steps per Second: 10,655.16985

Timestep Collection Time: 2.26552
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.69537

Cumulative Model Updates: 101,470
Cumulative Timesteps: 846,224,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,915.33780
Policy Entropy: 3.58533
Value Function Loss: 0.09128

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.53033
Value Function Update Magnitude: 0.89535

Collected Steps per Second: 22,495.67031
Overall Steps per Second: 10,724.23464

Timestep Collection Time: 2.22372
Timestep Consumption Time: 2.44086
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.66458

Cumulative Model Updates: 101,476
Cumulative Timesteps: 846,274,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 846274922...
Checkpoint 846274922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,488.26711
Policy Entropy: 3.59054
Value Function Loss: 0.08529

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.52006
Value Function Update Magnitude: 0.90211

Collected Steps per Second: 22,055.31507
Overall Steps per Second: 10,664.42680

Timestep Collection Time: 2.26721
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.68886

Cumulative Model Updates: 101,482
Cumulative Timesteps: 846,324,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,117.33935
Policy Entropy: 3.59158
Value Function Loss: 0.08015

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.91624

Collected Steps per Second: 22,188.65235
Overall Steps per Second: 10,847.40357

Timestep Collection Time: 2.25367
Timestep Consumption Time: 2.35628
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.60995

Cumulative Model Updates: 101,488
Cumulative Timesteps: 846,374,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 846374932...
Checkpoint 846374932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,094.98770
Policy Entropy: 3.59675
Value Function Loss: 0.08362

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.56920
Value Function Update Magnitude: 0.93008

Collected Steps per Second: 21,840.21334
Overall Steps per Second: 10,628.79972

Timestep Collection Time: 2.28945
Timestep Consumption Time: 2.41494
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.70439

Cumulative Model Updates: 101,494
Cumulative Timesteps: 846,424,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,706.10159
Policy Entropy: 3.59203
Value Function Loss: 0.08818

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.50839
Value Function Update Magnitude: 0.87370

Collected Steps per Second: 21,698.84861
Overall Steps per Second: 10,485.87812

Timestep Collection Time: 2.30436
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.76851

Cumulative Model Updates: 101,500
Cumulative Timesteps: 846,474,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 846474936...
Checkpoint 846474936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,474.14914
Policy Entropy: 3.60174
Value Function Loss: 0.09099

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.54403
Value Function Update Magnitude: 0.81995

Collected Steps per Second: 21,991.36332
Overall Steps per Second: 10,609.39471

Timestep Collection Time: 2.27435
Timestep Consumption Time: 2.43996
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.71431

Cumulative Model Updates: 101,506
Cumulative Timesteps: 846,524,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,812.13191
Policy Entropy: 3.60165
Value Function Loss: 0.08947

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.58990
Value Function Update Magnitude: 0.77980

Collected Steps per Second: 22,487.41545
Overall Steps per Second: 10,686.67163

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.68097

Cumulative Model Updates: 101,512
Cumulative Timesteps: 846,574,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 846574976...
Checkpoint 846574976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.42300
Policy Entropy: 3.60746
Value Function Loss: 0.08525

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.83985

Collected Steps per Second: 22,656.80610
Overall Steps per Second: 10,812.07354

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.41829
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62575

Cumulative Model Updates: 101,518
Cumulative Timesteps: 846,624,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,685.22675
Policy Entropy: 3.60867
Value Function Loss: 0.08547

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.51515
Value Function Update Magnitude: 0.88308

Collected Steps per Second: 22,978.03472
Overall Steps per Second: 10,663.56171

Timestep Collection Time: 2.17634
Timestep Consumption Time: 2.51328
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.68962

Cumulative Model Updates: 101,524
Cumulative Timesteps: 846,674,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 846674998...
Checkpoint 846674998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,784.64324
Policy Entropy: 3.59379
Value Function Loss: 0.08579

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.50614
Value Function Update Magnitude: 0.85042

Collected Steps per Second: 22,863.19833
Overall Steps per Second: 10,841.46597

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.42762
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.61690

Cumulative Model Updates: 101,530
Cumulative Timesteps: 846,725,052

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,125.72420
Policy Entropy: 3.58744
Value Function Loss: 0.09125

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.51272
Value Function Update Magnitude: 0.76033

Collected Steps per Second: 22,833.74573
Overall Steps per Second: 10,694.30442

Timestep Collection Time: 2.19035
Timestep Consumption Time: 2.48634
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.67670

Cumulative Model Updates: 101,536
Cumulative Timesteps: 846,775,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 846775066...
Checkpoint 846775066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,117.74297
Policy Entropy: 3.58417
Value Function Loss: 0.08960

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.52348
Value Function Update Magnitude: 0.85241

Collected Steps per Second: 22,653.30286
Overall Steps per Second: 10,657.44366

Timestep Collection Time: 2.20763
Timestep Consumption Time: 2.48487
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69249

Cumulative Model Updates: 101,542
Cumulative Timesteps: 846,825,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,909.55106
Policy Entropy: 3.59518
Value Function Loss: 0.09028

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.59291
Value Function Update Magnitude: 0.78115

Collected Steps per Second: 23,303.72934
Overall Steps per Second: 10,756.96361

Timestep Collection Time: 2.14584
Timestep Consumption Time: 2.50287
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.64871

Cumulative Model Updates: 101,548
Cumulative Timesteps: 846,875,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 846875082...
Checkpoint 846875082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,525.43551
Policy Entropy: 3.59921
Value Function Loss: 0.08852

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.67022
Value Function Update Magnitude: 0.70972

Collected Steps per Second: 22,694.83050
Overall Steps per Second: 10,631.74049

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.70365

Cumulative Model Updates: 101,554
Cumulative Timesteps: 846,925,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,621.64466
Policy Entropy: 3.60654
Value Function Loss: 0.08669

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.18031
Policy Update Magnitude: 0.49770
Value Function Update Magnitude: 0.69024

Collected Steps per Second: 22,678.69916
Overall Steps per Second: 10,821.00995

Timestep Collection Time: 2.20542
Timestep Consumption Time: 2.41670
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.62212

Cumulative Model Updates: 101,560
Cumulative Timesteps: 846,975,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 846975106...
Checkpoint 846975106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.09022
Policy Entropy: 3.61484
Value Function Loss: 0.08199

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14521
Policy Update Magnitude: 0.43237
Value Function Update Magnitude: 0.67356

Collected Steps per Second: 22,006.24075
Overall Steps per Second: 10,677.53072

Timestep Collection Time: 2.27290
Timestep Consumption Time: 2.41152
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.68442

Cumulative Model Updates: 101,566
Cumulative Timesteps: 847,025,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,974.42326
Policy Entropy: 3.61564
Value Function Loss: 0.07988

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.50386
Value Function Update Magnitude: 0.68871

Collected Steps per Second: 22,672.29427
Overall Steps per Second: 10,654.85676

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.48796
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69382

Cumulative Model Updates: 101,572
Cumulative Timesteps: 847,075,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 847075136...
Checkpoint 847075136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,123.11719
Policy Entropy: 3.61245
Value Function Loss: 0.08124

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.57163
Value Function Update Magnitude: 0.68035

Collected Steps per Second: 21,868.20445
Overall Steps per Second: 10,676.11708

Timestep Collection Time: 2.28679
Timestep Consumption Time: 2.39731
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.68410

Cumulative Model Updates: 101,578
Cumulative Timesteps: 847,125,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,566.66331
Policy Entropy: 3.61379
Value Function Loss: 0.08406

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.62359
Value Function Update Magnitude: 0.69655

Collected Steps per Second: 22,417.65706
Overall Steps per Second: 10,728.02411

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.43138
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.66274

Cumulative Model Updates: 101,584
Cumulative Timesteps: 847,175,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 847175166...
Checkpoint 847175166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,059.72393
Policy Entropy: 3.61855
Value Function Loss: 0.08245

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.66814
Value Function Update Magnitude: 0.75688

Collected Steps per Second: 22,135.22630
Overall Steps per Second: 10,682.10621

Timestep Collection Time: 2.25993
Timestep Consumption Time: 2.42304
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.68297

Cumulative Model Updates: 101,590
Cumulative Timesteps: 847,225,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,890.09681
Policy Entropy: 3.63256
Value Function Loss: 0.08099

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07966
Policy Update Magnitude: 0.76517
Value Function Update Magnitude: 0.86456

Collected Steps per Second: 22,196.09727
Overall Steps per Second: 10,828.17316

Timestep Collection Time: 2.25319
Timestep Consumption Time: 2.36550
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61869

Cumulative Model Updates: 101,596
Cumulative Timesteps: 847,275,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 847275202...
Checkpoint 847275202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,395.07641
Policy Entropy: 3.62409
Value Function Loss: 0.08082

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.65811
Value Function Update Magnitude: 0.90307

Collected Steps per Second: 22,103.73903
Overall Steps per Second: 10,636.81040

Timestep Collection Time: 2.26324
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.70310

Cumulative Model Updates: 101,602
Cumulative Timesteps: 847,325,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,378.36791
Policy Entropy: 3.62408
Value Function Loss: 0.08250

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.75835
Value Function Update Magnitude: 0.91410

Collected Steps per Second: 22,263.87922
Overall Steps per Second: 10,867.93581

Timestep Collection Time: 2.24687
Timestep Consumption Time: 2.35603
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60290

Cumulative Model Updates: 101,608
Cumulative Timesteps: 847,375,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 847375252...
Checkpoint 847375252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,134.56487
Policy Entropy: 3.60672
Value Function Loss: 0.08472

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.79773
Value Function Update Magnitude: 0.87473

Collected Steps per Second: 21,858.95889
Overall Steps per Second: 10,658.44935

Timestep Collection Time: 2.28840
Timestep Consumption Time: 2.40478
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.69318

Cumulative Model Updates: 101,614
Cumulative Timesteps: 847,425,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,618.01659
Policy Entropy: 3.60889
Value Function Loss: 0.08468

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.67919
Value Function Update Magnitude: 0.77688

Collected Steps per Second: 22,585.08645
Overall Steps per Second: 10,684.50125

Timestep Collection Time: 2.21536
Timestep Consumption Time: 2.46750
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.68286

Cumulative Model Updates: 101,620
Cumulative Timesteps: 847,475,308

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 847475308...
Checkpoint 847475308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,804.37915
Policy Entropy: 3.60413
Value Function Loss: 0.08450

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.72614

Collected Steps per Second: 22,563.91711
Overall Steps per Second: 10,839.41936

Timestep Collection Time: 2.21664
Timestep Consumption Time: 2.39763
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61427

Cumulative Model Updates: 101,626
Cumulative Timesteps: 847,525,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,508.56301
Policy Entropy: 3.60340
Value Function Loss: 0.08405

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.63678
Value Function Update Magnitude: 0.70617

Collected Steps per Second: 22,421.54476
Overall Steps per Second: 10,634.32517

Timestep Collection Time: 2.23089
Timestep Consumption Time: 2.47275
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.70364

Cumulative Model Updates: 101,632
Cumulative Timesteps: 847,575,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 847575344...
Checkpoint 847575344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,786.19272
Policy Entropy: 3.59458
Value Function Loss: 0.08422

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.76378
Value Function Update Magnitude: 0.77181

Collected Steps per Second: 22,729.59707
Overall Steps per Second: 10,548.70234

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.54045
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74049

Cumulative Model Updates: 101,638
Cumulative Timesteps: 847,625,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,634.06757
Policy Entropy: 3.61040
Value Function Loss: 0.08462

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.70649
Value Function Update Magnitude: 0.76569

Collected Steps per Second: 23,207.42526
Overall Steps per Second: 10,878.13214

Timestep Collection Time: 2.15474
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59693

Cumulative Model Updates: 101,644
Cumulative Timesteps: 847,675,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 847675356...
Checkpoint 847675356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,016.62991
Policy Entropy: 3.62222
Value Function Loss: 0.07889

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.86068

Collected Steps per Second: 22,611.47989
Overall Steps per Second: 10,664.56284

Timestep Collection Time: 2.21171
Timestep Consumption Time: 2.47765
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.68936

Cumulative Model Updates: 101,650
Cumulative Timesteps: 847,725,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,729.44607
Policy Entropy: 3.63334
Value Function Loss: 0.07613

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.53020
Value Function Update Magnitude: 0.92013

Collected Steps per Second: 23,153.09923
Overall Steps per Second: 10,932.67675

Timestep Collection Time: 2.16049
Timestep Consumption Time: 2.41497
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.57546

Cumulative Model Updates: 101,656
Cumulative Timesteps: 847,775,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 847775388...
Checkpoint 847775388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,518.24233
Policy Entropy: 3.63359
Value Function Loss: 0.08034

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.91970

Collected Steps per Second: 22,624.95114
Overall Steps per Second: 10,609.04224

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.71522

Cumulative Model Updates: 101,662
Cumulative Timesteps: 847,825,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,393.87226
Policy Entropy: 3.62936
Value Function Loss: 0.08405

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.55629
Value Function Update Magnitude: 0.78567

Collected Steps per Second: 22,972.80961
Overall Steps per Second: 10,836.37898

Timestep Collection Time: 2.17727
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.61575

Cumulative Model Updates: 101,668
Cumulative Timesteps: 847,875,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 847875430...
Checkpoint 847875430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,985.19872
Policy Entropy: 3.62250
Value Function Loss: 0.08635

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.79355

Collected Steps per Second: 22,458.34806
Overall Steps per Second: 10,705.43495

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.67183

Cumulative Model Updates: 101,674
Cumulative Timesteps: 847,925,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,348.05654
Policy Entropy: 3.61741
Value Function Loss: 0.08662

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.47867
Value Function Update Magnitude: 0.77384

Collected Steps per Second: 22,502.89230
Overall Steps per Second: 10,570.97471

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.72993

Cumulative Model Updates: 101,680
Cumulative Timesteps: 847,975,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 847975444...
Checkpoint 847975444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,855.52651
Policy Entropy: 3.61035
Value Function Loss: 0.08895

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.43565
Value Function Update Magnitude: 0.66098

Collected Steps per Second: 22,176.52405
Overall Steps per Second: 10,523.80480

Timestep Collection Time: 2.25572
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.75341

Cumulative Model Updates: 101,686
Cumulative Timesteps: 848,025,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,914.08872
Policy Entropy: 3.60737
Value Function Loss: 0.09153

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.55049
Value Function Update Magnitude: 0.66928

Collected Steps per Second: 22,587.78538
Overall Steps per Second: 10,627.37585

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.70502

Cumulative Model Updates: 101,692
Cumulative Timesteps: 848,075,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 848075470...
Checkpoint 848075470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,933.85346
Policy Entropy: 3.59338
Value Function Loss: 0.09144

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.16193
Policy Update Magnitude: 0.45464
Value Function Update Magnitude: 0.65744

Collected Steps per Second: 22,364.72600
Overall Steps per Second: 10,560.89458

Timestep Collection Time: 2.23692
Timestep Consumption Time: 2.50018
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.73710

Cumulative Model Updates: 101,698
Cumulative Timesteps: 848,125,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,790.16994
Policy Entropy: 3.59463
Value Function Loss: 0.08861

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.44555
Value Function Update Magnitude: 0.72447

Collected Steps per Second: 23,022.76362
Overall Steps per Second: 10,775.97633

Timestep Collection Time: 2.17176
Timestep Consumption Time: 2.46819
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.63995

Cumulative Model Updates: 101,704
Cumulative Timesteps: 848,175,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 848175498...
Checkpoint 848175498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,891.27216
Policy Entropy: 3.59045
Value Function Loss: 0.08740

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.49939
Value Function Update Magnitude: 0.73164

Collected Steps per Second: 22,467.46799
Overall Steps per Second: 10,666.50775

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.46430
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.69169

Cumulative Model Updates: 101,710
Cumulative Timesteps: 848,225,542

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,431.61694
Policy Entropy: 3.60023
Value Function Loss: 0.08581

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.16800
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.72157

Collected Steps per Second: 23,033.85726
Overall Steps per Second: 10,878.36867

Timestep Collection Time: 2.17124
Timestep Consumption Time: 2.42614
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.59738

Cumulative Model Updates: 101,716
Cumulative Timesteps: 848,275,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 848275554...
Checkpoint 848275554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,250.51968
Policy Entropy: 3.59688
Value Function Loss: 0.08598

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.57773
Value Function Update Magnitude: 0.70314

Collected Steps per Second: 22,165.83798
Overall Steps per Second: 10,693.44004

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.42062
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.67689

Cumulative Model Updates: 101,722
Cumulative Timesteps: 848,325,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,920.67452
Policy Entropy: 3.59016
Value Function Loss: 0.08425

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.64213
Value Function Update Magnitude: 0.70187

Collected Steps per Second: 21,760.41818
Overall Steps per Second: 10,537.29145

Timestep Collection Time: 2.29812
Timestep Consumption Time: 2.44769
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.74581

Cumulative Model Updates: 101,728
Cumulative Timesteps: 848,375,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 848375574...
Checkpoint 848375574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,801.38065
Policy Entropy: 3.58807
Value Function Loss: 0.08260

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.74874
Value Function Update Magnitude: 0.65014

Collected Steps per Second: 22,069.42080
Overall Steps per Second: 10,710.65973

Timestep Collection Time: 2.26612
Timestep Consumption Time: 2.40324
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.66937

Cumulative Model Updates: 101,734
Cumulative Timesteps: 848,425,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,388.16886
Policy Entropy: 3.58901
Value Function Loss: 0.08145

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.80303
Value Function Update Magnitude: 0.64829

Collected Steps per Second: 22,412.04679
Overall Steps per Second: 10,738.33343

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.42566
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.65696

Cumulative Model Updates: 101,740
Cumulative Timesteps: 848,475,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 848475594...
Checkpoint 848475594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,992.00722
Policy Entropy: 3.60078
Value Function Loss: 0.08105

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.81502
Value Function Update Magnitude: 0.71855

Collected Steps per Second: 21,655.53950
Overall Steps per Second: 10,674.86507

Timestep Collection Time: 2.30962
Timestep Consumption Time: 2.37578
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.68540

Cumulative Model Updates: 101,746
Cumulative Timesteps: 848,525,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,165.03115
Policy Entropy: 3.59857
Value Function Loss: 0.08407

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.75801
Value Function Update Magnitude: 0.75506

Collected Steps per Second: 22,007.01998
Overall Steps per Second: 10,560.75497

Timestep Collection Time: 2.27200
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.73451

Cumulative Model Updates: 101,752
Cumulative Timesteps: 848,575,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 848575610...
Checkpoint 848575610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,276.50182
Policy Entropy: 3.59752
Value Function Loss: 0.08469

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.80153
Value Function Update Magnitude: 0.84055

Collected Steps per Second: 22,217.85190
Overall Steps per Second: 10,604.09697

Timestep Collection Time: 2.25053
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.71535

Cumulative Model Updates: 101,758
Cumulative Timesteps: 848,625,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,229.14643
Policy Entropy: 3.59047
Value Function Loss: 0.08396

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.68484
Value Function Update Magnitude: 0.82914

Collected Steps per Second: 22,621.46101
Overall Steps per Second: 10,845.69279

Timestep Collection Time: 2.21117
Timestep Consumption Time: 2.40079
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.61197

Cumulative Model Updates: 101,764
Cumulative Timesteps: 848,675,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 848675632...
Checkpoint 848675632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,166.91054
Policy Entropy: 3.58567
Value Function Loss: 0.08442

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.76721

Collected Steps per Second: 22,832.38550
Overall Steps per Second: 10,666.52766

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.68850

Cumulative Model Updates: 101,770
Cumulative Timesteps: 848,725,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,020.85943
Policy Entropy: 3.58276
Value Function Loss: 0.08355

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.49412
Value Function Update Magnitude: 0.82948

Collected Steps per Second: 23,077.20391
Overall Steps per Second: 10,806.10729

Timestep Collection Time: 2.16664
Timestep Consumption Time: 2.46037
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.62701

Cumulative Model Updates: 101,776
Cumulative Timesteps: 848,775,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 848775642...
Checkpoint 848775642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,549.78758
Policy Entropy: 3.57542
Value Function Loss: 0.08392

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.52082
Value Function Update Magnitude: 0.86769

Collected Steps per Second: 22,584.18758
Overall Steps per Second: 10,685.98272

Timestep Collection Time: 2.21518
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.68165

Cumulative Model Updates: 101,782
Cumulative Timesteps: 848,825,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.49120
Policy Entropy: 3.57616
Value Function Loss: 0.08437

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.87518

Collected Steps per Second: 22,772.80194
Overall Steps per Second: 10,799.51310

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.63151

Cumulative Model Updates: 101,788
Cumulative Timesteps: 848,875,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 848875688...
Checkpoint 848875688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.69610
Policy Entropy: 3.57914
Value Function Loss: 0.08278

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.62448
Value Function Update Magnitude: 0.90935

Collected Steps per Second: 22,694.01202
Overall Steps per Second: 10,709.09430

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.46620
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.66986

Cumulative Model Updates: 101,794
Cumulative Timesteps: 848,925,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,257.67621
Policy Entropy: 3.58628
Value Function Loss: 0.07975

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.63172
Value Function Update Magnitude: 0.94265

Collected Steps per Second: 22,871.00518
Overall Steps per Second: 10,867.51059

Timestep Collection Time: 2.18722
Timestep Consumption Time: 2.41585
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60308

Cumulative Model Updates: 101,800
Cumulative Timesteps: 848,975,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 848975722...
Checkpoint 848975722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,428.91909
Policy Entropy: 3.58431
Value Function Loss: 0.07860

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.93332

Collected Steps per Second: 21,994.68403
Overall Steps per Second: 10,669.61226

Timestep Collection Time: 2.27364
Timestep Consumption Time: 2.41332
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.68696

Cumulative Model Updates: 101,806
Cumulative Timesteps: 849,025,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,551.39964
Policy Entropy: 3.58991
Value Function Loss: 0.07760

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.52116
Value Function Update Magnitude: 0.92071

Collected Steps per Second: 22,451.45310
Overall Steps per Second: 10,579.50102

Timestep Collection Time: 2.22819
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.72858

Cumulative Model Updates: 101,812
Cumulative Timesteps: 849,075,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 849075756...
Checkpoint 849075756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,417.71662
Policy Entropy: 3.59378
Value Function Loss: 0.08345

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.49862
Value Function Update Magnitude: 0.83449

Collected Steps per Second: 22,265.28739
Overall Steps per Second: 10,567.58394

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.73448

Cumulative Model Updates: 101,818
Cumulative Timesteps: 849,125,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,767.63410
Policy Entropy: 3.58425
Value Function Loss: 0.09047

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.49954
Value Function Update Magnitude: 0.74746

Collected Steps per Second: 22,522.92913
Overall Steps per Second: 10,625.93575

Timestep Collection Time: 2.22120
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.70810

Cumulative Model Updates: 101,824
Cumulative Timesteps: 849,175,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 849175816...
Checkpoint 849175816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,237.13681
Policy Entropy: 3.57266
Value Function Loss: 0.09489

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.51026
Value Function Update Magnitude: 0.71946

Collected Steps per Second: 22,844.33222
Overall Steps per Second: 10,616.91737

Timestep Collection Time: 2.18925
Timestep Consumption Time: 2.52134
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.71060

Cumulative Model Updates: 101,830
Cumulative Timesteps: 849,225,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,982.78571
Policy Entropy: 3.55606
Value Function Loss: 0.09171

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.50357
Value Function Update Magnitude: 0.73286

Collected Steps per Second: 23,231.01809
Overall Steps per Second: 10,736.05229

Timestep Collection Time: 2.15255
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.65776

Cumulative Model Updates: 101,836
Cumulative Timesteps: 849,275,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 849275834...
Checkpoint 849275834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,322.13670
Policy Entropy: 3.56517
Value Function Loss: 0.08682

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.50385
Value Function Update Magnitude: 0.77003

Collected Steps per Second: 22,500.81691
Overall Steps per Second: 10,652.56334

Timestep Collection Time: 2.22241
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.69427

Cumulative Model Updates: 101,842
Cumulative Timesteps: 849,325,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.46826
Policy Entropy: 3.57261
Value Function Loss: 0.08512

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.73992

Collected Steps per Second: 22,974.23155
Overall Steps per Second: 10,890.33789

Timestep Collection Time: 2.17835
Timestep Consumption Time: 2.41710
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.59545

Cumulative Model Updates: 101,848
Cumulative Timesteps: 849,375,886

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 849375886...
Checkpoint 849375886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,328.71442
Policy Entropy: 3.57820
Value Function Loss: 0.08742

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.49959
Value Function Update Magnitude: 0.77213

Collected Steps per Second: 22,720.78130
Overall Steps per Second: 10,677.15780

Timestep Collection Time: 2.20080
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.68327

Cumulative Model Updates: 101,854
Cumulative Timesteps: 849,425,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,029.43024
Policy Entropy: 3.57989
Value Function Loss: 0.08816

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.50622
Value Function Update Magnitude: 0.78900

Collected Steps per Second: 22,934.83334
Overall Steps per Second: 10,883.64207

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.41493
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.59589

Cumulative Model Updates: 101,860
Cumulative Timesteps: 849,475,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 849475910...
Checkpoint 849475910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,068.97898
Policy Entropy: 3.57644
Value Function Loss: 0.09203

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.70493

Collected Steps per Second: 22,329.90426
Overall Steps per Second: 10,665.34386

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.44942
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.68902

Cumulative Model Updates: 101,866
Cumulative Timesteps: 849,525,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,827.70830
Policy Entropy: 3.57578
Value Function Loss: 0.09341

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.50569
Value Function Update Magnitude: 0.66222

Collected Steps per Second: 22,292.71789
Overall Steps per Second: 10,537.78846

Timestep Collection Time: 2.24414
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.74749

Cumulative Model Updates: 101,872
Cumulative Timesteps: 849,575,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 849575948...
Checkpoint 849575948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,082.78958
Policy Entropy: 3.57512
Value Function Loss: 0.09514

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.51836
Value Function Update Magnitude: 0.64464

Collected Steps per Second: 22,450.26303
Overall Steps per Second: 10,563.22148

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.50766
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.73606

Cumulative Model Updates: 101,878
Cumulative Timesteps: 849,625,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,736.56692
Policy Entropy: 3.57757
Value Function Loss: 0.09399

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.53150
Value Function Update Magnitude: 0.71994

Collected Steps per Second: 22,789.52063
Overall Steps per Second: 10,819.87326

Timestep Collection Time: 2.19434
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.62187

Cumulative Model Updates: 101,884
Cumulative Timesteps: 849,675,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 849675984...
Checkpoint 849675984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,521.19499
Policy Entropy: 3.56374
Value Function Loss: 0.09441

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.47681
Value Function Update Magnitude: 0.70866

Collected Steps per Second: 22,570.49106
Overall Steps per Second: 10,723.87990

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.66604

Cumulative Model Updates: 101,890
Cumulative Timesteps: 849,726,022

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,060.85073
Policy Entropy: 3.55995
Value Function Loss: 0.09465

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.47529
Value Function Update Magnitude: 0.72408

Collected Steps per Second: 23,104.16315
Overall Steps per Second: 10,872.95373

Timestep Collection Time: 2.16446
Timestep Consumption Time: 2.43484
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.59930

Cumulative Model Updates: 101,896
Cumulative Timesteps: 849,776,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 849776030...
Checkpoint 849776030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,797.51395
Policy Entropy: 3.57297
Value Function Loss: 0.09373

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.50178
Value Function Update Magnitude: 0.69640

Collected Steps per Second: 22,375.24804
Overall Steps per Second: 10,733.35613

Timestep Collection Time: 2.23461
Timestep Consumption Time: 2.42376
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.65838

Cumulative Model Updates: 101,902
Cumulative Timesteps: 849,826,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,063.29386
Policy Entropy: 3.57698
Value Function Loss: 0.09437

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.16884
Policy Update Magnitude: 0.51867
Value Function Update Magnitude: 0.61743

Collected Steps per Second: 23,173.82770
Overall Steps per Second: 10,861.17507

Timestep Collection Time: 2.15873
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.60595

Cumulative Model Updates: 101,908
Cumulative Timesteps: 849,876,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 849876056...
Checkpoint 849876056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,944.59418
Policy Entropy: 3.57184
Value Function Loss: 0.09668

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15102
Policy Update Magnitude: 0.45651
Value Function Update Magnitude: 0.60004

Collected Steps per Second: 22,807.21909
Overall Steps per Second: 10,652.20390

Timestep Collection Time: 2.19352
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69649

Cumulative Model Updates: 101,914
Cumulative Timesteps: 849,926,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.07843
Policy Entropy: 3.57058
Value Function Loss: 0.09708

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.50021
Value Function Update Magnitude: 0.63407

Collected Steps per Second: 22,920.55359
Overall Steps per Second: 10,837.61331

Timestep Collection Time: 2.18162
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.61393

Cumulative Model Updates: 101,920
Cumulative Timesteps: 849,976,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 849976088...
Checkpoint 849976088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.03200
Policy Entropy: 3.56065
Value Function Loss: 0.09422

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.59160
Value Function Update Magnitude: 0.66875

Collected Steps per Second: 22,021.47182
Overall Steps per Second: 10,629.09490

Timestep Collection Time: 2.27196
Timestep Consumption Time: 2.43512
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.70708

Cumulative Model Updates: 101,926
Cumulative Timesteps: 850,026,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,204.00082
Policy Entropy: 3.57943
Value Function Loss: 0.09148

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.59469
Value Function Update Magnitude: 0.64256

Collected Steps per Second: 22,784.39332
Overall Steps per Second: 10,683.77186

Timestep Collection Time: 2.19571
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68262

Cumulative Model Updates: 101,932
Cumulative Timesteps: 850,076,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 850076148...
Checkpoint 850076148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,327.05119
Policy Entropy: 3.58568
Value Function Loss: 0.09187

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.58048
Value Function Update Magnitude: 0.67713

Collected Steps per Second: 22,252.10440
Overall Steps per Second: 10,519.34968

Timestep Collection Time: 2.24824
Timestep Consumption Time: 2.50757
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.75581

Cumulative Model Updates: 101,938
Cumulative Timesteps: 850,126,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.68813
Policy Entropy: 3.58738
Value Function Loss: 0.09329

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.57740
Value Function Update Magnitude: 0.70009

Collected Steps per Second: 22,590.19650
Overall Steps per Second: 10,646.50632

Timestep Collection Time: 2.21415
Timestep Consumption Time: 2.48392
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.69807

Cumulative Model Updates: 101,944
Cumulative Timesteps: 850,176,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 850176194...
Checkpoint 850176194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,642.37256
Policy Entropy: 3.57647
Value Function Loss: 0.09467

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.64162
Value Function Update Magnitude: 0.66385

Collected Steps per Second: 22,349.94827
Overall Steps per Second: 10,597.29238

Timestep Collection Time: 2.23804
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.72007

Cumulative Model Updates: 101,950
Cumulative Timesteps: 850,226,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,123.63416
Policy Entropy: 3.57243
Value Function Loss: 0.09003

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.58053
Value Function Update Magnitude: 0.63737

Collected Steps per Second: 23,147.42705
Overall Steps per Second: 10,710.12099

Timestep Collection Time: 2.16041
Timestep Consumption Time: 2.50882
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.66923

Cumulative Model Updates: 101,956
Cumulative Timesteps: 850,276,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 850276222...
Checkpoint 850276222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,442.01949
Policy Entropy: 3.55992
Value Function Loss: 0.08918

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.15236
Policy Update Magnitude: 0.61546
Value Function Update Magnitude: 0.63271

Collected Steps per Second: 22,182.99379
Overall Steps per Second: 10,624.53182

Timestep Collection Time: 2.25641
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.71117

Cumulative Model Updates: 101,962
Cumulative Timesteps: 850,326,276

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,005.38895
Policy Entropy: 3.57870
Value Function Loss: 0.08949

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.18847
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.65245

Collected Steps per Second: 23,024.12694
Overall Steps per Second: 10,875.32467

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59812

Cumulative Model Updates: 101,968
Cumulative Timesteps: 850,376,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 850376282...
Checkpoint 850376282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,683.02011
Policy Entropy: 3.58934
Value Function Loss: 0.08989

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16417
Policy Update Magnitude: 0.51747
Value Function Update Magnitude: 0.69066

Collected Steps per Second: 22,698.65809
Overall Steps per Second: 10,693.03744

Timestep Collection Time: 2.20286
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.67613

Cumulative Model Updates: 101,974
Cumulative Timesteps: 850,426,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,263.70569
Policy Entropy: 3.60655
Value Function Loss: 0.08890

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.58755
Value Function Update Magnitude: 0.71160

Collected Steps per Second: 23,099.46198
Overall Steps per Second: 10,857.62849

Timestep Collection Time: 2.16542
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60690

Cumulative Model Updates: 101,980
Cumulative Timesteps: 850,476,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 850476304...
Checkpoint 850476304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,965.99738
Policy Entropy: 3.60359
Value Function Loss: 0.08844

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.65178
Value Function Update Magnitude: 0.76352

Collected Steps per Second: 22,604.51390
Overall Steps per Second: 10,702.05965

Timestep Collection Time: 2.21230
Timestep Consumption Time: 2.46044
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.67275

Cumulative Model Updates: 101,986
Cumulative Timesteps: 850,526,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,647.81871
Policy Entropy: 3.58368
Value Function Loss: 0.09006

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.61036
Value Function Update Magnitude: 0.73522

Collected Steps per Second: 22,266.72222
Overall Steps per Second: 10,540.23478

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.74392

Cumulative Model Updates: 101,992
Cumulative Timesteps: 850,576,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 850576314...
Checkpoint 850576314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,243.63588
Policy Entropy: 3.58198
Value Function Loss: 0.09292

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.65072
Value Function Update Magnitude: 0.70267

Collected Steps per Second: 21,924.49291
Overall Steps per Second: 10,569.41157

Timestep Collection Time: 2.28156
Timestep Consumption Time: 2.45116
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.73271

Cumulative Model Updates: 101,998
Cumulative Timesteps: 850,626,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,405.62873
Policy Entropy: 3.58027
Value Function Loss: 0.09319

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.64789

Collected Steps per Second: 22,720.13452
Overall Steps per Second: 10,785.59271

Timestep Collection Time: 2.20166
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.63785

Cumulative Model Updates: 102,004
Cumulative Timesteps: 850,676,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 850676358...
Checkpoint 850676358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.91756
Policy Entropy: 3.58644
Value Function Loss: 0.09154

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.67345

Collected Steps per Second: 22,496.90657
Overall Steps per Second: 10,695.32597

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.67700

Cumulative Model Updates: 102,010
Cumulative Timesteps: 850,726,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,078.59582
Policy Entropy: 3.58345
Value Function Loss: 0.08859

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.58307
Value Function Update Magnitude: 0.78488

Collected Steps per Second: 22,779.15532
Overall Steps per Second: 10,701.61083

Timestep Collection Time: 2.19587
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.67406

Cumulative Model Updates: 102,016
Cumulative Timesteps: 850,776,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 850776400...
Checkpoint 850776400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.95690
Policy Entropy: 3.56877
Value Function Loss: 0.08631

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.81249

Collected Steps per Second: 22,664.54542
Overall Steps per Second: 10,805.69414

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.62886

Cumulative Model Updates: 102,022
Cumulative Timesteps: 850,826,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,142.07428
Policy Entropy: 3.56949
Value Function Loss: 0.08700

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.50684
Value Function Update Magnitude: 0.83225

Collected Steps per Second: 22,839.97379
Overall Steps per Second: 10,700.76371

Timestep Collection Time: 2.18932
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.67294

Cumulative Model Updates: 102,028
Cumulative Timesteps: 850,876,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 850876422...
Checkpoint 850876422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,843.46710
Policy Entropy: 3.57850
Value Function Loss: 0.08734

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.54904
Value Function Update Magnitude: 0.78824

Collected Steps per Second: 22,796.46517
Overall Steps per Second: 10,813.68141

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.43074
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62433

Cumulative Model Updates: 102,034
Cumulative Timesteps: 850,926,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,738.08920
Policy Entropy: 3.57529
Value Function Loss: 0.08840

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.57201
Value Function Update Magnitude: 0.74862

Collected Steps per Second: 22,358.49899
Overall Steps per Second: 10,735.24084

Timestep Collection Time: 2.23772
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.66054

Cumulative Model Updates: 102,040
Cumulative Timesteps: 850,976,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 850976460...
Checkpoint 850976460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,780.46854
Policy Entropy: 3.57598
Value Function Loss: 0.08909

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.53445
Value Function Update Magnitude: 0.80648

Collected Steps per Second: 21,509.97607
Overall Steps per Second: 10,521.90340

Timestep Collection Time: 2.32553
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.75408

Cumulative Model Updates: 102,046
Cumulative Timesteps: 851,026,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,887.79767
Policy Entropy: 3.57461
Value Function Loss: 0.08754

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.47928
Value Function Update Magnitude: 0.80793

Collected Steps per Second: 22,047.17121
Overall Steps per Second: 10,820.53589

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.35401
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.62288

Cumulative Model Updates: 102,052
Cumulative Timesteps: 851,076,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 851076504...
Checkpoint 851076504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,510.63363
Policy Entropy: 3.57641
Value Function Loss: 0.08837

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.47379
Value Function Update Magnitude: 0.78713

Collected Steps per Second: 21,558.36077
Overall Steps per Second: 10,713.45137

Timestep Collection Time: 2.31929
Timestep Consumption Time: 2.34774
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.66703

Cumulative Model Updates: 102,058
Cumulative Timesteps: 851,126,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,963.30720
Policy Entropy: 3.58451
Value Function Loss: 0.08638

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.50153
Value Function Update Magnitude: 0.82118

Collected Steps per Second: 22,210.23608
Overall Steps per Second: 10,856.50607

Timestep Collection Time: 2.25130
Timestep Consumption Time: 2.35441
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60572

Cumulative Model Updates: 102,064
Cumulative Timesteps: 851,176,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 851176506...
Checkpoint 851176506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,091.97643
Policy Entropy: 3.58647
Value Function Loss: 0.08712

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.69673
Value Function Update Magnitude: 0.85405

Collected Steps per Second: 21,760.31033
Overall Steps per Second: 10,627.19129

Timestep Collection Time: 2.29822
Timestep Consumption Time: 2.40763
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.70585

Cumulative Model Updates: 102,070
Cumulative Timesteps: 851,226,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,926.04768
Policy Entropy: 3.58970
Value Function Loss: 0.08878

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.81925
Value Function Update Magnitude: 0.80557

Collected Steps per Second: 22,753.28794
Overall Steps per Second: 10,698.47284

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.67562

Cumulative Model Updates: 102,076
Cumulative Timesteps: 851,276,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 851276538...
Checkpoint 851276538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,075.18014
Policy Entropy: 3.59497
Value Function Loss: 0.09058

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.71556
Value Function Update Magnitude: 0.81230

Collected Steps per Second: 22,789.21286
Overall Steps per Second: 10,838.27890

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.42023
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.61512

Cumulative Model Updates: 102,082
Cumulative Timesteps: 851,326,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,804.41425
Policy Entropy: 3.59288
Value Function Loss: 0.09216

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.60985
Value Function Update Magnitude: 0.77111

Collected Steps per Second: 23,225.38224
Overall Steps per Second: 10,949.02471

Timestep Collection Time: 2.15351
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.56808

Cumulative Model Updates: 102,088
Cumulative Timesteps: 851,376,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 851376574...
Checkpoint 851376574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,617.43224
Policy Entropy: 3.59794
Value Function Loss: 0.09257

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.59994
Value Function Update Magnitude: 0.71850

Collected Steps per Second: 22,478.65512
Overall Steps per Second: 10,644.91856

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.47334
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.69820

Cumulative Model Updates: 102,094
Cumulative Timesteps: 851,426,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,279.98354
Policy Entropy: 3.58906
Value Function Loss: 0.09164

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.74155

Collected Steps per Second: 23,257.98770
Overall Steps per Second: 10,909.42659

Timestep Collection Time: 2.15040
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.58448

Cumulative Model Updates: 102,100
Cumulative Timesteps: 851,476,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 851476600...
Checkpoint 851476600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.84766
Policy Entropy: 3.59730
Value Function Loss: 0.09095

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.61515
Value Function Update Magnitude: 0.84815

Collected Steps per Second: 22,462.93272
Overall Steps per Second: 10,585.27058

Timestep Collection Time: 2.22607
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.72392

Cumulative Model Updates: 102,106
Cumulative Timesteps: 851,526,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,476.25187
Policy Entropy: 3.58396
Value Function Loss: 0.09329

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.62592
Value Function Update Magnitude: 0.84743

Collected Steps per Second: 22,667.10737
Overall Steps per Second: 10,666.29719

Timestep Collection Time: 2.20619
Timestep Consumption Time: 2.48222
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.68841

Cumulative Model Updates: 102,112
Cumulative Timesteps: 851,576,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 851576612...
Checkpoint 851576612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,988.44337
Policy Entropy: 3.58740
Value Function Loss: 0.09154

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.52494
Value Function Update Magnitude: 0.80310

Collected Steps per Second: 22,119.70415
Overall Steps per Second: 10,515.57939

Timestep Collection Time: 2.26115
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.75637

Cumulative Model Updates: 102,118
Cumulative Timesteps: 851,626,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.58012
Policy Entropy: 3.58015
Value Function Loss: 0.09022

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.45885
Value Function Update Magnitude: 0.72008

Collected Steps per Second: 22,359.82058
Overall Steps per Second: 10,602.64434

Timestep Collection Time: 2.23615
Timestep Consumption Time: 2.47965
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.71580

Cumulative Model Updates: 102,124
Cumulative Timesteps: 851,676,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 851676628...
Checkpoint 851676628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,231.83698
Policy Entropy: 3.59704
Value Function Loss: 0.08967

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.46970
Value Function Update Magnitude: 0.69217

Collected Steps per Second: 22,439.37050
Overall Steps per Second: 10,627.68330

Timestep Collection Time: 2.22823
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.70469

Cumulative Model Updates: 102,130
Cumulative Timesteps: 851,726,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,645.27077
Policy Entropy: 3.59171
Value Function Loss: 0.09127

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.48736
Value Function Update Magnitude: 0.61014

Collected Steps per Second: 23,072.15227
Overall Steps per Second: 10,722.29594

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.49726
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.66542

Cumulative Model Updates: 102,136
Cumulative Timesteps: 851,776,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 851776652...
Checkpoint 851776652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,736.29387
Policy Entropy: 3.58188
Value Function Loss: 0.09253

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.55960

Collected Steps per Second: 22,615.17602
Overall Steps per Second: 10,611.42958

Timestep Collection Time: 2.21152
Timestep Consumption Time: 2.50170
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.71322

Cumulative Model Updates: 102,142
Cumulative Timesteps: 851,826,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,112.99059
Policy Entropy: 3.56960
Value Function Loss: 0.09009

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.50791
Value Function Update Magnitude: 0.55990

Collected Steps per Second: 23,160.59862
Overall Steps per Second: 10,867.19178

Timestep Collection Time: 2.15893
Timestep Consumption Time: 2.44226
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60119

Cumulative Model Updates: 102,148
Cumulative Timesteps: 851,876,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 851876668...
Checkpoint 851876668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,235.09360
Policy Entropy: 3.57444
Value Function Loss: 0.08671

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.52393
Value Function Update Magnitude: 0.60925

Collected Steps per Second: 22,301.67975
Overall Steps per Second: 10,718.60848

Timestep Collection Time: 2.24324
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.66740

Cumulative Model Updates: 102,154
Cumulative Timesteps: 851,926,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,851.46387
Policy Entropy: 3.57613
Value Function Loss: 0.08811

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.61731
Value Function Update Magnitude: 0.63307

Collected Steps per Second: 22,899.46347
Overall Steps per Second: 10,872.86765

Timestep Collection Time: 2.18398
Timestep Consumption Time: 2.41573
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.59971

Cumulative Model Updates: 102,160
Cumulative Timesteps: 851,976,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 851976708...
Checkpoint 851976708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,684.48734
Policy Entropy: 3.57162
Value Function Loss: 0.08716

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.18537
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.67375

Collected Steps per Second: 22,521.40718
Overall Steps per Second: 10,651.17003

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69676

Cumulative Model Updates: 102,166
Cumulative Timesteps: 852,026,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,864.25061
Policy Entropy: 3.57491
Value Function Loss: 0.09323

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.43671
Value Function Update Magnitude: 0.64493

Collected Steps per Second: 23,020.60503
Overall Steps per Second: 10,938.02674

Timestep Collection Time: 2.17336
Timestep Consumption Time: 2.40078
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.57413

Cumulative Model Updates: 102,172
Cumulative Timesteps: 852,076,766

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 852076766...
Checkpoint 852076766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,468.26394
Policy Entropy: 3.57262
Value Function Loss: 0.09188

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.51754
Value Function Update Magnitude: 0.68368

Collected Steps per Second: 22,335.43846
Overall Steps per Second: 10,616.25605

Timestep Collection Time: 2.23949
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.71164

Cumulative Model Updates: 102,178
Cumulative Timesteps: 852,126,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,607.69244
Policy Entropy: 3.58092
Value Function Loss: 0.09461

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.58016
Value Function Update Magnitude: 0.69870

Collected Steps per Second: 22,662.29854
Overall Steps per Second: 10,817.09700

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.41668
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.62361

Cumulative Model Updates: 102,184
Cumulative Timesteps: 852,176,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 852176800...
Checkpoint 852176800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,849.09887
Policy Entropy: 3.57534
Value Function Loss: 0.09304

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.54793
Value Function Update Magnitude: 0.65641

Collected Steps per Second: 20,792.90344
Overall Steps per Second: 10,334.86111

Timestep Collection Time: 2.40524
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.83916

Cumulative Model Updates: 102,190
Cumulative Timesteps: 852,226,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,381.89229
Policy Entropy: 3.56687
Value Function Loss: 0.09282

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.68993

Collected Steps per Second: 22,385.10807
Overall Steps per Second: 10,587.94638

Timestep Collection Time: 2.23479
Timestep Consumption Time: 2.49002
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.72481

Cumulative Model Updates: 102,196
Cumulative Timesteps: 852,276,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 852276838...
Checkpoint 852276838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,269.29331
Policy Entropy: 3.57340
Value Function Loss: 0.08902

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.75058

Collected Steps per Second: 21,749.93267
Overall Steps per Second: 10,568.46033

Timestep Collection Time: 2.29904
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.73144

Cumulative Model Updates: 102,202
Cumulative Timesteps: 852,326,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,315.69396
Policy Entropy: 3.57386
Value Function Loss: 0.08925

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.81452

Collected Steps per Second: 22,376.00174
Overall Steps per Second: 10,773.65409

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.40709
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.64225

Cumulative Model Updates: 102,208
Cumulative Timesteps: 852,376,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 852376856...
Checkpoint 852376856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,804.59233
Policy Entropy: 3.56891
Value Function Loss: 0.09072

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.79554

Collected Steps per Second: 21,994.55232
Overall Steps per Second: 10,656.84202

Timestep Collection Time: 2.27447
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.69426

Cumulative Model Updates: 102,214
Cumulative Timesteps: 852,426,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,986.76286
Policy Entropy: 3.56485
Value Function Loss: 0.09486

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.61764
Value Function Update Magnitude: 0.77958

Collected Steps per Second: 22,310.89606
Overall Steps per Second: 10,872.33306

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.35787
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.59901

Cumulative Model Updates: 102,220
Cumulative Timesteps: 852,476,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 852476884...
Checkpoint 852476884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,038.52958
Policy Entropy: 3.55543
Value Function Loss: 0.09385

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12512
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.71573

Collected Steps per Second: 21,860.96528
Overall Steps per Second: 10,646.64292

Timestep Collection Time: 2.28727
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.69650

Cumulative Model Updates: 102,226
Cumulative Timesteps: 852,526,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,040.11357
Policy Entropy: 3.55801
Value Function Loss: 0.09486

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.68583

Collected Steps per Second: 23,129.43856
Overall Steps per Second: 10,950.25540

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.40513
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.56756

Cumulative Model Updates: 102,232
Cumulative Timesteps: 852,576,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 852576902...
Checkpoint 852576902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,644.50855
Policy Entropy: 3.54739
Value Function Loss: 0.09410

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.59197
Value Function Update Magnitude: 0.62955

Collected Steps per Second: 21,901.02413
Overall Steps per Second: 10,615.18875

Timestep Collection Time: 2.28364
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.71155

Cumulative Model Updates: 102,238
Cumulative Timesteps: 852,626,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,231.16491
Policy Entropy: 3.54265
Value Function Loss: 0.09745

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.58254

Collected Steps per Second: 22,682.85947
Overall Steps per Second: 10,832.32313

Timestep Collection Time: 2.20501
Timestep Consumption Time: 2.41228
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61729

Cumulative Model Updates: 102,244
Cumulative Timesteps: 852,676,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 852676932...
Checkpoint 852676932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,152.83597
Policy Entropy: 3.53465
Value Function Loss: 0.09875

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.53481
Value Function Update Magnitude: 0.58455

Collected Steps per Second: 22,012.16859
Overall Steps per Second: 10,633.44805

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.70252

Cumulative Model Updates: 102,250
Cumulative Timesteps: 852,726,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,022.38339
Policy Entropy: 3.54235
Value Function Loss: 0.10096

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.52329
Value Function Update Magnitude: 0.55415

Collected Steps per Second: 22,704.14340
Overall Steps per Second: 10,551.50345

Timestep Collection Time: 2.20224
Timestep Consumption Time: 2.53642
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.73866

Cumulative Model Updates: 102,256
Cumulative Timesteps: 852,776,936

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 852776936...
Checkpoint 852776936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,196.38428
Policy Entropy: 3.53805
Value Function Loss: 0.09781

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.47544
Value Function Update Magnitude: 0.61300

Collected Steps per Second: 22,606.83846
Overall Steps per Second: 10,652.86549

Timestep Collection Time: 2.21269
Timestep Consumption Time: 2.48294
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.69564

Cumulative Model Updates: 102,262
Cumulative Timesteps: 852,826,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,756.94890
Policy Entropy: 3.54326
Value Function Loss: 0.09675

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.45371
Value Function Update Magnitude: 0.65388

Collected Steps per Second: 23,322.63439
Overall Steps per Second: 10,945.07057

Timestep Collection Time: 2.14504
Timestep Consumption Time: 2.42578
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.57082

Cumulative Model Updates: 102,268
Cumulative Timesteps: 852,876,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 852876986...
Checkpoint 852876986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,287.88071
Policy Entropy: 3.53939
Value Function Loss: 0.09220

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.44469
Value Function Update Magnitude: 0.67029

Collected Steps per Second: 22,578.47320
Overall Steps per Second: 10,582.92863

Timestep Collection Time: 2.21459
Timestep Consumption Time: 2.51019
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.72478

Cumulative Model Updates: 102,274
Cumulative Timesteps: 852,926,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,848.56109
Policy Entropy: 3.54775
Value Function Loss: 0.09170

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.48514
Value Function Update Magnitude: 0.66783

Collected Steps per Second: 22,732.37762
Overall Steps per Second: 10,687.74117

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.48004
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.68069

Cumulative Model Updates: 102,280
Cumulative Timesteps: 852,977,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 852977014...
Checkpoint 852977014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,052.17674
Policy Entropy: 3.55256
Value Function Loss: 0.09055

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.57927
Value Function Update Magnitude: 0.64819

Collected Steps per Second: 22,423.56887
Overall Steps per Second: 10,639.83713

Timestep Collection Time: 2.23096
Timestep Consumption Time: 2.47081
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.70176

Cumulative Model Updates: 102,286
Cumulative Timesteps: 853,027,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,354.85321
Policy Entropy: 3.55081
Value Function Loss: 0.09116

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.48656
Value Function Update Magnitude: 0.72934

Collected Steps per Second: 23,177.36238
Overall Steps per Second: 10,730.35440

Timestep Collection Time: 2.15823
Timestep Consumption Time: 2.50350
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.66173

Cumulative Model Updates: 102,292
Cumulative Timesteps: 853,077,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 853077062...
Checkpoint 853077062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,112.25278
Policy Entropy: 3.57733
Value Function Loss: 0.09088

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.40846
Value Function Update Magnitude: 0.68984

Collected Steps per Second: 22,163.70943
Overall Steps per Second: 10,605.79314

Timestep Collection Time: 2.25747
Timestep Consumption Time: 2.46014
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.71761

Cumulative Model Updates: 102,298
Cumulative Timesteps: 853,127,096

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,032.64901
Policy Entropy: 3.58060
Value Function Loss: 0.09264

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.53693
Value Function Update Magnitude: 0.66613

Collected Steps per Second: 22,505.42894
Overall Steps per Second: 10,674.79650

Timestep Collection Time: 2.22240
Timestep Consumption Time: 2.46303
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68543

Cumulative Model Updates: 102,304
Cumulative Timesteps: 853,177,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 853177112...
Checkpoint 853177112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,174.60202
Policy Entropy: 3.58473
Value Function Loss: 0.10075

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.61520
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 22,042.85142
Overall Steps per Second: 10,507.61047

Timestep Collection Time: 2.26949
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.76093

Cumulative Model Updates: 102,310
Cumulative Timesteps: 853,227,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,521.77490
Policy Entropy: 3.55821
Value Function Loss: 0.10019

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.61678
Value Function Update Magnitude: 0.57127

Collected Steps per Second: 22,502.74794
Overall Steps per Second: 10,747.17607

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.65369

Cumulative Model Updates: 102,316
Cumulative Timesteps: 853,277,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853277152...
Checkpoint 853277152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,538.21192
Policy Entropy: 3.55901
Value Function Loss: 0.09912

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.50107
Value Function Update Magnitude: 0.60835

Collected Steps per Second: 22,344.51983
Overall Steps per Second: 10,681.84655

Timestep Collection Time: 2.23840
Timestep Consumption Time: 2.44394
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.68234

Cumulative Model Updates: 102,322
Cumulative Timesteps: 853,327,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,050.63442
Policy Entropy: 3.54914
Value Function Loss: 0.09350

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.46515
Value Function Update Magnitude: 0.64330

Collected Steps per Second: 23,332.15016
Overall Steps per Second: 10,912.57589

Timestep Collection Time: 2.14339
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.58279

Cumulative Model Updates: 102,328
Cumulative Timesteps: 853,377,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 853377178...
Checkpoint 853377178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,339.98106
Policy Entropy: 3.54878
Value Function Loss: 0.09576

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.46938
Value Function Update Magnitude: 0.58124

Collected Steps per Second: 22,687.33537
Overall Steps per Second: 10,679.87216

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.47902
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.68395

Cumulative Model Updates: 102,334
Cumulative Timesteps: 853,427,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,548.75948
Policy Entropy: 3.57018
Value Function Loss: 0.09108

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.47533
Value Function Update Magnitude: 0.65223

Collected Steps per Second: 22,456.40683
Overall Steps per Second: 10,908.91758

Timestep Collection Time: 2.22787
Timestep Consumption Time: 2.35828
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.58616

Cumulative Model Updates: 102,340
Cumulative Timesteps: 853,477,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 853477232...
Checkpoint 853477232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,153.27123
Policy Entropy: 3.57699
Value Function Loss: 0.08969

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.51541
Value Function Update Magnitude: 0.81180

Collected Steps per Second: 21,993.64308
Overall Steps per Second: 10,599.36878

Timestep Collection Time: 2.27475
Timestep Consumption Time: 2.44534
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.72009

Cumulative Model Updates: 102,346
Cumulative Timesteps: 853,527,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,243.46193
Policy Entropy: 3.58537
Value Function Loss: 0.08744

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.46376
Value Function Update Magnitude: 0.87860

Collected Steps per Second: 21,942.98710
Overall Steps per Second: 10,676.14610

Timestep Collection Time: 2.27936
Timestep Consumption Time: 2.40548
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.68484

Cumulative Model Updates: 102,352
Cumulative Timesteps: 853,577,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 853577278...
Checkpoint 853577278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,137.75725
Policy Entropy: 3.57260
Value Function Loss: 0.08990

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11062
Policy Update Magnitude: 0.61719
Value Function Update Magnitude: 0.79075

Collected Steps per Second: 22,315.95868
Overall Steps per Second: 10,954.36704

Timestep Collection Time: 2.24198
Timestep Consumption Time: 2.32533
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.56731

Cumulative Model Updates: 102,358
Cumulative Timesteps: 853,627,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,065.47738
Policy Entropy: 3.56192
Value Function Loss: 0.09069

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.67245

Collected Steps per Second: 21,892.32471
Overall Steps per Second: 10,510.59637

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.75825

Cumulative Model Updates: 102,364
Cumulative Timesteps: 853,677,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 853677322...
Checkpoint 853677322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,741.80855
Policy Entropy: 3.56468
Value Function Loss: 0.08872

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.46950
Value Function Update Magnitude: 0.74230

Collected Steps per Second: 22,523.67250
Overall Steps per Second: 10,695.21826

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.67723

Cumulative Model Updates: 102,370
Cumulative Timesteps: 853,727,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,196.37437
Policy Entropy: 3.57274
Value Function Loss: 0.08621

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.45547
Value Function Update Magnitude: 0.81407

Collected Steps per Second: 22,839.51452
Overall Steps per Second: 10,789.91779

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.44594
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.63618

Cumulative Model Updates: 102,376
Cumulative Timesteps: 853,777,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 853777370...
Checkpoint 853777370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,006.32059
Policy Entropy: 3.58670
Value Function Loss: 0.08730

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.52025
Value Function Update Magnitude: 0.81643

Collected Steps per Second: 21,907.11467
Overall Steps per Second: 10,609.95827

Timestep Collection Time: 2.28319
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.71425

Cumulative Model Updates: 102,382
Cumulative Timesteps: 853,827,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.15349
Policy Entropy: 3.57551
Value Function Loss: 0.09129

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.50439
Value Function Update Magnitude: 0.71162

Collected Steps per Second: 22,926.70136
Overall Steps per Second: 10,838.04035

Timestep Collection Time: 2.18104
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.61375

Cumulative Model Updates: 102,388
Cumulative Timesteps: 853,877,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 853877392...
Checkpoint 853877392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,310.51714
Policy Entropy: 3.56679
Value Function Loss: 0.09506

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.48859
Value Function Update Magnitude: 0.66032

Collected Steps per Second: 22,877.78259
Overall Steps per Second: 10,668.03099

Timestep Collection Time: 2.18596
Timestep Consumption Time: 2.50187
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.68784

Cumulative Model Updates: 102,394
Cumulative Timesteps: 853,927,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,685.13900
Policy Entropy: 3.56767
Value Function Loss: 0.09536

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.45366
Value Function Update Magnitude: 0.66672

Collected Steps per Second: 23,225.33141
Overall Steps per Second: 10,882.04153

Timestep Collection Time: 2.15342
Timestep Consumption Time: 2.44259
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.59601

Cumulative Model Updates: 102,400
Cumulative Timesteps: 853,977,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853977416...
Checkpoint 853977416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.91412
Policy Entropy: 3.56398
Value Function Loss: 0.09397

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10252
Policy Update Magnitude: 0.43841
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 22,759.40154
Overall Steps per Second: 10,722.98200

Timestep Collection Time: 2.19733
Timestep Consumption Time: 2.46648
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.66381

Cumulative Model Updates: 102,406
Cumulative Timesteps: 854,027,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,396.47155
Policy Entropy: 3.55578
Value Function Loss: 0.09514

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.43269
Value Function Update Magnitude: 0.53742

Collected Steps per Second: 23,062.45836
Overall Steps per Second: 10,865.05759

Timestep Collection Time: 2.16846
Timestep Consumption Time: 2.43437
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60283

Cumulative Model Updates: 102,412
Cumulative Timesteps: 854,077,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 854077436...
Checkpoint 854077436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,423.63688
Policy Entropy: 3.56173
Value Function Loss: 0.09746

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.45391
Value Function Update Magnitude: 0.53005

Collected Steps per Second: 22,510.48347
Overall Steps per Second: 10,683.63650

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.45887
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.68005

Cumulative Model Updates: 102,418
Cumulative Timesteps: 854,127,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,338.14800
Policy Entropy: 3.55445
Value Function Loss: 0.09889

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.44775
Value Function Update Magnitude: 0.52334

Collected Steps per Second: 22,636.83251
Overall Steps per Second: 10,789.54756

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.42591
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.63523

Cumulative Model Updates: 102,424
Cumulative Timesteps: 854,177,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 854177448...
Checkpoint 854177448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,650.69387
Policy Entropy: 3.55950
Value Function Loss: 0.09616

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.44621
Value Function Update Magnitude: 0.63052

Collected Steps per Second: 21,961.10749
Overall Steps per Second: 10,659.67111

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.41450
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.69189

Cumulative Model Updates: 102,430
Cumulative Timesteps: 854,227,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,431.38843
Policy Entropy: 3.54934
Value Function Loss: 0.09386

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.44488
Value Function Update Magnitude: 0.68361

Collected Steps per Second: 22,862.91064
Overall Steps per Second: 10,712.85681

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66766

Cumulative Model Updates: 102,436
Cumulative Timesteps: 854,277,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 854277466...
Checkpoint 854277466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,230.86114
Policy Entropy: 3.56073
Value Function Loss: 0.09655

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.47115
Value Function Update Magnitude: 0.69104

Collected Steps per Second: 22,287.59139
Overall Steps per Second: 10,552.43068

Timestep Collection Time: 2.24394
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.73938

Cumulative Model Updates: 102,442
Cumulative Timesteps: 854,327,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,661.24625
Policy Entropy: 3.56090
Value Function Loss: 0.10087

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.47999
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 23,331.01659
Overall Steps per Second: 10,942.62187

Timestep Collection Time: 2.14410
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.57148

Cumulative Model Updates: 102,448
Cumulative Timesteps: 854,377,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 854377502...
Checkpoint 854377502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,838.65361
Policy Entropy: 3.57505
Value Function Loss: 0.10095

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.48615
Value Function Update Magnitude: 0.64848

Collected Steps per Second: 22,639.54165
Overall Steps per Second: 10,658.88656

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.69148

Cumulative Model Updates: 102,454
Cumulative Timesteps: 854,427,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,672.38380
Policy Entropy: 3.57191
Value Function Loss: 0.10006

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.52311
Value Function Update Magnitude: 0.67775

Collected Steps per Second: 22,709.78140
Overall Steps per Second: 10,853.52970

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.40529
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.60716

Cumulative Model Updates: 102,460
Cumulative Timesteps: 854,477,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 854477512...
Checkpoint 854477512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.52801
Policy Entropy: 3.57326
Value Function Loss: 0.09581

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.51165
Value Function Update Magnitude: 0.73166

Collected Steps per Second: 21,970.32083
Overall Steps per Second: 10,608.52431

Timestep Collection Time: 2.27653
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71470

Cumulative Model Updates: 102,466
Cumulative Timesteps: 854,527,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,551.55698
Policy Entropy: 3.56748
Value Function Loss: 0.09393

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.47390
Value Function Update Magnitude: 0.69535

Collected Steps per Second: 22,282.10420
Overall Steps per Second: 10,855.17543

Timestep Collection Time: 2.24512
Timestep Consumption Time: 2.36337
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60849

Cumulative Model Updates: 102,472
Cumulative Timesteps: 854,577,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 854577554...
Checkpoint 854577554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,332.71522
Policy Entropy: 3.56407
Value Function Loss: 0.09197

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.46622
Value Function Update Magnitude: 0.72034

Collected Steps per Second: 21,739.93540
Overall Steps per Second: 10,778.40015

Timestep Collection Time: 2.30093
Timestep Consumption Time: 2.34002
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.64095

Cumulative Model Updates: 102,478
Cumulative Timesteps: 854,627,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,273.92826
Policy Entropy: 3.56978
Value Function Loss: 0.08926

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.47552
Value Function Update Magnitude: 0.73872

Collected Steps per Second: 22,049.44033
Overall Steps per Second: 10,554.89905

Timestep Collection Time: 2.26845
Timestep Consumption Time: 2.47039
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.73884

Cumulative Model Updates: 102,484
Cumulative Timesteps: 854,677,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 854677594...
Checkpoint 854677594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,684.76229
Policy Entropy: 3.57703
Value Function Loss: 0.08755

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.48972
Value Function Update Magnitude: 0.69379

Collected Steps per Second: 22,317.32211
Overall Steps per Second: 10,600.90808

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.71695

Cumulative Model Updates: 102,490
Cumulative Timesteps: 854,727,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,849.38275
Policy Entropy: 3.58547
Value Function Loss: 0.08691

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.71702

Collected Steps per Second: 22,524.32614
Overall Steps per Second: 10,857.91252

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.38559
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.60586

Cumulative Model Updates: 102,496
Cumulative Timesteps: 854,777,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 854777608...
Checkpoint 854777608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,509.12498
Policy Entropy: 3.58385
Value Function Loss: 0.08796

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.69206

Collected Steps per Second: 22,307.45224
Overall Steps per Second: 10,596.63847

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.71904

Cumulative Model Updates: 102,502
Cumulative Timesteps: 854,827,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,279.41649
Policy Entropy: 3.57870
Value Function Loss: 0.09419

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.67571
Value Function Update Magnitude: 0.73603

Collected Steps per Second: 23,201.18326
Overall Steps per Second: 10,909.71510

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.58307

Cumulative Model Updates: 102,508
Cumulative Timesteps: 854,877,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 854877614...
Checkpoint 854877614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,652.12427
Policy Entropy: 3.58145
Value Function Loss: 0.09342

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.58377
Value Function Update Magnitude: 0.81354

Collected Steps per Second: 22,602.26624
Overall Steps per Second: 10,567.95086

Timestep Collection Time: 2.21252
Timestep Consumption Time: 2.51952
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73204

Cumulative Model Updates: 102,514
Cumulative Timesteps: 854,927,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,766.45926
Policy Entropy: 3.57647
Value Function Loss: 0.09100

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.51590
Value Function Update Magnitude: 0.82045

Collected Steps per Second: 23,161.62260
Overall Steps per Second: 10,988.31507

Timestep Collection Time: 2.15978
Timestep Consumption Time: 2.39269
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.55247

Cumulative Model Updates: 102,520
Cumulative Timesteps: 854,977,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 854977646...
Checkpoint 854977646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,590.10336
Policy Entropy: 3.58407
Value Function Loss: 0.08858

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.50207
Value Function Update Magnitude: 0.78440

Collected Steps per Second: 22,434.94982
Overall Steps per Second: 10,608.74883

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.71366

Cumulative Model Updates: 102,526
Cumulative Timesteps: 855,027,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,992.13939
Policy Entropy: 3.58100
Value Function Loss: 0.08890

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.53245
Value Function Update Magnitude: 0.73228

Collected Steps per Second: 23,242.17625
Overall Steps per Second: 10,943.96908

Timestep Collection Time: 2.15204
Timestep Consumption Time: 2.41834
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.57037

Cumulative Model Updates: 102,532
Cumulative Timesteps: 855,077,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 855077670...
Checkpoint 855077670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,006.11629
Policy Entropy: 3.57699
Value Function Loss: 0.09183

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.65942
Value Function Update Magnitude: 0.68896

Collected Steps per Second: 22,895.20822
Overall Steps per Second: 10,804.10204

Timestep Collection Time: 2.18517
Timestep Consumption Time: 2.44548
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.63065

Cumulative Model Updates: 102,538
Cumulative Timesteps: 855,127,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,437.51952
Policy Entropy: 3.57337
Value Function Loss: 0.09414

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.62696
Value Function Update Magnitude: 0.68829

Collected Steps per Second: 22,732.48608
Overall Steps per Second: 10,734.33229

Timestep Collection Time: 2.20108
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.66131

Cumulative Model Updates: 102,544
Cumulative Timesteps: 855,177,736

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 855177736...
Checkpoint 855177736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,171.62894
Policy Entropy: 3.57527
Value Function Loss: 0.09775

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.58812
Value Function Update Magnitude: 0.67206

Collected Steps per Second: 22,134.32802
Overall Steps per Second: 10,621.35004

Timestep Collection Time: 2.25984
Timestep Consumption Time: 2.44954
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.70938

Cumulative Model Updates: 102,550
Cumulative Timesteps: 855,227,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.07967
Policy Entropy: 3.56738
Value Function Loss: 0.09608

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.62362
Value Function Update Magnitude: 0.65416

Collected Steps per Second: 22,875.03516
Overall Steps per Second: 10,829.33983

Timestep Collection Time: 2.18693
Timestep Consumption Time: 2.43256
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61949

Cumulative Model Updates: 102,556
Cumulative Timesteps: 855,277,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 855277782...
Checkpoint 855277782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,717.55392
Policy Entropy: 3.56461
Value Function Loss: 0.10080

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.66672
Value Function Update Magnitude: 0.62460

Collected Steps per Second: 22,308.74545
Overall Steps per Second: 10,726.53365

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.42006
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.66134

Cumulative Model Updates: 102,562
Cumulative Timesteps: 855,327,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,245.35877
Policy Entropy: 3.57454
Value Function Loss: 0.09896

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.63134
Value Function Update Magnitude: 0.65973

Collected Steps per Second: 23,086.85945
Overall Steps per Second: 10,814.82845

Timestep Collection Time: 2.16617
Timestep Consumption Time: 2.45804
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62421

Cumulative Model Updates: 102,568
Cumulative Timesteps: 855,377,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 855377792...
Checkpoint 855377792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,110.13070
Policy Entropy: 3.57544
Value Function Loss: 0.09605

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.52319
Value Function Update Magnitude: 0.76470

Collected Steps per Second: 22,401.11792
Overall Steps per Second: 10,743.19258

Timestep Collection Time: 2.23328
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.65672

Cumulative Model Updates: 102,574
Cumulative Timesteps: 855,427,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,764.37119
Policy Entropy: 3.56257
Value Function Loss: 0.09197

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.54287
Value Function Update Magnitude: 0.77871

Collected Steps per Second: 23,117.97666
Overall Steps per Second: 10,858.39487

Timestep Collection Time: 2.16325
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60565

Cumulative Model Updates: 102,580
Cumulative Timesteps: 855,477,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 855477830...
Checkpoint 855477830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,545.34912
Policy Entropy: 3.55397
Value Function Loss: 0.09084

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.57534
Value Function Update Magnitude: 0.66060

Collected Steps per Second: 22,838.26759
Overall Steps per Second: 10,657.17696

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.69449

Cumulative Model Updates: 102,586
Cumulative Timesteps: 855,527,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,665.25455
Policy Entropy: 3.55656
Value Function Loss: 0.08966

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.69853

Collected Steps per Second: 22,952.90579
Overall Steps per Second: 10,843.41072

Timestep Collection Time: 2.17881
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61202

Cumulative Model Updates: 102,592
Cumulative Timesteps: 855,577,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 855577870...
Checkpoint 855577870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,016.86979
Policy Entropy: 3.56926
Value Function Loss: 0.08883

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.68592

Collected Steps per Second: 22,842.05794
Overall Steps per Second: 10,702.18911

Timestep Collection Time: 2.18921
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.67250

Cumulative Model Updates: 102,598
Cumulative Timesteps: 855,627,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,242.43458
Policy Entropy: 3.57427
Value Function Loss: 0.08898

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.53032
Value Function Update Magnitude: 0.63300

Collected Steps per Second: 22,510.58643
Overall Steps per Second: 10,640.63977

Timestep Collection Time: 2.22242
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.70160

Cumulative Model Updates: 102,604
Cumulative Timesteps: 855,677,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 855677904...
Checkpoint 855677904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,664.28493
Policy Entropy: 3.57659
Value Function Loss: 0.09193

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.62857

Collected Steps per Second: 21,992.43200
Overall Steps per Second: 10,441.15018

Timestep Collection Time: 2.27360
Timestep Consumption Time: 2.51534
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.78894

Cumulative Model Updates: 102,610
Cumulative Timesteps: 855,727,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,115.91825
Policy Entropy: 3.58146
Value Function Loss: 0.09446

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.61679
Value Function Update Magnitude: 0.67731

Collected Steps per Second: 22,852.77411
Overall Steps per Second: 10,823.68915

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62079

Cumulative Model Updates: 102,616
Cumulative Timesteps: 855,777,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 855777920...
Checkpoint 855777920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,438.73541
Policy Entropy: 3.58134
Value Function Loss: 0.09658

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.63627
Value Function Update Magnitude: 0.66723

Collected Steps per Second: 22,215.37215
Overall Steps per Second: 10,686.77720

Timestep Collection Time: 2.25204
Timestep Consumption Time: 2.42944
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.68149

Cumulative Model Updates: 102,622
Cumulative Timesteps: 855,827,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,019.94065
Policy Entropy: 3.58863
Value Function Loss: 0.10005

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15928
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.63150

Collected Steps per Second: 22,797.79050
Overall Steps per Second: 10,632.11429

Timestep Collection Time: 2.19416
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70480

Cumulative Model Updates: 102,628
Cumulative Timesteps: 855,877,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 855877972...
Checkpoint 855877972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,230.40041
Policy Entropy: 3.57772
Value Function Loss: 0.09927

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.44551
Value Function Update Magnitude: 0.72062

Collected Steps per Second: 22,852.90466
Overall Steps per Second: 10,723.50319

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.66284

Cumulative Model Updates: 102,634
Cumulative Timesteps: 855,927,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,977.65835
Policy Entropy: 3.57481
Value Function Loss: 0.09923

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.51821
Value Function Update Magnitude: 0.69609

Collected Steps per Second: 23,068.53052
Overall Steps per Second: 10,716.70607

Timestep Collection Time: 2.16850
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.66785

Cumulative Model Updates: 102,640
Cumulative Timesteps: 855,977,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 855977998...
Checkpoint 855977998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,720.80601
Policy Entropy: 3.57614
Value Function Loss: 0.09856

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.60506
Value Function Update Magnitude: 0.67800

Collected Steps per Second: 22,714.12540
Overall Steps per Second: 10,607.33281

Timestep Collection Time: 2.20145
Timestep Consumption Time: 2.51265
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.71410

Cumulative Model Updates: 102,646
Cumulative Timesteps: 856,028,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,038.34596
Policy Entropy: 3.57095
Value Function Loss: 0.09679

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.62079
Value Function Update Magnitude: 0.66168

Collected Steps per Second: 21,885.90648
Overall Steps per Second: 10,466.66694

Timestep Collection Time: 2.28585
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.77975

Cumulative Model Updates: 102,652
Cumulative Timesteps: 856,078,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 856078030...
Checkpoint 856078030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,744.09013
Policy Entropy: 3.55833
Value Function Loss: 0.09649

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.56319
Value Function Update Magnitude: 0.68338

Collected Steps per Second: 22,332.88309
Overall Steps per Second: 10,672.65119

Timestep Collection Time: 2.23984
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.68693

Cumulative Model Updates: 102,658
Cumulative Timesteps: 856,128,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,118.36220
Policy Entropy: 3.56671
Value Function Loss: 0.09255

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.80859

Collected Steps per Second: 22,606.02972
Overall Steps per Second: 10,637.12151

Timestep Collection Time: 2.21233
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.70165

Cumulative Model Updates: 102,664
Cumulative Timesteps: 856,178,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 856178064...
Checkpoint 856178064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,841.21814
Policy Entropy: 3.57041
Value Function Loss: 0.09356

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.67751
Value Function Update Magnitude: 0.84493

Collected Steps per Second: 22,416.16790
Overall Steps per Second: 10,554.60168

Timestep Collection Time: 2.23053
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.73727

Cumulative Model Updates: 102,670
Cumulative Timesteps: 856,228,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.52623
Policy Entropy: 3.57085
Value Function Loss: 0.09220

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.71379
Value Function Update Magnitude: 0.75798

Collected Steps per Second: 23,027.14144
Overall Steps per Second: 10,775.29402

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.46978
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.64192

Cumulative Model Updates: 102,676
Cumulative Timesteps: 856,278,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 856278082...
Checkpoint 856278082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,434.60794
Policy Entropy: 3.56552
Value Function Loss: 0.09627

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.65001
Value Function Update Magnitude: 0.72721

Collected Steps per Second: 22,757.23333
Overall Steps per Second: 10,629.06422

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.50718
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.70446

Cumulative Model Updates: 102,682
Cumulative Timesteps: 856,328,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,592.59163
Policy Entropy: 3.56203
Value Function Loss: 0.09037

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.82183

Collected Steps per Second: 23,060.48747
Overall Steps per Second: 10,864.76605

Timestep Collection Time: 2.16916
Timestep Consumption Time: 2.43489
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.60406

Cumulative Model Updates: 102,688
Cumulative Timesteps: 856,378,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 856378108...
Checkpoint 856378108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,445.35040
Policy Entropy: 3.55222
Value Function Loss: 0.09144

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.19651
Policy Update Magnitude: 0.53236
Value Function Update Magnitude: 0.83104

Collected Steps per Second: 22,628.73776
Overall Steps per Second: 10,712.41593

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.45859
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.66879

Cumulative Model Updates: 102,694
Cumulative Timesteps: 856,428,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,442.79639
Policy Entropy: 3.55426
Value Function Loss: 0.08995

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.49095
Value Function Update Magnitude: 0.72400

Collected Steps per Second: 23,003.90753
Overall Steps per Second: 10,843.79779

Timestep Collection Time: 2.17380
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.61148

Cumulative Model Updates: 102,700
Cumulative Timesteps: 856,478,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 856478128...
Checkpoint 856478128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,260.56852
Policy Entropy: 3.57072
Value Function Loss: 0.09146

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.61840

Collected Steps per Second: 22,524.56365
Overall Steps per Second: 10,752.47210

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.65307

Cumulative Model Updates: 102,706
Cumulative Timesteps: 856,528,160

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,589.49300
Policy Entropy: 3.56879
Value Function Loss: 0.08986

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.64067

Collected Steps per Second: 22,760.23470
Overall Steps per Second: 10,819.00415

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.62353

Cumulative Model Updates: 102,712
Cumulative Timesteps: 856,578,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 856578182...
Checkpoint 856578182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,398.70402
Policy Entropy: 3.58312
Value Function Loss: 0.08945

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.64158
Value Function Update Magnitude: 0.64912

Collected Steps per Second: 22,170.23854
Overall Steps per Second: 10,699.39398

Timestep Collection Time: 2.25537
Timestep Consumption Time: 2.41798
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.67335

Cumulative Model Updates: 102,718
Cumulative Timesteps: 856,628,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,611.42786
Policy Entropy: 3.57608
Value Function Loss: 0.08876

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.73879
Value Function Update Magnitude: 0.64694

Collected Steps per Second: 22,649.85769
Overall Steps per Second: 10,792.27602

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.63572

Cumulative Model Updates: 102,724
Cumulative Timesteps: 856,678,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 856678214...
Checkpoint 856678214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,727.51837
Policy Entropy: 3.58323
Value Function Loss: 0.08927

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.71338
Value Function Update Magnitude: 0.62738

Collected Steps per Second: 22,393.47192
Overall Steps per Second: 10,699.08940

Timestep Collection Time: 2.23306
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.67386

Cumulative Model Updates: 102,730
Cumulative Timesteps: 856,728,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,153.25356
Policy Entropy: 3.56992
Value Function Loss: 0.08948

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.59750
Value Function Update Magnitude: 0.61348

Collected Steps per Second: 23,043.23422
Overall Steps per Second: 10,853.20425

Timestep Collection Time: 2.16983
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.60693

Cumulative Model Updates: 102,736
Cumulative Timesteps: 856,778,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 856778220...
Checkpoint 856778220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,765.57562
Policy Entropy: 3.57411
Value Function Loss: 0.08594

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.66350

Collected Steps per Second: 22,778.53489
Overall Steps per Second: 10,714.47922

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.66752

Cumulative Model Updates: 102,742
Cumulative Timesteps: 856,828,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,476.66117
Policy Entropy: 3.56004
Value Function Loss: 0.08738

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.59962
Value Function Update Magnitude: 0.71275

Collected Steps per Second: 22,832.76802
Overall Steps per Second: 10,830.51165

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.42879
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.62046

Cumulative Model Updates: 102,748
Cumulative Timesteps: 856,878,272

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 856878272...
Checkpoint 856878272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,532.68492
Policy Entropy: 3.55625
Value Function Loss: 0.08760

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.68109
Value Function Update Magnitude: 0.67164

Collected Steps per Second: 22,654.87797
Overall Steps per Second: 10,734.96596

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.45172
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.65973

Cumulative Model Updates: 102,754
Cumulative Timesteps: 856,928,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,636.13899
Policy Entropy: 3.56906
Value Function Loss: 0.08915

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.55209
Value Function Update Magnitude: 0.71816

Collected Steps per Second: 23,209.54215
Overall Steps per Second: 10,970.43679

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.40496
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.56062

Cumulative Model Updates: 102,760
Cumulative Timesteps: 856,978,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 856978326...
Checkpoint 856978326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,329.38950
Policy Entropy: 3.59999
Value Function Loss: 0.08749

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.43378
Value Function Update Magnitude: 0.74201

Collected Steps per Second: 21,992.00762
Overall Steps per Second: 10,673.68615

Timestep Collection Time: 2.27392
Timestep Consumption Time: 2.41125
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.68517

Cumulative Model Updates: 102,766
Cumulative Timesteps: 857,028,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.33363
Policy Entropy: 3.61518
Value Function Loss: 0.08429

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.65107
Value Function Update Magnitude: 0.75465

Collected Steps per Second: 21,755.47115
Overall Steps per Second: 10,760.73021

Timestep Collection Time: 2.30020
Timestep Consumption Time: 2.35022
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.65043

Cumulative Model Updates: 102,772
Cumulative Timesteps: 857,078,376

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 857078376...
Checkpoint 857078376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,294.48543
Policy Entropy: 3.61205
Value Function Loss: 0.08309

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.73358
Value Function Update Magnitude: 0.69872

Collected Steps per Second: 21,720.54669
Overall Steps per Second: 10,749.51304

Timestep Collection Time: 2.30215
Timestep Consumption Time: 2.34959
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.65175

Cumulative Model Updates: 102,778
Cumulative Timesteps: 857,128,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,461.32063
Policy Entropy: 3.60695
Value Function Loss: 0.08401

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.58436
Value Function Update Magnitude: 0.67308

Collected Steps per Second: 21,913.40861
Overall Steps per Second: 10,789.82484

Timestep Collection Time: 2.28289
Timestep Consumption Time: 2.35351
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.63641

Cumulative Model Updates: 102,784
Cumulative Timesteps: 857,178,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 857178406...
Checkpoint 857178406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,040.97031
Policy Entropy: 3.60740
Value Function Loss: 0.08661

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.53514
Value Function Update Magnitude: 0.68663

Collected Steps per Second: 21,950.08842
Overall Steps per Second: 10,727.09501

Timestep Collection Time: 2.27817
Timestep Consumption Time: 2.38348
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.66165

Cumulative Model Updates: 102,790
Cumulative Timesteps: 857,228,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,183.52241
Policy Entropy: 3.59798
Value Function Loss: 0.08570

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.56804
Value Function Update Magnitude: 0.67488

Collected Steps per Second: 21,932.31865
Overall Steps per Second: 10,619.45152

Timestep Collection Time: 2.28084
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.71060

Cumulative Model Updates: 102,796
Cumulative Timesteps: 857,278,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 857278436...
Checkpoint 857278436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,764.51825
Policy Entropy: 3.60226
Value Function Loss: 0.08433

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.56461
Value Function Update Magnitude: 0.75215

Collected Steps per Second: 22,177.07560
Overall Steps per Second: 10,588.86708

Timestep Collection Time: 2.25566
Timestep Consumption Time: 2.46854
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.72421

Cumulative Model Updates: 102,802
Cumulative Timesteps: 857,328,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,067.94946
Policy Entropy: 3.60957
Value Function Loss: 0.08219

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.15412
Policy Update Magnitude: 0.51022
Value Function Update Magnitude: 0.71230

Collected Steps per Second: 22,923.44802
Overall Steps per Second: 10,792.14886

Timestep Collection Time: 2.18239
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.63559

Cumulative Model Updates: 102,808
Cumulative Timesteps: 857,378,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 857378488...
Checkpoint 857378488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,633.54575
Policy Entropy: 3.61306
Value Function Loss: 0.08392

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.51375
Value Function Update Magnitude: 0.66957

Collected Steps per Second: 22,750.28141
Overall Steps per Second: 10,710.11515

Timestep Collection Time: 2.19848
Timestep Consumption Time: 2.47150
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.66998

Cumulative Model Updates: 102,814
Cumulative Timesteps: 857,428,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,914.99374
Policy Entropy: 3.61685
Value Function Loss: 0.08734

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.56863
Value Function Update Magnitude: 0.63113

Collected Steps per Second: 23,192.29956
Overall Steps per Second: 10,806.79258

Timestep Collection Time: 2.15641
Timestep Consumption Time: 2.47142
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.62783

Cumulative Model Updates: 102,820
Cumulative Timesteps: 857,478,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 857478516...
Checkpoint 857478516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,190.76788
Policy Entropy: 3.62444
Value Function Loss: 0.08630

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.64099

Collected Steps per Second: 22,740.54630
Overall Steps per Second: 10,678.56785

Timestep Collection Time: 2.19986
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.68471

Cumulative Model Updates: 102,826
Cumulative Timesteps: 857,528,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,144.90126
Policy Entropy: 3.61322
Value Function Loss: 0.08471

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.56872
Value Function Update Magnitude: 0.68993

Collected Steps per Second: 22,458.49725
Overall Steps per Second: 10,595.39241

Timestep Collection Time: 2.22677
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.71998

Cumulative Model Updates: 102,832
Cumulative Timesteps: 857,578,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 857578552...
Checkpoint 857578552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,552.83822
Policy Entropy: 3.61447
Value Function Loss: 0.08371

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.72618

Collected Steps per Second: 22,590.91926
Overall Steps per Second: 10,674.92031

Timestep Collection Time: 2.21390
Timestep Consumption Time: 2.47129
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.68519

Cumulative Model Updates: 102,838
Cumulative Timesteps: 857,628,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,463.18600
Policy Entropy: 3.60386
Value Function Loss: 0.08504

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.49275
Value Function Update Magnitude: 0.79229

Collected Steps per Second: 22,135.27566
Overall Steps per Second: 10,653.96081

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.69478

Cumulative Model Updates: 102,844
Cumulative Timesteps: 857,678,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 857678584...
Checkpoint 857678584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.81411
Policy Entropy: 3.61018
Value Function Loss: 0.08529

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.63910
Value Function Update Magnitude: 0.74913

Collected Steps per Second: 22,648.71717
Overall Steps per Second: 10,665.61698

Timestep Collection Time: 2.20843
Timestep Consumption Time: 2.48122
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.68965

Cumulative Model Updates: 102,850
Cumulative Timesteps: 857,728,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,553.19791
Policy Entropy: 3.60024
Value Function Loss: 0.08544

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.77275
Value Function Update Magnitude: 0.70655

Collected Steps per Second: 22,887.89459
Overall Steps per Second: 10,814.33603

Timestep Collection Time: 2.18465
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62368

Cumulative Model Updates: 102,856
Cumulative Timesteps: 857,778,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 857778604...
Checkpoint 857778604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,912.32849
Policy Entropy: 3.59687
Value Function Loss: 0.08502

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.70617
Value Function Update Magnitude: 0.71120

Collected Steps per Second: 22,699.14042
Overall Steps per Second: 10,755.76388

Timestep Collection Time: 2.20387
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.65109

Cumulative Model Updates: 102,862
Cumulative Timesteps: 857,828,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,322.85982
Policy Entropy: 3.60003
Value Function Loss: 0.08404

Mean KL Divergence: 0.02523
SB3 Clip Fraction: 0.18897
Policy Update Magnitude: 0.60816
Value Function Update Magnitude: 0.69404

Collected Steps per Second: 22,956.72163
Overall Steps per Second: 10,846.69605

Timestep Collection Time: 2.17827
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61025

Cumulative Model Updates: 102,868
Cumulative Timesteps: 857,878,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 857878636...
Checkpoint 857878636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,630.49105
Policy Entropy: 3.61472
Value Function Loss: 0.08386

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15546
Policy Update Magnitude: 0.50093
Value Function Update Magnitude: 0.77176

Collected Steps per Second: 22,530.85901
Overall Steps per Second: 10,754.73220

Timestep Collection Time: 2.22051
Timestep Consumption Time: 2.43140
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.65191

Cumulative Model Updates: 102,874
Cumulative Timesteps: 857,928,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,883.64468
Policy Entropy: 3.61700
Value Function Loss: 0.08485

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.59407
Value Function Update Magnitude: 0.80685

Collected Steps per Second: 21,905.30421
Overall Steps per Second: 10,398.83073

Timestep Collection Time: 2.28319
Timestep Consumption Time: 2.52639
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.80958

Cumulative Model Updates: 102,880
Cumulative Timesteps: 857,978,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 857978680...
Checkpoint 857978680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,121.63357
Policy Entropy: 3.62075
Value Function Loss: 0.08283

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.55703
Value Function Update Magnitude: 0.78807

Collected Steps per Second: 22,764.13777
Overall Steps per Second: 10,630.25245

Timestep Collection Time: 2.19653
Timestep Consumption Time: 2.50722
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.70375

Cumulative Model Updates: 102,886
Cumulative Timesteps: 858,028,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,191.01808
Policy Entropy: 3.61545
Value Function Loss: 0.08095

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.56472
Value Function Update Magnitude: 0.78551

Collected Steps per Second: 22,157.88836
Overall Steps per Second: 10,519.58738

Timestep Collection Time: 2.25680
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75361

Cumulative Model Updates: 102,892
Cumulative Timesteps: 858,078,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 858078688...
Checkpoint 858078688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,588.59125
Policy Entropy: 3.60526
Value Function Loss: 0.08266

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.59300
Value Function Update Magnitude: 0.71754

Collected Steps per Second: 21,997.64019
Overall Steps per Second: 10,584.19722

Timestep Collection Time: 2.27306
Timestep Consumption Time: 2.45115
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.72421

Cumulative Model Updates: 102,898
Cumulative Timesteps: 858,128,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.06776
Policy Entropy: 3.59886
Value Function Loss: 0.08512

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.51104
Value Function Update Magnitude: 0.67228

Collected Steps per Second: 22,516.06974
Overall Steps per Second: 10,619.22600

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.71051

Cumulative Model Updates: 102,904
Cumulative Timesteps: 858,178,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 858178712...
Checkpoint 858178712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,048.26633
Policy Entropy: 3.60710
Value Function Loss: 0.08340

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.50031
Value Function Update Magnitude: 0.71342

Collected Steps per Second: 22,658.69650
Overall Steps per Second: 10,663.65405

Timestep Collection Time: 2.20736
Timestep Consumption Time: 2.48296
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69032

Cumulative Model Updates: 102,910
Cumulative Timesteps: 858,228,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,078.75580
Policy Entropy: 3.60729
Value Function Loss: 0.08280

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.49584
Value Function Update Magnitude: 0.70009

Collected Steps per Second: 22,810.91101
Overall Steps per Second: 10,717.97139

Timestep Collection Time: 2.19193
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.66506

Cumulative Model Updates: 102,916
Cumulative Timesteps: 858,278,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 858278728...
Checkpoint 858278728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.09954
Policy Entropy: 3.59642
Value Function Loss: 0.08551

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.50988
Value Function Update Magnitude: 0.73587

Collected Steps per Second: 22,740.03610
Overall Steps per Second: 10,636.64932

Timestep Collection Time: 2.19894
Timestep Consumption Time: 2.50216
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.70110

Cumulative Model Updates: 102,922
Cumulative Timesteps: 858,328,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.49560
Policy Entropy: 3.59153
Value Function Loss: 0.08631

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.54916
Value Function Update Magnitude: 0.77964

Collected Steps per Second: 23,012.62413
Overall Steps per Second: 10,869.21883

Timestep Collection Time: 2.17281
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60033

Cumulative Model Updates: 102,928
Cumulative Timesteps: 858,378,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 858378734...
Checkpoint 858378734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.84188
Policy Entropy: 3.58736
Value Function Loss: 0.08673

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.57516
Value Function Update Magnitude: 0.75511

Collected Steps per Second: 22,807.29224
Overall Steps per Second: 10,664.63011

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69027

Cumulative Model Updates: 102,934
Cumulative Timesteps: 858,428,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,669.61740
Policy Entropy: 3.58586
Value Function Loss: 0.08805

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.62965
Value Function Update Magnitude: 0.74271

Collected Steps per Second: 22,220.55895
Overall Steps per Second: 10,854.48920

Timestep Collection Time: 2.25125
Timestep Consumption Time: 2.35735
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60860

Cumulative Model Updates: 102,940
Cumulative Timesteps: 858,478,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 858478778...
Checkpoint 858478778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,069.02787
Policy Entropy: 3.57141
Value Function Loss: 0.08871

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.67232
Value Function Update Magnitude: 0.80986

Collected Steps per Second: 22,318.05572
Overall Steps per Second: 10,728.69375

Timestep Collection Time: 2.24150
Timestep Consumption Time: 2.42132
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.66282

Cumulative Model Updates: 102,946
Cumulative Timesteps: 858,528,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,438.95894
Policy Entropy: 3.58148
Value Function Loss: 0.08495

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.61835
Value Function Update Magnitude: 0.83757

Collected Steps per Second: 22,279.01098
Overall Steps per Second: 10,901.18948

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.34333
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.58849

Cumulative Model Updates: 102,952
Cumulative Timesteps: 858,578,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 858578824...
Checkpoint 858578824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.15144
Policy Entropy: 3.59573
Value Function Loss: 0.08265

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.78272

Collected Steps per Second: 21,644.17934
Overall Steps per Second: 10,619.90899

Timestep Collection Time: 2.31018
Timestep Consumption Time: 2.39814
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.70833

Cumulative Model Updates: 102,958
Cumulative Timesteps: 858,628,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,755.98561
Policy Entropy: 3.60567
Value Function Loss: 0.08606

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.64316
Value Function Update Magnitude: 0.80473

Collected Steps per Second: 21,717.47717
Overall Steps per Second: 10,600.54460

Timestep Collection Time: 2.30229
Timestep Consumption Time: 2.41445
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.71674

Cumulative Model Updates: 102,964
Cumulative Timesteps: 858,678,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 858678826...
Checkpoint 858678826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,719.49239
Policy Entropy: 3.60085
Value Function Loss: 0.09038

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.68075
Value Function Update Magnitude: 0.77592

Collected Steps per Second: 21,923.34054
Overall Steps per Second: 10,696.48555

Timestep Collection Time: 2.28159
Timestep Consumption Time: 2.39472
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.67630

Cumulative Model Updates: 102,970
Cumulative Timesteps: 858,728,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,360.06964
Policy Entropy: 3.58951
Value Function Loss: 0.08925

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.61351
Value Function Update Magnitude: 0.84850

Collected Steps per Second: 21,906.64761
Overall Steps per Second: 10,699.73109

Timestep Collection Time: 2.28269
Timestep Consumption Time: 2.39089
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.67358

Cumulative Model Updates: 102,976
Cumulative Timesteps: 858,778,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 858778852...
Checkpoint 858778852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,733.03257
Policy Entropy: 3.60211
Value Function Loss: 0.08417

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.76664

Collected Steps per Second: 22,191.47711
Overall Steps per Second: 10,625.55141

Timestep Collection Time: 2.25474
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.70903

Cumulative Model Updates: 102,982
Cumulative Timesteps: 858,828,888

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.08304
Policy Entropy: 3.60179
Value Function Loss: 0.08344

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.65511
Value Function Update Magnitude: 0.65248

Collected Steps per Second: 22,464.35996
Overall Steps per Second: 10,750.02124

Timestep Collection Time: 2.22691
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.65357

Cumulative Model Updates: 102,988
Cumulative Timesteps: 858,878,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 858878914...
Checkpoint 858878914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,896.99411
Policy Entropy: 3.59539
Value Function Loss: 0.08457

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.77656
Value Function Update Magnitude: 0.63135

Collected Steps per Second: 22,419.57133
Overall Steps per Second: 10,799.69720

Timestep Collection Time: 2.23144
Timestep Consumption Time: 2.40091
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.63235

Cumulative Model Updates: 102,994
Cumulative Timesteps: 858,928,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,091.87374
Policy Entropy: 3.58593
Value Function Loss: 0.08678

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.78823
Value Function Update Magnitude: 0.68958

Collected Steps per Second: 22,774.63176
Overall Steps per Second: 10,868.88485

Timestep Collection Time: 2.19657
Timestep Consumption Time: 2.40611
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60268

Cumulative Model Updates: 103,000
Cumulative Timesteps: 858,978,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 858978968...
Checkpoint 858978968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,127.28437
Policy Entropy: 3.59328
Value Function Loss: 0.08493

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.68797
Value Function Update Magnitude: 0.80743

Collected Steps per Second: 22,815.04131
Overall Steps per Second: 10,723.55459

Timestep Collection Time: 2.19241
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.66450

Cumulative Model Updates: 103,006
Cumulative Timesteps: 859,028,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,466.26922
Policy Entropy: 3.58914
Value Function Loss: 0.08361

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.63352
Value Function Update Magnitude: 0.81024

Collected Steps per Second: 22,633.68851
Overall Steps per Second: 10,812.55113

Timestep Collection Time: 2.20936
Timestep Consumption Time: 2.41545
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62481

Cumulative Model Updates: 103,012
Cumulative Timesteps: 859,078,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 859078994...
Checkpoint 859078994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,862.95712
Policy Entropy: 3.59921
Value Function Loss: 0.08311

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.70832
Value Function Update Magnitude: 0.74620

Collected Steps per Second: 22,387.42959
Overall Steps per Second: 10,737.76631

Timestep Collection Time: 2.23366
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.65702

Cumulative Model Updates: 103,018
Cumulative Timesteps: 859,129,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,379.47594
Policy Entropy: 3.60244
Value Function Loss: 0.08294

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.73817
Value Function Update Magnitude: 0.70298

Collected Steps per Second: 22,525.20017
Overall Steps per Second: 10,767.73443

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.42561
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.64703

Cumulative Model Updates: 103,024
Cumulative Timesteps: 859,179,038

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 859179038...
Checkpoint 859179038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,458.85356
Policy Entropy: 3.60983
Value Function Loss: 0.08350

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.63508
Value Function Update Magnitude: 0.71706

Collected Steps per Second: 22,473.30772
Overall Steps per Second: 10,779.03498

Timestep Collection Time: 2.22531
Timestep Consumption Time: 2.41426
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.63956

Cumulative Model Updates: 103,030
Cumulative Timesteps: 859,229,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,250.41663
Policy Entropy: 3.60001
Value Function Loss: 0.08516

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.57549
Value Function Update Magnitude: 0.70369

Collected Steps per Second: 22,935.56738
Overall Steps per Second: 10,758.60952

Timestep Collection Time: 2.18089
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.64930

Cumulative Model Updates: 103,036
Cumulative Timesteps: 859,279,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 859279068...
Checkpoint 859279068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,673.12994
Policy Entropy: 3.60211
Value Function Loss: 0.08805

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.65812
Value Function Update Magnitude: 0.69808

Collected Steps per Second: 22,996.58119
Overall Steps per Second: 10,696.09384

Timestep Collection Time: 2.17432
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.67479

Cumulative Model Updates: 103,042
Cumulative Timesteps: 859,329,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,542.74579
Policy Entropy: 3.60180
Value Function Loss: 0.08795

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.70105

Collected Steps per Second: 23,065.63608
Overall Steps per Second: 10,878.66395

Timestep Collection Time: 2.16859
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.59799

Cumulative Model Updates: 103,048
Cumulative Timesteps: 859,379,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 859379090...
Checkpoint 859379090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.82134
Policy Entropy: 3.60383
Value Function Loss: 0.08692

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.49077
Value Function Update Magnitude: 0.69432

Collected Steps per Second: 22,822.99543
Overall Steps per Second: 10,706.88305

Timestep Collection Time: 2.19218
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.67288

Cumulative Model Updates: 103,054
Cumulative Timesteps: 859,429,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,033.01793
Policy Entropy: 3.59389
Value Function Loss: 0.08626

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.49633
Value Function Update Magnitude: 0.68701

Collected Steps per Second: 22,777.41656
Overall Steps per Second: 10,799.33638

Timestep Collection Time: 2.19568
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63103

Cumulative Model Updates: 103,060
Cumulative Timesteps: 859,479,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 859479134...
Checkpoint 859479134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,059.87211
Policy Entropy: 3.59664
Value Function Loss: 0.08699

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.47815
Value Function Update Magnitude: 0.68989

Collected Steps per Second: 22,680.60618
Overall Steps per Second: 10,816.51481

Timestep Collection Time: 2.20647
Timestep Consumption Time: 2.42016
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.62663

Cumulative Model Updates: 103,066
Cumulative Timesteps: 859,529,178

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,355.41710
Policy Entropy: 3.58837
Value Function Loss: 0.08855

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.46755
Value Function Update Magnitude: 0.73873

Collected Steps per Second: 22,919.03727
Overall Steps per Second: 10,840.76518

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61480

Cumulative Model Updates: 103,072
Cumulative Timesteps: 859,579,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859579206...
Checkpoint 859579206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,834.25475
Policy Entropy: 3.58562
Value Function Loss: 0.08837

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.49007
Value Function Update Magnitude: 0.74400

Collected Steps per Second: 22,337.01674
Overall Steps per Second: 10,639.13867

Timestep Collection Time: 2.23942
Timestep Consumption Time: 2.46227
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.70170

Cumulative Model Updates: 103,078
Cumulative Timesteps: 859,629,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,922.99326
Policy Entropy: 3.57692
Value Function Loss: 0.08931

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.72332

Collected Steps per Second: 22,357.84286
Overall Steps per Second: 10,521.52761

Timestep Collection Time: 2.23734
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.75425

Cumulative Model Updates: 103,084
Cumulative Timesteps: 859,679,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 859679250...
Checkpoint 859679250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.94518
Policy Entropy: 3.57611
Value Function Loss: 0.09285

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.59994
Value Function Update Magnitude: 0.69398

Collected Steps per Second: 22,598.37986
Overall Steps per Second: 10,570.36580

Timestep Collection Time: 2.21290
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.73096

Cumulative Model Updates: 103,090
Cumulative Timesteps: 859,729,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,052.38457
Policy Entropy: 3.57745
Value Function Loss: 0.09135

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.49484
Value Function Update Magnitude: 0.67414

Collected Steps per Second: 22,979.42049
Overall Steps per Second: 10,831.89860

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.44150
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.61858

Cumulative Model Updates: 103,096
Cumulative Timesteps: 859,779,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859779286...
Checkpoint 859779286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,582.46945
Policy Entropy: 3.58471
Value Function Loss: 0.09160

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.51912
Value Function Update Magnitude: 0.64085

Collected Steps per Second: 23,025.57830
Overall Steps per Second: 10,713.68005

Timestep Collection Time: 2.17219
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.66842

Cumulative Model Updates: 103,102
Cumulative Timesteps: 859,829,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,061.16804
Policy Entropy: 3.58882
Value Function Loss: 0.08668

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.50661
Value Function Update Magnitude: 0.68483

Collected Steps per Second: 22,887.13142
Overall Steps per Second: 10,855.26521

Timestep Collection Time: 2.18560
Timestep Consumption Time: 2.42249
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60809

Cumulative Model Updates: 103,108
Cumulative Timesteps: 859,879,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 859879324...
Checkpoint 859879324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,780.19177
Policy Entropy: 3.59100
Value Function Loss: 0.08627

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.47828
Value Function Update Magnitude: 0.73041

Collected Steps per Second: 22,423.72632
Overall Steps per Second: 10,735.00867

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.42953
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.66083

Cumulative Model Updates: 103,114
Cumulative Timesteps: 859,929,358

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.66049
Policy Entropy: 3.59573
Value Function Loss: 0.08482

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.48274
Value Function Update Magnitude: 0.76018

Collected Steps per Second: 23,078.42483
Overall Steps per Second: 10,927.79120

Timestep Collection Time: 2.16670
Timestep Consumption Time: 2.40916
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.57586

Cumulative Model Updates: 103,120
Cumulative Timesteps: 859,979,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 859979362...
Checkpoint 859979362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,339.21560
Policy Entropy: 3.59171
Value Function Loss: 0.08353

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.47825
Value Function Update Magnitude: 0.75657

Collected Steps per Second: 22,551.24925
Overall Steps per Second: 10,603.23362

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.71799

Cumulative Model Updates: 103,126
Cumulative Timesteps: 860,029,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,824.44038
Policy Entropy: 3.59235
Value Function Loss: 0.08861

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.45921
Value Function Update Magnitude: 0.72696

Collected Steps per Second: 22,481.64044
Overall Steps per Second: 10,816.10438

Timestep Collection Time: 2.22448
Timestep Consumption Time: 2.39918
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.62366

Cumulative Model Updates: 103,132
Cumulative Timesteps: 860,079,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 860079398...
Checkpoint 860079398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,145.96585
Policy Entropy: 3.58033
Value Function Loss: 0.09210

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.43177
Value Function Update Magnitude: 0.78522

Collected Steps per Second: 22,346.65326
Overall Steps per Second: 10,702.05741

Timestep Collection Time: 2.23819
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.67349

Cumulative Model Updates: 103,138
Cumulative Timesteps: 860,129,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,282.07279
Policy Entropy: 3.57740
Value Function Loss: 0.09552

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.38534
Value Function Update Magnitude: 0.72217

Collected Steps per Second: 22,822.14378
Overall Steps per Second: 10,709.02800

Timestep Collection Time: 2.19173
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.67083

Cumulative Model Updates: 103,144
Cumulative Timesteps: 860,179,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 860179434...
Checkpoint 860179434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,520.71215
Policy Entropy: 3.57676
Value Function Loss: 0.09841

Mean KL Divergence: 0.02792
SB3 Clip Fraction: 0.20555
Policy Update Magnitude: 0.44675
Value Function Update Magnitude: 0.66399

Collected Steps per Second: 22,755.09418
Overall Steps per Second: 10,797.28332

Timestep Collection Time: 2.19819
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.63265

Cumulative Model Updates: 103,150
Cumulative Timesteps: 860,229,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,271.43137
Policy Entropy: 3.56864
Value Function Loss: 0.09799

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.18748
Policy Update Magnitude: 0.36970
Value Function Update Magnitude: 0.69236

Collected Steps per Second: 22,703.81622
Overall Steps per Second: 10,609.95245

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71538

Cumulative Model Updates: 103,156
Cumulative Timesteps: 860,279,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 860279484...
Checkpoint 860279484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,594.96416
Policy Entropy: 3.57393
Value Function Loss: 0.09571

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.17190
Policy Update Magnitude: 0.37493
Value Function Update Magnitude: 0.64584

Collected Steps per Second: 22,735.84140
Overall Steps per Second: 10,675.51990

Timestep Collection Time: 2.19987
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68511

Cumulative Model Updates: 103,162
Cumulative Timesteps: 860,329,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,726.64902
Policy Entropy: 3.57437
Value Function Loss: 0.09449

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.16304
Policy Update Magnitude: 0.37984
Value Function Update Magnitude: 0.67209

Collected Steps per Second: 22,850.68225
Overall Steps per Second: 10,803.01263

Timestep Collection Time: 2.18821
Timestep Consumption Time: 2.44032
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.62852

Cumulative Model Updates: 103,168
Cumulative Timesteps: 860,379,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 860379502...
Checkpoint 860379502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,853.95068
Policy Entropy: 3.58587
Value Function Loss: 0.09405

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.69813

Collected Steps per Second: 22,627.08009
Overall Steps per Second: 10,611.10080

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.71374

Cumulative Model Updates: 103,174
Cumulative Timesteps: 860,429,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,160.35906
Policy Entropy: 3.57156
Value Function Loss: 0.09375

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.68060
Value Function Update Magnitude: 0.69245

Collected Steps per Second: 22,593.13240
Overall Steps per Second: 10,790.59180

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63385

Cumulative Model Updates: 103,180
Cumulative Timesteps: 860,479,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 860479522...
Checkpoint 860479522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.83569
Policy Entropy: 3.56486
Value Function Loss: 0.09795

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.17909
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.64317

Collected Steps per Second: 22,749.90630
Overall Steps per Second: 10,750.89294

Timestep Collection Time: 2.19816
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.65152

Cumulative Model Updates: 103,186
Cumulative Timesteps: 860,529,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,092.16406
Policy Entropy: 3.56642
Value Function Loss: 0.09671

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.45297
Value Function Update Magnitude: 0.64529

Collected Steps per Second: 22,221.32462
Overall Steps per Second: 10,520.03755

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.50314
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.75360

Cumulative Model Updates: 103,192
Cumulative Timesteps: 860,579,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 860579538...
Checkpoint 860579538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.86089
Policy Entropy: 3.57375
Value Function Loss: 0.09458

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.46040
Value Function Update Magnitude: 0.62232

Collected Steps per Second: 22,446.46852
Overall Steps per Second: 10,586.01285

Timestep Collection Time: 2.22841
Timestep Consumption Time: 2.49669
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.72510

Cumulative Model Updates: 103,198
Cumulative Timesteps: 860,629,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,856.34239
Policy Entropy: 3.58251
Value Function Loss: 0.08986

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.44649
Value Function Update Magnitude: 0.69374

Collected Steps per Second: 22,133.12654
Overall Steps per Second: 10,447.76469

Timestep Collection Time: 2.25942
Timestep Consumption Time: 2.52706
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.78648

Cumulative Model Updates: 103,204
Cumulative Timesteps: 860,679,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 860679566...
Checkpoint 860679566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,566.76863
Policy Entropy: 3.58068
Value Function Loss: 0.08995

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.45589
Value Function Update Magnitude: 0.74052

Collected Steps per Second: 22,163.22290
Overall Steps per Second: 10,693.45252

Timestep Collection Time: 2.25671
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.67725

Cumulative Model Updates: 103,210
Cumulative Timesteps: 860,729,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,060.69290
Policy Entropy: 3.58104
Value Function Loss: 0.08829

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.44276
Value Function Update Magnitude: 0.73859

Collected Steps per Second: 22,827.97474
Overall Steps per Second: 10,772.96625

Timestep Collection Time: 2.19143
Timestep Consumption Time: 2.45223
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.64366

Cumulative Model Updates: 103,216
Cumulative Timesteps: 860,779,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 860779608...
Checkpoint 860779608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,609.08122
Policy Entropy: 3.56938
Value Function Loss: 0.09079

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.42933
Value Function Update Magnitude: 0.69514

Collected Steps per Second: 22,733.92264
Overall Steps per Second: 10,733.73352

Timestep Collection Time: 2.19962
Timestep Consumption Time: 2.45915
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.65877

Cumulative Model Updates: 103,222
Cumulative Timesteps: 860,829,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,234.71811
Policy Entropy: 3.58138
Value Function Loss: 0.09009

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.45792
Value Function Update Magnitude: 0.68279

Collected Steps per Second: 22,707.51677
Overall Steps per Second: 10,786.33299

Timestep Collection Time: 2.20244
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.63661

Cumulative Model Updates: 103,228
Cumulative Timesteps: 860,879,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 860879626...
Checkpoint 860879626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,985.28483
Policy Entropy: 3.58243
Value Function Loss: 0.09451

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.51242
Value Function Update Magnitude: 0.69095

Collected Steps per Second: 22,602.20597
Overall Steps per Second: 10,740.55398

Timestep Collection Time: 2.21253
Timestep Consumption Time: 2.44347
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.65600

Cumulative Model Updates: 103,234
Cumulative Timesteps: 860,929,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,626.59139
Policy Entropy: 3.59762
Value Function Loss: 0.09386

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.49250
Value Function Update Magnitude: 0.65424

Collected Steps per Second: 23,171.44344
Overall Steps per Second: 10,902.87567

Timestep Collection Time: 2.15878
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.58796

Cumulative Model Updates: 103,240
Cumulative Timesteps: 860,979,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 860979656...
Checkpoint 860979656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,170.34072
Policy Entropy: 3.58046
Value Function Loss: 0.09420

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.46357
Value Function Update Magnitude: 0.63587

Collected Steps per Second: 22,918.90880
Overall Steps per Second: 10,701.74025

Timestep Collection Time: 2.18291
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.67494

Cumulative Model Updates: 103,246
Cumulative Timesteps: 861,029,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,489.11040
Policy Entropy: 3.59511
Value Function Loss: 0.09174

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.45326
Value Function Update Magnitude: 0.66979

Collected Steps per Second: 22,868.88701
Overall Steps per Second: 10,799.29954

Timestep Collection Time: 2.18681
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.63086

Cumulative Model Updates: 103,252
Cumulative Timesteps: 861,079,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 861079696...
Checkpoint 861079696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,001.45021
Policy Entropy: 3.58069
Value Function Loss: 0.09384

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.68397

Collected Steps per Second: 22,338.24970
Overall Steps per Second: 10,740.44351

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.41747
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.65623

Cumulative Model Updates: 103,258
Cumulative Timesteps: 861,129,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,647.99562
Policy Entropy: 3.59604
Value Function Loss: 0.09259

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.67050

Collected Steps per Second: 22,756.42898
Overall Steps per Second: 10,817.57891

Timestep Collection Time: 2.19850
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.62488

Cumulative Model Updates: 103,264
Cumulative Timesteps: 861,179,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 861179736...
Checkpoint 861179736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,048.85746
Policy Entropy: 3.58754
Value Function Loss: 0.09284

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.47844
Value Function Update Magnitude: 0.66124

Collected Steps per Second: 21,729.10896
Overall Steps per Second: 10,675.24990

Timestep Collection Time: 2.30180
Timestep Consumption Time: 2.38343
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.68523

Cumulative Model Updates: 103,270
Cumulative Timesteps: 861,229,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,184.72178
Policy Entropy: 3.60844
Value Function Loss: 0.09097

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.49312
Value Function Update Magnitude: 0.69660

Collected Steps per Second: 22,187.37715
Overall Steps per Second: 10,825.82610

Timestep Collection Time: 2.25462
Timestep Consumption Time: 2.36619
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62080

Cumulative Model Updates: 103,276
Cumulative Timesteps: 861,279,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 861279776...
Checkpoint 861279776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,148.86362
Policy Entropy: 3.58623
Value Function Loss: 0.09374

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.49046
Value Function Update Magnitude: 0.68903

Collected Steps per Second: 22,093.50324
Overall Steps per Second: 10,764.37665

Timestep Collection Time: 2.26338
Timestep Consumption Time: 2.38213
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.64551

Cumulative Model Updates: 103,282
Cumulative Timesteps: 861,329,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,592.88767
Policy Entropy: 3.57287
Value Function Loss: 0.09386

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.48288
Value Function Update Magnitude: 0.69514

Collected Steps per Second: 22,139.02760
Overall Steps per Second: 10,857.05025

Timestep Collection Time: 2.25891
Timestep Consumption Time: 2.34732
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.60622

Cumulative Model Updates: 103,288
Cumulative Timesteps: 861,379,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 861379792...
Checkpoint 861379792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.28506
Policy Entropy: 3.55684
Value Function Loss: 0.09601

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.49734
Value Function Update Magnitude: 0.67727

Collected Steps per Second: 21,907.95201
Overall Steps per Second: 10,709.75379

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.38761
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.67107

Cumulative Model Updates: 103,294
Cumulative Timesteps: 861,429,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,691.71592
Policy Entropy: 3.57236
Value Function Loss: 0.09373

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.58574
Value Function Update Magnitude: 0.68675

Collected Steps per Second: 22,135.28931
Overall Steps per Second: 10,558.94647

Timestep Collection Time: 2.25947
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.73665

Cumulative Model Updates: 103,300
Cumulative Timesteps: 861,479,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 861479832...
Checkpoint 861479832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,521.23325
Policy Entropy: 3.57936
Value Function Loss: 0.09392

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.64779
Value Function Update Magnitude: 0.72916

Collected Steps per Second: 22,406.05877
Overall Steps per Second: 10,653.17506

Timestep Collection Time: 2.23216
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.69475

Cumulative Model Updates: 103,306
Cumulative Timesteps: 861,529,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,681.44268
Policy Entropy: 3.57638
Value Function Loss: 0.09563

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.64654
Value Function Update Magnitude: 0.80034

Collected Steps per Second: 22,833.03961
Overall Steps per Second: 10,805.68985

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.62941

Cumulative Model Updates: 103,312
Cumulative Timesteps: 861,579,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 861579870...
Checkpoint 861579870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,347.49030
Policy Entropy: 3.57702
Value Function Loss: 0.09700

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.58947
Value Function Update Magnitude: 0.72508

Collected Steps per Second: 22,330.23382
Overall Steps per Second: 10,613.75529

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.71313

Cumulative Model Updates: 103,318
Cumulative Timesteps: 861,629,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,312.58734
Policy Entropy: 3.55966
Value Function Loss: 0.10133

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.66988
Value Function Update Magnitude: 0.66702

Collected Steps per Second: 22,501.28590
Overall Steps per Second: 10,592.68382

Timestep Collection Time: 2.22334
Timestep Consumption Time: 2.49954
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.72288

Cumulative Model Updates: 103,324
Cumulative Timesteps: 861,679,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 861679922...
Checkpoint 861679922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,467.68733
Policy Entropy: 3.54822
Value Function Loss: 0.10287

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.62222
Value Function Update Magnitude: 0.64794

Collected Steps per Second: 22,430.80837
Overall Steps per Second: 10,566.99633

Timestep Collection Time: 2.23015
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.73398

Cumulative Model Updates: 103,330
Cumulative Timesteps: 861,729,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.06359
Policy Entropy: 3.53619
Value Function Loss: 0.10383

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.60824

Collected Steps per Second: 22,970.84689
Overall Steps per Second: 10,794.38719

Timestep Collection Time: 2.17676
Timestep Consumption Time: 2.45546
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.63222

Cumulative Model Updates: 103,336
Cumulative Timesteps: 861,779,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 861779948...
Checkpoint 861779948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,676.43748
Policy Entropy: 3.53226
Value Function Loss: 0.10170

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.51887
Value Function Update Magnitude: 0.59653

Collected Steps per Second: 21,837.54584
Overall Steps per Second: 10,616.96170

Timestep Collection Time: 2.29073
Timestep Consumption Time: 2.42097
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.71171

Cumulative Model Updates: 103,342
Cumulative Timesteps: 861,829,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,146.52910
Policy Entropy: 3.55040
Value Function Loss: 0.09864

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.59899
Value Function Update Magnitude: 0.62695

Collected Steps per Second: 22,535.45786
Overall Steps per Second: 10,524.34227

Timestep Collection Time: 2.22068
Timestep Consumption Time: 2.53439
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.75507

Cumulative Model Updates: 103,348
Cumulative Timesteps: 861,880,016

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 861880016...
Checkpoint 861880016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,040.74327
Policy Entropy: 3.55303
Value Function Loss: 0.10041

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.67236
Value Function Update Magnitude: 0.63911

Collected Steps per Second: 22,349.22479
Overall Steps per Second: 10,653.50026

Timestep Collection Time: 2.23927
Timestep Consumption Time: 2.45834
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.69761

Cumulative Model Updates: 103,354
Cumulative Timesteps: 861,930,062

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,873.15112
Policy Entropy: 3.57122
Value Function Loss: 0.09818

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.69757

Collected Steps per Second: 22,718.01175
Overall Steps per Second: 10,616.43834

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.71005

Cumulative Model Updates: 103,360
Cumulative Timesteps: 861,980,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 861980066...
Checkpoint 861980066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,472.25509
Policy Entropy: 3.57058
Value Function Loss: 0.09577

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.50712
Value Function Update Magnitude: 0.67360

Collected Steps per Second: 23,018.61395
Overall Steps per Second: 10,873.11113

Timestep Collection Time: 2.17224
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59868

Cumulative Model Updates: 103,366
Cumulative Timesteps: 862,030,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.31916
Policy Entropy: 3.56738
Value Function Loss: 0.09377

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.49953
Value Function Update Magnitude: 0.70424

Collected Steps per Second: 22,504.63140
Overall Steps per Second: 10,567.05920

Timestep Collection Time: 2.22265
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.73358

Cumulative Model Updates: 103,372
Cumulative Timesteps: 862,080,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 862080088...
Checkpoint 862080088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,494.42145
Policy Entropy: 3.55875
Value Function Loss: 0.09524

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.51701
Value Function Update Magnitude: 0.65943

Collected Steps per Second: 23,151.14528
Overall Steps per Second: 10,925.52639

Timestep Collection Time: 2.16102
Timestep Consumption Time: 2.41817
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.57918

Cumulative Model Updates: 103,378
Cumulative Timesteps: 862,130,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,616.05177
Policy Entropy: 3.55389
Value Function Loss: 0.09385

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.17927
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.65686

Collected Steps per Second: 22,510.23054
Overall Steps per Second: 10,549.10196

Timestep Collection Time: 2.22166
Timestep Consumption Time: 2.51903
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.74069

Cumulative Model Updates: 103,384
Cumulative Timesteps: 862,180,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 862180128...
Checkpoint 862180128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,920.49247
Policy Entropy: 3.53913
Value Function Loss: 0.09432

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.21222
Policy Update Magnitude: 0.41921
Value Function Update Magnitude: 0.66444

Collected Steps per Second: 23,030.38233
Overall Steps per Second: 10,722.23212

Timestep Collection Time: 2.17217
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.66563

Cumulative Model Updates: 103,390
Cumulative Timesteps: 862,230,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,725.17195
Policy Entropy: 3.55837
Value Function Loss: 0.09349

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.19433
Policy Update Magnitude: 0.36070
Value Function Update Magnitude: 0.70170

Collected Steps per Second: 22,867.95766
Overall Steps per Second: 10,800.47220

Timestep Collection Time: 2.18769
Timestep Consumption Time: 2.44433
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.63202

Cumulative Model Updates: 103,396
Cumulative Timesteps: 862,280,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 862280182...
Checkpoint 862280182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.53152
Policy Entropy: 3.54971
Value Function Loss: 0.09383

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.17568
Policy Update Magnitude: 0.37000
Value Function Update Magnitude: 0.73549

Collected Steps per Second: 22,269.06173
Overall Steps per Second: 10,672.93174

Timestep Collection Time: 2.24715
Timestep Consumption Time: 2.44153
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.68868

Cumulative Model Updates: 103,402
Cumulative Timesteps: 862,330,224

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,157.97391
Policy Entropy: 3.56454
Value Function Loss: 0.09210

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.36661
Value Function Update Magnitude: 0.75161

Collected Steps per Second: 22,369.53179
Overall Steps per Second: 10,571.46928

Timestep Collection Time: 2.23608
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.73160

Cumulative Model Updates: 103,408
Cumulative Timesteps: 862,380,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 862380244...
Checkpoint 862380244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,467.77003
Policy Entropy: 3.57061
Value Function Loss: 0.08746

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.39221
Value Function Update Magnitude: 0.81172

Collected Steps per Second: 22,346.50352
Overall Steps per Second: 10,540.70219

Timestep Collection Time: 2.23793
Timestep Consumption Time: 2.50653
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.74447

Cumulative Model Updates: 103,414
Cumulative Timesteps: 862,430,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,124.98856
Policy Entropy: 3.59472
Value Function Loss: 0.08606

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.16012
Policy Update Magnitude: 0.46120
Value Function Update Magnitude: 0.76580

Collected Steps per Second: 22,192.17925
Overall Steps per Second: 10,474.69258

Timestep Collection Time: 2.25359
Timestep Consumption Time: 2.52097
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.77456

Cumulative Model Updates: 103,420
Cumulative Timesteps: 862,480,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 862480266...
Checkpoint 862480266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.38767
Policy Entropy: 3.59019
Value Function Loss: 0.08533

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.40747
Value Function Update Magnitude: 0.72898

Collected Steps per Second: 22,248.20080
Overall Steps per Second: 10,616.03797

Timestep Collection Time: 2.24809
Timestep Consumption Time: 2.46327
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.71136

Cumulative Model Updates: 103,426
Cumulative Timesteps: 862,530,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.97242
Policy Entropy: 3.58848
Value Function Loss: 0.08644

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.16371
Policy Update Magnitude: 0.45553
Value Function Update Magnitude: 0.75062

Collected Steps per Second: 23,123.62114
Overall Steps per Second: 10,817.96062

Timestep Collection Time: 2.16324
Timestep Consumption Time: 2.46073
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62398

Cumulative Model Updates: 103,432
Cumulative Timesteps: 862,580,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 862580304...
Checkpoint 862580304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,522.64465
Policy Entropy: 3.59781
Value Function Loss: 0.08033

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.40187
Value Function Update Magnitude: 0.83348

Collected Steps per Second: 23,096.25636
Overall Steps per Second: 10,778.61794

Timestep Collection Time: 2.16494
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.63900

Cumulative Model Updates: 103,438
Cumulative Timesteps: 862,630,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.92327
Policy Entropy: 3.60451
Value Function Loss: 0.07442

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.43990
Value Function Update Magnitude: 0.88193

Collected Steps per Second: 23,074.11200
Overall Steps per Second: 10,875.99249

Timestep Collection Time: 2.16780
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.59912

Cumulative Model Updates: 103,444
Cumulative Timesteps: 862,680,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 862680326...
Checkpoint 862680326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.66617
Policy Entropy: 3.60784
Value Function Loss: 0.07457

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.51143
Value Function Update Magnitude: 0.74537

Collected Steps per Second: 22,722.79530
Overall Steps per Second: 10,716.08456

Timestep Collection Time: 2.20043
Timestep Consumption Time: 2.46545
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.66588

Cumulative Model Updates: 103,450
Cumulative Timesteps: 862,730,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,789.86826
Policy Entropy: 3.58303
Value Function Loss: 0.07776

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.50984
Value Function Update Magnitude: 0.69781

Collected Steps per Second: 23,108.43037
Overall Steps per Second: 10,800.37377

Timestep Collection Time: 2.16458
Timestep Consumption Time: 2.46674
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.63132

Cumulative Model Updates: 103,456
Cumulative Timesteps: 862,780,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 862780346...
Checkpoint 862780346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,829.74052
Policy Entropy: 3.58418
Value Function Loss: 0.08154

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.46831
Value Function Update Magnitude: 0.69120

Collected Steps per Second: 22,593.60017
Overall Steps per Second: 10,626.11454

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.70577

Cumulative Model Updates: 103,462
Cumulative Timesteps: 862,830,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,244.41948
Policy Entropy: 3.58252
Value Function Loss: 0.07994

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.46843
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 22,442.39361
Overall Steps per Second: 10,665.95700

Timestep Collection Time: 2.22873
Timestep Consumption Time: 2.46077
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.68950

Cumulative Model Updates: 103,468
Cumulative Timesteps: 862,880,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 862880368...
Checkpoint 862880368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,126.72273
Policy Entropy: 3.60330
Value Function Loss: 0.07654

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.53653
Value Function Update Magnitude: 0.53044

Collected Steps per Second: 22,374.15299
Overall Steps per Second: 10,592.42228

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.48623
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72149

Cumulative Model Updates: 103,474
Cumulative Timesteps: 862,930,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,704.48267
Policy Entropy: 3.60562
Value Function Loss: 0.07604

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.63301
Value Function Update Magnitude: 0.54981

Collected Steps per Second: 22,502.40448
Overall Steps per Second: 10,761.88955

Timestep Collection Time: 2.22314
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.64844

Cumulative Model Updates: 103,480
Cumulative Timesteps: 862,980,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 862980406...
Checkpoint 862980406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,250.09828
Policy Entropy: 3.61042
Value Function Loss: 0.07539

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.55059

Collected Steps per Second: 22,375.32682
Overall Steps per Second: 10,639.84302

Timestep Collection Time: 2.23478
Timestep Consumption Time: 2.46491
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.69969

Cumulative Model Updates: 103,486
Cumulative Timesteps: 863,030,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,995.16829
Policy Entropy: 3.61221
Value Function Loss: 0.07283

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.56452
Value Function Update Magnitude: 0.53694

Collected Steps per Second: 22,595.18378
Overall Steps per Second: 10,772.41995

Timestep Collection Time: 2.21313
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.64204

Cumulative Model Updates: 103,492
Cumulative Timesteps: 863,080,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 863080416...
Checkpoint 863080416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,837.29595
Policy Entropy: 3.61215
Value Function Loss: 0.06970

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07175
Policy Update Magnitude: 0.66589
Value Function Update Magnitude: 0.59974

Collected Steps per Second: 22,554.95403
Overall Steps per Second: 10,777.33593

Timestep Collection Time: 2.21805
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.64196

Cumulative Model Updates: 103,498
Cumulative Timesteps: 863,130,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,625.49771
Policy Entropy: 3.61083
Value Function Loss: 0.06721

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.68708
Value Function Update Magnitude: 0.66885

Collected Steps per Second: 23,015.56546
Overall Steps per Second: 10,850.39199

Timestep Collection Time: 2.17331
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.60997

Cumulative Model Updates: 103,504
Cumulative Timesteps: 863,180,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 863180464...
Checkpoint 863180464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,361.18766
Policy Entropy: 3.61351
Value Function Loss: 0.07072

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.61741
Value Function Update Magnitude: 0.69916

Collected Steps per Second: 22,925.80328
Overall Steps per Second: 10,648.09577

Timestep Collection Time: 2.18104
Timestep Consumption Time: 2.51483
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.69586

Cumulative Model Updates: 103,510
Cumulative Timesteps: 863,230,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,169.23568
Policy Entropy: 3.62049
Value Function Loss: 0.06869

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.53647
Value Function Update Magnitude: 0.72111

Collected Steps per Second: 22,861.93233
Overall Steps per Second: 10,833.54012

Timestep Collection Time: 2.18765
Timestep Consumption Time: 2.42893
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.61659

Cumulative Model Updates: 103,516
Cumulative Timesteps: 863,280,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 863280480...
Checkpoint 863280480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,459.57879
Policy Entropy: 3.61612
Value Function Loss: 0.07226

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.61153
Value Function Update Magnitude: 0.68265

Collected Steps per Second: 22,757.60026
Overall Steps per Second: 10,718.22775

Timestep Collection Time: 2.19812
Timestep Consumption Time: 2.46907
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.66719

Cumulative Model Updates: 103,522
Cumulative Timesteps: 863,330,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,107.21160
Policy Entropy: 3.62825
Value Function Loss: 0.07281

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.63746
Value Function Update Magnitude: 0.67054

Collected Steps per Second: 22,553.71684
Overall Steps per Second: 10,634.12024

Timestep Collection Time: 2.21728
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.70260

Cumulative Model Updates: 103,528
Cumulative Timesteps: 863,380,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 863380512...
Checkpoint 863380512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,416.39367
Policy Entropy: 3.62748
Value Function Loss: 0.07632

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.57198
Value Function Update Magnitude: 0.68362

Collected Steps per Second: 22,416.12419
Overall Steps per Second: 10,593.89686

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.72102

Cumulative Model Updates: 103,534
Cumulative Timesteps: 863,430,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,214.31913
Policy Entropy: 3.62456
Value Function Loss: 0.07826

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.56999
Value Function Update Magnitude: 0.70684

Collected Steps per Second: 22,671.84553
Overall Steps per Second: 10,761.92093

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.44083
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.64638

Cumulative Model Updates: 103,540
Cumulative Timesteps: 863,480,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 863480530...
Checkpoint 863480530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,054.28811
Policy Entropy: 3.61523
Value Function Loss: 0.07580

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.72397

Collected Steps per Second: 22,212.58427
Overall Steps per Second: 10,643.24761

Timestep Collection Time: 2.25152
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.69894

Cumulative Model Updates: 103,546
Cumulative Timesteps: 863,530,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,306.81057
Policy Entropy: 3.61362
Value Function Loss: 0.07792

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.49237
Value Function Update Magnitude: 0.71505

Collected Steps per Second: 22,990.50129
Overall Steps per Second: 10,707.32256

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.49639
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.67250

Cumulative Model Updates: 103,552
Cumulative Timesteps: 863,580,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 863580572...
Checkpoint 863580572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,762.43174
Policy Entropy: 3.62276
Value Function Loss: 0.07672

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.49855
Value Function Update Magnitude: 0.72938

Collected Steps per Second: 22,850.60445
Overall Steps per Second: 10,841.40104

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.61398

Cumulative Model Updates: 103,558
Cumulative Timesteps: 863,630,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,997.10214
Policy Entropy: 3.62453
Value Function Loss: 0.07754

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.51245
Value Function Update Magnitude: 0.74782

Collected Steps per Second: 23,048.43867
Overall Steps per Second: 10,844.64751

Timestep Collection Time: 2.17047
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.61297

Cumulative Model Updates: 103,564
Cumulative Timesteps: 863,680,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 863680620...
Checkpoint 863680620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.28876
Policy Entropy: 3.62668
Value Function Loss: 0.07537

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.53848
Value Function Update Magnitude: 0.77353

Collected Steps per Second: 22,381.72392
Overall Steps per Second: 10,647.06617

Timestep Collection Time: 2.23405
Timestep Consumption Time: 2.46226
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.69632

Cumulative Model Updates: 103,570
Cumulative Timesteps: 863,730,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,915.98506
Policy Entropy: 3.62405
Value Function Loss: 0.07446

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.51307
Value Function Update Magnitude: 0.77321

Collected Steps per Second: 22,429.14932
Overall Steps per Second: 10,551.55230

Timestep Collection Time: 2.23049
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.74129

Cumulative Model Updates: 103,576
Cumulative Timesteps: 863,780,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 863780650...
Checkpoint 863780650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,171.01815
Policy Entropy: 3.60580
Value Function Loss: 0.07655

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.63500
Value Function Update Magnitude: 0.72495

Collected Steps per Second: 22,163.88392
Overall Steps per Second: 10,698.02609

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.41784
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.67376

Cumulative Model Updates: 103,582
Cumulative Timesteps: 863,830,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.32596
Policy Entropy: 3.60371
Value Function Loss: 0.07714

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.73066
Value Function Update Magnitude: 0.78340

Collected Steps per Second: 22,327.16670
Overall Steps per Second: 10,583.16946

Timestep Collection Time: 2.23987
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.72543

Cumulative Model Updates: 103,588
Cumulative Timesteps: 863,880,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 863880660...
Checkpoint 863880660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,320.10100
Policy Entropy: 3.60947
Value Function Loss: 0.07929

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.61018
Value Function Update Magnitude: 0.75509

Collected Steps per Second: 22,280.87617
Overall Steps per Second: 10,597.34176

Timestep Collection Time: 2.24462
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.71930

Cumulative Model Updates: 103,594
Cumulative Timesteps: 863,930,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,166.74646
Policy Entropy: 3.61267
Value Function Loss: 0.08115

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.54470
Value Function Update Magnitude: 0.79759

Collected Steps per Second: 22,513.39279
Overall Steps per Second: 10,776.04948

Timestep Collection Time: 2.22099
Timestep Consumption Time: 2.41912
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.64010

Cumulative Model Updates: 103,600
Cumulative Timesteps: 863,980,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 863980674...
Checkpoint 863980674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,731.17338
Policy Entropy: 3.60941
Value Function Loss: 0.08347

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.50783
Value Function Update Magnitude: 0.78979

Collected Steps per Second: 22,141.23092
Overall Steps per Second: 10,604.89232

Timestep Collection Time: 2.25895
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.71631

Cumulative Model Updates: 103,606
Cumulative Timesteps: 864,030,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,293.82229
Policy Entropy: 3.59966
Value Function Loss: 0.08160

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06975
Policy Update Magnitude: 0.64876
Value Function Update Magnitude: 0.85963

Collected Steps per Second: 22,419.95564
Overall Steps per Second: 10,439.73468

Timestep Collection Time: 2.23069
Timestep Consumption Time: 2.55985
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.79054

Cumulative Model Updates: 103,612
Cumulative Timesteps: 864,080,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 864080702...
Checkpoint 864080702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.92203
Policy Entropy: 3.59766
Value Function Loss: 0.08031

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.70627
Value Function Update Magnitude: 0.85349

Collected Steps per Second: 22,816.42271
Overall Steps per Second: 10,644.61330

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.50581
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.69721

Cumulative Model Updates: 103,618
Cumulative Timesteps: 864,130,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,276.33188
Policy Entropy: 3.60581
Value Function Loss: 0.07776

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.60846
Value Function Update Magnitude: 0.80016

Collected Steps per Second: 22,880.65309
Overall Steps per Second: 10,840.48454

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61400

Cumulative Model Updates: 103,624
Cumulative Timesteps: 864,180,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 864180720...
Checkpoint 864180720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,515.86225
Policy Entropy: 3.59272
Value Function Loss: 0.07795

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.55607
Value Function Update Magnitude: 0.74020

Collected Steps per Second: 22,798.65010
Overall Steps per Second: 10,712.45425

Timestep Collection Time: 2.19346
Timestep Consumption Time: 2.47475
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.66821

Cumulative Model Updates: 103,630
Cumulative Timesteps: 864,230,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,726.27756
Policy Entropy: 3.60617
Value Function Loss: 0.07742

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.69354

Collected Steps per Second: 22,841.71406
Overall Steps per Second: 10,812.86240

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62449

Cumulative Model Updates: 103,636
Cumulative Timesteps: 864,280,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 864280732...
Checkpoint 864280732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,916.67527
Policy Entropy: 3.59984
Value Function Loss: 0.07811

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.56057
Value Function Update Magnitude: 0.78227

Collected Steps per Second: 22,682.95793
Overall Steps per Second: 10,706.87166

Timestep Collection Time: 2.20509
Timestep Consumption Time: 2.46649
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.67158

Cumulative Model Updates: 103,642
Cumulative Timesteps: 864,330,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,229.76594
Policy Entropy: 3.61033
Value Function Loss: 0.07778

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.57456
Value Function Update Magnitude: 0.88567

Collected Steps per Second: 23,016.54727
Overall Steps per Second: 10,851.39496

Timestep Collection Time: 2.17313
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.60936

Cumulative Model Updates: 103,648
Cumulative Timesteps: 864,380,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 864380768...
Checkpoint 864380768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,406.63451
Policy Entropy: 3.61518
Value Function Loss: 0.07958

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.82702

Collected Steps per Second: 21,550.48465
Overall Steps per Second: 10,684.59656

Timestep Collection Time: 2.32125
Timestep Consumption Time: 2.36063
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.68188

Cumulative Model Updates: 103,654
Cumulative Timesteps: 864,430,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.15626
Policy Entropy: 3.62413
Value Function Loss: 0.08154

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.76745

Collected Steps per Second: 21,717.29332
Overall Steps per Second: 10,580.41678

Timestep Collection Time: 2.30342
Timestep Consumption Time: 2.42456
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.72798

Cumulative Model Updates: 103,660
Cumulative Timesteps: 864,480,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 864480816...
Checkpoint 864480816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,108.15435
Policy Entropy: 3.61178
Value Function Loss: 0.08127

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.79498

Collected Steps per Second: 21,608.05967
Overall Steps per Second: 10,530.34044

Timestep Collection Time: 2.31506
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.75046

Cumulative Model Updates: 103,666
Cumulative Timesteps: 864,530,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,409.50866
Policy Entropy: 3.60793
Value Function Loss: 0.08206

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.60963
Value Function Update Magnitude: 0.84882

Collected Steps per Second: 21,989.14825
Overall Steps per Second: 10,721.16814

Timestep Collection Time: 2.27558
Timestep Consumption Time: 2.39164
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.66722

Cumulative Model Updates: 103,672
Cumulative Timesteps: 864,580,878

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 864580878...
Checkpoint 864580878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,939.01380
Policy Entropy: 3.59216
Value Function Loss: 0.08118

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.54445
Value Function Update Magnitude: 0.89976

Collected Steps per Second: 21,566.90131
Overall Steps per Second: 10,545.35559

Timestep Collection Time: 2.31902
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.74275

Cumulative Model Updates: 103,678
Cumulative Timesteps: 864,630,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.34523
Policy Entropy: 3.58447
Value Function Loss: 0.08038

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.58553
Value Function Update Magnitude: 0.88519

Collected Steps per Second: 22,413.60045
Overall Steps per Second: 10,735.26589

Timestep Collection Time: 2.23106
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.65811

Cumulative Model Updates: 103,684
Cumulative Timesteps: 864,680,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 864680898...
Checkpoint 864680898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,816.75554
Policy Entropy: 3.58605
Value Function Loss: 0.07768

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.92093

Collected Steps per Second: 21,832.02344
Overall Steps per Second: 10,617.30940

Timestep Collection Time: 2.29195
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.71287

Cumulative Model Updates: 103,690
Cumulative Timesteps: 864,730,936

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,978.51516
Policy Entropy: 3.58908
Value Function Loss: 0.07798

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.92103

Collected Steps per Second: 22,376.72970
Overall Steps per Second: 10,908.31109

Timestep Collection Time: 2.23545
Timestep Consumption Time: 2.35023
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.58568

Cumulative Model Updates: 103,696
Cumulative Timesteps: 864,780,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 864780958...
Checkpoint 864780958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,898.84781
Policy Entropy: 3.59619
Value Function Loss: 0.07930

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.88704

Collected Steps per Second: 22,265.05551
Overall Steps per Second: 10,707.12714

Timestep Collection Time: 2.24576
Timestep Consumption Time: 2.42421
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.66997

Cumulative Model Updates: 103,702
Cumulative Timesteps: 864,830,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,873.18747
Policy Entropy: 3.60863
Value Function Loss: 0.08243

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.58672
Value Function Update Magnitude: 0.86932

Collected Steps per Second: 22,376.59674
Overall Steps per Second: 10,772.48029

Timestep Collection Time: 2.23582
Timestep Consumption Time: 2.40842
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.64424

Cumulative Model Updates: 103,708
Cumulative Timesteps: 864,880,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 864880990...
Checkpoint 864880990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,408.30817
Policy Entropy: 3.59764
Value Function Loss: 0.08512

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.59187
Value Function Update Magnitude: 0.81233

Collected Steps per Second: 22,634.90254
Overall Steps per Second: 10,737.94455

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.44770
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.65694

Cumulative Model Updates: 103,714
Cumulative Timesteps: 864,930,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,818.39737
Policy Entropy: 3.59271
Value Function Loss: 0.08677

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.60140
Value Function Update Magnitude: 0.74393

Collected Steps per Second: 22,724.85789
Overall Steps per Second: 10,871.88122

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.39898
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.59939

Cumulative Model Updates: 103,720
Cumulative Timesteps: 864,981,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 864981000...
Checkpoint 864981000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,393.44478
Policy Entropy: 3.59091
Value Function Loss: 0.08728

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.50806
Value Function Update Magnitude: 0.71801

Collected Steps per Second: 22,368.17846
Overall Steps per Second: 10,664.85688

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.45406
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.69036

Cumulative Model Updates: 103,726
Cumulative Timesteps: 865,031,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,590.90731
Policy Entropy: 3.60639
Value Function Loss: 0.08715

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.50718
Value Function Update Magnitude: 0.72785

Collected Steps per Second: 22,776.24810
Overall Steps per Second: 10,817.06175

Timestep Collection Time: 2.19544
Timestep Consumption Time: 2.42725
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62270

Cumulative Model Updates: 103,732
Cumulative Timesteps: 865,081,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 865081026...
Checkpoint 865081026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,598.45368
Policy Entropy: 3.60375
Value Function Loss: 0.08654

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.40067
Value Function Update Magnitude: 0.71785

Collected Steps per Second: 22,330.48429
Overall Steps per Second: 10,663.28417

Timestep Collection Time: 2.23936
Timestep Consumption Time: 2.45019
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.68955

Cumulative Model Updates: 103,738
Cumulative Timesteps: 865,131,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,980.29203
Policy Entropy: 3.60561
Value Function Loss: 0.08367

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.45365
Value Function Update Magnitude: 0.75692

Collected Steps per Second: 22,851.40954
Overall Steps per Second: 10,543.39760

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.55456
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74287

Cumulative Model Updates: 103,744
Cumulative Timesteps: 865,181,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 865181038...
Checkpoint 865181038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,191.44528
Policy Entropy: 3.59758
Value Function Loss: 0.08141

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.60875
Value Function Update Magnitude: 0.73456

Collected Steps per Second: 22,790.03401
Overall Steps per Second: 10,607.96114

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.52031
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.71495

Cumulative Model Updates: 103,750
Cumulative Timesteps: 865,231,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,465.39883
Policy Entropy: 3.60331
Value Function Loss: 0.07891

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.61680
Value Function Update Magnitude: 0.69668

Collected Steps per Second: 22,612.49908
Overall Steps per Second: 10,638.88461

Timestep Collection Time: 2.21196
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.70143

Cumulative Model Updates: 103,756
Cumulative Timesteps: 865,281,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 865281072...
Checkpoint 865281072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,316.75294
Policy Entropy: 3.61686
Value Function Loss: 0.07436

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.80175

Collected Steps per Second: 22,945.17854
Overall Steps per Second: 10,844.46459

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61083

Cumulative Model Updates: 103,762
Cumulative Timesteps: 865,331,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,665.86158
Policy Entropy: 3.64245
Value Function Loss: 0.07248

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.59383
Value Function Update Magnitude: 0.88173

Collected Steps per Second: 22,855.38777
Overall Steps per Second: 10,681.86830

Timestep Collection Time: 2.18793
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.68139

Cumulative Model Updates: 103,768
Cumulative Timesteps: 865,381,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 865381080...
Checkpoint 865381080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,797.06368
Policy Entropy: 3.64485
Value Function Loss: 0.07297

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.87401

Collected Steps per Second: 22,891.99940
Overall Steps per Second: 10,924.92395

Timestep Collection Time: 2.18443
Timestep Consumption Time: 2.39281
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.57724

Cumulative Model Updates: 103,774
Cumulative Timesteps: 865,431,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.31010
Policy Entropy: 3.63534
Value Function Loss: 0.07770

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.55788
Value Function Update Magnitude: 0.74363

Collected Steps per Second: 22,403.33511
Overall Steps per Second: 10,611.50551

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.48065
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71300

Cumulative Model Updates: 103,780
Cumulative Timesteps: 865,481,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 865481098...
Checkpoint 865481098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,696.68688
Policy Entropy: 3.61646
Value Function Loss: 0.08295

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.63023
Value Function Update Magnitude: 0.66006

Collected Steps per Second: 22,506.92684
Overall Steps per Second: 10,589.42623

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.72660

Cumulative Model Updates: 103,786
Cumulative Timesteps: 865,531,150

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,833.31927
Policy Entropy: 3.61236
Value Function Loss: 0.08460

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.63177
Value Function Update Magnitude: 0.67364

Collected Steps per Second: 22,239.97927
Overall Steps per Second: 10,550.63847

Timestep Collection Time: 2.24937
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.74151

Cumulative Model Updates: 103,792
Cumulative Timesteps: 865,581,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 865581176...
Checkpoint 865581176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,722.90437
Policy Entropy: 3.61047
Value Function Loss: 0.08790

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.64297
Value Function Update Magnitude: 0.72912

Collected Steps per Second: 22,545.62291
Overall Steps per Second: 10,582.86323

Timestep Collection Time: 2.21897
Timestep Consumption Time: 2.50830
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.72727

Cumulative Model Updates: 103,798
Cumulative Timesteps: 865,631,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,342.34983
Policy Entropy: 3.61195
Value Function Loss: 0.08632

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.59705
Value Function Update Magnitude: 0.70874

Collected Steps per Second: 22,577.83692
Overall Steps per Second: 10,515.73272

Timestep Collection Time: 2.21571
Timestep Consumption Time: 2.54154
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.75725

Cumulative Model Updates: 103,804
Cumulative Timesteps: 865,681,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 865681230...
Checkpoint 865681230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,092.59368
Policy Entropy: 3.60213
Value Function Loss: 0.08842

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.50962
Value Function Update Magnitude: 0.71324

Collected Steps per Second: 23,052.06438
Overall Steps per Second: 10,852.88271

Timestep Collection Time: 2.16996
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.60910

Cumulative Model Updates: 103,810
Cumulative Timesteps: 865,731,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,819.80904
Policy Entropy: 3.59121
Value Function Loss: 0.08640

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.50366
Value Function Update Magnitude: 0.72355

Collected Steps per Second: 22,998.27019
Overall Steps per Second: 10,721.88389

Timestep Collection Time: 2.17538
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.66616

Cumulative Model Updates: 103,816
Cumulative Timesteps: 865,781,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 865781282...
Checkpoint 865781282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,897.25223
Policy Entropy: 3.58861
Value Function Loss: 0.08421

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.48880
Value Function Update Magnitude: 0.76756

Collected Steps per Second: 22,951.75648
Overall Steps per Second: 10,846.02485

Timestep Collection Time: 2.17935
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.61183

Cumulative Model Updates: 103,822
Cumulative Timesteps: 865,831,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,289.77146
Policy Entropy: 3.59913
Value Function Loss: 0.08049

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.58169
Value Function Update Magnitude: 0.81308

Collected Steps per Second: 23,064.59655
Overall Steps per Second: 10,875.30577

Timestep Collection Time: 2.16843
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.59886

Cumulative Model Updates: 103,828
Cumulative Timesteps: 865,881,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 865881316...
Checkpoint 865881316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,949.48008
Policy Entropy: 3.60582
Value Function Loss: 0.07767

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.88039

Collected Steps per Second: 22,837.54434
Overall Steps per Second: 10,779.06779

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.64048

Cumulative Model Updates: 103,834
Cumulative Timesteps: 865,931,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,550.75845
Policy Entropy: 3.61633
Value Function Loss: 0.07742

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.84560

Collected Steps per Second: 22,398.21767
Overall Steps per Second: 10,627.46647

Timestep Collection Time: 2.23330
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.70686

Cumulative Model Updates: 103,840
Cumulative Timesteps: 865,981,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 865981358...
Checkpoint 865981358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,871.48957
Policy Entropy: 3.62630
Value Function Loss: 0.07915

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.53370
Value Function Update Magnitude: 0.81052

Collected Steps per Second: 22,498.05119
Overall Steps per Second: 10,811.68519

Timestep Collection Time: 2.22277
Timestep Consumption Time: 2.40260
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.62537

Cumulative Model Updates: 103,846
Cumulative Timesteps: 866,031,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,792.10999
Policy Entropy: 3.64467
Value Function Loss: 0.07781

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.58340
Value Function Update Magnitude: 0.84602

Collected Steps per Second: 22,543.89241
Overall Steps per Second: 10,772.16161

Timestep Collection Time: 2.21896
Timestep Consumption Time: 2.42486
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.64382

Cumulative Model Updates: 103,852
Cumulative Timesteps: 866,081,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 866081390...
Checkpoint 866081390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.47215
Policy Entropy: 3.64135
Value Function Loss: 0.07732

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.57660
Value Function Update Magnitude: 0.81970

Collected Steps per Second: 22,213.28656
Overall Steps per Second: 10,680.29210

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.68152

Cumulative Model Updates: 103,858
Cumulative Timesteps: 866,131,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,903.55605
Policy Entropy: 3.64330
Value Function Loss: 0.07976

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.77540

Collected Steps per Second: 23,394.80754
Overall Steps per Second: 10,887.92585

Timestep Collection Time: 2.13791
Timestep Consumption Time: 2.45580
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.59371

Cumulative Model Updates: 103,864
Cumulative Timesteps: 866,181,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 866181406...
Checkpoint 866181406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,878.31673
Policy Entropy: 3.62996
Value Function Loss: 0.08061

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.58514
Value Function Update Magnitude: 0.84186

Collected Steps per Second: 22,075.11658
Overall Steps per Second: 10,665.83716

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68843

Cumulative Model Updates: 103,870
Cumulative Timesteps: 866,231,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,420.56730
Policy Entropy: 3.62370
Value Function Loss: 0.07925

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.64020
Value Function Update Magnitude: 0.90423

Collected Steps per Second: 21,818.70189
Overall Steps per Second: 10,656.52873

Timestep Collection Time: 2.29198
Timestep Consumption Time: 2.40073
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69271

Cumulative Model Updates: 103,876
Cumulative Timesteps: 866,281,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 866281420...
Checkpoint 866281420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,326.04784
Policy Entropy: 3.62231
Value Function Loss: 0.07728

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.61922
Value Function Update Magnitude: 0.93921

Collected Steps per Second: 22,240.62269
Overall Steps per Second: 10,851.13209

Timestep Collection Time: 2.24922
Timestep Consumption Time: 2.36081
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61003

Cumulative Model Updates: 103,882
Cumulative Timesteps: 866,331,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,049.75407
Policy Entropy: 3.63674
Value Function Loss: 0.07764

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.61449
Value Function Update Magnitude: 0.97656

Collected Steps per Second: 22,331.62993
Overall Steps per Second: 10,894.33320

Timestep Collection Time: 2.23907
Timestep Consumption Time: 2.35066
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.58973

Cumulative Model Updates: 103,888
Cumulative Timesteps: 866,381,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 866381446...
Checkpoint 866381446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,210.10041
Policy Entropy: 3.64785
Value Function Loss: 0.07756

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.66351
Value Function Update Magnitude: 1.02378

Collected Steps per Second: 22,234.17898
Overall Steps per Second: 10,779.56121

Timestep Collection Time: 2.24996
Timestep Consumption Time: 2.39086
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.64082

Cumulative Model Updates: 103,894
Cumulative Timesteps: 866,431,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,511.89595
Policy Entropy: 3.64115
Value Function Loss: 0.07890

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.58657
Value Function Update Magnitude: 0.99803

Collected Steps per Second: 22,531.62673
Overall Steps per Second: 10,800.14660

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.41095
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.63049

Cumulative Model Updates: 103,900
Cumulative Timesteps: 866,481,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 866481482...
Checkpoint 866481482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,545.99502
Policy Entropy: 3.63224
Value Function Loss: 0.08277

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.55291
Value Function Update Magnitude: 0.84100

Collected Steps per Second: 22,358.54244
Overall Steps per Second: 10,631.33762

Timestep Collection Time: 2.23762
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.70590

Cumulative Model Updates: 103,906
Cumulative Timesteps: 866,531,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,022.66027
Policy Entropy: 3.62888
Value Function Loss: 0.08561

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.60079
Value Function Update Magnitude: 0.84036

Collected Steps per Second: 22,660.24438
Overall Steps per Second: 10,854.20619

Timestep Collection Time: 2.20748
Timestep Consumption Time: 2.40106
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60854

Cumulative Model Updates: 103,912
Cumulative Timesteps: 866,581,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 866581534...
Checkpoint 866581534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,757.78631
Policy Entropy: 3.63233
Value Function Loss: 0.08823

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.59451
Value Function Update Magnitude: 0.87809

Collected Steps per Second: 22,671.51487
Overall Steps per Second: 10,776.70758

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.43461
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.64038

Cumulative Model Updates: 103,918
Cumulative Timesteps: 866,631,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,266.99428
Policy Entropy: 3.63434
Value Function Loss: 0.09032

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.47624
Value Function Update Magnitude: 0.78266

Collected Steps per Second: 23,041.59569
Overall Steps per Second: 10,777.65596

Timestep Collection Time: 2.17025
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.63978

Cumulative Model Updates: 103,924
Cumulative Timesteps: 866,681,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 866681548...
Checkpoint 866681548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,226.54477
Policy Entropy: 3.63585
Value Function Loss: 0.09008

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.51591
Value Function Update Magnitude: 0.76010

Collected Steps per Second: 22,781.52352
Overall Steps per Second: 10,710.91623

Timestep Collection Time: 2.19502
Timestep Consumption Time: 2.47367
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.66869

Cumulative Model Updates: 103,930
Cumulative Timesteps: 866,731,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,916.78631
Policy Entropy: 3.62571
Value Function Loss: 0.08703

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.49858
Value Function Update Magnitude: 0.85238

Collected Steps per Second: 23,287.81722
Overall Steps per Second: 10,934.92613

Timestep Collection Time: 2.14782
Timestep Consumption Time: 2.42633
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.57415

Cumulative Model Updates: 103,936
Cumulative Timesteps: 866,781,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 866781572...
Checkpoint 866781572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,523.44739
Policy Entropy: 3.62307
Value Function Loss: 0.08212

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.89658

Collected Steps per Second: 22,685.05025
Overall Steps per Second: 10,633.76857

Timestep Collection Time: 2.20542
Timestep Consumption Time: 2.49941
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.70482

Cumulative Model Updates: 103,942
Cumulative Timesteps: 866,831,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,564.26105
Policy Entropy: 3.60789
Value Function Loss: 0.08052

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.64506
Value Function Update Magnitude: 0.81024

Collected Steps per Second: 22,725.66340
Overall Steps per Second: 10,794.79967

Timestep Collection Time: 2.20024
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63205

Cumulative Model Updates: 103,948
Cumulative Timesteps: 866,881,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 866881604...
Checkpoint 866881604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,397.12740
Policy Entropy: 3.61056
Value Function Loss: 0.08169

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.66444
Value Function Update Magnitude: 0.79396

Collected Steps per Second: 21,986.42674
Overall Steps per Second: 10,698.61654

Timestep Collection Time: 2.27422
Timestep Consumption Time: 2.39947
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.67369

Cumulative Model Updates: 103,954
Cumulative Timesteps: 866,931,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.34132
Policy Entropy: 3.61286
Value Function Loss: 0.08400

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.62740
Value Function Update Magnitude: 0.76516

Collected Steps per Second: 22,630.46944
Overall Steps per Second: 10,595.57437

Timestep Collection Time: 2.20994
Timestep Consumption Time: 2.51014
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.72008

Cumulative Model Updates: 103,960
Cumulative Timesteps: 866,981,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 866981618...
Checkpoint 866981618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,078.38741
Policy Entropy: 3.62658
Value Function Loss: 0.08361

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.66927
Value Function Update Magnitude: 0.88859

Collected Steps per Second: 22,317.35100
Overall Steps per Second: 10,631.77569

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.46267
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70326

Cumulative Model Updates: 103,966
Cumulative Timesteps: 867,031,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,094.25918
Policy Entropy: 3.62679
Value Function Loss: 0.08435

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.15844
Policy Update Magnitude: 0.64545
Value Function Update Magnitude: 0.88290

Collected Steps per Second: 22,557.82450
Overall Steps per Second: 10,742.99383

Timestep Collection Time: 2.21653
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.65420

Cumulative Model Updates: 103,972
Cumulative Timesteps: 867,081,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 867081622...
Checkpoint 867081622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,927.86514
Policy Entropy: 3.62597
Value Function Loss: 0.08711

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.47441
Value Function Update Magnitude: 0.80310

Collected Steps per Second: 22,097.93807
Overall Steps per Second: 10,325.10498

Timestep Collection Time: 2.26347
Timestep Consumption Time: 2.58084
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.84431

Cumulative Model Updates: 103,978
Cumulative Timesteps: 867,131,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,394.18108
Policy Entropy: 3.61838
Value Function Loss: 0.08752

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.47976
Value Function Update Magnitude: 0.80552

Collected Steps per Second: 23,101.40576
Overall Steps per Second: 10,777.31178

Timestep Collection Time: 2.16489
Timestep Consumption Time: 2.47560
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.64049

Cumulative Model Updates: 103,984
Cumulative Timesteps: 867,181,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 867181652...
Checkpoint 867181652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,658.26016
Policy Entropy: 3.59907
Value Function Loss: 0.08869

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.53184
Value Function Update Magnitude: 0.83120

Collected Steps per Second: 22,715.09683
Overall Steps per Second: 10,679.33317

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.48106
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.68250

Cumulative Model Updates: 103,990
Cumulative Timesteps: 867,231,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,346.15078
Policy Entropy: 3.60404
Value Function Loss: 0.08682

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.49299
Value Function Update Magnitude: 0.82544

Collected Steps per Second: 23,056.95071
Overall Steps per Second: 10,849.52807

Timestep Collection Time: 2.16880
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.60905

Cumulative Model Updates: 103,996
Cumulative Timesteps: 867,281,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 867281664...
Checkpoint 867281664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,358.19366
Policy Entropy: 3.60927
Value Function Loss: 0.09001

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.51815
Value Function Update Magnitude: 0.85864

Collected Steps per Second: 22,853.89838
Overall Steps per Second: 10,697.08382

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.67641

Cumulative Model Updates: 104,002
Cumulative Timesteps: 867,331,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,101.25550
Policy Entropy: 3.61593
Value Function Loss: 0.08897

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08621
Policy Update Magnitude: 0.59983
Value Function Update Magnitude: 0.87459

Collected Steps per Second: 23,113.84990
Overall Steps per Second: 10,910.80692

Timestep Collection Time: 2.16355
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.58335

Cumulative Model Updates: 104,008
Cumulative Timesteps: 867,381,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 867381696...
Checkpoint 867381696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,697.93348
Policy Entropy: 3.61150
Value Function Loss: 0.09149

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.83111

Collected Steps per Second: 22,752.41544
Overall Steps per Second: 10,655.73140

Timestep Collection Time: 2.19836
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.69400

Cumulative Model Updates: 104,014
Cumulative Timesteps: 867,431,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,650.82283
Policy Entropy: 3.60584
Value Function Loss: 0.09277

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.49687
Value Function Update Magnitude: 0.71633

Collected Steps per Second: 22,489.06277
Overall Steps per Second: 10,589.02348

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.49867
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72206

Cumulative Model Updates: 104,020
Cumulative Timesteps: 867,481,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 867481716...
Checkpoint 867481716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,981.74038
Policy Entropy: 3.59554
Value Function Loss: 0.09325

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.47008
Value Function Update Magnitude: 0.62279

Collected Steps per Second: 22,306.65875
Overall Steps per Second: 10,559.52452

Timestep Collection Time: 2.24184
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.73582

Cumulative Model Updates: 104,026
Cumulative Timesteps: 867,531,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,383.25862
Policy Entropy: 3.59184
Value Function Loss: 0.09212

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.62607

Collected Steps per Second: 21,661.07556
Overall Steps per Second: 10,375.00305

Timestep Collection Time: 2.30986
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.82255

Cumulative Model Updates: 104,032
Cumulative Timesteps: 867,581,758

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 867581758...
Checkpoint 867581758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,033.04172
Policy Entropy: 3.58997
Value Function Loss: 0.09031

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.66853

Collected Steps per Second: 22,045.49497
Overall Steps per Second: 10,650.87719

Timestep Collection Time: 2.26813
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.69464

Cumulative Model Updates: 104,038
Cumulative Timesteps: 867,631,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,135.92779
Policy Entropy: 3.58519
Value Function Loss: 0.09047

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.62972
Value Function Update Magnitude: 0.77998

Collected Steps per Second: 22,686.44366
Overall Steps per Second: 10,649.67625

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.49142
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.69573

Cumulative Model Updates: 104,044
Cumulative Timesteps: 867,681,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 867681768...
Checkpoint 867681768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,463.15059
Policy Entropy: 3.60248
Value Function Loss: 0.08781

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.75829

Collected Steps per Second: 22,619.56088
Overall Steps per Second: 10,566.03305

Timestep Collection Time: 2.21207
Timestep Consumption Time: 2.52348
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.73555

Cumulative Model Updates: 104,050
Cumulative Timesteps: 867,731,804

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,559.20079
Policy Entropy: 3.60512
Value Function Loss: 0.09005

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.58901
Value Function Update Magnitude: 0.67225

Collected Steps per Second: 23,126.65728
Overall Steps per Second: 10,884.59601

Timestep Collection Time: 2.16209
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.59383

Cumulative Model Updates: 104,056
Cumulative Timesteps: 867,781,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 867781806...
Checkpoint 867781806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,151.68091
Policy Entropy: 3.61430
Value Function Loss: 0.08829

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.61692
Value Function Update Magnitude: 0.69427

Collected Steps per Second: 22,643.99942
Overall Steps per Second: 10,599.76255

Timestep Collection Time: 2.20809
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71709

Cumulative Model Updates: 104,062
Cumulative Timesteps: 867,831,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,429.91466
Policy Entropy: 3.60843
Value Function Loss: 0.08882

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.58753
Value Function Update Magnitude: 0.70758

Collected Steps per Second: 23,151.04826
Overall Steps per Second: 10,854.58634

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.44769
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.60837

Cumulative Model Updates: 104,068
Cumulative Timesteps: 867,881,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 867881828...
Checkpoint 867881828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,142.47352
Policy Entropy: 3.61577
Value Function Loss: 0.08721

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.72392

Collected Steps per Second: 22,716.27272
Overall Steps per Second: 10,696.13220

Timestep Collection Time: 2.20186
Timestep Consumption Time: 2.47441
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.67627

Cumulative Model Updates: 104,074
Cumulative Timesteps: 867,931,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,291.12414
Policy Entropy: 3.61522
Value Function Loss: 0.08274

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.63597
Value Function Update Magnitude: 0.83385

Collected Steps per Second: 22,661.89111
Overall Steps per Second: 10,784.87371

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.63612

Cumulative Model Updates: 104,080
Cumulative Timesteps: 867,981,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 867981846...
Checkpoint 867981846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,304.48890
Policy Entropy: 3.61190
Value Function Loss: 0.08293

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.66188
Value Function Update Magnitude: 0.81876

Collected Steps per Second: 22,730.33202
Overall Steps per Second: 10,711.40848

Timestep Collection Time: 2.19970
Timestep Consumption Time: 2.46822
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.66792

Cumulative Model Updates: 104,086
Cumulative Timesteps: 868,031,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,162.89846
Policy Entropy: 3.60341
Value Function Loss: 0.08673

Mean KL Divergence: 0.02888
SB3 Clip Fraction: 0.20579
Policy Update Magnitude: 0.62694
Value Function Update Magnitude: 0.74051

Collected Steps per Second: 22,761.83655
Overall Steps per Second: 10,799.03954

Timestep Collection Time: 2.19745
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.63171

Cumulative Model Updates: 104,092
Cumulative Timesteps: 868,081,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 868081864...
Checkpoint 868081864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,375.89798
Policy Entropy: 3.59432
Value Function Loss: 0.08737

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.17541
Policy Update Magnitude: 0.54332
Value Function Update Magnitude: 0.79327

Collected Steps per Second: 22,084.34491
Overall Steps per Second: 10,656.64787

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.69453

Cumulative Model Updates: 104,098
Cumulative Timesteps: 868,131,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,099.28353
Policy Entropy: 3.61292
Value Function Loss: 0.08333

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.46396
Value Function Update Magnitude: 0.80042

Collected Steps per Second: 22,454.66567
Overall Steps per Second: 10,550.00131

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.51303
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.74009

Cumulative Model Updates: 104,104
Cumulative Timesteps: 868,181,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 868181900...
Checkpoint 868181900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,426.45696
Policy Entropy: 3.61055
Value Function Loss: 0.07681

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.50587
Value Function Update Magnitude: 0.83721

Collected Steps per Second: 22,557.38466
Overall Steps per Second: 10,672.68452

Timestep Collection Time: 2.21852
Timestep Consumption Time: 2.47046
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.68898

Cumulative Model Updates: 104,110
Cumulative Timesteps: 868,231,944

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,412.02747
Policy Entropy: 3.60682
Value Function Loss: 0.07473

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.72364
Value Function Update Magnitude: 0.76346

Collected Steps per Second: 23,180.12162
Overall Steps per Second: 10,782.88109

Timestep Collection Time: 2.15840
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63995

Cumulative Model Updates: 104,116
Cumulative Timesteps: 868,281,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 868281976...
Checkpoint 868281976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.35027
Policy Entropy: 3.60792
Value Function Loss: 0.07474

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.85115
Value Function Update Magnitude: 0.76002

Collected Steps per Second: 22,610.40749
Overall Steps per Second: 10,706.47056

Timestep Collection Time: 2.21181
Timestep Consumption Time: 2.45919
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.67101

Cumulative Model Updates: 104,122
Cumulative Timesteps: 868,331,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.16243
Policy Entropy: 3.61296
Value Function Loss: 0.07866

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.85830
Value Function Update Magnitude: 0.84246

Collected Steps per Second: 22,808.00734
Overall Steps per Second: 10,691.33253

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.48666
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.68080

Cumulative Model Updates: 104,128
Cumulative Timesteps: 868,382,030

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 868382030...
Checkpoint 868382030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.81427
Policy Entropy: 3.61372
Value Function Loss: 0.07850

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.78566
Value Function Update Magnitude: 0.88518

Collected Steps per Second: 22,848.82840
Overall Steps per Second: 10,863.91852

Timestep Collection Time: 2.18882
Timestep Consumption Time: 2.41467
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.60350

Cumulative Model Updates: 104,134
Cumulative Timesteps: 868,432,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,500.22125
Policy Entropy: 3.61663
Value Function Loss: 0.08105

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.72252
Value Function Update Magnitude: 0.89625

Collected Steps per Second: 22,978.59946
Overall Steps per Second: 10,831.86102

Timestep Collection Time: 2.17602
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.61620

Cumulative Model Updates: 104,140
Cumulative Timesteps: 868,482,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 868482044...
Checkpoint 868482044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,183.32816
Policy Entropy: 3.63501
Value Function Loss: 0.07976

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.70014
Value Function Update Magnitude: 0.80276

Collected Steps per Second: 22,437.16093
Overall Steps per Second: 10,730.60883

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.66236

Cumulative Model Updates: 104,146
Cumulative Timesteps: 868,532,074

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,018.61454
Policy Entropy: 3.63701
Value Function Loss: 0.07995

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.63140
Value Function Update Magnitude: 0.76829

Collected Steps per Second: 22,404.81447
Overall Steps per Second: 10,557.06989

Timestep Collection Time: 2.23273
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.73844

Cumulative Model Updates: 104,152
Cumulative Timesteps: 868,582,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 868582098...
Checkpoint 868582098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,073.15990
Policy Entropy: 3.62578
Value Function Loss: 0.08186

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.73332

Collected Steps per Second: 22,193.29075
Overall Steps per Second: 10,546.94231

Timestep Collection Time: 2.25329
Timestep Consumption Time: 2.48818
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.74147

Cumulative Model Updates: 104,158
Cumulative Timesteps: 868,632,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.39515
Policy Entropy: 3.62517
Value Function Loss: 0.08495

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 22,797.55079
Overall Steps per Second: 10,662.63284

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.49725
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.69152

Cumulative Model Updates: 104,164
Cumulative Timesteps: 868,682,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 868682130...
Checkpoint 868682130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,730.01809
Policy Entropy: 3.62292
Value Function Loss: 0.08666

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12072
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.67791

Collected Steps per Second: 22,570.65699
Overall Steps per Second: 10,629.85076

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.48847
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.70373

Cumulative Model Updates: 104,170
Cumulative Timesteps: 868,732,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,441.12236
Policy Entropy: 3.63199
Value Function Loss: 0.08391

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.46393
Value Function Update Magnitude: 0.69052

Collected Steps per Second: 23,178.62063
Overall Steps per Second: 10,737.81113

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.65905

Cumulative Model Updates: 104,176
Cumulative Timesteps: 868,782,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 868782158...
Checkpoint 868782158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.07369
Policy Entropy: 3.65581
Value Function Loss: 0.08231

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.78063

Collected Steps per Second: 22,892.30426
Overall Steps per Second: 10,676.94440

Timestep Collection Time: 2.18519
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.68524

Cumulative Model Updates: 104,182
Cumulative Timesteps: 868,832,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,296.67284
Policy Entropy: 3.65994
Value Function Loss: 0.07816

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.60260
Value Function Update Magnitude: 0.87889

Collected Steps per Second: 23,057.43529
Overall Steps per Second: 10,864.93321

Timestep Collection Time: 2.16850
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.60196

Cumulative Model Updates: 104,188
Cumulative Timesteps: 868,882,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 868882182...
Checkpoint 868882182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,805.69040
Policy Entropy: 3.65969
Value Function Loss: 0.07758

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.54443
Value Function Update Magnitude: 0.91579

Collected Steps per Second: 22,703.17111
Overall Steps per Second: 10,595.28738

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.51694
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.71946

Cumulative Model Updates: 104,194
Cumulative Timesteps: 868,932,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,063.01614
Policy Entropy: 3.64775
Value Function Loss: 0.07765

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06862
Policy Update Magnitude: 0.68805
Value Function Update Magnitude: 0.95312

Collected Steps per Second: 23,202.81975
Overall Steps per Second: 10,885.85240

Timestep Collection Time: 2.15500
Timestep Consumption Time: 2.43830
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59330

Cumulative Model Updates: 104,200
Cumulative Timesteps: 868,982,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 868982188...
Checkpoint 868982188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,615.57565
Policy Entropy: 3.64491
Value Function Loss: 0.07978

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.80790
Value Function Update Magnitude: 0.80975

Collected Steps per Second: 22,873.07083
Overall Steps per Second: 10,747.91774

Timestep Collection Time: 2.18641
Timestep Consumption Time: 2.46658
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.65299

Cumulative Model Updates: 104,206
Cumulative Timesteps: 869,032,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,957.97388
Policy Entropy: 3.64792
Value Function Loss: 0.07850

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15935
Policy Update Magnitude: 0.70530
Value Function Update Magnitude: 0.74108

Collected Steps per Second: 22,869.43765
Overall Steps per Second: 10,884.87538

Timestep Collection Time: 2.18685
Timestep Consumption Time: 2.40778
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.59463

Cumulative Model Updates: 104,212
Cumulative Timesteps: 869,082,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 869082210...
Checkpoint 869082210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,942.45399
Policy Entropy: 3.65068
Value Function Loss: 0.07812

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.48972
Value Function Update Magnitude: 0.72552

Collected Steps per Second: 22,104.31448
Overall Steps per Second: 10,573.36465

Timestep Collection Time: 2.26354
Timestep Consumption Time: 2.46854
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.73208

Cumulative Model Updates: 104,218
Cumulative Timesteps: 869,132,244

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.59549
Policy Entropy: 3.65166
Value Function Loss: 0.07896

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.48672
Value Function Update Magnitude: 0.69631

Collected Steps per Second: 22,819.86717
Overall Steps per Second: 10,878.26102

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.40765
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60092

Cumulative Model Updates: 104,224
Cumulative Timesteps: 869,182,294

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 869182294...
Checkpoint 869182294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.75531
Policy Entropy: 3.64824
Value Function Loss: 0.07917

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.56654
Value Function Update Magnitude: 0.71108

Collected Steps per Second: 22,074.15280
Overall Steps per Second: 10,632.72338

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.70284

Cumulative Model Updates: 104,230
Cumulative Timesteps: 869,232,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,575.21259
Policy Entropy: 3.63510
Value Function Loss: 0.07835

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.74998
Value Function Update Magnitude: 0.71814

Collected Steps per Second: 23,094.21994
Overall Steps per Second: 10,867.38560

Timestep Collection Time: 2.16504
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60092

Cumulative Model Updates: 104,236
Cumulative Timesteps: 869,282,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 869282298...
Checkpoint 869282298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,466.21700
Policy Entropy: 3.63213
Value Function Loss: 0.07919

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.80891
Value Function Update Magnitude: 0.71439

Collected Steps per Second: 22,713.58537
Overall Steps per Second: 10,626.44881

Timestep Collection Time: 2.20177
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.70618

Cumulative Model Updates: 104,242
Cumulative Timesteps: 869,332,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,637.24414
Policy Entropy: 3.62579
Value Function Loss: 0.08227

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.80600
Value Function Update Magnitude: 0.69883

Collected Steps per Second: 23,382.72157
Overall Steps per Second: 11,022.32311

Timestep Collection Time: 2.13970
Timestep Consumption Time: 2.39945
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.53915

Cumulative Model Updates: 104,248
Cumulative Timesteps: 869,382,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 869382340...
Checkpoint 869382340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,563.19736
Policy Entropy: 3.62945
Value Function Loss: 0.08324

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.63454
Value Function Update Magnitude: 0.66974

Collected Steps per Second: 22,639.50879
Overall Steps per Second: 10,671.41934

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.47837
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.68822

Cumulative Model Updates: 104,254
Cumulative Timesteps: 869,432,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360.75279
Policy Entropy: 3.62900
Value Function Loss: 0.08408

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.60433
Value Function Update Magnitude: 0.66110

Collected Steps per Second: 22,791.99942
Overall Steps per Second: 10,583.89932

Timestep Collection Time: 2.19454
Timestep Consumption Time: 2.53132
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.72586

Cumulative Model Updates: 104,260
Cumulative Timesteps: 869,482,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 869482388...
Checkpoint 869482388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,618.04467
Policy Entropy: 3.64730
Value Function Loss: 0.08048

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.48999
Value Function Update Magnitude: 0.70092

Collected Steps per Second: 22,898.44198
Overall Steps per Second: 10,704.53734

Timestep Collection Time: 2.18382
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.67148

Cumulative Model Updates: 104,266
Cumulative Timesteps: 869,532,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,218.58519
Policy Entropy: 3.64546
Value Function Loss: 0.08180

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.48201
Value Function Update Magnitude: 0.71020

Collected Steps per Second: 22,748.37129
Overall Steps per Second: 10,756.38973

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.45122
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.64989

Cumulative Model Updates: 104,272
Cumulative Timesteps: 869,582,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 869582410...
Checkpoint 869582410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.66746
Policy Entropy: 3.64479
Value Function Loss: 0.08150

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.52519
Value Function Update Magnitude: 0.69970

Collected Steps per Second: 22,310.22152
Overall Steps per Second: 10,626.84176

Timestep Collection Time: 2.24229
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.70751

Cumulative Model Updates: 104,278
Cumulative Timesteps: 869,632,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,532.89723
Policy Entropy: 3.65150
Value Function Loss: 0.07695

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.48526
Value Function Update Magnitude: 0.80343

Collected Steps per Second: 22,987.60570
Overall Steps per Second: 10,808.19917

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.45221
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62834

Cumulative Model Updates: 104,284
Cumulative Timesteps: 869,682,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 869682460...
Checkpoint 869682460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,821.82875
Policy Entropy: 3.65113
Value Function Loss: 0.07555

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.67650
Value Function Update Magnitude: 0.83845

Collected Steps per Second: 22,324.23604
Overall Steps per Second: 10,735.99797

Timestep Collection Time: 2.23972
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.65723

Cumulative Model Updates: 104,290
Cumulative Timesteps: 869,732,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,283.10162
Policy Entropy: 3.65762
Value Function Loss: 0.07244

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.68408
Value Function Update Magnitude: 0.73312

Collected Steps per Second: 23,005.10615
Overall Steps per Second: 10,816.55427

Timestep Collection Time: 2.17430
Timestep Consumption Time: 2.45009
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.62439

Cumulative Model Updates: 104,296
Cumulative Timesteps: 869,782,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 869782480...
Checkpoint 869782480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.51505
Policy Entropy: 3.65967
Value Function Loss: 0.07244

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.70476
Value Function Update Magnitude: 0.75129

Collected Steps per Second: 22,810.13286
Overall Steps per Second: 10,709.55329

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.67134

Cumulative Model Updates: 104,302
Cumulative Timesteps: 869,832,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,543.46474
Policy Entropy: 3.67207
Value Function Loss: 0.07155

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.64044
Value Function Update Magnitude: 0.78772

Collected Steps per Second: 23,288.83887
Overall Steps per Second: 10,909.25961

Timestep Collection Time: 2.14764
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.58473

Cumulative Model Updates: 104,308
Cumulative Timesteps: 869,882,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 869882524...
Checkpoint 869882524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.19930
Policy Entropy: 3.66492
Value Function Loss: 0.07077

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.61764
Value Function Update Magnitude: 0.83947

Collected Steps per Second: 22,827.85795
Overall Steps per Second: 10,631.41112

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.51394
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.70530

Cumulative Model Updates: 104,314
Cumulative Timesteps: 869,932,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,513.90507
Policy Entropy: 3.67078
Value Function Loss: 0.07215

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.51849
Value Function Update Magnitude: 0.82958

Collected Steps per Second: 23,070.26562
Overall Steps per Second: 10,875.84039

Timestep Collection Time: 2.16842
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.59974

Cumulative Model Updates: 104,320
Cumulative Timesteps: 869,982,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 869982574...
Checkpoint 869982574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,554.83734
Policy Entropy: 3.66265
Value Function Loss: 0.07535

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.50186
Value Function Update Magnitude: 0.84280

Collected Steps per Second: 22,341.64390
Overall Steps per Second: 10,749.36476

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.65255

Cumulative Model Updates: 104,326
Cumulative Timesteps: 870,032,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,691.39367
Policy Entropy: 3.66371
Value Function Loss: 0.07332

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.86954

Collected Steps per Second: 22,717.44433
Overall Steps per Second: 10,777.95006

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.43815
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.63910

Cumulative Model Updates: 104,332
Cumulative Timesteps: 870,082,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 870082586...
Checkpoint 870082586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,581.80209
Policy Entropy: 3.66108
Value Function Loss: 0.07328

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.58154
Value Function Update Magnitude: 0.86252

Collected Steps per Second: 22,156.21562
Overall Steps per Second: 10,661.50993

Timestep Collection Time: 2.25806
Timestep Consumption Time: 2.43452
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.69258

Cumulative Model Updates: 104,338
Cumulative Timesteps: 870,132,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,107.04823
Policy Entropy: 3.66534
Value Function Loss: 0.07372

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.58746
Value Function Update Magnitude: 0.87745

Collected Steps per Second: 22,561.83100
Overall Steps per Second: 10,585.42200

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.72518

Cumulative Model Updates: 104,344
Cumulative Timesteps: 870,182,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 870182634...
Checkpoint 870182634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.44952
Policy Entropy: 3.66062
Value Function Loss: 0.07291

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.68315
Value Function Update Magnitude: 0.89074

Collected Steps per Second: 22,438.38494
Overall Steps per Second: 10,641.83181

Timestep Collection Time: 2.22922
Timestep Consumption Time: 2.47110
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.70032

Cumulative Model Updates: 104,350
Cumulative Timesteps: 870,232,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,009.75303
Policy Entropy: 3.66098
Value Function Loss: 0.07307

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.71427
Value Function Update Magnitude: 0.90387

Collected Steps per Second: 23,357.41852
Overall Steps per Second: 10,857.91086

Timestep Collection Time: 2.14125
Timestep Consumption Time: 2.46498
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.60623

Cumulative Model Updates: 104,356
Cumulative Timesteps: 870,282,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 870282668...
Checkpoint 870282668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.84046
Policy Entropy: 3.66418
Value Function Loss: 0.07526

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.67489
Value Function Update Magnitude: 0.90837

Collected Steps per Second: 22,584.16728
Overall Steps per Second: 10,674.19368

Timestep Collection Time: 2.21412
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68457

Cumulative Model Updates: 104,362
Cumulative Timesteps: 870,332,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,506.16308
Policy Entropy: 3.65434
Value Function Loss: 0.07946

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.61175
Value Function Update Magnitude: 0.84874

Collected Steps per Second: 23,035.10032
Overall Steps per Second: 10,882.22483

Timestep Collection Time: 2.17173
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.59704

Cumulative Model Updates: 104,368
Cumulative Timesteps: 870,382,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 870382698...
Checkpoint 870382698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,444.14078
Policy Entropy: 3.65068
Value Function Loss: 0.08415

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.81465

Collected Steps per Second: 22,630.21763
Overall Steps per Second: 10,615.02527

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.50187
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.71219

Cumulative Model Updates: 104,374
Cumulative Timesteps: 870,432,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,320.03429
Policy Entropy: 3.64690
Value Function Loss: 0.08582

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.53660
Value Function Update Magnitude: 0.81661

Collected Steps per Second: 22,820.51758
Overall Steps per Second: 10,807.20853

Timestep Collection Time: 2.19127
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62710

Cumulative Model Updates: 104,380
Cumulative Timesteps: 870,482,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 870482724...
Checkpoint 870482724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,691.88774
Policy Entropy: 3.64909
Value Function Loss: 0.08321

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.66481
Value Function Update Magnitude: 0.91790

Collected Steps per Second: 22,431.77182
Overall Steps per Second: 10,722.48379

Timestep Collection Time: 2.22943
Timestep Consumption Time: 2.43460
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.66403

Cumulative Model Updates: 104,386
Cumulative Timesteps: 870,532,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,500.19791
Policy Entropy: 3.64963
Value Function Loss: 0.08339

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.56750
Value Function Update Magnitude: 0.94777

Collected Steps per Second: 22,429.60345
Overall Steps per Second: 10,551.76237

Timestep Collection Time: 2.23000
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.74025

Cumulative Model Updates: 104,392
Cumulative Timesteps: 870,582,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 870582752...
Checkpoint 870582752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,196.18272
Policy Entropy: 3.63622
Value Function Loss: 0.08427

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.50410
Value Function Update Magnitude: 0.81734

Collected Steps per Second: 22,242.01998
Overall Steps per Second: 10,587.77141

Timestep Collection Time: 2.24863
Timestep Consumption Time: 2.47512
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.72375

Cumulative Model Updates: 104,398
Cumulative Timesteps: 870,632,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,512.98900
Policy Entropy: 3.62631
Value Function Loss: 0.09256

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.61008
Value Function Update Magnitude: 0.70991

Collected Steps per Second: 22,686.24765
Overall Steps per Second: 10,692.68071

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.47311
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.67797

Cumulative Model Updates: 104,404
Cumulative Timesteps: 870,682,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 870682786...
Checkpoint 870682786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,861.30182
Policy Entropy: 3.62383
Value Function Loss: 0.08986

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.53215
Value Function Update Magnitude: 0.64726

Collected Steps per Second: 22,114.41504
Overall Steps per Second: 10,539.78088

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.74545

Cumulative Model Updates: 104,410
Cumulative Timesteps: 870,732,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,057.66126
Policy Entropy: 3.63634
Value Function Loss: 0.08665

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.62621
Value Function Update Magnitude: 0.70063

Collected Steps per Second: 22,778.16474
Overall Steps per Second: 10,798.07147

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.63268

Cumulative Model Updates: 104,416
Cumulative Timesteps: 870,782,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 870782826...
Checkpoint 870782826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,148.81476
Policy Entropy: 3.64839
Value Function Loss: 0.08225

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.59993
Value Function Update Magnitude: 0.79794

Collected Steps per Second: 22,601.73833
Overall Steps per Second: 10,585.16236

Timestep Collection Time: 2.21240
Timestep Consumption Time: 2.51157
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.72397

Cumulative Model Updates: 104,422
Cumulative Timesteps: 870,832,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.21766
Policy Entropy: 3.65999
Value Function Loss: 0.08121

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.16225
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.83825

Collected Steps per Second: 23,267.58453
Overall Steps per Second: 10,915.03726

Timestep Collection Time: 2.14943
Timestep Consumption Time: 2.43251
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.58194

Cumulative Model Updates: 104,428
Cumulative Timesteps: 870,882,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 870882842...
Checkpoint 870882842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,150.69212
Policy Entropy: 3.65638
Value Function Loss: 0.08020

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.78715

Collected Steps per Second: 22,569.01539
Overall Steps per Second: 10,659.40488

Timestep Collection Time: 2.21578
Timestep Consumption Time: 2.47566
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.69144

Cumulative Model Updates: 104,434
Cumulative Timesteps: 870,932,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.76798
Policy Entropy: 3.64729
Value Function Loss: 0.08025

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.59903
Value Function Update Magnitude: 0.77895

Collected Steps per Second: 21,257.37428
Overall Steps per Second: 10,368.64747

Timestep Collection Time: 2.35231
Timestep Consumption Time: 2.47030
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.82262

Cumulative Model Updates: 104,440
Cumulative Timesteps: 870,982,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 870982854...
Checkpoint 870982854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,443.30969
Policy Entropy: 3.64962
Value Function Loss: 0.08094

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.70650
Value Function Update Magnitude: 0.84251

Collected Steps per Second: 21,403.85939
Overall Steps per Second: 10,338.85267

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.50130
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.83845

Cumulative Model Updates: 104,446
Cumulative Timesteps: 871,032,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,702.47625
Policy Entropy: 3.64347
Value Function Loss: 0.08051

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.71065
Value Function Update Magnitude: 0.92520

Collected Steps per Second: 22,612.89583
Overall Steps per Second: 10,842.85848

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.40087
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.61262

Cumulative Model Updates: 104,452
Cumulative Timesteps: 871,082,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 871082892...
Checkpoint 871082892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,118.95276
Policy Entropy: 3.65136
Value Function Loss: 0.07904

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.62331
Value Function Update Magnitude: 0.91106

Collected Steps per Second: 21,878.52950
Overall Steps per Second: 10,647.54629

Timestep Collection Time: 2.28635
Timestep Consumption Time: 2.41163
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.69798

Cumulative Model Updates: 104,458
Cumulative Timesteps: 871,132,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,702.58608
Policy Entropy: 3.64653
Value Function Loss: 0.07999

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.58739
Value Function Update Magnitude: 0.93196

Collected Steps per Second: 22,152.77335
Overall Steps per Second: 10,856.10583

Timestep Collection Time: 2.25778
Timestep Consumption Time: 2.34940
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.60718

Cumulative Model Updates: 104,464
Cumulative Timesteps: 871,182,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 871182930...
Checkpoint 871182930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,095.27067
Policy Entropy: 3.65003
Value Function Loss: 0.08368

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.60058
Value Function Update Magnitude: 0.95128

Collected Steps per Second: 21,457.43628
Overall Steps per Second: 10,667.98688

Timestep Collection Time: 2.33019
Timestep Consumption Time: 2.35673
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.68692

Cumulative Model Updates: 104,470
Cumulative Timesteps: 871,232,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,703.82155
Policy Entropy: 3.64419
Value Function Loss: 0.08725

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.65772
Value Function Update Magnitude: 0.97344

Collected Steps per Second: 22,152.54785
Overall Steps per Second: 10,725.29973

Timestep Collection Time: 2.25771
Timestep Consumption Time: 2.40547
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.66318

Cumulative Model Updates: 104,476
Cumulative Timesteps: 871,282,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 871282944...
Checkpoint 871282944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,773.85313
Policy Entropy: 3.63498
Value Function Loss: 0.09181

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.67831
Value Function Update Magnitude: 0.94427

Collected Steps per Second: 21,676.93200
Overall Steps per Second: 10,594.62929

Timestep Collection Time: 2.30808
Timestep Consumption Time: 2.41432
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.72239

Cumulative Model Updates: 104,482
Cumulative Timesteps: 871,332,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,560.90687
Policy Entropy: 3.62744
Value Function Loss: 0.09246

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.63647
Value Function Update Magnitude: 0.93506

Collected Steps per Second: 22,705.25949
Overall Steps per Second: 10,771.02702

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.44093
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.64394

Cumulative Model Updates: 104,488
Cumulative Timesteps: 871,382,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 871382996...
Checkpoint 871382996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,774.17717
Policy Entropy: 3.61677
Value Function Loss: 0.09103

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.64369
Value Function Update Magnitude: 0.89390

Collected Steps per Second: 22,753.20100
Overall Steps per Second: 10,713.61715

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.47075
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.66938

Cumulative Model Updates: 104,494
Cumulative Timesteps: 871,433,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,366.21973
Policy Entropy: 3.61162
Value Function Loss: 0.08948

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.63006
Value Function Update Magnitude: 0.84871

Collected Steps per Second: 22,908.09405
Overall Steps per Second: 10,778.51427

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.64034

Cumulative Model Updates: 104,500
Cumulative Timesteps: 871,483,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 871483038...
Checkpoint 871483038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.11889
Policy Entropy: 3.62050
Value Function Loss: 0.08657

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.62919
Value Function Update Magnitude: 0.88219

Collected Steps per Second: 22,618.55387
Overall Steps per Second: 10,682.64265

Timestep Collection Time: 2.21146
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.68236

Cumulative Model Updates: 104,506
Cumulative Timesteps: 871,533,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,941.37532
Policy Entropy: 3.63217
Value Function Loss: 0.08343

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.61725
Value Function Update Magnitude: 0.81017

Collected Steps per Second: 23,465.25383
Overall Steps per Second: 10,909.82395

Timestep Collection Time: 2.13132
Timestep Consumption Time: 2.45280
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.58413

Cumulative Model Updates: 104,512
Cumulative Timesteps: 871,583,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 871583070...
Checkpoint 871583070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,728.66982
Policy Entropy: 3.62967
Value Function Loss: 0.08561

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.65627
Value Function Update Magnitude: 0.74412

Collected Steps per Second: 22,785.09010
Overall Steps per Second: 10,659.19324

Timestep Collection Time: 2.19547
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.69304

Cumulative Model Updates: 104,518
Cumulative Timesteps: 871,633,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,157.32170
Policy Entropy: 3.61545
Value Function Loss: 0.08674

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.64314
Value Function Update Magnitude: 0.68998

Collected Steps per Second: 22,714.64079
Overall Steps per Second: 10,785.42655

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63607

Cumulative Model Updates: 104,524
Cumulative Timesteps: 871,683,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 871683096...
Checkpoint 871683096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,201.10203
Policy Entropy: 3.59803
Value Function Loss: 0.09014

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.56028
Value Function Update Magnitude: 0.70470

Collected Steps per Second: 22,034.52722
Overall Steps per Second: 10,637.85685

Timestep Collection Time: 2.26971
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.70132

Cumulative Model Updates: 104,530
Cumulative Timesteps: 871,733,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,727.15885
Policy Entropy: 3.59824
Value Function Loss: 0.08855

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.44446
Value Function Update Magnitude: 0.70846

Collected Steps per Second: 22,553.80063
Overall Steps per Second: 10,585.55210

Timestep Collection Time: 2.21790
Timestep Consumption Time: 2.50760
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.72550

Cumulative Model Updates: 104,536
Cumulative Timesteps: 871,783,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 871783130...
Checkpoint 871783130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,875.28173
Policy Entropy: 3.59381
Value Function Loss: 0.08877

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.45399
Value Function Update Magnitude: 0.69541

Collected Steps per Second: 22,420.44998
Overall Steps per Second: 10,599.04957

Timestep Collection Time: 2.23029
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.71778

Cumulative Model Updates: 104,542
Cumulative Timesteps: 871,833,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,162.05778
Policy Entropy: 3.60663
Value Function Loss: 0.08400

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.79385

Collected Steps per Second: 22,836.08679
Overall Steps per Second: 10,646.10947

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.69937

Cumulative Model Updates: 104,548
Cumulative Timesteps: 871,883,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 871883164...
Checkpoint 871883164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,887.30039
Policy Entropy: 3.60751
Value Function Loss: 0.08331

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.79130

Collected Steps per Second: 22,606.62440
Overall Steps per Second: 10,612.35800

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.71450

Cumulative Model Updates: 104,554
Cumulative Timesteps: 871,933,196

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,797.11579
Policy Entropy: 3.61142
Value Function Loss: 0.08370

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.68040

Collected Steps per Second: 23,211.08202
Overall Steps per Second: 10,740.38466

Timestep Collection Time: 2.15449
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.65607

Cumulative Model Updates: 104,560
Cumulative Timesteps: 871,983,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 871983204...
Checkpoint 871983204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,190.45538
Policy Entropy: 3.60830
Value Function Loss: 0.08318

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.60771
Value Function Update Magnitude: 0.65940

Collected Steps per Second: 22,847.03090
Overall Steps per Second: 10,645.32273

Timestep Collection Time: 2.18943
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.69897

Cumulative Model Updates: 104,566
Cumulative Timesteps: 872,033,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,021.80453
Policy Entropy: 3.59751
Value Function Loss: 0.08474

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.74290
Value Function Update Magnitude: 0.66703

Collected Steps per Second: 22,852.34987
Overall Steps per Second: 10,792.66583

Timestep Collection Time: 2.18796
Timestep Consumption Time: 2.44482
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.63278

Cumulative Model Updates: 104,572
Cumulative Timesteps: 872,083,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 872083226...
Checkpoint 872083226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,362.33149
Policy Entropy: 3.59533
Value Function Loss: 0.08600

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.63200
Value Function Update Magnitude: 0.66138

Collected Steps per Second: 22,601.56515
Overall Steps per Second: 10,701.47971

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.46070
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.67356

Cumulative Model Updates: 104,578
Cumulative Timesteps: 872,133,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.22593
Policy Entropy: 3.59818
Value Function Loss: 0.09071

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.58064
Value Function Update Magnitude: 0.66210

Collected Steps per Second: 23,095.82278
Overall Steps per Second: 10,942.00055

Timestep Collection Time: 2.16585
Timestep Consumption Time: 2.40571
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.57156

Cumulative Model Updates: 104,584
Cumulative Timesteps: 872,183,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 872183262...
Checkpoint 872183262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,872.49152
Policy Entropy: 3.60385
Value Function Loss: 0.09110

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.69174
Value Function Update Magnitude: 0.67425

Collected Steps per Second: 22,333.19396
Overall Steps per Second: 10,667.36181

Timestep Collection Time: 2.23909
Timestep Consumption Time: 2.44867
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.68776

Cumulative Model Updates: 104,590
Cumulative Timesteps: 872,233,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,702.89781
Policy Entropy: 3.59820
Value Function Loss: 0.09046

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.69307
Value Function Update Magnitude: 0.63558

Collected Steps per Second: 22,711.92703
Overall Steps per Second: 10,784.31001

Timestep Collection Time: 2.20272
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63896

Cumulative Model Updates: 104,596
Cumulative Timesteps: 872,283,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 872283296...
Checkpoint 872283296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,048.02350
Policy Entropy: 3.58550
Value Function Loss: 0.09015

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.58400
Value Function Update Magnitude: 0.63458

Collected Steps per Second: 22,313.32604
Overall Steps per Second: 10,694.46086

Timestep Collection Time: 2.24081
Timestep Consumption Time: 2.43450
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.67532

Cumulative Model Updates: 104,602
Cumulative Timesteps: 872,333,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,778.74782
Policy Entropy: 3.58108
Value Function Loss: 0.08752

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.77724

Collected Steps per Second: 22,774.39074
Overall Steps per Second: 10,657.89086

Timestep Collection Time: 2.19685
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69436

Cumulative Model Updates: 104,608
Cumulative Timesteps: 872,383,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 872383328...
Checkpoint 872383328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,943.30418
Policy Entropy: 3.58480
Value Function Loss: 0.08730

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.49353
Value Function Update Magnitude: 0.85268

Collected Steps per Second: 22,597.79175
Overall Steps per Second: 10,556.03111

Timestep Collection Time: 2.21314
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.73777

Cumulative Model Updates: 104,614
Cumulative Timesteps: 872,433,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,668.08019
Policy Entropy: 3.58536
Value Function Loss: 0.08531

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.51114
Value Function Update Magnitude: 0.91792

Collected Steps per Second: 23,161.00787
Overall Steps per Second: 10,722.19195

Timestep Collection Time: 2.15880
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.66323

Cumulative Model Updates: 104,620
Cumulative Timesteps: 872,483,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 872483340...
Checkpoint 872483340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,136.67767
Policy Entropy: 3.59436
Value Function Loss: 0.08646

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.70142
Value Function Update Magnitude: 0.90779

Collected Steps per Second: 22,414.08795
Overall Steps per Second: 10,819.30804

Timestep Collection Time: 2.23199
Timestep Consumption Time: 2.39197
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.62396

Cumulative Model Updates: 104,626
Cumulative Timesteps: 872,533,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.15165
Policy Entropy: 3.59753
Value Function Loss: 0.08576

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.82830
Value Function Update Magnitude: 0.90486

Collected Steps per Second: 23,040.08906
Overall Steps per Second: 10,841.97287

Timestep Collection Time: 2.17013
Timestep Consumption Time: 2.44158
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.61171

Cumulative Model Updates: 104,632
Cumulative Timesteps: 872,583,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 872583368...
Checkpoint 872583368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,240.96983
Policy Entropy: 3.59545
Value Function Loss: 0.08571

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.83341
Value Function Update Magnitude: 0.89582

Collected Steps per Second: 22,482.54756
Overall Steps per Second: 10,677.12466

Timestep Collection Time: 2.22555
Timestep Consumption Time: 2.46073
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.68628

Cumulative Model Updates: 104,638
Cumulative Timesteps: 872,633,404

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,154.58628
Policy Entropy: 3.58551
Value Function Loss: 0.08754

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.82606
Value Function Update Magnitude: 0.93226

Collected Steps per Second: 22,789.47099
Overall Steps per Second: 10,798.72956

Timestep Collection Time: 2.19408
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.63036

Cumulative Model Updates: 104,644
Cumulative Timesteps: 872,683,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 872683406...
Checkpoint 872683406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,639.35636
Policy Entropy: 3.59309
Value Function Loss: 0.08809

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.80355
Value Function Update Magnitude: 0.97135

Collected Steps per Second: 22,128.02566
Overall Steps per Second: 10,665.27773

Timestep Collection Time: 2.26012
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.68924

Cumulative Model Updates: 104,650
Cumulative Timesteps: 872,733,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,491.88862
Policy Entropy: 3.61259
Value Function Loss: 0.08484

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.80370
Value Function Update Magnitude: 0.93808

Collected Steps per Second: 22,770.14797
Overall Steps per Second: 10,671.75336

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.68695

Cumulative Model Updates: 104,656
Cumulative Timesteps: 872,783,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 872783436...
Checkpoint 872783436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.69174
Policy Entropy: 3.60801
Value Function Loss: 0.08404

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.85051
Value Function Update Magnitude: 0.94946

Collected Steps per Second: 22,390.38219
Overall Steps per Second: 10,599.84408

Timestep Collection Time: 2.23319
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.71724

Cumulative Model Updates: 104,662
Cumulative Timesteps: 872,833,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,807.90132
Policy Entropy: 3.59453
Value Function Loss: 0.08757

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.18268
Policy Update Magnitude: 0.75438
Value Function Update Magnitude: 0.92937

Collected Steps per Second: 22,957.78257
Overall Steps per Second: 10,763.48655

Timestep Collection Time: 2.17904
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.64775

Cumulative Model Updates: 104,668
Cumulative Timesteps: 872,883,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 872883464...
Checkpoint 872883464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,656.63109
Policy Entropy: 3.58414
Value Function Loss: 0.09300

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.17278
Policy Update Magnitude: 0.53140
Value Function Update Magnitude: 0.86914

Collected Steps per Second: 22,504.84860
Overall Steps per Second: 10,602.60289

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.71677

Cumulative Model Updates: 104,674
Cumulative Timesteps: 872,933,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.09555
Policy Entropy: 3.58619
Value Function Loss: 0.09084

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11964
Policy Update Magnitude: 0.49257
Value Function Update Magnitude: 0.90626

Collected Steps per Second: 22,838.61614
Overall Steps per Second: 10,687.27577

Timestep Collection Time: 2.18989
Timestep Consumption Time: 2.48988
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.67977

Cumulative Model Updates: 104,680
Cumulative Timesteps: 872,983,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 872983488...
Checkpoint 872983488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,475.93157
Policy Entropy: 3.59261
Value Function Loss: 0.09064

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.57056
Value Function Update Magnitude: 0.81677

Collected Steps per Second: 22,815.05363
Overall Steps per Second: 10,835.89628

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.42402
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61669

Cumulative Model Updates: 104,686
Cumulative Timesteps: 873,033,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,583.44289
Policy Entropy: 3.60822
Value Function Loss: 0.08948

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.75040

Collected Steps per Second: 23,180.04330
Overall Steps per Second: 10,907.50317

Timestep Collection Time: 2.15746
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.58492

Cumulative Model Updates: 104,692
Cumulative Timesteps: 873,083,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 873083524...
Checkpoint 873083524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.86503
Policy Entropy: 3.62629
Value Function Loss: 0.08970

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.47838
Value Function Update Magnitude: 0.71850

Collected Steps per Second: 22,723.71052
Overall Steps per Second: 10,716.93735

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.46605
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.66719

Cumulative Model Updates: 104,698
Cumulative Timesteps: 873,133,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,221.31798
Policy Entropy: 3.61691
Value Function Loss: 0.09308

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.50650
Value Function Update Magnitude: 0.70998

Collected Steps per Second: 23,523.27234
Overall Steps per Second: 10,960.53179

Timestep Collection Time: 2.12666
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.56419

Cumulative Model Updates: 104,704
Cumulative Timesteps: 873,183,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 873183568...
Checkpoint 873183568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,372.70197
Policy Entropy: 3.60887
Value Function Loss: 0.09221

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.50613
Value Function Update Magnitude: 0.76452

Collected Steps per Second: 21,671.06706
Overall Steps per Second: 10,638.99566

Timestep Collection Time: 2.30824
Timestep Consumption Time: 2.39352
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.70176

Cumulative Model Updates: 104,710
Cumulative Timesteps: 873,233,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,090.61779
Policy Entropy: 3.61009
Value Function Loss: 0.09399

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.54871
Value Function Update Magnitude: 0.71432

Collected Steps per Second: 21,748.37123
Overall Steps per Second: 10,636.11688

Timestep Collection Time: 2.29911
Timestep Consumption Time: 2.40204
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.70115

Cumulative Model Updates: 104,716
Cumulative Timesteps: 873,283,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 873283592...
Checkpoint 873283592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,181.53785
Policy Entropy: 3.60954
Value Function Loss: 0.09142

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.68430

Collected Steps per Second: 20,803.68785
Overall Steps per Second: 10,408.41302

Timestep Collection Time: 2.40361
Timestep Consumption Time: 2.40058
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.80419

Cumulative Model Updates: 104,722
Cumulative Timesteps: 873,333,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,528.85213
Policy Entropy: 3.61284
Value Function Loss: 0.09219

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.52175
Value Function Update Magnitude: 0.67745

Collected Steps per Second: 21,765.29601
Overall Steps per Second: 10,585.91971

Timestep Collection Time: 2.29733
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.72344

Cumulative Model Updates: 104,728
Cumulative Timesteps: 873,383,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 873383598...
Checkpoint 873383598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,523.44581
Policy Entropy: 3.59573
Value Function Loss: 0.09308

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.57118
Value Function Update Magnitude: 0.67061

Collected Steps per Second: 22,247.40916
Overall Steps per Second: 10,536.13395

Timestep Collection Time: 2.24790
Timestep Consumption Time: 2.49862
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.74652

Cumulative Model Updates: 104,734
Cumulative Timesteps: 873,433,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,781.37511
Policy Entropy: 3.59428
Value Function Loss: 0.09057

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.58634
Value Function Update Magnitude: 0.69901

Collected Steps per Second: 23,140.73869
Overall Steps per Second: 10,925.20248

Timestep Collection Time: 2.16190
Timestep Consumption Time: 2.41724
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.57914

Cumulative Model Updates: 104,740
Cumulative Timesteps: 873,483,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 873483636...
Checkpoint 873483636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,444.49385
Policy Entropy: 3.60025
Value Function Loss: 0.08725

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.73561

Collected Steps per Second: 22,621.35232
Overall Steps per Second: 10,674.16499

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.47470
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.68571

Cumulative Model Updates: 104,746
Cumulative Timesteps: 873,533,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,683.62421
Policy Entropy: 3.60643
Value Function Loss: 0.08124

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.53484
Value Function Update Magnitude: 0.72586

Collected Steps per Second: 23,214.73687
Overall Steps per Second: 10,878.16845

Timestep Collection Time: 2.15398
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.59673

Cumulative Model Updates: 104,752
Cumulative Timesteps: 873,583,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 873583656...
Checkpoint 873583656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,341.71183
Policy Entropy: 3.60421
Value Function Loss: 0.08653

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.59917
Value Function Update Magnitude: 0.73360

Collected Steps per Second: 22,791.78705
Overall Steps per Second: 10,774.58913

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.44775
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.64240

Cumulative Model Updates: 104,758
Cumulative Timesteps: 873,633,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,952.04779
Policy Entropy: 3.58991
Value Function Loss: 0.08846

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.57617
Value Function Update Magnitude: 0.76338

Collected Steps per Second: 22,886.74336
Overall Steps per Second: 10,762.69707

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.46327
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.64995

Cumulative Model Updates: 104,764
Cumulative Timesteps: 873,683,722

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 873683722...
Checkpoint 873683722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,138.80009
Policy Entropy: 3.58686
Value Function Loss: 0.09032

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.70497

Collected Steps per Second: 22,217.71046
Overall Steps per Second: 10,698.02003

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.67470

Cumulative Model Updates: 104,770
Cumulative Timesteps: 873,733,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,291.67050
Policy Entropy: 3.58228
Value Function Loss: 0.09177

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.68927

Collected Steps per Second: 22,734.10241
Overall Steps per Second: 10,803.52975

Timestep Collection Time: 2.19995
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.62941

Cumulative Model Updates: 104,776
Cumulative Timesteps: 873,783,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 873783746...
Checkpoint 873783746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,223.80894
Policy Entropy: 3.59659
Value Function Loss: 0.09117

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.50047
Value Function Update Magnitude: 0.73651

Collected Steps per Second: 22,238.73883
Overall Steps per Second: 10,700.64656

Timestep Collection Time: 2.24932
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.67467

Cumulative Model Updates: 104,782
Cumulative Timesteps: 873,833,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,708.52345
Policy Entropy: 3.61481
Value Function Loss: 0.09295

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.52362
Value Function Update Magnitude: 0.75950

Collected Steps per Second: 22,816.46303
Overall Steps per Second: 10,660.59753

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.49997
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.69242

Cumulative Model Updates: 104,788
Cumulative Timesteps: 873,883,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 873883792...
Checkpoint 873883792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,790.01477
Policy Entropy: 3.61078
Value Function Loss: 0.08853

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.51110
Value Function Update Magnitude: 0.73120

Collected Steps per Second: 22,582.75841
Overall Steps per Second: 10,594.23734

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.72162

Cumulative Model Updates: 104,794
Cumulative Timesteps: 873,933,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,793.07301
Policy Entropy: 3.60205
Value Function Loss: 0.08920

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.48986
Value Function Update Magnitude: 0.71930

Collected Steps per Second: 22,981.60575
Overall Steps per Second: 10,733.86900

Timestep Collection Time: 2.17591
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.65871

Cumulative Model Updates: 104,800
Cumulative Timesteps: 873,983,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 873983820...
Checkpoint 873983820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.02496
Policy Entropy: 3.59651
Value Function Loss: 0.08893

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.49951
Value Function Update Magnitude: 0.64058

Collected Steps per Second: 22,515.40611
Overall Steps per Second: 10,653.22380

Timestep Collection Time: 2.22079
Timestep Consumption Time: 2.47281
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.69360

Cumulative Model Updates: 104,806
Cumulative Timesteps: 874,033,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,139.60721
Policy Entropy: 3.58554
Value Function Loss: 0.09396

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.61401

Collected Steps per Second: 23,029.74915
Overall Steps per Second: 10,863.13630

Timestep Collection Time: 2.17180
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60420

Cumulative Model Updates: 104,812
Cumulative Timesteps: 874,083,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 874083838...
Checkpoint 874083838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,508.28753
Policy Entropy: 3.59250
Value Function Loss: 0.09464

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.53486
Value Function Update Magnitude: 0.63375

Collected Steps per Second: 22,346.44860
Overall Steps per Second: 10,710.04336

Timestep Collection Time: 2.23776
Timestep Consumption Time: 2.43131
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.66908

Cumulative Model Updates: 104,818
Cumulative Timesteps: 874,133,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,641.83005
Policy Entropy: 3.59953
Value Function Loss: 0.09644

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.63319
Value Function Update Magnitude: 0.65284

Collected Steps per Second: 23,158.25468
Overall Steps per Second: 10,929.18913

Timestep Collection Time: 2.15940
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.57564

Cumulative Model Updates: 104,824
Cumulative Timesteps: 874,183,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 874183852...
Checkpoint 874183852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,556.86738
Policy Entropy: 3.61182
Value Function Loss: 0.09250

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.63779
Value Function Update Magnitude: 0.65360

Collected Steps per Second: 22,621.29655
Overall Steps per Second: 10,705.64230

Timestep Collection Time: 2.21137
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.67268

Cumulative Model Updates: 104,830
Cumulative Timesteps: 874,233,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,793.82774
Policy Entropy: 3.60809
Value Function Loss: 0.09169

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.74760
Value Function Update Magnitude: 0.66149

Collected Steps per Second: 22,839.49817
Overall Steps per Second: 10,845.29164

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.61232

Cumulative Model Updates: 104,836
Cumulative Timesteps: 874,283,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 874283898...
Checkpoint 874283898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,764.28742
Policy Entropy: 3.61989
Value Function Loss: 0.08828

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.72315
Value Function Update Magnitude: 0.65479

Collected Steps per Second: 22,221.66941
Overall Steps per Second: 10,615.35578

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.71242

Cumulative Model Updates: 104,842
Cumulative Timesteps: 874,333,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,136.71753
Policy Entropy: 3.61367
Value Function Loss: 0.08917

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.66492
Value Function Update Magnitude: 0.62787

Collected Steps per Second: 22,211.01557
Overall Steps per Second: 10,516.17915

Timestep Collection Time: 2.25204
Timestep Consumption Time: 2.50444
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.75648

Cumulative Model Updates: 104,848
Cumulative Timesteps: 874,383,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 874383942...
Checkpoint 874383942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.14629
Policy Entropy: 3.60841
Value Function Loss: 0.08874

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.62735
Value Function Update Magnitude: 0.64621

Collected Steps per Second: 22,274.11686
Overall Steps per Second: 10,545.84369

Timestep Collection Time: 2.24485
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.74139

Cumulative Model Updates: 104,854
Cumulative Timesteps: 874,433,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,405.86078
Policy Entropy: 3.61361
Value Function Loss: 0.08811

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.64753

Collected Steps per Second: 23,281.60465
Overall Steps per Second: 10,862.77585

Timestep Collection Time: 2.14959
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.60711

Cumulative Model Updates: 104,860
Cumulative Timesteps: 874,483,990

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 874483990...
Checkpoint 874483990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,736.92085
Policy Entropy: 3.60370
Value Function Loss: 0.08850

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.58804
Value Function Update Magnitude: 0.64086

Collected Steps per Second: 22,481.51628
Overall Steps per Second: 10,763.19082

Timestep Collection Time: 2.22423
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.64583

Cumulative Model Updates: 104,866
Cumulative Timesteps: 874,533,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,635.64139
Policy Entropy: 3.62452
Value Function Loss: 0.08716

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.56684
Value Function Update Magnitude: 0.70076

Collected Steps per Second: 23,073.49788
Overall Steps per Second: 10,848.36680

Timestep Collection Time: 2.16742
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.60991

Cumulative Model Updates: 104,872
Cumulative Timesteps: 874,584,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 874584004...
Checkpoint 874584004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.05042
Policy Entropy: 3.62882
Value Function Loss: 0.08233

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.61363
Value Function Update Magnitude: 0.75135

Collected Steps per Second: 22,565.30330
Overall Steps per Second: 10,613.96280

Timestep Collection Time: 2.21641
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.71209

Cumulative Model Updates: 104,878
Cumulative Timesteps: 874,634,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,141.58515
Policy Entropy: 3.62792
Value Function Loss: 0.08348

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.67362
Value Function Update Magnitude: 0.68147

Collected Steps per Second: 22,734.88077
Overall Steps per Second: 10,687.57533

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.47936
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.67889

Cumulative Model Updates: 104,884
Cumulative Timesteps: 874,684,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874684024...
Checkpoint 874684024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,763.49962
Policy Entropy: 3.62749
Value Function Loss: 0.08131

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.71271
Value Function Update Magnitude: 0.63626

Collected Steps per Second: 22,748.05407
Overall Steps per Second: 10,813.58569

Timestep Collection Time: 2.19887
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62566

Cumulative Model Updates: 104,890
Cumulative Timesteps: 874,734,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,160.34989
Policy Entropy: 3.62215
Value Function Loss: 0.08146

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.68542
Value Function Update Magnitude: 0.68526

Collected Steps per Second: 22,347.50477
Overall Steps per Second: 10,519.73868

Timestep Collection Time: 2.23846
Timestep Consumption Time: 2.51679
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.75525

Cumulative Model Updates: 104,896
Cumulative Timesteps: 874,784,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 874784068...
Checkpoint 874784068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,964.42343
Policy Entropy: 3.61346
Value Function Loss: 0.08518

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.75928
Value Function Update Magnitude: 0.64439

Collected Steps per Second: 22,184.51262
Overall Steps per Second: 10,718.30002

Timestep Collection Time: 2.25572
Timestep Consumption Time: 2.41312
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.66884

Cumulative Model Updates: 104,902
Cumulative Timesteps: 874,834,110

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.92012
Policy Entropy: 3.61032
Value Function Loss: 0.08664

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.72295
Value Function Update Magnitude: 0.64921

Collected Steps per Second: 22,807.97561
Overall Steps per Second: 10,819.69169

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62287

Cumulative Model Updates: 104,908
Cumulative Timesteps: 874,884,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 874884128...
Checkpoint 874884128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,254.24684
Policy Entropy: 3.60281
Value Function Loss: 0.08695

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.70939
Value Function Update Magnitude: 0.70625

Collected Steps per Second: 22,238.11393
Overall Steps per Second: 10,621.92794

Timestep Collection Time: 2.24911
Timestep Consumption Time: 2.45964
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.70875

Cumulative Model Updates: 104,914
Cumulative Timesteps: 874,934,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,543.81061
Policy Entropy: 3.59384
Value Function Loss: 0.08799

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.17429
Policy Update Magnitude: 0.65222
Value Function Update Magnitude: 0.65153

Collected Steps per Second: 23,353.82853
Overall Steps per Second: 10,888.22729

Timestep Collection Time: 2.14123
Timestep Consumption Time: 2.45143
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59267

Cumulative Model Updates: 104,920
Cumulative Timesteps: 874,984,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874984150...
Checkpoint 874984150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,800.96395
Policy Entropy: 3.59995
Value Function Loss: 0.08778

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15226
Policy Update Magnitude: 0.50299
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 22,796.71151
Overall Steps per Second: 10,709.63314

Timestep Collection Time: 2.19330
Timestep Consumption Time: 2.47540
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.66869

Cumulative Model Updates: 104,926
Cumulative Timesteps: 875,034,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,285.33499
Policy Entropy: 3.59949
Value Function Loss: 0.08644

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.53725
Value Function Update Magnitude: 0.69236

Collected Steps per Second: 23,433.11486
Overall Steps per Second: 10,889.32278

Timestep Collection Time: 2.13416
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.59257

Cumulative Model Updates: 104,932
Cumulative Timesteps: 875,084,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 875084160...
Checkpoint 875084160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,665.14612
Policy Entropy: 3.60423
Value Function Loss: 0.08552

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.54442
Value Function Update Magnitude: 0.69682

Collected Steps per Second: 22,718.42529
Overall Steps per Second: 10,664.64484

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.68858

Cumulative Model Updates: 104,938
Cumulative Timesteps: 875,134,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,956.35639
Policy Entropy: 3.60334
Value Function Loss: 0.08834

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.64641

Collected Steps per Second: 22,990.21284
Overall Steps per Second: 10,899.54774

Timestep Collection Time: 2.17484
Timestep Consumption Time: 2.41251
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.58735

Cumulative Model Updates: 104,944
Cumulative Timesteps: 875,184,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 875184162...
Checkpoint 875184162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,592.04870
Policy Entropy: 3.59995
Value Function Loss: 0.09033

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.64626
Value Function Update Magnitude: 0.66335

Collected Steps per Second: 21,271.73164
Overall Steps per Second: 10,568.95578

Timestep Collection Time: 2.35157
Timestep Consumption Time: 2.38135
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.73292

Cumulative Model Updates: 104,950
Cumulative Timesteps: 875,234,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,418.73713
Policy Entropy: 3.60381
Value Function Loss: 0.08914

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.16455
Policy Update Magnitude: 0.58224
Value Function Update Magnitude: 0.68369

Collected Steps per Second: 21,846.34022
Overall Steps per Second: 10,625.28685

Timestep Collection Time: 2.28990
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.70820

Cumulative Model Updates: 104,956
Cumulative Timesteps: 875,284,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 875284210...
Checkpoint 875284210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.31338
Policy Entropy: 3.61131
Value Function Loss: 0.08736

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.51354
Value Function Update Magnitude: 0.61476

Collected Steps per Second: 21,136.54232
Overall Steps per Second: 10,550.57656

Timestep Collection Time: 2.36557
Timestep Consumption Time: 2.37351
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.73908

Cumulative Model Updates: 104,962
Cumulative Timesteps: 875,334,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,314.67795
Policy Entropy: 3.60777
Value Function Loss: 0.08803

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.55945

Collected Steps per Second: 22,110.75943
Overall Steps per Second: 10,818.65170

Timestep Collection Time: 2.26134
Timestep Consumption Time: 2.36031
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.62165

Cumulative Model Updates: 104,968
Cumulative Timesteps: 875,384,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 875384210...
Checkpoint 875384210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,103.95532
Policy Entropy: 3.60874
Value Function Loss: 0.08905

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.53072
Value Function Update Magnitude: 0.57041

Collected Steps per Second: 21,544.22039
Overall Steps per Second: 10,671.19245

Timestep Collection Time: 2.32183
Timestep Consumption Time: 2.36574
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.68757

Cumulative Model Updates: 104,974
Cumulative Timesteps: 875,434,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,223.83979
Policy Entropy: 3.59620
Value Function Loss: 0.08886

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.50672
Value Function Update Magnitude: 0.54871

Collected Steps per Second: 22,196.43929
Overall Steps per Second: 10,740.73839

Timestep Collection Time: 2.25351
Timestep Consumption Time: 2.40352
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.65704

Cumulative Model Updates: 104,980
Cumulative Timesteps: 875,484,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 875484252...
Checkpoint 875484252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,433.48801
Policy Entropy: 3.59917
Value Function Loss: 0.08698

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.16610
Policy Update Magnitude: 0.48397
Value Function Update Magnitude: 0.50986

Collected Steps per Second: 21,843.99316
Overall Steps per Second: 10,521.62485

Timestep Collection Time: 2.28914
Timestep Consumption Time: 2.46336
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.75250

Cumulative Model Updates: 104,986
Cumulative Timesteps: 875,534,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,217.45216
Policy Entropy: 3.62039
Value Function Loss: 0.08374

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.37143
Value Function Update Magnitude: 0.55782

Collected Steps per Second: 23,163.47740
Overall Steps per Second: 10,733.90990

Timestep Collection Time: 2.15969
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.66056

Cumulative Model Updates: 104,992
Cumulative Timesteps: 875,584,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 875584282...
Checkpoint 875584282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,004.13749
Policy Entropy: 3.62299
Value Function Loss: 0.08273

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.33191
Value Function Update Magnitude: 0.66912

Collected Steps per Second: 22,254.24971
Overall Steps per Second: 10,676.32808

Timestep Collection Time: 2.24793
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.68569

Cumulative Model Updates: 104,998
Cumulative Timesteps: 875,634,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,800.62576
Policy Entropy: 3.62726
Value Function Loss: 0.08224

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.32971
Value Function Update Magnitude: 0.68762

Collected Steps per Second: 22,703.54480
Overall Steps per Second: 10,861.73665

Timestep Collection Time: 2.20300
Timestep Consumption Time: 2.40178
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60479

Cumulative Model Updates: 105,004
Cumulative Timesteps: 875,684,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 875684324...
Checkpoint 875684324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,920.43918
Policy Entropy: 3.63186
Value Function Loss: 0.08201

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.38480
Value Function Update Magnitude: 0.65429

Collected Steps per Second: 22,527.36701
Overall Steps per Second: 10,694.98410

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.45655
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.67696

Cumulative Model Updates: 105,010
Cumulative Timesteps: 875,734,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.84917
Policy Entropy: 3.64597
Value Function Loss: 0.07768

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.43445
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 22,725.16135
Overall Steps per Second: 10,826.91986

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.61812

Cumulative Model Updates: 105,016
Cumulative Timesteps: 875,784,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 875784344...
Checkpoint 875784344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,468.76722
Policy Entropy: 3.64116
Value Function Loss: 0.07472

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.45199
Value Function Update Magnitude: 0.67160

Collected Steps per Second: 22,491.91857
Overall Steps per Second: 10,676.36155

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.68437

Cumulative Model Updates: 105,022
Cumulative Timesteps: 875,834,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,806.70690
Policy Entropy: 3.64025
Value Function Loss: 0.07427

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.50480
Value Function Update Magnitude: 0.66233

Collected Steps per Second: 22,629.51673
Overall Steps per Second: 10,636.87960

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.49242
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.70307

Cumulative Model Updates: 105,028
Cumulative Timesteps: 875,884,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 875884382...
Checkpoint 875884382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,813.35864
Policy Entropy: 3.63746
Value Function Loss: 0.07225

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.71966

Collected Steps per Second: 22,266.73689
Overall Steps per Second: 10,528.69705

Timestep Collection Time: 2.24550
Timestep Consumption Time: 2.50342
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.74893

Cumulative Model Updates: 105,034
Cumulative Timesteps: 875,934,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,200.62867
Policy Entropy: 3.64788
Value Function Loss: 0.07039

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.69396

Collected Steps per Second: 22,960.78327
Overall Steps per Second: 10,772.37702

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.46466
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.64299

Cumulative Model Updates: 105,040
Cumulative Timesteps: 875,984,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 875984398...
Checkpoint 875984398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,491.01324
Policy Entropy: 3.64615
Value Function Loss: 0.07070

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.60020
Value Function Update Magnitude: 0.65006

Collected Steps per Second: 22,664.36375
Overall Steps per Second: 10,687.49983

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.68136

Cumulative Model Updates: 105,046
Cumulative Timesteps: 876,034,430

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,164.24184
Policy Entropy: 3.64091
Value Function Loss: 0.07310

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.64639
Value Function Update Magnitude: 0.73260

Collected Steps per Second: 23,086.13546
Overall Steps per Second: 10,875.33673

Timestep Collection Time: 2.16615
Timestep Consumption Time: 2.43215
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.59829

Cumulative Model Updates: 105,052
Cumulative Timesteps: 876,084,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 876084438...
Checkpoint 876084438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,335.96178
Policy Entropy: 3.62715
Value Function Loss: 0.07294

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.64675
Value Function Update Magnitude: 0.80206

Collected Steps per Second: 22,719.58957
Overall Steps per Second: 10,706.78528

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.46959
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.67068

Cumulative Model Updates: 105,058
Cumulative Timesteps: 876,134,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,637.83614
Policy Entropy: 3.62467
Value Function Loss: 0.07256

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.63722
Value Function Update Magnitude: 0.83440

Collected Steps per Second: 23,031.34466
Overall Steps per Second: 10,854.10624

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60876

Cumulative Model Updates: 105,064
Cumulative Timesteps: 876,184,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 876184470...
Checkpoint 876184470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,367.58076
Policy Entropy: 3.62437
Value Function Loss: 0.07137

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.65918
Value Function Update Magnitude: 0.82164

Collected Steps per Second: 22,753.45255
Overall Steps per Second: 10,671.61896

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.68664

Cumulative Model Updates: 105,070
Cumulative Timesteps: 876,234,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,361.22977
Policy Entropy: 3.62144
Value Function Loss: 0.07440

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06850
Policy Update Magnitude: 0.70460
Value Function Update Magnitude: 0.74578

Collected Steps per Second: 22,172.16466
Overall Steps per Second: 10,502.23256

Timestep Collection Time: 2.25589
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.76261

Cumulative Model Updates: 105,076
Cumulative Timesteps: 876,284,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 876284502...
Checkpoint 876284502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.92133
Policy Entropy: 3.62752
Value Function Loss: 0.07683

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.74721
Value Function Update Magnitude: 0.74018

Collected Steps per Second: 22,086.00400
Overall Steps per Second: 10,590.05354

Timestep Collection Time: 2.26460
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.72292

Cumulative Model Updates: 105,082
Cumulative Timesteps: 876,334,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.90100
Policy Entropy: 3.61245
Value Function Loss: 0.07766

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.64358
Value Function Update Magnitude: 0.68506

Collected Steps per Second: 22,408.36713
Overall Steps per Second: 10,581.33953

Timestep Collection Time: 2.23167
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.72606

Cumulative Model Updates: 105,088
Cumulative Timesteps: 876,384,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 876384526...
Checkpoint 876384526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,398.02220
Policy Entropy: 3.61982
Value Function Loss: 0.07849

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.68019

Collected Steps per Second: 22,203.51467
Overall Steps per Second: 10,525.60964

Timestep Collection Time: 2.25352
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.75374

Cumulative Model Updates: 105,094
Cumulative Timesteps: 876,434,562

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,576.91227
Policy Entropy: 3.61594
Value Function Loss: 0.08018

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.56889
Value Function Update Magnitude: 0.69560

Collected Steps per Second: 23,122.23195
Overall Steps per Second: 10,834.89118

Timestep Collection Time: 2.16251
Timestep Consumption Time: 2.45240
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61491

Cumulative Model Updates: 105,100
Cumulative Timesteps: 876,484,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 876484564...
Checkpoint 876484564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,607.25088
Policy Entropy: 3.61425
Value Function Loss: 0.08523

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.65706

Collected Steps per Second: 22,642.09752
Overall Steps per Second: 10,717.45941

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.45740
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.66603

Cumulative Model Updates: 105,106
Cumulative Timesteps: 876,534,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,219.18166
Policy Entropy: 3.61422
Value Function Loss: 0.08857

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.64071

Collected Steps per Second: 23,140.78199
Overall Steps per Second: 10,870.14248

Timestep Collection Time: 2.16172
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60196

Cumulative Model Updates: 105,112
Cumulative Timesteps: 876,584,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 876584596...
Checkpoint 876584596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,512.59390
Policy Entropy: 3.60381
Value Function Loss: 0.08848

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.50018
Value Function Update Magnitude: 0.65199

Collected Steps per Second: 22,561.33202
Overall Steps per Second: 10,657.66516

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.47548
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.69183

Cumulative Model Updates: 105,118
Cumulative Timesteps: 876,634,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,493.32228
Policy Entropy: 3.60173
Value Function Loss: 0.08921

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.58042
Value Function Update Magnitude: 0.64010

Collected Steps per Second: 23,362.01530
Overall Steps per Second: 10,964.35753

Timestep Collection Time: 2.14194
Timestep Consumption Time: 2.42194
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.56388

Cumulative Model Updates: 105,124
Cumulative Timesteps: 876,684,640

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 876684640...
Checkpoint 876684640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,407.61481
Policy Entropy: 3.59482
Value Function Loss: 0.08992

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.52532
Value Function Update Magnitude: 0.73206

Collected Steps per Second: 22,833.64889
Overall Steps per Second: 10,663.02071

Timestep Collection Time: 2.19115
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69210

Cumulative Model Updates: 105,130
Cumulative Timesteps: 876,734,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,653.39137
Policy Entropy: 3.60564
Value Function Loss: 0.08899

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.43749
Value Function Update Magnitude: 0.80319

Collected Steps per Second: 22,686.88485
Overall Steps per Second: 10,786.17173

Timestep Collection Time: 2.20515
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.63816

Cumulative Model Updates: 105,136
Cumulative Timesteps: 876,784,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 876784700...
Checkpoint 876784700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,287.08653
Policy Entropy: 3.58927
Value Function Loss: 0.09281

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.40084
Value Function Update Magnitude: 0.70605

Collected Steps per Second: 22,234.99234
Overall Steps per Second: 10,693.35055

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.67786

Cumulative Model Updates: 105,142
Cumulative Timesteps: 876,834,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,821.97067
Policy Entropy: 3.59998
Value Function Loss: 0.09154

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.42717
Value Function Update Magnitude: 0.63591

Collected Steps per Second: 22,859.30279
Overall Steps per Second: 10,849.05113

Timestep Collection Time: 2.18843
Timestep Consumption Time: 2.42266
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61109

Cumulative Model Updates: 105,148
Cumulative Timesteps: 876,884,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 876884748...
Checkpoint 876884748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,394.41227
Policy Entropy: 3.57383
Value Function Loss: 0.09151

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.49469
Value Function Update Magnitude: 0.62756

Collected Steps per Second: 21,890.53812
Overall Steps per Second: 10,645.84525

Timestep Collection Time: 2.28501
Timestep Consumption Time: 2.41354
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.69855

Cumulative Model Updates: 105,154
Cumulative Timesteps: 876,934,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,688.97678
Policy Entropy: 3.59653
Value Function Loss: 0.08786

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.47671
Value Function Update Magnitude: 0.64242

Collected Steps per Second: 22,831.65064
Overall Steps per Second: 10,639.17377

Timestep Collection Time: 2.19029
Timestep Consumption Time: 2.51007
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70037

Cumulative Model Updates: 105,160
Cumulative Timesteps: 876,984,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 876984776...
Checkpoint 876984776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,519.25345
Policy Entropy: 3.58361
Value Function Loss: 0.08671

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.16460
Policy Update Magnitude: 0.43724
Value Function Update Magnitude: 0.64625

Collected Steps per Second: 22,294.97979
Overall Steps per Second: 10,518.10985

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.75561

Cumulative Model Updates: 105,166
Cumulative Timesteps: 877,034,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,078.07383
Policy Entropy: 3.59559
Value Function Loss: 0.08228

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.38970
Value Function Update Magnitude: 0.64413

Collected Steps per Second: 22,353.69185
Overall Steps per Second: 10,887.88188

Timestep Collection Time: 2.23704
Timestep Consumption Time: 2.35578
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.59281

Cumulative Model Updates: 105,172
Cumulative Timesteps: 877,084,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 877084802...
Checkpoint 877084802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,660.14634
Policy Entropy: 3.59366
Value Function Loss: 0.08338

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.42873
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 21,698.17857
Overall Steps per Second: 10,662.60271

Timestep Collection Time: 2.30499
Timestep Consumption Time: 2.38561
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.69060

Cumulative Model Updates: 105,178
Cumulative Timesteps: 877,134,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,863.95789
Policy Entropy: 3.59700
Value Function Loss: 0.08582

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.48309
Value Function Update Magnitude: 0.57872

Collected Steps per Second: 21,866.35858
Overall Steps per Second: 10,658.39431

Timestep Collection Time: 2.28735
Timestep Consumption Time: 2.40529
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69264

Cumulative Model Updates: 105,184
Cumulative Timesteps: 877,184,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 877184832...
Checkpoint 877184832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,600.50334
Policy Entropy: 3.58567
Value Function Loss: 0.08925

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.63174
Value Function Update Magnitude: 0.53927

Collected Steps per Second: 21,722.33603
Overall Steps per Second: 10,585.10954

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.72834

Cumulative Model Updates: 105,190
Cumulative Timesteps: 877,234,882

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,178.72686
Policy Entropy: 3.57661
Value Function Loss: 0.09120

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.60856
Value Function Update Magnitude: 0.49458

Collected Steps per Second: 22,147.51150
Overall Steps per Second: 10,737.96937

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.39936
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.65749

Cumulative Model Updates: 105,196
Cumulative Timesteps: 877,284,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 877284894...
Checkpoint 877284894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,812.89968
Policy Entropy: 3.57527
Value Function Loss: 0.09226

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.43936
Value Function Update Magnitude: 0.49616

Collected Steps per Second: 21,566.02000
Overall Steps per Second: 10,370.06819

Timestep Collection Time: 2.32087
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.82658

Cumulative Model Updates: 105,202
Cumulative Timesteps: 877,334,946

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,260.82157
Policy Entropy: 3.56631
Value Function Loss: 0.09162

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.42346
Value Function Update Magnitude: 0.55288

Collected Steps per Second: 23,303.59956
Overall Steps per Second: 10,793.81867

Timestep Collection Time: 2.14748
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.63636

Cumulative Model Updates: 105,208
Cumulative Timesteps: 877,384,990

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 877384990...
Checkpoint 877384990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,982.89890
Policy Entropy: 3.57036
Value Function Loss: 0.08948

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.16620
Policy Update Magnitude: 0.41319
Value Function Update Magnitude: 0.54959

Collected Steps per Second: 22,709.82174
Overall Steps per Second: 10,683.94093

Timestep Collection Time: 2.20292
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.68254

Cumulative Model Updates: 105,214
Cumulative Timesteps: 877,435,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.17137
Policy Entropy: 3.58521
Value Function Loss: 0.08610

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.38968
Value Function Update Magnitude: 0.53674

Collected Steps per Second: 22,943.57627
Overall Steps per Second: 10,918.78088

Timestep Collection Time: 2.18048
Timestep Consumption Time: 2.40135
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.58183

Cumulative Model Updates: 105,220
Cumulative Timesteps: 877,485,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 877485046...
Checkpoint 877485046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,802.11729
Policy Entropy: 3.59429
Value Function Loss: 0.08043

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.45660
Value Function Update Magnitude: 0.56734

Collected Steps per Second: 22,786.85080
Overall Steps per Second: 10,762.88869

Timestep Collection Time: 2.19548
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.64819

Cumulative Model Updates: 105,226
Cumulative Timesteps: 877,535,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,917.97375
Policy Entropy: 3.61056
Value Function Loss: 0.07388

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.45322
Value Function Update Magnitude: 0.58322

Collected Steps per Second: 23,072.67885
Overall Steps per Second: 10,723.07950

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.66526

Cumulative Model Updates: 105,232
Cumulative Timesteps: 877,585,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 877585100...
Checkpoint 877585100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,869.32264
Policy Entropy: 3.62950
Value Function Loss: 0.07151

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.60614

Collected Steps per Second: 22,369.04600
Overall Steps per Second: 10,698.09437

Timestep Collection Time: 2.23747
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.67840

Cumulative Model Updates: 105,238
Cumulative Timesteps: 877,635,150

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,998.12704
Policy Entropy: 3.63689
Value Function Loss: 0.06914

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.53004
Value Function Update Magnitude: 0.66305

Collected Steps per Second: 22,887.43698
Overall Steps per Second: 10,842.16563

Timestep Collection Time: 2.18513
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.61273

Cumulative Model Updates: 105,244
Cumulative Timesteps: 877,685,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 877685162...
Checkpoint 877685162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,112.33833
Policy Entropy: 3.63494
Value Function Loss: 0.06847

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.74900

Collected Steps per Second: 22,178.93568
Overall Steps per Second: 10,712.19272

Timestep Collection Time: 2.25556
Timestep Consumption Time: 2.41444
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.67001

Cumulative Model Updates: 105,250
Cumulative Timesteps: 877,735,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.18127
Policy Entropy: 3.62587
Value Function Loss: 0.06868

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.76768

Collected Steps per Second: 22,603.21579
Overall Steps per Second: 10,654.27233

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.48217
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.69539

Cumulative Model Updates: 105,256
Cumulative Timesteps: 877,785,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 877785214...
Checkpoint 877785214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,919.17460
Policy Entropy: 3.61676
Value Function Loss: 0.07138

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.71326

Collected Steps per Second: 21,925.15582
Overall Steps per Second: 10,451.17826

Timestep Collection Time: 2.28094
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.78511

Cumulative Model Updates: 105,262
Cumulative Timesteps: 877,835,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,264.07732
Policy Entropy: 3.62249
Value Function Loss: 0.07501

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.51507
Value Function Update Magnitude: 0.74287

Collected Steps per Second: 23,092.04474
Overall Steps per Second: 10,800.77865

Timestep Collection Time: 2.16577
Timestep Consumption Time: 2.46464
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.63041

Cumulative Model Updates: 105,268
Cumulative Timesteps: 877,885,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 877885236...
Checkpoint 877885236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,698.89026
Policy Entropy: 3.61861
Value Function Loss: 0.07617

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.49245
Value Function Update Magnitude: 0.77077

Collected Steps per Second: 22,364.71328
Overall Steps per Second: 10,683.98897

Timestep Collection Time: 2.23566
Timestep Consumption Time: 2.44424
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.67990

Cumulative Model Updates: 105,274
Cumulative Timesteps: 877,935,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,372.91206
Policy Entropy: 3.61408
Value Function Loss: 0.07591

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06706
Policy Update Magnitude: 0.62056
Value Function Update Magnitude: 0.73170

Collected Steps per Second: 22,921.16005
Overall Steps per Second: 10,742.02693

Timestep Collection Time: 2.18270
Timestep Consumption Time: 2.47471
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.65741

Cumulative Model Updates: 105,280
Cumulative Timesteps: 877,985,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 877985266...
Checkpoint 877985266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,311.11133
Policy Entropy: 3.62259
Value Function Loss: 0.07659

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.68908
Value Function Update Magnitude: 0.71995

Collected Steps per Second: 22,803.64585
Overall Steps per Second: 10,819.55595

Timestep Collection Time: 2.19360
Timestep Consumption Time: 2.42970
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.62330

Cumulative Model Updates: 105,286
Cumulative Timesteps: 878,035,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,988.90737
Policy Entropy: 3.61557
Value Function Loss: 0.07673

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.58255
Value Function Update Magnitude: 0.69677

Collected Steps per Second: 22,978.34554
Overall Steps per Second: 10,855.79103

Timestep Collection Time: 2.17640
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60676

Cumulative Model Updates: 105,292
Cumulative Timesteps: 878,085,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 878085298...
Checkpoint 878085298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,592.38312
Policy Entropy: 3.62696
Value Function Loss: 0.08101

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.48133
Value Function Update Magnitude: 0.67717

Collected Steps per Second: 22,473.96830
Overall Steps per Second: 10,794.61727

Timestep Collection Time: 2.22515
Timestep Consumption Time: 2.40753
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.63268

Cumulative Model Updates: 105,298
Cumulative Timesteps: 878,135,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,488.41771
Policy Entropy: 3.60761
Value Function Loss: 0.08542

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.44447
Value Function Update Magnitude: 0.63715

Collected Steps per Second: 22,415.22378
Overall Steps per Second: 10,733.62273

Timestep Collection Time: 2.23152
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.66012

Cumulative Model Updates: 105,304
Cumulative Timesteps: 878,185,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 878185326...
Checkpoint 878185326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,501.64514
Policy Entropy: 3.60374
Value Function Loss: 0.08726

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.47775
Value Function Update Magnitude: 0.62180

Collected Steps per Second: 22,333.61300
Overall Steps per Second: 10,683.33015

Timestep Collection Time: 2.23994
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.68262

Cumulative Model Updates: 105,310
Cumulative Timesteps: 878,235,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,650.56290
Policy Entropy: 3.60068
Value Function Loss: 0.08639

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.58620
Value Function Update Magnitude: 0.65294

Collected Steps per Second: 22,413.92256
Overall Steps per Second: 10,549.91345

Timestep Collection Time: 2.23209
Timestep Consumption Time: 2.51012
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.74222

Cumulative Model Updates: 105,316
Cumulative Timesteps: 878,285,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 878285382...
Checkpoint 878285382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,352.67481
Policy Entropy: 3.59195
Value Function Loss: 0.08381

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.52647
Value Function Update Magnitude: 0.76424

Collected Steps per Second: 22,410.52856
Overall Steps per Second: 10,588.74080

Timestep Collection Time: 2.23234
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.72464

Cumulative Model Updates: 105,322
Cumulative Timesteps: 878,335,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,168.69951
Policy Entropy: 3.60317
Value Function Loss: 0.08106

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.46468
Value Function Update Magnitude: 0.81974

Collected Steps per Second: 23,119.89763
Overall Steps per Second: 10,837.66455

Timestep Collection Time: 2.16368
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.61575

Cumulative Model Updates: 105,328
Cumulative Timesteps: 878,385,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 878385434...
Checkpoint 878385434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,687.75412
Policy Entropy: 3.60607
Value Function Loss: 0.08264

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.60448
Value Function Update Magnitude: 0.86044

Collected Steps per Second: 22,756.39185
Overall Steps per Second: 10,682.38121

Timestep Collection Time: 2.19771
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.68173

Cumulative Model Updates: 105,334
Cumulative Timesteps: 878,435,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,256.38556
Policy Entropy: 3.61126
Value Function Loss: 0.08408

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.74226
Value Function Update Magnitude: 0.83739

Collected Steps per Second: 23,009.45003
Overall Steps per Second: 10,928.54196

Timestep Collection Time: 2.17380
Timestep Consumption Time: 2.40302
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.57682

Cumulative Model Updates: 105,340
Cumulative Timesteps: 878,485,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 878485464...
Checkpoint 878485464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,971.13752
Policy Entropy: 3.60292
Value Function Loss: 0.08778

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.69603
Value Function Update Magnitude: 0.77446

Collected Steps per Second: 22,293.97695
Overall Steps per Second: 10,672.92680

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.44277
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.68625

Cumulative Model Updates: 105,346
Cumulative Timesteps: 878,535,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,833.74667
Policy Entropy: 3.60587
Value Function Loss: 0.08761

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.53463
Value Function Update Magnitude: 0.72435

Collected Steps per Second: 23,061.29308
Overall Steps per Second: 10,850.03077

Timestep Collection Time: 2.16935
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61086

Cumulative Model Updates: 105,352
Cumulative Timesteps: 878,585,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 878585508...
Checkpoint 878585508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,316.42221
Policy Entropy: 3.61201
Value Function Loss: 0.08641

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.47168
Value Function Update Magnitude: 0.80424

Collected Steps per Second: 22,755.76085
Overall Steps per Second: 10,680.37535

Timestep Collection Time: 2.19812
Timestep Consumption Time: 2.48523
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.68336

Cumulative Model Updates: 105,358
Cumulative Timesteps: 878,635,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,956.92098
Policy Entropy: 3.61673
Value Function Loss: 0.08620

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.48918
Value Function Update Magnitude: 0.81801

Collected Steps per Second: 22,335.12963
Overall Steps per Second: 10,686.97949

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.68102

Cumulative Model Updates: 105,364
Cumulative Timesteps: 878,685,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 878685554...
Checkpoint 878685554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,832.96735
Policy Entropy: 3.62219
Value Function Loss: 0.08769

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.68105
Value Function Update Magnitude: 0.87306

Collected Steps per Second: 22,732.10808
Overall Steps per Second: 10,902.64023

Timestep Collection Time: 2.19971
Timestep Consumption Time: 2.38670
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.58641

Cumulative Model Updates: 105,370
Cumulative Timesteps: 878,735,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,188.97827
Policy Entropy: 3.61626
Value Function Loss: 0.09113

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.70711
Value Function Update Magnitude: 0.87711

Collected Steps per Second: 22,439.59489
Overall Steps per Second: 10,774.73466

Timestep Collection Time: 2.22910
Timestep Consumption Time: 2.41325
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.64234

Cumulative Model Updates: 105,376
Cumulative Timesteps: 878,785,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 878785578...
Checkpoint 878785578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,360.97314
Policy Entropy: 3.61623
Value Function Loss: 0.09265

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.62186
Value Function Update Magnitude: 0.84840

Collected Steps per Second: 22,386.34238
Overall Steps per Second: 10,678.09262

Timestep Collection Time: 2.23404
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.68361

Cumulative Model Updates: 105,382
Cumulative Timesteps: 878,835,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,996.23035
Policy Entropy: 3.60668
Value Function Loss: 0.09472

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.62744
Value Function Update Magnitude: 0.84869

Collected Steps per Second: 23,013.77477
Overall Steps per Second: 10,659.82751

Timestep Collection Time: 2.17339
Timestep Consumption Time: 2.51880
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.69220

Cumulative Model Updates: 105,388
Cumulative Timesteps: 878,885,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 878885608...
Checkpoint 878885608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,145.30736
Policy Entropy: 3.59361
Value Function Loss: 0.09027

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.84473

Collected Steps per Second: 22,813.66151
Overall Steps per Second: 10,857.75529

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.41459
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.60740

Cumulative Model Updates: 105,394
Cumulative Timesteps: 878,935,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.76579
Policy Entropy: 3.59703
Value Function Loss: 0.08892

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.51929
Value Function Update Magnitude: 0.87653

Collected Steps per Second: 22,432.69888
Overall Steps per Second: 10,520.44651

Timestep Collection Time: 2.22907
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.75303

Cumulative Model Updates: 105,400
Cumulative Timesteps: 878,985,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 878985638...
Checkpoint 878985638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,866.87167
Policy Entropy: 3.60849
Value Function Loss: 0.08376

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.54577
Value Function Update Magnitude: 0.87777

Collected Steps per Second: 22,754.76952
Overall Steps per Second: 10,702.01726

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.67575

Cumulative Model Updates: 105,406
Cumulative Timesteps: 879,035,678

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,488.12415
Policy Entropy: 3.61800
Value Function Loss: 0.08359

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.90211

Collected Steps per Second: 21,696.20267
Overall Steps per Second: 10,407.03673

Timestep Collection Time: 2.30529
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.80598

Cumulative Model Updates: 105,412
Cumulative Timesteps: 879,085,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 879085694...
Checkpoint 879085694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.13657
Policy Entropy: 3.62877
Value Function Loss: 0.08366

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.86411

Collected Steps per Second: 22,423.84172
Overall Steps per Second: 10,637.79398

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.47124
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.70173

Cumulative Model Updates: 105,418
Cumulative Timesteps: 879,135,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.88266
Policy Entropy: 3.61302
Value Function Loss: 0.08733

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.55396
Value Function Update Magnitude: 0.87461

Collected Steps per Second: 22,701.99900
Overall Steps per Second: 10,670.99639

Timestep Collection Time: 2.20333
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.68747

Cumulative Model Updates: 105,424
Cumulative Timesteps: 879,185,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 879185730...
Checkpoint 879185730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,004.16490
Policy Entropy: 3.59701
Value Function Loss: 0.08959

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.86402

Collected Steps per Second: 22,570.16031
Overall Steps per Second: 10,645.49194

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.48191
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.69758

Cumulative Model Updates: 105,430
Cumulative Timesteps: 879,235,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,797.82749
Policy Entropy: 3.57649
Value Function Loss: 0.09113

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.57009
Value Function Update Magnitude: 0.90197

Collected Steps per Second: 22,859.38686
Overall Steps per Second: 10,656.63761

Timestep Collection Time: 2.18895
Timestep Consumption Time: 2.50653
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69548

Cumulative Model Updates: 105,436
Cumulative Timesteps: 879,285,776

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 879285776...
Checkpoint 879285776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,618.58002
Policy Entropy: 3.58630
Value Function Loss: 0.09020

Mean KL Divergence: 0.03113
SB3 Clip Fraction: 0.21498
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.89935

Collected Steps per Second: 22,188.90254
Overall Steps per Second: 10,710.30192

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.67008

Cumulative Model Updates: 105,442
Cumulative Timesteps: 879,335,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,103.38307
Policy Entropy: 3.62427
Value Function Loss: 0.08917

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.18068
Policy Update Magnitude: 0.55204
Value Function Update Magnitude: 0.91370

Collected Steps per Second: 22,567.53968
Overall Steps per Second: 10,614.12567

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.49513
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.71070

Cumulative Model Updates: 105,448
Cumulative Timesteps: 879,385,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 879385794...
Checkpoint 879385794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,256.09257
Policy Entropy: 3.60793
Value Function Loss: 0.09090

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.52756
Value Function Update Magnitude: 0.77544

Collected Steps per Second: 23,007.57412
Overall Steps per Second: 10,604.04619

Timestep Collection Time: 2.17355
Timestep Consumption Time: 2.54239
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.71594

Cumulative Model Updates: 105,454
Cumulative Timesteps: 879,435,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.34417
Policy Entropy: 3.62674
Value Function Loss: 0.09533

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.48810
Value Function Update Magnitude: 0.71719

Collected Steps per Second: 22,900.53726
Overall Steps per Second: 10,723.14843

Timestep Collection Time: 2.18440
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.66505

Cumulative Model Updates: 105,460
Cumulative Timesteps: 879,485,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879485826...
Checkpoint 879485826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,808.19765
Policy Entropy: 3.60670
Value Function Loss: 0.09802

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.49972
Value Function Update Magnitude: 0.74868

Collected Steps per Second: 22,798.25075
Overall Steps per Second: 10,676.40059

Timestep Collection Time: 2.19376
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68454

Cumulative Model Updates: 105,466
Cumulative Timesteps: 879,535,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,880.02234
Policy Entropy: 3.59248
Value Function Loss: 0.09493

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.74457

Collected Steps per Second: 22,819.30387
Overall Steps per Second: 10,799.39274

Timestep Collection Time: 2.19227
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.63230

Cumulative Model Updates: 105,472
Cumulative Timesteps: 879,585,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 879585866...
Checkpoint 879585866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,921.29147
Policy Entropy: 3.58318
Value Function Loss: 0.09170

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.77062

Collected Steps per Second: 22,526.25034
Overall Steps per Second: 10,777.78218

Timestep Collection Time: 2.22034
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.64066

Cumulative Model Updates: 105,478
Cumulative Timesteps: 879,635,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,531.95963
Policy Entropy: 3.59031
Value Function Loss: 0.08504

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.64906
Value Function Update Magnitude: 0.78517

Collected Steps per Second: 23,212.57509
Overall Steps per Second: 10,921.27866

Timestep Collection Time: 2.15461
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.57950

Cumulative Model Updates: 105,484
Cumulative Timesteps: 879,685,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 879685896...
Checkpoint 879685896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,287.04884
Policy Entropy: 3.59905
Value Function Loss: 0.08610

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.55826
Value Function Update Magnitude: 0.78686

Collected Steps per Second: 22,225.55606
Overall Steps per Second: 10,626.73282

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.70512

Cumulative Model Updates: 105,490
Cumulative Timesteps: 879,735,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,916.02505
Policy Entropy: 3.60157
Value Function Loss: 0.08660

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.52654
Value Function Update Magnitude: 0.78866

Collected Steps per Second: 22,398.76101
Overall Steps per Second: 10,567.96772

Timestep Collection Time: 2.23253
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.73185

Cumulative Model Updates: 105,496
Cumulative Timesteps: 879,785,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 879785902...
Checkpoint 879785902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,741.30671
Policy Entropy: 3.59972
Value Function Loss: 0.08760

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.73517

Collected Steps per Second: 22,271.64554
Overall Steps per Second: 10,529.63416

Timestep Collection Time: 2.24689
Timestep Consumption Time: 2.50560
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.75249

Cumulative Model Updates: 105,502
Cumulative Timesteps: 879,835,944

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,962.04219
Policy Entropy: 3.60119
Value Function Loss: 0.08449

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.79105

Collected Steps per Second: 22,432.13002
Overall Steps per Second: 10,586.94367

Timestep Collection Time: 2.22939
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.72374

Cumulative Model Updates: 105,508
Cumulative Timesteps: 879,885,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 879885954...
Checkpoint 879885954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.59454
Policy Entropy: 3.60828
Value Function Loss: 0.08256

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.43904
Value Function Update Magnitude: 0.80493

Collected Steps per Second: 22,828.40380
Overall Steps per Second: 10,662.45957

Timestep Collection Time: 2.19043
Timestep Consumption Time: 2.49930
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.68972

Cumulative Model Updates: 105,514
Cumulative Timesteps: 879,935,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,169.70080
Policy Entropy: 3.60641
Value Function Loss: 0.08309

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11024
Policy Update Magnitude: 0.49404
Value Function Update Magnitude: 0.77552

Collected Steps per Second: 23,040.40384
Overall Steps per Second: 10,663.09241

Timestep Collection Time: 2.17114
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.69132

Cumulative Model Updates: 105,520
Cumulative Timesteps: 879,985,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879985982...
Checkpoint 879985982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,457.69082
Policy Entropy: 3.61090
Value Function Loss: 0.07999

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.75942

Collected Steps per Second: 22,681.44167
Overall Steps per Second: 10,700.47196

Timestep Collection Time: 2.20568
Timestep Consumption Time: 2.46963
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.67531

Cumulative Model Updates: 105,526
Cumulative Timesteps: 880,036,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,907.92375
Policy Entropy: 3.60674
Value Function Loss: 0.08109

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.78060

Collected Steps per Second: 22,732.19498
Overall Steps per Second: 10,818.59483

Timestep Collection Time: 2.20058
Timestep Consumption Time: 2.42331
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.62389

Cumulative Model Updates: 105,532
Cumulative Timesteps: 880,086,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 880086034...
Checkpoint 880086034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,533.21925
Policy Entropy: 3.60654
Value Function Loss: 0.07917

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.59293
Value Function Update Magnitude: 0.74766

Collected Steps per Second: 22,725.74148
Overall Steps per Second: 10,740.62633

Timestep Collection Time: 2.20112
Timestep Consumption Time: 2.45615
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.65727

Cumulative Model Updates: 105,538
Cumulative Timesteps: 880,136,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,004.47096
Policy Entropy: 3.61162
Value Function Loss: 0.08357

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.15502
Policy Update Magnitude: 0.51097
Value Function Update Magnitude: 0.67191

Collected Steps per Second: 22,800.55707
Overall Steps per Second: 10,826.60663

Timestep Collection Time: 2.19407
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62065

Cumulative Model Updates: 105,544
Cumulative Timesteps: 880,186,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 880186082...
Checkpoint 880186082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,501.93174
Policy Entropy: 3.61966
Value Function Loss: 0.08181

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.44858
Value Function Update Magnitude: 0.63251

Collected Steps per Second: 22,089.92567
Overall Steps per Second: 10,679.25899

Timestep Collection Time: 2.26429
Timestep Consumption Time: 2.41937
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.68366

Cumulative Model Updates: 105,550
Cumulative Timesteps: 880,236,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,623.17746
Policy Entropy: 3.60653
Value Function Loss: 0.08329

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.43060
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 21,955.82866
Overall Steps per Second: 10,676.35620

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.40604
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.68343

Cumulative Model Updates: 105,556
Cumulative Timesteps: 880,286,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 880286102...
Checkpoint 880286102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,408.16217
Policy Entropy: 3.59552
Value Function Loss: 0.08464

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.45364
Value Function Update Magnitude: 0.59000

Collected Steps per Second: 21,897.03700
Overall Steps per Second: 10,804.34042

Timestep Collection Time: 2.28451
Timestep Consumption Time: 2.34548
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.62999

Cumulative Model Updates: 105,562
Cumulative Timesteps: 880,336,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,183.85375
Policy Entropy: 3.59905
Value Function Loss: 0.08338

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.50529
Value Function Update Magnitude: 0.61513

Collected Steps per Second: 21,759.92025
Overall Steps per Second: 10,572.04621

Timestep Collection Time: 2.29826
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.73040

Cumulative Model Updates: 105,568
Cumulative Timesteps: 880,386,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 880386136...
Checkpoint 880386136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,982.20975
Policy Entropy: 3.61402
Value Function Loss: 0.08283

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06356
Policy Update Magnitude: 0.67182
Value Function Update Magnitude: 0.66299

Collected Steps per Second: 21,896.66027
Overall Steps per Second: 10,585.23156

Timestep Collection Time: 2.28382
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.72432

Cumulative Model Updates: 105,574
Cumulative Timesteps: 880,436,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,865.26475
Policy Entropy: 3.62863
Value Function Loss: 0.07875

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.79770
Value Function Update Magnitude: 0.70191

Collected Steps per Second: 22,457.28385
Overall Steps per Second: 10,870.79536

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.37332
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60003

Cumulative Model Updates: 105,580
Cumulative Timesteps: 880,486,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 880486150...
Checkpoint 880486150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,962.29238
Policy Entropy: 3.63146
Value Function Loss: 0.08056

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.69865
Value Function Update Magnitude: 0.69803

Collected Steps per Second: 22,283.80045
Overall Steps per Second: 10,732.01752

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.41643
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.66138

Cumulative Model Updates: 105,586
Cumulative Timesteps: 880,536,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,122.08391
Policy Entropy: 3.63296
Value Function Loss: 0.08157

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.68854

Collected Steps per Second: 22,368.88235
Overall Steps per Second: 10,775.65498

Timestep Collection Time: 2.23596
Timestep Consumption Time: 2.40561
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.64157

Cumulative Model Updates: 105,592
Cumulative Timesteps: 880,586,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 880586192...
Checkpoint 880586192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,163.15734
Policy Entropy: 3.62514
Value Function Loss: 0.08285

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.65836
Value Function Update Magnitude: 0.67496

Collected Steps per Second: 22,693.20632
Overall Steps per Second: 10,724.16523

Timestep Collection Time: 2.20418
Timestep Consumption Time: 2.46005
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.66423

Cumulative Model Updates: 105,598
Cumulative Timesteps: 880,636,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,195.46753
Policy Entropy: 3.60797
Value Function Loss: 0.08141

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.63618
Value Function Update Magnitude: 0.79773

Collected Steps per Second: 23,243.62338
Overall Steps per Second: 10,943.79556

Timestep Collection Time: 2.15130
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.56916

Cumulative Model Updates: 105,604
Cumulative Timesteps: 880,686,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 880686216...
Checkpoint 880686216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,117.63198
Policy Entropy: 3.60018
Value Function Loss: 0.08534

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.52949
Value Function Update Magnitude: 0.88831

Collected Steps per Second: 22,698.26203
Overall Steps per Second: 10,723.75091

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.46033
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.66367

Cumulative Model Updates: 105,610
Cumulative Timesteps: 880,736,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.81492
Policy Entropy: 3.61178
Value Function Loss: 0.08429

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.57968
Value Function Update Magnitude: 0.91609

Collected Steps per Second: 22,180.03621
Overall Steps per Second: 10,758.25611

Timestep Collection Time: 2.25446
Timestep Consumption Time: 2.39351
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.64797

Cumulative Model Updates: 105,616
Cumulative Timesteps: 880,786,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 880786232...
Checkpoint 880786232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.93296
Policy Entropy: 3.61311
Value Function Loss: 0.08318

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.51039
Value Function Update Magnitude: 0.90275

Collected Steps per Second: 22,086.66563
Overall Steps per Second: 10,753.43296

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.38615
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.65024

Cumulative Model Updates: 105,622
Cumulative Timesteps: 880,836,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.06499
Policy Entropy: 3.62044
Value Function Loss: 0.08063

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.47137
Value Function Update Magnitude: 0.87761

Collected Steps per Second: 22,787.18884
Overall Steps per Second: 10,825.98945

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62129

Cumulative Model Updates: 105,628
Cumulative Timesteps: 880,886,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 880886268...
Checkpoint 880886268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,656.19249
Policy Entropy: 3.62902
Value Function Loss: 0.07886

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.48552
Value Function Update Magnitude: 0.89315

Collected Steps per Second: 22,454.35763
Overall Steps per Second: 10,686.12174

Timestep Collection Time: 2.22754
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.68065

Cumulative Model Updates: 105,634
Cumulative Timesteps: 880,936,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,046.96937
Policy Entropy: 3.62223
Value Function Loss: 0.07819

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.51984
Value Function Update Magnitude: 0.77319

Collected Steps per Second: 22,464.86428
Overall Steps per Second: 10,760.86578

Timestep Collection Time: 2.22588
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.64684

Cumulative Model Updates: 105,640
Cumulative Timesteps: 880,986,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 880986290...
Checkpoint 880986290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,576.76978
Policy Entropy: 3.61601
Value Function Loss: 0.07683

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.71415

Collected Steps per Second: 22,399.92435
Overall Steps per Second: 10,702.80307

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.67429

Cumulative Model Updates: 105,646
Cumulative Timesteps: 881,036,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,371.78228
Policy Entropy: 3.62166
Value Function Loss: 0.07627

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.57912
Value Function Update Magnitude: 0.69207

Collected Steps per Second: 22,784.88464
Overall Steps per Second: 10,691.88257

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67701

Cumulative Model Updates: 105,652
Cumulative Timesteps: 881,086,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 881086324...
Checkpoint 881086324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.07165
Policy Entropy: 3.62379
Value Function Loss: 0.07219

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.57505
Value Function Update Magnitude: 0.73326

Collected Steps per Second: 22,895.45415
Overall Steps per Second: 10,862.01398

Timestep Collection Time: 2.18445
Timestep Consumption Time: 2.42004
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.60449

Cumulative Model Updates: 105,658
Cumulative Timesteps: 881,136,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,869.47275
Policy Entropy: 3.61254
Value Function Loss: 0.07074

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.64095
Value Function Update Magnitude: 0.75557

Collected Steps per Second: 22,240.19670
Overall Steps per Second: 10,495.87435

Timestep Collection Time: 2.24899
Timestep Consumption Time: 2.51650
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.76549

Cumulative Model Updates: 105,664
Cumulative Timesteps: 881,186,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 881186356...
Checkpoint 881186356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,814.24390
Policy Entropy: 3.60930
Value Function Loss: 0.07327

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.57328
Value Function Update Magnitude: 0.68412

Collected Steps per Second: 22,248.08887
Overall Steps per Second: 10,643.44520

Timestep Collection Time: 2.24828
Timestep Consumption Time: 2.45132
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.69961

Cumulative Model Updates: 105,670
Cumulative Timesteps: 881,236,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,851.81278
Policy Entropy: 3.60479
Value Function Loss: 0.07416

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.51095
Value Function Update Magnitude: 0.67048

Collected Steps per Second: 22,526.07600
Overall Steps per Second: 10,593.16494

Timestep Collection Time: 2.22089
Timestep Consumption Time: 2.50178
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.72267

Cumulative Model Updates: 105,676
Cumulative Timesteps: 881,286,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 881286404...
Checkpoint 881286404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,186.78430
Policy Entropy: 3.60466
Value Function Loss: 0.07558

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.50054
Value Function Update Magnitude: 0.66981

Collected Steps per Second: 22,560.43633
Overall Steps per Second: 10,527.78555

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.53408
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.75124

Cumulative Model Updates: 105,682
Cumulative Timesteps: 881,336,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.64973
Policy Entropy: 3.61424
Value Function Loss: 0.07753

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.50047
Value Function Update Magnitude: 0.60280

Collected Steps per Second: 22,753.91414
Overall Steps per Second: 10,787.10103

Timestep Collection Time: 2.19830
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.63702

Cumulative Model Updates: 105,688
Cumulative Timesteps: 881,386,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 881386444...
Checkpoint 881386444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,619.00507
Policy Entropy: 3.61638
Value Function Loss: 0.08001

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.47178
Value Function Update Magnitude: 0.57263

Collected Steps per Second: 22,794.61860
Overall Steps per Second: 10,730.07194

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.66222

Cumulative Model Updates: 105,694
Cumulative Timesteps: 881,436,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,194.47975
Policy Entropy: 3.60971
Value Function Loss: 0.08156

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.45427
Value Function Update Magnitude: 0.58175

Collected Steps per Second: 22,637.37093
Overall Steps per Second: 10,644.67989

Timestep Collection Time: 2.20953
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.69887

Cumulative Model Updates: 105,700
Cumulative Timesteps: 881,486,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 881486488...
Checkpoint 881486488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,493.22443
Policy Entropy: 3.61488
Value Function Loss: 0.07957

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.17548
Policy Update Magnitude: 0.39585
Value Function Update Magnitude: 0.64751

Collected Steps per Second: 22,751.74180
Overall Steps per Second: 10,833.29928

Timestep Collection Time: 2.19860
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.61743

Cumulative Model Updates: 105,706
Cumulative Timesteps: 881,536,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,964.65909
Policy Entropy: 3.61502
Value Function Loss: 0.07402

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.76118

Collected Steps per Second: 22,644.31425
Overall Steps per Second: 10,606.50454

Timestep Collection Time: 2.20806
Timestep Consumption Time: 2.50603
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.71409

Cumulative Model Updates: 105,712
Cumulative Timesteps: 881,586,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 881586510...
Checkpoint 881586510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,871.28025
Policy Entropy: 3.61685
Value Function Loss: 0.07454

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.62907
Value Function Update Magnitude: 0.80449

Collected Steps per Second: 22,709.34705
Overall Steps per Second: 10,641.60781

Timestep Collection Time: 2.20253
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.70023

Cumulative Model Updates: 105,718
Cumulative Timesteps: 881,636,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,718.26755
Policy Entropy: 3.61423
Value Function Loss: 0.07602

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.57610
Value Function Update Magnitude: 0.71822

Collected Steps per Second: 22,501.27102
Overall Steps per Second: 10,753.32721

Timestep Collection Time: 2.22263
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65084

Cumulative Model Updates: 105,724
Cumulative Timesteps: 881,686,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 881686540...
Checkpoint 881686540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,526.74309
Policy Entropy: 3.61570
Value Function Loss: 0.08155

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.58625

Collected Steps per Second: 22,190.54735
Overall Steps per Second: 10,665.46930

Timestep Collection Time: 2.25429
Timestep Consumption Time: 2.43598
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.69028

Cumulative Model Updates: 105,730
Cumulative Timesteps: 881,736,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.36438
Policy Entropy: 3.62164
Value Function Loss: 0.08358

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.45596
Value Function Update Magnitude: 0.54035

Collected Steps per Second: 22,554.09854
Overall Steps per Second: 10,613.19503

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.49452
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71168

Cumulative Model Updates: 105,736
Cumulative Timesteps: 881,786,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 881786570...
Checkpoint 881786570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,374.63484
Policy Entropy: 3.61459
Value Function Loss: 0.08349

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.51660
Value Function Update Magnitude: 0.54984

Collected Steps per Second: 22,163.65825
Overall Steps per Second: 10,527.23923

Timestep Collection Time: 2.25721
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.75224

Cumulative Model Updates: 105,742
Cumulative Timesteps: 881,836,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,859.41992
Policy Entropy: 3.62644
Value Function Loss: 0.08029

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.52217
Value Function Update Magnitude: 0.58224

Collected Steps per Second: 22,677.94440
Overall Steps per Second: 10,654.54380

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.69434

Cumulative Model Updates: 105,748
Cumulative Timesteps: 881,886,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 881886614...
Checkpoint 881886614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,018.17404
Policy Entropy: 3.64007
Value Function Loss: 0.07508

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.51703
Value Function Update Magnitude: 0.62694

Collected Steps per Second: 22,972.78472
Overall Steps per Second: 10,802.24696

Timestep Collection Time: 2.17718
Timestep Consumption Time: 2.45296
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.63015

Cumulative Model Updates: 105,754
Cumulative Timesteps: 881,936,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,204.28369
Policy Entropy: 3.65195
Value Function Loss: 0.07614

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.66303

Collected Steps per Second: 22,419.68070
Overall Steps per Second: 10,532.71262

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.51814
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.74939

Cumulative Model Updates: 105,760
Cumulative Timesteps: 881,986,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 881986654...
Checkpoint 881986654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,706.94730
Policy Entropy: 3.63937
Value Function Loss: 0.07761

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.70258
Value Function Update Magnitude: 0.64774

Collected Steps per Second: 22,719.23863
Overall Steps per Second: 10,622.77280

Timestep Collection Time: 2.20113
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.70762

Cumulative Model Updates: 105,766
Cumulative Timesteps: 882,036,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,394.70537
Policy Entropy: 3.62481
Value Function Loss: 0.08083

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.71634
Value Function Update Magnitude: 0.62910

Collected Steps per Second: 22,784.98662
Overall Steps per Second: 10,811.50737

Timestep Collection Time: 2.19460
Timestep Consumption Time: 2.43047
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62507

Cumulative Model Updates: 105,772
Cumulative Timesteps: 882,086,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 882086666...
Checkpoint 882086666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,224.26798
Policy Entropy: 3.61930
Value Function Loss: 0.08521

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.59655
Value Function Update Magnitude: 0.56355

Collected Steps per Second: 22,507.75586
Overall Steps per Second: 10,708.97009

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.67066

Cumulative Model Updates: 105,778
Cumulative Timesteps: 882,136,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,647.86308
Policy Entropy: 3.60798
Value Function Loss: 0.08847

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.18127
Policy Update Magnitude: 0.48424
Value Function Update Magnitude: 0.63843

Collected Steps per Second: 23,111.14035
Overall Steps per Second: 10,907.28671

Timestep Collection Time: 2.16458
Timestep Consumption Time: 2.42189
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.58648

Cumulative Model Updates: 105,784
Cumulative Timesteps: 882,186,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 882186710...
Checkpoint 882186710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,007.46735
Policy Entropy: 3.62097
Value Function Loss: 0.08729

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.15127
Policy Update Magnitude: 0.45553
Value Function Update Magnitude: 0.67117

Collected Steps per Second: 22,347.03675
Overall Steps per Second: 10,697.72574

Timestep Collection Time: 2.23788
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.67483

Cumulative Model Updates: 105,790
Cumulative Timesteps: 882,236,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,457.63862
Policy Entropy: 3.62021
Value Function Loss: 0.08377

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.66389

Collected Steps per Second: 22,877.05968
Overall Steps per Second: 10,842.96556

Timestep Collection Time: 2.18612
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61239

Cumulative Model Updates: 105,796
Cumulative Timesteps: 882,286,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 882286732...
Checkpoint 882286732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.33762
Policy Entropy: 3.62774
Value Function Loss: 0.08463

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.57319
Value Function Update Magnitude: 0.68186

Collected Steps per Second: 21,578.66475
Overall Steps per Second: 10,741.20081

Timestep Collection Time: 2.31896
Timestep Consumption Time: 2.33974
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.65870

Cumulative Model Updates: 105,802
Cumulative Timesteps: 882,336,772

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,098.04261
Policy Entropy: 3.63745
Value Function Loss: 0.08370

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.71517

Collected Steps per Second: 21,923.94589
Overall Steps per Second: 10,795.11056

Timestep Collection Time: 2.28189
Timestep Consumption Time: 2.35243
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.63432

Cumulative Model Updates: 105,808
Cumulative Timesteps: 882,386,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 882386800...
Checkpoint 882386800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,158.54743
Policy Entropy: 3.63392
Value Function Loss: 0.08403

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.52997
Value Function Update Magnitude: 0.69682

Collected Steps per Second: 22,103.81029
Overall Steps per Second: 10,714.35573

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.40478
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.66701

Cumulative Model Updates: 105,814
Cumulative Timesteps: 882,436,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,883.88203
Policy Entropy: 3.62656
Value Function Loss: 0.08157

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.48582
Value Function Update Magnitude: 0.77374

Collected Steps per Second: 22,236.50592
Overall Steps per Second: 10,605.95201

Timestep Collection Time: 2.24918
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.71565

Cumulative Model Updates: 105,820
Cumulative Timesteps: 882,486,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 882486818...
Checkpoint 882486818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,882.53171
Policy Entropy: 3.61038
Value Function Loss: 0.08498

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.50541
Value Function Update Magnitude: 0.74937

Collected Steps per Second: 22,899.38886
Overall Steps per Second: 10,877.11989

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.41363
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.59736

Cumulative Model Updates: 105,826
Cumulative Timesteps: 882,536,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,823.85515
Policy Entropy: 3.60093
Value Function Loss: 0.08613

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.50346
Value Function Update Magnitude: 0.74374

Collected Steps per Second: 23,103.73262
Overall Steps per Second: 10,934.60527

Timestep Collection Time: 2.16459
Timestep Consumption Time: 2.40897
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.57355

Cumulative Model Updates: 105,832
Cumulative Timesteps: 882,586,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 882586834...
Checkpoint 882586834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,728.08077
Policy Entropy: 3.59244
Value Function Loss: 0.08559

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.49577
Value Function Update Magnitude: 0.80396

Collected Steps per Second: 22,158.75648
Overall Steps per Second: 10,681.76054

Timestep Collection Time: 2.25690
Timestep Consumption Time: 2.42492
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.68181

Cumulative Model Updates: 105,838
Cumulative Timesteps: 882,636,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,276.05453
Policy Entropy: 3.59463
Value Function Loss: 0.08075

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.47281
Value Function Update Magnitude: 0.78391

Collected Steps per Second: 22,831.26184
Overall Steps per Second: 10,856.70817

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.41576
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.60600

Cumulative Model Updates: 105,844
Cumulative Timesteps: 882,686,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 882686850...
Checkpoint 882686850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,908.12566
Policy Entropy: 3.59590
Value Function Loss: 0.08050

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.49773
Value Function Update Magnitude: 0.75742

Collected Steps per Second: 22,252.03451
Overall Steps per Second: 10,666.05954

Timestep Collection Time: 2.24851
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.69095

Cumulative Model Updates: 105,850
Cumulative Timesteps: 882,736,884

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.26008
Policy Entropy: 3.59048
Value Function Loss: 0.08099

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.79132

Collected Steps per Second: 22,515.06481
Overall Steps per Second: 10,638.31439

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.70168

Cumulative Model Updates: 105,856
Cumulative Timesteps: 882,786,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 882786902...
Checkpoint 882786902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,506.99348
Policy Entropy: 3.58144
Value Function Loss: 0.08284

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.56264
Value Function Update Magnitude: 0.79312

Collected Steps per Second: 22,498.83202
Overall Steps per Second: 10,643.48716

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.47666
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.70015

Cumulative Model Updates: 105,862
Cumulative Timesteps: 882,836,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,902.15996
Policy Entropy: 3.57952
Value Function Loss: 0.08514

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.83079

Collected Steps per Second: 22,358.32992
Overall Steps per Second: 10,659.93598

Timestep Collection Time: 2.23684
Timestep Consumption Time: 2.45475
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.69159

Cumulative Model Updates: 105,868
Cumulative Timesteps: 882,886,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 882886940...
Checkpoint 882886940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,443.67303
Policy Entropy: 3.58422
Value Function Loss: 0.08667

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.46684
Value Function Update Magnitude: 0.74904

Collected Steps per Second: 21,810.28030
Overall Steps per Second: 10,642.54844

Timestep Collection Time: 2.29305
Timestep Consumption Time: 2.40620
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.69925

Cumulative Model Updates: 105,874
Cumulative Timesteps: 882,936,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,583.52165
Policy Entropy: 3.60055
Value Function Loss: 0.08351

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.60699
Value Function Update Magnitude: 0.73654

Collected Steps per Second: 22,328.39024
Overall Steps per Second: 10,526.75902

Timestep Collection Time: 2.23930
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.74980

Cumulative Model Updates: 105,880
Cumulative Timesteps: 882,986,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 882986952...
Checkpoint 882986952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,091.74492
Policy Entropy: 3.60339
Value Function Loss: 0.08052

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.67736
Value Function Update Magnitude: 0.77422

Collected Steps per Second: 22,322.76022
Overall Steps per Second: 10,643.83477

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.45907
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.70019

Cumulative Model Updates: 105,886
Cumulative Timesteps: 883,036,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,171.46050
Policy Entropy: 3.61978
Value Function Loss: 0.07717

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.16054
Policy Update Magnitude: 0.55904
Value Function Update Magnitude: 0.69967

Collected Steps per Second: 22,687.85028
Overall Steps per Second: 10,646.24141

Timestep Collection Time: 2.20462
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69818

Cumulative Model Updates: 105,892
Cumulative Timesteps: 883,086,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 883086998...
Checkpoint 883086998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,485.95296
Policy Entropy: 3.62255
Value Function Loss: 0.07981

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.52106
Value Function Update Magnitude: 0.71198

Collected Steps per Second: 23,009.88569
Overall Steps per Second: 10,780.77449

Timestep Collection Time: 2.17402
Timestep Consumption Time: 2.46609
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.64011

Cumulative Model Updates: 105,898
Cumulative Timesteps: 883,137,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,491.10096
Policy Entropy: 3.63872
Value Function Loss: 0.08133

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.76159

Collected Steps per Second: 22,708.21317
Overall Steps per Second: 10,623.52515

Timestep Collection Time: 2.20290
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.70879

Cumulative Model Updates: 105,904
Cumulative Timesteps: 883,187,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 883187046...
Checkpoint 883187046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.96953
Policy Entropy: 3.63546
Value Function Loss: 0.08127

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.72852
Value Function Update Magnitude: 0.77561

Collected Steps per Second: 22,944.83973
Overall Steps per Second: 10,744.23455

Timestep Collection Time: 2.18019
Timestep Consumption Time: 2.47571
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.65589

Cumulative Model Updates: 105,910
Cumulative Timesteps: 883,237,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.21916
Policy Entropy: 3.64706
Value Function Loss: 0.07881

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.77182
Value Function Update Magnitude: 0.88990

Collected Steps per Second: 23,280.62596
Overall Steps per Second: 10,716.63092

Timestep Collection Time: 2.14797
Timestep Consumption Time: 2.51824
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.66621

Cumulative Model Updates: 105,916
Cumulative Timesteps: 883,287,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 883287076...
Checkpoint 883287076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,634.81225
Policy Entropy: 3.65473
Value Function Loss: 0.07405

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.67371
Value Function Update Magnitude: 0.95293

Collected Steps per Second: 22,398.76412
Overall Steps per Second: 10,653.62971

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.69361

Cumulative Model Updates: 105,922
Cumulative Timesteps: 883,337,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.58906
Policy Entropy: 3.67368
Value Function Loss: 0.07241

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.62346
Value Function Update Magnitude: 0.92771

Collected Steps per Second: 22,952.09560
Overall Steps per Second: 10,875.60113

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.59929

Cumulative Model Updates: 105,928
Cumulative Timesteps: 883,387,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 883387100...
Checkpoint 883387100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,369.51465
Policy Entropy: 3.69404
Value Function Loss: 0.07076

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.57857
Value Function Update Magnitude: 0.94443

Collected Steps per Second: 22,226.80299
Overall Steps per Second: 10,723.96614

Timestep Collection Time: 2.24999
Timestep Consumption Time: 2.41340
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.66339

Cumulative Model Updates: 105,934
Cumulative Timesteps: 883,437,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,778.82159
Policy Entropy: 3.69198
Value Function Loss: 0.07000

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.65053
Value Function Update Magnitude: 0.96682

Collected Steps per Second: 22,737.79466
Overall Steps per Second: 10,915.20105

Timestep Collection Time: 2.19995
Timestep Consumption Time: 2.38283
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.58278

Cumulative Model Updates: 105,940
Cumulative Timesteps: 883,487,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 883487132...
Checkpoint 883487132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.52578
Policy Entropy: 3.69406
Value Function Loss: 0.06973

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.71589
Value Function Update Magnitude: 0.94812

Collected Steps per Second: 22,055.37412
Overall Steps per Second: 10,591.88274

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.45495
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.72324

Cumulative Model Updates: 105,946
Cumulative Timesteps: 883,537,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,362.90384
Policy Entropy: 3.68786
Value Function Loss: 0.07122

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.72364
Value Function Update Magnitude: 0.94799

Collected Steps per Second: 22,097.96408
Overall Steps per Second: 10,464.46829

Timestep Collection Time: 2.26292
Timestep Consumption Time: 2.51572
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.77865

Cumulative Model Updates: 105,952
Cumulative Timesteps: 883,587,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 883587166...
Checkpoint 883587166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,532.94883
Policy Entropy: 3.67795
Value Function Loss: 0.07217

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.76747
Value Function Update Magnitude: 0.86036

Collected Steps per Second: 22,629.66698
Overall Steps per Second: 10,636.61856

Timestep Collection Time: 2.21117
Timestep Consumption Time: 2.49315
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.70431

Cumulative Model Updates: 105,958
Cumulative Timesteps: 883,637,204

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040.30836
Policy Entropy: 3.68385
Value Function Loss: 0.07118

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.68778
Value Function Update Magnitude: 0.79229

Collected Steps per Second: 21,931.61055
Overall Steps per Second: 10,423.86732

Timestep Collection Time: 2.28018
Timestep Consumption Time: 2.51727
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.79745

Cumulative Model Updates: 105,964
Cumulative Timesteps: 883,687,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 883687212...
Checkpoint 883687212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.90203
Policy Entropy: 3.68817
Value Function Loss: 0.07166

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.64508
Value Function Update Magnitude: 0.70232

Collected Steps per Second: 22,724.23327
Overall Steps per Second: 10,639.21173

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70185

Cumulative Model Updates: 105,970
Cumulative Timesteps: 883,737,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,044.69878
Policy Entropy: 3.69589
Value Function Loss: 0.06855

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.66747
Value Function Update Magnitude: 0.76850

Collected Steps per Second: 22,569.31110
Overall Steps per Second: 10,603.64401

Timestep Collection Time: 2.21593
Timestep Consumption Time: 2.50056
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.71649

Cumulative Model Updates: 105,976
Cumulative Timesteps: 883,787,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 883787248...
Checkpoint 883787248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.40942
Policy Entropy: 3.70715
Value Function Loss: 0.06666

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.68876
Value Function Update Magnitude: 0.87183

Collected Steps per Second: 22,965.78179
Overall Steps per Second: 10,945.02766

Timestep Collection Time: 2.17776
Timestep Consumption Time: 2.39180
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.56956

Cumulative Model Updates: 105,982
Cumulative Timesteps: 883,837,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,323.78849
Policy Entropy: 3.69466
Value Function Loss: 0.06639

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.66217
Value Function Update Magnitude: 0.88102

Collected Steps per Second: 23,063.36603
Overall Steps per Second: 10,820.39094

Timestep Collection Time: 2.16907
Timestep Consumption Time: 2.45424
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62331

Cumulative Model Updates: 105,988
Cumulative Timesteps: 883,887,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 883887288...
Checkpoint 883887288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.35286
Policy Entropy: 3.69009
Value Function Loss: 0.06509

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.77881
Value Function Update Magnitude: 0.87202

Collected Steps per Second: 22,260.73206
Overall Steps per Second: 10,685.94606

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.68148

Cumulative Model Updates: 105,994
Cumulative Timesteps: 883,937,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,918.92598
Policy Entropy: 3.67291
Value Function Loss: 0.06681

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.84480
Value Function Update Magnitude: 0.84539

Collected Steps per Second: 22,180.59087
Overall Steps per Second: 10,545.63720

Timestep Collection Time: 2.25476
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.74244

Cumulative Model Updates: 106,000
Cumulative Timesteps: 883,987,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 883987326...
Checkpoint 883987326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,089.22300
Policy Entropy: 3.67319
Value Function Loss: 0.06457

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.79380
Value Function Update Magnitude: 0.85696

Collected Steps per Second: 22,305.36476
Overall Steps per Second: 10,641.38124

Timestep Collection Time: 2.24287
Timestep Consumption Time: 2.45840
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.70127

Cumulative Model Updates: 106,006
Cumulative Timesteps: 884,037,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.00810
Policy Entropy: 3.66741
Value Function Loss: 0.06881

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.78670
Value Function Update Magnitude: 0.85941

Collected Steps per Second: 22,667.86429
Overall Steps per Second: 10,791.41962

Timestep Collection Time: 2.20603
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.63387

Cumulative Model Updates: 106,012
Cumulative Timesteps: 884,087,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 884087360...
Checkpoint 884087360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.39470
Policy Entropy: 3.66457
Value Function Loss: 0.07149

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.79444
Value Function Update Magnitude: 0.86543

Collected Steps per Second: 22,398.28294
Overall Steps per Second: 10,697.20704

Timestep Collection Time: 2.23321
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.67599

Cumulative Model Updates: 106,018
Cumulative Timesteps: 884,137,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,586.50665
Policy Entropy: 3.65692
Value Function Loss: 0.07575

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.65165
Value Function Update Magnitude: 0.84255

Collected Steps per Second: 22,625.31787
Overall Steps per Second: 10,701.10103

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.46260
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.67260

Cumulative Model Updates: 106,024
Cumulative Timesteps: 884,187,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 884187382...
Checkpoint 884187382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,896.27113
Policy Entropy: 3.65473
Value Function Loss: 0.07514

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.80079

Collected Steps per Second: 22,936.36992
Overall Steps per Second: 10,829.19027

Timestep Collection Time: 2.18047
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61826

Cumulative Model Updates: 106,030
Cumulative Timesteps: 884,237,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,236.29305
Policy Entropy: 3.64823
Value Function Loss: 0.07735

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.72885

Collected Steps per Second: 22,375.50021
Overall Steps per Second: 10,511.02509

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.52303
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.75824

Cumulative Model Updates: 106,036
Cumulative Timesteps: 884,287,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 884287408...
Checkpoint 884287408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,751.59185
Policy Entropy: 3.64867
Value Function Loss: 0.07498

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.62812
Value Function Update Magnitude: 0.82165

Collected Steps per Second: 22,715.97547
Overall Steps per Second: 10,729.02091

Timestep Collection Time: 2.20206
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.66231

Cumulative Model Updates: 106,042
Cumulative Timesteps: 884,337,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,794.02246
Policy Entropy: 3.64209
Value Function Loss: 0.07395

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.66710
Value Function Update Magnitude: 0.85028

Collected Steps per Second: 23,042.20179
Overall Steps per Second: 10,822.34409

Timestep Collection Time: 2.17063
Timestep Consumption Time: 2.45092
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.62155

Cumulative Model Updates: 106,048
Cumulative Timesteps: 884,387,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 884387446...
Checkpoint 884387446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,627.09893
Policy Entropy: 3.64684
Value Function Loss: 0.07250

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.59599
Value Function Update Magnitude: 0.80995

Collected Steps per Second: 22,586.98366
Overall Steps per Second: 10,689.96802

Timestep Collection Time: 2.21437
Timestep Consumption Time: 2.46441
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.67878

Cumulative Model Updates: 106,054
Cumulative Timesteps: 884,437,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,673.72298
Policy Entropy: 3.64569
Value Function Loss: 0.07395

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.58732
Value Function Update Magnitude: 0.77242

Collected Steps per Second: 22,736.77387
Overall Steps per Second: 10,789.36467

Timestep Collection Time: 2.19926
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.63456

Cumulative Model Updates: 106,060
Cumulative Timesteps: 884,487,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 884487466...
Checkpoint 884487466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,054.00030
Policy Entropy: 3.64362
Value Function Loss: 0.07302

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.52114
Value Function Update Magnitude: 0.71418

Collected Steps per Second: 22,156.09059
Overall Steps per Second: 10,730.19146

Timestep Collection Time: 2.25762
Timestep Consumption Time: 2.40399
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.66161

Cumulative Model Updates: 106,066
Cumulative Timesteps: 884,537,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,557.38693
Policy Entropy: 3.64077
Value Function Loss: 0.07381

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.51673
Value Function Update Magnitude: 0.69045

Collected Steps per Second: 22,270.91561
Overall Steps per Second: 10,538.24659

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.74614

Cumulative Model Updates: 106,072
Cumulative Timesteps: 884,587,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 884587502...
Checkpoint 884587502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.51311
Policy Entropy: 3.65140
Value Function Loss: 0.07514

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.65285

Collected Steps per Second: 22,213.28725
Overall Steps per Second: 10,570.21811

Timestep Collection Time: 2.25208
Timestep Consumption Time: 2.48066
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.73273

Cumulative Model Updates: 106,078
Cumulative Timesteps: 884,637,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.21812
Policy Entropy: 3.65683
Value Function Loss: 0.07532

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.58726
Value Function Update Magnitude: 0.63589

Collected Steps per Second: 22,574.53427
Overall Steps per Second: 10,642.44119

Timestep Collection Time: 2.21524
Timestep Consumption Time: 2.48368
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.69892

Cumulative Model Updates: 106,084
Cumulative Timesteps: 884,687,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 884687536...
Checkpoint 884687536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,768.42896
Policy Entropy: 3.65947
Value Function Loss: 0.07437

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.58887
Value Function Update Magnitude: 0.68767

Collected Steps per Second: 22,569.10197
Overall Steps per Second: 10,592.00806

Timestep Collection Time: 2.21577
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.72130

Cumulative Model Updates: 106,090
Cumulative Timesteps: 884,737,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.59063
Policy Entropy: 3.65485
Value Function Loss: 0.07523

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.59056
Value Function Update Magnitude: 0.74204

Collected Steps per Second: 22,978.94907
Overall Steps per Second: 10,712.03058

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.49324
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.67045

Cumulative Model Updates: 106,096
Cumulative Timesteps: 884,787,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 884787574...
Checkpoint 884787574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,189.75402
Policy Entropy: 3.64087
Value Function Loss: 0.07642

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.50306
Value Function Update Magnitude: 0.74302

Collected Steps per Second: 21,495.18713
Overall Steps per Second: 10,309.46045

Timestep Collection Time: 2.32694
Timestep Consumption Time: 2.52472
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.85166

Cumulative Model Updates: 106,102
Cumulative Timesteps: 884,837,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,146.83660
Policy Entropy: 3.62475
Value Function Loss: 0.07892

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.51419
Value Function Update Magnitude: 0.68889

Collected Steps per Second: 23,002.25291
Overall Steps per Second: 10,791.94807

Timestep Collection Time: 2.17474
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.63531

Cumulative Model Updates: 106,108
Cumulative Timesteps: 884,887,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 884887616...
Checkpoint 884887616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,500.81557
Policy Entropy: 3.62945
Value Function Loss: 0.07731

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.57119
Value Function Update Magnitude: 0.78345

Collected Steps per Second: 22,767.49922
Overall Steps per Second: 10,696.75901

Timestep Collection Time: 2.19620
Timestep Consumption Time: 2.47830
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.67450

Cumulative Model Updates: 106,114
Cumulative Timesteps: 884,937,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,262.67406
Policy Entropy: 3.62327
Value Function Loss: 0.07753

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.50950
Value Function Update Magnitude: 0.80406

Collected Steps per Second: 22,830.29798
Overall Steps per Second: 10,919.07615

Timestep Collection Time: 2.19130
Timestep Consumption Time: 2.39041
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.58171

Cumulative Model Updates: 106,120
Cumulative Timesteps: 884,987,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 884987646...
Checkpoint 884987646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.82085
Policy Entropy: 3.63423
Value Function Loss: 0.08369

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.49037
Value Function Update Magnitude: 0.71084

Collected Steps per Second: 22,855.98213
Overall Steps per Second: 10,652.54531

Timestep Collection Time: 2.18779
Timestep Consumption Time: 2.50630
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.69409

Cumulative Model Updates: 106,126
Cumulative Timesteps: 885,037,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,976.19865
Policy Entropy: 3.62918
Value Function Loss: 0.08575

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.51136
Value Function Update Magnitude: 0.64221

Collected Steps per Second: 22,247.21014
Overall Steps per Second: 10,630.55773

Timestep Collection Time: 2.24873
Timestep Consumption Time: 2.45732
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.70606

Cumulative Model Updates: 106,132
Cumulative Timesteps: 885,087,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 885087678...
Checkpoint 885087678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,625.40023
Policy Entropy: 3.61935
Value Function Loss: 0.08779

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.55300
Value Function Update Magnitude: 0.60853

Collected Steps per Second: 22,413.53547
Overall Steps per Second: 10,637.69456

Timestep Collection Time: 2.23115
Timestep Consumption Time: 2.46987
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.70102

Cumulative Model Updates: 106,138
Cumulative Timesteps: 885,137,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,096.80136
Policy Entropy: 3.60660
Value Function Loss: 0.08954

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.63072
Value Function Update Magnitude: 0.59887

Collected Steps per Second: 22,310.87482
Overall Steps per Second: 10,721.43072

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.42366
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.66580

Cumulative Model Updates: 106,144
Cumulative Timesteps: 885,187,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 885187710...
Checkpoint 885187710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,546.83135
Policy Entropy: 3.60535
Value Function Loss: 0.08902

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.61119
Value Function Update Magnitude: 0.61873

Collected Steps per Second: 22,342.08055
Overall Steps per Second: 10,597.21447

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.48059
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.71879

Cumulative Model Updates: 106,150
Cumulative Timesteps: 885,237,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,884.52110
Policy Entropy: 3.60952
Value Function Loss: 0.08173

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.60864
Value Function Update Magnitude: 0.70601

Collected Steps per Second: 22,689.65342
Overall Steps per Second: 10,587.88368

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.51964
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.72408

Cumulative Model Updates: 106,156
Cumulative Timesteps: 885,287,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 885287734...
Checkpoint 885287734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.70761
Policy Entropy: 3.64468
Value Function Loss: 0.07467

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.63264
Value Function Update Magnitude: 0.74942

Collected Steps per Second: 23,051.83114
Overall Steps per Second: 10,895.65721

Timestep Collection Time: 2.17033
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.59174

Cumulative Model Updates: 106,162
Cumulative Timesteps: 885,337,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,224.54041
Policy Entropy: 3.64599
Value Function Loss: 0.07361

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15196
Policy Update Magnitude: 0.48272
Value Function Update Magnitude: 0.78360

Collected Steps per Second: 22,863.34348
Overall Steps per Second: 10,711.14351

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.66916

Cumulative Model Updates: 106,168
Cumulative Timesteps: 885,387,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 885387776...
Checkpoint 885387776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,162.30723
Policy Entropy: 3.65166
Value Function Loss: 0.07610

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.50612
Value Function Update Magnitude: 0.82972

Collected Steps per Second: 23,004.85060
Overall Steps per Second: 10,857.72841

Timestep Collection Time: 2.17398
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60612

Cumulative Model Updates: 106,174
Cumulative Timesteps: 885,437,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,984.62545
Policy Entropy: 3.62398
Value Function Loss: 0.07888

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.47516
Value Function Update Magnitude: 0.76347

Collected Steps per Second: 22,791.97816
Overall Steps per Second: 10,853.70487

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.41548
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61151

Cumulative Model Updates: 106,180
Cumulative Timesteps: 885,487,840

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 885487840...
Checkpoint 885487840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.16102
Policy Entropy: 3.62663
Value Function Loss: 0.08089

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.45400
Value Function Update Magnitude: 0.66085

Collected Steps per Second: 22,663.53966
Overall Steps per Second: 10,762.51775

Timestep Collection Time: 2.20654
Timestep Consumption Time: 2.43996
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.64650

Cumulative Model Updates: 106,186
Cumulative Timesteps: 885,537,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,325.85104
Policy Entropy: 3.62526
Value Function Loss: 0.08177

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.48427
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 22,671.46623
Overall Steps per Second: 10,809.27006

Timestep Collection Time: 2.20559
Timestep Consumption Time: 2.42044
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.62603

Cumulative Model Updates: 106,192
Cumulative Timesteps: 885,587,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 885587852...
Checkpoint 885587852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,372.09446
Policy Entropy: 3.63260
Value Function Loss: 0.08064

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.53291
Value Function Update Magnitude: 0.69886

Collected Steps per Second: 21,990.44616
Overall Steps per Second: 10,703.94336

Timestep Collection Time: 2.27490
Timestep Consumption Time: 2.39871
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.67360

Cumulative Model Updates: 106,198
Cumulative Timesteps: 885,637,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,967.32357
Policy Entropy: 3.63425
Value Function Loss: 0.07862

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.48358
Value Function Update Magnitude: 0.68818

Collected Steps per Second: 22,771.73629
Overall Steps per Second: 10,845.86185

Timestep Collection Time: 2.19623
Timestep Consumption Time: 2.41493
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61116

Cumulative Model Updates: 106,204
Cumulative Timesteps: 885,687,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 885687890...
Checkpoint 885687890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.15507
Policy Entropy: 3.62999
Value Function Loss: 0.07393

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.48666
Value Function Update Magnitude: 0.67437

Collected Steps per Second: 22,953.04110
Overall Steps per Second: 10,782.21767

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.46038
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.64005

Cumulative Model Updates: 106,210
Cumulative Timesteps: 885,737,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.46769
Policy Entropy: 3.63485
Value Function Loss: 0.07514

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.49578
Value Function Update Magnitude: 0.59250

Collected Steps per Second: 22,995.22559
Overall Steps per Second: 10,837.10506

Timestep Collection Time: 2.17541
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61599

Cumulative Model Updates: 106,216
Cumulative Timesteps: 885,787,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 885787944...
Checkpoint 885787944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.70269
Policy Entropy: 3.63388
Value Function Loss: 0.07355

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.47346
Value Function Update Magnitude: 0.46708

Collected Steps per Second: 22,538.02452
Overall Steps per Second: 10,679.07613

Timestep Collection Time: 2.21927
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.68374

Cumulative Model Updates: 106,222
Cumulative Timesteps: 885,837,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.26478
Policy Entropy: 3.62277
Value Function Loss: 0.07138

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.47332
Value Function Update Magnitude: 0.48159

Collected Steps per Second: 22,738.20412
Overall Steps per Second: 10,783.56855

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.43901
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.63910

Cumulative Model Updates: 106,228
Cumulative Timesteps: 885,887,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 885887988...
Checkpoint 885887988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,670.00907
Policy Entropy: 3.63370
Value Function Loss: 0.06236

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.42045
Value Function Update Magnitude: 0.60239

Collected Steps per Second: 22,562.29163
Overall Steps per Second: 10,784.92596

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.63888

Cumulative Model Updates: 106,234
Cumulative Timesteps: 885,938,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,497.88791
Policy Entropy: 3.64763
Value Function Loss: 0.05937

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.15870
Policy Update Magnitude: 0.43235
Value Function Update Magnitude: 0.61907

Collected Steps per Second: 22,601.26968
Overall Steps per Second: 10,674.67556

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.68586

Cumulative Model Updates: 106,240
Cumulative Timesteps: 885,988,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 885988038...
Checkpoint 885988038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,311.52295
Policy Entropy: 3.65815
Value Function Loss: 0.05952

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.47300
Value Function Update Magnitude: 0.52127

Collected Steps per Second: 22,218.11072
Overall Steps per Second: 10,775.78499

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.39038
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.64152

Cumulative Model Updates: 106,246
Cumulative Timesteps: 886,038,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834.58818
Policy Entropy: 3.67549
Value Function Loss: 0.05918

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.52128
Value Function Update Magnitude: 0.41050

Collected Steps per Second: 22,385.50957
Overall Steps per Second: 10,530.43930

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.51536
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.74966

Cumulative Model Updates: 106,252
Cumulative Timesteps: 886,088,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 886088070...
Checkpoint 886088070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,940.64917
Policy Entropy: 3.67287
Value Function Loss: 0.05887

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.49137
Value Function Update Magnitude: 0.39617

Collected Steps per Second: 22,086.41050
Overall Steps per Second: 10,661.45133

Timestep Collection Time: 2.26402
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.69017

Cumulative Model Updates: 106,258
Cumulative Timesteps: 886,138,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,844.63044
Policy Entropy: 3.68080
Value Function Loss: 0.06237

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.41344
Value Function Update Magnitude: 0.36034

Collected Steps per Second: 22,487.05477
Overall Steps per Second: 10,547.16491

Timestep Collection Time: 2.22484
Timestep Consumption Time: 2.51862
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.74345

Cumulative Model Updates: 106,264
Cumulative Timesteps: 886,188,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 886188104...
Checkpoint 886188104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,895.02003
Policy Entropy: 3.66519
Value Function Loss: 0.06380

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.37766
Value Function Update Magnitude: 0.38325

Collected Steps per Second: 22,487.23067
Overall Steps per Second: 10,595.53023

Timestep Collection Time: 2.22437
Timestep Consumption Time: 2.49649
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.72086

Cumulative Model Updates: 106,270
Cumulative Timesteps: 886,238,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.47870
Policy Entropy: 3.66697
Value Function Loss: 0.06093

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.37035
Value Function Update Magnitude: 0.36759

Collected Steps per Second: 22,934.23686
Overall Steps per Second: 10,797.16064

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.63196

Cumulative Model Updates: 106,276
Cumulative Timesteps: 886,288,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 886288136...
Checkpoint 886288136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.70259
Policy Entropy: 3.66927
Value Function Loss: 0.05631

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.42225
Value Function Update Magnitude: 0.42613

Collected Steps per Second: 23,031.03292
Overall Steps per Second: 10,675.62921

Timestep Collection Time: 2.17203
Timestep Consumption Time: 2.51379
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.68581

Cumulative Model Updates: 106,282
Cumulative Timesteps: 886,338,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.49080
Policy Entropy: 3.67950
Value Function Loss: 0.05286

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.40958
Value Function Update Magnitude: 0.56123

Collected Steps per Second: 22,795.30893
Overall Steps per Second: 10,879.18702

Timestep Collection Time: 2.19449
Timestep Consumption Time: 2.40365
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.59814

Cumulative Model Updates: 106,288
Cumulative Timesteps: 886,388,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 886388184...
Checkpoint 886388184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.87361
Policy Entropy: 3.68037
Value Function Loss: 0.05345

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.40199
Value Function Update Magnitude: 0.55153

Collected Steps per Second: 22,754.16998
Overall Steps per Second: 10,684.25254

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.48298
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68091

Cumulative Model Updates: 106,294
Cumulative Timesteps: 886,438,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,152.80034
Policy Entropy: 3.69149
Value Function Loss: 0.05191

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.43324
Value Function Update Magnitude: 0.53780

Collected Steps per Second: 22,657.23308
Overall Steps per Second: 10,839.81848

Timestep Collection Time: 2.20742
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61391

Cumulative Model Updates: 106,300
Cumulative Timesteps: 886,488,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 886488210...
Checkpoint 886488210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.27172
Policy Entropy: 3.68143
Value Function Loss: 0.05098

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.44344
Value Function Update Magnitude: 0.51971

Collected Steps per Second: 22,473.09569
Overall Steps per Second: 10,691.25341

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.45223
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.67747

Cumulative Model Updates: 106,306
Cumulative Timesteps: 886,538,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,947.17809
Policy Entropy: 3.69437
Value Function Loss: 0.04808

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.47723
Value Function Update Magnitude: 0.54405

Collected Steps per Second: 22,636.90982
Overall Steps per Second: 10,663.69598

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.68937

Cumulative Model Updates: 106,312
Cumulative Timesteps: 886,588,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 886588224...
Checkpoint 886588224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,756.41738
Policy Entropy: 3.69777
Value Function Loss: 0.05019

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.51807
Value Function Update Magnitude: 0.53572

Collected Steps per Second: 22,753.28177
Overall Steps per Second: 10,822.04194

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.42310
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62094

Cumulative Model Updates: 106,318
Cumulative Timesteps: 886,638,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.10446
Policy Entropy: 3.69335
Value Function Loss: 0.05092

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.52065
Value Function Update Magnitude: 0.56358

Collected Steps per Second: 22,468.46337
Overall Steps per Second: 10,629.69343

Timestep Collection Time: 2.22650
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.70625

Cumulative Model Updates: 106,324
Cumulative Timesteps: 886,688,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 886688258...
Checkpoint 886688258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.27828
Policy Entropy: 3.68639
Value Function Loss: 0.05335

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.54904
Value Function Update Magnitude: 0.53190

Collected Steps per Second: 22,643.30663
Overall Steps per Second: 10,588.16465

Timestep Collection Time: 2.20931
Timestep Consumption Time: 2.51540
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.72471

Cumulative Model Updates: 106,330
Cumulative Timesteps: 886,738,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.82965
Policy Entropy: 3.68256
Value Function Loss: 0.05562

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.60340
Value Function Update Magnitude: 0.50913

Collected Steps per Second: 22,844.60048
Overall Steps per Second: 10,913.64856

Timestep Collection Time: 2.18888
Timestep Consumption Time: 2.39291
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.58179

Cumulative Model Updates: 106,336
Cumulative Timesteps: 886,788,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 886788288...
Checkpoint 886788288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,357.43548
Policy Entropy: 3.68932
Value Function Loss: 0.05966

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.48703

Collected Steps per Second: 22,707.34618
Overall Steps per Second: 10,650.85620

Timestep Collection Time: 2.20264
Timestep Consumption Time: 2.49333
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.69596

Cumulative Model Updates: 106,342
Cumulative Timesteps: 886,838,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,216.71116
Policy Entropy: 3.69820
Value Function Loss: 0.06004

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.57971
Value Function Update Magnitude: 0.48489

Collected Steps per Second: 23,239.18135
Overall Steps per Second: 10,836.45049

Timestep Collection Time: 2.15240
Timestep Consumption Time: 2.46350
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.61590

Cumulative Model Updates: 106,348
Cumulative Timesteps: 886,888,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 886888324...
Checkpoint 886888324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.51653
Policy Entropy: 3.69450
Value Function Loss: 0.05965

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07021
Policy Update Magnitude: 0.69144
Value Function Update Magnitude: 0.54014

Collected Steps per Second: 22,496.84085
Overall Steps per Second: 10,652.27036

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.69646

Cumulative Model Updates: 106,354
Cumulative Timesteps: 886,938,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,899.96056
Policy Entropy: 3.69392
Value Function Loss: 0.06330

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.70681
Value Function Update Magnitude: 0.58648

Collected Steps per Second: 22,447.13128
Overall Steps per Second: 10,609.28528

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.48669
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.71530

Cumulative Model Updates: 106,360
Cumulative Timesteps: 886,988,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 886988378...
Checkpoint 886988378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,053.34733
Policy Entropy: 3.67719
Value Function Loss: 0.07096

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.59218
Value Function Update Magnitude: 0.60640

Collected Steps per Second: 22,514.73177
Overall Steps per Second: 10,571.42802

Timestep Collection Time: 2.22139
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.73105

Cumulative Model Updates: 106,366
Cumulative Timesteps: 887,038,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,578.10308
Policy Entropy: 3.68336
Value Function Loss: 0.07157

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.69544

Collected Steps per Second: 22,637.40577
Overall Steps per Second: 10,800.61706

Timestep Collection Time: 2.20953
Timestep Consumption Time: 2.42150
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.63103

Cumulative Model Updates: 106,372
Cumulative Timesteps: 887,088,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 887088410...
Checkpoint 887088410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,356.61778
Policy Entropy: 3.69695
Value Function Loss: 0.07133

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.51641
Value Function Update Magnitude: 0.74451

Collected Steps per Second: 22,862.78131
Overall Steps per Second: 10,666.66576

Timestep Collection Time: 2.18784
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.68938

Cumulative Model Updates: 106,378
Cumulative Timesteps: 887,138,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,689.03764
Policy Entropy: 3.69118
Value Function Loss: 0.07112

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.50450
Value Function Update Magnitude: 0.75054

Collected Steps per Second: 22,700.48904
Overall Steps per Second: 10,656.35293

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69598

Cumulative Model Updates: 106,384
Cumulative Timesteps: 887,188,472

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 887188472...
Checkpoint 887188472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,028.00593
Policy Entropy: 3.68264
Value Function Loss: 0.07258

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.49421
Value Function Update Magnitude: 0.66464

Collected Steps per Second: 22,797.72666
Overall Steps per Second: 10,821.21014

Timestep Collection Time: 2.19434
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.62296

Cumulative Model Updates: 106,390
Cumulative Timesteps: 887,238,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.80478
Policy Entropy: 3.65826
Value Function Loss: 0.07350

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.68238

Collected Steps per Second: 22,894.10519
Overall Steps per Second: 10,691.65972

Timestep Collection Time: 2.18397
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.67654

Cumulative Model Updates: 106,396
Cumulative Timesteps: 887,288,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 887288498...
Checkpoint 887288498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,352.20943
Policy Entropy: 3.66008
Value Function Loss: 0.07107

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.53239
Value Function Update Magnitude: 0.70250

Collected Steps per Second: 22,854.15338
Overall Steps per Second: 10,829.86468

Timestep Collection Time: 2.18901
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61945

Cumulative Model Updates: 106,402
Cumulative Timesteps: 887,338,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,705.74645
Policy Entropy: 3.65471
Value Function Loss: 0.06841

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.74750

Collected Steps per Second: 22,780.37679
Overall Steps per Second: 10,749.21287

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.45683
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.65188

Cumulative Model Updates: 106,408
Cumulative Timesteps: 887,388,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 887388530...
Checkpoint 887388530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,940.06578
Policy Entropy: 3.65076
Value Function Loss: 0.07004

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.64457
Value Function Update Magnitude: 0.75620

Collected Steps per Second: 22,503.30865
Overall Steps per Second: 10,594.67439

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.72162

Cumulative Model Updates: 106,414
Cumulative Timesteps: 887,438,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.06122
Policy Entropy: 3.64689
Value Function Loss: 0.07249

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.66200
Value Function Update Magnitude: 0.73121

Collected Steps per Second: 22,844.26910
Overall Steps per Second: 10,728.33120

Timestep Collection Time: 2.18917
Timestep Consumption Time: 2.47232
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.66149

Cumulative Model Updates: 106,420
Cumulative Timesteps: 887,488,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 887488564...
Checkpoint 887488564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,790.17312
Policy Entropy: 3.64692
Value Function Loss: 0.07593

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.76209

Collected Steps per Second: 22,252.87581
Overall Steps per Second: 10,697.57107

Timestep Collection Time: 2.24690
Timestep Consumption Time: 2.42706
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.67396

Cumulative Model Updates: 106,426
Cumulative Timesteps: 887,538,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,775.00455
Policy Entropy: 3.64177
Value Function Loss: 0.07776

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.52196
Value Function Update Magnitude: 0.72191

Collected Steps per Second: 22,500.54058
Overall Steps per Second: 10,598.55678

Timestep Collection Time: 2.22306
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.71951

Cumulative Model Updates: 106,432
Cumulative Timesteps: 887,588,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 887588584...
Checkpoint 887588584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,398.22897
Policy Entropy: 3.63594
Value Function Loss: 0.07998

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.51735
Value Function Update Magnitude: 0.77946

Collected Steps per Second: 22,963.71888
Overall Steps per Second: 10,664.55647

Timestep Collection Time: 2.17848
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.69087

Cumulative Model Updates: 106,438
Cumulative Timesteps: 887,638,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,373.35037
Policy Entropy: 3.62499
Value Function Loss: 0.08416

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.52280
Value Function Update Magnitude: 0.74055

Collected Steps per Second: 22,791.27171
Overall Steps per Second: 10,650.91820

Timestep Collection Time: 2.19400
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69481

Cumulative Model Updates: 106,444
Cumulative Timesteps: 887,688,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 887688614...
Checkpoint 887688614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,135.89434
Policy Entropy: 3.62238
Value Function Loss: 0.08605

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.55398
Value Function Update Magnitude: 0.62279

Collected Steps per Second: 22,859.63387
Overall Steps per Second: 10,675.22381

Timestep Collection Time: 2.18752
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68430

Cumulative Model Updates: 106,450
Cumulative Timesteps: 887,738,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,767.93155
Policy Entropy: 3.63523
Value Function Loss: 0.08494

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.51332
Value Function Update Magnitude: 0.55197

Collected Steps per Second: 23,040.50871
Overall Steps per Second: 10,865.66341

Timestep Collection Time: 2.17070
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60294

Cumulative Model Updates: 106,456
Cumulative Timesteps: 887,788,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 887788634...
Checkpoint 887788634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,607.46963
Policy Entropy: 3.63383
Value Function Loss: 0.08349

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06861
Policy Update Magnitude: 0.61862
Value Function Update Magnitude: 0.54292

Collected Steps per Second: 22,509.02993
Overall Steps per Second: 10,688.92766

Timestep Collection Time: 2.22311
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.68148

Cumulative Model Updates: 106,462
Cumulative Timesteps: 887,838,674

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,957.89658
Policy Entropy: 3.63558
Value Function Loss: 0.08508

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.71411
Value Function Update Magnitude: 0.55341

Collected Steps per Second: 23,154.14236
Overall Steps per Second: 10,875.52876

Timestep Collection Time: 2.16065
Timestep Consumption Time: 2.43940
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.60005

Cumulative Model Updates: 106,468
Cumulative Timesteps: 887,888,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 887888702...
Checkpoint 887888702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,457.60561
Policy Entropy: 3.62492
Value Function Loss: 0.08693

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.70338
Value Function Update Magnitude: 0.55903

Collected Steps per Second: 22,466.97886
Overall Steps per Second: 10,759.87839

Timestep Collection Time: 2.22611
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.64819

Cumulative Model Updates: 106,474
Cumulative Timesteps: 887,938,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,277.89136
Policy Entropy: 3.61985
Value Function Loss: 0.08797

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.61846
Value Function Update Magnitude: 0.58671

Collected Steps per Second: 22,676.26952
Overall Steps per Second: 10,799.22608

Timestep Collection Time: 2.20557
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.63126

Cumulative Model Updates: 106,480
Cumulative Timesteps: 887,988,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 887988730...
Checkpoint 887988730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,605.76316
Policy Entropy: 3.61940
Value Function Loss: 0.08902

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.54168
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 22,320.04110
Overall Steps per Second: 10,712.98491

Timestep Collection Time: 2.24104
Timestep Consumption Time: 2.42806
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.66910

Cumulative Model Updates: 106,486
Cumulative Timesteps: 888,038,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,118.93971
Policy Entropy: 3.62696
Value Function Loss: 0.09235

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.56444

Collected Steps per Second: 22,726.78743
Overall Steps per Second: 10,786.24349

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.63776

Cumulative Model Updates: 106,492
Cumulative Timesteps: 888,088,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 888088774...
Checkpoint 888088774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,649.83586
Policy Entropy: 3.62184
Value Function Loss: 0.09251

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.57602
Value Function Update Magnitude: 0.58617

Collected Steps per Second: 22,418.11277
Overall Steps per Second: 10,645.52818

Timestep Collection Time: 2.23105
Timestep Consumption Time: 2.46726
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.69831

Cumulative Model Updates: 106,498
Cumulative Timesteps: 888,138,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,303.28550
Policy Entropy: 3.62704
Value Function Loss: 0.08984

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.53090
Value Function Update Magnitude: 0.58873

Collected Steps per Second: 22,987.29984
Overall Steps per Second: 10,682.60135

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.50539
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68051

Cumulative Model Updates: 106,504
Cumulative Timesteps: 888,188,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 888188790...
Checkpoint 888188790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,361.12269
Policy Entropy: 3.61538
Value Function Loss: 0.08690

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.53115
Value Function Update Magnitude: 0.56886

Collected Steps per Second: 23,090.28914
Overall Steps per Second: 10,881.12579

Timestep Collection Time: 2.16611
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.59658

Cumulative Model Updates: 106,510
Cumulative Timesteps: 888,238,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,446.64140
Policy Entropy: 3.62718
Value Function Loss: 0.08722

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.57004
Value Function Update Magnitude: 0.54926

Collected Steps per Second: 22,871.93013
Overall Steps per Second: 10,677.89745

Timestep Collection Time: 2.18644
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.68332

Cumulative Model Updates: 106,516
Cumulative Timesteps: 888,288,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 888288814...
Checkpoint 888288814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.22180
Policy Entropy: 3.61816
Value Function Loss: 0.08984

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.60229
Value Function Update Magnitude: 0.58802

Collected Steps per Second: 23,227.08259
Overall Steps per Second: 10,899.03954

Timestep Collection Time: 2.15266
Timestep Consumption Time: 2.43490
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.58756

Cumulative Model Updates: 106,522
Cumulative Timesteps: 888,338,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,568.93909
Policy Entropy: 3.61526
Value Function Loss: 0.09118

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.62540
Value Function Update Magnitude: 0.59922

Collected Steps per Second: 22,831.82229
Overall Steps per Second: 10,737.02567

Timestep Collection Time: 2.19124
Timestep Consumption Time: 2.46834
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.65958

Cumulative Model Updates: 106,528
Cumulative Timesteps: 888,388,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 888388844...
Checkpoint 888388844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,551.96883
Policy Entropy: 3.60127
Value Function Loss: 0.09120

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.55457

Collected Steps per Second: 22,523.12995
Overall Steps per Second: 10,791.83865

Timestep Collection Time: 2.22101
Timestep Consumption Time: 2.41435
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.63535

Cumulative Model Updates: 106,534
Cumulative Timesteps: 888,438,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.46544
Policy Entropy: 3.60236
Value Function Loss: 0.08997

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.48427
Value Function Update Magnitude: 0.57689

Collected Steps per Second: 22,398.19596
Overall Steps per Second: 10,553.36657

Timestep Collection Time: 2.23286
Timestep Consumption Time: 2.50610
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.73896

Cumulative Model Updates: 106,540
Cumulative Timesteps: 888,488,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 888488880...
Checkpoint 888488880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,246.12828
Policy Entropy: 3.59590
Value Function Loss: 0.08882

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.48016
Value Function Update Magnitude: 0.61537

Collected Steps per Second: 22,402.03823
Overall Steps per Second: 10,605.04287

Timestep Collection Time: 2.23221
Timestep Consumption Time: 2.48310
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.71530

Cumulative Model Updates: 106,546
Cumulative Timesteps: 888,538,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,080.25490
Policy Entropy: 3.60625
Value Function Loss: 0.08935

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.62457

Collected Steps per Second: 22,425.63268
Overall Steps per Second: 10,577.51072

Timestep Collection Time: 2.22959
Timestep Consumption Time: 2.49742
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.72701

Cumulative Model Updates: 106,552
Cumulative Timesteps: 888,588,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 888588886...
Checkpoint 888588886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,390.38629
Policy Entropy: 3.59394
Value Function Loss: 0.09266

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.53145
Value Function Update Magnitude: 0.66439

Collected Steps per Second: 22,392.38201
Overall Steps per Second: 10,567.47881

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.73453

Cumulative Model Updates: 106,558
Cumulative Timesteps: 888,638,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,802.03478
Policy Entropy: 3.59331
Value Function Loss: 0.09540

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.53992
Value Function Update Magnitude: 0.69347

Collected Steps per Second: 22,246.58572
Overall Steps per Second: 10,499.24780

Timestep Collection Time: 2.24772
Timestep Consumption Time: 2.51491
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.76263

Cumulative Model Updates: 106,564
Cumulative Timesteps: 888,688,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 888688922...
Checkpoint 888688922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,622.52853
Policy Entropy: 3.59099
Value Function Loss: 0.09443

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.79288

Collected Steps per Second: 22,533.19850
Overall Steps per Second: 10,690.72563

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.45938
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.67957

Cumulative Model Updates: 106,570
Cumulative Timesteps: 888,738,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,050.52759
Policy Entropy: 3.60069
Value Function Loss: 0.09022

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.77001

Collected Steps per Second: 22,274.15705
Overall Steps per Second: 10,692.63024

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.67724

Cumulative Model Updates: 106,576
Cumulative Timesteps: 888,788,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 888788962...
Checkpoint 888788962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,575.48527
Policy Entropy: 3.60052
Value Function Loss: 0.08952

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.58380
Value Function Update Magnitude: 0.71450

Collected Steps per Second: 22,653.48524
Overall Steps per Second: 10,761.63263

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.64744

Cumulative Model Updates: 106,582
Cumulative Timesteps: 888,838,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,213.95921
Policy Entropy: 3.58950
Value Function Loss: 0.09198

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.57843
Value Function Update Magnitude: 0.63500

Collected Steps per Second: 23,167.79345
Overall Steps per Second: 10,813.66030

Timestep Collection Time: 2.16007
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.62785

Cumulative Model Updates: 106,588
Cumulative Timesteps: 888,889,020

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 888889020...
Checkpoint 888889020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,375.81057
Policy Entropy: 3.58002
Value Function Loss: 0.09037

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.68221

Collected Steps per Second: 23,074.90030
Overall Steps per Second: 10,719.98783

Timestep Collection Time: 2.16686
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66418

Cumulative Model Updates: 106,594
Cumulative Timesteps: 888,939,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,938.18300
Policy Entropy: 3.56252
Value Function Loss: 0.09119

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.18162
Policy Update Magnitude: 0.48943
Value Function Update Magnitude: 0.58961

Collected Steps per Second: 22,707.29786
Overall Steps per Second: 10,787.08813

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.43353
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.63573

Cumulative Model Updates: 106,600
Cumulative Timesteps: 888,989,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 888989026...
Checkpoint 888989026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,030.19160
Policy Entropy: 3.57496
Value Function Loss: 0.08987

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.47995
Value Function Update Magnitude: 0.69203

Collected Steps per Second: 22,933.96320
Overall Steps per Second: 10,763.10538

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.46562
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.64606

Cumulative Model Updates: 106,606
Cumulative Timesteps: 889,039,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,590.54311
Policy Entropy: 3.57078
Value Function Loss: 0.09066

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.54742
Value Function Update Magnitude: 0.80660

Collected Steps per Second: 22,904.84765
Overall Steps per Second: 10,826.65482

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.61916

Cumulative Model Updates: 106,612
Cumulative Timesteps: 889,089,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 889089042...
Checkpoint 889089042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,025.14863
Policy Entropy: 3.58209
Value Function Loss: 0.08911

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.68514

Collected Steps per Second: 22,421.71361
Overall Steps per Second: 10,768.24341

Timestep Collection Time: 2.23096
Timestep Consumption Time: 2.41436
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.64533

Cumulative Model Updates: 106,618
Cumulative Timesteps: 889,139,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,843.40002
Policy Entropy: 3.57830
Value Function Loss: 0.09092

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.62134
Value Function Update Magnitude: 0.70415

Collected Steps per Second: 22,424.46624
Overall Steps per Second: 10,609.60910

Timestep Collection Time: 2.23105
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.71554

Cumulative Model Updates: 106,624
Cumulative Timesteps: 889,189,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 889189094...
Checkpoint 889189094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,557.37170
Policy Entropy: 3.58174
Value Function Loss: 0.08911

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.56245
Value Function Update Magnitude: 0.68480

Collected Steps per Second: 21,939.75354
Overall Steps per Second: 10,461.66505

Timestep Collection Time: 2.27979
Timestep Consumption Time: 2.50129
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.78107

Cumulative Model Updates: 106,630
Cumulative Timesteps: 889,239,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,521.67026
Policy Entropy: 3.58526
Value Function Loss: 0.09176

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.73637

Collected Steps per Second: 22,603.71267
Overall Steps per Second: 10,764.08494

Timestep Collection Time: 2.21247
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.64601

Cumulative Model Updates: 106,636
Cumulative Timesteps: 889,289,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 889289122...
Checkpoint 889289122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,463.44394
Policy Entropy: 3.57305
Value Function Loss: 0.08933

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.63266
Value Function Update Magnitude: 0.68244

Collected Steps per Second: 22,128.51857
Overall Steps per Second: 10,646.80410

Timestep Collection Time: 2.26034
Timestep Consumption Time: 2.43759
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.69794

Cumulative Model Updates: 106,642
Cumulative Timesteps: 889,339,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,654.19681
Policy Entropy: 3.57059
Value Function Loss: 0.09280

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15556
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.68956

Collected Steps per Second: 22,984.86621
Overall Steps per Second: 10,615.69345

Timestep Collection Time: 2.17534
Timestep Consumption Time: 2.53466
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.71001

Cumulative Model Updates: 106,648
Cumulative Timesteps: 889,389,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 889389140...
Checkpoint 889389140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.22735
Policy Entropy: 3.57657
Value Function Loss: 0.08740

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.49758
Value Function Update Magnitude: 0.65231

Collected Steps per Second: 22,166.02661
Overall Steps per Second: 10,547.02140

Timestep Collection Time: 2.25625
Timestep Consumption Time: 2.48557
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.74181

Cumulative Model Updates: 106,654
Cumulative Timesteps: 889,439,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,341.54805
Policy Entropy: 3.58395
Value Function Loss: 0.08573

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.47751
Value Function Update Magnitude: 0.62684

Collected Steps per Second: 23,145.83058
Overall Steps per Second: 10,867.98056

Timestep Collection Time: 2.16143
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60325

Cumulative Model Updates: 106,660
Cumulative Timesteps: 889,489,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 889489180...
Checkpoint 889489180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,340.64810
Policy Entropy: 3.59331
Value Function Loss: 0.08231

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.54887
Value Function Update Magnitude: 0.60488

Collected Steps per Second: 22,568.52823
Overall Steps per Second: 10,644.65010

Timestep Collection Time: 2.21663
Timestep Consumption Time: 2.48301
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.69964

Cumulative Model Updates: 106,666
Cumulative Timesteps: 889,539,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,336.99951
Policy Entropy: 3.58701
Value Function Loss: 0.08621

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.64052
Value Function Update Magnitude: 0.62379

Collected Steps per Second: 22,920.69170
Overall Steps per Second: 10,724.04379

Timestep Collection Time: 2.18274
Timestep Consumption Time: 2.48247
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.66522

Cumulative Model Updates: 106,672
Cumulative Timesteps: 889,589,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 889589236...
Checkpoint 889589236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,181.44815
Policy Entropy: 3.58165
Value Function Loss: 0.09000

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.71484
Value Function Update Magnitude: 0.60506

Collected Steps per Second: 22,896.50491
Overall Steps per Second: 10,859.86187

Timestep Collection Time: 2.18479
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60632

Cumulative Model Updates: 106,678
Cumulative Timesteps: 889,639,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,709.77937
Policy Entropy: 3.58873
Value Function Loss: 0.09264

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.67856
Value Function Update Magnitude: 0.64275

Collected Steps per Second: 22,257.42033
Overall Steps per Second: 10,522.91143

Timestep Collection Time: 2.24671
Timestep Consumption Time: 2.50540
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.75211

Cumulative Model Updates: 106,684
Cumulative Timesteps: 889,689,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 889689266...
Checkpoint 889689266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,711.05750
Policy Entropy: 3.59153
Value Function Loss: 0.09229

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.70537
Value Function Update Magnitude: 0.65608

Collected Steps per Second: 22,344.08724
Overall Steps per Second: 10,561.39580

Timestep Collection Time: 2.23809
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.73498

Cumulative Model Updates: 106,690
Cumulative Timesteps: 889,739,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,618.31679
Policy Entropy: 3.58377
Value Function Loss: 0.09226

Mean KL Divergence: 0.02533
SB3 Clip Fraction: 0.19783
Policy Update Magnitude: 0.58900
Value Function Update Magnitude: 0.73743

Collected Steps per Second: 22,842.72933
Overall Steps per Second: 10,828.49953

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.61781

Cumulative Model Updates: 106,696
Cumulative Timesteps: 889,789,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 889789278...
Checkpoint 889789278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,043.22308
Policy Entropy: 3.58159
Value Function Loss: 0.09033

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.15428
Policy Update Magnitude: 0.51228
Value Function Update Magnitude: 0.83051

Collected Steps per Second: 22,594.66617
Overall Steps per Second: 10,684.69251

Timestep Collection Time: 2.21318
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.68015

Cumulative Model Updates: 106,702
Cumulative Timesteps: 889,839,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,768.05977
Policy Entropy: 3.56801
Value Function Loss: 0.08975

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.82128

Collected Steps per Second: 23,054.40384
Overall Steps per Second: 10,845.30734

Timestep Collection Time: 2.16956
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61195

Cumulative Model Updates: 106,708
Cumulative Timesteps: 889,889,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 889889302...
Checkpoint 889889302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,628.69969
Policy Entropy: 3.56647
Value Function Loss: 0.08884

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.72347

Collected Steps per Second: 22,939.05837
Overall Steps per Second: 10,731.34282

Timestep Collection Time: 2.17986
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.65962

Cumulative Model Updates: 106,714
Cumulative Timesteps: 889,939,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,905.69052
Policy Entropy: 3.55022
Value Function Loss: 0.09128

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.17433
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.75306

Collected Steps per Second: 23,023.44583
Overall Steps per Second: 10,873.45526

Timestep Collection Time: 2.17292
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.60093

Cumulative Model Updates: 106,720
Cumulative Timesteps: 889,989,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 889989334...
Checkpoint 889989334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,807.72600
Policy Entropy: 3.55767
Value Function Loss: 0.08483

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.16614
Policy Update Magnitude: 0.43959
Value Function Update Magnitude: 0.80377

Collected Steps per Second: 21,940.39853
Overall Steps per Second: 10,721.13458

Timestep Collection Time: 2.27927
Timestep Consumption Time: 2.38517
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.66443

Cumulative Model Updates: 106,726
Cumulative Timesteps: 890,039,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,132.07281
Policy Entropy: 3.56425
Value Function Loss: 0.08359

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.47826
Value Function Update Magnitude: 0.84330

Collected Steps per Second: 21,933.54733
Overall Steps per Second: 10,782.33761

Timestep Collection Time: 2.28089
Timestep Consumption Time: 2.35892
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.63981

Cumulative Model Updates: 106,732
Cumulative Timesteps: 890,089,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 890089370...
Checkpoint 890089370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,223.74491
Policy Entropy: 3.56303
Value Function Loss: 0.08241

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.50711
Value Function Update Magnitude: 0.83030

Collected Steps per Second: 21,562.19532
Overall Steps per Second: 10,691.26872

Timestep Collection Time: 2.31897
Timestep Consumption Time: 2.35793
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.67690

Cumulative Model Updates: 106,738
Cumulative Timesteps: 890,139,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,593.63662
Policy Entropy: 3.55936
Value Function Loss: 0.09037

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.47950
Value Function Update Magnitude: 0.64062

Collected Steps per Second: 21,834.81692
Overall Steps per Second: 10,612.83939

Timestep Collection Time: 2.29093
Timestep Consumption Time: 2.42242
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.71335

Cumulative Model Updates: 106,744
Cumulative Timesteps: 890,189,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 890189394...
Checkpoint 890189394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,905.79515
Policy Entropy: 3.55588
Value Function Loss: 0.09636

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.52461
Value Function Update Magnitude: 0.59426

Collected Steps per Second: 21,861.43521
Overall Steps per Second: 10,647.41997

Timestep Collection Time: 2.28805
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.69785

Cumulative Model Updates: 106,750
Cumulative Timesteps: 890,239,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,589.83275
Policy Entropy: 3.56842
Value Function Loss: 0.09895

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.50586
Value Function Update Magnitude: 0.54730

Collected Steps per Second: 21,866.45268
Overall Steps per Second: 10,512.26237

Timestep Collection Time: 2.28697
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.75711

Cumulative Model Updates: 106,756
Cumulative Timesteps: 890,289,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 890289422...
Checkpoint 890289422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,530.74372
Policy Entropy: 3.55741
Value Function Loss: 0.09743

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.50851
Value Function Update Magnitude: 0.56740

Collected Steps per Second: 22,605.35179
Overall Steps per Second: 10,678.62057

Timestep Collection Time: 2.21187
Timestep Consumption Time: 2.47039
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68225

Cumulative Model Updates: 106,762
Cumulative Timesteps: 890,339,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,691.44509
Policy Entropy: 3.57875
Value Function Loss: 0.09424

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.49777
Value Function Update Magnitude: 0.57071

Collected Steps per Second: 23,076.11570
Overall Steps per Second: 10,666.23039

Timestep Collection Time: 2.16752
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.68938

Cumulative Model Updates: 106,768
Cumulative Timesteps: 890,389,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 890389440...
Checkpoint 890389440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,720.88010
Policy Entropy: 3.57599
Value Function Loss: 0.09207

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.48444
Value Function Update Magnitude: 0.62495

Collected Steps per Second: 22,739.25488
Overall Steps per Second: 10,703.85086

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.67178

Cumulative Model Updates: 106,774
Cumulative Timesteps: 890,439,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,393.75236
Policy Entropy: 3.58684
Value Function Loss: 0.09325

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.49178
Value Function Update Magnitude: 0.57634

Collected Steps per Second: 23,312.04344
Overall Steps per Second: 10,839.67181

Timestep Collection Time: 2.14507
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.61324

Cumulative Model Updates: 106,780
Cumulative Timesteps: 890,489,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 890489452...
Checkpoint 890489452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,039.71718
Policy Entropy: 3.57547
Value Function Loss: 0.09309

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.69026

Collected Steps per Second: 22,835.58407
Overall Steps per Second: 10,615.26791

Timestep Collection Time: 2.19053
Timestep Consumption Time: 2.52174
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.71227

Cumulative Model Updates: 106,786
Cumulative Timesteps: 890,539,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,494.19556
Policy Entropy: 3.56011
Value Function Loss: 0.09527

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.50172
Value Function Update Magnitude: 0.67191

Collected Steps per Second: 21,888.04801
Overall Steps per Second: 10,454.42173

Timestep Collection Time: 2.28581
Timestep Consumption Time: 2.49991
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.78573

Cumulative Model Updates: 106,792
Cumulative Timesteps: 890,589,506

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 890589506...
Checkpoint 890589506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,574.20807
Policy Entropy: 3.55912
Value Function Loss: 0.09609

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.56978
Value Function Update Magnitude: 0.65385

Collected Steps per Second: 22,580.01706
Overall Steps per Second: 10,681.41654

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.46747
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.68253

Cumulative Model Updates: 106,798
Cumulative Timesteps: 890,639,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,784.64362
Policy Entropy: 3.56714
Value Function Loss: 0.09383

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.67206
Value Function Update Magnitude: 0.72446

Collected Steps per Second: 22,824.82153
Overall Steps per Second: 10,845.59327

Timestep Collection Time: 2.19121
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61146

Cumulative Model Updates: 106,804
Cumulative Timesteps: 890,689,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 890689536...
Checkpoint 890689536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,964.20630
Policy Entropy: 3.57738
Value Function Loss: 0.09216

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.60779
Value Function Update Magnitude: 0.73768

Collected Steps per Second: 22,380.29460
Overall Steps per Second: 10,734.76380

Timestep Collection Time: 2.23464
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.65888

Cumulative Model Updates: 106,810
Cumulative Timesteps: 890,739,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.67222
Policy Entropy: 3.57576
Value Function Loss: 0.09320

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.51793
Value Function Update Magnitude: 0.72017

Collected Steps per Second: 22,691.22997
Overall Steps per Second: 10,854.51912

Timestep Collection Time: 2.20376
Timestep Consumption Time: 2.40317
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60693

Cumulative Model Updates: 106,816
Cumulative Timesteps: 890,789,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 890789554...
Checkpoint 890789554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.09717
Policy Entropy: 3.56832
Value Function Loss: 0.09134

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.49820
Value Function Update Magnitude: 0.76450

Collected Steps per Second: 22,488.44921
Overall Steps per Second: 10,688.80694

Timestep Collection Time: 2.22381
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.67873

Cumulative Model Updates: 106,822
Cumulative Timesteps: 890,839,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,429.25832
Policy Entropy: 3.55914
Value Function Loss: 0.09194

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.52657
Value Function Update Magnitude: 0.74397

Collected Steps per Second: 23,307.79294
Overall Steps per Second: 10,855.07376

Timestep Collection Time: 2.14563
Timestep Consumption Time: 2.46143
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.60706

Cumulative Model Updates: 106,828
Cumulative Timesteps: 890,889,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 890889574...
Checkpoint 890889574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,394.91610
Policy Entropy: 3.54894
Value Function Loss: 0.09192

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.52174
Value Function Update Magnitude: 0.70809

Collected Steps per Second: 22,723.27583
Overall Steps per Second: 10,642.06177

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.70116

Cumulative Model Updates: 106,834
Cumulative Timesteps: 890,939,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.82502
Policy Entropy: 3.54629
Value Function Loss: 0.09333

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.51035
Value Function Update Magnitude: 0.68757

Collected Steps per Second: 23,090.72498
Overall Steps per Second: 10,871.30674

Timestep Collection Time: 2.16598
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60055

Cumulative Model Updates: 106,840
Cumulative Timesteps: 890,989,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 890989618...
Checkpoint 890989618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,430.89137
Policy Entropy: 3.54443
Value Function Loss: 0.09461

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.49817
Value Function Update Magnitude: 0.67364

Collected Steps per Second: 22,040.84122
Overall Steps per Second: 10,640.58007

Timestep Collection Time: 2.26906
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.70012

Cumulative Model Updates: 106,846
Cumulative Timesteps: 891,039,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,417.79601
Policy Entropy: 3.53886
Value Function Loss: 0.09894

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.49162
Value Function Update Magnitude: 0.69024

Collected Steps per Second: 22,747.38819
Overall Steps per Second: 10,725.89037

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.46514
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.66460

Cumulative Model Updates: 106,852
Cumulative Timesteps: 891,089,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 891089662...
Checkpoint 891089662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,273.72979
Policy Entropy: 3.53723
Value Function Loss: 0.10374

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.56227
Value Function Update Magnitude: 0.70255

Collected Steps per Second: 22,746.73951
Overall Steps per Second: 10,792.97047

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.63468

Cumulative Model Updates: 106,858
Cumulative Timesteps: 891,139,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,646.36653
Policy Entropy: 3.55333
Value Function Loss: 0.10181

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.63107
Value Function Update Magnitude: 0.76157

Collected Steps per Second: 22,630.39161
Overall Steps per Second: 10,618.56541

Timestep Collection Time: 2.20995
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.70986

Cumulative Model Updates: 106,864
Cumulative Timesteps: 891,189,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 891189696...
Checkpoint 891189696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,295.14280
Policy Entropy: 3.56107
Value Function Loss: 0.09800

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.61201
Value Function Update Magnitude: 0.77103

Collected Steps per Second: 22,375.66756
Overall Steps per Second: 10,583.77950

Timestep Collection Time: 2.23511
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.72534

Cumulative Model Updates: 106,870
Cumulative Timesteps: 891,239,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,808.57600
Policy Entropy: 3.56914
Value Function Loss: 0.09504

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.58640
Value Function Update Magnitude: 0.71409

Collected Steps per Second: 22,754.14322
Overall Steps per Second: 10,597.90437

Timestep Collection Time: 2.19758
Timestep Consumption Time: 2.52071
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.71829

Cumulative Model Updates: 106,876
Cumulative Timesteps: 891,289,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 891289712...
Checkpoint 891289712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.63807
Policy Entropy: 3.56700
Value Function Loss: 0.09619

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.70390

Collected Steps per Second: 23,077.65390
Overall Steps per Second: 10,895.66107

Timestep Collection Time: 2.16720
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.59027

Cumulative Model Updates: 106,882
Cumulative Timesteps: 891,339,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,529.06986
Policy Entropy: 3.57392
Value Function Loss: 0.09516

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.62129
Value Function Update Magnitude: 0.72020

Collected Steps per Second: 23,100.95922
Overall Steps per Second: 10,879.82729

Timestep Collection Time: 2.16510
Timestep Consumption Time: 2.43203
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59713

Cumulative Model Updates: 106,888
Cumulative Timesteps: 891,389,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 891389742...
Checkpoint 891389742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,761.74866
Policy Entropy: 3.56016
Value Function Loss: 0.09391

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.63258
Value Function Update Magnitude: 0.68069

Collected Steps per Second: 22,698.73668
Overall Steps per Second: 10,715.28845

Timestep Collection Time: 2.20391
Timestep Consumption Time: 2.46475
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.66866

Cumulative Model Updates: 106,894
Cumulative Timesteps: 891,439,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,609.72599
Policy Entropy: 3.57151
Value Function Loss: 0.09242

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.55006
Value Function Update Magnitude: 0.67385

Collected Steps per Second: 22,879.28582
Overall Steps per Second: 10,816.72294

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62247

Cumulative Model Updates: 106,900
Cumulative Timesteps: 891,489,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 891489768...
Checkpoint 891489768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,131.15668
Policy Entropy: 3.57158
Value Function Loss: 0.09401

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.75643

Collected Steps per Second: 22,811.30966
Overall Steps per Second: 10,695.58535

Timestep Collection Time: 2.19260
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.67632

Cumulative Model Updates: 106,906
Cumulative Timesteps: 891,539,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,488.99871
Policy Entropy: 3.56963
Value Function Loss: 0.09535

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.57467
Value Function Update Magnitude: 0.68855

Collected Steps per Second: 22,856.78669
Overall Steps per Second: 10,715.55003

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.66798

Cumulative Model Updates: 106,912
Cumulative Timesteps: 891,589,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 891589804...
Checkpoint 891589804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,564.09328
Policy Entropy: 3.55600
Value Function Loss: 0.09941

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.62633
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 21,834.42417
Overall Steps per Second: 10,479.20013

Timestep Collection Time: 2.29143
Timestep Consumption Time: 2.48298
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.77441

Cumulative Model Updates: 106,918
Cumulative Timesteps: 891,639,836

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,936.50911
Policy Entropy: 3.54450
Value Function Loss: 0.09898

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.67124
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 22,257.81523
Overall Steps per Second: 10,580.04472

Timestep Collection Time: 2.24757
Timestep Consumption Time: 2.48077
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.72834

Cumulative Model Updates: 106,924
Cumulative Timesteps: 891,689,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 891689862...
Checkpoint 891689862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,113.38635
Policy Entropy: 3.54312
Value Function Loss: 0.09929

Mean KL Divergence: 0.02916
SB3 Clip Fraction: 0.21039
Policy Update Magnitude: 0.58145
Value Function Update Magnitude: 0.60880

Collected Steps per Second: 22,424.18502
Overall Steps per Second: 10,574.39717

Timestep Collection Time: 2.23089
Timestep Consumption Time: 2.49997
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.73086

Cumulative Model Updates: 106,930
Cumulative Timesteps: 891,739,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,100.10366
Policy Entropy: 3.55836
Value Function Loss: 0.09596

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.15789
Policy Update Magnitude: 0.63979
Value Function Update Magnitude: 0.63891

Collected Steps per Second: 22,617.76448
Overall Steps per Second: 10,810.40275

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.41481
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.62573

Cumulative Model Updates: 106,936
Cumulative Timesteps: 891,789,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 891789894...
Checkpoint 891789894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,524.33689
Policy Entropy: 3.56820
Value Function Loss: 0.09182

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.16275
Policy Update Magnitude: 0.68883
Value Function Update Magnitude: 0.73161

Collected Steps per Second: 21,841.02594
Overall Steps per Second: 10,608.68699

Timestep Collection Time: 2.29037
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.71538

Cumulative Model Updates: 106,942
Cumulative Timesteps: 891,839,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,649.31836
Policy Entropy: 3.56987
Value Function Loss: 0.08900

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.65993
Value Function Update Magnitude: 0.74429

Collected Steps per Second: 22,581.85210
Overall Steps per Second: 10,884.45206

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.37973
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.59408

Cumulative Model Updates: 106,948
Cumulative Timesteps: 891,889,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 891889922...
Checkpoint 891889922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,658.08888
Policy Entropy: 3.57581
Value Function Loss: 0.08722

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.66283
Value Function Update Magnitude: 0.77248

Collected Steps per Second: 22,182.47120
Overall Steps per Second: 10,677.00141

Timestep Collection Time: 2.25520
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.68540

Cumulative Model Updates: 106,954
Cumulative Timesteps: 891,939,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,387.32311
Policy Entropy: 3.59565
Value Function Loss: 0.09045

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.66402
Value Function Update Magnitude: 0.88214

Collected Steps per Second: 22,316.43547
Overall Steps per Second: 10,858.46383

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.36430
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60489

Cumulative Model Updates: 106,960
Cumulative Timesteps: 891,989,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 891989950...
Checkpoint 891989950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,550.58480
Policy Entropy: 3.59982
Value Function Loss: 0.08771

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.74331
Value Function Update Magnitude: 0.98495

Collected Steps per Second: 22,088.75339
Overall Steps per Second: 10,693.94269

Timestep Collection Time: 2.26468
Timestep Consumption Time: 2.41311
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.67779

Cumulative Model Updates: 106,966
Cumulative Timesteps: 892,039,974

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,217.80679
Policy Entropy: 3.61234
Value Function Loss: 0.09055

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.84096
Value Function Update Magnitude: 0.86723

Collected Steps per Second: 22,507.91760
Overall Steps per Second: 10,785.88257

Timestep Collection Time: 2.22188
Timestep Consumption Time: 2.41473
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.63662

Cumulative Model Updates: 106,972
Cumulative Timesteps: 892,089,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 892089984...
Checkpoint 892089984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,396.60289
Policy Entropy: 3.59497
Value Function Loss: 0.09065

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.83637
Value Function Update Magnitude: 0.78061

Collected Steps per Second: 22,175.94939
Overall Steps per Second: 10,722.81740

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.40826
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.66295

Cumulative Model Updates: 106,978
Cumulative Timesteps: 892,139,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,642.94380
Policy Entropy: 3.60251
Value Function Loss: 0.08996

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.72304
Value Function Update Magnitude: 0.76154

Collected Steps per Second: 22,369.28711
Overall Steps per Second: 10,641.43536

Timestep Collection Time: 2.23548
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.69918

Cumulative Model Updates: 106,984
Cumulative Timesteps: 892,189,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 892189990...
Checkpoint 892189990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,972.30101
Policy Entropy: 3.60368
Value Function Loss: 0.08429

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.67388
Value Function Update Magnitude: 0.82082

Collected Steps per Second: 22,293.71481
Overall Steps per Second: 10,655.63003

Timestep Collection Time: 2.24287
Timestep Consumption Time: 2.44967
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.69254

Cumulative Model Updates: 106,990
Cumulative Timesteps: 892,239,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.99563
Policy Entropy: 3.60445
Value Function Loss: 0.08284

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.79922
Value Function Update Magnitude: 0.85116

Collected Steps per Second: 22,873.15162
Overall Steps per Second: 10,675.69170

Timestep Collection Time: 2.18623
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.68410

Cumulative Model Updates: 106,996
Cumulative Timesteps: 892,289,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 892289998...
Checkpoint 892289998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,179.55060
Policy Entropy: 3.59555
Value Function Loss: 0.08573

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.88053
Value Function Update Magnitude: 0.83832

Collected Steps per Second: 22,385.90449
Overall Steps per Second: 10,633.80673

Timestep Collection Time: 2.23408
Timestep Consumption Time: 2.46903
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.70311

Cumulative Model Updates: 107,002
Cumulative Timesteps: 892,340,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,870.55164
Policy Entropy: 3.57780
Value Function Loss: 0.08938

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.85161
Value Function Update Magnitude: 0.94004

Collected Steps per Second: 23,198.55934
Overall Steps per Second: 10,900.92801

Timestep Collection Time: 2.15634
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.58897

Cumulative Model Updates: 107,008
Cumulative Timesteps: 892,390,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 892390034...
Checkpoint 892390034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.69817
Policy Entropy: 3.59515
Value Function Loss: 0.09002

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.74701
Value Function Update Magnitude: 0.94247

Collected Steps per Second: 22,708.24442
Overall Steps per Second: 10,665.20432

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.48700
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.68946

Cumulative Model Updates: 107,014
Cumulative Timesteps: 892,440,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.07011
Policy Entropy: 3.62170
Value Function Loss: 0.09086

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.16553
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.89248

Collected Steps per Second: 23,168.50813
Overall Steps per Second: 10,879.68624

Timestep Collection Time: 2.15940
Timestep Consumption Time: 2.43908
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.59848

Cumulative Model Updates: 107,020
Cumulative Timesteps: 892,490,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 892490078...
Checkpoint 892490078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,847.84334
Policy Entropy: 3.63246
Value Function Loss: 0.08629

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.53552
Value Function Update Magnitude: 0.84665

Collected Steps per Second: 22,521.45394
Overall Steps per Second: 10,687.66466

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.45976
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.68128

Cumulative Model Updates: 107,026
Cumulative Timesteps: 892,540,110

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,777.31468
Policy Entropy: 3.62827
Value Function Loss: 0.08172

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.89741

Collected Steps per Second: 23,043.63445
Overall Steps per Second: 10,862.69133

Timestep Collection Time: 2.17101
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60549

Cumulative Model Updates: 107,032
Cumulative Timesteps: 892,590,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 892590138...
Checkpoint 892590138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,694.74023
Policy Entropy: 3.62839
Value Function Loss: 0.07653

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.95302

Collected Steps per Second: 22,134.48448
Overall Steps per Second: 10,648.89279

Timestep Collection Time: 2.25946
Timestep Consumption Time: 2.43699
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.69645

Cumulative Model Updates: 107,038
Cumulative Timesteps: 892,640,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,486.39495
Policy Entropy: 3.62622
Value Function Loss: 0.07505

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.58598
Value Function Update Magnitude: 0.95883

Collected Steps per Second: 22,582.43430
Overall Steps per Second: 10,602.87371

Timestep Collection Time: 2.21606
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.71985

Cumulative Model Updates: 107,044
Cumulative Timesteps: 892,690,194

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 892690194...
Checkpoint 892690194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,563.49199
Policy Entropy: 3.63127
Value Function Loss: 0.07287

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.61186
Value Function Update Magnitude: 0.96337

Collected Steps per Second: 22,474.35191
Overall Steps per Second: 10,563.28241

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.50922
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73451

Cumulative Model Updates: 107,050
Cumulative Timesteps: 892,740,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.31631
Policy Entropy: 3.63713
Value Function Loss: 0.07321

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.63778
Value Function Update Magnitude: 0.96552

Collected Steps per Second: 22,526.31654
Overall Steps per Second: 10,633.40249

Timestep Collection Time: 2.22078
Timestep Consumption Time: 2.48383
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.70461

Cumulative Model Updates: 107,056
Cumulative Timesteps: 892,790,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 892790232...
Checkpoint 892790232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,920.48176
Policy Entropy: 3.65123
Value Function Loss: 0.07320

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.67315
Value Function Update Magnitude: 0.99090

Collected Steps per Second: 22,174.85279
Overall Steps per Second: 10,430.79561

Timestep Collection Time: 2.25481
Timestep Consumption Time: 2.53869
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.79350

Cumulative Model Updates: 107,062
Cumulative Timesteps: 892,840,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,456.00270
Policy Entropy: 3.64080
Value Function Loss: 0.07424

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.74037
Value Function Update Magnitude: 0.97265

Collected Steps per Second: 23,040.13340
Overall Steps per Second: 10,814.10801

Timestep Collection Time: 2.17143
Timestep Consumption Time: 2.45494
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62636

Cumulative Model Updates: 107,068
Cumulative Timesteps: 892,890,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 892890262...
Checkpoint 892890262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,537.17074
Policy Entropy: 3.64057
Value Function Loss: 0.07419

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.77433
Value Function Update Magnitude: 0.98249

Collected Steps per Second: 22,721.46339
Overall Steps per Second: 10,790.81226

Timestep Collection Time: 2.20100
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.63450

Cumulative Model Updates: 107,074
Cumulative Timesteps: 892,940,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,300.09420
Policy Entropy: 3.64052
Value Function Loss: 0.07441

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.18865
Policy Update Magnitude: 0.64707
Value Function Update Magnitude: 0.99376

Collected Steps per Second: 22,944.14056
Overall Steps per Second: 10,855.15722

Timestep Collection Time: 2.18008
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.60795

Cumulative Model Updates: 107,080
Cumulative Timesteps: 892,990,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 892990292...
Checkpoint 892990292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.09128
Policy Entropy: 3.65034
Value Function Loss: 0.07176

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.52563
Value Function Update Magnitude: 0.98894

Collected Steps per Second: 22,712.03285
Overall Steps per Second: 10,653.63592

Timestep Collection Time: 2.20236
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69511

Cumulative Model Updates: 107,086
Cumulative Timesteps: 893,040,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,766.27744
Policy Entropy: 3.64301
Value Function Loss: 0.07460

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.62125
Value Function Update Magnitude: 0.97631

Collected Steps per Second: 23,097.73469
Overall Steps per Second: 10,875.34009

Timestep Collection Time: 2.16584
Timestep Consumption Time: 2.43411
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59995

Cumulative Model Updates: 107,092
Cumulative Timesteps: 893,090,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 893090338...
Checkpoint 893090338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.44515
Policy Entropy: 3.63788
Value Function Loss: 0.07746

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.74504
Value Function Update Magnitude: 0.94171

Collected Steps per Second: 22,206.24609
Overall Steps per Second: 10,669.62010

Timestep Collection Time: 2.25225
Timestep Consumption Time: 2.43527
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.68751

Cumulative Model Updates: 107,098
Cumulative Timesteps: 893,140,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,840.37116
Policy Entropy: 3.62906
Value Function Loss: 0.07881

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.63925
Value Function Update Magnitude: 0.87393

Collected Steps per Second: 22,660.54086
Overall Steps per Second: 10,702.42054

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.67352

Cumulative Model Updates: 107,104
Cumulative Timesteps: 893,190,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 893190370...
Checkpoint 893190370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,909.80445
Policy Entropy: 3.62442
Value Function Loss: 0.07831

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.58258
Value Function Update Magnitude: 0.79212

Collected Steps per Second: 21,850.25827
Overall Steps per Second: 10,451.98087

Timestep Collection Time: 2.28867
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.78455

Cumulative Model Updates: 107,110
Cumulative Timesteps: 893,240,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,613.36271
Policy Entropy: 3.62162
Value Function Loss: 0.08068

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.61421
Value Function Update Magnitude: 0.75594

Collected Steps per Second: 21,820.82391
Overall Steps per Second: 10,764.79081

Timestep Collection Time: 2.29240
Timestep Consumption Time: 2.35442
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.64682

Cumulative Model Updates: 107,116
Cumulative Timesteps: 893,290,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 893290400...
Checkpoint 893290400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,777.07084
Policy Entropy: 3.62854
Value Function Loss: 0.08040

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.68610
Value Function Update Magnitude: 0.84737

Collected Steps per Second: 21,840.02971
Overall Steps per Second: 10,794.10365

Timestep Collection Time: 2.29002
Timestep Consumption Time: 2.34344
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.63346

Cumulative Model Updates: 107,122
Cumulative Timesteps: 893,340,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,880.14139
Policy Entropy: 3.63624
Value Function Loss: 0.07673

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.65899
Value Function Update Magnitude: 0.91563

Collected Steps per Second: 22,213.10467
Overall Steps per Second: 10,785.06451

Timestep Collection Time: 2.25182
Timestep Consumption Time: 2.38607
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63790

Cumulative Model Updates: 107,128
Cumulative Timesteps: 893,390,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 893390434...
Checkpoint 893390434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,790.49853
Policy Entropy: 3.64534
Value Function Loss: 0.07277

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.72557
Value Function Update Magnitude: 0.96368

Collected Steps per Second: 21,982.03624
Overall Steps per Second: 10,623.43832

Timestep Collection Time: 2.27540
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.70827

Cumulative Model Updates: 107,134
Cumulative Timesteps: 893,440,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,970.65759
Policy Entropy: 3.64892
Value Function Loss: 0.07088

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.83394
Value Function Update Magnitude: 0.96387

Collected Steps per Second: 22,212.08706
Overall Steps per Second: 10,711.21555

Timestep Collection Time: 2.25157
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.66912

Cumulative Model Updates: 107,140
Cumulative Timesteps: 893,490,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 893490464...
Checkpoint 893490464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,418.37627
Policy Entropy: 3.66861
Value Function Loss: 0.07197

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11355
Policy Update Magnitude: 0.81386
Value Function Update Magnitude: 0.95741

Collected Steps per Second: 22,415.88865
Overall Steps per Second: 10,937.79533

Timestep Collection Time: 2.23101
Timestep Consumption Time: 2.34121
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.57222

Cumulative Model Updates: 107,146
Cumulative Timesteps: 893,540,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,148.71514
Policy Entropy: 3.68737
Value Function Loss: 0.07121

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.64506
Value Function Update Magnitude: 0.96655

Collected Steps per Second: 22,308.98782
Overall Steps per Second: 10,880.53185

Timestep Collection Time: 2.24188
Timestep Consumption Time: 2.35477
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.59665

Cumulative Model Updates: 107,152
Cumulative Timesteps: 893,590,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 893590488...
Checkpoint 893590488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,279.50072
Policy Entropy: 3.68257
Value Function Loss: 0.07012

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.92672

Collected Steps per Second: 21,780.12678
Overall Steps per Second: 10,653.81831

Timestep Collection Time: 2.29686
Timestep Consumption Time: 2.39873
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.69559

Cumulative Model Updates: 107,158
Cumulative Timesteps: 893,640,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.31173
Policy Entropy: 3.70454
Value Function Loss: 0.06738

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.67540
Value Function Update Magnitude: 0.89902

Collected Steps per Second: 21,689.75718
Overall Steps per Second: 10,420.53911

Timestep Collection Time: 2.30542
Timestep Consumption Time: 2.49318
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.79860

Cumulative Model Updates: 107,164
Cumulative Timesteps: 893,690,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 893690518...
Checkpoint 893690518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.21291
Policy Entropy: 3.70866
Value Function Loss: 0.06868

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.80598
Value Function Update Magnitude: 0.86217

Collected Steps per Second: 22,088.36858
Overall Steps per Second: 10,689.68636

Timestep Collection Time: 2.26382
Timestep Consumption Time: 2.41396
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.67778

Cumulative Model Updates: 107,170
Cumulative Timesteps: 893,740,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.62468
Policy Entropy: 3.70947
Value Function Loss: 0.06970

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.74180
Value Function Update Magnitude: 0.82308

Collected Steps per Second: 21,948.97660
Overall Steps per Second: 10,528.38775

Timestep Collection Time: 2.27828
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.74964

Cumulative Model Updates: 107,176
Cumulative Timesteps: 893,790,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 893790528...
Checkpoint 893790528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.20579
Policy Entropy: 3.69223
Value Function Loss: 0.07125

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.70925
Value Function Update Magnitude: 0.75967

Collected Steps per Second: 22,157.99585
Overall Steps per Second: 10,519.88934

Timestep Collection Time: 2.25760
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75518

Cumulative Model Updates: 107,182
Cumulative Timesteps: 893,840,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,513.80477
Policy Entropy: 3.67813
Value Function Loss: 0.07156

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.67391
Value Function Update Magnitude: 0.71802

Collected Steps per Second: 23,026.99303
Overall Steps per Second: 10,852.99204

Timestep Collection Time: 2.17310
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61071

Cumulative Model Updates: 107,188
Cumulative Timesteps: 893,890,592

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 893890592...
Checkpoint 893890592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,117.91649
Policy Entropy: 3.67143
Value Function Loss: 0.07272

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.67924
Value Function Update Magnitude: 0.71304

Collected Steps per Second: 22,532.63481
Overall Steps per Second: 10,657.68668

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.69239

Cumulative Model Updates: 107,194
Cumulative Timesteps: 893,940,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859.22795
Policy Entropy: 3.66566
Value Function Loss: 0.07277

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.71709
Value Function Update Magnitude: 0.75703

Collected Steps per Second: 23,155.84394
Overall Steps per Second: 10,917.19194

Timestep Collection Time: 2.15937
Timestep Consumption Time: 2.42075
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.58012

Cumulative Model Updates: 107,200
Cumulative Timesteps: 893,990,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 893990604...
Checkpoint 893990604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,534.99889
Policy Entropy: 3.65991
Value Function Loss: 0.07084

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.74044
Value Function Update Magnitude: 0.75640

Collected Steps per Second: 22,698.77382
Overall Steps per Second: 10,650.26754

Timestep Collection Time: 2.20311
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.69547

Cumulative Model Updates: 107,206
Cumulative Timesteps: 894,040,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,739.46814
Policy Entropy: 3.65975
Value Function Loss: 0.07323

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.65718
Value Function Update Magnitude: 0.75359

Collected Steps per Second: 23,075.77774
Overall Steps per Second: 10,834.34928

Timestep Collection Time: 2.16799
Timestep Consumption Time: 2.44955
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61754

Cumulative Model Updates: 107,212
Cumulative Timesteps: 894,090,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 894090640...
Checkpoint 894090640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.89080
Policy Entropy: 3.65366
Value Function Loss: 0.07419

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.56052
Value Function Update Magnitude: 0.75547

Collected Steps per Second: 22,683.88685
Overall Steps per Second: 10,742.96455

Timestep Collection Time: 2.20500
Timestep Consumption Time: 2.45088
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.65588

Cumulative Model Updates: 107,218
Cumulative Timesteps: 894,140,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.31264
Policy Entropy: 3.65694
Value Function Loss: 0.07681

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.54147
Value Function Update Magnitude: 0.73392

Collected Steps per Second: 23,039.39940
Overall Steps per Second: 10,866.30716

Timestep Collection Time: 2.17063
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.60230

Cumulative Model Updates: 107,224
Cumulative Timesteps: 894,190,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 894190668...
Checkpoint 894190668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,046.11958
Policy Entropy: 3.66069
Value Function Loss: 0.08032

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.60897
Value Function Update Magnitude: 0.69054

Collected Steps per Second: 21,822.31082
Overall Steps per Second: 10,575.39558

Timestep Collection Time: 2.29261
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73079

Cumulative Model Updates: 107,230
Cumulative Timesteps: 894,240,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,064.52694
Policy Entropy: 3.65392
Value Function Loss: 0.08071

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.59685
Value Function Update Magnitude: 0.73027

Collected Steps per Second: 22,663.17244
Overall Steps per Second: 10,591.17358

Timestep Collection Time: 2.20684
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.72223

Cumulative Model Updates: 107,236
Cumulative Timesteps: 894,290,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 894290712...
Checkpoint 894290712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,388.97546
Policy Entropy: 3.64925
Value Function Loss: 0.08142

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.60259
Value Function Update Magnitude: 0.77069

Collected Steps per Second: 22,438.88946
Overall Steps per Second: 10,583.76574

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.72441

Cumulative Model Updates: 107,242
Cumulative Timesteps: 894,340,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,774.53738
Policy Entropy: 3.64765
Value Function Loss: 0.07725

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.84402

Collected Steps per Second: 22,751.17610
Overall Steps per Second: 10,536.98791

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.54770
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.74557

Cumulative Model Updates: 107,248
Cumulative Timesteps: 894,390,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 894390718...
Checkpoint 894390718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,829.96614
Policy Entropy: 3.65406
Value Function Loss: 0.07491

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.86921

Collected Steps per Second: 22,228.31427
Overall Steps per Second: 10,584.77248

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.72415

Cumulative Model Updates: 107,254
Cumulative Timesteps: 894,440,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,130.44324
Policy Entropy: 3.64694
Value Function Loss: 0.07489

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.70831
Value Function Update Magnitude: 0.89752

Collected Steps per Second: 22,450.61650
Overall Steps per Second: 10,603.86972

Timestep Collection Time: 2.22845
Timestep Consumption Time: 2.48964
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.71809

Cumulative Model Updates: 107,260
Cumulative Timesteps: 894,490,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 894490752...
Checkpoint 894490752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.83744
Policy Entropy: 3.64846
Value Function Loss: 0.07515

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.68343
Value Function Update Magnitude: 0.93341

Collected Steps per Second: 22,188.82148
Overall Steps per Second: 10,512.19811

Timestep Collection Time: 2.25411
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.75790

Cumulative Model Updates: 107,266
Cumulative Timesteps: 894,540,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,228.85045
Policy Entropy: 3.65013
Value Function Loss: 0.07762

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.62880
Value Function Update Magnitude: 0.94791

Collected Steps per Second: 22,614.32400
Overall Steps per Second: 10,649.82703

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.69660

Cumulative Model Updates: 107,272
Cumulative Timesteps: 894,590,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 894590786...
Checkpoint 894590786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,401.92853
Policy Entropy: 3.64454
Value Function Loss: 0.07719

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.63482
Value Function Update Magnitude: 0.94163

Collected Steps per Second: 22,565.85112
Overall Steps per Second: 10,613.01152

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.49686
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.71384

Cumulative Model Updates: 107,278
Cumulative Timesteps: 894,640,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,722.50080
Policy Entropy: 3.64119
Value Function Loss: 0.08176

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.59114
Value Function Update Magnitude: 0.85581

Collected Steps per Second: 22,832.10934
Overall Steps per Second: 10,719.98324

Timestep Collection Time: 2.19016
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.66475

Cumulative Model Updates: 107,284
Cumulative Timesteps: 894,690,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 894690820...
Checkpoint 894690820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216.98105
Policy Entropy: 3.63026
Value Function Loss: 0.08405

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16574
Policy Update Magnitude: 0.55701
Value Function Update Magnitude: 0.72780

Collected Steps per Second: 22,806.93101
Overall Steps per Second: 10,644.40795

Timestep Collection Time: 2.19363
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.70012

Cumulative Model Updates: 107,290
Cumulative Timesteps: 894,740,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,330.61603
Policy Entropy: 3.62772
Value Function Loss: 0.08611

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.47190
Value Function Update Magnitude: 0.75584

Collected Steps per Second: 23,178.59709
Overall Steps per Second: 10,916.21681

Timestep Collection Time: 2.15768
Timestep Consumption Time: 2.42376
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.58144

Cumulative Model Updates: 107,296
Cumulative Timesteps: 894,790,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 894790862...
Checkpoint 894790862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,113.96495
Policy Entropy: 3.62470
Value Function Loss: 0.08649

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.44780
Value Function Update Magnitude: 0.81286

Collected Steps per Second: 22,823.09477
Overall Steps per Second: 10,663.89701

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.49805
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.68890

Cumulative Model Updates: 107,302
Cumulative Timesteps: 894,840,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,774.76151
Policy Entropy: 3.63990
Value Function Loss: 0.08603

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.53361
Value Function Update Magnitude: 0.72707

Collected Steps per Second: 22,903.46370
Overall Steps per Second: 10,841.97650

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.61318

Cumulative Model Updates: 107,308
Cumulative Timesteps: 894,890,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 894890880...
Checkpoint 894890880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.24864
Policy Entropy: 3.64227
Value Function Loss: 0.08711

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.66509
Value Function Update Magnitude: 0.71457

Collected Steps per Second: 22,310.00984
Overall Steps per Second: 10,656.99498

Timestep Collection Time: 2.24177
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.69307

Cumulative Model Updates: 107,314
Cumulative Timesteps: 894,940,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,257.57867
Policy Entropy: 3.64662
Value Function Loss: 0.08744

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.72064
Value Function Update Magnitude: 0.73862

Collected Steps per Second: 22,524.81357
Overall Steps per Second: 10,626.67943

Timestep Collection Time: 2.22075
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.70721

Cumulative Model Updates: 107,320
Cumulative Timesteps: 894,990,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 894990916...
Checkpoint 894990916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.65331
Policy Entropy: 3.62922
Value Function Loss: 0.08882

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.62618
Value Function Update Magnitude: 0.73204

Collected Steps per Second: 22,500.34815
Overall Steps per Second: 10,656.72363

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.69394

Cumulative Model Updates: 107,326
Cumulative Timesteps: 895,040,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,432.60002
Policy Entropy: 3.61283
Value Function Loss: 0.09069

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.71594

Collected Steps per Second: 22,509.13416
Overall Steps per Second: 10,733.15036

Timestep Collection Time: 2.22292
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.66182

Cumulative Model Updates: 107,332
Cumulative Timesteps: 895,090,974

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 895090974...
Checkpoint 895090974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.77001
Policy Entropy: 3.60406
Value Function Loss: 0.09357

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.52753
Value Function Update Magnitude: 0.67356

Collected Steps per Second: 22,433.32209
Overall Steps per Second: 10,598.52601

Timestep Collection Time: 2.22972
Timestep Consumption Time: 2.48981
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.71952

Cumulative Model Updates: 107,338
Cumulative Timesteps: 895,140,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,490.55483
Policy Entropy: 3.60107
Value Function Loss: 0.09312

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.52349
Value Function Update Magnitude: 0.65902

Collected Steps per Second: 23,059.80384
Overall Steps per Second: 10,859.87702

Timestep Collection Time: 2.16949
Timestep Consumption Time: 2.43719
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60668

Cumulative Model Updates: 107,344
Cumulative Timesteps: 895,191,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 895191022...
Checkpoint 895191022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.59117
Policy Entropy: 3.60514
Value Function Loss: 0.09107

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.55592
Value Function Update Magnitude: 0.68710

Collected Steps per Second: 22,315.92906
Overall Steps per Second: 10,681.80526

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.68235

Cumulative Model Updates: 107,350
Cumulative Timesteps: 895,241,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,581.66929
Policy Entropy: 3.60838
Value Function Loss: 0.08983

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15313
Policy Update Magnitude: 0.51653
Value Function Update Magnitude: 0.74181

Collected Steps per Second: 23,268.19689
Overall Steps per Second: 10,885.39900

Timestep Collection Time: 2.15075
Timestep Consumption Time: 2.44660
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.59735

Cumulative Model Updates: 107,356
Cumulative Timesteps: 895,291,082

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 895291082...
Checkpoint 895291082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,118.83149
Policy Entropy: 3.61100
Value Function Loss: 0.09030

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.73273

Collected Steps per Second: 22,207.56794
Overall Steps per Second: 10,629.33207

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.45326
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.70547

Cumulative Model Updates: 107,362
Cumulative Timesteps: 895,341,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.83025
Policy Entropy: 3.61160
Value Function Loss: 0.09045

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.61122
Value Function Update Magnitude: 0.73409

Collected Steps per Second: 22,985.93248
Overall Steps per Second: 10,724.93868

Timestep Collection Time: 2.17533
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.66222

Cumulative Model Updates: 107,368
Cumulative Timesteps: 895,391,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 895391100...
Checkpoint 895391100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,048.50101
Policy Entropy: 3.62265
Value Function Loss: 0.08669

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.58749
Value Function Update Magnitude: 0.73582

Collected Steps per Second: 22,555.23456
Overall Steps per Second: 10,858.83174

Timestep Collection Time: 2.21776
Timestep Consumption Time: 2.38882
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60657

Cumulative Model Updates: 107,374
Cumulative Timesteps: 895,441,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.28497
Policy Entropy: 3.62652
Value Function Loss: 0.08565

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.59628
Value Function Update Magnitude: 0.78349

Collected Steps per Second: 22,522.97492
Overall Steps per Second: 10,586.71440

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.72385

Cumulative Model Updates: 107,380
Cumulative Timesteps: 895,491,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 895491132...
Checkpoint 895491132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,889.24103
Policy Entropy: 3.62166
Value Function Loss: 0.08393

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.67747
Value Function Update Magnitude: 0.81412

Collected Steps per Second: 22,325.98472
Overall Steps per Second: 10,529.10267

Timestep Collection Time: 2.24089
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.75159

Cumulative Model Updates: 107,386
Cumulative Timesteps: 895,541,162

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,211.13508
Policy Entropy: 3.60957
Value Function Loss: 0.08368

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.71961
Value Function Update Magnitude: 0.83443

Collected Steps per Second: 21,924.09440
Overall Steps per Second: 10,447.89937

Timestep Collection Time: 2.28133
Timestep Consumption Time: 2.50586
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.78718

Cumulative Model Updates: 107,392
Cumulative Timesteps: 895,591,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 895591178...
Checkpoint 895591178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,720.92500
Policy Entropy: 3.60841
Value Function Loss: 0.08666

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.17098
Policy Update Magnitude: 0.59310
Value Function Update Magnitude: 0.85894

Collected Steps per Second: 22,098.70161
Overall Steps per Second: 10,662.38881

Timestep Collection Time: 2.26357
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.69144

Cumulative Model Updates: 107,398
Cumulative Timesteps: 895,641,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.97016
Policy Entropy: 3.61561
Value Function Loss: 0.08423

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.53160
Value Function Update Magnitude: 0.87118

Collected Steps per Second: 23,121.28575
Overall Steps per Second: 10,807.60382

Timestep Collection Time: 2.16346
Timestep Consumption Time: 2.46495
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62841

Cumulative Model Updates: 107,404
Cumulative Timesteps: 895,691,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 895691222...
Checkpoint 895691222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,832.04373
Policy Entropy: 3.62379
Value Function Loss: 0.08297

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.52617
Value Function Update Magnitude: 0.85979

Collected Steps per Second: 22,536.98463
Overall Steps per Second: 10,695.71150

Timestep Collection Time: 2.21875
Timestep Consumption Time: 2.45639
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.67514

Cumulative Model Updates: 107,410
Cumulative Timesteps: 895,741,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,118.38361
Policy Entropy: 3.61549
Value Function Loss: 0.08128

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.76620

Collected Steps per Second: 23,229.41976
Overall Steps per Second: 10,888.83898

Timestep Collection Time: 2.15305
Timestep Consumption Time: 2.44010
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.59314

Cumulative Model Updates: 107,416
Cumulative Timesteps: 895,791,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 895791240...
Checkpoint 895791240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.57738
Policy Entropy: 3.61376
Value Function Loss: 0.07889

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.67816
Value Function Update Magnitude: 0.70238

Collected Steps per Second: 22,721.99855
Overall Steps per Second: 10,687.46263

Timestep Collection Time: 2.20069
Timestep Consumption Time: 2.47807
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.67875

Cumulative Model Updates: 107,422
Cumulative Timesteps: 895,841,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,974.42430
Policy Entropy: 3.61342
Value Function Loss: 0.07777

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.64198
Value Function Update Magnitude: 0.70571

Collected Steps per Second: 23,237.91785
Overall Steps per Second: 10,901.36549

Timestep Collection Time: 2.15209
Timestep Consumption Time: 2.43541
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58750

Cumulative Model Updates: 107,428
Cumulative Timesteps: 895,891,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 895891254...
Checkpoint 895891254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,529.19787
Policy Entropy: 3.63102
Value Function Loss: 0.07470

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.53405
Value Function Update Magnitude: 0.67781

Collected Steps per Second: 22,551.00604
Overall Steps per Second: 10,631.36292

Timestep Collection Time: 2.21853
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.70589

Cumulative Model Updates: 107,434
Cumulative Timesteps: 895,941,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.65745
Policy Entropy: 3.62832
Value Function Loss: 0.07489

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.57223
Value Function Update Magnitude: 0.67237

Collected Steps per Second: 22,715.21041
Overall Steps per Second: 10,681.40521

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68403

Cumulative Model Updates: 107,440
Cumulative Timesteps: 895,991,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 895991316...
Checkpoint 895991316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,127.62725
Policy Entropy: 3.62582
Value Function Loss: 0.07354

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.55229
Value Function Update Magnitude: 0.63403

Collected Steps per Second: 22,013.03240
Overall Steps per Second: 10,495.78681

Timestep Collection Time: 2.27229
Timestep Consumption Time: 2.49343
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.76572

Cumulative Model Updates: 107,446
Cumulative Timesteps: 896,041,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,321.50888
Policy Entropy: 3.62340
Value Function Loss: 0.06941

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.67175

Collected Steps per Second: 22,625.78849
Overall Steps per Second: 10,858.69163

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.39541
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.60590

Cumulative Model Updates: 107,452
Cumulative Timesteps: 896,091,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 896091350...
Checkpoint 896091350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,575.28038
Policy Entropy: 3.62204
Value Function Loss: 0.06441

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.51399
Value Function Update Magnitude: 0.70311

Collected Steps per Second: 22,082.99704
Overall Steps per Second: 10,606.60467

Timestep Collection Time: 2.26536
Timestep Consumption Time: 2.45113
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.71650

Cumulative Model Updates: 107,458
Cumulative Timesteps: 896,141,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,992.45859
Policy Entropy: 3.64012
Value Function Loss: 0.06108

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.51090
Value Function Update Magnitude: 0.71849

Collected Steps per Second: 22,442.15351
Overall Steps per Second: 10,555.49936

Timestep Collection Time: 2.22804
Timestep Consumption Time: 2.50902
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.73706

Cumulative Model Updates: 107,464
Cumulative Timesteps: 896,191,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 896191378...
Checkpoint 896191378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,297.65398
Policy Entropy: 3.63333
Value Function Loss: 0.06103

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.71759

Collected Steps per Second: 22,412.46922
Overall Steps per Second: 10,592.25267

Timestep Collection Time: 2.23090
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.72043

Cumulative Model Updates: 107,470
Cumulative Timesteps: 896,241,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,529.20796
Policy Entropy: 3.64354
Value Function Loss: 0.06090

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.55684
Value Function Update Magnitude: 0.71565

Collected Steps per Second: 22,781.67783
Overall Steps per Second: 10,841.08929

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61503

Cumulative Model Updates: 107,476
Cumulative Timesteps: 896,291,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 896291410...
Checkpoint 896291410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,990.94375
Policy Entropy: 3.65506
Value Function Loss: 0.05986

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.60690
Value Function Update Magnitude: 0.69741

Collected Steps per Second: 21,648.49877
Overall Steps per Second: 10,344.64377

Timestep Collection Time: 2.31009
Timestep Consumption Time: 2.52429
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.83439

Cumulative Model Updates: 107,482
Cumulative Timesteps: 896,341,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.14212
Policy Entropy: 3.65839
Value Function Loss: 0.06001

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.69304
Value Function Update Magnitude: 0.71047

Collected Steps per Second: 22,867.28265
Overall Steps per Second: 10,845.61034

Timestep Collection Time: 2.18793
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.61311

Cumulative Model Updates: 107,488
Cumulative Timesteps: 896,391,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 896391452...
Checkpoint 896391452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,582.48057
Policy Entropy: 3.65347
Value Function Loss: 0.06242

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.76243
Value Function Update Magnitude: 0.74945

Collected Steps per Second: 22,627.23398
Overall Steps per Second: 10,610.92682

Timestep Collection Time: 2.21105
Timestep Consumption Time: 2.50390
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71495

Cumulative Model Updates: 107,494
Cumulative Timesteps: 896,441,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,272.58715
Policy Entropy: 3.63865
Value Function Loss: 0.06407

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.81693
Value Function Update Magnitude: 0.76116

Collected Steps per Second: 22,916.91888
Overall Steps per Second: 10,841.16770

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.43084
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61316

Cumulative Model Updates: 107,500
Cumulative Timesteps: 896,491,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 896491494...
Checkpoint 896491494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.32415
Policy Entropy: 3.64037
Value Function Loss: 0.06688

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.79607
Value Function Update Magnitude: 0.75107

Collected Steps per Second: 22,705.10726
Overall Steps per Second: 10,718.66541

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.46409
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.66756

Cumulative Model Updates: 107,506
Cumulative Timesteps: 896,541,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.45165
Policy Entropy: 3.63427
Value Function Loss: 0.06922

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.72431
Value Function Update Magnitude: 0.72698

Collected Steps per Second: 22,729.75778
Overall Steps per Second: 10,833.81933

Timestep Collection Time: 2.20134
Timestep Consumption Time: 2.41716
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.61850

Cumulative Model Updates: 107,512
Cumulative Timesteps: 896,591,560

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 896591560...
Checkpoint 896591560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,417.30159
Policy Entropy: 3.62358
Value Function Loss: 0.07011

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.63624
Value Function Update Magnitude: 0.66116

Collected Steps per Second: 21,907.84800
Overall Steps per Second: 10,673.43547

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.40282
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.68565

Cumulative Model Updates: 107,518
Cumulative Timesteps: 896,641,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,631.47925
Policy Entropy: 3.63027
Value Function Loss: 0.07393

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.65414

Collected Steps per Second: 22,643.53156
Overall Steps per Second: 10,627.99357

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.49672
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70512

Cumulative Model Updates: 107,524
Cumulative Timesteps: 896,691,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 896691578...
Checkpoint 896691578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,745.64983
Policy Entropy: 3.62861
Value Function Loss: 0.07651

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.51136
Value Function Update Magnitude: 0.62586

Collected Steps per Second: 22,388.76631
Overall Steps per Second: 10,632.38699

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.46984
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.70355

Cumulative Model Updates: 107,530
Cumulative Timesteps: 896,741,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,123.82261
Policy Entropy: 3.62744
Value Function Loss: 0.07973

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.45884
Value Function Update Magnitude: 0.52936

Collected Steps per Second: 22,857.26505
Overall Steps per Second: 10,711.70734

Timestep Collection Time: 2.18854
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.67003

Cumulative Model Updates: 107,536
Cumulative Timesteps: 896,791,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 896791612...
Checkpoint 896791612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,698.10638
Policy Entropy: 3.63210
Value Function Loss: 0.07812

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.42979
Value Function Update Magnitude: 0.49058

Collected Steps per Second: 22,626.36697
Overall Steps per Second: 10,695.65882

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.46548
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.67573

Cumulative Model Updates: 107,542
Cumulative Timesteps: 896,841,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,117.12602
Policy Entropy: 3.62757
Value Function Loss: 0.07909

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.52357

Collected Steps per Second: 23,024.14484
Overall Steps per Second: 10,816.50189

Timestep Collection Time: 2.17268
Timestep Consumption Time: 2.45211
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62479

Cumulative Model Updates: 107,548
Cumulative Timesteps: 896,891,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 896891646...
Checkpoint 896891646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,601.01771
Policy Entropy: 3.62734
Value Function Loss: 0.08064

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.52749
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 22,748.67035
Overall Steps per Second: 10,732.52923

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.46218
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.66134

Cumulative Model Updates: 107,554
Cumulative Timesteps: 896,941,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.10981
Policy Entropy: 3.63241
Value Function Loss: 0.08064

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.48878
Value Function Update Magnitude: 0.71802

Collected Steps per Second: 22,735.21837
Overall Steps per Second: 10,647.32220

Timestep Collection Time: 2.20046
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.69865

Cumulative Model Updates: 107,560
Cumulative Timesteps: 896,991,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 896991702...
Checkpoint 896991702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,899.41914
Policy Entropy: 3.62747
Value Function Loss: 0.08014

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.48798
Value Function Update Magnitude: 0.78031

Collected Steps per Second: 22,863.07605
Overall Steps per Second: 10,823.67584

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61969

Cumulative Model Updates: 107,566
Cumulative Timesteps: 897,041,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,145.54426
Policy Entropy: 3.61957
Value Function Loss: 0.07914

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.74632

Collected Steps per Second: 22,678.06891
Overall Steps per Second: 10,596.47156

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.51448
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.71987

Cumulative Model Updates: 107,572
Cumulative Timesteps: 897,091,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 897091718...
Checkpoint 897091718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,812.15167
Policy Entropy: 3.61294
Value Function Loss: 0.07725

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.55755
Value Function Update Magnitude: 0.67102

Collected Steps per Second: 21,734.80573
Overall Steps per Second: 10,576.39469

Timestep Collection Time: 2.30073
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.72808

Cumulative Model Updates: 107,578
Cumulative Timesteps: 897,141,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.24468
Policy Entropy: 3.60619
Value Function Loss: 0.08009

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.69958
Value Function Update Magnitude: 0.62093

Collected Steps per Second: 22,663.53124
Overall Steps per Second: 10,659.90670

Timestep Collection Time: 2.20725
Timestep Consumption Time: 2.48548
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69272

Cumulative Model Updates: 107,584
Cumulative Timesteps: 897,191,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 897191748...
Checkpoint 897191748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,701.06981
Policy Entropy: 3.59809
Value Function Loss: 0.08448

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06991
Policy Update Magnitude: 0.75820
Value Function Update Magnitude: 0.62346

Collected Steps per Second: 22,417.03020
Overall Steps per Second: 10,562.48440

Timestep Collection Time: 2.23045
Timestep Consumption Time: 2.50329
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.73373

Cumulative Model Updates: 107,590
Cumulative Timesteps: 897,241,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,356.10296
Policy Entropy: 3.59193
Value Function Loss: 0.08711

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.80828
Value Function Update Magnitude: 0.59423

Collected Steps per Second: 23,170.33075
Overall Steps per Second: 10,729.42084

Timestep Collection Time: 2.15854
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.66139

Cumulative Model Updates: 107,596
Cumulative Timesteps: 897,291,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 897291762...
Checkpoint 897291762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,382.18231
Policy Entropy: 3.59014
Value Function Loss: 0.08860

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.70499
Value Function Update Magnitude: 0.56615

Collected Steps per Second: 22,863.34751
Overall Steps per Second: 10,672.36656

Timestep Collection Time: 2.18822
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68781

Cumulative Model Updates: 107,602
Cumulative Timesteps: 897,341,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,277.58460
Policy Entropy: 3.59985
Value Function Loss: 0.08648

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.58109

Collected Steps per Second: 23,013.00114
Overall Steps per Second: 10,858.67322

Timestep Collection Time: 2.17390
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.60719

Cumulative Model Updates: 107,608
Cumulative Timesteps: 897,391,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 897391820...
Checkpoint 897391820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,901.84871
Policy Entropy: 3.60265
Value Function Loss: 0.08686

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.51461
Value Function Update Magnitude: 0.58817

Collected Steps per Second: 22,554.68957
Overall Steps per Second: 10,706.06483

Timestep Collection Time: 2.21710
Timestep Consumption Time: 2.45371
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.67081

Cumulative Model Updates: 107,614
Cumulative Timesteps: 897,441,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,443.40632
Policy Entropy: 3.60795
Value Function Loss: 0.08990

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.50296
Value Function Update Magnitude: 0.57738

Collected Steps per Second: 23,038.31357
Overall Steps per Second: 10,841.92373

Timestep Collection Time: 2.17143
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61413

Cumulative Model Updates: 107,620
Cumulative Timesteps: 897,491,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 897491852...
Checkpoint 897491852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,877.63710
Policy Entropy: 3.59229
Value Function Loss: 0.09503

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.49014
Value Function Update Magnitude: 0.55208

Collected Steps per Second: 22,661.28057
Overall Steps per Second: 10,672.81556

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.47849
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.68499

Cumulative Model Updates: 107,626
Cumulative Timesteps: 897,541,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,132.42325
Policy Entropy: 3.58846
Value Function Loss: 0.09951

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.48845
Value Function Update Magnitude: 0.56866

Collected Steps per Second: 22,460.32009
Overall Steps per Second: 10,599.82185

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71932

Cumulative Model Updates: 107,632
Cumulative Timesteps: 897,591,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 897591878...
Checkpoint 897591878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.18435
Policy Entropy: 3.57712
Value Function Loss: 0.10111

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.48600
Value Function Update Magnitude: 0.52079

Collected Steps per Second: 22,070.19429
Overall Steps per Second: 10,557.76535

Timestep Collection Time: 2.26613
Timestep Consumption Time: 2.47104
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.73718

Cumulative Model Updates: 107,638
Cumulative Timesteps: 897,641,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,927.72875
Policy Entropy: 3.58709
Value Function Loss: 0.09549

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.47051
Value Function Update Magnitude: 0.46714

Collected Steps per Second: 22,629.51306
Overall Steps per Second: 10,796.35537

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.42372
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.63508

Cumulative Model Updates: 107,644
Cumulative Timesteps: 897,691,934

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 897691934...
Checkpoint 897691934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,471.46805
Policy Entropy: 3.57819
Value Function Loss: 0.09291

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.49267
Value Function Update Magnitude: 0.50754

Collected Steps per Second: 22,225.16338
Overall Steps per Second: 10,650.99659

Timestep Collection Time: 2.25006
Timestep Consumption Time: 2.44509
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.69515

Cumulative Model Updates: 107,650
Cumulative Timesteps: 897,741,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,245.66412
Policy Entropy: 3.58712
Value Function Loss: 0.09191

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.48669
Value Function Update Magnitude: 0.51435

Collected Steps per Second: 22,996.31784
Overall Steps per Second: 10,645.77544

Timestep Collection Time: 2.17435
Timestep Consumption Time: 2.52254
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.69689

Cumulative Model Updates: 107,656
Cumulative Timesteps: 897,791,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 897791944...
Checkpoint 897791944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,034.14163
Policy Entropy: 3.58686
Value Function Loss: 0.09441

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.49271
Value Function Update Magnitude: 0.52650

Collected Steps per Second: 22,698.95380
Overall Steps per Second: 10,602.15614

Timestep Collection Time: 2.20371
Timestep Consumption Time: 2.51438
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.71810

Cumulative Model Updates: 107,662
Cumulative Timesteps: 897,841,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,845.89942
Policy Entropy: 3.58606
Value Function Loss: 0.09612

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.47920
Value Function Update Magnitude: 0.54854

Collected Steps per Second: 23,251.52913
Overall Steps per Second: 10,810.29952

Timestep Collection Time: 2.15091
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.62633

Cumulative Model Updates: 107,668
Cumulative Timesteps: 897,891,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 897891978...
Checkpoint 897891978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,367.32773
Policy Entropy: 3.58999
Value Function Loss: 0.10187

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.47739
Value Function Update Magnitude: 0.53432

Collected Steps per Second: 22,615.57456
Overall Steps per Second: 10,622.67693

Timestep Collection Time: 2.21193
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70917

Cumulative Model Updates: 107,674
Cumulative Timesteps: 897,942,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,528.27747
Policy Entropy: 3.57456
Value Function Loss: 0.10207

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.48875
Value Function Update Magnitude: 0.46324

Collected Steps per Second: 23,021.72259
Overall Steps per Second: 10,857.09828

Timestep Collection Time: 2.17290
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60749

Cumulative Model Updates: 107,680
Cumulative Timesteps: 897,992,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 897992026...
Checkpoint 897992026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.62398
Policy Entropy: 3.57028
Value Function Loss: 0.09930

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.45832
Value Function Update Magnitude: 0.53375

Collected Steps per Second: 22,374.23242
Overall Steps per Second: 10,741.71584

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.42033
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.65531

Cumulative Model Updates: 107,686
Cumulative Timesteps: 898,042,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,384.59073
Policy Entropy: 3.56750
Value Function Loss: 0.09377

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.65778

Collected Steps per Second: 22,768.14366
Overall Steps per Second: 10,805.79606

Timestep Collection Time: 2.19710
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62937

Cumulative Model Updates: 107,692
Cumulative Timesteps: 898,092,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 898092056...
Checkpoint 898092056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,268.98611
Policy Entropy: 3.57608
Value Function Loss: 0.09446

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.50728
Value Function Update Magnitude: 0.59071

Collected Steps per Second: 22,219.28720
Overall Steps per Second: 10,669.63519

Timestep Collection Time: 2.25174
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.68919

Cumulative Model Updates: 107,698
Cumulative Timesteps: 898,142,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,962.52645
Policy Entropy: 3.55790
Value Function Loss: 0.09962

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.50778
Value Function Update Magnitude: 0.53562

Collected Steps per Second: 22,459.88844
Overall Steps per Second: 10,595.74911

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.49408
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.72152

Cumulative Model Updates: 107,704
Cumulative Timesteps: 898,192,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 898192116...
Checkpoint 898192116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.27853
Policy Entropy: 3.56123
Value Function Loss: 0.09930

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.50632
Value Function Update Magnitude: 0.58295

Collected Steps per Second: 21,638.37903
Overall Steps per Second: 10,470.85089

Timestep Collection Time: 2.31191
Timestep Consumption Time: 2.46573
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.77764

Cumulative Model Updates: 107,710
Cumulative Timesteps: 898,242,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,490.61999
Policy Entropy: 3.54492
Value Function Loss: 0.10169

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.50375
Value Function Update Magnitude: 0.53998

Collected Steps per Second: 22,714.98883
Overall Steps per Second: 10,629.00076

Timestep Collection Time: 2.20207
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.70599

Cumulative Model Updates: 107,716
Cumulative Timesteps: 898,292,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 898292162...
Checkpoint 898292162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.44076
Policy Entropy: 3.55710
Value Function Loss: 0.10172

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.49568
Value Function Update Magnitude: 0.49631

Collected Steps per Second: 22,561.26275
Overall Steps per Second: 10,556.15694

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.52079
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.73733

Cumulative Model Updates: 107,722
Cumulative Timesteps: 898,342,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,735.15483
Policy Entropy: 3.55060
Value Function Loss: 0.10383

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.52590
Value Function Update Magnitude: 0.51847

Collected Steps per Second: 23,394.51919
Overall Steps per Second: 10,949.65807

Timestep Collection Time: 2.13751
Timestep Consumption Time: 2.42939
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.56690

Cumulative Model Updates: 107,728
Cumulative Timesteps: 898,392,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 898392176...
Checkpoint 898392176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,909.70664
Policy Entropy: 3.54140
Value Function Loss: 0.10171

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.49997
Value Function Update Magnitude: 0.53462

Collected Steps per Second: 22,582.55182
Overall Steps per Second: 10,610.46804

Timestep Collection Time: 2.21498
Timestep Consumption Time: 2.49923
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.71421

Cumulative Model Updates: 107,734
Cumulative Timesteps: 898,442,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,512.38909
Policy Entropy: 3.53606
Value Function Loss: 0.10165

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.55561

Collected Steps per Second: 23,213.84248
Overall Steps per Second: 10,903.56587

Timestep Collection Time: 2.15423
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.58639

Cumulative Model Updates: 107,740
Cumulative Timesteps: 898,492,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 898492204...
Checkpoint 898492204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,209.13754
Policy Entropy: 3.52679
Value Function Loss: 0.10239

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.48955
Value Function Update Magnitude: 0.60932

Collected Steps per Second: 22,091.76766
Overall Steps per Second: 10,631.27894

Timestep Collection Time: 2.26437
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.70536

Cumulative Model Updates: 107,746
Cumulative Timesteps: 898,542,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,780.42848
Policy Entropy: 3.52453
Value Function Loss: 0.10193

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.64232

Collected Steps per Second: 22,340.58203
Overall Steps per Second: 10,888.10304

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.35588
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.59566

Cumulative Model Updates: 107,752
Cumulative Timesteps: 898,592,266

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 898592266...
Checkpoint 898592266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,980.27784
Policy Entropy: 3.52673
Value Function Loss: 0.10220

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.53309
Value Function Update Magnitude: 0.70427

Collected Steps per Second: 21,722.50552
Overall Steps per Second: 10,703.99553

Timestep Collection Time: 2.30351
Timestep Consumption Time: 2.37119
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.67470

Cumulative Model Updates: 107,758
Cumulative Timesteps: 898,642,304

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,145.95566
Policy Entropy: 3.54224
Value Function Loss: 0.10140

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.60724
Value Function Update Magnitude: 0.72105

Collected Steps per Second: 21,830.70998
Overall Steps per Second: 10,637.64616

Timestep Collection Time: 2.29081
Timestep Consumption Time: 2.41042
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.70123

Cumulative Model Updates: 107,764
Cumulative Timesteps: 898,692,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 898692314...
Checkpoint 898692314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.63072
Policy Entropy: 3.54213
Value Function Loss: 0.10062

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.59603
Value Function Update Magnitude: 0.70495

Collected Steps per Second: 21,435.62922
Overall Steps per Second: 10,504.39116

Timestep Collection Time: 2.33359
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.76201

Cumulative Model Updates: 107,770
Cumulative Timesteps: 898,742,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,233.89824
Policy Entropy: 3.54001
Value Function Loss: 0.10134

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.16814
Policy Update Magnitude: 0.45951
Value Function Update Magnitude: 0.63718

Collected Steps per Second: 21,872.13471
Overall Steps per Second: 10,773.50996

Timestep Collection Time: 2.28620
Timestep Consumption Time: 2.35519
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.64138

Cumulative Model Updates: 107,776
Cumulative Timesteps: 898,792,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 898792340...
Checkpoint 898792340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,653.92914
Policy Entropy: 3.54403
Value Function Loss: 0.09820

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.16529
Policy Update Magnitude: 0.43078
Value Function Update Magnitude: 0.60992

Collected Steps per Second: 21,434.53251
Overall Steps per Second: 10,432.46425

Timestep Collection Time: 2.33371
Timestep Consumption Time: 2.46113
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.79484

Cumulative Model Updates: 107,782
Cumulative Timesteps: 898,842,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,758.26732
Policy Entropy: 3.54502
Value Function Loss: 0.09650

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.44046
Value Function Update Magnitude: 0.63128

Collected Steps per Second: 23,013.43623
Overall Steps per Second: 10,749.63952

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.65392

Cumulative Model Updates: 107,788
Cumulative Timesteps: 898,892,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 898892390...
Checkpoint 898892390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,347.63177
Policy Entropy: 3.55123
Value Function Loss: 0.09182

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.61647
Value Function Update Magnitude: 0.75467

Collected Steps per Second: 22,531.62519
Overall Steps per Second: 10,630.65177

Timestep Collection Time: 2.22017
Timestep Consumption Time: 2.48547
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.70564

Cumulative Model Updates: 107,794
Cumulative Timesteps: 898,942,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,543.08483
Policy Entropy: 3.56474
Value Function Loss: 0.09099

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.52784
Value Function Update Magnitude: 0.75995

Collected Steps per Second: 22,937.86031
Overall Steps per Second: 10,927.23241

Timestep Collection Time: 2.18059
Timestep Consumption Time: 2.39678
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.57737

Cumulative Model Updates: 107,800
Cumulative Timesteps: 898,992,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 898992432...
Checkpoint 898992432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,491.99556
Policy Entropy: 3.56838
Value Function Loss: 0.09396

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.19034
Policy Update Magnitude: 0.50044
Value Function Update Magnitude: 0.72354

Collected Steps per Second: 22,331.59576
Overall Steps per Second: 10,638.56510

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.70157

Cumulative Model Updates: 107,806
Cumulative Timesteps: 899,042,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,829.47529
Policy Entropy: 3.56124
Value Function Loss: 0.09263

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.17795
Policy Update Magnitude: 0.41512
Value Function Update Magnitude: 0.80473

Collected Steps per Second: 23,047.07057
Overall Steps per Second: 10,868.70852

Timestep Collection Time: 2.17077
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60312

Cumulative Model Updates: 107,812
Cumulative Timesteps: 899,092,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 899092480...
Checkpoint 899092480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,882.47174
Policy Entropy: 3.54755
Value Function Loss: 0.09549

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.16820
Policy Update Magnitude: 0.41699
Value Function Update Magnitude: 0.74242

Collected Steps per Second: 22,710.20599
Overall Steps per Second: 10,671.18524

Timestep Collection Time: 2.20192
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.68608

Cumulative Model Updates: 107,818
Cumulative Timesteps: 899,142,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,221.63715
Policy Entropy: 3.56388
Value Function Loss: 0.09416

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.44218
Value Function Update Magnitude: 0.61547

Collected Steps per Second: 22,649.48002
Overall Steps per Second: 10,666.24231

Timestep Collection Time: 2.20764
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68787

Cumulative Model Updates: 107,824
Cumulative Timesteps: 899,192,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 899192488...
Checkpoint 899192488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,723.90490
Policy Entropy: 3.56825
Value Function Loss: 0.09412

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.47789
Value Function Update Magnitude: 0.60461

Collected Steps per Second: 22,329.75571
Overall Steps per Second: 10,573.21795

Timestep Collection Time: 2.23934
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.72931

Cumulative Model Updates: 107,830
Cumulative Timesteps: 899,242,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,173.08887
Policy Entropy: 3.57720
Value Function Loss: 0.09079

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.51338
Value Function Update Magnitude: 0.64594

Collected Steps per Second: 22,908.55797
Overall Steps per Second: 10,731.97525

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.47757
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.66121

Cumulative Model Updates: 107,836
Cumulative Timesteps: 899,292,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 899292516...
Checkpoint 899292516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,038.11942
Policy Entropy: 3.56466
Value Function Loss: 0.09128

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.50630
Value Function Update Magnitude: 0.68144

Collected Steps per Second: 22,694.97983
Overall Steps per Second: 10,635.27089

Timestep Collection Time: 2.20313
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.70134

Cumulative Model Updates: 107,842
Cumulative Timesteps: 899,342,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,341.74011
Policy Entropy: 3.55890
Value Function Loss: 0.09271

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.50159
Value Function Update Magnitude: 0.65721

Collected Steps per Second: 22,968.16438
Overall Steps per Second: 10,833.00296

Timestep Collection Time: 2.17788
Timestep Consumption Time: 2.43967
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.61756

Cumulative Model Updates: 107,848
Cumulative Timesteps: 899,392,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 899392538...
Checkpoint 899392538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,527.35685
Policy Entropy: 3.56145
Value Function Loss: 0.09343

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.51202
Value Function Update Magnitude: 0.68384

Collected Steps per Second: 22,500.15538
Overall Steps per Second: 10,717.18007

Timestep Collection Time: 2.22354
Timestep Consumption Time: 2.44467
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.66821

Cumulative Model Updates: 107,854
Cumulative Timesteps: 899,442,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,056.70552
Policy Entropy: 3.57326
Value Function Loss: 0.09321

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.53565
Value Function Update Magnitude: 0.64365

Collected Steps per Second: 22,932.02278
Overall Steps per Second: 10,828.85737

Timestep Collection Time: 2.18062
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.61785

Cumulative Model Updates: 107,860
Cumulative Timesteps: 899,492,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 899492574...
Checkpoint 899492574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,406.14981
Policy Entropy: 3.56939
Value Function Loss: 0.09055

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.51698
Value Function Update Magnitude: 0.63680

Collected Steps per Second: 22,685.54404
Overall Steps per Second: 10,724.71948

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.45877
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.66343

Cumulative Model Updates: 107,866
Cumulative Timesteps: 899,542,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,807.66778
Policy Entropy: 3.57224
Value Function Loss: 0.09167

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.64767

Collected Steps per Second: 23,037.34027
Overall Steps per Second: 10,838.73865

Timestep Collection Time: 2.17074
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61382

Cumulative Model Updates: 107,872
Cumulative Timesteps: 899,592,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 899592596...
Checkpoint 899592596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.94493
Policy Entropy: 3.57334
Value Function Loss: 0.09355

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.62371
Value Function Update Magnitude: 0.66825

Collected Steps per Second: 22,259.35130
Overall Steps per Second: 10,783.26128

Timestep Collection Time: 2.24706
Timestep Consumption Time: 2.39143
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.63849

Cumulative Model Updates: 107,878
Cumulative Timesteps: 899,642,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.00653
Policy Entropy: 3.58718
Value Function Loss: 0.09157

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.16137
Policy Update Magnitude: 0.52749
Value Function Update Magnitude: 0.66960

Collected Steps per Second: 22,502.32431
Overall Steps per Second: 10,795.29458

Timestep Collection Time: 2.22324
Timestep Consumption Time: 2.41100
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.63424

Cumulative Model Updates: 107,884
Cumulative Timesteps: 899,692,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899692642...
Checkpoint 899692642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.99109
Policy Entropy: 3.59489
Value Function Loss: 0.09046

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.53467
Value Function Update Magnitude: 0.81536

Collected Steps per Second: 22,155.96858
Overall Steps per Second: 10,645.90126

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.44226
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.70115

Cumulative Model Updates: 107,890
Cumulative Timesteps: 899,742,690

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,513.53023
Policy Entropy: 3.57669
Value Function Loss: 0.08987

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.50790
Value Function Update Magnitude: 0.79240

Collected Steps per Second: 22,711.81341
Overall Steps per Second: 10,571.92812

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.52821
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.72988

Cumulative Model Updates: 107,896
Cumulative Timesteps: 899,792,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 899792694...
Checkpoint 899792694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,679.20275
Policy Entropy: 3.56437
Value Function Loss: 0.09170

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.44842
Value Function Update Magnitude: 0.66870

Collected Steps per Second: 22,171.30738
Overall Steps per Second: 10,579.42591

Timestep Collection Time: 2.25562
Timestep Consumption Time: 2.47148
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.72710

Cumulative Model Updates: 107,902
Cumulative Timesteps: 899,842,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.35763
Policy Entropy: 3.56250
Value Function Loss: 0.09143

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.42729
Value Function Update Magnitude: 0.64306

Collected Steps per Second: 22,779.60955
Overall Steps per Second: 10,803.70150

Timestep Collection Time: 2.19635
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.63101

Cumulative Model Updates: 107,908
Cumulative Timesteps: 899,892,736

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 899892736...
Checkpoint 899892736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,189.39037
Policy Entropy: 3.57796
Value Function Loss: 0.08860

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.43581
Value Function Update Magnitude: 0.72039

Collected Steps per Second: 22,406.20192
Overall Steps per Second: 10,713.17519

Timestep Collection Time: 2.23224
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.66864

Cumulative Model Updates: 107,914
Cumulative Timesteps: 899,942,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,874.19072
Policy Entropy: 3.56711
Value Function Loss: 0.09322

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.48762
Value Function Update Magnitude: 0.71924

Collected Steps per Second: 23,301.10943
Overall Steps per Second: 10,932.34173

Timestep Collection Time: 2.14694
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.57596

Cumulative Model Updates: 107,920
Cumulative Timesteps: 899,992,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 899992778...
Checkpoint 899992778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,823.46561
Policy Entropy: 3.56571
Value Function Loss: 0.09940

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.48126
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 22,729.43142
Overall Steps per Second: 10,650.19874

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.49566
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.69606

Cumulative Model Updates: 107,926
Cumulative Timesteps: 900,042,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,794.56239
Policy Entropy: 3.55667
Value Function Loss: 0.10385

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.48293
Value Function Update Magnitude: 0.55952

Collected Steps per Second: 22,669.23463
Overall Steps per Second: 10,698.74805

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.46909
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.67587

Cumulative Model Updates: 107,932
Cumulative Timesteps: 900,092,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 900092818...
Checkpoint 900092818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,795.01372
Policy Entropy: 3.55656
Value Function Loss: 0.10417

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.57051

Collected Steps per Second: 22,300.31100
Overall Steps per Second: 10,574.02927

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.48774
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.73103

Cumulative Model Updates: 107,938
Cumulative Timesteps: 900,142,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,815.20020
Policy Entropy: 3.54825
Value Function Loss: 0.10196

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.52064
Value Function Update Magnitude: 0.56280

Collected Steps per Second: 22,423.75053
Overall Steps per Second: 10,762.43872

Timestep Collection Time: 2.23121
Timestep Consumption Time: 2.41755
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.64876

Cumulative Model Updates: 107,944
Cumulative Timesteps: 900,192,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 900192876...
Checkpoint 900192876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,586.49972
Policy Entropy: 3.55184
Value Function Loss: 0.09896

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.46575
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 21,180.15681
Overall Steps per Second: 10,604.44668

Timestep Collection Time: 2.36212
Timestep Consumption Time: 2.35572
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.71783

Cumulative Model Updates: 107,950
Cumulative Timesteps: 900,242,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,625.64716
Policy Entropy: 3.55591
Value Function Loss: 0.09693

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.51561
Value Function Update Magnitude: 0.58669

Collected Steps per Second: 21,843.71148
Overall Steps per Second: 10,623.85079

Timestep Collection Time: 2.28899
Timestep Consumption Time: 2.41740
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.70639

Cumulative Model Updates: 107,956
Cumulative Timesteps: 900,292,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 900292906...
Checkpoint 900292906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,067.58330
Policy Entropy: 3.55683
Value Function Loss: 0.09433

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.51230
Value Function Update Magnitude: 0.59329

Collected Steps per Second: 21,715.81408
Overall Steps per Second: 10,573.31425

Timestep Collection Time: 2.30394
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.73191

Cumulative Model Updates: 107,962
Cumulative Timesteps: 900,342,938

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.90422
Policy Entropy: 3.56672
Value Function Loss: 0.09202

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.49657
Value Function Update Magnitude: 0.60669

Collected Steps per Second: 21,927.02144
Overall Steps per Second: 10,749.37720

Timestep Collection Time: 2.28129
Timestep Consumption Time: 2.37218
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.65348

Cumulative Model Updates: 107,968
Cumulative Timesteps: 900,392,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 900392960...
Checkpoint 900392960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,042.32539
Policy Entropy: 3.56369
Value Function Loss: 0.09306

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.49857
Value Function Update Magnitude: 0.61121

Collected Steps per Second: 21,852.02082
Overall Steps per Second: 10,735.07734

Timestep Collection Time: 2.28812
Timestep Consumption Time: 2.36951
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.65763

Cumulative Model Updates: 107,974
Cumulative Timesteps: 900,442,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,963.97002
Policy Entropy: 3.57128
Value Function Loss: 0.09788

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.51285
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 22,268.04825
Overall Steps per Second: 10,818.55451

Timestep Collection Time: 2.24681
Timestep Consumption Time: 2.37784
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.62465

Cumulative Model Updates: 107,980
Cumulative Timesteps: 900,492,992

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 900492992...
Checkpoint 900492992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.48575
Policy Entropy: 3.56751
Value Function Loss: 0.10222

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.61064

Collected Steps per Second: 22,230.11611
Overall Steps per Second: 10,749.10964

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.40273
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.65229

Cumulative Model Updates: 107,986
Cumulative Timesteps: 900,543,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,361.69024
Policy Entropy: 3.56422
Value Function Loss: 0.10166

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.48556
Value Function Update Magnitude: 0.61469

Collected Steps per Second: 23,280.04697
Overall Steps per Second: 10,870.81602

Timestep Collection Time: 2.14785
Timestep Consumption Time: 2.45181
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.59965

Cumulative Model Updates: 107,992
Cumulative Timesteps: 900,593,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 900593002...
Checkpoint 900593002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,892.57720
Policy Entropy: 3.55816
Value Function Loss: 0.10353

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.47245
Value Function Update Magnitude: 0.60231

Collected Steps per Second: 22,474.15012
Overall Steps per Second: 10,626.15223

Timestep Collection Time: 2.22611
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.70820

Cumulative Model Updates: 107,998
Cumulative Timesteps: 900,643,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.55727
Policy Entropy: 3.55591
Value Function Loss: 0.10003

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.50644
Value Function Update Magnitude: 0.64572

Collected Steps per Second: 22,682.66750
Overall Steps per Second: 10,817.26505

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.41927
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62483

Cumulative Model Updates: 108,004
Cumulative Timesteps: 900,693,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 900693060...
Checkpoint 900693060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,787.36243
Policy Entropy: 3.55536
Value Function Loss: 0.09768

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.52622
Value Function Update Magnitude: 0.60793

Collected Steps per Second: 22,163.64487
Overall Steps per Second: 10,730.14463

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.40527
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.66257

Cumulative Model Updates: 108,010
Cumulative Timesteps: 900,743,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,375.34668
Policy Entropy: 3.54608
Value Function Loss: 0.09727

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.68951
Value Function Update Magnitude: 0.58357

Collected Steps per Second: 22,518.38686
Overall Steps per Second: 10,597.19978

Timestep Collection Time: 2.22085
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.71917

Cumulative Model Updates: 108,016
Cumulative Timesteps: 900,793,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 900793100...
Checkpoint 900793100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,974.33092
Policy Entropy: 3.53906
Value Function Loss: 0.10263

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.70721
Value Function Update Magnitude: 0.60689

Collected Steps per Second: 22,585.45267
Overall Steps per Second: 10,615.80003

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.71109

Cumulative Model Updates: 108,022
Cumulative Timesteps: 900,843,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,305.87447
Policy Entropy: 3.54042
Value Function Loss: 0.10144

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.19476
Policy Update Magnitude: 0.55318
Value Function Update Magnitude: 0.64969

Collected Steps per Second: 23,101.65244
Overall Steps per Second: 10,800.54314

Timestep Collection Time: 2.16547
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.63180

Cumulative Model Updates: 108,028
Cumulative Timesteps: 900,893,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 900893138...
Checkpoint 900893138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,188.07080
Policy Entropy: 3.55388
Value Function Loss: 0.09562

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.17021
Policy Update Magnitude: 0.52730
Value Function Update Magnitude: 0.68704

Collected Steps per Second: 22,521.58435
Overall Steps per Second: 10,595.91043

Timestep Collection Time: 2.22063
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.71993

Cumulative Model Updates: 108,034
Cumulative Timesteps: 900,943,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,731.88574
Policy Entropy: 3.58472
Value Function Loss: 0.08944

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.15878
Policy Update Magnitude: 0.49319
Value Function Update Magnitude: 0.65886

Collected Steps per Second: 22,888.33760
Overall Steps per Second: 10,722.99678

Timestep Collection Time: 2.18513
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.66418

Cumulative Model Updates: 108,040
Cumulative Timesteps: 900,993,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 900993164...
Checkpoint 900993164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.93783
Policy Entropy: 3.60414
Value Function Loss: 0.09666

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.50855
Value Function Update Magnitude: 0.55940

Collected Steps per Second: 22,628.23215
Overall Steps per Second: 10,803.42188

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.41911
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62927

Cumulative Model Updates: 108,046
Cumulative Timesteps: 901,043,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,885.21144
Policy Entropy: 3.61257
Value Function Loss: 0.09534

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.55669
Value Function Update Magnitude: 0.42386

Collected Steps per Second: 22,895.38078
Overall Steps per Second: 10,652.78523

Timestep Collection Time: 2.18446
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.69492

Cumulative Model Updates: 108,052
Cumulative Timesteps: 901,093,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 901093190...
Checkpoint 901093190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.71766
Policy Entropy: 3.59934
Value Function Loss: 0.08888

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.33911

Collected Steps per Second: 22,697.58188
Overall Steps per Second: 10,662.26449

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69150

Cumulative Model Updates: 108,058
Cumulative Timesteps: 901,143,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,165.65097
Policy Entropy: 3.60800
Value Function Loss: 0.08858

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.59411
Value Function Update Magnitude: 0.33604

Collected Steps per Second: 22,444.59504
Overall Steps per Second: 10,733.04316

Timestep Collection Time: 2.22851
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.66019

Cumulative Model Updates: 108,064
Cumulative Timesteps: 901,193,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 901193230...
Checkpoint 901193230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,647.80098
Policy Entropy: 3.60420
Value Function Loss: 0.08015

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.63284
Value Function Update Magnitude: 0.37593

Collected Steps per Second: 22,325.60796
Overall Steps per Second: 10,760.01695

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.64981

Cumulative Model Updates: 108,070
Cumulative Timesteps: 901,243,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,311.96191
Policy Entropy: 3.61031
Value Function Loss: 0.08135

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.56347
Value Function Update Magnitude: 0.49222

Collected Steps per Second: 22,054.30020
Overall Steps per Second: 10,450.56352

Timestep Collection Time: 2.26749
Timestep Consumption Time: 2.51770
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.78520

Cumulative Model Updates: 108,076
Cumulative Timesteps: 901,293,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 901293270...
Checkpoint 901293270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,581.26070
Policy Entropy: 3.60479
Value Function Loss: 0.07959

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.57775

Collected Steps per Second: 22,300.56460
Overall Steps per Second: 10,578.74225

Timestep Collection Time: 2.24210
Timestep Consumption Time: 2.48436
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.72646

Cumulative Model Updates: 108,082
Cumulative Timesteps: 901,343,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,077.66973
Policy Entropy: 3.60932
Value Function Loss: 0.07851

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.61006
Value Function Update Magnitude: 0.68541

Collected Steps per Second: 22,845.82313
Overall Steps per Second: 10,837.09270

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61434

Cumulative Model Updates: 108,088
Cumulative Timesteps: 901,393,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 901393276...
Checkpoint 901393276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.15095
Policy Entropy: 3.60981
Value Function Loss: 0.07743

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.51399
Value Function Update Magnitude: 0.64976

Collected Steps per Second: 22,416.50558
Overall Steps per Second: 10,733.79692

Timestep Collection Time: 2.23050
Timestep Consumption Time: 2.42768
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.65818

Cumulative Model Updates: 108,094
Cumulative Timesteps: 901,443,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,342.59801
Policy Entropy: 3.62108
Value Function Loss: 0.07810

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.62560

Collected Steps per Second: 23,146.88216
Overall Steps per Second: 10,892.48174

Timestep Collection Time: 2.16124
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.59271

Cumulative Model Updates: 108,100
Cumulative Timesteps: 901,493,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 901493302...
Checkpoint 901493302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,057.52907
Policy Entropy: 3.61973
Value Function Loss: 0.07612

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07480
Policy Update Magnitude: 0.67450
Value Function Update Magnitude: 0.61575

Collected Steps per Second: 22,857.09690
Overall Steps per Second: 10,647.77868

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.50951
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.69807

Cumulative Model Updates: 108,106
Cumulative Timesteps: 901,543,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,286.37967
Policy Entropy: 3.61981
Value Function Loss: 0.07628

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.72544
Value Function Update Magnitude: 0.63455

Collected Steps per Second: 22,840.55044
Overall Steps per Second: 10,814.84352

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62328

Cumulative Model Updates: 108,112
Cumulative Timesteps: 901,593,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 901593326...
Checkpoint 901593326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,495.54096
Policy Entropy: 3.60876
Value Function Loss: 0.07344

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.74005
Value Function Update Magnitude: 0.74637

Collected Steps per Second: 22,787.63441
Overall Steps per Second: 10,671.03786

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.68595

Cumulative Model Updates: 108,118
Cumulative Timesteps: 901,643,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,554.02218
Policy Entropy: 3.60766
Value Function Loss: 0.07303

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.74652
Value Function Update Magnitude: 0.79197

Collected Steps per Second: 22,569.14050
Overall Steps per Second: 10,633.34175

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.70275

Cumulative Model Updates: 108,124
Cumulative Timesteps: 901,693,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 901693336...
Checkpoint 901693336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.93167
Policy Entropy: 3.60050
Value Function Loss: 0.07925

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.75026
Value Function Update Magnitude: 0.76284

Collected Steps per Second: 22,381.71702
Overall Steps per Second: 10,535.52599

Timestep Collection Time: 2.23468
Timestep Consumption Time: 2.51269
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.74737

Cumulative Model Updates: 108,130
Cumulative Timesteps: 901,743,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,427.00082
Policy Entropy: 3.60773
Value Function Loss: 0.08018

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.70692
Value Function Update Magnitude: 0.74706

Collected Steps per Second: 22,365.54786
Overall Steps per Second: 10,611.66959

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.47760
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.71443

Cumulative Model Updates: 108,136
Cumulative Timesteps: 901,793,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 901793380...
Checkpoint 901793380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,343.25969
Policy Entropy: 3.60764
Value Function Loss: 0.08183

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.55216
Value Function Update Magnitude: 0.65674

Collected Steps per Second: 22,174.18495
Overall Steps per Second: 10,520.89608

Timestep Collection Time: 2.25505
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.75283

Cumulative Model Updates: 108,142
Cumulative Timesteps: 901,843,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.38110
Policy Entropy: 3.62111
Value Function Loss: 0.08199

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.47913
Value Function Update Magnitude: 0.64030

Collected Steps per Second: 22,332.38955
Overall Steps per Second: 10,710.78964

Timestep Collection Time: 2.23989
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.67024

Cumulative Model Updates: 108,148
Cumulative Timesteps: 901,893,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 901893406...
Checkpoint 901893406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.43821
Policy Entropy: 3.60317
Value Function Loss: 0.08610

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.68000

Collected Steps per Second: 22,489.84281
Overall Steps per Second: 10,695.61513

Timestep Collection Time: 2.22367
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.67575

Cumulative Model Updates: 108,154
Cumulative Timesteps: 901,943,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,429.13737
Policy Entropy: 3.59128
Value Function Loss: 0.08582

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.58299
Value Function Update Magnitude: 0.70502

Collected Steps per Second: 23,155.37818
Overall Steps per Second: 10,951.86900

Timestep Collection Time: 2.15984
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.56653

Cumulative Model Updates: 108,160
Cumulative Timesteps: 901,993,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 901993428...
Checkpoint 901993428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,605.76007
Policy Entropy: 3.59041
Value Function Loss: 0.08756

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.68305

Collected Steps per Second: 22,501.41309
Overall Steps per Second: 10,658.56621

Timestep Collection Time: 2.22297
Timestep Consumption Time: 2.46997
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.69294

Cumulative Model Updates: 108,166
Cumulative Timesteps: 902,043,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,266.55558
Policy Entropy: 3.60635
Value Function Loss: 0.08555

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.67088

Collected Steps per Second: 21,649.52310
Overall Steps per Second: 10,436.63862

Timestep Collection Time: 2.30998
Timestep Consumption Time: 2.48179
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.79177

Cumulative Model Updates: 108,172
Cumulative Timesteps: 902,093,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 902093458...
Checkpoint 902093458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,231.23415
Policy Entropy: 3.59893
Value Function Loss: 0.08490

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.60389
Value Function Update Magnitude: 0.72687

Collected Steps per Second: 22,196.18073
Overall Steps per Second: 10,647.38335

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.44345
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.69618

Cumulative Model Updates: 108,178
Cumulative Timesteps: 902,143,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,891.75002
Policy Entropy: 3.61779
Value Function Loss: 0.08311

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.58677
Value Function Update Magnitude: 0.79401

Collected Steps per Second: 22,850.54258
Overall Steps per Second: 10,885.27425

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.40542
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59373

Cumulative Model Updates: 108,184
Cumulative Timesteps: 902,193,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 902193464...
Checkpoint 902193464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,234.28053
Policy Entropy: 3.62173
Value Function Loss: 0.08634

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.83111

Collected Steps per Second: 22,346.82087
Overall Steps per Second: 10,723.54362

Timestep Collection Time: 2.23880
Timestep Consumption Time: 2.42664
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.66544

Cumulative Model Updates: 108,190
Cumulative Timesteps: 902,243,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,011.60678
Policy Entropy: 3.61677
Value Function Loss: 0.08788

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.77988

Collected Steps per Second: 22,982.03479
Overall Steps per Second: 10,809.51289

Timestep Collection Time: 2.17666
Timestep Consumption Time: 2.45112
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.62778

Cumulative Model Updates: 108,196
Cumulative Timesteps: 902,293,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 902293518...
Checkpoint 902293518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.52198
Policy Entropy: 3.60476
Value Function Loss: 0.09191

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.52275
Value Function Update Magnitude: 0.66047

Collected Steps per Second: 22,725.78720
Overall Steps per Second: 10,645.70617

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.69974

Cumulative Model Updates: 108,202
Cumulative Timesteps: 902,343,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,989.35520
Policy Entropy: 3.59566
Value Function Loss: 0.09531

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.63048

Collected Steps per Second: 22,942.24762
Overall Steps per Second: 10,839.98318

Timestep Collection Time: 2.18017
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61421

Cumulative Model Updates: 108,208
Cumulative Timesteps: 902,393,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 902393568...
Checkpoint 902393568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,667.98880
Policy Entropy: 3.60450
Value Function Loss: 0.09549

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.16504
Policy Update Magnitude: 0.51587
Value Function Update Magnitude: 0.64363

Collected Steps per Second: 22,650.49455
Overall Steps per Second: 10,740.72782

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.44890
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.65741

Cumulative Model Updates: 108,214
Cumulative Timesteps: 902,443,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,895.55927
Policy Entropy: 3.62648
Value Function Loss: 0.09275

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.62794

Collected Steps per Second: 23,285.36352
Overall Steps per Second: 10,924.58256

Timestep Collection Time: 2.14830
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.57903

Cumulative Model Updates: 108,220
Cumulative Timesteps: 902,493,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 902493616...
Checkpoint 902493616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,070.82808
Policy Entropy: 3.63990
Value Function Loss: 0.08692

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07348
Policy Update Magnitude: 0.76999
Value Function Update Magnitude: 0.67718

Collected Steps per Second: 22,440.09009
Overall Steps per Second: 10,632.88481

Timestep Collection Time: 2.22833
Timestep Consumption Time: 2.47444
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.70277

Cumulative Model Updates: 108,226
Cumulative Timesteps: 902,543,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,596.84553
Policy Entropy: 3.62189
Value Function Loss: 0.08938

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.75239
Value Function Update Magnitude: 0.84079

Collected Steps per Second: 22,587.63127
Overall Steps per Second: 10,637.99085

Timestep Collection Time: 2.21449
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70202

Cumulative Model Updates: 108,232
Cumulative Timesteps: 902,593,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 902593640...
Checkpoint 902593640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,153.51366
Policy Entropy: 3.59354
Value Function Loss: 0.09857

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.60168
Value Function Update Magnitude: 0.76946

Collected Steps per Second: 22,136.12109
Overall Steps per Second: 10,610.69635

Timestep Collection Time: 2.26101
Timestep Consumption Time: 2.45593
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.71694

Cumulative Model Updates: 108,238
Cumulative Timesteps: 902,643,690

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,295.70126
Policy Entropy: 3.58028
Value Function Loss: 0.10110

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.56464
Value Function Update Magnitude: 0.72018

Collected Steps per Second: 22,806.57153
Overall Steps per Second: 10,753.91080

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.45820
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.65152

Cumulative Model Updates: 108,244
Cumulative Timesteps: 902,693,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 902693712...
Checkpoint 902693712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,371.42341
Policy Entropy: 3.57274
Value Function Loss: 0.09780

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.71713

Collected Steps per Second: 22,650.51416
Overall Steps per Second: 10,630.95426

Timestep Collection Time: 2.20790
Timestep Consumption Time: 2.49629
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.70419

Cumulative Model Updates: 108,250
Cumulative Timesteps: 902,743,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,093.74696
Policy Entropy: 3.56881
Value Function Loss: 0.09241

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.54666
Value Function Update Magnitude: 0.70534

Collected Steps per Second: 23,030.93348
Overall Steps per Second: 10,845.21480

Timestep Collection Time: 2.17143
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61125

Cumulative Model Updates: 108,256
Cumulative Timesteps: 902,793,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 902793732...
Checkpoint 902793732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,622.60311
Policy Entropy: 3.56222
Value Function Loss: 0.08860

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.58867
Value Function Update Magnitude: 0.80248

Collected Steps per Second: 22,483.14225
Overall Steps per Second: 10,735.94628

Timestep Collection Time: 2.22496
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.65949

Cumulative Model Updates: 108,262
Cumulative Timesteps: 902,843,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,560.14534
Policy Entropy: 3.56937
Value Function Loss: 0.08932

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.60289
Value Function Update Magnitude: 0.80027

Collected Steps per Second: 23,012.12102
Overall Steps per Second: 10,816.75402

Timestep Collection Time: 2.17364
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62431

Cumulative Model Updates: 108,268
Cumulative Timesteps: 902,893,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 902893776...
Checkpoint 902893776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,372.68243
Policy Entropy: 3.57325
Value Function Loss: 0.09080

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.57246
Value Function Update Magnitude: 0.80893

Collected Steps per Second: 22,515.08681
Overall Steps per Second: 10,760.26398

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.64821

Cumulative Model Updates: 108,274
Cumulative Timesteps: 902,943,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,475.71061
Policy Entropy: 3.57479
Value Function Loss: 0.09600

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.54924
Value Function Update Magnitude: 0.70337

Collected Steps per Second: 22,788.83701
Overall Steps per Second: 10,807.24012

Timestep Collection Time: 2.19493
Timestep Consumption Time: 2.43344
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.62838

Cumulative Model Updates: 108,280
Cumulative Timesteps: 902,993,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 902993812...
Checkpoint 902993812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,855.08480
Policy Entropy: 3.57066
Value Function Loss: 0.09687

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.56177
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 22,339.09299
Overall Steps per Second: 10,745.79824

Timestep Collection Time: 2.23841
Timestep Consumption Time: 2.41495
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.65335

Cumulative Model Updates: 108,286
Cumulative Timesteps: 903,043,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,887.47089
Policy Entropy: 3.56894
Value Function Loss: 0.10569

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.56338
Value Function Update Magnitude: 0.57667

Collected Steps per Second: 22,944.04806
Overall Steps per Second: 10,860.01145

Timestep Collection Time: 2.18061
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.60699

Cumulative Model Updates: 108,292
Cumulative Timesteps: 903,093,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 903093848...
Checkpoint 903093848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,504.94361
Policy Entropy: 3.56354
Value Function Loss: 0.10635

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.59943
Value Function Update Magnitude: 0.43659

Collected Steps per Second: 22,347.69729
Overall Steps per Second: 10,625.49573

Timestep Collection Time: 2.23871
Timestep Consumption Time: 2.46978
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.70849

Cumulative Model Updates: 108,298
Cumulative Timesteps: 903,143,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,115.17323
Policy Entropy: 3.56761
Value Function Loss: 0.10647

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.50490
Value Function Update Magnitude: 0.44836

Collected Steps per Second: 22,677.50910
Overall Steps per Second: 10,657.35510

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69404

Cumulative Model Updates: 108,304
Cumulative Timesteps: 903,193,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 903193904...
Checkpoint 903193904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,219.13604
Policy Entropy: 3.57271
Value Function Loss: 0.10264

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.46585
Value Function Update Magnitude: 0.52669

Collected Steps per Second: 22,796.70860
Overall Steps per Second: 10,588.15777

Timestep Collection Time: 2.19418
Timestep Consumption Time: 2.52997
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.72415

Cumulative Model Updates: 108,310
Cumulative Timesteps: 903,243,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,726.70229
Policy Entropy: 3.58342
Value Function Loss: 0.09728

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.46249
Value Function Update Magnitude: 0.53086

Collected Steps per Second: 23,167.86784
Overall Steps per Second: 10,730.42987

Timestep Collection Time: 2.15920
Timestep Consumption Time: 2.50268
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.66188

Cumulative Model Updates: 108,316
Cumulative Timesteps: 903,293,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 903293948...
Checkpoint 903293948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,359.46656
Policy Entropy: 3.57801
Value Function Loss: 0.09581

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.57602
Value Function Update Magnitude: 0.61171

Collected Steps per Second: 22,586.55104
Overall Steps per Second: 10,644.07617

Timestep Collection Time: 2.21512
Timestep Consumption Time: 2.48533
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.70045

Cumulative Model Updates: 108,322
Cumulative Timesteps: 903,343,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,159.63290
Policy Entropy: 3.58435
Value Function Loss: 0.09440

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.59909

Collected Steps per Second: 22,759.31508
Overall Steps per Second: 10,664.24466

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68988

Cumulative Model Updates: 108,328
Cumulative Timesteps: 903,393,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 903393994...
Checkpoint 903393994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.82305
Policy Entropy: 3.58725
Value Function Loss: 0.09979

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.43054
Value Function Update Magnitude: 0.57213

Collected Steps per Second: 22,721.86845
Overall Steps per Second: 10,855.51341

Timestep Collection Time: 2.20070
Timestep Consumption Time: 2.40562
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60632

Cumulative Model Updates: 108,334
Cumulative Timesteps: 903,443,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,266.03814
Policy Entropy: 3.56573
Value Function Loss: 0.10256

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.43341
Value Function Update Magnitude: 0.54938

Collected Steps per Second: 23,150.86396
Overall Steps per Second: 10,875.73732

Timestep Collection Time: 2.16070
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59941

Cumulative Model Updates: 108,340
Cumulative Timesteps: 903,494,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 903494020...
Checkpoint 903494020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,461.73536
Policy Entropy: 3.56168
Value Function Loss: 0.10337

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.51447
Value Function Update Magnitude: 0.54697

Collected Steps per Second: 21,978.95806
Overall Steps per Second: 10,631.91787

Timestep Collection Time: 2.27509
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.70320

Cumulative Model Updates: 108,346
Cumulative Timesteps: 903,544,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,214.24518
Policy Entropy: 3.55220
Value Function Loss: 0.10129

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.51245
Value Function Update Magnitude: 0.54345

Collected Steps per Second: 22,511.32588
Overall Steps per Second: 10,546.42369

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.52034
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.74189

Cumulative Model Updates: 108,352
Cumulative Timesteps: 903,594,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 903594034...
Checkpoint 903594034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,775.52577
Policy Entropy: 3.57752
Value Function Loss: 0.09804

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.57201
Value Function Update Magnitude: 0.51734

Collected Steps per Second: 22,354.67384
Overall Steps per Second: 10,658.77948

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.45528
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.69285

Cumulative Model Updates: 108,358
Cumulative Timesteps: 903,644,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,137.97457
Policy Entropy: 3.57020
Value Function Loss: 0.09450

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.51753
Value Function Update Magnitude: 0.69910

Collected Steps per Second: 22,475.97332
Overall Steps per Second: 10,574.98097

Timestep Collection Time: 2.22495
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.72890

Cumulative Model Updates: 108,364
Cumulative Timesteps: 903,694,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 903694062...
Checkpoint 903694062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.83676
Policy Entropy: 3.58306
Value Function Loss: 0.09302

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.50390
Value Function Update Magnitude: 0.77712

Collected Steps per Second: 22,328.16482
Overall Steps per Second: 10,544.51982

Timestep Collection Time: 2.23968
Timestep Consumption Time: 2.50288
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.74256

Cumulative Model Updates: 108,370
Cumulative Timesteps: 903,744,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,270.57214
Policy Entropy: 3.58652
Value Function Loss: 0.09107

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.49075
Value Function Update Magnitude: 0.79035

Collected Steps per Second: 23,188.24296
Overall Steps per Second: 10,780.04971

Timestep Collection Time: 2.15739
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.64061

Cumulative Model Updates: 108,376
Cumulative Timesteps: 903,794,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 903794096...
Checkpoint 903794096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,080.35548
Policy Entropy: 3.58488
Value Function Loss: 0.09117

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.74152

Collected Steps per Second: 22,487.35749
Overall Steps per Second: 10,713.09516

Timestep Collection Time: 2.22401
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.66831

Cumulative Model Updates: 108,382
Cumulative Timesteps: 903,844,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,514.82944
Policy Entropy: 3.58297
Value Function Loss: 0.09075

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.51912
Value Function Update Magnitude: 0.73214

Collected Steps per Second: 22,956.94838
Overall Steps per Second: 10,885.02347

Timestep Collection Time: 2.17921
Timestep Consumption Time: 2.41683
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59604

Cumulative Model Updates: 108,388
Cumulative Timesteps: 903,894,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 903894136...
Checkpoint 903894136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,952.05565
Policy Entropy: 3.58118
Value Function Loss: 0.09306

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.50895
Value Function Update Magnitude: 0.60595

Collected Steps per Second: 22,855.11441
Overall Steps per Second: 10,645.83845

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.50968
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69799

Cumulative Model Updates: 108,394
Cumulative Timesteps: 903,944,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,173.38492
Policy Entropy: 3.59053
Value Function Loss: 0.09410

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.51547
Value Function Update Magnitude: 0.54870

Collected Steps per Second: 23,140.10803
Overall Steps per Second: 10,892.92190

Timestep Collection Time: 2.16161
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59197

Cumulative Model Updates: 108,400
Cumulative Timesteps: 903,994,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 903994170...
Checkpoint 903994170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,624.24695
Policy Entropy: 3.59677
Value Function Loss: 0.09156

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.52656
Value Function Update Magnitude: 0.60887

Collected Steps per Second: 22,656.54437
Overall Steps per Second: 10,662.54222

Timestep Collection Time: 2.20784
Timestep Consumption Time: 2.48354
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.69138

Cumulative Model Updates: 108,406
Cumulative Timesteps: 904,044,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,606.57471
Policy Entropy: 3.59168
Value Function Loss: 0.08823

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.75866

Collected Steps per Second: 22,360.08978
Overall Steps per Second: 10,551.49442

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74170

Cumulative Model Updates: 108,412
Cumulative Timesteps: 904,094,224

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 904094224...
Checkpoint 904094224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,368.40967
Policy Entropy: 3.58847
Value Function Loss: 0.08708

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.57431
Value Function Update Magnitude: 0.77825

Collected Steps per Second: 22,276.07343
Overall Steps per Second: 10,567.41024

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.73418

Cumulative Model Updates: 108,418
Cumulative Timesteps: 904,144,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,907.88320
Policy Entropy: 3.56918
Value Function Loss: 0.09166

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.60302
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,506.15647
Overall Steps per Second: 10,842.00853

Timestep Collection Time: 2.22197
Timestep Consumption Time: 2.39046
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61243

Cumulative Model Updates: 108,424
Cumulative Timesteps: 904,194,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 904194260...
Checkpoint 904194260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,061.38959
Policy Entropy: 3.56753
Value Function Loss: 0.09474

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.59352
Value Function Update Magnitude: 0.56905

Collected Steps per Second: 21,925.03355
Overall Steps per Second: 10,506.51294

Timestep Collection Time: 2.28132
Timestep Consumption Time: 2.47935
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.76067

Cumulative Model Updates: 108,430
Cumulative Timesteps: 904,244,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,315.65246
Policy Entropy: 3.56707
Value Function Loss: 0.09836

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.48611
Value Function Update Magnitude: 0.56629

Collected Steps per Second: 22,847.14032
Overall Steps per Second: 10,702.22183

Timestep Collection Time: 2.18916
Timestep Consumption Time: 2.48426
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.67342

Cumulative Model Updates: 108,436
Cumulative Timesteps: 904,294,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 904294294...
Checkpoint 904294294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,428.79467
Policy Entropy: 3.57841
Value Function Loss: 0.09584

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.52988
Value Function Update Magnitude: 0.58415

Collected Steps per Second: 22,674.03622
Overall Steps per Second: 10,586.48810

Timestep Collection Time: 2.20525
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.72319

Cumulative Model Updates: 108,442
Cumulative Timesteps: 904,344,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,094.75395
Policy Entropy: 3.58426
Value Function Loss: 0.09476

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11790
Policy Update Magnitude: 0.58202
Value Function Update Magnitude: 0.65148

Collected Steps per Second: 23,255.22138
Overall Steps per Second: 10,888.74842

Timestep Collection Time: 2.15066
Timestep Consumption Time: 2.44252
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.59318

Cumulative Model Updates: 108,448
Cumulative Timesteps: 904,394,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 904394310...
Checkpoint 904394310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.89171
Policy Entropy: 3.57622
Value Function Loss: 0.09052

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.62866
Value Function Update Magnitude: 0.66456

Collected Steps per Second: 22,545.65432
Overall Steps per Second: 10,661.69357

Timestep Collection Time: 2.21888
Timestep Consumption Time: 2.47325
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.69213

Cumulative Model Updates: 108,454
Cumulative Timesteps: 904,444,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,560.92306
Policy Entropy: 3.58224
Value Function Loss: 0.09101

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.59916
Value Function Update Magnitude: 0.65221

Collected Steps per Second: 22,815.54414
Overall Steps per Second: 10,847.42846

Timestep Collection Time: 2.19254
Timestep Consumption Time: 2.41906
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61160

Cumulative Model Updates: 108,460
Cumulative Timesteps: 904,494,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 904494360...
Checkpoint 904494360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,481.81068
Policy Entropy: 3.59246
Value Function Loss: 0.08761

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.58742
Value Function Update Magnitude: 0.76011

Collected Steps per Second: 22,373.74089
Overall Steps per Second: 10,742.47734

Timestep Collection Time: 2.23503
Timestep Consumption Time: 2.41995
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.65498

Cumulative Model Updates: 108,466
Cumulative Timesteps: 904,544,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.12346
Policy Entropy: 3.60654
Value Function Loss: 0.08668

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.76727

Collected Steps per Second: 22,548.51784
Overall Steps per Second: 10,659.89819

Timestep Collection Time: 2.21921
Timestep Consumption Time: 2.47501
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.69423

Cumulative Model Updates: 108,472
Cumulative Timesteps: 904,594,406

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 904594406...
Checkpoint 904594406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.59735
Policy Entropy: 3.60966
Value Function Loss: 0.09035

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.71374

Collected Steps per Second: 22,501.62669
Overall Steps per Second: 10,612.51563

Timestep Collection Time: 2.22446
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.71651

Cumulative Model Updates: 108,478
Cumulative Timesteps: 904,644,460

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,083.03132
Policy Entropy: 3.60240
Value Function Loss: 0.09614

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.70510

Collected Steps per Second: 22,860.38616
Overall Steps per Second: 10,741.07096

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.46823
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.65577

Cumulative Model Updates: 108,484
Cumulative Timesteps: 904,694,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 904694468...
Checkpoint 904694468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,713.38068
Policy Entropy: 3.60648
Value Function Loss: 0.09536

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.52734
Value Function Update Magnitude: 0.72319

Collected Steps per Second: 22,468.54606
Overall Steps per Second: 10,599.41424

Timestep Collection Time: 2.22711
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.72102

Cumulative Model Updates: 108,490
Cumulative Timesteps: 904,744,508

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,415.89659
Policy Entropy: 3.59798
Value Function Loss: 0.09542

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.65813

Collected Steps per Second: 22,964.67320
Overall Steps per Second: 10,658.73247

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.69287

Cumulative Model Updates: 108,496
Cumulative Timesteps: 904,794,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 904794528...
Checkpoint 904794528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,445.39998
Policy Entropy: 3.60011
Value Function Loss: 0.09326

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.74541

Collected Steps per Second: 22,865.97349
Overall Steps per Second: 10,829.83391

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61965

Cumulative Model Updates: 108,502
Cumulative Timesteps: 904,844,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,960.27763
Policy Entropy: 3.60184
Value Function Loss: 0.09302

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.53232
Value Function Update Magnitude: 0.72994

Collected Steps per Second: 22,977.60687
Overall Steps per Second: 10,713.39187

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.66724

Cumulative Model Updates: 108,508
Cumulative Timesteps: 904,894,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 904894560...
Checkpoint 904894560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,262.27231
Policy Entropy: 3.59062
Value Function Loss: 0.08881

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.73289

Collected Steps per Second: 22,726.73669
Overall Steps per Second: 10,787.28780

Timestep Collection Time: 2.20049
Timestep Consumption Time: 2.43552
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.63601

Cumulative Model Updates: 108,514
Cumulative Timesteps: 904,944,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,351.27407
Policy Entropy: 3.57133
Value Function Loss: 0.08859

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.64139
Value Function Update Magnitude: 0.74401

Collected Steps per Second: 21,940.91124
Overall Steps per Second: 10,608.74769

Timestep Collection Time: 2.27949
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.71441

Cumulative Model Updates: 108,520
Cumulative Timesteps: 904,994,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 904994584...
Checkpoint 904994584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,356.83989
Policy Entropy: 3.56122
Value Function Loss: 0.08824

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.57961
Value Function Update Magnitude: 0.78330

Collected Steps per Second: 22,610.23484
Overall Steps per Second: 10,581.00508

Timestep Collection Time: 2.21280
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72847

Cumulative Model Updates: 108,526
Cumulative Timesteps: 905,044,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,947.68347
Policy Entropy: 3.57234
Value Function Loss: 0.08677

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.65400
Value Function Update Magnitude: 0.82898

Collected Steps per Second: 22,442.88541
Overall Steps per Second: 10,560.94521

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.50705
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73537

Cumulative Model Updates: 108,532
Cumulative Timesteps: 905,094,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 905094626...
Checkpoint 905094626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,037.88264
Policy Entropy: 3.59289
Value Function Loss: 0.08736

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.70092
Value Function Update Magnitude: 0.81192

Collected Steps per Second: 22,037.05810
Overall Steps per Second: 10,548.12768

Timestep Collection Time: 2.26972
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.74188

Cumulative Model Updates: 108,538
Cumulative Timesteps: 905,144,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,437.16693
Policy Entropy: 3.59380
Value Function Loss: 0.08847

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.60162
Value Function Update Magnitude: 0.87280

Collected Steps per Second: 22,838.28838
Overall Steps per Second: 10,835.06845

Timestep Collection Time: 2.19001
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.61612

Cumulative Model Updates: 108,544
Cumulative Timesteps: 905,194,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 905194660...
Checkpoint 905194660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,615.68664
Policy Entropy: 3.59257
Value Function Loss: 0.09117

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.61117
Value Function Update Magnitude: 0.88021

Collected Steps per Second: 22,019.01396
Overall Steps per Second: 10,651.67952

Timestep Collection Time: 2.27131
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.69522

Cumulative Model Updates: 108,550
Cumulative Timesteps: 905,244,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,717.25467
Policy Entropy: 3.58556
Value Function Loss: 0.08855

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.81343

Collected Steps per Second: 22,416.82574
Overall Steps per Second: 10,506.88856

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75935

Cumulative Model Updates: 108,556
Cumulative Timesteps: 905,294,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 905294678...
Checkpoint 905294678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,722.65660
Policy Entropy: 3.60101
Value Function Loss: 0.09071

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.50498
Value Function Update Magnitude: 0.77439

Collected Steps per Second: 21,596.48120
Overall Steps per Second: 10,529.51948

Timestep Collection Time: 2.31547
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.74912

Cumulative Model Updates: 108,562
Cumulative Timesteps: 905,344,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,235.15130
Policy Entropy: 3.59089
Value Function Loss: 0.08812

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.45925
Value Function Update Magnitude: 0.67346

Collected Steps per Second: 22,900.68470
Overall Steps per Second: 10,648.49061

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.69588

Cumulative Model Updates: 108,568
Cumulative Timesteps: 905,394,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 905394688...
Checkpoint 905394688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,046.93259
Policy Entropy: 3.60140
Value Function Loss: 0.08680

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.63974

Collected Steps per Second: 22,098.06326
Overall Steps per Second: 10,717.23257

Timestep Collection Time: 2.26382
Timestep Consumption Time: 2.40399
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.66781

Cumulative Model Updates: 108,574
Cumulative Timesteps: 905,444,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,952.30810
Policy Entropy: 3.61298
Value Function Loss: 0.07998

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.52157
Value Function Update Magnitude: 0.70378

Collected Steps per Second: 22,589.03479
Overall Steps per Second: 10,722.82300

Timestep Collection Time: 2.21364
Timestep Consumption Time: 2.44968
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.66332

Cumulative Model Updates: 108,580
Cumulative Timesteps: 905,494,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 905494718...
Checkpoint 905494718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.54293
Policy Entropy: 3.61176
Value Function Loss: 0.07402

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.53919
Value Function Update Magnitude: 0.72725

Collected Steps per Second: 22,042.64583
Overall Steps per Second: 10,627.34157

Timestep Collection Time: 2.26960
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70748

Cumulative Model Updates: 108,586
Cumulative Timesteps: 905,544,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,118.85121
Policy Entropy: 3.62450
Value Function Loss: 0.06956

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.54128
Value Function Update Magnitude: 0.68495

Collected Steps per Second: 22,153.70824
Overall Steps per Second: 10,850.22128

Timestep Collection Time: 2.25777
Timestep Consumption Time: 2.35209
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.60986

Cumulative Model Updates: 108,592
Cumulative Timesteps: 905,594,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 905594764...
Checkpoint 905594764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,308.13352
Policy Entropy: 3.62636
Value Function Loss: 0.06288

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.61965
Value Function Update Magnitude: 0.76978

Collected Steps per Second: 22,059.48686
Overall Steps per Second: 10,742.12381

Timestep Collection Time: 2.26687
Timestep Consumption Time: 2.38826
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.65513

Cumulative Model Updates: 108,598
Cumulative Timesteps: 905,644,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.72655
Policy Entropy: 3.64203
Value Function Loss: 0.05768

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.73411
Value Function Update Magnitude: 0.75839

Collected Steps per Second: 21,724.40647
Overall Steps per Second: 10,630.21465

Timestep Collection Time: 2.30266
Timestep Consumption Time: 2.40317
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.70583

Cumulative Model Updates: 108,604
Cumulative Timesteps: 905,694,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 905694794...
Checkpoint 905694794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,709.99141
Policy Entropy: 3.64939
Value Function Loss: 0.05403

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.72098
Value Function Update Magnitude: 0.79734

Collected Steps per Second: 21,786.64325
Overall Steps per Second: 10,618.90106

Timestep Collection Time: 2.29590
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.71047

Cumulative Model Updates: 108,610
Cumulative Timesteps: 905,744,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,984.14679
Policy Entropy: 3.64695
Value Function Loss: 0.05517

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.66895
Value Function Update Magnitude: 0.81356

Collected Steps per Second: 21,863.37580
Overall Steps per Second: 10,791.28063

Timestep Collection Time: 2.28830
Timestep Consumption Time: 2.34785
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.63615

Cumulative Model Updates: 108,616
Cumulative Timesteps: 905,794,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 905794844...
Checkpoint 905794844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,332.34215
Policy Entropy: 3.65806
Value Function Loss: 0.05724

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.72131
Value Function Update Magnitude: 0.80106

Collected Steps per Second: 21,736.47125
Overall Steps per Second: 10,556.24101

Timestep Collection Time: 2.30129
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.73862

Cumulative Model Updates: 108,622
Cumulative Timesteps: 905,844,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,442.99274
Policy Entropy: 3.65377
Value Function Loss: 0.05730

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.66862
Value Function Update Magnitude: 0.80241

Collected Steps per Second: 22,828.98273
Overall Steps per Second: 10,703.28244

Timestep Collection Time: 2.19090
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.67296

Cumulative Model Updates: 108,628
Cumulative Timesteps: 905,894,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 905894882...
Checkpoint 905894882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.46194
Policy Entropy: 3.66646
Value Function Loss: 0.05385

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.61228
Value Function Update Magnitude: 0.78307

Collected Steps per Second: 22,236.14347
Overall Steps per Second: 10,504.32283

Timestep Collection Time: 2.24868
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.76014

Cumulative Model Updates: 108,634
Cumulative Timesteps: 905,944,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.93649
Policy Entropy: 3.65617
Value Function Loss: 0.05311

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.68078
Value Function Update Magnitude: 0.74662

Collected Steps per Second: 23,058.42774
Overall Steps per Second: 10,861.38863

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.60567

Cumulative Model Updates: 108,640
Cumulative Timesteps: 905,994,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 905994908...
Checkpoint 905994908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,685.22621
Policy Entropy: 3.65880
Value Function Loss: 0.05392

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.64166
Value Function Update Magnitude: 0.73614

Collected Steps per Second: 22,482.27872
Overall Steps per Second: 10,670.76062

Timestep Collection Time: 2.22495
Timestep Consumption Time: 2.46281
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.68776

Cumulative Model Updates: 108,646
Cumulative Timesteps: 906,044,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,115.87628
Policy Entropy: 3.65110
Value Function Loss: 0.05613

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.63779
Value Function Update Magnitude: 0.74930

Collected Steps per Second: 22,958.75793
Overall Steps per Second: 10,808.76172

Timestep Collection Time: 2.17808
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62643

Cumulative Model Updates: 108,652
Cumulative Timesteps: 906,094,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 906094936...
Checkpoint 906094936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.12388
Policy Entropy: 3.65845
Value Function Loss: 0.05726

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.62034
Value Function Update Magnitude: 0.76810

Collected Steps per Second: 22,652.14580
Overall Steps per Second: 10,669.73386

Timestep Collection Time: 2.20844
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.68859

Cumulative Model Updates: 108,658
Cumulative Timesteps: 906,144,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,566.67154
Policy Entropy: 3.66427
Value Function Loss: 0.05890

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.79689

Collected Steps per Second: 23,107.42161
Overall Steps per Second: 10,865.49072

Timestep Collection Time: 2.16485
Timestep Consumption Time: 2.43909
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60393

Cumulative Model Updates: 108,664
Cumulative Timesteps: 906,194,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 906194986...
Checkpoint 906194986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,637.05164
Policy Entropy: 3.66737
Value Function Loss: 0.05827

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.64191
Value Function Update Magnitude: 0.80736

Collected Steps per Second: 22,177.34970
Overall Steps per Second: 10,712.88389

Timestep Collection Time: 2.25473
Timestep Consumption Time: 2.41292
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.66765

Cumulative Model Updates: 108,670
Cumulative Timesteps: 906,244,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,124.22400
Policy Entropy: 3.67608
Value Function Loss: 0.05744

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.62279
Value Function Update Magnitude: 0.79131

Collected Steps per Second: 22,557.79940
Overall Steps per Second: 10,637.56197

Timestep Collection Time: 2.21759
Timestep Consumption Time: 2.48499
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.70258

Cumulative Model Updates: 108,676
Cumulative Timesteps: 906,295,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 906295014...
Checkpoint 906295014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.59266
Policy Entropy: 3.67598
Value Function Loss: 0.05879

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.61312
Value Function Update Magnitude: 0.77730

Collected Steps per Second: 22,582.48613
Overall Steps per Second: 10,819.32535

Timestep Collection Time: 2.21535
Timestep Consumption Time: 2.40860
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62395

Cumulative Model Updates: 108,682
Cumulative Timesteps: 906,345,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,359.76033
Policy Entropy: 3.67130
Value Function Loss: 0.06231

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.66310
Value Function Update Magnitude: 0.79779

Collected Steps per Second: 22,592.73672
Overall Steps per Second: 10,663.23979

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.47700
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.69107

Cumulative Model Updates: 108,688
Cumulative Timesteps: 906,395,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 906395064...
Checkpoint 906395064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,141.30022
Policy Entropy: 3.65233
Value Function Loss: 0.06714

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.77944
Value Function Update Magnitude: 0.81689

Collected Steps per Second: 22,393.22999
Overall Steps per Second: 10,488.61965

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.53436
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.76726

Cumulative Model Updates: 108,694
Cumulative Timesteps: 906,445,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,896.62663
Policy Entropy: 3.64503
Value Function Loss: 0.06936

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.87525
Value Function Update Magnitude: 0.80900

Collected Steps per Second: 22,337.22538
Overall Steps per Second: 10,461.83198

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.54147
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.78042

Cumulative Model Updates: 108,700
Cumulative Timesteps: 906,495,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 906495078...
Checkpoint 906495078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,722.83491
Policy Entropy: 3.64313
Value Function Loss: 0.07184

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.89165
Value Function Update Magnitude: 0.86401

Collected Steps per Second: 22,616.95706
Overall Steps per Second: 10,642.39600

Timestep Collection Time: 2.21091
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.69857

Cumulative Model Updates: 108,706
Cumulative Timesteps: 906,545,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,438.96887
Policy Entropy: 3.63639
Value Function Loss: 0.07179

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.84471
Value Function Update Magnitude: 0.91314

Collected Steps per Second: 23,177.20827
Overall Steps per Second: 10,879.36793

Timestep Collection Time: 2.15772
Timestep Consumption Time: 2.43905
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59677

Cumulative Model Updates: 108,712
Cumulative Timesteps: 906,595,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 906595092...
Checkpoint 906595092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.06449
Policy Entropy: 3.62503
Value Function Loss: 0.07169

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.68654
Value Function Update Magnitude: 0.91563

Collected Steps per Second: 22,666.34028
Overall Steps per Second: 10,649.90871

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.48946
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69581

Cumulative Model Updates: 108,718
Cumulative Timesteps: 906,645,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,765.86070
Policy Entropy: 3.62554
Value Function Loss: 0.07437

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.65017
Value Function Update Magnitude: 0.88853

Collected Steps per Second: 22,799.36450
Overall Steps per Second: 10,814.31559

Timestep Collection Time: 2.19392
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.62535

Cumulative Model Updates: 108,724
Cumulative Timesteps: 906,695,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 906695122...
Checkpoint 906695122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,523.08396
Policy Entropy: 3.61722
Value Function Loss: 0.07578

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.64221
Value Function Update Magnitude: 0.91700

Collected Steps per Second: 22,546.23797
Overall Steps per Second: 10,777.62580

Timestep Collection Time: 2.21935
Timestep Consumption Time: 2.42342
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.64277

Cumulative Model Updates: 108,730
Cumulative Timesteps: 906,745,160

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,797.27851
Policy Entropy: 3.61618
Value Function Loss: 0.07647

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.74392
Value Function Update Magnitude: 0.84246

Collected Steps per Second: 22,458.64295
Overall Steps per Second: 10,621.06354

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.71196

Cumulative Model Updates: 108,736
Cumulative Timesteps: 906,795,206

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 906795206...
Checkpoint 906795206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.17134
Policy Entropy: 3.61543
Value Function Loss: 0.07816

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.70985
Value Function Update Magnitude: 0.77675

Collected Steps per Second: 22,345.23051
Overall Steps per Second: 10,620.18734

Timestep Collection Time: 2.23815
Timestep Consumption Time: 2.47099
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.70914

Cumulative Model Updates: 108,742
Cumulative Timesteps: 906,845,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,692.48545
Policy Entropy: 3.61733
Value Function Loss: 0.07857

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.66899
Value Function Update Magnitude: 0.78371

Collected Steps per Second: 22,706.33420
Overall Steps per Second: 10,726.44680

Timestep Collection Time: 2.20212
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.66156

Cumulative Model Updates: 108,748
Cumulative Timesteps: 906,895,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 906895220...
Checkpoint 906895220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,682.93162
Policy Entropy: 3.61849
Value Function Loss: 0.07889

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.60797
Value Function Update Magnitude: 0.75459

Collected Steps per Second: 22,081.96627
Overall Steps per Second: 10,625.83712

Timestep Collection Time: 2.26465
Timestep Consumption Time: 2.44161
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.70626

Cumulative Model Updates: 108,754
Cumulative Timesteps: 906,945,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,554.18848
Policy Entropy: 3.62335
Value Function Loss: 0.07961

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.62401
Value Function Update Magnitude: 0.75764

Collected Steps per Second: 22,947.75801
Overall Steps per Second: 10,665.97955

Timestep Collection Time: 2.17904
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.68818

Cumulative Model Updates: 108,760
Cumulative Timesteps: 906,995,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 906995232...
Checkpoint 906995232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,891.57939
Policy Entropy: 3.62052
Value Function Loss: 0.08091

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.74363
Value Function Update Magnitude: 0.74888

Collected Steps per Second: 22,918.13041
Overall Steps per Second: 10,852.61034

Timestep Collection Time: 2.18177
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60737

Cumulative Model Updates: 108,766
Cumulative Timesteps: 907,045,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,819.08045
Policy Entropy: 3.60937
Value Function Loss: 0.08040

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.59971
Value Function Update Magnitude: 0.75082

Collected Steps per Second: 22,930.68010
Overall Steps per Second: 10,835.81556

Timestep Collection Time: 2.18127
Timestep Consumption Time: 2.43472
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.61599

Cumulative Model Updates: 108,772
Cumulative Timesteps: 907,095,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 907095252...
Checkpoint 907095252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,527.94855
Policy Entropy: 3.60999
Value Function Loss: 0.08144

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.72625

Collected Steps per Second: 22,477.85532
Overall Steps per Second: 10,759.47977

Timestep Collection Time: 2.22557
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.64948

Cumulative Model Updates: 108,778
Cumulative Timesteps: 907,145,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,467.61106
Policy Entropy: 3.61722
Value Function Loss: 0.08430

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.63280
Value Function Update Magnitude: 0.71284

Collected Steps per Second: 23,273.77015
Overall Steps per Second: 10,933.88747

Timestep Collection Time: 2.14903
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.57440

Cumulative Model Updates: 108,784
Cumulative Timesteps: 907,195,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 907195294...
Checkpoint 907195294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,514.77927
Policy Entropy: 3.62581
Value Function Loss: 0.08317

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.62342
Value Function Update Magnitude: 0.73588

Collected Steps per Second: 21,993.24757
Overall Steps per Second: 10,616.88568

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.71023

Cumulative Model Updates: 108,790
Cumulative Timesteps: 907,245,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,167.92425
Policy Entropy: 3.62790
Value Function Loss: 0.08176

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11708
Policy Update Magnitude: 0.65061
Value Function Update Magnitude: 0.74342

Collected Steps per Second: 21,911.90531
Overall Steps per Second: 10,637.23305

Timestep Collection Time: 2.28241
Timestep Consumption Time: 2.41919
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.70160

Cumulative Model Updates: 108,796
Cumulative Timesteps: 907,295,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 907295314...
Checkpoint 907295314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,869.13092
Policy Entropy: 3.64044
Value Function Loss: 0.07894

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.70005
Value Function Update Magnitude: 0.68196

Collected Steps per Second: 21,660.13777
Overall Steps per Second: 10,621.61568

Timestep Collection Time: 2.30968
Timestep Consumption Time: 2.40034
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.71002

Cumulative Model Updates: 108,802
Cumulative Timesteps: 907,345,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.73126
Policy Entropy: 3.64237
Value Function Loss: 0.08033

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.74882
Value Function Update Magnitude: 0.65876

Collected Steps per Second: 21,954.04816
Overall Steps per Second: 10,778.15940

Timestep Collection Time: 2.27748
Timestep Consumption Time: 2.36153
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.63901

Cumulative Model Updates: 108,808
Cumulative Timesteps: 907,395,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 907395342...
Checkpoint 907395342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,980.22415
Policy Entropy: 3.63927
Value Function Loss: 0.08129

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.67480
Value Function Update Magnitude: 0.76791

Collected Steps per Second: 21,898.92267
Overall Steps per Second: 10,592.77547

Timestep Collection Time: 2.28404
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72190

Cumulative Model Updates: 108,814
Cumulative Timesteps: 907,445,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,701.28587
Policy Entropy: 3.62875
Value Function Loss: 0.08007

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.61460
Value Function Update Magnitude: 0.82600

Collected Steps per Second: 21,922.09788
Overall Steps per Second: 10,647.56925

Timestep Collection Time: 2.28162
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.69760

Cumulative Model Updates: 108,820
Cumulative Timesteps: 907,495,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 907495378...
Checkpoint 907495378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,736.81363
Policy Entropy: 3.61931
Value Function Loss: 0.08003

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.66100
Value Function Update Magnitude: 0.83088

Collected Steps per Second: 22,333.70817
Overall Steps per Second: 10,877.49159

Timestep Collection Time: 2.23931
Timestep Consumption Time: 2.35845
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.59775

Cumulative Model Updates: 108,826
Cumulative Timesteps: 907,545,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,721.71402
Policy Entropy: 3.61791
Value Function Loss: 0.08113

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.68138
Value Function Update Magnitude: 0.80561

Collected Steps per Second: 22,423.75299
Overall Steps per Second: 10,677.05694

Timestep Collection Time: 2.23076
Timestep Consumption Time: 2.45424
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68500

Cumulative Model Updates: 108,832
Cumulative Timesteps: 907,595,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 907595412...
Checkpoint 907595412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,157.32301
Policy Entropy: 3.61271
Value Function Loss: 0.08956

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.65726
Value Function Update Magnitude: 0.69184

Collected Steps per Second: 22,753.19375
Overall Steps per Second: 10,903.59215

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.38949
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.58821

Cumulative Model Updates: 108,838
Cumulative Timesteps: 907,645,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,293.10242
Policy Entropy: 3.61051
Value Function Loss: 0.09158

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.58803
Value Function Update Magnitude: 0.72524

Collected Steps per Second: 22,883.02613
Overall Steps per Second: 10,869.61837

Timestep Collection Time: 2.18572
Timestep Consumption Time: 2.41572
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.60145

Cumulative Model Updates: 108,844
Cumulative Timesteps: 907,695,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 907695456...
Checkpoint 907695456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,425.85928
Policy Entropy: 3.62190
Value Function Loss: 0.09118

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.52840
Value Function Update Magnitude: 0.75544

Collected Steps per Second: 22,269.07069
Overall Steps per Second: 10,688.21813

Timestep Collection Time: 2.24634
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.68029

Cumulative Model Updates: 108,850
Cumulative Timesteps: 907,745,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,881.68065
Policy Entropy: 3.63412
Value Function Loss: 0.09061

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.77713

Collected Steps per Second: 22,722.99185
Overall Steps per Second: 10,860.92009

Timestep Collection Time: 2.20112
Timestep Consumption Time: 2.40402
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60513

Cumulative Model Updates: 108,856
Cumulative Timesteps: 907,795,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 907795496...
Checkpoint 907795496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.73039
Policy Entropy: 3.62952
Value Function Loss: 0.09284

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.62677
Value Function Update Magnitude: 0.73947

Collected Steps per Second: 21,117.42028
Overall Steps per Second: 10,230.74784

Timestep Collection Time: 2.36828
Timestep Consumption Time: 2.52012
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.88840

Cumulative Model Updates: 108,862
Cumulative Timesteps: 907,845,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,297.80718
Policy Entropy: 3.60521
Value Function Loss: 0.09533

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10322
Policy Update Magnitude: 0.71525
Value Function Update Magnitude: 0.72033

Collected Steps per Second: 22,452.65275
Overall Steps per Second: 10,523.27893

Timestep Collection Time: 2.22824
Timestep Consumption Time: 2.52598
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.75422

Cumulative Model Updates: 108,868
Cumulative Timesteps: 907,895,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 907895538...
Checkpoint 907895538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,845.99474
Policy Entropy: 3.60067
Value Function Loss: 0.09428

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.68218
Value Function Update Magnitude: 0.76454

Collected Steps per Second: 22,185.25271
Overall Steps per Second: 10,634.47680

Timestep Collection Time: 2.25501
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.70432

Cumulative Model Updates: 108,874
Cumulative Timesteps: 907,945,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,681.07677
Policy Entropy: 3.59712
Value Function Loss: 0.09059

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.66129
Value Function Update Magnitude: 0.80765

Collected Steps per Second: 22,971.31581
Overall Steps per Second: 10,814.88048

Timestep Collection Time: 2.17663
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.62326

Cumulative Model Updates: 108,880
Cumulative Timesteps: 907,995,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 907995566...
Checkpoint 907995566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,362.84575
Policy Entropy: 3.63587
Value Function Loss: 0.08511

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.65187
Value Function Update Magnitude: 0.83117

Collected Steps per Second: 22,396.05346
Overall Steps per Second: 10,763.41071

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.41312
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.64593

Cumulative Model Updates: 108,886
Cumulative Timesteps: 908,045,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,202.73528
Policy Entropy: 3.64731
Value Function Loss: 0.08195

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.66406
Value Function Update Magnitude: 0.83582

Collected Steps per Second: 22,911.75790
Overall Steps per Second: 10,819.67552

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.44039
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.62398

Cumulative Model Updates: 108,892
Cumulative Timesteps: 908,095,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 908095602...
Checkpoint 908095602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,543.44903
Policy Entropy: 3.67433
Value Function Loss: 0.07851

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.72291
Value Function Update Magnitude: 0.89538

Collected Steps per Second: 22,696.13044
Overall Steps per Second: 10,646.17911

Timestep Collection Time: 2.20425
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.69915

Cumulative Model Updates: 108,898
Cumulative Timesteps: 908,145,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,128.96647
Policy Entropy: 3.67024
Value Function Loss: 0.07979

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.74124
Value Function Update Magnitude: 0.96871

Collected Steps per Second: 23,139.85492
Overall Steps per Second: 10,892.25485

Timestep Collection Time: 2.16207
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.59317

Cumulative Model Updates: 108,904
Cumulative Timesteps: 908,195,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 908195660...
Checkpoint 908195660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,682.79033
Policy Entropy: 3.66350
Value Function Loss: 0.07900

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.76526
Value Function Update Magnitude: 0.97974

Collected Steps per Second: 22,312.14550
Overall Steps per Second: 10,718.95915

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.66482

Cumulative Model Updates: 108,910
Cumulative Timesteps: 908,245,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.01504
Policy Entropy: 3.64583
Value Function Loss: 0.08130

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.63800
Value Function Update Magnitude: 0.87512

Collected Steps per Second: 22,475.35520
Overall Steps per Second: 10,643.98265

Timestep Collection Time: 2.22626
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.70087

Cumulative Model Updates: 108,916
Cumulative Timesteps: 908,295,698

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 908295698...
Checkpoint 908295698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,498.83878
Policy Entropy: 3.64676
Value Function Loss: 0.08139

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.56419
Value Function Update Magnitude: 0.84586

Collected Steps per Second: 22,036.27807
Overall Steps per Second: 10,521.46930

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.48469
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.75504

Cumulative Model Updates: 108,922
Cumulative Timesteps: 908,345,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,481.26547
Policy Entropy: 3.65056
Value Function Loss: 0.07879

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.53097
Value Function Update Magnitude: 0.97122

Collected Steps per Second: 22,493.87161
Overall Steps per Second: 10,749.12105

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.65210

Cumulative Model Updates: 108,928
Cumulative Timesteps: 908,395,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 908395734...
Checkpoint 908395734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,102.68459
Policy Entropy: 3.66587
Value Function Loss: 0.07704

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.66948
Value Function Update Magnitude: 0.98574

Collected Steps per Second: 22,372.52741
Overall Steps per Second: 10,749.97438

Timestep Collection Time: 2.23569
Timestep Consumption Time: 2.41716
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.65285

Cumulative Model Updates: 108,934
Cumulative Timesteps: 908,445,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.50047
Policy Entropy: 3.66429
Value Function Loss: 0.07454

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.68159
Value Function Update Magnitude: 0.99902

Collected Steps per Second: 22,766.71700
Overall Steps per Second: 10,729.20443

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.66092

Cumulative Model Updates: 108,940
Cumulative Timesteps: 908,495,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 908495760...
Checkpoint 908495760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.62256
Policy Entropy: 3.65308
Value Function Loss: 0.07233

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.71897
Value Function Update Magnitude: 0.98577

Collected Steps per Second: 22,588.92261
Overall Steps per Second: 10,691.39428

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.46466
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.67946

Cumulative Model Updates: 108,946
Cumulative Timesteps: 908,545,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,554.93814
Policy Entropy: 3.63974
Value Function Loss: 0.07444

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.80044
Value Function Update Magnitude: 0.96951

Collected Steps per Second: 22,631.96667
Overall Steps per Second: 10,666.19303

Timestep Collection Time: 2.20979
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.68883

Cumulative Model Updates: 108,952
Cumulative Timesteps: 908,595,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 908595802...
Checkpoint 908595802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.46186
Policy Entropy: 3.63917
Value Function Loss: 0.07328

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.73109
Value Function Update Magnitude: 0.96245

Collected Steps per Second: 22,570.33564
Overall Steps per Second: 10,646.84150

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.48143
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.69717

Cumulative Model Updates: 108,958
Cumulative Timesteps: 908,645,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,467.45005
Policy Entropy: 3.64579
Value Function Loss: 0.07663

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.64891
Value Function Update Magnitude: 0.92234

Collected Steps per Second: 23,050.28796
Overall Steps per Second: 10,714.64708

Timestep Collection Time: 2.17021
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.66875

Cumulative Model Updates: 108,964
Cumulative Timesteps: 908,695,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 908695836...
Checkpoint 908695836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,494.72619
Policy Entropy: 3.65198
Value Function Loss: 0.07778

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.65249
Value Function Update Magnitude: 0.94774

Collected Steps per Second: 22,795.84268
Overall Steps per Second: 10,639.95117

Timestep Collection Time: 2.19365
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.69983

Cumulative Model Updates: 108,970
Cumulative Timesteps: 908,745,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,725.84777
Policy Entropy: 3.64264
Value Function Loss: 0.08227

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.66211
Value Function Update Magnitude: 0.95391

Collected Steps per Second: 22,286.99493
Overall Steps per Second: 10,862.67014

Timestep Collection Time: 2.24481
Timestep Consumption Time: 2.36087
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60568

Cumulative Model Updates: 108,976
Cumulative Timesteps: 908,795,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 908795872...
Checkpoint 908795872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,217.72123
Policy Entropy: 3.64826
Value Function Loss: 0.08263

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.64637
Value Function Update Magnitude: 0.96891

Collected Steps per Second: 21,434.33053
Overall Steps per Second: 10,669.38278

Timestep Collection Time: 2.33271
Timestep Consumption Time: 2.35360
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.68631

Cumulative Model Updates: 108,982
Cumulative Timesteps: 908,845,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,464.65336
Policy Entropy: 3.66447
Value Function Loss: 0.07785

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.15774
Policy Update Magnitude: 0.65038
Value Function Update Magnitude: 0.97318

Collected Steps per Second: 21,638.21991
Overall Steps per Second: 10,523.83191

Timestep Collection Time: 2.31193
Timestep Consumption Time: 2.44166
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.75359

Cumulative Model Updates: 108,988
Cumulative Timesteps: 908,895,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 908895898...
Checkpoint 908895898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,468.75551
Policy Entropy: 3.68087
Value Function Loss: 0.07055

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.67924
Value Function Update Magnitude: 0.96118

Collected Steps per Second: 21,697.27114
Overall Steps per Second: 10,592.80505

Timestep Collection Time: 2.30508
Timestep Consumption Time: 2.41642
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.72151

Cumulative Model Updates: 108,994
Cumulative Timesteps: 908,945,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,577.43591
Policy Entropy: 3.68761
Value Function Loss: 0.06635

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.76345
Value Function Update Magnitude: 0.93690

Collected Steps per Second: 21,447.36253
Overall Steps per Second: 10,439.18978

Timestep Collection Time: 2.33222
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.79156

Cumulative Model Updates: 109,000
Cumulative Timesteps: 908,995,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 908995932...
Checkpoint 908995932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,499.44864
Policy Entropy: 3.68995
Value Function Loss: 0.06421

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.69255
Value Function Update Magnitude: 0.93493

Collected Steps per Second: 20,704.83046
Overall Steps per Second: 10,261.07736

Timestep Collection Time: 2.41509
Timestep Consumption Time: 2.45808
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.87317

Cumulative Model Updates: 109,006
Cumulative Timesteps: 909,045,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,384.54890
Policy Entropy: 3.69728
Value Function Loss: 0.06621

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.61857
Value Function Update Magnitude: 0.93045

Collected Steps per Second: 22,009.85650
Overall Steps per Second: 10,446.61439

Timestep Collection Time: 2.27198
Timestep Consumption Time: 2.51483
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.78681

Cumulative Model Updates: 109,012
Cumulative Timesteps: 909,095,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 909095942...
Checkpoint 909095942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,477.96036
Policy Entropy: 3.68416
Value Function Loss: 0.07040

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.64791
Value Function Update Magnitude: 0.94420

Collected Steps per Second: 22,591.89148
Overall Steps per Second: 10,644.52524

Timestep Collection Time: 2.21371
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.69838

Cumulative Model Updates: 109,018
Cumulative Timesteps: 909,145,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,639.77323
Policy Entropy: 3.67556
Value Function Loss: 0.07467

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.62157
Value Function Update Magnitude: 0.94454

Collected Steps per Second: 22,850.07202
Overall Steps per Second: 10,884.76485

Timestep Collection Time: 2.18879
Timestep Consumption Time: 2.40607
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.59486

Cumulative Model Updates: 109,024
Cumulative Timesteps: 909,195,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 909195968...
Checkpoint 909195968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855.00871
Policy Entropy: 3.66075
Value Function Loss: 0.07573

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.71744
Value Function Update Magnitude: 0.95391

Collected Steps per Second: 22,919.81210
Overall Steps per Second: 10,789.36894

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.45307
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.63493

Cumulative Model Updates: 109,030
Cumulative Timesteps: 909,245,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.18064
Policy Entropy: 3.66682
Value Function Loss: 0.07494

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.69857
Value Function Update Magnitude: 0.96226

Collected Steps per Second: 22,822.54787
Overall Steps per Second: 10,706.84697

Timestep Collection Time: 2.19090
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.67010

Cumulative Model Updates: 109,036
Cumulative Timesteps: 909,295,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 909295978...
Checkpoint 909295978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,114.69414
Policy Entropy: 3.67279
Value Function Loss: 0.07453

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.79487
Value Function Update Magnitude: 0.88741

Collected Steps per Second: 22,690.14682
Overall Steps per Second: 10,640.48502

Timestep Collection Time: 2.20386
Timestep Consumption Time: 2.49573
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.69960

Cumulative Model Updates: 109,042
Cumulative Timesteps: 909,345,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,564.65816
Policy Entropy: 3.68204
Value Function Loss: 0.07454

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.80540
Value Function Update Magnitude: 0.84162

Collected Steps per Second: 22,065.41279
Overall Steps per Second: 10,549.73936

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.47475
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.74192

Cumulative Model Updates: 109,048
Cumulative Timesteps: 909,396,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 909396010...
Checkpoint 909396010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,133.15352
Policy Entropy: 3.68320
Value Function Loss: 0.07501

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.66358
Value Function Update Magnitude: 0.82156

Collected Steps per Second: 22,171.14122
Overall Steps per Second: 10,595.66254

Timestep Collection Time: 2.25681
Timestep Consumption Time: 2.46550
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72231

Cumulative Model Updates: 109,054
Cumulative Timesteps: 909,446,046

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.62989
Policy Entropy: 3.68092
Value Function Loss: 0.07427

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.65721
Value Function Update Magnitude: 0.82805

Collected Steps per Second: 22,572.30806
Overall Steps per Second: 10,803.45310

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.62982

Cumulative Model Updates: 109,060
Cumulative Timesteps: 909,496,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 909496064...
Checkpoint 909496064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.17437
Policy Entropy: 3.67179
Value Function Loss: 0.07381

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.66562
Value Function Update Magnitude: 0.87836

Collected Steps per Second: 22,479.40744
Overall Steps per Second: 10,655.63953

Timestep Collection Time: 2.22461
Timestep Consumption Time: 2.46849
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.69310

Cumulative Model Updates: 109,066
Cumulative Timesteps: 909,546,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,422.57964
Policy Entropy: 3.67190
Value Function Loss: 0.06976

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.71478
Value Function Update Magnitude: 0.87831

Collected Steps per Second: 22,987.45671
Overall Steps per Second: 10,908.41599

Timestep Collection Time: 2.17606
Timestep Consumption Time: 2.40958
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.58563

Cumulative Model Updates: 109,072
Cumulative Timesteps: 909,596,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 909596094...
Checkpoint 909596094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,475.24602
Policy Entropy: 3.67770
Value Function Loss: 0.07261

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.70339
Value Function Update Magnitude: 0.86206

Collected Steps per Second: 22,360.48603
Overall Steps per Second: 10,671.15998

Timestep Collection Time: 2.23680
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.68703

Cumulative Model Updates: 109,078
Cumulative Timesteps: 909,646,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,081.78080
Policy Entropy: 3.69750
Value Function Loss: 0.06890

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.92614

Collected Steps per Second: 22,505.20168
Overall Steps per Second: 10,569.03046

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.50940
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.73137

Cumulative Model Updates: 109,084
Cumulative Timesteps: 909,696,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 909696116...
Checkpoint 909696116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.37385
Policy Entropy: 3.68906
Value Function Loss: 0.07119

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.58384
Value Function Update Magnitude: 0.95467

Collected Steps per Second: 21,917.75587
Overall Steps per Second: 10,544.48407

Timestep Collection Time: 2.28189
Timestep Consumption Time: 2.46125
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.74314

Cumulative Model Updates: 109,090
Cumulative Timesteps: 909,746,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.99919
Policy Entropy: 3.68408
Value Function Loss: 0.07073

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.57918
Value Function Update Magnitude: 0.94592

Collected Steps per Second: 22,937.11784
Overall Steps per Second: 10,831.89223

Timestep Collection Time: 2.18040
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61711

Cumulative Model Updates: 109,096
Cumulative Timesteps: 909,796,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 909796142...
Checkpoint 909796142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.44192
Policy Entropy: 3.66569
Value Function Loss: 0.07263

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.61119
Value Function Update Magnitude: 0.96067

Collected Steps per Second: 22,505.59265
Overall Steps per Second: 10,717.17583

Timestep Collection Time: 2.22220
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.66653

Cumulative Model Updates: 109,102
Cumulative Timesteps: 909,846,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.78304
Policy Entropy: 3.66014
Value Function Loss: 0.07136

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.96074

Collected Steps per Second: 22,497.68059
Overall Steps per Second: 10,686.93601

Timestep Collection Time: 2.22352
Timestep Consumption Time: 2.45734
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.68086

Cumulative Model Updates: 109,108
Cumulative Timesteps: 909,896,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 909896178...
Checkpoint 909896178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,513.49575
Policy Entropy: 3.66582
Value Function Loss: 0.06956

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.52255
Value Function Update Magnitude: 0.92626

Collected Steps per Second: 22,501.71806
Overall Steps per Second: 10,624.07839

Timestep Collection Time: 2.22330
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.70893

Cumulative Model Updates: 109,114
Cumulative Timesteps: 909,946,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,025.50387
Policy Entropy: 3.66404
Value Function Loss: 0.07132

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.50165
Value Function Update Magnitude: 0.79853

Collected Steps per Second: 22,854.93024
Overall Steps per Second: 10,735.01284

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.65822

Cumulative Model Updates: 109,120
Cumulative Timesteps: 909,996,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 909996212...
Checkpoint 909996212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.98121
Policy Entropy: 3.66990
Value Function Loss: 0.07347

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.49931
Value Function Update Magnitude: 0.76050

Collected Steps per Second: 22,566.57410
Overall Steps per Second: 10,605.89326

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.49869
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71436

Cumulative Model Updates: 109,126
Cumulative Timesteps: 910,046,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,217.28170
Policy Entropy: 3.65971
Value Function Loss: 0.07703

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.68438

Collected Steps per Second: 23,193.27337
Overall Steps per Second: 10,814.47636

Timestep Collection Time: 2.15588
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62362

Cumulative Model Updates: 109,132
Cumulative Timesteps: 910,096,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 910096214...
Checkpoint 910096214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,461.95931
Policy Entropy: 3.64958
Value Function Loss: 0.07679

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.56408
Value Function Update Magnitude: 0.70518

Collected Steps per Second: 22,444.30523
Overall Steps per Second: 10,726.44265

Timestep Collection Time: 2.22783
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.66156

Cumulative Model Updates: 109,138
Cumulative Timesteps: 910,146,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,325.92192
Policy Entropy: 3.64519
Value Function Loss: 0.07583

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.81872

Collected Steps per Second: 22,750.28257
Overall Steps per Second: 10,830.78794

Timestep Collection Time: 2.19777
Timestep Consumption Time: 2.41869
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.61647

Cumulative Model Updates: 109,144
Cumulative Timesteps: 910,196,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 910196216...
Checkpoint 910196216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,434.28317
Policy Entropy: 3.63508
Value Function Loss: 0.07699

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.62118
Value Function Update Magnitude: 0.88031

Collected Steps per Second: 22,764.42817
Overall Steps per Second: 10,717.10809

Timestep Collection Time: 2.19746
Timestep Consumption Time: 2.47021
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.66768

Cumulative Model Updates: 109,150
Cumulative Timesteps: 910,246,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,359.38650
Policy Entropy: 3.63663
Value Function Loss: 0.07960

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.90575

Collected Steps per Second: 22,740.83606
Overall Steps per Second: 10,786.30624

Timestep Collection Time: 2.19878
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.63569

Cumulative Model Updates: 109,156
Cumulative Timesteps: 910,296,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 910296242...
Checkpoint 910296242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,254.49940
Policy Entropy: 3.62306
Value Function Loss: 0.07928

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.42582
Value Function Update Magnitude: 0.91661

Collected Steps per Second: 22,601.40448
Overall Steps per Second: 10,770.21305

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.64243

Cumulative Model Updates: 109,162
Cumulative Timesteps: 910,346,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,640.83696
Policy Entropy: 3.62532
Value Function Loss: 0.07853

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.38723
Value Function Update Magnitude: 0.85839

Collected Steps per Second: 22,057.02775
Overall Steps per Second: 10,463.94924

Timestep Collection Time: 2.26758
Timestep Consumption Time: 2.51226
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.77984

Cumulative Model Updates: 109,168
Cumulative Timesteps: 910,396,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 910396258...
Checkpoint 910396258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,097.49156
Policy Entropy: 3.63740
Value Function Loss: 0.07606

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.44887
Value Function Update Magnitude: 0.77575

Collected Steps per Second: 22,467.17288
Overall Steps per Second: 10,637.04896

Timestep Collection Time: 2.22574
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.70112

Cumulative Model Updates: 109,174
Cumulative Timesteps: 910,446,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,302.27290
Policy Entropy: 3.64036
Value Function Loss: 0.07465

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.45481
Value Function Update Magnitude: 0.71226

Collected Steps per Second: 22,398.40702
Overall Steps per Second: 10,779.51976

Timestep Collection Time: 2.23239
Timestep Consumption Time: 2.40622
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.63861

Cumulative Model Updates: 109,180
Cumulative Timesteps: 910,496,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 910496266...
Checkpoint 910496266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.91767
Policy Entropy: 3.64333
Value Function Loss: 0.07118

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.51309
Value Function Update Magnitude: 0.71635

Collected Steps per Second: 22,914.19501
Overall Steps per Second: 10,713.51280

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.48565
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.66831

Cumulative Model Updates: 109,186
Cumulative Timesteps: 910,546,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.87920
Policy Entropy: 3.64908
Value Function Loss: 0.06880

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.74673

Collected Steps per Second: 22,775.55180
Overall Steps per Second: 10,844.58234

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.41603
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61207

Cumulative Model Updates: 109,192
Cumulative Timesteps: 910,596,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 910596296...
Checkpoint 910596296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,179.73396
Policy Entropy: 3.64577
Value Function Loss: 0.06740

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.53063
Value Function Update Magnitude: 0.72392

Collected Steps per Second: 22,546.05806
Overall Steps per Second: 10,695.84460

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.45742
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.67546

Cumulative Model Updates: 109,198
Cumulative Timesteps: 910,646,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,241.32247
Policy Entropy: 3.66182
Value Function Loss: 0.06635

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.51544
Value Function Update Magnitude: 0.72007

Collected Steps per Second: 22,513.16483
Overall Steps per Second: 10,685.93634

Timestep Collection Time: 2.22128
Timestep Consumption Time: 2.45852
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.67980

Cumulative Model Updates: 109,204
Cumulative Timesteps: 910,696,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 910696312...
Checkpoint 910696312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.42309
Policy Entropy: 3.66338
Value Function Loss: 0.06561

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.49949
Value Function Update Magnitude: 0.72437

Collected Steps per Second: 22,713.49252
Overall Steps per Second: 10,774.91040

Timestep Collection Time: 2.20178
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.64134

Cumulative Model Updates: 109,210
Cumulative Timesteps: 910,746,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.71313
Policy Entropy: 3.66857
Value Function Loss: 0.06220

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.74159

Collected Steps per Second: 22,584.10248
Overall Steps per Second: 10,607.76450

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.50038
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71504

Cumulative Model Updates: 109,216
Cumulative Timesteps: 910,796,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 910796338...
Checkpoint 910796338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.92582
Policy Entropy: 3.66593
Value Function Loss: 0.06171

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.63322
Value Function Update Magnitude: 0.78289

Collected Steps per Second: 22,839.97242
Overall Steps per Second: 10,666.78522

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.68745

Cumulative Model Updates: 109,222
Cumulative Timesteps: 910,846,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,255.79496
Policy Entropy: 3.66755
Value Function Loss: 0.06041

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06581
Policy Update Magnitude: 0.72885
Value Function Update Magnitude: 0.78201

Collected Steps per Second: 22,405.91067
Overall Steps per Second: 10,727.69825

Timestep Collection Time: 2.23325
Timestep Consumption Time: 2.43112
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.66437

Cumulative Model Updates: 109,228
Cumulative Timesteps: 910,896,376

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 910896376...
Checkpoint 910896376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.55617
Policy Entropy: 3.66066
Value Function Loss: 0.06091

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.79421
Value Function Update Magnitude: 0.78255

Collected Steps per Second: 22,102.06341
Overall Steps per Second: 10,646.88424

Timestep Collection Time: 2.26241
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.69659

Cumulative Model Updates: 109,234
Cumulative Timesteps: 910,946,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,384.23384
Policy Entropy: 3.64772
Value Function Loss: 0.06136

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.82167
Value Function Update Magnitude: 0.77567

Collected Steps per Second: 22,713.87247
Overall Steps per Second: 10,639.61404

Timestep Collection Time: 2.20315
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.70337

Cumulative Model Updates: 109,240
Cumulative Timesteps: 910,996,422

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 910996422...
Checkpoint 910996422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.68349
Policy Entropy: 3.63804
Value Function Loss: 0.06361

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.80294
Value Function Update Magnitude: 0.76771

Collected Steps per Second: 22,353.20396
Overall Steps per Second: 10,533.27018

Timestep Collection Time: 2.23717
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.74762

Cumulative Model Updates: 109,246
Cumulative Timesteps: 911,046,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,219.68462
Policy Entropy: 3.63319
Value Function Loss: 0.06722

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.80095
Value Function Update Magnitude: 0.77233

Collected Steps per Second: 22,708.88206
Overall Steps per Second: 10,548.77348

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.53902
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.74159

Cumulative Model Updates: 109,252
Cumulative Timesteps: 911,096,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 911096448...
Checkpoint 911096448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.47923
Policy Entropy: 3.63822
Value Function Loss: 0.07071

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.78980
Value Function Update Magnitude: 0.78882

Collected Steps per Second: 22,511.72367
Overall Steps per Second: 10,538.75958

Timestep Collection Time: 2.22204
Timestep Consumption Time: 2.52444
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.74648

Cumulative Model Updates: 109,258
Cumulative Timesteps: 911,146,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.41883
Policy Entropy: 3.64907
Value Function Loss: 0.07231

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.81465
Value Function Update Magnitude: 0.80054

Collected Steps per Second: 23,115.49260
Overall Steps per Second: 10,873.58759

Timestep Collection Time: 2.16478
Timestep Consumption Time: 2.43720
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60198

Cumulative Model Updates: 109,264
Cumulative Timesteps: 911,196,510

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 911196510...
Checkpoint 911196510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,805.14396
Policy Entropy: 3.65054
Value Function Loss: 0.07178

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07420
Policy Update Magnitude: 0.78233
Value Function Update Magnitude: 0.81244

Collected Steps per Second: 22,711.27220
Overall Steps per Second: 10,707.35665

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.46903
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.67137

Cumulative Model Updates: 109,270
Cumulative Timesteps: 911,246,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,858.88275
Policy Entropy: 3.64334
Value Function Loss: 0.07512

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.80399
Value Function Update Magnitude: 0.77021

Collected Steps per Second: 22,894.31822
Overall Steps per Second: 10,835.23013

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.43150
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.61624

Cumulative Model Updates: 109,276
Cumulative Timesteps: 911,296,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 911296546...
Checkpoint 911296546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,039.38284
Policy Entropy: 3.61849
Value Function Loss: 0.07708

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.75509
Value Function Update Magnitude: 0.68842

Collected Steps per Second: 22,754.48878
Overall Steps per Second: 10,713.68125

Timestep Collection Time: 2.19798
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66824

Cumulative Model Updates: 109,282
Cumulative Timesteps: 911,346,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,213.65179
Policy Entropy: 3.61861
Value Function Loss: 0.07956

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.67919
Value Function Update Magnitude: 0.69006

Collected Steps per Second: 21,912.57299
Overall Steps per Second: 10,683.89438

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.39959
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.68275

Cumulative Model Updates: 109,288
Cumulative Timesteps: 911,396,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 911396590...
Checkpoint 911396590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,206.35034
Policy Entropy: 3.63024
Value Function Loss: 0.07750

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.69342

Collected Steps per Second: 21,522.63983
Overall Steps per Second: 10,551.44242

Timestep Collection Time: 2.32351
Timestep Consumption Time: 2.41594
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73945

Cumulative Model Updates: 109,294
Cumulative Timesteps: 911,446,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,076.89862
Policy Entropy: 3.62918
Value Function Loss: 0.07896

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.72216

Collected Steps per Second: 22,092.19546
Overall Steps per Second: 10,771.52623

Timestep Collection Time: 2.26478
Timestep Consumption Time: 2.38024
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.64502

Cumulative Model Updates: 109,300
Cumulative Timesteps: 911,496,632

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 911496632...
Checkpoint 911496632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,085.55333
Policy Entropy: 3.62759
Value Function Loss: 0.07837

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.73157

Collected Steps per Second: 21,738.96788
Overall Steps per Second: 10,632.74350

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.40273
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.70302

Cumulative Model Updates: 109,306
Cumulative Timesteps: 911,546,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,521.06852
Policy Entropy: 3.62937
Value Function Loss: 0.08038

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.56515
Value Function Update Magnitude: 0.73271

Collected Steps per Second: 21,705.45932
Overall Steps per Second: 10,627.77784

Timestep Collection Time: 2.30458
Timestep Consumption Time: 2.40214
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.70672

Cumulative Model Updates: 109,312
Cumulative Timesteps: 911,596,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 911596660...
Checkpoint 911596660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,490.22475
Policy Entropy: 3.62151
Value Function Loss: 0.08254

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.59876
Value Function Update Magnitude: 0.74635

Collected Steps per Second: 22,288.87442
Overall Steps per Second: 10,652.53316

Timestep Collection Time: 2.24372
Timestep Consumption Time: 2.45094
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.69466

Cumulative Model Updates: 109,318
Cumulative Timesteps: 911,646,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,159.12945
Policy Entropy: 3.61632
Value Function Loss: 0.08568

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.72297

Collected Steps per Second: 22,120.78075
Overall Steps per Second: 10,662.13323

Timestep Collection Time: 2.26068
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.69024

Cumulative Model Updates: 109,324
Cumulative Timesteps: 911,696,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 911696678...
Checkpoint 911696678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,265.66418
Policy Entropy: 3.61867
Value Function Loss: 0.08568

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10580
Policy Update Magnitude: 0.51166
Value Function Update Magnitude: 0.74209

Collected Steps per Second: 22,710.76654
Overall Steps per Second: 10,664.99234

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.69011

Cumulative Model Updates: 109,330
Cumulative Timesteps: 911,746,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.88623
Policy Entropy: 3.61909
Value Function Loss: 0.08751

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.54088
Value Function Update Magnitude: 0.73430

Collected Steps per Second: 22,843.59141
Overall Steps per Second: 10,881.27753

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59652

Cumulative Model Updates: 109,336
Cumulative Timesteps: 911,796,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 911796714...
Checkpoint 911796714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.41052
Policy Entropy: 3.61267
Value Function Loss: 0.08965

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.60601
Value Function Update Magnitude: 0.70245

Collected Steps per Second: 22,810.00470
Overall Steps per Second: 10,717.74846

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.47413
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.66703

Cumulative Model Updates: 109,342
Cumulative Timesteps: 911,846,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,861.00972
Policy Entropy: 3.62994
Value Function Loss: 0.08891

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.65277

Collected Steps per Second: 22,788.03339
Overall Steps per Second: 10,838.73374

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.42021
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61548

Cumulative Model Updates: 109,348
Cumulative Timesteps: 911,896,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 911896760...
Checkpoint 911896760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,787.71277
Policy Entropy: 3.62753
Value Function Loss: 0.08828

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.68319

Collected Steps per Second: 22,488.50896
Overall Steps per Second: 10,696.63286

Timestep Collection Time: 2.22460
Timestep Consumption Time: 2.45238
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.67699

Cumulative Model Updates: 109,354
Cumulative Timesteps: 911,946,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,964.79117
Policy Entropy: 3.62710
Value Function Loss: 0.08800

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.71565

Collected Steps per Second: 22,526.17048
Overall Steps per Second: 10,596.07521

Timestep Collection Time: 2.22017
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.71986

Cumulative Model Updates: 109,360
Cumulative Timesteps: 911,996,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 911996800...
Checkpoint 911996800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,567.73877
Policy Entropy: 3.62467
Value Function Loss: 0.08836

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.62462
Value Function Update Magnitude: 0.76993

Collected Steps per Second: 22,587.76134
Overall Steps per Second: 10,637.96224

Timestep Collection Time: 2.21377
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.70052

Cumulative Model Updates: 109,366
Cumulative Timesteps: 912,046,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,795.31767
Policy Entropy: 3.61045
Value Function Loss: 0.09054

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.67560
Value Function Update Magnitude: 0.74487

Collected Steps per Second: 22,596.49413
Overall Steps per Second: 10,767.77249

Timestep Collection Time: 2.21335
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.64479

Cumulative Model Updates: 109,372
Cumulative Timesteps: 912,096,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 912096818...
Checkpoint 912096818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,826.05359
Policy Entropy: 3.61075
Value Function Loss: 0.09090

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.64963
Value Function Update Magnitude: 0.73412

Collected Steps per Second: 22,760.37463
Overall Steps per Second: 10,600.76206

Timestep Collection Time: 2.19742
Timestep Consumption Time: 2.52055
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.71796

Cumulative Model Updates: 109,378
Cumulative Timesteps: 912,146,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.86489
Policy Entropy: 3.60581
Value Function Loss: 0.09013

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.59902
Value Function Update Magnitude: 0.75547

Collected Steps per Second: 22,832.09400
Overall Steps per Second: 10,688.75143

Timestep Collection Time: 2.19174
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.68174

Cumulative Model Updates: 109,384
Cumulative Timesteps: 912,196,874

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 912196874...
Checkpoint 912196874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.60057
Policy Entropy: 3.61740
Value Function Loss: 0.08512

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.64389
Value Function Update Magnitude: 0.71001

Collected Steps per Second: 23,152.49645
Overall Steps per Second: 10,890.50398

Timestep Collection Time: 2.16080
Timestep Consumption Time: 2.43292
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59373

Cumulative Model Updates: 109,390
Cumulative Timesteps: 912,246,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,178.78790
Policy Entropy: 3.60440
Value Function Loss: 0.08339

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.59441
Value Function Update Magnitude: 0.74659

Collected Steps per Second: 22,758.08125
Overall Steps per Second: 10,855.36655

Timestep Collection Time: 2.19781
Timestep Consumption Time: 2.40986
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.60767

Cumulative Model Updates: 109,396
Cumulative Timesteps: 912,296,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 912296920...
Checkpoint 912296920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.66077
Policy Entropy: 3.59797
Value Function Loss: 0.08559

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.85165

Collected Steps per Second: 22,633.67010
Overall Steps per Second: 10,692.20782

Timestep Collection Time: 2.21034
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.67892

Cumulative Model Updates: 109,402
Cumulative Timesteps: 912,346,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.36269
Policy Entropy: 3.59730
Value Function Loss: 0.08662

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12250
Policy Update Magnitude: 0.61584
Value Function Update Magnitude: 0.88479

Collected Steps per Second: 22,845.77453
Overall Steps per Second: 10,898.05885

Timestep Collection Time: 2.18894
Timestep Consumption Time: 2.39977
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.58871

Cumulative Model Updates: 109,408
Cumulative Timesteps: 912,396,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 912396956...
Checkpoint 912396956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.16475
Policy Entropy: 3.60257
Value Function Loss: 0.08510

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.55493
Value Function Update Magnitude: 0.81329

Collected Steps per Second: 22,325.95891
Overall Steps per Second: 10,674.77498

Timestep Collection Time: 2.24035
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.68563

Cumulative Model Updates: 109,414
Cumulative Timesteps: 912,446,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,262.01137
Policy Entropy: 3.61217
Value Function Loss: 0.08596

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.72560

Collected Steps per Second: 22,362.74177
Overall Steps per Second: 10,563.39821

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.73389

Cumulative Model Updates: 109,420
Cumulative Timesteps: 912,496,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 912496980...
Checkpoint 912496980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,694.06304
Policy Entropy: 3.60247
Value Function Loss: 0.08688

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.62265
Value Function Update Magnitude: 0.74644

Collected Steps per Second: 22,498.86986
Overall Steps per Second: 10,582.99402

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72588

Cumulative Model Updates: 109,426
Cumulative Timesteps: 912,546,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,643.98049
Policy Entropy: 3.59833
Value Function Loss: 0.08948

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.70424
Value Function Update Magnitude: 0.75799

Collected Steps per Second: 22,665.70416
Overall Steps per Second: 10,753.13829

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.44451
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.65111

Cumulative Model Updates: 109,432
Cumulative Timesteps: 912,597,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 912597008...
Checkpoint 912597008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,795.52450
Policy Entropy: 3.57484
Value Function Loss: 0.09051

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.16651
Policy Update Magnitude: 0.63191
Value Function Update Magnitude: 0.71190

Collected Steps per Second: 22,504.17250
Overall Steps per Second: 10,690.55010

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.45522
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.67703

Cumulative Model Updates: 109,438
Cumulative Timesteps: 912,647,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.61883
Policy Entropy: 3.56793
Value Function Loss: 0.08860

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.66235
Value Function Update Magnitude: 0.68638

Collected Steps per Second: 22,834.60537
Overall Steps per Second: 10,803.52549

Timestep Collection Time: 2.19053
Timestep Consumption Time: 2.43944
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.62997

Cumulative Model Updates: 109,444
Cumulative Timesteps: 912,697,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 912697028...
Checkpoint 912697028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.87577
Policy Entropy: 3.56855
Value Function Loss: 0.08986

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.61382
Value Function Update Magnitude: 0.60026

Collected Steps per Second: 22,580.09614
Overall Steps per Second: 10,769.31188

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.42868
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.64319

Cumulative Model Updates: 109,450
Cumulative Timesteps: 912,747,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,823.05824
Policy Entropy: 3.57578
Value Function Loss: 0.09510

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.53055
Value Function Update Magnitude: 0.53141

Collected Steps per Second: 23,044.57921
Overall Steps per Second: 10,864.31196

Timestep Collection Time: 2.17014
Timestep Consumption Time: 2.43300
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60314

Cumulative Model Updates: 109,456
Cumulative Timesteps: 912,797,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 912797042...
Checkpoint 912797042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,245.18426
Policy Entropy: 3.57734
Value Function Loss: 0.09887

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.47757
Value Function Update Magnitude: 0.45790

Collected Steps per Second: 22,343.92838
Overall Steps per Second: 10,650.31923

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.69714

Cumulative Model Updates: 109,462
Cumulative Timesteps: 912,847,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,162.60573
Policy Entropy: 3.56181
Value Function Loss: 0.10126

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.48083
Value Function Update Magnitude: 0.46870

Collected Steps per Second: 22,728.73148
Overall Steps per Second: 10,658.90802

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.69429

Cumulative Model Updates: 109,468
Cumulative Timesteps: 912,897,104

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 912897104...
Checkpoint 912897104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,733.73559
Policy Entropy: 3.55252
Value Function Loss: 0.09654

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.43456
Value Function Update Magnitude: 0.46708

Collected Steps per Second: 22,771.04784
Overall Steps per Second: 10,801.11875

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.63026

Cumulative Model Updates: 109,474
Cumulative Timesteps: 912,947,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,802.18346
Policy Entropy: 3.56315
Value Function Loss: 0.09387

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.38322
Value Function Update Magnitude: 0.55266

Collected Steps per Second: 22,365.04468
Overall Steps per Second: 10,575.25224

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.72972

Cumulative Model Updates: 109,480
Cumulative Timesteps: 912,997,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 912997134...
Checkpoint 912997134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.08676
Policy Entropy: 3.56995
Value Function Loss: 0.08644

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.40094
Value Function Update Magnitude: 0.66550

Collected Steps per Second: 22,464.44481
Overall Steps per Second: 10,642.84666

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.47324
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.69987

Cumulative Model Updates: 109,486
Cumulative Timesteps: 913,047,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,891.21116
Policy Entropy: 3.56705
Value Function Loss: 0.08945

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.44060
Value Function Update Magnitude: 0.71941

Collected Steps per Second: 22,510.88316
Overall Steps per Second: 10,590.63268

Timestep Collection Time: 2.22141
Timestep Consumption Time: 2.50031
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.72172

Cumulative Model Updates: 109,492
Cumulative Timesteps: 913,097,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 913097160...
Checkpoint 913097160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,402.98703
Policy Entropy: 3.56204
Value Function Loss: 0.09026

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.52131
Value Function Update Magnitude: 0.58641

Collected Steps per Second: 22,195.57574
Overall Steps per Second: 10,471.76071

Timestep Collection Time: 2.25387
Timestep Consumption Time: 2.52336
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.77723

Cumulative Model Updates: 109,498
Cumulative Timesteps: 913,147,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,568.12167
Policy Entropy: 3.56273
Value Function Loss: 0.09567

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.50852
Value Function Update Magnitude: 0.55333

Collected Steps per Second: 22,646.31761
Overall Steps per Second: 10,605.52708

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71622

Cumulative Model Updates: 109,504
Cumulative Timesteps: 913,197,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 913197204...
Checkpoint 913197204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,436.52746
Policy Entropy: 3.55915
Value Function Loss: 0.09733

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.53485
Value Function Update Magnitude: 0.63160

Collected Steps per Second: 22,871.26072
Overall Steps per Second: 10,707.78456

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.48484
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.67230

Cumulative Model Updates: 109,510
Cumulative Timesteps: 913,247,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,735.28725
Policy Entropy: 3.56347
Value Function Loss: 0.09812

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.51557
Value Function Update Magnitude: 0.72858

Collected Steps per Second: 22,857.37471
Overall Steps per Second: 10,692.24884

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.49010
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.67872

Cumulative Model Updates: 109,516
Cumulative Timesteps: 913,297,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 913297260...
Checkpoint 913297260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,860.31594
Policy Entropy: 3.55672
Value Function Loss: 0.09496

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.48142
Value Function Update Magnitude: 0.82642

Collected Steps per Second: 22,909.92731
Overall Steps per Second: 10,646.83448

Timestep Collection Time: 2.18255
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.69642

Cumulative Model Updates: 109,522
Cumulative Timesteps: 913,347,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,583.98350
Policy Entropy: 3.56861
Value Function Loss: 0.09335

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.47344
Value Function Update Magnitude: 0.79221

Collected Steps per Second: 23,082.32150
Overall Steps per Second: 10,870.18472

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60397

Cumulative Model Updates: 109,528
Cumulative Timesteps: 913,397,308

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 913397308...
Checkpoint 913397308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,415.80555
Policy Entropy: 3.56708
Value Function Loss: 0.09494

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.48244
Value Function Update Magnitude: 0.68075

Collected Steps per Second: 22,813.18101
Overall Steps per Second: 10,665.27142

Timestep Collection Time: 2.19198
Timestep Consumption Time: 2.49670
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.68868

Cumulative Model Updates: 109,534
Cumulative Timesteps: 913,447,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,246.02213
Policy Entropy: 3.55434
Value Function Loss: 0.09705

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.52398
Value Function Update Magnitude: 0.68762

Collected Steps per Second: 22,774.62622
Overall Steps per Second: 10,810.75754

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.62706

Cumulative Model Updates: 109,540
Cumulative Timesteps: 913,497,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 913497336...
Checkpoint 913497336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,017.50620
Policy Entropy: 3.53969
Value Function Loss: 0.09811

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.48186
Value Function Update Magnitude: 0.60167

Collected Steps per Second: 21,746.74820
Overall Steps per Second: 10,718.05528

Timestep Collection Time: 2.30011
Timestep Consumption Time: 2.36678
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.66689

Cumulative Model Updates: 109,546
Cumulative Timesteps: 913,547,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,180.85485
Policy Entropy: 3.55060
Value Function Loss: 0.09996

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.48441
Value Function Update Magnitude: 0.59155

Collected Steps per Second: 21,039.99074
Overall Steps per Second: 10,486.01510

Timestep Collection Time: 2.37776
Timestep Consumption Time: 2.39317
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.77093

Cumulative Model Updates: 109,552
Cumulative Timesteps: 913,597,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 913597384...
Checkpoint 913597384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,131.73476
Policy Entropy: 3.56946
Value Function Loss: 0.10168

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.44264
Value Function Update Magnitude: 0.65655

Collected Steps per Second: 21,611.15774
Overall Steps per Second: 10,648.82140

Timestep Collection Time: 2.31427
Timestep Consumption Time: 2.38240
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.69667

Cumulative Model Updates: 109,558
Cumulative Timesteps: 913,647,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,619.82147
Policy Entropy: 3.58640
Value Function Loss: 0.09802

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.43245
Value Function Update Magnitude: 0.74137

Collected Steps per Second: 21,907.47512
Overall Steps per Second: 10,644.38509

Timestep Collection Time: 2.28360
Timestep Consumption Time: 2.41634
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69994

Cumulative Model Updates: 109,564
Cumulative Timesteps: 913,697,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 913697426...
Checkpoint 913697426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,991.32719
Policy Entropy: 3.57796
Value Function Loss: 0.09422

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.82336

Collected Steps per Second: 22,075.21501
Overall Steps per Second: 10,782.31465

Timestep Collection Time: 2.26526
Timestep Consumption Time: 2.37252
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.63778

Cumulative Model Updates: 109,570
Cumulative Timesteps: 913,747,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,364.80402
Policy Entropy: 3.55948
Value Function Loss: 0.09098

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.59384
Value Function Update Magnitude: 0.79936

Collected Steps per Second: 22,088.61717
Overall Steps per Second: 10,677.33441

Timestep Collection Time: 2.26497
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.68563

Cumulative Model Updates: 109,576
Cumulative Timesteps: 913,797,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 913797462...
Checkpoint 913797462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,560.86592
Policy Entropy: 3.54760
Value Function Loss: 0.09051

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.61314
Value Function Update Magnitude: 0.78357

Collected Steps per Second: 22,315.39466
Overall Steps per Second: 10,603.92457

Timestep Collection Time: 2.24105
Timestep Consumption Time: 2.47512
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.71618

Cumulative Model Updates: 109,582
Cumulative Timesteps: 913,847,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,218.68716
Policy Entropy: 3.54561
Value Function Loss: 0.09056

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.51824
Value Function Update Magnitude: 0.70527

Collected Steps per Second: 22,656.21341
Overall Steps per Second: 10,784.37773

Timestep Collection Time: 2.20769
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.63801

Cumulative Model Updates: 109,588
Cumulative Timesteps: 913,897,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 913897490...
Checkpoint 913897490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,102.44972
Policy Entropy: 3.55991
Value Function Loss: 0.09037

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.48397
Value Function Update Magnitude: 0.72232

Collected Steps per Second: 22,850.29126
Overall Steps per Second: 10,684.12174

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.68115

Cumulative Model Updates: 109,594
Cumulative Timesteps: 913,947,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,988.57043
Policy Entropy: 3.57388
Value Function Loss: 0.09328

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.50815
Value Function Update Magnitude: 0.71851

Collected Steps per Second: 22,974.55987
Overall Steps per Second: 10,903.69042

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.58854

Cumulative Model Updates: 109,600
Cumulative Timesteps: 913,997,536

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 913997536...
Checkpoint 913997536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,353.79402
Policy Entropy: 3.56519
Value Function Loss: 0.09506

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.51520
Value Function Update Magnitude: 0.74028

Collected Steps per Second: 22,609.45464
Overall Steps per Second: 10,701.18584

Timestep Collection Time: 2.21279
Timestep Consumption Time: 2.46239
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.67518

Cumulative Model Updates: 109,606
Cumulative Timesteps: 914,047,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,917.57375
Policy Entropy: 3.56970
Value Function Loss: 0.09750

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.71551

Collected Steps per Second: 22,563.65575
Overall Steps per Second: 10,638.38319

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.70109

Cumulative Model Updates: 109,612
Cumulative Timesteps: 914,097,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 914097578...
Checkpoint 914097578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,838.62126
Policy Entropy: 3.54280
Value Function Loss: 0.10039

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.50190
Value Function Update Magnitude: 0.78053

Collected Steps per Second: 22,250.58695
Overall Steps per Second: 10,521.38957

Timestep Collection Time: 2.24794
Timestep Consumption Time: 2.50599
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.75393

Cumulative Model Updates: 109,618
Cumulative Timesteps: 914,147,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,482.86535
Policy Entropy: 3.54740
Value Function Loss: 0.09890

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.46890
Value Function Update Magnitude: 0.75406

Collected Steps per Second: 22,755.23497
Overall Steps per Second: 10,780.59760

Timestep Collection Time: 2.19818
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63982

Cumulative Model Updates: 109,624
Cumulative Timesteps: 914,197,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 914197616...
Checkpoint 914197616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,126.13353
Policy Entropy: 3.54540
Value Function Loss: 0.10203

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.51338
Value Function Update Magnitude: 0.67674

Collected Steps per Second: 22,435.97117
Overall Steps per Second: 10,753.35936

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.65231

Cumulative Model Updates: 109,630
Cumulative Timesteps: 914,247,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,667.22065
Policy Entropy: 3.55349
Value Function Loss: 0.10198

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.46649
Value Function Update Magnitude: 0.50367

Collected Steps per Second: 23,338.24132
Overall Steps per Second: 10,829.55256

Timestep Collection Time: 2.14249
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61718

Cumulative Model Updates: 109,636
Cumulative Timesteps: 914,297,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 914297646...
Checkpoint 914297646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,906.49388
Policy Entropy: 3.55248
Value Function Loss: 0.10130

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.42977
Value Function Update Magnitude: 0.46669

Collected Steps per Second: 22,770.08095
Overall Steps per Second: 10,606.99088

Timestep Collection Time: 2.19674
Timestep Consumption Time: 2.51902
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.71576

Cumulative Model Updates: 109,642
Cumulative Timesteps: 914,347,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,834.46191
Policy Entropy: 3.55806
Value Function Loss: 0.10090

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.43981
Value Function Update Magnitude: 0.57401

Collected Steps per Second: 23,051.68865
Overall Steps per Second: 10,851.74526

Timestep Collection Time: 2.16947
Timestep Consumption Time: 2.43900
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60848

Cumulative Model Updates: 109,648
Cumulative Timesteps: 914,397,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 914397676...
Checkpoint 914397676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,987.27839
Policy Entropy: 3.56165
Value Function Loss: 0.09924

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.50264
Value Function Update Magnitude: 0.64757

Collected Steps per Second: 22,511.20304
Overall Steps per Second: 10,758.72833

Timestep Collection Time: 2.22112
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.64739

Cumulative Model Updates: 109,654
Cumulative Timesteps: 914,447,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,403.78909
Policy Entropy: 3.56211
Value Function Loss: 0.09424

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.56709
Value Function Update Magnitude: 0.70059

Collected Steps per Second: 22,824.26240
Overall Steps per Second: 10,800.09323

Timestep Collection Time: 2.19100
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.63033

Cumulative Model Updates: 109,660
Cumulative Timesteps: 914,497,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 914497684...
Checkpoint 914497684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,344.60318
Policy Entropy: 3.57225
Value Function Loss: 0.09254

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.16233
Policy Update Magnitude: 0.54608
Value Function Update Magnitude: 0.66133

Collected Steps per Second: 22,603.16472
Overall Steps per Second: 10,697.04737

Timestep Collection Time: 2.21323
Timestep Consumption Time: 2.46339
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67662

Cumulative Model Updates: 109,666
Cumulative Timesteps: 914,547,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.65165
Policy Entropy: 3.58171
Value Function Loss: 0.09265

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.46788
Value Function Update Magnitude: 0.65770

Collected Steps per Second: 22,215.29493
Overall Steps per Second: 10,476.03955

Timestep Collection Time: 2.25196
Timestep Consumption Time: 2.52351
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.77547

Cumulative Model Updates: 109,672
Cumulative Timesteps: 914,597,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 914597738...
Checkpoint 914597738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,249.92139
Policy Entropy: 3.59444
Value Function Loss: 0.09314

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.42663
Value Function Update Magnitude: 0.68067

Collected Steps per Second: 22,257.65400
Overall Steps per Second: 10,640.56467

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.45268
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.69919

Cumulative Model Updates: 109,678
Cumulative Timesteps: 914,647,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,625.75529
Policy Entropy: 3.58832
Value Function Loss: 0.09321

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.48230
Value Function Update Magnitude: 0.68697

Collected Steps per Second: 22,597.33967
Overall Steps per Second: 10,637.25154

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.48881
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.70234

Cumulative Model Updates: 109,684
Cumulative Timesteps: 914,697,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 914697760...
Checkpoint 914697760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019.59972
Policy Entropy: 3.57408
Value Function Loss: 0.09056

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.47101
Value Function Update Magnitude: 0.65339

Collected Steps per Second: 22,495.04034
Overall Steps per Second: 10,537.71009

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.52367
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.74771

Cumulative Model Updates: 109,690
Cumulative Timesteps: 914,747,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,337.42179
Policy Entropy: 3.57450
Value Function Loss: 0.09006

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.50180
Value Function Update Magnitude: 0.72212

Collected Steps per Second: 22,819.31959
Overall Steps per Second: 10,763.97103

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.45508
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.64717

Cumulative Model Updates: 109,696
Cumulative Timesteps: 914,797,812

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 914797812...
Checkpoint 914797812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,644.05441
Policy Entropy: 3.56593
Value Function Loss: 0.09148

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.45787
Value Function Update Magnitude: 0.70927

Collected Steps per Second: 22,780.46172
Overall Steps per Second: 10,769.74520

Timestep Collection Time: 2.19530
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.64356

Cumulative Model Updates: 109,702
Cumulative Timesteps: 914,847,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,965.63632
Policy Entropy: 3.57549
Value Function Loss: 0.09106

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.43295
Value Function Update Magnitude: 0.74840

Collected Steps per Second: 22,826.52181
Overall Steps per Second: 10,774.04662

Timestep Collection Time: 2.19114
Timestep Consumption Time: 2.45113
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.64227

Cumulative Model Updates: 109,708
Cumulative Timesteps: 914,897,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 914897838...
Checkpoint 914897838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,383.44066
Policy Entropy: 3.57750
Value Function Loss: 0.08727

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.44297
Value Function Update Magnitude: 0.76831

Collected Steps per Second: 22,746.97904
Overall Steps per Second: 10,714.17599

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.46911
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.66765

Cumulative Model Updates: 109,714
Cumulative Timesteps: 914,947,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.67145
Policy Entropy: 3.58934
Value Function Loss: 0.08195

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.46029
Value Function Update Magnitude: 0.70948

Collected Steps per Second: 22,997.33602
Overall Steps per Second: 10,839.10647

Timestep Collection Time: 2.17434
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61330

Cumulative Model Updates: 109,720
Cumulative Timesteps: 914,997,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 914997852...
Checkpoint 914997852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,338.53144
Policy Entropy: 3.59143
Value Function Loss: 0.07915

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.45911
Value Function Update Magnitude: 0.77416

Collected Steps per Second: 22,654.38344
Overall Steps per Second: 10,707.92120

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.67037

Cumulative Model Updates: 109,726
Cumulative Timesteps: 915,047,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,117.93910
Policy Entropy: 3.58570
Value Function Loss: 0.07688

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.44649
Value Function Update Magnitude: 0.77914

Collected Steps per Second: 22,715.83358
Overall Steps per Second: 10,838.29507

Timestep Collection Time: 2.20137
Timestep Consumption Time: 2.41245
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61383

Cumulative Model Updates: 109,732
Cumulative Timesteps: 915,097,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 915097868...
Checkpoint 915097868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,087.53769
Policy Entropy: 3.58992
Value Function Loss: 0.07896

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.45555
Value Function Update Magnitude: 0.74919

Collected Steps per Second: 22,341.92736
Overall Steps per Second: 10,671.69021

Timestep Collection Time: 2.23848
Timestep Consumption Time: 2.44794
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.68642

Cumulative Model Updates: 109,738
Cumulative Timesteps: 915,147,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,303.70925
Policy Entropy: 3.58518
Value Function Loss: 0.07781

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.47387
Value Function Update Magnitude: 0.70320

Collected Steps per Second: 22,169.59925
Overall Steps per Second: 10,483.62571

Timestep Collection Time: 2.25651
Timestep Consumption Time: 2.51531
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.77182

Cumulative Model Updates: 109,744
Cumulative Timesteps: 915,197,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 915197906...
Checkpoint 915197906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,256.88898
Policy Entropy: 3.59085
Value Function Loss: 0.07671

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.66515
Value Function Update Magnitude: 0.67835

Collected Steps per Second: 22,346.87408
Overall Steps per Second: 10,676.83147

Timestep Collection Time: 2.23745
Timestep Consumption Time: 2.44559
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.68304

Cumulative Model Updates: 109,750
Cumulative Timesteps: 915,247,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,378.03829
Policy Entropy: 3.59307
Value Function Loss: 0.07455

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.68906
Value Function Update Magnitude: 0.64858

Collected Steps per Second: 22,250.94754
Overall Steps per Second: 10,508.61888

Timestep Collection Time: 2.24719
Timestep Consumption Time: 2.51100
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.75819

Cumulative Model Updates: 109,756
Cumulative Timesteps: 915,297,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 915297908...
Checkpoint 915297908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,681.42047
Policy Entropy: 3.59835
Value Function Loss: 0.07481

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.70584
Value Function Update Magnitude: 0.56739

Collected Steps per Second: 22,353.86702
Overall Steps per Second: 10,523.91771

Timestep Collection Time: 2.23782
Timestep Consumption Time: 2.51554
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.75336

Cumulative Model Updates: 109,762
Cumulative Timesteps: 915,347,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,054.16145
Policy Entropy: 3.60037
Value Function Loss: 0.07775

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.59655
Value Function Update Magnitude: 0.52552

Collected Steps per Second: 22,675.30197
Overall Steps per Second: 10,633.48294

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70213

Cumulative Model Updates: 109,768
Cumulative Timesteps: 915,397,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 915397932...
Checkpoint 915397932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,231.31688
Policy Entropy: 3.59820
Value Function Loss: 0.07930

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.64596
Value Function Update Magnitude: 0.50339

Collected Steps per Second: 22,882.04072
Overall Steps per Second: 10,845.49833

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.42732
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61445

Cumulative Model Updates: 109,774
Cumulative Timesteps: 915,447,978

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,041.75847
Policy Entropy: 3.60474
Value Function Loss: 0.08232

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.65955
Value Function Update Magnitude: 0.47970

Collected Steps per Second: 21,270.96708
Overall Steps per Second: 10,420.11567

Timestep Collection Time: 2.35081
Timestep Consumption Time: 2.44799
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.79880

Cumulative Model Updates: 109,780
Cumulative Timesteps: 915,497,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 915497982...
Checkpoint 915497982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,331.26654
Policy Entropy: 3.59305
Value Function Loss: 0.08284

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.63210
Value Function Update Magnitude: 0.51214

Collected Steps per Second: 22,770.34183
Overall Steps per Second: 10,787.32626

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.63785

Cumulative Model Updates: 109,786
Cumulative Timesteps: 915,548,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,847.07251
Policy Entropy: 3.60796
Value Function Loss: 0.08467

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.49643
Value Function Update Magnitude: 0.44792

Collected Steps per Second: 23,039.55369
Overall Steps per Second: 10,838.94026

Timestep Collection Time: 2.17105
Timestep Consumption Time: 2.44379
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61484

Cumulative Model Updates: 109,792
Cumulative Timesteps: 915,598,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 915598032...
Checkpoint 915598032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.53511
Policy Entropy: 3.60430
Value Function Loss: 0.08457

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.44373
Value Function Update Magnitude: 0.44358

Collected Steps per Second: 22,377.64939
Overall Steps per Second: 10,713.03571

Timestep Collection Time: 2.23652
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.67169

Cumulative Model Updates: 109,798
Cumulative Timesteps: 915,648,080

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,357.88878
Policy Entropy: 3.59749
Value Function Loss: 0.08520

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.44661
Value Function Update Magnitude: 0.45318

Collected Steps per Second: 22,208.94514
Overall Steps per Second: 10,465.90277

Timestep Collection Time: 2.25234
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.77952

Cumulative Model Updates: 109,804
Cumulative Timesteps: 915,698,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 915698102...
Checkpoint 915698102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,775.74083
Policy Entropy: 3.60533
Value Function Loss: 0.08216

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.46316
Value Function Update Magnitude: 0.48140

Collected Steps per Second: 22,262.32012
Overall Steps per Second: 10,617.82828

Timestep Collection Time: 2.24595
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.70906

Cumulative Model Updates: 109,810
Cumulative Timesteps: 915,748,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,205.19342
Policy Entropy: 3.59912
Value Function Loss: 0.08713

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.45856
Value Function Update Magnitude: 0.47832

Collected Steps per Second: 22,434.83389
Overall Steps per Second: 10,577.98993

Timestep Collection Time: 2.22948
Timestep Consumption Time: 2.49902
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.72850

Cumulative Model Updates: 109,816
Cumulative Timesteps: 915,798,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 915798120...
Checkpoint 915798120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,057.91832
Policy Entropy: 3.60147
Value Function Loss: 0.08931

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.45888
Value Function Update Magnitude: 0.49906

Collected Steps per Second: 22,691.07845
Overall Steps per Second: 10,605.70556

Timestep Collection Time: 2.20483
Timestep Consumption Time: 2.51244
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.71727

Cumulative Model Updates: 109,822
Cumulative Timesteps: 915,848,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.49672
Policy Entropy: 3.60328
Value Function Loss: 0.08995

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.47589
Value Function Update Magnitude: 0.50733

Collected Steps per Second: 23,177.35290
Overall Steps per Second: 10,777.49553

Timestep Collection Time: 2.15805
Timestep Consumption Time: 2.48291
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.64097

Cumulative Model Updates: 109,828
Cumulative Timesteps: 915,898,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 915898168...
Checkpoint 915898168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,039.77049
Policy Entropy: 3.60612
Value Function Loss: 0.08844

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.46365
Value Function Update Magnitude: 0.49764

Collected Steps per Second: 22,764.30878
Overall Steps per Second: 10,633.88182

Timestep Collection Time: 2.19651
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.70214

Cumulative Model Updates: 109,834
Cumulative Timesteps: 915,948,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,375.04090
Policy Entropy: 3.59103
Value Function Loss: 0.09042

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.45508
Value Function Update Magnitude: 0.53589

Collected Steps per Second: 22,517.34924
Overall Steps per Second: 10,625.41472

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.70720

Cumulative Model Updates: 109,840
Cumulative Timesteps: 915,998,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 915998186...
Checkpoint 915998186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,093.01548
Policy Entropy: 3.59542
Value Function Loss: 0.08964

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.46284
Value Function Update Magnitude: 0.53188

Collected Steps per Second: 22,787.32632
Overall Steps per Second: 10,851.89126

Timestep Collection Time: 2.19429
Timestep Consumption Time: 2.41339
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.60768

Cumulative Model Updates: 109,846
Cumulative Timesteps: 916,048,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,429.56194
Policy Entropy: 3.59329
Value Function Loss: 0.09257

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.52630
Value Function Update Magnitude: 0.52020

Collected Steps per Second: 22,610.37186
Overall Steps per Second: 10,581.53056

Timestep Collection Time: 2.21297
Timestep Consumption Time: 2.51565
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.72862

Cumulative Model Updates: 109,852
Cumulative Timesteps: 916,098,224

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 916098224...
Checkpoint 916098224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,602.53424
Policy Entropy: 3.59669
Value Function Loss: 0.09403

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.45522
Value Function Update Magnitude: 0.54376

Collected Steps per Second: 22,783.63664
Overall Steps per Second: 10,659.89408

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.49632
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.69123

Cumulative Model Updates: 109,858
Cumulative Timesteps: 916,148,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,121.71777
Policy Entropy: 3.58410
Value Function Loss: 0.10100

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.41582
Value Function Update Magnitude: 0.54466

Collected Steps per Second: 21,919.06545
Overall Steps per Second: 10,781.60655

Timestep Collection Time: 2.28203
Timestep Consumption Time: 2.35735
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.63938

Cumulative Model Updates: 109,864
Cumulative Timesteps: 916,198,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 916198252...
Checkpoint 916198252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,325.00486
Policy Entropy: 3.58388
Value Function Loss: 0.10227

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.43042
Value Function Update Magnitude: 0.49825

Collected Steps per Second: 21,600.46082
Overall Steps per Second: 10,724.10541

Timestep Collection Time: 2.31606
Timestep Consumption Time: 2.34894
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.66500

Cumulative Model Updates: 109,870
Cumulative Timesteps: 916,248,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,494.91820
Policy Entropy: 3.59828
Value Function Loss: 0.10007

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.49035
Value Function Update Magnitude: 0.49643

Collected Steps per Second: 22,007.13309
Overall Steps per Second: 10,781.53984

Timestep Collection Time: 2.27254
Timestep Consumption Time: 2.36613
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.63867

Cumulative Model Updates: 109,876
Cumulative Timesteps: 916,298,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 916298292...
Checkpoint 916298292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,666.25986
Policy Entropy: 3.61633
Value Function Loss: 0.08796

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.52170
Value Function Update Magnitude: 0.60192

Collected Steps per Second: 21,676.84955
Overall Steps per Second: 10,629.38164

Timestep Collection Time: 2.30725
Timestep Consumption Time: 2.39801
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.70526

Cumulative Model Updates: 109,882
Cumulative Timesteps: 916,348,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,756.45388
Policy Entropy: 3.61451
Value Function Loss: 0.08269

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.59089
Value Function Update Magnitude: 0.65996

Collected Steps per Second: 22,259.55287
Overall Steps per Second: 10,727.80055

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.41572
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.66302

Cumulative Model Updates: 109,888
Cumulative Timesteps: 916,398,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 916398330...
Checkpoint 916398330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,301.79047
Policy Entropy: 3.62626
Value Function Loss: 0.08303

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.65192

Collected Steps per Second: 22,310.17983
Overall Steps per Second: 10,648.56356

Timestep Collection Time: 2.24212
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.69753

Cumulative Model Updates: 109,894
Cumulative Timesteps: 916,448,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.01189
Policy Entropy: 3.60201
Value Function Loss: 0.08955

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.59883

Collected Steps per Second: 23,022.28435
Overall Steps per Second: 10,717.94133

Timestep Collection Time: 2.17216
Timestep Consumption Time: 2.49367
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.66582

Cumulative Model Updates: 109,900
Cumulative Timesteps: 916,498,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 916498360...
Checkpoint 916498360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.82730
Policy Entropy: 3.59770
Value Function Loss: 0.09526

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.61718
Value Function Update Magnitude: 0.59975

Collected Steps per Second: 22,679.07218
Overall Steps per Second: 10,659.12496

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.69269

Cumulative Model Updates: 109,906
Cumulative Timesteps: 916,548,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,906.15163
Policy Entropy: 3.58775
Value Function Loss: 0.09548

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.79263
Value Function Update Magnitude: 0.58352

Collected Steps per Second: 22,781.90039
Overall Steps per Second: 10,846.43398

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.41528
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.61018

Cumulative Model Updates: 109,912
Cumulative Timesteps: 916,598,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 916598384...
Checkpoint 916598384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,870.79118
Policy Entropy: 3.57038
Value Function Loss: 0.09557

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.71132
Value Function Update Magnitude: 0.57525

Collected Steps per Second: 22,516.97290
Overall Steps per Second: 10,705.49540

Timestep Collection Time: 2.22197
Timestep Consumption Time: 2.45152
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.67349

Cumulative Model Updates: 109,918
Cumulative Timesteps: 916,648,416

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,771.45800
Policy Entropy: 3.57297
Value Function Loss: 0.09698

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.70637
Value Function Update Magnitude: 0.55127

Collected Steps per Second: 22,422.77994
Overall Steps per Second: 10,544.07125

Timestep Collection Time: 2.23095
Timestep Consumption Time: 2.51333
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.74428

Cumulative Model Updates: 109,924
Cumulative Timesteps: 916,698,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 916698440...
Checkpoint 916698440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,422.33844
Policy Entropy: 3.56874
Value Function Loss: 0.09711

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.67109
Value Function Update Magnitude: 0.51548

Collected Steps per Second: 22,466.99262
Overall Steps per Second: 10,552.54386

Timestep Collection Time: 2.22549
Timestep Consumption Time: 2.51271
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.73819

Cumulative Model Updates: 109,930
Cumulative Timesteps: 916,748,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,393.25348
Policy Entropy: 3.56833
Value Function Loss: 0.09988

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11383
Policy Update Magnitude: 0.53810
Value Function Update Magnitude: 0.47745

Collected Steps per Second: 22,201.26472
Overall Steps per Second: 10,507.06437

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.76061

Cumulative Model Updates: 109,936
Cumulative Timesteps: 916,798,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 916798460...
Checkpoint 916798460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,144.92225
Policy Entropy: 3.57477
Value Function Loss: 0.09741

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.54548
Value Function Update Magnitude: 0.48064

Collected Steps per Second: 22,041.90192
Overall Steps per Second: 10,574.79306

Timestep Collection Time: 2.26868
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.72879

Cumulative Model Updates: 109,942
Cumulative Timesteps: 916,848,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,762.27648
Policy Entropy: 3.57459
Value Function Loss: 0.09866

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.66283
Value Function Update Magnitude: 0.51867

Collected Steps per Second: 22,999.95042
Overall Steps per Second: 10,861.33473

Timestep Collection Time: 2.17418
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.60404

Cumulative Model Updates: 109,948
Cumulative Timesteps: 916,898,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 916898472...
Checkpoint 916898472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,840.77769
Policy Entropy: 3.57392
Value Function Loss: 0.10126

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.67756
Value Function Update Magnitude: 0.52242

Collected Steps per Second: 22,707.40217
Overall Steps per Second: 10,652.34508

Timestep Collection Time: 2.20289
Timestep Consumption Time: 2.49297
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69587

Cumulative Model Updates: 109,954
Cumulative Timesteps: 916,948,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,256.20510
Policy Entropy: 3.58160
Value Function Loss: 0.10457

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.60404

Collected Steps per Second: 22,820.23196
Overall Steps per Second: 10,681.18543

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.49129
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.68338

Cumulative Model Updates: 109,960
Cumulative Timesteps: 916,998,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 916998518...
Checkpoint 916998518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,585.41030
Policy Entropy: 3.57889
Value Function Loss: 0.10512

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.44092
Value Function Update Magnitude: 0.56228

Collected Steps per Second: 22,877.32082
Overall Steps per Second: 10,838.64703

Timestep Collection Time: 2.18592
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61386

Cumulative Model Updates: 109,966
Cumulative Timesteps: 917,048,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,770.96922
Policy Entropy: 3.58438
Value Function Loss: 0.10064

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.42618
Value Function Update Magnitude: 0.53175

Collected Steps per Second: 22,977.66425
Overall Steps per Second: 10,843.55995

Timestep Collection Time: 2.17724
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.61361

Cumulative Model Updates: 109,972
Cumulative Timesteps: 917,098,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 917098554...
Checkpoint 917098554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,228.93577
Policy Entropy: 3.56844
Value Function Loss: 0.09616

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.45167
Value Function Update Magnitude: 0.51626

Collected Steps per Second: 22,456.52344
Overall Steps per Second: 10,721.56432

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.66406

Cumulative Model Updates: 109,978
Cumulative Timesteps: 917,148,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,043.04959
Policy Entropy: 3.57323
Value Function Loss: 0.09139

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.45490
Value Function Update Magnitude: 0.51116

Collected Steps per Second: 22,658.31974
Overall Steps per Second: 10,630.47518

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.49726
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70440

Cumulative Model Updates: 109,984
Cumulative Timesteps: 917,198,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 917198570...
Checkpoint 917198570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,567.44523
Policy Entropy: 3.57785
Value Function Loss: 0.09540

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.48904
Value Function Update Magnitude: 0.51984

Collected Steps per Second: 22,644.68791
Overall Steps per Second: 10,705.28626

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.46414
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.67358

Cumulative Model Updates: 109,990
Cumulative Timesteps: 917,248,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,159.47772
Policy Entropy: 3.60539
Value Function Loss: 0.09620

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.56093

Collected Steps per Second: 22,345.57315
Overall Steps per Second: 10,675.77252

Timestep Collection Time: 2.23865
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.68575

Cumulative Model Updates: 109,996
Cumulative Timesteps: 917,298,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 917298626...
Checkpoint 917298626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.27064
Policy Entropy: 3.59536
Value Function Loss: 0.09601

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.61343
Value Function Update Magnitude: 0.76653

Collected Steps per Second: 22,753.38416
Overall Steps per Second: 10,670.16179

Timestep Collection Time: 2.19871
Timestep Consumption Time: 2.48988
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.68859

Cumulative Model Updates: 110,002
Cumulative Timesteps: 917,348,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,184.14098
Policy Entropy: 3.59080
Value Function Loss: 0.09514

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.70515
Value Function Update Magnitude: 0.82723

Collected Steps per Second: 22,957.38549
Overall Steps per Second: 10,819.08166

Timestep Collection Time: 2.17865
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.62294

Cumulative Model Updates: 110,008
Cumulative Timesteps: 917,398,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 917398670...
Checkpoint 917398670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,910.89677
Policy Entropy: 3.59568
Value Function Loss: 0.08888

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.62027
Value Function Update Magnitude: 0.87414

Collected Steps per Second: 22,728.96576
Overall Steps per Second: 10,721.80210

Timestep Collection Time: 2.20019
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.66414

Cumulative Model Updates: 110,014
Cumulative Timesteps: 917,448,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,086.77569
Policy Entropy: 3.60626
Value Function Loss: 0.08743

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.62109
Value Function Update Magnitude: 0.87284

Collected Steps per Second: 22,894.54937
Overall Steps per Second: 10,869.74029

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.41629
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.60048

Cumulative Model Updates: 110,020
Cumulative Timesteps: 917,498,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 917498684...
Checkpoint 917498684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,954.57144
Policy Entropy: 3.61428
Value Function Loss: 0.08637

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.67560
Value Function Update Magnitude: 0.81883

Collected Steps per Second: 22,658.98901
Overall Steps per Second: 10,673.21458

Timestep Collection Time: 2.20760
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.68669

Cumulative Model Updates: 110,026
Cumulative Timesteps: 917,548,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,741.49131
Policy Entropy: 3.60901
Value Function Loss: 0.09229

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.63290
Value Function Update Magnitude: 0.71680

Collected Steps per Second: 22,303.92110
Overall Steps per Second: 10,540.07326

Timestep Collection Time: 2.24203
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.74437

Cumulative Model Updates: 110,032
Cumulative Timesteps: 917,598,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 917598712...
Checkpoint 917598712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,298.87634
Policy Entropy: 3.59382
Value Function Loss: 0.09534

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.65927

Collected Steps per Second: 22,267.22693
Overall Steps per Second: 10,555.22233

Timestep Collection Time: 2.24653
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.73927

Cumulative Model Updates: 110,038
Cumulative Timesteps: 917,648,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,124.10332
Policy Entropy: 3.58600
Value Function Loss: 0.09436

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.66362

Collected Steps per Second: 22,200.96757
Overall Steps per Second: 10,505.52053

Timestep Collection Time: 2.25342
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.76207

Cumulative Model Updates: 110,044
Cumulative Timesteps: 917,698,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 917698764...
Checkpoint 917698764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.23243
Policy Entropy: 3.59060
Value Function Loss: 0.09256

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.59315
Value Function Update Magnitude: 0.64681

Collected Steps per Second: 22,557.83513
Overall Steps per Second: 10,566.58784

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.51577
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.73265

Cumulative Model Updates: 110,050
Cumulative Timesteps: 917,748,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,586.47588
Policy Entropy: 3.59938
Value Function Loss: 0.09109

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.80830

Collected Steps per Second: 22,908.06286
Overall Steps per Second: 10,648.35624

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.51423
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.69800

Cumulative Model Updates: 110,056
Cumulative Timesteps: 917,798,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 917798798...
Checkpoint 917798798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.69552
Policy Entropy: 3.60568
Value Function Loss: 0.09029

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.88793

Collected Steps per Second: 22,892.59577
Overall Steps per Second: 10,830.54981

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.61657

Cumulative Model Updates: 110,062
Cumulative Timesteps: 917,848,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,099.57567
Policy Entropy: 3.59260
Value Function Loss: 0.09208

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.93093

Collected Steps per Second: 22,349.16448
Overall Steps per Second: 10,525.94195

Timestep Collection Time: 2.23722
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.75017

Cumulative Model Updates: 110,068
Cumulative Timesteps: 917,898,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 917898798...
Checkpoint 917898798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,762.09422
Policy Entropy: 3.59906
Value Function Loss: 0.09101

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.51609
Value Function Update Magnitude: 0.96971

Collected Steps per Second: 22,669.04862
Overall Steps per Second: 10,612.18200

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.71251

Cumulative Model Updates: 110,074
Cumulative Timesteps: 917,948,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,940.45593
Policy Entropy: 3.60492
Value Function Loss: 0.09120

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.47807
Value Function Update Magnitude: 0.94911

Collected Steps per Second: 22,882.93921
Overall Steps per Second: 10,841.17052

Timestep Collection Time: 2.18556
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61315

Cumulative Model Updates: 110,080
Cumulative Timesteps: 917,998,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 917998820...
Checkpoint 917998820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,689.85536
Policy Entropy: 3.61093
Value Function Loss: 0.08973

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.46490
Value Function Update Magnitude: 0.81966

Collected Steps per Second: 22,738.08563
Overall Steps per Second: 10,718.51057

Timestep Collection Time: 2.19939
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66576

Cumulative Model Updates: 110,086
Cumulative Timesteps: 918,048,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,508.13162
Policy Entropy: 3.60459
Value Function Loss: 0.09173

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.45720
Value Function Update Magnitude: 0.80312

Collected Steps per Second: 21,727.43018
Overall Steps per Second: 10,610.11019

Timestep Collection Time: 2.30188
Timestep Consumption Time: 2.41192
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.71381

Cumulative Model Updates: 110,092
Cumulative Timesteps: 918,098,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 918098844...
Checkpoint 918098844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,991.54050
Policy Entropy: 3.60380
Value Function Loss: 0.09190

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.48534
Value Function Update Magnitude: 0.82844

Collected Steps per Second: 21,596.44404
Overall Steps per Second: 10,538.39237

Timestep Collection Time: 2.31566
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.74551

Cumulative Model Updates: 110,098
Cumulative Timesteps: 918,148,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,334.63029
Policy Entropy: 3.60775
Value Function Loss: 0.09591

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.50259
Value Function Update Magnitude: 0.82398

Collected Steps per Second: 21,868.36439
Overall Steps per Second: 10,760.60313

Timestep Collection Time: 2.28714
Timestep Consumption Time: 2.36093
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.64807

Cumulative Model Updates: 110,104
Cumulative Timesteps: 918,198,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 918198870...
Checkpoint 918198870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,266.55509
Policy Entropy: 3.61134
Value Function Loss: 0.09949

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.49562
Value Function Update Magnitude: 0.81246

Collected Steps per Second: 21,517.29874
Overall Steps per Second: 10,657.63122

Timestep Collection Time: 2.32399
Timestep Consumption Time: 2.36805
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.69204

Cumulative Model Updates: 110,110
Cumulative Timesteps: 918,248,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,355.98838
Policy Entropy: 3.60931
Value Function Loss: 0.10289

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14930
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.74841

Collected Steps per Second: 22,270.13544
Overall Steps per Second: 10,862.22375

Timestep Collection Time: 2.24624
Timestep Consumption Time: 2.35908
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60532

Cumulative Model Updates: 110,116
Cumulative Timesteps: 918,298,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918298900...
Checkpoint 918298900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,319.45879
Policy Entropy: 3.62863
Value Function Loss: 0.09711

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.57282
Value Function Update Magnitude: 0.75118

Collected Steps per Second: 22,126.54597
Overall Steps per Second: 10,685.84108

Timestep Collection Time: 2.26063
Timestep Consumption Time: 2.42033
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.68096

Cumulative Model Updates: 110,122
Cumulative Timesteps: 918,348,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.48182
Policy Entropy: 3.61376
Value Function Loss: 0.09306

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.64783
Value Function Update Magnitude: 0.90508

Collected Steps per Second: 22,741.77605
Overall Steps per Second: 10,736.65415

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.45953
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.65918

Cumulative Model Updates: 110,128
Cumulative Timesteps: 918,398,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918398944...
Checkpoint 918398944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,676.48000
Policy Entropy: 3.61725
Value Function Loss: 0.09190

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.61542
Value Function Update Magnitude: 0.81353

Collected Steps per Second: 23,029.18266
Overall Steps per Second: 10,854.91733

Timestep Collection Time: 2.17125
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.60639

Cumulative Model Updates: 110,134
Cumulative Timesteps: 918,448,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,572.63971
Policy Entropy: 3.59703
Value Function Loss: 0.09467

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.57746
Value Function Update Magnitude: 0.74469

Collected Steps per Second: 22,298.97808
Overall Steps per Second: 10,619.35017

Timestep Collection Time: 2.24243
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70876

Cumulative Model Updates: 110,140
Cumulative Timesteps: 918,498,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 918498950...
Checkpoint 918498950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.29904
Policy Entropy: 3.62131
Value Function Loss: 0.09222

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.79327

Collected Steps per Second: 22,927.71763
Overall Steps per Second: 10,690.64657

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.49862
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.68148

Cumulative Model Updates: 110,146
Cumulative Timesteps: 918,548,998

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,120.69475
Policy Entropy: 3.62245
Value Function Loss: 0.09012

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.80912

Collected Steps per Second: 21,964.49764
Overall Steps per Second: 10,631.87125

Timestep Collection Time: 2.27640
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.70284

Cumulative Model Updates: 110,152
Cumulative Timesteps: 918,598,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 918598998...
Checkpoint 918598998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,961.72774
Policy Entropy: 3.63114
Value Function Loss: 0.08846

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.67971
Value Function Update Magnitude: 0.78614

Collected Steps per Second: 22,394.62500
Overall Steps per Second: 10,737.30042

Timestep Collection Time: 2.23393
Timestep Consumption Time: 2.42534
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.65927

Cumulative Model Updates: 110,158
Cumulative Timesteps: 918,649,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,590.81770
Policy Entropy: 3.62023
Value Function Loss: 0.08603

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.58270
Value Function Update Magnitude: 0.78982

Collected Steps per Second: 21,974.70909
Overall Steps per Second: 10,427.99586

Timestep Collection Time: 2.27616
Timestep Consumption Time: 2.52035
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.79651

Cumulative Model Updates: 110,164
Cumulative Timesteps: 918,699,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 918699044...
Checkpoint 918699044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,205.50630
Policy Entropy: 3.62085
Value Function Loss: 0.08713

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.81217

Collected Steps per Second: 22,335.43173
Overall Steps per Second: 10,708.85292

Timestep Collection Time: 2.24057
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.67314

Cumulative Model Updates: 110,170
Cumulative Timesteps: 918,749,088

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,185.19867
Policy Entropy: 3.61950
Value Function Loss: 0.08612

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.60066
Value Function Update Magnitude: 0.88259

Collected Steps per Second: 22,665.50386
Overall Steps per Second: 10,579.20167

Timestep Collection Time: 2.20661
Timestep Consumption Time: 2.52096
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72758

Cumulative Model Updates: 110,176
Cumulative Timesteps: 918,799,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 918799102...
Checkpoint 918799102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,237.53626
Policy Entropy: 3.61213
Value Function Loss: 0.08749

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.55922
Value Function Update Magnitude: 0.93565

Collected Steps per Second: 22,833.37404
Overall Steps per Second: 10,806.89587

Timestep Collection Time: 2.18995
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.62705

Cumulative Model Updates: 110,182
Cumulative Timesteps: 918,849,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,439.16337
Policy Entropy: 3.61854
Value Function Loss: 0.08282

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.87650

Collected Steps per Second: 22,787.87497
Overall Steps per Second: 10,630.04076

Timestep Collection Time: 2.19468
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.70478

Cumulative Model Updates: 110,188
Cumulative Timesteps: 918,899,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 918899118...
Checkpoint 918899118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777.64932
Policy Entropy: 3.62769
Value Function Loss: 0.07912

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.51974
Value Function Update Magnitude: 0.87890

Collected Steps per Second: 22,690.54393
Overall Steps per Second: 10,606.13531

Timestep Collection Time: 2.20418
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.71557

Cumulative Model Updates: 110,194
Cumulative Timesteps: 918,949,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.29804
Policy Entropy: 3.63455
Value Function Loss: 0.07920

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.91980

Collected Steps per Second: 22,650.34596
Overall Steps per Second: 10,779.60783

Timestep Collection Time: 2.20756
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63857

Cumulative Model Updates: 110,200
Cumulative Timesteps: 918,999,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 918999134...
Checkpoint 918999134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,973.54099
Policy Entropy: 3.61535
Value Function Loss: 0.08550

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.83991

Collected Steps per Second: 22,761.73504
Overall Steps per Second: 10,752.93898

Timestep Collection Time: 2.19746
Timestep Consumption Time: 2.45411
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.65157

Cumulative Model Updates: 110,206
Cumulative Timesteps: 919,049,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,115.00982
Policy Entropy: 3.61113
Value Function Loss: 0.09191

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.56464
Value Function Update Magnitude: 0.80819

Collected Steps per Second: 22,502.46956
Overall Steps per Second: 10,607.35846

Timestep Collection Time: 2.22216
Timestep Consumption Time: 2.49193
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.71409

Cumulative Model Updates: 110,212
Cumulative Timesteps: 919,099,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 919099156...
Checkpoint 919099156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,072.66499
Policy Entropy: 3.60989
Value Function Loss: 0.09124

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.76573

Collected Steps per Second: 22,232.35460
Overall Steps per Second: 10,635.05493

Timestep Collection Time: 2.24933
Timestep Consumption Time: 2.45285
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.70219

Cumulative Model Updates: 110,218
Cumulative Timesteps: 919,149,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,318.85437
Policy Entropy: 3.61178
Value Function Loss: 0.08725

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.75079

Collected Steps per Second: 22,440.98386
Overall Steps per Second: 10,718.12234

Timestep Collection Time: 2.22922
Timestep Consumption Time: 2.43820
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.66742

Cumulative Model Updates: 110,224
Cumulative Timesteps: 919,199,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 919199190...
Checkpoint 919199190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.50844
Policy Entropy: 3.59882
Value Function Loss: 0.08377

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.55753
Value Function Update Magnitude: 0.76844

Collected Steps per Second: 22,242.44092
Overall Steps per Second: 10,718.43584

Timestep Collection Time: 2.24885
Timestep Consumption Time: 2.41787
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.66673

Cumulative Model Updates: 110,230
Cumulative Timesteps: 919,249,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,883.87658
Policy Entropy: 3.59161
Value Function Loss: 0.08492

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.56879
Value Function Update Magnitude: 0.77789

Collected Steps per Second: 22,529.63953
Overall Steps per Second: 10,577.26825

Timestep Collection Time: 2.21965
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.72787

Cumulative Model Updates: 110,236
Cumulative Timesteps: 919,299,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 919299218...
Checkpoint 919299218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,992.69270
Policy Entropy: 3.59114
Value Function Loss: 0.08491

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.58702
Value Function Update Magnitude: 0.78695

Collected Steps per Second: 22,739.47780
Overall Steps per Second: 10,521.12779

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.55414
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.75348

Cumulative Model Updates: 110,242
Cumulative Timesteps: 919,349,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,211.73781
Policy Entropy: 3.60363
Value Function Loss: 0.08599

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.61057
Value Function Update Magnitude: 0.67787

Collected Steps per Second: 22,809.87923
Overall Steps per Second: 10,791.77671

Timestep Collection Time: 2.19273
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.63464

Cumulative Model Updates: 110,248
Cumulative Timesteps: 919,399,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 919399246...
Checkpoint 919399246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,233.16831
Policy Entropy: 3.61676
Value Function Loss: 0.08680

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.75416

Collected Steps per Second: 22,897.56943
Overall Steps per Second: 10,653.51113

Timestep Collection Time: 2.18425
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.69460

Cumulative Model Updates: 110,254
Cumulative Timesteps: 919,449,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,066.65965
Policy Entropy: 3.62367
Value Function Loss: 0.08501

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.56948
Value Function Update Magnitude: 0.71537

Collected Steps per Second: 22,917.91381
Overall Steps per Second: 10,883.73860

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.41337
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.59603

Cumulative Model Updates: 110,260
Cumulative Timesteps: 919,499,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 919499282...
Checkpoint 919499282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,404.10595
Policy Entropy: 3.62852
Value Function Loss: 0.08295

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.67502

Collected Steps per Second: 22,825.58898
Overall Steps per Second: 10,658.44902

Timestep Collection Time: 2.19061
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.69130

Cumulative Model Updates: 110,266
Cumulative Timesteps: 919,549,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,942.52781
Policy Entropy: 3.63958
Value Function Loss: 0.08001

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.58032
Value Function Update Magnitude: 0.64103

Collected Steps per Second: 23,043.95185
Overall Steps per Second: 10,911.61377

Timestep Collection Time: 2.17003
Timestep Consumption Time: 2.41280
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.58282

Cumulative Model Updates: 110,272
Cumulative Timesteps: 919,599,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 919599290...
Checkpoint 919599290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,497.34881
Policy Entropy: 3.63336
Value Function Loss: 0.07823

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.73960
Value Function Update Magnitude: 0.66068

Collected Steps per Second: 22,436.61273
Overall Steps per Second: 10,690.45421

Timestep Collection Time: 2.22877
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.67763

Cumulative Model Updates: 110,278
Cumulative Timesteps: 919,649,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.55198
Policy Entropy: 3.62950
Value Function Loss: 0.07939

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.79516
Value Function Update Magnitude: 0.75075

Collected Steps per Second: 22,254.53505
Overall Steps per Second: 10,510.26653

Timestep Collection Time: 2.24754
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.75897

Cumulative Model Updates: 110,284
Cumulative Timesteps: 919,699,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 919699314...
Checkpoint 919699314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.07807
Policy Entropy: 3.62614
Value Function Loss: 0.07874

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.69132
Value Function Update Magnitude: 0.72164

Collected Steps per Second: 22,150.17311
Overall Steps per Second: 10,552.85858

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.74071

Cumulative Model Updates: 110,290
Cumulative Timesteps: 919,749,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.11609
Policy Entropy: 3.64711
Value Function Loss: 0.07859

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.18334
Policy Update Magnitude: 0.59965
Value Function Update Magnitude: 0.66399

Collected Steps per Second: 22,411.74831
Overall Steps per Second: 10,620.65721

Timestep Collection Time: 2.23106
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.70799

Cumulative Model Updates: 110,296
Cumulative Timesteps: 919,799,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 919799344...
Checkpoint 919799344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,548.37364
Policy Entropy: 3.65134
Value Function Loss: 0.07480

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.51543
Value Function Update Magnitude: 0.66504

Collected Steps per Second: 21,780.76190
Overall Steps per Second: 10,493.10130

Timestep Collection Time: 2.29671
Timestep Consumption Time: 2.47062
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.76732

Cumulative Model Updates: 110,302
Cumulative Timesteps: 919,849,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.67911
Policy Entropy: 3.64874
Value Function Loss: 0.07766

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.49812
Value Function Update Magnitude: 0.72503

Collected Steps per Second: 22,757.15301
Overall Steps per Second: 10,793.97399

Timestep Collection Time: 2.19817
Timestep Consumption Time: 2.43627
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.63444

Cumulative Model Updates: 110,308
Cumulative Timesteps: 919,899,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 919899392...
Checkpoint 919899392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,950.21329
Policy Entropy: 3.63869
Value Function Loss: 0.07637

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.48908
Value Function Update Magnitude: 0.76654

Collected Steps per Second: 22,794.13996
Overall Steps per Second: 10,712.18766

Timestep Collection Time: 2.19451
Timestep Consumption Time: 2.47512
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.66963

Cumulative Model Updates: 110,314
Cumulative Timesteps: 919,949,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.83601
Policy Entropy: 3.62234
Value Function Loss: 0.07798

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.49506
Value Function Update Magnitude: 0.83867

Collected Steps per Second: 22,890.24650
Overall Steps per Second: 10,899.30014

Timestep Collection Time: 2.18486
Timestep Consumption Time: 2.40369
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.58855

Cumulative Model Updates: 110,320
Cumulative Timesteps: 919,999,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 919999426...
Checkpoint 919999426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.92359
Policy Entropy: 3.63321
Value Function Loss: 0.07582

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.51857
Value Function Update Magnitude: 0.87462

Collected Steps per Second: 22,776.30778
Overall Steps per Second: 10,695.62951

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.67612

Cumulative Model Updates: 110,326
Cumulative Timesteps: 920,049,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.42920
Policy Entropy: 3.62980
Value Function Loss: 0.07419

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.47264
Value Function Update Magnitude: 0.79206

Collected Steps per Second: 22,842.04691
Overall Steps per Second: 10,858.52558

Timestep Collection Time: 2.18912
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60505

Cumulative Model Updates: 110,332
Cumulative Timesteps: 920,099,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 920099444...
Checkpoint 920099444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.62791
Policy Entropy: 3.62915
Value Function Loss: 0.06882

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.47045
Value Function Update Magnitude: 0.80418

Collected Steps per Second: 22,728.72770
Overall Steps per Second: 10,662.12400

Timestep Collection Time: 2.20092
Timestep Consumption Time: 2.49083
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.69175

Cumulative Model Updates: 110,338
Cumulative Timesteps: 920,149,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,372.46514
Policy Entropy: 3.63269
Value Function Loss: 0.06682

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.50557
Value Function Update Magnitude: 0.78171

Collected Steps per Second: 21,930.90201
Overall Steps per Second: 10,475.28064

Timestep Collection Time: 2.28162
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.77677

Cumulative Model Updates: 110,344
Cumulative Timesteps: 920,199,506

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 920199506...
Checkpoint 920199506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,087.42725
Policy Entropy: 3.63134
Value Function Loss: 0.06503

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.51268
Value Function Update Magnitude: 0.74700

Collected Steps per Second: 22,118.73155
Overall Steps per Second: 10,681.65145

Timestep Collection Time: 2.26071
Timestep Consumption Time: 2.42059
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.68130

Cumulative Model Updates: 110,350
Cumulative Timesteps: 920,249,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,740.78295
Policy Entropy: 3.63039
Value Function Loss: 0.06434

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.50224
Value Function Update Magnitude: 0.81563

Collected Steps per Second: 22,216.18800
Overall Steps per Second: 10,623.57623

Timestep Collection Time: 2.25160
Timestep Consumption Time: 2.45698
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.70858

Cumulative Model Updates: 110,356
Cumulative Timesteps: 920,299,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 920299532...
Checkpoint 920299532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.12068
Policy Entropy: 3.63509
Value Function Loss: 0.06202

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.84426

Collected Steps per Second: 22,200.57347
Overall Steps per Second: 10,448.48381

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.53380
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.78653

Cumulative Model Updates: 110,362
Cumulative Timesteps: 920,349,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,888.89247
Policy Entropy: 3.64411
Value Function Loss: 0.05907

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.85295

Collected Steps per Second: 22,494.98344
Overall Steps per Second: 10,632.57464

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.70479

Cumulative Model Updates: 110,368
Cumulative Timesteps: 920,399,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 920399568...
Checkpoint 920399568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,820.53234
Policy Entropy: 3.65958
Value Function Loss: 0.05583

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.51495
Value Function Update Magnitude: 0.84689

Collected Steps per Second: 23,014.32576
Overall Steps per Second: 10,946.54163

Timestep Collection Time: 2.17456
Timestep Consumption Time: 2.39730
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.57185

Cumulative Model Updates: 110,374
Cumulative Timesteps: 920,449,614

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,415.34145
Policy Entropy: 3.66760
Value Function Loss: 0.05489

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.58374
Value Function Update Magnitude: 0.82534

Collected Steps per Second: 22,621.18760
Overall Steps per Second: 10,811.00874

Timestep Collection Time: 2.21102
Timestep Consumption Time: 2.41537
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62640

Cumulative Model Updates: 110,380
Cumulative Timesteps: 920,499,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 920499630...
Checkpoint 920499630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.64778
Policy Entropy: 3.67776
Value Function Loss: 0.05526

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.67372
Value Function Update Magnitude: 0.81819

Collected Steps per Second: 22,724.44307
Overall Steps per Second: 10,658.24044

Timestep Collection Time: 2.20071
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.69214

Cumulative Model Updates: 110,386
Cumulative Timesteps: 920,549,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,197.76573
Policy Entropy: 3.66386
Value Function Loss: 0.05653

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.63092
Value Function Update Magnitude: 0.81338

Collected Steps per Second: 22,677.91939
Overall Steps per Second: 10,622.50582

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.70699

Cumulative Model Updates: 110,392
Cumulative Timesteps: 920,599,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 920599640...
Checkpoint 920599640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,716.52699
Policy Entropy: 3.66204
Value Function Loss: 0.05681

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.80293

Collected Steps per Second: 23,245.94139
Overall Steps per Second: 10,964.80200

Timestep Collection Time: 2.15255
Timestep Consumption Time: 2.41096
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.56351

Cumulative Model Updates: 110,398
Cumulative Timesteps: 920,649,678

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,950.48007
Policy Entropy: 3.66163
Value Function Loss: 0.05839

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.74789

Collected Steps per Second: 22,340.22822
Overall Steps per Second: 10,519.54799

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.51615
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.75534

Cumulative Model Updates: 110,404
Cumulative Timesteps: 920,699,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 920699702...
Checkpoint 920699702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,521.75291
Policy Entropy: 3.66521
Value Function Loss: 0.05839

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.60191
Value Function Update Magnitude: 0.73841

Collected Steps per Second: 22,507.88082
Overall Steps per Second: 10,565.47544

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.51105
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.73258

Cumulative Model Updates: 110,410
Cumulative Timesteps: 920,749,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.30870
Policy Entropy: 3.65931
Value Function Loss: 0.05912

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.79097

Collected Steps per Second: 22,512.67170
Overall Steps per Second: 10,603.24532

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.49636
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.71893

Cumulative Model Updates: 110,416
Cumulative Timesteps: 920,799,740

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 920799740...
Checkpoint 920799740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.13906
Policy Entropy: 3.65166
Value Function Loss: 0.06071

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.55597
Value Function Update Magnitude: 0.80637

Collected Steps per Second: 22,312.63506
Overall Steps per Second: 10,529.43124

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.50801
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.74916

Cumulative Model Updates: 110,422
Cumulative Timesteps: 920,849,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.21027
Policy Entropy: 3.64406
Value Function Loss: 0.06111

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.60112
Value Function Update Magnitude: 0.79940

Collected Steps per Second: 22,094.40990
Overall Steps per Second: 10,451.62346

Timestep Collection Time: 2.26320
Timestep Consumption Time: 2.52113
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.78433

Cumulative Model Updates: 110,428
Cumulative Timesteps: 920,899,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 920899750...
Checkpoint 920899750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,419.84959
Policy Entropy: 3.64774
Value Function Loss: 0.06491

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.74330

Collected Steps per Second: 22,638.77635
Overall Steps per Second: 10,583.91344

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.51615
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.72528

Cumulative Model Updates: 110,434
Cumulative Timesteps: 920,949,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,028.86331
Policy Entropy: 3.64986
Value Function Loss: 0.06717

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.73161

Collected Steps per Second: 23,003.71400
Overall Steps per Second: 10,878.90650

Timestep Collection Time: 2.17426
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59752

Cumulative Model Updates: 110,440
Cumulative Timesteps: 920,999,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 920999778...
Checkpoint 920999778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.19822
Policy Entropy: 3.65308
Value Function Loss: 0.06972

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.57048
Value Function Update Magnitude: 0.80391

Collected Steps per Second: 22,596.97806
Overall Steps per Second: 10,682.92044

Timestep Collection Time: 2.21330
Timestep Consumption Time: 2.46837
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.68168

Cumulative Model Updates: 110,446
Cumulative Timesteps: 921,049,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,266.20055
Policy Entropy: 3.66090
Value Function Loss: 0.06878

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.57842
Value Function Update Magnitude: 0.82803

Collected Steps per Second: 22,758.12861
Overall Steps per Second: 10,777.59554

Timestep Collection Time: 2.19702
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.63925

Cumulative Model Updates: 110,452
Cumulative Timesteps: 921,099,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 921099792...
Checkpoint 921099792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.36126
Policy Entropy: 3.67261
Value Function Loss: 0.06808

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06759
Policy Update Magnitude: 0.65843
Value Function Update Magnitude: 0.77552

Collected Steps per Second: 22,976.28854
Overall Steps per Second: 10,724.41668

Timestep Collection Time: 2.17650
Timestep Consumption Time: 2.48650
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66300

Cumulative Model Updates: 110,458
Cumulative Timesteps: 921,149,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,306.82342
Policy Entropy: 3.66830
Value Function Loss: 0.06553

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.66546
Value Function Update Magnitude: 0.73546

Collected Steps per Second: 22,720.55292
Overall Steps per Second: 10,683.37452

Timestep Collection Time: 2.20109
Timestep Consumption Time: 2.48001
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.68111

Cumulative Model Updates: 110,464
Cumulative Timesteps: 921,199,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 921199810...
Checkpoint 921199810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,945.68080
Policy Entropy: 3.65126
Value Function Loss: 0.06578

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.57610
Value Function Update Magnitude: 0.72084

Collected Steps per Second: 21,261.93816
Overall Steps per Second: 10,469.22184

Timestep Collection Time: 2.35228
Timestep Consumption Time: 2.42496
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.77724

Cumulative Model Updates: 110,470
Cumulative Timesteps: 921,249,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,948.69776
Policy Entropy: 3.64439
Value Function Loss: 0.07009

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.51477
Value Function Update Magnitude: 0.72052

Collected Steps per Second: 22,247.53975
Overall Steps per Second: 10,499.02751

Timestep Collection Time: 2.24807
Timestep Consumption Time: 2.51561
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.76368

Cumulative Model Updates: 110,476
Cumulative Timesteps: 921,299,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 921299838...
Checkpoint 921299838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,043.22029
Policy Entropy: 3.65283
Value Function Loss: 0.07381

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.65794
Value Function Update Magnitude: 0.71462

Collected Steps per Second: 22,049.05174
Overall Steps per Second: 10,559.18086

Timestep Collection Time: 2.26876
Timestep Consumption Time: 2.46873
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.73749

Cumulative Model Updates: 110,482
Cumulative Timesteps: 921,349,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.70554
Policy Entropy: 3.64405
Value Function Loss: 0.07468

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.78066

Collected Steps per Second: 22,434.99511
Overall Steps per Second: 10,532.46756

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.51887
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.74780

Cumulative Model Updates: 110,488
Cumulative Timesteps: 921,399,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 921399868...
Checkpoint 921399868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.61829
Policy Entropy: 3.64255
Value Function Loss: 0.07422

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.53176
Value Function Update Magnitude: 0.84974

Collected Steps per Second: 22,835.16231
Overall Steps per Second: 10,602.30974

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.71633

Cumulative Model Updates: 110,494
Cumulative Timesteps: 921,449,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.50425
Policy Entropy: 3.62691
Value Function Loss: 0.07558

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.58158
Value Function Update Magnitude: 0.89217

Collected Steps per Second: 22,684.01173
Overall Steps per Second: 10,754.13743

Timestep Collection Time: 2.20543
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.65198

Cumulative Model Updates: 110,500
Cumulative Timesteps: 921,499,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 921499900...
Checkpoint 921499900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,496.74414
Policy Entropy: 3.62869
Value Function Loss: 0.07783

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.68355
Value Function Update Magnitude: 0.88376

Collected Steps per Second: 22,557.81121
Overall Steps per Second: 10,776.73792

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.64204

Cumulative Model Updates: 110,506
Cumulative Timesteps: 921,549,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,221.92293
Policy Entropy: 3.61925
Value Function Loss: 0.07980

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.71093
Value Function Update Magnitude: 0.83941

Collected Steps per Second: 23,068.12732
Overall Steps per Second: 10,859.67351

Timestep Collection Time: 2.16905
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60750

Cumulative Model Updates: 110,512
Cumulative Timesteps: 921,599,962

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 921599962...
Checkpoint 921599962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.64882
Policy Entropy: 3.62312
Value Function Loss: 0.08418

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.72007
Value Function Update Magnitude: 0.70263

Collected Steps per Second: 22,707.45942
Overall Steps per Second: 10,681.01540

Timestep Collection Time: 2.20306
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.68364

Cumulative Model Updates: 110,518
Cumulative Timesteps: 921,649,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,614.91265
Policy Entropy: 3.62997
Value Function Loss: 0.08385

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.64185
Value Function Update Magnitude: 0.69289

Collected Steps per Second: 22,649.87812
Overall Steps per Second: 10,769.97179

Timestep Collection Time: 2.20787
Timestep Consumption Time: 2.43541
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.64328

Cumulative Model Updates: 110,524
Cumulative Timesteps: 921,699,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 921699996...
Checkpoint 921699996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,802.99068
Policy Entropy: 3.64997
Value Function Loss: 0.08176

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.78266

Collected Steps per Second: 22,198.22047
Overall Steps per Second: 10,683.39227

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.42792
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.68054

Cumulative Model Updates: 110,530
Cumulative Timesteps: 921,750,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,126.63891
Policy Entropy: 3.64664
Value Function Loss: 0.07860

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.51802
Value Function Update Magnitude: 0.84118

Collected Steps per Second: 22,237.59067
Overall Steps per Second: 10,515.55119

Timestep Collection Time: 2.25006
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.75829

Cumulative Model Updates: 110,536
Cumulative Timesteps: 921,800,036

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 921800036...
Checkpoint 921800036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.99424
Policy Entropy: 3.65080
Value Function Loss: 0.08105

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.57292
Value Function Update Magnitude: 0.86312

Collected Steps per Second: 22,496.03671
Overall Steps per Second: 10,663.81571

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.46772
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.69175

Cumulative Model Updates: 110,542
Cumulative Timesteps: 921,850,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,326.92485
Policy Entropy: 3.65140
Value Function Loss: 0.08219

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.51635
Value Function Update Magnitude: 0.86686

Collected Steps per Second: 22,527.87169
Overall Steps per Second: 10,611.98766

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.71316

Cumulative Model Updates: 110,548
Cumulative Timesteps: 921,900,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 921900084...
Checkpoint 921900084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,649.99156
Policy Entropy: 3.64071
Value Function Loss: 0.08517

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.47825
Value Function Update Magnitude: 0.80268

Collected Steps per Second: 22,436.90747
Overall Steps per Second: 10,569.21176

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.73167

Cumulative Model Updates: 110,554
Cumulative Timesteps: 921,950,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,395.54057
Policy Entropy: 3.61977
Value Function Loss: 0.08705

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.53817
Value Function Update Magnitude: 0.75899

Collected Steps per Second: 23,024.66559
Overall Steps per Second: 10,812.18121

Timestep Collection Time: 2.17158
Timestep Consumption Time: 2.45283
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.62441

Cumulative Model Updates: 110,560
Cumulative Timesteps: 922,000,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 922000094...
Checkpoint 922000094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,707.19883
Policy Entropy: 3.63357
Value Function Loss: 0.08723

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.47575
Value Function Update Magnitude: 0.75994

Collected Steps per Second: 22,426.90188
Overall Steps per Second: 10,643.19355

Timestep Collection Time: 2.22955
Timestep Consumption Time: 2.46847
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.69803

Cumulative Model Updates: 110,566
Cumulative Timesteps: 922,050,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,516.03018
Policy Entropy: 3.63885
Value Function Loss: 0.08757

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.39667
Value Function Update Magnitude: 0.80450

Collected Steps per Second: 22,619.57106
Overall Steps per Second: 10,756.80874

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64859

Cumulative Model Updates: 110,572
Cumulative Timesteps: 922,100,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 922100100...
Checkpoint 922100100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,929.48848
Policy Entropy: 3.64147
Value Function Loss: 0.08728

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.46600
Value Function Update Magnitude: 0.77238

Collected Steps per Second: 22,548.61863
Overall Steps per Second: 10,767.03746

Timestep Collection Time: 2.21858
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.64622

Cumulative Model Updates: 110,578
Cumulative Timesteps: 922,150,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,526.25935
Policy Entropy: 3.62678
Value Function Loss: 0.08718

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.45260
Value Function Update Magnitude: 0.71835

Collected Steps per Second: 22,812.06472
Overall Steps per Second: 10,835.87377

Timestep Collection Time: 2.19261
Timestep Consumption Time: 2.42335
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.61596

Cumulative Model Updates: 110,584
Cumulative Timesteps: 922,200,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 922200144...
Checkpoint 922200144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,559.85205
Policy Entropy: 3.61874
Value Function Loss: 0.08255

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.50068
Value Function Update Magnitude: 0.67955

Collected Steps per Second: 22,642.34326
Overall Steps per Second: 10,746.21603

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.65336

Cumulative Model Updates: 110,590
Cumulative Timesteps: 922,250,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,240.44390
Policy Entropy: 3.61707
Value Function Loss: 0.08090

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.51354
Value Function Update Magnitude: 0.67099

Collected Steps per Second: 22,002.36674
Overall Steps per Second: 10,425.10176

Timestep Collection Time: 2.27257
Timestep Consumption Time: 2.52373
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.79631

Cumulative Model Updates: 110,596
Cumulative Timesteps: 922,300,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 922300152...
Checkpoint 922300152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.92180
Policy Entropy: 3.60957
Value Function Loss: 0.07931

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.57583
Value Function Update Magnitude: 0.65873

Collected Steps per Second: 21,605.69787
Overall Steps per Second: 10,636.18085

Timestep Collection Time: 2.31522
Timestep Consumption Time: 2.38778
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.70300

Cumulative Model Updates: 110,602
Cumulative Timesteps: 922,350,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,990.68374
Policy Entropy: 3.61228
Value Function Loss: 0.08003

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.59005
Value Function Update Magnitude: 0.65976

Collected Steps per Second: 21,815.61522
Overall Steps per Second: 10,633.14335

Timestep Collection Time: 2.29267
Timestep Consumption Time: 2.41111
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.70378

Cumulative Model Updates: 110,608
Cumulative Timesteps: 922,400,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 922400190...
Checkpoint 922400190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,795.30754
Policy Entropy: 3.62098
Value Function Loss: 0.07844

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.56084
Value Function Update Magnitude: 0.78998

Collected Steps per Second: 21,547.18209
Overall Steps per Second: 10,532.21054

Timestep Collection Time: 2.32170
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.74981

Cumulative Model Updates: 110,614
Cumulative Timesteps: 922,450,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,228.54261
Policy Entropy: 3.63159
Value Function Loss: 0.07616

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.62409
Value Function Update Magnitude: 0.86442

Collected Steps per Second: 21,713.75192
Overall Steps per Second: 10,590.86967

Timestep Collection Time: 2.30287
Timestep Consumption Time: 2.41855
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.72143

Cumulative Model Updates: 110,620
Cumulative Timesteps: 922,500,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 922500220...
Checkpoint 922500220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.12566
Policy Entropy: 3.62383
Value Function Loss: 0.07702

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.70782
Value Function Update Magnitude: 0.84748

Collected Steps per Second: 22,115.07060
Overall Steps per Second: 10,792.86919

Timestep Collection Time: 2.26199
Timestep Consumption Time: 2.37293
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63491

Cumulative Model Updates: 110,626
Cumulative Timesteps: 922,550,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,153.58759
Policy Entropy: 3.62806
Value Function Loss: 0.07551

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.76056

Collected Steps per Second: 22,053.03303
Overall Steps per Second: 10,652.93007

Timestep Collection Time: 2.26753
Timestep Consumption Time: 2.42657
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.69411

Cumulative Model Updates: 110,632
Cumulative Timesteps: 922,600,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 922600250...
Checkpoint 922600250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,300.41374
Policy Entropy: 3.60354
Value Function Loss: 0.07871

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.48666
Value Function Update Magnitude: 0.71797

Collected Steps per Second: 22,322.35513
Overall Steps per Second: 10,909.26375

Timestep Collection Time: 2.24044
Timestep Consumption Time: 2.34392
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.58436

Cumulative Model Updates: 110,638
Cumulative Timesteps: 922,650,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,859.07862
Policy Entropy: 3.60156
Value Function Loss: 0.07931

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.49911
Value Function Update Magnitude: 0.70958

Collected Steps per Second: 22,141.02038
Overall Steps per Second: 10,513.43781

Timestep Collection Time: 2.25934
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.75810

Cumulative Model Updates: 110,644
Cumulative Timesteps: 922,700,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 922700286...
Checkpoint 922700286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.18628
Policy Entropy: 3.59819
Value Function Loss: 0.08465

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.50719
Value Function Update Magnitude: 0.70881

Collected Steps per Second: 22,487.53690
Overall Steps per Second: 10,650.98555

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69722

Cumulative Model Updates: 110,650
Cumulative Timesteps: 922,750,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,136.71535
Policy Entropy: 3.60753
Value Function Loss: 0.08333

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.56331
Value Function Update Magnitude: 0.70564

Collected Steps per Second: 23,006.20305
Overall Steps per Second: 10,916.15748

Timestep Collection Time: 2.17385
Timestep Consumption Time: 2.40762
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.58147

Cumulative Model Updates: 110,656
Cumulative Timesteps: 922,800,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 922800328...
Checkpoint 922800328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,120.26111
Policy Entropy: 3.60404
Value Function Loss: 0.08455

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.16860
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.73439

Collected Steps per Second: 21,999.32649
Overall Steps per Second: 10,738.34542

Timestep Collection Time: 2.27316
Timestep Consumption Time: 2.38380
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.65696

Cumulative Model Updates: 110,662
Cumulative Timesteps: 922,850,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,442.03192
Policy Entropy: 3.62528
Value Function Loss: 0.08098

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.46937
Value Function Update Magnitude: 0.70816

Collected Steps per Second: 22,506.91679
Overall Steps per Second: 10,770.23088

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.64335

Cumulative Model Updates: 110,668
Cumulative Timesteps: 922,900,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 922900346...
Checkpoint 922900346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,964.11243
Policy Entropy: 3.61432
Value Function Loss: 0.08036

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.42183
Value Function Update Magnitude: 0.70147

Collected Steps per Second: 22,211.75927
Overall Steps per Second: 10,667.06235

Timestep Collection Time: 2.25133
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.68789

Cumulative Model Updates: 110,674
Cumulative Timesteps: 922,950,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,300.74185
Policy Entropy: 3.62716
Value Function Loss: 0.07817

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.40470
Value Function Update Magnitude: 0.81457

Collected Steps per Second: 22,459.32279
Overall Steps per Second: 10,558.11198

Timestep Collection Time: 2.22696
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.73721

Cumulative Model Updates: 110,680
Cumulative Timesteps: 923,000,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 923000368...
Checkpoint 923000368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370.91718
Policy Entropy: 3.61898
Value Function Loss: 0.07642

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.47201
Value Function Update Magnitude: 0.85671

Collected Steps per Second: 22,616.53412
Overall Steps per Second: 10,615.45552

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.71143

Cumulative Model Updates: 110,686
Cumulative Timesteps: 923,050,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,345.87429
Policy Entropy: 3.63253
Value Function Loss: 0.07119

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.55483
Value Function Update Magnitude: 0.86712

Collected Steps per Second: 23,036.95933
Overall Steps per Second: 10,791.23043

Timestep Collection Time: 2.17181
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.63636

Cumulative Model Updates: 110,692
Cumulative Timesteps: 923,100,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 923100414...
Checkpoint 923100414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,937.14586
Policy Entropy: 3.63197
Value Function Loss: 0.06940

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.47424
Value Function Update Magnitude: 0.86485

Collected Steps per Second: 21,540.67318
Overall Steps per Second: 10,564.07247

Timestep Collection Time: 2.32212
Timestep Consumption Time: 2.41280
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.73492

Cumulative Model Updates: 110,698
Cumulative Timesteps: 923,150,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,583.70370
Policy Entropy: 3.63118
Value Function Loss: 0.06872

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.61714
Value Function Update Magnitude: 0.83632

Collected Steps per Second: 22,749.92156
Overall Steps per Second: 10,613.93227

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.71117

Cumulative Model Updates: 110,704
Cumulative Timesteps: 923,200,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 923200438...
Checkpoint 923200438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,889.05899
Policy Entropy: 3.62401
Value Function Loss: 0.07459

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.74174
Value Function Update Magnitude: 0.77588

Collected Steps per Second: 22,556.32009
Overall Steps per Second: 10,611.68371

Timestep Collection Time: 2.21676
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.71198

Cumulative Model Updates: 110,710
Cumulative Timesteps: 923,250,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,698.72560
Policy Entropy: 3.62493
Value Function Loss: 0.07791

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.67806
Value Function Update Magnitude: 0.67040

Collected Steps per Second: 22,928.14344
Overall Steps per Second: 10,823.37243

Timestep Collection Time: 2.18203
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62240

Cumulative Model Updates: 110,716
Cumulative Timesteps: 923,300,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 923300470...
Checkpoint 923300470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.18138
Policy Entropy: 3.61825
Value Function Loss: 0.08005

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.65262

Collected Steps per Second: 22,758.74889
Overall Steps per Second: 10,721.42758

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.46670
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.66374

Cumulative Model Updates: 110,722
Cumulative Timesteps: 923,350,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,200.92103
Policy Entropy: 3.60662
Value Function Loss: 0.07922

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.63408

Collected Steps per Second: 22,311.05094
Overall Steps per Second: 10,556.07213

Timestep Collection Time: 2.24104
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.73661

Cumulative Model Updates: 110,728
Cumulative Timesteps: 923,400,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 923400472...
Checkpoint 923400472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,434.57627
Policy Entropy: 3.60366
Value Function Loss: 0.08029

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.57742
Value Function Update Magnitude: 0.67487

Collected Steps per Second: 22,370.88420
Overall Steps per Second: 10,548.92602

Timestep Collection Time: 2.23505
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.73982

Cumulative Model Updates: 110,734
Cumulative Timesteps: 923,450,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,714.97459
Policy Entropy: 3.59136
Value Function Loss: 0.08128

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.17518
Policy Update Magnitude: 0.48222
Value Function Update Magnitude: 0.61752

Collected Steps per Second: 22,418.22606
Overall Steps per Second: 10,619.21453

Timestep Collection Time: 2.23086
Timestep Consumption Time: 2.47871
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.70958

Cumulative Model Updates: 110,740
Cumulative Timesteps: 923,500,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 923500484...
Checkpoint 923500484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.96047
Policy Entropy: 3.60545
Value Function Loss: 0.08167

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.38235
Value Function Update Magnitude: 0.63550

Collected Steps per Second: 22,350.40218
Overall Steps per Second: 10,564.78407

Timestep Collection Time: 2.23826
Timestep Consumption Time: 2.49691
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73517

Cumulative Model Updates: 110,746
Cumulative Timesteps: 923,550,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.37485
Policy Entropy: 3.60104
Value Function Loss: 0.07806

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.43895
Value Function Update Magnitude: 0.61519

Collected Steps per Second: 22,444.57825
Overall Steps per Second: 10,704.45399

Timestep Collection Time: 2.22780
Timestep Consumption Time: 2.44334
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.67114

Cumulative Model Updates: 110,752
Cumulative Timesteps: 923,600,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 923600512...
Checkpoint 923600512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,165.61989
Policy Entropy: 3.60783
Value Function Loss: 0.07658

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.49425
Value Function Update Magnitude: 0.72358

Collected Steps per Second: 22,967.66434
Overall Steps per Second: 10,732.23618

Timestep Collection Time: 2.17758
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.66017

Cumulative Model Updates: 110,758
Cumulative Timesteps: 923,650,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,840.13315
Policy Entropy: 3.61782
Value Function Loss: 0.07993

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.47067
Value Function Update Magnitude: 0.81477

Collected Steps per Second: 22,845.60244
Overall Steps per Second: 10,788.42167

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.44619
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.63497

Cumulative Model Updates: 110,764
Cumulative Timesteps: 923,700,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 923700530...
Checkpoint 923700530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,242.13041
Policy Entropy: 3.61869
Value Function Loss: 0.08310

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.86625

Collected Steps per Second: 22,672.79692
Overall Steps per Second: 10,732.59703

Timestep Collection Time: 2.20661
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.66150

Cumulative Model Updates: 110,770
Cumulative Timesteps: 923,750,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,831.87284
Policy Entropy: 3.61062
Value Function Loss: 0.08558

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.82013

Collected Steps per Second: 23,034.70490
Overall Steps per Second: 10,847.42315

Timestep Collection Time: 2.17081
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.60976

Cumulative Model Updates: 110,776
Cumulative Timesteps: 923,800,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 923800564...
Checkpoint 923800564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,406.20440
Policy Entropy: 3.60786
Value Function Loss: 0.08551

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.55087
Value Function Update Magnitude: 0.71472

Collected Steps per Second: 22,808.25383
Overall Steps per Second: 10,707.09115

Timestep Collection Time: 2.19333
Timestep Consumption Time: 2.47890
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.67223

Cumulative Model Updates: 110,782
Cumulative Timesteps: 923,850,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.52717
Policy Entropy: 3.59960
Value Function Loss: 0.09005

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.68703

Collected Steps per Second: 22,841.86222
Overall Steps per Second: 10,801.99709

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.62914

Cumulative Model Updates: 110,788
Cumulative Timesteps: 923,900,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 923900594...
Checkpoint 923900594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,319.96940
Policy Entropy: 3.59706
Value Function Loss: 0.08820

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.73601

Collected Steps per Second: 22,379.28227
Overall Steps per Second: 10,705.46512

Timestep Collection Time: 2.23555
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.67331

Cumulative Model Updates: 110,794
Cumulative Timesteps: 923,950,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,577.24429
Policy Entropy: 3.59253
Value Function Loss: 0.08907

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.52578
Value Function Update Magnitude: 0.68862

Collected Steps per Second: 22,170.26387
Overall Steps per Second: 10,482.14009

Timestep Collection Time: 2.25599
Timestep Consumption Time: 2.51555
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.77154

Cumulative Model Updates: 110,800
Cumulative Timesteps: 924,000,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 924000640...
Checkpoint 924000640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,835.93703
Policy Entropy: 3.58933
Value Function Loss: 0.08968

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.49887
Value Function Update Magnitude: 0.59970

Collected Steps per Second: 22,403.70628
Overall Steps per Second: 10,706.08950

Timestep Collection Time: 2.23267
Timestep Consumption Time: 2.43944
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.67211

Cumulative Model Updates: 110,806
Cumulative Timesteps: 924,050,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,213.61102
Policy Entropy: 3.58629
Value Function Loss: 0.08794

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.49372
Value Function Update Magnitude: 0.63261

Collected Steps per Second: 22,519.85420
Overall Steps per Second: 10,729.17194

Timestep Collection Time: 2.22160
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.66299

Cumulative Model Updates: 110,812
Cumulative Timesteps: 924,100,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 924100690...
Checkpoint 924100690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,323.43176
Policy Entropy: 3.58599
Value Function Loss: 0.08786

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.45540
Value Function Update Magnitude: 0.63381

Collected Steps per Second: 22,802.21473
Overall Steps per Second: 10,761.44311

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.45384
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.64696

Cumulative Model Updates: 110,818
Cumulative Timesteps: 924,150,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,916.91784
Policy Entropy: 3.60150
Value Function Loss: 0.08433

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.43423
Value Function Update Magnitude: 0.67848

Collected Steps per Second: 23,181.74209
Overall Steps per Second: 10,863.19303

Timestep Collection Time: 2.15696
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.60288

Cumulative Model Updates: 110,824
Cumulative Timesteps: 924,200,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 924200700...
Checkpoint 924200700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.06850
Policy Entropy: 3.60801
Value Function Loss: 0.08072

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.49476
Value Function Update Magnitude: 0.68913

Collected Steps per Second: 22,853.25805
Overall Steps per Second: 10,643.61076

Timestep Collection Time: 2.18875
Timestep Consumption Time: 2.51079
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69953

Cumulative Model Updates: 110,830
Cumulative Timesteps: 924,250,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,600.24300
Policy Entropy: 3.62714
Value Function Loss: 0.08012

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.52804
Value Function Update Magnitude: 0.67235

Collected Steps per Second: 22,861.17832
Overall Steps per Second: 10,826.64866

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61897

Cumulative Model Updates: 110,836
Cumulative Timesteps: 924,300,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 924300728...
Checkpoint 924300728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,740.91836
Policy Entropy: 3.62052
Value Function Loss: 0.08203

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.72287
Value Function Update Magnitude: 0.66666

Collected Steps per Second: 22,639.98731
Overall Steps per Second: 10,788.90613

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.63532

Cumulative Model Updates: 110,842
Cumulative Timesteps: 924,350,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.76884
Policy Entropy: 3.60854
Value Function Loss: 0.08370

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.76893
Value Function Update Magnitude: 0.67908

Collected Steps per Second: 22,862.66553
Overall Steps per Second: 10,819.60182

Timestep Collection Time: 2.18776
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62291

Cumulative Model Updates: 110,848
Cumulative Timesteps: 924,400,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 924400756...
Checkpoint 924400756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,587.96232
Policy Entropy: 3.58640
Value Function Loss: 0.08202

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.76711
Value Function Update Magnitude: 0.63062

Collected Steps per Second: 22,226.29968
Overall Steps per Second: 10,723.14769

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.41342
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.66318

Cumulative Model Updates: 110,854
Cumulative Timesteps: 924,450,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.45366
Policy Entropy: 3.57948
Value Function Loss: 0.08261

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.77343
Value Function Update Magnitude: 0.59713

Collected Steps per Second: 22,617.14485
Overall Steps per Second: 10,800.39167

Timestep Collection Time: 2.21169
Timestep Consumption Time: 2.41981
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.63150

Cumulative Model Updates: 110,860
Cumulative Timesteps: 924,500,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 924500782...
Checkpoint 924500782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,627.51805
Policy Entropy: 3.59411
Value Function Loss: 0.08036

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.65226
Value Function Update Magnitude: 0.65046

Collected Steps per Second: 22,177.63541
Overall Steps per Second: 10,661.06534

Timestep Collection Time: 2.25543
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.69184

Cumulative Model Updates: 110,866
Cumulative Timesteps: 924,550,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,516.46130
Policy Entropy: 3.60316
Value Function Loss: 0.07990

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.62556
Value Function Update Magnitude: 0.65235

Collected Steps per Second: 22,582.45388
Overall Steps per Second: 10,592.84642

Timestep Collection Time: 2.21526
Timestep Consumption Time: 2.50736
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.72262

Cumulative Model Updates: 110,872
Cumulative Timesteps: 924,600,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 924600828...
Checkpoint 924600828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,525.44105
Policy Entropy: 3.60315
Value Function Loss: 0.07940

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.63028

Collected Steps per Second: 22,342.01185
Overall Steps per Second: 10,531.98065

Timestep Collection Time: 2.23829
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.74820

Cumulative Model Updates: 110,878
Cumulative Timesteps: 924,650,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,183.85973
Policy Entropy: 3.59428
Value Function Loss: 0.07801

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.50782
Value Function Update Magnitude: 0.63966

Collected Steps per Second: 22,914.18946
Overall Steps per Second: 10,657.16241

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.50993
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.69224

Cumulative Model Updates: 110,884
Cumulative Timesteps: 924,700,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 924700842...
Checkpoint 924700842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,418.87289
Policy Entropy: 3.59964
Value Function Loss: 0.07789

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.59563
Value Function Update Magnitude: 0.70459

Collected Steps per Second: 22,849.65013
Overall Steps per Second: 10,827.73622

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62091

Cumulative Model Updates: 110,890
Cumulative Timesteps: 924,750,876

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,718.19780
Policy Entropy: 3.60801
Value Function Loss: 0.07804

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.79545

Collected Steps per Second: 22,737.74567
Overall Steps per Second: 10,642.62485

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.70034

Cumulative Model Updates: 110,896
Cumulative Timesteps: 924,800,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 924800900...
Checkpoint 924800900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,089.35410
Policy Entropy: 3.60958
Value Function Loss: 0.07861

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.50664
Value Function Update Magnitude: 0.84809

Collected Steps per Second: 22,925.88172
Overall Steps per Second: 10,887.80015

Timestep Collection Time: 2.18094
Timestep Consumption Time: 2.41135
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.59230

Cumulative Model Updates: 110,902
Cumulative Timesteps: 924,850,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,774.22489
Policy Entropy: 3.60083
Value Function Loss: 0.07994

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.47920
Value Function Update Magnitude: 0.84252

Collected Steps per Second: 22,493.78258
Overall Steps per Second: 10,536.76983

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.52427
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.74870

Cumulative Model Updates: 110,908
Cumulative Timesteps: 924,900,936

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 924900936...
Checkpoint 924900936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,053.15847
Policy Entropy: 3.60346
Value Function Loss: 0.07786

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.46984
Value Function Update Magnitude: 0.80896

Collected Steps per Second: 22,786.33773
Overall Steps per Second: 10,635.42755

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.70146

Cumulative Model Updates: 110,914
Cumulative Timesteps: 924,950,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,830.04129
Policy Entropy: 3.60193
Value Function Loss: 0.08345

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.52409
Value Function Update Magnitude: 0.75439

Collected Steps per Second: 22,405.60881
Overall Steps per Second: 10,580.16810

Timestep Collection Time: 2.23203
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.72677

Cumulative Model Updates: 110,920
Cumulative Timesteps: 925,000,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 925000948...
Checkpoint 925000948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,489.65381
Policy Entropy: 3.60920
Value Function Loss: 0.08282

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.52438
Value Function Update Magnitude: 0.70259

Collected Steps per Second: 22,504.18849
Overall Steps per Second: 10,609.47911

Timestep Collection Time: 2.22252
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71427

Cumulative Model Updates: 110,926
Cumulative Timesteps: 925,050,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,929.53236
Policy Entropy: 3.60412
Value Function Loss: 0.08649

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.61592
Value Function Update Magnitude: 0.68669

Collected Steps per Second: 22,676.91138
Overall Steps per Second: 10,729.06602

Timestep Collection Time: 2.20497
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.66042

Cumulative Model Updates: 110,932
Cumulative Timesteps: 925,100,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 925100966...
Checkpoint 925100966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,646.12488
Policy Entropy: 3.60480
Value Function Loss: 0.08782

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.69410

Collected Steps per Second: 22,671.13371
Overall Steps per Second: 10,673.28772

Timestep Collection Time: 2.20686
Timestep Consumption Time: 2.48073
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.68759

Cumulative Model Updates: 110,938
Cumulative Timesteps: 925,150,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.37298
Policy Entropy: 3.59328
Value Function Loss: 0.08883

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.49968
Value Function Update Magnitude: 0.63481

Collected Steps per Second: 23,093.89479
Overall Steps per Second: 10,830.47494

Timestep Collection Time: 2.16559
Timestep Consumption Time: 2.45212
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.61771

Cumulative Model Updates: 110,944
Cumulative Timesteps: 925,201,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 925201010...
Checkpoint 925201010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,768.84837
Policy Entropy: 3.59045
Value Function Loss: 0.08847

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.62773
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,831.11066
Overall Steps per Second: 10,762.48342

Timestep Collection Time: 2.19113
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.64818

Cumulative Model Updates: 110,950
Cumulative Timesteps: 925,251,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.23569
Policy Entropy: 3.57136
Value Function Loss: 0.08971

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.64065

Collected Steps per Second: 22,529.91803
Overall Steps per Second: 10,625.26948

Timestep Collection Time: 2.22043
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.70821

Cumulative Model Updates: 110,956
Cumulative Timesteps: 925,301,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 925301062...
Checkpoint 925301062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,585.16666
Policy Entropy: 3.57705
Value Function Loss: 0.09141

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.61717
Value Function Update Magnitude: 0.70944

Collected Steps per Second: 22,762.42306
Overall Steps per Second: 10,680.04369

Timestep Collection Time: 2.19783
Timestep Consumption Time: 2.48642
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.68425

Cumulative Model Updates: 110,962
Cumulative Timesteps: 925,351,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,447.20450
Policy Entropy: 3.58344
Value Function Loss: 0.08889

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.76360
Value Function Update Magnitude: 0.80191

Collected Steps per Second: 23,024.89368
Overall Steps per Second: 10,682.96376

Timestep Collection Time: 2.17269
Timestep Consumption Time: 2.51009
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.68278

Cumulative Model Updates: 110,968
Cumulative Timesteps: 925,401,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 925401116...
Checkpoint 925401116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,512.39151
Policy Entropy: 3.59647
Value Function Loss: 0.08770

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.73994
Value Function Update Magnitude: 0.76014

Collected Steps per Second: 22,614.36311
Overall Steps per Second: 10,624.62056

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.49527
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.70643

Cumulative Model Updates: 110,974
Cumulative Timesteps: 925,451,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.09319
Policy Entropy: 3.59584
Value Function Loss: 0.08952

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.74911
Value Function Update Magnitude: 0.78590

Collected Steps per Second: 22,196.10863
Overall Steps per Second: 10,510.54527

Timestep Collection Time: 2.25400
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75998

Cumulative Model Updates: 110,980
Cumulative Timesteps: 925,501,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 925501150...
Checkpoint 925501150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.93746
Policy Entropy: 3.57454
Value Function Loss: 0.09202

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.60526
Value Function Update Magnitude: 0.81379

Collected Steps per Second: 22,507.90326
Overall Steps per Second: 10,591.93667

Timestep Collection Time: 2.22171
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.72114

Cumulative Model Updates: 110,986
Cumulative Timesteps: 925,551,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.99863
Policy Entropy: 3.57626
Value Function Loss: 0.09099

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.60237
Value Function Update Magnitude: 0.79928

Collected Steps per Second: 22,382.05483
Overall Steps per Second: 10,553.82511

Timestep Collection Time: 2.23438
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.73857

Cumulative Model Updates: 110,992
Cumulative Timesteps: 925,601,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 925601166...
Checkpoint 925601166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,218.84712
Policy Entropy: 3.56905
Value Function Loss: 0.09435

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.68015
Value Function Update Magnitude: 0.66944

Collected Steps per Second: 22,335.35978
Overall Steps per Second: 10,527.22594

Timestep Collection Time: 2.23932
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.75111

Cumulative Model Updates: 110,998
Cumulative Timesteps: 925,651,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,098.35787
Policy Entropy: 3.56813
Value Function Loss: 0.09458

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.67749

Collected Steps per Second: 22,349.83573
Overall Steps per Second: 10,537.55406

Timestep Collection Time: 2.23850
Timestep Consumption Time: 2.50929
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.74778

Cumulative Model Updates: 111,004
Cumulative Timesteps: 925,701,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 925701212...
Checkpoint 925701212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,243.00076
Policy Entropy: 3.53642
Value Function Loss: 0.09481

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.53793
Value Function Update Magnitude: 0.71995

Collected Steps per Second: 22,728.83225
Overall Steps per Second: 10,570.27116

Timestep Collection Time: 2.20055
Timestep Consumption Time: 2.53121
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.73176

Cumulative Model Updates: 111,010
Cumulative Timesteps: 925,751,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,287.88454
Policy Entropy: 3.53477
Value Function Loss: 0.09504

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.53972
Value Function Update Magnitude: 0.65224

Collected Steps per Second: 22,995.86283
Overall Steps per Second: 10,835.14376

Timestep Collection Time: 2.17509
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61627

Cumulative Model Updates: 111,016
Cumulative Timesteps: 925,801,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 925801246...
Checkpoint 925801246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,719.50679
Policy Entropy: 3.54391
Value Function Loss: 0.09833

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.56534
Value Function Update Magnitude: 0.62501

Collected Steps per Second: 22,871.62737
Overall Steps per Second: 10,703.73918

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.48634
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.67351

Cumulative Model Updates: 111,022
Cumulative Timesteps: 925,851,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,537.95219
Policy Entropy: 3.55161
Value Function Loss: 0.10285

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.60194
Value Function Update Magnitude: 0.67045

Collected Steps per Second: 22,644.36256
Overall Steps per Second: 10,617.89639

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.50328
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.71336

Cumulative Model Updates: 111,028
Cumulative Timesteps: 925,901,316

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 925901316...
Checkpoint 925901316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,564.54054
Policy Entropy: 3.55175
Value Function Loss: 0.10144

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.73791
Value Function Update Magnitude: 0.68372

Collected Steps per Second: 22,854.31244
Overall Steps per Second: 10,731.95029

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.47201
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.66048

Cumulative Model Updates: 111,034
Cumulative Timesteps: 925,951,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,726.46679
Policy Entropy: 3.54509
Value Function Loss: 0.10224

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.67974
Value Function Update Magnitude: 0.59601

Collected Steps per Second: 22,627.32496
Overall Steps per Second: 10,654.82409

Timestep Collection Time: 2.21034
Timestep Consumption Time: 2.48369
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.69402

Cumulative Model Updates: 111,040
Cumulative Timesteps: 926,001,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 926001346...
Checkpoint 926001346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,537.60112
Policy Entropy: 3.53103
Value Function Loss: 0.10108

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.53570

Collected Steps per Second: 22,599.90030
Overall Steps per Second: 10,635.90055

Timestep Collection Time: 2.21328
Timestep Consumption Time: 2.48966
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.70294

Cumulative Model Updates: 111,046
Cumulative Timesteps: 926,051,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,167.10736
Policy Entropy: 3.53815
Value Function Loss: 0.09671

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.20150
Policy Update Magnitude: 0.41882
Value Function Update Magnitude: 0.57042

Collected Steps per Second: 22,505.23966
Overall Steps per Second: 10,604.46309

Timestep Collection Time: 2.22295
Timestep Consumption Time: 2.49469
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.71764

Cumulative Model Updates: 111,052
Cumulative Timesteps: 926,101,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 926101394...
Checkpoint 926101394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,604.78034
Policy Entropy: 3.56014
Value Function Loss: 0.09205

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.18623
Policy Update Magnitude: 0.39716
Value Function Update Magnitude: 0.59854

Collected Steps per Second: 22,424.72947
Overall Steps per Second: 10,568.95399

Timestep Collection Time: 2.23039
Timestep Consumption Time: 2.50196
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.73235

Cumulative Model Updates: 111,058
Cumulative Timesteps: 926,151,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,562.39781
Policy Entropy: 3.58003
Value Function Loss: 0.09017

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.16370
Policy Update Magnitude: 0.38805
Value Function Update Magnitude: 0.57618

Collected Steps per Second: 22,715.24925
Overall Steps per Second: 10,630.50748

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.70834

Cumulative Model Updates: 111,064
Cumulative Timesteps: 926,201,462

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 926201462...
Checkpoint 926201462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,027.81539
Policy Entropy: 3.57629
Value Function Loss: 0.09396

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15076
Policy Update Magnitude: 0.39257
Value Function Update Magnitude: 0.61552

Collected Steps per Second: 22,724.22835
Overall Steps per Second: 10,766.12117

Timestep Collection Time: 2.20153
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.64680

Cumulative Model Updates: 111,070
Cumulative Timesteps: 926,251,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,099.02334
Policy Entropy: 3.57555
Value Function Loss: 0.09190

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.38378
Value Function Update Magnitude: 0.64722

Collected Steps per Second: 22,825.22928
Overall Steps per Second: 10,653.22900

Timestep Collection Time: 2.19135
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.69510

Cumulative Model Updates: 111,076
Cumulative Timesteps: 926,301,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 926301508...
Checkpoint 926301508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,908.57790
Policy Entropy: 3.55777
Value Function Loss: 0.09117

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.40498
Value Function Update Magnitude: 0.64444

Collected Steps per Second: 22,944.18342
Overall Steps per Second: 10,725.81832

Timestep Collection Time: 2.18042
Timestep Consumption Time: 2.48384
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.66426

Cumulative Model Updates: 111,082
Cumulative Timesteps: 926,351,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,001.79677
Policy Entropy: 3.57364
Value Function Loss: 0.08633

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.41977
Value Function Update Magnitude: 0.63878

Collected Steps per Second: 23,112.18873
Overall Steps per Second: 10,705.59442

Timestep Collection Time: 2.16345
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.67064

Cumulative Model Updates: 111,088
Cumulative Timesteps: 926,401,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 926401538...
Checkpoint 926401538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,296.13603
Policy Entropy: 3.56416
Value Function Loss: 0.08521

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.40647
Value Function Update Magnitude: 0.68040

Collected Steps per Second: 22,096.89020
Overall Steps per Second: 10,643.42764

Timestep Collection Time: 2.26412
Timestep Consumption Time: 2.43643
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.70055

Cumulative Model Updates: 111,094
Cumulative Timesteps: 926,451,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,757.85873
Policy Entropy: 3.58998
Value Function Loss: 0.08168

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.41864
Value Function Update Magnitude: 0.79478

Collected Steps per Second: 22,022.63506
Overall Steps per Second: 10,714.88161

Timestep Collection Time: 2.27130
Timestep Consumption Time: 2.39697
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.66827

Cumulative Model Updates: 111,100
Cumulative Timesteps: 926,501,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 926501588...
Checkpoint 926501588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,405.03605
Policy Entropy: 3.58870
Value Function Loss: 0.08252

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.49289
Value Function Update Magnitude: 0.79339

Collected Steps per Second: 21,491.31502
Overall Steps per Second: 10,555.58231

Timestep Collection Time: 2.32652
Timestep Consumption Time: 2.41031
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.73683

Cumulative Model Updates: 111,106
Cumulative Timesteps: 926,551,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,149.44228
Policy Entropy: 3.60530
Value Function Loss: 0.08229

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.49909
Value Function Update Magnitude: 0.70627

Collected Steps per Second: 21,707.57863
Overall Steps per Second: 10,737.40856

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.35346
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.65699

Cumulative Model Updates: 111,112
Cumulative Timesteps: 926,601,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 926601592...
Checkpoint 926601592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,288.47146
Policy Entropy: 3.61103
Value Function Loss: 0.08230

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.47958
Value Function Update Magnitude: 0.71990

Collected Steps per Second: 21,446.52235
Overall Steps per Second: 10,688.48194

Timestep Collection Time: 2.33203
Timestep Consumption Time: 2.34721
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.67924

Cumulative Model Updates: 111,118
Cumulative Timesteps: 926,651,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,709.75126
Policy Entropy: 3.62141
Value Function Loss: 0.07769

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.56859
Value Function Update Magnitude: 0.77541

Collected Steps per Second: 21,743.18641
Overall Steps per Second: 10,435.04545

Timestep Collection Time: 2.30095
Timestep Consumption Time: 2.49347
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.79442

Cumulative Model Updates: 111,124
Cumulative Timesteps: 926,701,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 926701636...
Checkpoint 926701636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,229.85423
Policy Entropy: 3.62398
Value Function Loss: 0.07550

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.58438
Value Function Update Magnitude: 0.79002

Collected Steps per Second: 22,383.48029
Overall Steps per Second: 10,634.03854

Timestep Collection Time: 2.23388
Timestep Consumption Time: 2.46819
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.70207

Cumulative Model Updates: 111,130
Cumulative Timesteps: 926,751,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,687.36977
Policy Entropy: 3.61816
Value Function Loss: 0.07327

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.65305
Value Function Update Magnitude: 0.81894

Collected Steps per Second: 22,792.71393
Overall Steps per Second: 10,809.73755

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62749

Cumulative Model Updates: 111,136
Cumulative Timesteps: 926,801,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 926801660...
Checkpoint 926801660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,108.08628
Policy Entropy: 3.62051
Value Function Loss: 0.07375

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.63758
Value Function Update Magnitude: 0.79315

Collected Steps per Second: 22,734.61351
Overall Steps per Second: 10,625.18585

Timestep Collection Time: 2.19973
Timestep Consumption Time: 2.50701
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.70674

Cumulative Model Updates: 111,142
Cumulative Timesteps: 926,851,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,962.57727
Policy Entropy: 3.61374
Value Function Loss: 0.07732

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.53029
Value Function Update Magnitude: 0.77426

Collected Steps per Second: 22,796.90113
Overall Steps per Second: 10,631.06040

Timestep Collection Time: 2.19425
Timestep Consumption Time: 2.51102
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.70527

Cumulative Model Updates: 111,148
Cumulative Timesteps: 926,901,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 926901692...
Checkpoint 926901692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.46453
Policy Entropy: 3.61500
Value Function Loss: 0.07992

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.75924

Collected Steps per Second: 23,012.23485
Overall Steps per Second: 10,700.83267

Timestep Collection Time: 2.17406
Timestep Consumption Time: 2.50128
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.67534

Cumulative Model Updates: 111,154
Cumulative Timesteps: 926,951,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,415.76967
Policy Entropy: 3.60913
Value Function Loss: 0.08107

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.58430
Value Function Update Magnitude: 0.72026

Collected Steps per Second: 22,551.17851
Overall Steps per Second: 10,727.13978

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.66145

Cumulative Model Updates: 111,160
Cumulative Timesteps: 927,001,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 927001726...
Checkpoint 927001726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,257.11831
Policy Entropy: 3.60952
Value Function Loss: 0.08117

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.58823
Value Function Update Magnitude: 0.68439

Collected Steps per Second: 22,663.05073
Overall Steps per Second: 10,683.85333

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.47471
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.68183

Cumulative Model Updates: 111,166
Cumulative Timesteps: 927,051,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,820.46557
Policy Entropy: 3.61746
Value Function Loss: 0.08114

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.16257
Policy Update Magnitude: 0.53115
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,203.55433
Overall Steps per Second: 10,499.24174

Timestep Collection Time: 2.25342
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.76549

Cumulative Model Updates: 111,172
Cumulative Timesteps: 927,101,780

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 927101780...
Checkpoint 927101780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,615.67055
Policy Entropy: 3.62451
Value Function Loss: 0.08368

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.51736
Value Function Update Magnitude: 0.61263

Collected Steps per Second: 22,457.95553
Overall Steps per Second: 10,605.79700

Timestep Collection Time: 2.22745
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.71667

Cumulative Model Updates: 111,178
Cumulative Timesteps: 927,151,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,932.06912
Policy Entropy: 3.62985
Value Function Loss: 0.08672

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.58885

Collected Steps per Second: 22,642.64397
Overall Steps per Second: 10,642.01709

Timestep Collection Time: 2.20919
Timestep Consumption Time: 2.49123
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.70042

Cumulative Model Updates: 111,184
Cumulative Timesteps: 927,201,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 927201826...
Checkpoint 927201826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,576.98170
Policy Entropy: 3.62642
Value Function Loss: 0.08565

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.71373

Collected Steps per Second: 22,514.22735
Overall Steps per Second: 10,498.95297

Timestep Collection Time: 2.22180
Timestep Consumption Time: 2.54268
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.76448

Cumulative Model Updates: 111,190
Cumulative Timesteps: 927,251,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,486.58672
Policy Entropy: 3.62394
Value Function Loss: 0.08435

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.81295

Collected Steps per Second: 22,868.88373
Overall Steps per Second: 10,790.76571

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.44839
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63582

Cumulative Model Updates: 111,196
Cumulative Timesteps: 927,301,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 927301872...
Checkpoint 927301872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,559.72034
Policy Entropy: 3.61791
Value Function Loss: 0.08502

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.64994
Value Function Update Magnitude: 0.83192

Collected Steps per Second: 22,838.50663
Overall Steps per Second: 10,726.82715

Timestep Collection Time: 2.18990
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.66252

Cumulative Model Updates: 111,202
Cumulative Timesteps: 927,351,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,992.53118
Policy Entropy: 3.62284
Value Function Loss: 0.08721

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.66861
Value Function Update Magnitude: 0.85719

Collected Steps per Second: 23,081.25527
Overall Steps per Second: 10,859.76160

Timestep Collection Time: 2.16661
Timestep Consumption Time: 2.43828
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60489

Cumulative Model Updates: 111,208
Cumulative Timesteps: 927,401,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 927401894...
Checkpoint 927401894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,572.57721
Policy Entropy: 3.63120
Value Function Loss: 0.08716

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.60849
Value Function Update Magnitude: 0.87875

Collected Steps per Second: 22,836.22730
Overall Steps per Second: 10,669.04270

Timestep Collection Time: 2.19134
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.69039

Cumulative Model Updates: 111,214
Cumulative Timesteps: 927,451,936

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,431.61581
Policy Entropy: 3.63367
Value Function Loss: 0.08524

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.59325
Value Function Update Magnitude: 0.78065

Collected Steps per Second: 22,619.53111
Overall Steps per Second: 10,661.01649

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.48020
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.69130

Cumulative Model Updates: 111,220
Cumulative Timesteps: 927,501,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 927501950...
Checkpoint 927501950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,718.89156
Policy Entropy: 3.63148
Value Function Loss: 0.08507

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.69057
Value Function Update Magnitude: 0.64658

Collected Steps per Second: 22,904.86184
Overall Steps per Second: 10,868.44872

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.60194

Cumulative Model Updates: 111,226
Cumulative Timesteps: 927,551,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,815.75578
Policy Entropy: 3.63027
Value Function Loss: 0.08770

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.72111
Value Function Update Magnitude: 0.62151

Collected Steps per Second: 22,631.98143
Overall Steps per Second: 10,662.25624

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.48097
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.69094

Cumulative Model Updates: 111,232
Cumulative Timesteps: 927,601,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 927601982...
Checkpoint 927601982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,799.51285
Policy Entropy: 3.62281
Value Function Loss: 0.09061

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.58420
Value Function Update Magnitude: 0.56099

Collected Steps per Second: 21,894.66415
Overall Steps per Second: 10,685.41388

Timestep Collection Time: 2.28439
Timestep Consumption Time: 2.39638
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.68077

Cumulative Model Updates: 111,238
Cumulative Timesteps: 927,651,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,248.10712
Policy Entropy: 3.61709
Value Function Loss: 0.09448

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.59508

Collected Steps per Second: 21,522.94248
Overall Steps per Second: 10,658.74742

Timestep Collection Time: 2.32375
Timestep Consumption Time: 2.36854
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.69230

Cumulative Model Updates: 111,244
Cumulative Timesteps: 927,702,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 927702012...
Checkpoint 927702012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,524.87588
Policy Entropy: 3.60031
Value Function Loss: 0.09407

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.18411
Policy Update Magnitude: 0.43093
Value Function Update Magnitude: 0.69135

Collected Steps per Second: 21,735.81250
Overall Steps per Second: 10,699.65283

Timestep Collection Time: 2.30238
Timestep Consumption Time: 2.37479
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.67716

Cumulative Model Updates: 111,250
Cumulative Timesteps: 927,752,056

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.26254
Policy Entropy: 3.61755
Value Function Loss: 0.09451

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.38662
Value Function Update Magnitude: 0.73305

Collected Steps per Second: 22,197.14658
Overall Steps per Second: 10,797.16337

Timestep Collection Time: 2.25380
Timestep Consumption Time: 2.37964
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.63344

Cumulative Model Updates: 111,256
Cumulative Timesteps: 927,802,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 927802084...
Checkpoint 927802084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,275.42464
Policy Entropy: 3.62570
Value Function Loss: 0.09631

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.50222
Value Function Update Magnitude: 0.71643

Collected Steps per Second: 22,244.95653
Overall Steps per Second: 10,704.64782

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.42433
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67311

Cumulative Model Updates: 111,262
Cumulative Timesteps: 927,852,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,523.47501
Policy Entropy: 3.62553
Value Function Loss: 0.09648

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.60582
Value Function Update Magnitude: 0.67846

Collected Steps per Second: 22,157.38368
Overall Steps per Second: 10,523.48091

Timestep Collection Time: 2.25785
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75394

Cumulative Model Updates: 111,268
Cumulative Timesteps: 927,902,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 927902136...
Checkpoint 927902136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,995.00931
Policy Entropy: 3.61083
Value Function Loss: 0.09470

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.60552
Value Function Update Magnitude: 0.66111

Collected Steps per Second: 22,750.59208
Overall Steps per Second: 10,703.58748

Timestep Collection Time: 2.19775
Timestep Consumption Time: 2.47359
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.67133

Cumulative Model Updates: 111,274
Cumulative Timesteps: 927,952,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,647.89572
Policy Entropy: 3.60400
Value Function Loss: 0.09412

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.58824
Value Function Update Magnitude: 0.68472

Collected Steps per Second: 22,874.72626
Overall Steps per Second: 10,816.34589

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.62485

Cumulative Model Updates: 111,280
Cumulative Timesteps: 928,002,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 928002160...
Checkpoint 928002160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,669.46216
Policy Entropy: 3.60862
Value Function Loss: 0.09240

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.53068
Value Function Update Magnitude: 0.64187

Collected Steps per Second: 22,814.07921
Overall Steps per Second: 10,699.30596

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.48187
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.67376

Cumulative Model Updates: 111,286
Cumulative Timesteps: 928,052,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,559.27310
Policy Entropy: 3.61249
Value Function Loss: 0.09418

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.62347
Value Function Update Magnitude: 0.73259

Collected Steps per Second: 22,811.92683
Overall Steps per Second: 10,900.63827

Timestep Collection Time: 2.19280
Timestep Consumption Time: 2.39611
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.58891

Cumulative Model Updates: 111,292
Cumulative Timesteps: 928,102,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 928102188...
Checkpoint 928102188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,648.77022
Policy Entropy: 3.60760
Value Function Loss: 0.09486

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.69292
Value Function Update Magnitude: 0.74470

Collected Steps per Second: 22,140.63608
Overall Steps per Second: 10,690.96737

Timestep Collection Time: 2.25847
Timestep Consumption Time: 2.41875
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.67722

Cumulative Model Updates: 111,298
Cumulative Timesteps: 928,152,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,291.10000
Policy Entropy: 3.60197
Value Function Loss: 0.09887

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.64795
Value Function Update Magnitude: 0.69223

Collected Steps per Second: 22,390.49239
Overall Steps per Second: 10,571.89424

Timestep Collection Time: 2.23541
Timestep Consumption Time: 2.49903
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.73444

Cumulative Model Updates: 111,304
Cumulative Timesteps: 928,202,244

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 928202244...
Checkpoint 928202244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,531.07186
Policy Entropy: 3.61109
Value Function Loss: 0.09649

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.53715
Value Function Update Magnitude: 0.70814

Collected Steps per Second: 22,347.09463
Overall Steps per Second: 10,547.71319

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.50354
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.74150

Cumulative Model Updates: 111,310
Cumulative Timesteps: 928,252,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,017.43021
Policy Entropy: 3.62512
Value Function Loss: 0.09327

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.55165
Value Function Update Magnitude: 0.68295

Collected Steps per Second: 22,645.04051
Overall Steps per Second: 10,821.52584

Timestep Collection Time: 2.20896
Timestep Consumption Time: 2.41349
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62245

Cumulative Model Updates: 111,316
Cumulative Timesteps: 928,302,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 928302278...
Checkpoint 928302278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,958.34625
Policy Entropy: 3.63560
Value Function Loss: 0.08694

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.60426
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 22,476.26830
Overall Steps per Second: 10,715.55745

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.66686

Cumulative Model Updates: 111,322
Cumulative Timesteps: 928,352,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,515.62204
Policy Entropy: 3.63848
Value Function Loss: 0.08192

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.63575
Value Function Update Magnitude: 0.58986

Collected Steps per Second: 22,472.27962
Overall Steps per Second: 10,584.75547

Timestep Collection Time: 2.22585
Timestep Consumption Time: 2.49981
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.72566

Cumulative Model Updates: 111,328
Cumulative Timesteps: 928,402,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 928402306...
Checkpoint 928402306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,707.23328
Policy Entropy: 3.63887
Value Function Loss: 0.08274

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.66188

Collected Steps per Second: 22,909.88318
Overall Steps per Second: 10,829.25248

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.61786

Cumulative Model Updates: 111,334
Cumulative Timesteps: 928,452,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,662.44498
Policy Entropy: 3.63755
Value Function Loss: 0.08281

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10252
Policy Update Magnitude: 0.47354
Value Function Update Magnitude: 0.69507

Collected Steps per Second: 22,618.49322
Overall Steps per Second: 10,590.78505

Timestep Collection Time: 2.21173
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.72354

Cumulative Model Updates: 111,340
Cumulative Timesteps: 928,502,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 928502340...
Checkpoint 928502340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,774.16296
Policy Entropy: 3.62820
Value Function Loss: 0.08817

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.56193
Value Function Update Magnitude: 0.72526

Collected Steps per Second: 22,735.21074
Overall Steps per Second: 10,634.49798

Timestep Collection Time: 2.20029
Timestep Consumption Time: 2.50365
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.70394

Cumulative Model Updates: 111,346
Cumulative Timesteps: 928,552,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,509.79504
Policy Entropy: 3.62941
Value Function Loss: 0.08508

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.75999

Collected Steps per Second: 23,097.86833
Overall Steps per Second: 10,887.84539

Timestep Collection Time: 2.16488
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.59264

Cumulative Model Updates: 111,352
Cumulative Timesteps: 928,602,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 928602368...
Checkpoint 928602368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,171.75928
Policy Entropy: 3.61625
Value Function Loss: 0.08722

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.62656
Value Function Update Magnitude: 0.79066

Collected Steps per Second: 22,591.28802
Overall Steps per Second: 10,617.21074

Timestep Collection Time: 2.21457
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.71216

Cumulative Model Updates: 111,358
Cumulative Timesteps: 928,652,398

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,953.99729
Policy Entropy: 3.60478
Value Function Loss: 0.08754

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.59475
Value Function Update Magnitude: 0.84032

Collected Steps per Second: 22,343.91901
Overall Steps per Second: 10,538.00433

Timestep Collection Time: 2.23855
Timestep Consumption Time: 2.50789
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.74644

Cumulative Model Updates: 111,364
Cumulative Timesteps: 928,702,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 928702416...
Checkpoint 928702416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,801.88447
Policy Entropy: 3.60124
Value Function Loss: 0.08891

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.87843

Collected Steps per Second: 22,030.57191
Overall Steps per Second: 10,614.03915

Timestep Collection Time: 2.26957
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.71074

Cumulative Model Updates: 111,370
Cumulative Timesteps: 928,752,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.56787
Policy Entropy: 3.60888
Value Function Loss: 0.08951

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.46737
Value Function Update Magnitude: 0.89320

Collected Steps per Second: 22,321.32795
Overall Steps per Second: 10,554.90357

Timestep Collection Time: 2.24064
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.73846

Cumulative Model Updates: 111,376
Cumulative Timesteps: 928,802,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 928802430...
Checkpoint 928802430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,055.61501
Policy Entropy: 3.61203
Value Function Loss: 0.08575

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.38984
Value Function Update Magnitude: 0.85990

Collected Steps per Second: 22,503.90898
Overall Steps per Second: 10,589.51554

Timestep Collection Time: 2.22424
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.72675

Cumulative Model Updates: 111,382
Cumulative Timesteps: 928,852,484

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,480.09863
Policy Entropy: 3.61574
Value Function Loss: 0.08594

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.42469
Value Function Update Magnitude: 0.78810

Collected Steps per Second: 21,777.70131
Overall Steps per Second: 10,423.13858

Timestep Collection Time: 2.29684
Timestep Consumption Time: 2.50209
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.79894

Cumulative Model Updates: 111,388
Cumulative Timesteps: 928,902,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 928902504...
Checkpoint 928902504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,048.21822
Policy Entropy: 3.59992
Value Function Loss: 0.08805

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.46119
Value Function Update Magnitude: 0.74665

Collected Steps per Second: 22,095.17438
Overall Steps per Second: 10,603.89585

Timestep Collection Time: 2.26366
Timestep Consumption Time: 2.45310
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.71676

Cumulative Model Updates: 111,394
Cumulative Timesteps: 928,952,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096.36132
Policy Entropy: 3.58802
Value Function Loss: 0.09111

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.71161
Value Function Update Magnitude: 0.72899

Collected Steps per Second: 22,447.97673
Overall Steps per Second: 10,584.29759

Timestep Collection Time: 2.22791
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.72511

Cumulative Model Updates: 111,400
Cumulative Timesteps: 929,002,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 929002532...
Checkpoint 929002532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,812.00109
Policy Entropy: 3.58689
Value Function Loss: 0.09300

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.75003
Value Function Update Magnitude: 0.74061

Collected Steps per Second: 22,561.80953
Overall Steps per Second: 10,554.62884

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.73934

Cumulative Model Updates: 111,406
Cumulative Timesteps: 929,052,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,766.92596
Policy Entropy: 3.60118
Value Function Loss: 0.09520

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.70388

Collected Steps per Second: 23,111.28570
Overall Steps per Second: 10,815.61010

Timestep Collection Time: 2.16483
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.62591

Cumulative Model Updates: 111,412
Cumulative Timesteps: 929,102,586

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 929102586...
Checkpoint 929102586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,846.24084
Policy Entropy: 3.60279
Value Function Loss: 0.09634

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.64500
Value Function Update Magnitude: 0.69465

Collected Steps per Second: 22,631.58023
Overall Steps per Second: 10,660.60257

Timestep Collection Time: 2.20930
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.69017

Cumulative Model Updates: 111,418
Cumulative Timesteps: 929,152,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,278.94234
Policy Entropy: 3.60044
Value Function Loss: 0.09818

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.70918
Value Function Update Magnitude: 0.63713

Collected Steps per Second: 22,874.78068
Overall Steps per Second: 10,833.52164

Timestep Collection Time: 2.18660
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.61697

Cumulative Model Updates: 111,424
Cumulative Timesteps: 929,202,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 929202604...
Checkpoint 929202604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,563.18269
Policy Entropy: 3.59718
Value Function Loss: 0.09822

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.59468
Value Function Update Magnitude: 0.61290

Collected Steps per Second: 22,517.37074
Overall Steps per Second: 10,671.18644

Timestep Collection Time: 2.22131
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.68720

Cumulative Model Updates: 111,430
Cumulative Timesteps: 929,252,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.19010
Policy Entropy: 3.59572
Value Function Loss: 0.09336

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.52306
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 22,981.13336
Overall Steps per Second: 10,861.67980

Timestep Collection Time: 2.17587
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60371

Cumulative Model Updates: 111,436
Cumulative Timesteps: 929,302,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 929302626...
Checkpoint 929302626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,818.31297
Policy Entropy: 3.59362
Value Function Loss: 0.09139

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.66676

Collected Steps per Second: 22,648.30592
Overall Steps per Second: 10,723.62930

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.45581
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.66428

Cumulative Model Updates: 111,442
Cumulative Timesteps: 929,352,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526.03282
Policy Entropy: 3.59727
Value Function Loss: 0.09395

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.67153

Collected Steps per Second: 21,821.65969
Overall Steps per Second: 10,644.81416

Timestep Collection Time: 2.29231
Timestep Consumption Time: 2.40688
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.69919

Cumulative Model Updates: 111,448
Cumulative Timesteps: 929,402,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 929402666...
Checkpoint 929402666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,195.36179
Policy Entropy: 3.59924
Value Function Loss: 0.09659

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.51214
Value Function Update Magnitude: 0.70524

Collected Steps per Second: 21,931.95034
Overall Steps per Second: 10,800.17546

Timestep Collection Time: 2.27987
Timestep Consumption Time: 2.34987
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62974

Cumulative Model Updates: 111,454
Cumulative Timesteps: 929,452,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,895.68911
Policy Entropy: 3.59225
Value Function Loss: 0.09736

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.48526
Value Function Update Magnitude: 0.66065

Collected Steps per Second: 21,773.29600
Overall Steps per Second: 10,557.51070

Timestep Collection Time: 2.29713
Timestep Consumption Time: 2.44035
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.73748

Cumulative Model Updates: 111,460
Cumulative Timesteps: 929,502,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 929502684...
Checkpoint 929502684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.16942
Policy Entropy: 3.59565
Value Function Loss: 0.09647

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.65520

Collected Steps per Second: 21,772.93447
Overall Steps per Second: 10,659.20307

Timestep Collection Time: 2.29790
Timestep Consumption Time: 2.39589
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.69378

Cumulative Model Updates: 111,466
Cumulative Timesteps: 929,552,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.48701
Policy Entropy: 3.59343
Value Function Loss: 0.09439

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.68504

Collected Steps per Second: 22,376.08283
Overall Steps per Second: 10,806.17141

Timestep Collection Time: 2.23515
Timestep Consumption Time: 2.39313
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62828

Cumulative Model Updates: 111,472
Cumulative Timesteps: 929,602,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 929602730...
Checkpoint 929602730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,534.02199
Policy Entropy: 3.58955
Value Function Loss: 0.09452

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.16374
Policy Update Magnitude: 0.48618
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 22,060.90737
Overall Steps per Second: 10,688.48940

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.41254
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.67999

Cumulative Model Updates: 111,478
Cumulative Timesteps: 929,652,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,558.84182
Policy Entropy: 3.58341
Value Function Loss: 0.09693

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.42821
Value Function Update Magnitude: 0.59047

Collected Steps per Second: 21,865.63888
Overall Steps per Second: 10,646.06487

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.41181
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.70033

Cumulative Model Updates: 111,484
Cumulative Timesteps: 929,702,792

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 929702792...
Checkpoint 929702792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,611.09892
Policy Entropy: 3.56914
Value Function Loss: 0.09609

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.50024
Value Function Update Magnitude: 0.59329

Collected Steps per Second: 21,812.53820
Overall Steps per Second: 10,486.02385

Timestep Collection Time: 2.29318
Timestep Consumption Time: 2.47698
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.77016

Cumulative Model Updates: 111,490
Cumulative Timesteps: 929,752,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.86779
Policy Entropy: 3.56945
Value Function Loss: 0.09353

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.44441
Value Function Update Magnitude: 0.67678

Collected Steps per Second: 22,576.64098
Overall Steps per Second: 10,820.35474

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.40653
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62148

Cumulative Model Updates: 111,496
Cumulative Timesteps: 929,802,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 929802818...
Checkpoint 929802818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,719.04558
Policy Entropy: 3.56110
Value Function Loss: 0.09244

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.46068
Value Function Update Magnitude: 0.67058

Collected Steps per Second: 22,594.34927
Overall Steps per Second: 10,716.42392

Timestep Collection Time: 2.21400
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.66798

Cumulative Model Updates: 111,502
Cumulative Timesteps: 929,852,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,546.50595
Policy Entropy: 3.56046
Value Function Loss: 0.09274

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.57718
Value Function Update Magnitude: 0.67988

Collected Steps per Second: 22,910.50317
Overall Steps per Second: 10,885.81562

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.41189
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59534

Cumulative Model Updates: 111,508
Cumulative Timesteps: 929,902,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 929902866...
Checkpoint 929902866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,193.91540
Policy Entropy: 3.55559
Value Function Loss: 0.08890

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.72299

Collected Steps per Second: 22,208.34897
Overall Steps per Second: 10,712.25988

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.41624
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.66774

Cumulative Model Updates: 111,514
Cumulative Timesteps: 929,952,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,810.47703
Policy Entropy: 3.55891
Value Function Loss: 0.08849

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.69742
Value Function Update Magnitude: 0.69787

Collected Steps per Second: 22,366.50659
Overall Steps per Second: 10,510.62903

Timestep Collection Time: 2.23665
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.75956

Cumulative Model Updates: 111,520
Cumulative Timesteps: 930,002,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 930002894...
Checkpoint 930002894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,749.09360
Policy Entropy: 3.55514
Value Function Loss: 0.08833

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.72969
Value Function Update Magnitude: 0.76906

Collected Steps per Second: 22,176.88600
Overall Steps per Second: 10,552.83061

Timestep Collection Time: 2.25559
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.74015

Cumulative Model Updates: 111,526
Cumulative Timesteps: 930,052,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.73019
Policy Entropy: 3.54579
Value Function Loss: 0.09037

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.63517
Value Function Update Magnitude: 0.83552

Collected Steps per Second: 22,663.88367
Overall Steps per Second: 10,665.43762

Timestep Collection Time: 2.20668
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.68917

Cumulative Model Updates: 111,532
Cumulative Timesteps: 930,102,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 930102928...
Checkpoint 930102928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,024.78578
Policy Entropy: 3.55299
Value Function Loss: 0.09346

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.17723
Policy Update Magnitude: 0.48301
Value Function Update Magnitude: 0.71450

Collected Steps per Second: 22,733.24799
Overall Steps per Second: 10,632.19005

Timestep Collection Time: 2.19960
Timestep Consumption Time: 2.50348
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.70308

Cumulative Model Updates: 111,538
Cumulative Timesteps: 930,152,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,129.86210
Policy Entropy: 3.55322
Value Function Loss: 0.09493

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.58128
Value Function Update Magnitude: 0.72284

Collected Steps per Second: 23,033.76422
Overall Steps per Second: 10,657.01996

Timestep Collection Time: 2.17133
Timestep Consumption Time: 2.52172
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.69306

Cumulative Model Updates: 111,544
Cumulative Timesteps: 930,202,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 930202946...
Checkpoint 930202946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,658.08362
Policy Entropy: 3.55130
Value Function Loss: 0.09686

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.57159
Value Function Update Magnitude: 0.70151

Collected Steps per Second: 22,756.34228
Overall Steps per Second: 10,675.22244

Timestep Collection Time: 2.19763
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.68468

Cumulative Model Updates: 111,550
Cumulative Timesteps: 930,252,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,274.77831
Policy Entropy: 3.55503
Value Function Loss: 0.10070

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.52144
Value Function Update Magnitude: 0.71495

Collected Steps per Second: 22,923.90277
Overall Steps per Second: 10,821.22635

Timestep Collection Time: 2.18157
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62147

Cumulative Model Updates: 111,556
Cumulative Timesteps: 930,302,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 930302966...
Checkpoint 930302966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,033.21564
Policy Entropy: 3.54580
Value Function Loss: 0.10024

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.50917
Value Function Update Magnitude: 0.69465

Collected Steps per Second: 22,896.04584
Overall Steps per Second: 10,721.15593

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.66517

Cumulative Model Updates: 111,562
Cumulative Timesteps: 930,352,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,953.53169
Policy Entropy: 3.54069
Value Function Loss: 0.10283

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.58620
Value Function Update Magnitude: 0.63469

Collected Steps per Second: 22,832.99633
Overall Steps per Second: 10,832.91189

Timestep Collection Time: 2.19148
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.61907

Cumulative Model Updates: 111,568
Cumulative Timesteps: 930,403,020

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 930403020...
Checkpoint 930403020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,433.93941
Policy Entropy: 3.54112
Value Function Loss: 0.10456

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.52429
Value Function Update Magnitude: 0.59256

Collected Steps per Second: 22,538.39826
Overall Steps per Second: 10,720.83892

Timestep Collection Time: 2.21923
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.66549

Cumulative Model Updates: 111,574
Cumulative Timesteps: 930,453,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,408.31916
Policy Entropy: 3.54034
Value Function Loss: 0.10445

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.45822
Value Function Update Magnitude: 0.62090

Collected Steps per Second: 22,472.94610
Overall Steps per Second: 10,578.19164

Timestep Collection Time: 2.22552
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.72803

Cumulative Model Updates: 111,580
Cumulative Timesteps: 930,503,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 930503052...
Checkpoint 930503052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.86556
Policy Entropy: 3.53149
Value Function Loss: 0.10494

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.43860
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 21,915.03184
Overall Steps per Second: 10,565.33543

Timestep Collection Time: 2.28227
Timestep Consumption Time: 2.45170
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.73397

Cumulative Model Updates: 111,586
Cumulative Timesteps: 930,553,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,784.79539
Policy Entropy: 3.52688
Value Function Loss: 0.10433

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.45310
Value Function Update Magnitude: 0.56996

Collected Steps per Second: 22,636.28498
Overall Steps per Second: 10,766.71829

Timestep Collection Time: 2.20964
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.64561

Cumulative Model Updates: 111,592
Cumulative Timesteps: 930,603,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 930603086...
Checkpoint 930603086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,797.64083
Policy Entropy: 3.52350
Value Function Loss: 0.10616

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.50770
Value Function Update Magnitude: 0.56293

Collected Steps per Second: 22,180.50793
Overall Steps per Second: 10,658.59669

Timestep Collection Time: 2.25603
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.69480

Cumulative Model Updates: 111,598
Cumulative Timesteps: 930,653,126

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,118.32909
Policy Entropy: 3.54670
Value Function Loss: 0.10469

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.50676
Value Function Update Magnitude: 0.57305

Collected Steps per Second: 22,727.51755
Overall Steps per Second: 10,558.57243

Timestep Collection Time: 2.20015
Timestep Consumption Time: 2.53572
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.73587

Cumulative Model Updates: 111,604
Cumulative Timesteps: 930,703,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 930703130...
Checkpoint 930703130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,593.92476
Policy Entropy: 3.56349
Value Function Loss: 0.10163

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.51718
Value Function Update Magnitude: 0.53650

Collected Steps per Second: 22,492.50621
Overall Steps per Second: 10,603.54976

Timestep Collection Time: 2.22394
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.71748

Cumulative Model Updates: 111,610
Cumulative Timesteps: 930,753,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,997.07385
Policy Entropy: 3.58665
Value Function Loss: 0.09288

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.54652
Value Function Update Magnitude: 0.59526

Collected Steps per Second: 21,999.27370
Overall Steps per Second: 10,426.07952

Timestep Collection Time: 2.27426
Timestep Consumption Time: 2.52448
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.79874

Cumulative Model Updates: 111,616
Cumulative Timesteps: 930,803,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 930803184...
Checkpoint 930803184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,610.25481
Policy Entropy: 3.60817
Value Function Loss: 0.08703

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.70768

Collected Steps per Second: 22,607.68449
Overall Steps per Second: 10,661.12125

Timestep Collection Time: 2.21235
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.69144

Cumulative Model Updates: 111,622
Cumulative Timesteps: 930,853,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,035.43392
Policy Entropy: 3.62407
Value Function Loss: 0.08215

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.59834
Value Function Update Magnitude: 0.68186

Collected Steps per Second: 22,932.61381
Overall Steps per Second: 10,830.06400

Timestep Collection Time: 2.18056
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61733

Cumulative Model Updates: 111,628
Cumulative Timesteps: 930,903,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 930903206...
Checkpoint 930903206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,037.05636
Policy Entropy: 3.61816
Value Function Loss: 0.08390

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.65804
Value Function Update Magnitude: 0.68992

Collected Steps per Second: 22,504.22100
Overall Steps per Second: 10,787.53422

Timestep Collection Time: 2.22216
Timestep Consumption Time: 2.41356
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.63572

Cumulative Model Updates: 111,634
Cumulative Timesteps: 930,953,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.08398
Policy Entropy: 3.60399
Value Function Loss: 0.08466

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.73275
Value Function Update Magnitude: 0.72069

Collected Steps per Second: 22,768.10352
Overall Steps per Second: 10,777.29710

Timestep Collection Time: 2.19737
Timestep Consumption Time: 2.44479
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.64217

Cumulative Model Updates: 111,640
Cumulative Timesteps: 931,003,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931003244...
Checkpoint 931003244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,533.80491
Policy Entropy: 3.59830
Value Function Loss: 0.08379

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.63577
Value Function Update Magnitude: 0.79962

Collected Steps per Second: 22,448.90502
Overall Steps per Second: 10,685.66378

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.45218
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.67973

Cumulative Model Updates: 111,646
Cumulative Timesteps: 931,053,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.13776
Policy Entropy: 3.60404
Value Function Loss: 0.08429

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.59148
Value Function Update Magnitude: 0.86919

Collected Steps per Second: 22,507.96857
Overall Steps per Second: 10,612.56330

Timestep Collection Time: 2.22286
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.71441

Cumulative Model Updates: 111,652
Cumulative Timesteps: 931,103,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 931103282...
Checkpoint 931103282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,209.56534
Policy Entropy: 3.61315
Value Function Loss: 0.08272

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.90856

Collected Steps per Second: 22,281.32078
Overall Steps per Second: 10,531.81386

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.75018

Cumulative Model Updates: 111,658
Cumulative Timesteps: 931,153,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.41544
Policy Entropy: 3.60560
Value Function Loss: 0.08488

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.62961
Value Function Update Magnitude: 0.93211

Collected Steps per Second: 22,774.21768
Overall Steps per Second: 10,644.64110

Timestep Collection Time: 2.19643
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69927

Cumulative Model Updates: 111,664
Cumulative Timesteps: 931,203,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 931203332...
Checkpoint 931203332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,953.87414
Policy Entropy: 3.58746
Value Function Loss: 0.08867

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.95560

Collected Steps per Second: 22,812.19811
Overall Steps per Second: 10,607.62793

Timestep Collection Time: 2.19190
Timestep Consumption Time: 2.52188
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.71378

Cumulative Model Updates: 111,670
Cumulative Timesteps: 931,253,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,730.67045
Policy Entropy: 3.57043
Value Function Loss: 0.09243

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.51141
Value Function Update Magnitude: 0.91142

Collected Steps per Second: 22,794.68967
Overall Steps per Second: 10,734.41028

Timestep Collection Time: 2.19384
Timestep Consumption Time: 2.46482
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.65866

Cumulative Model Updates: 111,676
Cumulative Timesteps: 931,303,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 931303342...
Checkpoint 931303342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,394.00107
Policy Entropy: 3.56305
Value Function Loss: 0.09323

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.45185
Value Function Update Magnitude: 0.77226

Collected Steps per Second: 22,672.49289
Overall Steps per Second: 10,658.17628

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69123

Cumulative Model Updates: 111,682
Cumulative Timesteps: 931,353,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,900.56891
Policy Entropy: 3.57238
Value Function Loss: 0.09455

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.49613
Value Function Update Magnitude: 0.72540

Collected Steps per Second: 22,815.02714
Overall Steps per Second: 10,802.41551

Timestep Collection Time: 2.19233
Timestep Consumption Time: 2.43793
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.63026

Cumulative Model Updates: 111,688
Cumulative Timesteps: 931,403,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931403360...
Checkpoint 931403360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,802.10696
Policy Entropy: 3.57504
Value Function Loss: 0.09455

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.51045
Value Function Update Magnitude: 0.74402

Collected Steps per Second: 22,589.64874
Overall Steps per Second: 10,663.93749

Timestep Collection Time: 2.21349
Timestep Consumption Time: 2.47540
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.68889

Cumulative Model Updates: 111,694
Cumulative Timesteps: 931,453,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,425.78571
Policy Entropy: 3.55935
Value Function Loss: 0.09578

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.48829
Value Function Update Magnitude: 0.84338

Collected Steps per Second: 22,583.80587
Overall Steps per Second: 10,628.89062

Timestep Collection Time: 2.21530
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.70698

Cumulative Model Updates: 111,700
Cumulative Timesteps: 931,503,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931503392...
Checkpoint 931503392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,262.31401
Policy Entropy: 3.55882
Value Function Loss: 0.09398

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.45018
Value Function Update Magnitude: 0.93895

Collected Steps per Second: 22,650.20438
Overall Steps per Second: 10,671.46752

Timestep Collection Time: 2.20749
Timestep Consumption Time: 2.47791
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68539

Cumulative Model Updates: 111,706
Cumulative Timesteps: 931,553,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,699.26523
Policy Entropy: 3.56047
Value Function Loss: 0.09319

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.49194
Value Function Update Magnitude: 1.00838

Collected Steps per Second: 22,520.74215
Overall Steps per Second: 10,752.07461

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.65287

Cumulative Model Updates: 111,712
Cumulative Timesteps: 931,603,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 931603420...
Checkpoint 931603420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,408.26507
Policy Entropy: 3.55798
Value Function Loss: 0.09452

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.62833
Value Function Update Magnitude: 0.89624

Collected Steps per Second: 21,629.80176
Overall Steps per Second: 10,661.96137

Timestep Collection Time: 2.31200
Timestep Consumption Time: 2.37832
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.69032

Cumulative Model Updates: 111,718
Cumulative Timesteps: 931,653,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,547.79914
Policy Entropy: 3.55045
Value Function Loss: 0.09530

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.64567
Value Function Update Magnitude: 0.73974

Collected Steps per Second: 21,624.65451
Overall Steps per Second: 10,578.54799

Timestep Collection Time: 2.31338
Timestep Consumption Time: 2.41563
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.72900

Cumulative Model Updates: 111,724
Cumulative Timesteps: 931,703,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 931703454...
Checkpoint 931703454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,505.54146
Policy Entropy: 3.56205
Value Function Loss: 0.09508

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.17774
Policy Update Magnitude: 0.52068
Value Function Update Magnitude: 0.72869

Collected Steps per Second: 21,520.47573
Overall Steps per Second: 10,495.39775

Timestep Collection Time: 2.32467
Timestep Consumption Time: 2.44199
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.76666

Cumulative Model Updates: 111,730
Cumulative Timesteps: 931,753,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,638.00777
Policy Entropy: 3.57270
Value Function Loss: 0.09550

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.39352
Value Function Update Magnitude: 0.69770

Collected Steps per Second: 21,837.08886
Overall Steps per Second: 10,551.34700

Timestep Collection Time: 2.29106
Timestep Consumption Time: 2.45052
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.74157

Cumulative Model Updates: 111,736
Cumulative Timesteps: 931,803,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931803512...
Checkpoint 931803512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,042.84000
Policy Entropy: 3.58569
Value Function Loss: 0.09330

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.42387
Value Function Update Magnitude: 0.76923

Collected Steps per Second: 21,961.10846
Overall Steps per Second: 10,547.87917

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.74162

Cumulative Model Updates: 111,742
Cumulative Timesteps: 931,853,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,217.72713
Policy Entropy: 3.58252
Value Function Loss: 0.08844

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.84999

Collected Steps per Second: 22,284.42941
Overall Steps per Second: 10,850.69605

Timestep Collection Time: 2.24408
Timestep Consumption Time: 2.36466
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60874

Cumulative Model Updates: 111,748
Cumulative Timesteps: 931,903,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 931903534...
Checkpoint 931903534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,089.02877
Policy Entropy: 3.57903
Value Function Loss: 0.08902

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.62875
Value Function Update Magnitude: 0.78047

Collected Steps per Second: 21,735.27066
Overall Steps per Second: 10,635.15158

Timestep Collection Time: 2.30133
Timestep Consumption Time: 2.40194
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.70327

Cumulative Model Updates: 111,754
Cumulative Timesteps: 931,953,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,801.21920
Policy Entropy: 3.57815
Value Function Loss: 0.09180

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.78405
Value Function Update Magnitude: 0.83908

Collected Steps per Second: 22,852.56459
Overall Steps per Second: 10,696.28157

Timestep Collection Time: 2.18873
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.67620

Cumulative Model Updates: 111,760
Cumulative Timesteps: 932,003,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 932003572...
Checkpoint 932003572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.02941
Policy Entropy: 3.58568
Value Function Loss: 0.09344

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.73661
Value Function Update Magnitude: 0.94343

Collected Steps per Second: 22,625.92053
Overall Steps per Second: 10,849.26720

Timestep Collection Time: 2.21047
Timestep Consumption Time: 2.39942
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60990

Cumulative Model Updates: 111,766
Cumulative Timesteps: 932,053,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,823.24472
Policy Entropy: 3.59119
Value Function Loss: 0.09101

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.55726
Value Function Update Magnitude: 0.95734

Collected Steps per Second: 22,653.32439
Overall Steps per Second: 10,696.31044

Timestep Collection Time: 2.20833
Timestep Consumption Time: 2.46861
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.67694

Cumulative Model Updates: 111,772
Cumulative Timesteps: 932,103,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 932103612...
Checkpoint 932103612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,362.49615
Policy Entropy: 3.59433
Value Function Loss: 0.09079

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.48601
Value Function Update Magnitude: 0.97214

Collected Steps per Second: 22,380.01334
Overall Steps per Second: 10,595.99194

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.72254

Cumulative Model Updates: 111,778
Cumulative Timesteps: 932,153,652

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.68674
Policy Entropy: 3.58307
Value Function Loss: 0.09106

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.45785
Value Function Update Magnitude: 0.94721

Collected Steps per Second: 22,387.44033
Overall Steps per Second: 10,692.39261

Timestep Collection Time: 2.23384
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.67716

Cumulative Model Updates: 111,784
Cumulative Timesteps: 932,203,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 932203662...
Checkpoint 932203662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,763.22007
Policy Entropy: 3.58447
Value Function Loss: 0.08936

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.44781
Value Function Update Magnitude: 0.93575

Collected Steps per Second: 22,052.51424
Overall Steps per Second: 10,632.32601

Timestep Collection Time: 2.26813
Timestep Consumption Time: 2.43620
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.70433

Cumulative Model Updates: 111,790
Cumulative Timesteps: 932,253,680

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,802.61250
Policy Entropy: 3.58655
Value Function Loss: 0.08967

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.48291
Value Function Update Magnitude: 0.91867

Collected Steps per Second: 22,656.02010
Overall Steps per Second: 10,590.97936

Timestep Collection Time: 2.20710
Timestep Consumption Time: 2.51428
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.72138

Cumulative Model Updates: 111,796
Cumulative Timesteps: 932,303,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 932303684...
Checkpoint 932303684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,865.79662
Policy Entropy: 3.59434
Value Function Loss: 0.08963

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.53590
Value Function Update Magnitude: 0.94172

Collected Steps per Second: 22,240.98267
Overall Steps per Second: 10,574.79875

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.72974

Cumulative Model Updates: 111,802
Cumulative Timesteps: 932,353,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,217.51133
Policy Entropy: 3.58151
Value Function Loss: 0.08881

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.62274
Value Function Update Magnitude: 0.95691

Collected Steps per Second: 23,167.78693
Overall Steps per Second: 10,841.04749

Timestep Collection Time: 2.15843
Timestep Consumption Time: 2.45423
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61265

Cumulative Model Updates: 111,808
Cumulative Timesteps: 932,403,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 932403706...
Checkpoint 932403706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,234.28347
Policy Entropy: 3.58199
Value Function Loss: 0.09036

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.94706

Collected Steps per Second: 22,818.60663
Overall Steps per Second: 10,757.38008

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.45747
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.64927

Cumulative Model Updates: 111,814
Cumulative Timesteps: 932,453,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,899.36184
Policy Entropy: 3.56853
Value Function Loss: 0.09277

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.64572
Value Function Update Magnitude: 0.82686

Collected Steps per Second: 23,273.31001
Overall Steps per Second: 10,904.97708

Timestep Collection Time: 2.14959
Timestep Consumption Time: 2.43804
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.58763

Cumulative Model Updates: 111,820
Cumulative Timesteps: 932,503,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 932503748...
Checkpoint 932503748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,028.46329
Policy Entropy: 3.56289
Value Function Loss: 0.09731

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.75220
Value Function Update Magnitude: 0.70992

Collected Steps per Second: 22,642.92309
Overall Steps per Second: 10,651.46997

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.48649
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69513

Cumulative Model Updates: 111,826
Cumulative Timesteps: 932,553,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,632.93508
Policy Entropy: 3.55187
Value Function Loss: 0.10214

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.68509
Value Function Update Magnitude: 0.69535

Collected Steps per Second: 22,921.71866
Overall Steps per Second: 10,812.75960

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.44410
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62657

Cumulative Model Updates: 111,832
Cumulative Timesteps: 932,603,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 932603784...
Checkpoint 932603784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,526.13681
Policy Entropy: 3.54617
Value Function Loss: 0.10251

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.58470
Value Function Update Magnitude: 0.73009

Collected Steps per Second: 22,550.91032
Overall Steps per Second: 10,724.80821

Timestep Collection Time: 2.21791
Timestep Consumption Time: 2.44567
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.66358

Cumulative Model Updates: 111,838
Cumulative Timesteps: 932,653,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,637.10545
Policy Entropy: 3.56097
Value Function Loss: 0.10032

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.56639
Value Function Update Magnitude: 0.74178

Collected Steps per Second: 22,389.24715
Overall Steps per Second: 10,575.96558

Timestep Collection Time: 2.23420
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.72978

Cumulative Model Updates: 111,844
Cumulative Timesteps: 932,703,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 932703822...
Checkpoint 932703822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,421.73276
Policy Entropy: 3.58621
Value Function Loss: 0.09845

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.58992
Value Function Update Magnitude: 0.76324

Collected Steps per Second: 22,107.29185
Overall Steps per Second: 10,536.68198

Timestep Collection Time: 2.26197
Timestep Consumption Time: 2.48393
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.74590

Cumulative Model Updates: 111,850
Cumulative Timesteps: 932,753,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,226.94088
Policy Entropy: 3.61201
Value Function Loss: 0.09307

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.79678

Collected Steps per Second: 22,434.94827
Overall Steps per Second: 10,563.60469

Timestep Collection Time: 2.22902
Timestep Consumption Time: 2.50497
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73399

Cumulative Model Updates: 111,856
Cumulative Timesteps: 932,803,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 932803836...
Checkpoint 932803836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,929.64201
Policy Entropy: 3.60734
Value Function Loss: 0.09226

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.74992
Value Function Update Magnitude: 0.78002

Collected Steps per Second: 22,088.29242
Overall Steps per Second: 10,483.85297

Timestep Collection Time: 2.26500
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.77210

Cumulative Model Updates: 111,862
Cumulative Timesteps: 932,853,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,265.49836
Policy Entropy: 3.63113
Value Function Loss: 0.09228

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.73674
Value Function Update Magnitude: 0.72866

Collected Steps per Second: 22,375.76937
Overall Steps per Second: 10,514.69720

Timestep Collection Time: 2.23474
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75563

Cumulative Model Updates: 111,868
Cumulative Timesteps: 932,903,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 932903870...
Checkpoint 932903870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,949.50941
Policy Entropy: 3.61681
Value Function Loss: 0.09372

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.62387
Value Function Update Magnitude: 0.71900

Collected Steps per Second: 22,516.20530
Overall Steps per Second: 10,642.05188

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.47871
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.70022

Cumulative Model Updates: 111,874
Cumulative Timesteps: 932,953,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,637.45035
Policy Entropy: 3.61757
Value Function Loss: 0.09413

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.63182
Value Function Update Magnitude: 0.67403

Collected Steps per Second: 22,850.54728
Overall Steps per Second: 10,753.25983

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.46162
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.64975

Cumulative Model Updates: 111,880
Cumulative Timesteps: 933,003,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 933003890...
Checkpoint 933003890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.14646
Policy Entropy: 3.60248
Value Function Loss: 0.09247

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.64655
Value Function Update Magnitude: 0.60520

Collected Steps per Second: 22,782.36083
Overall Steps per Second: 10,770.24496

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.44901
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.64483

Cumulative Model Updates: 111,886
Cumulative Timesteps: 933,053,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.40225
Policy Entropy: 3.59866
Value Function Loss: 0.09189

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.69319
Value Function Update Magnitude: 0.63239

Collected Steps per Second: 22,901.34145
Overall Steps per Second: 10,815.02797

Timestep Collection Time: 2.18406
Timestep Consumption Time: 2.44080
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.62486

Cumulative Model Updates: 111,892
Cumulative Timesteps: 933,103,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 933103934...
Checkpoint 933103934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.19196
Policy Entropy: 3.61638
Value Function Loss: 0.09100

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.66618
Value Function Update Magnitude: 0.72738

Collected Steps per Second: 22,604.79071
Overall Steps per Second: 10,799.12698

Timestep Collection Time: 2.21307
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.63241

Cumulative Model Updates: 111,898
Cumulative Timesteps: 933,153,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,140.58239
Policy Entropy: 3.61517
Value Function Loss: 0.09078

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.62445
Value Function Update Magnitude: 0.73130

Collected Steps per Second: 22,903.98166
Overall Steps per Second: 10,800.01364

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.63185

Cumulative Model Updates: 111,904
Cumulative Timesteps: 933,203,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 933203984...
Checkpoint 933203984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,932.59799
Policy Entropy: 3.63217
Value Function Loss: 0.08591

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.63712
Value Function Update Magnitude: 0.66939

Collected Steps per Second: 22,255.35000
Overall Steps per Second: 10,676.44721

Timestep Collection Time: 2.24746
Timestep Consumption Time: 2.43743
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.68489

Cumulative Model Updates: 111,910
Cumulative Timesteps: 933,254,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,704.19340
Policy Entropy: 3.61296
Value Function Loss: 0.08418

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.71187
Value Function Update Magnitude: 0.69895

Collected Steps per Second: 22,603.66791
Overall Steps per Second: 10,630.80074

Timestep Collection Time: 2.21238
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.70407

Cumulative Model Updates: 111,916
Cumulative Timesteps: 933,304,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 933304010...
Checkpoint 933304010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,513.46756
Policy Entropy: 3.59848
Value Function Loss: 0.08537

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.74155
Value Function Update Magnitude: 0.74831

Collected Steps per Second: 22,307.63677
Overall Steps per Second: 10,527.88497

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.75138

Cumulative Model Updates: 111,922
Cumulative Timesteps: 933,354,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,023.44199
Policy Entropy: 3.58833
Value Function Loss: 0.09119

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.63177
Value Function Update Magnitude: 0.76911

Collected Steps per Second: 22,610.59515
Overall Steps per Second: 10,823.27162

Timestep Collection Time: 2.21303
Timestep Consumption Time: 2.41015
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62319

Cumulative Model Updates: 111,928
Cumulative Timesteps: 933,404,070

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 933404070...
Checkpoint 933404070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.63997
Policy Entropy: 3.58021
Value Function Loss: 0.09342

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.18578
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.70085

Collected Steps per Second: 22,477.63417
Overall Steps per Second: 10,642.40700

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.47415
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.69894

Cumulative Model Updates: 111,934
Cumulative Timesteps: 933,454,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,006.66401
Policy Entropy: 3.57428
Value Function Loss: 0.09353

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.56331
Value Function Update Magnitude: 0.65709

Collected Steps per Second: 22,734.73647
Overall Steps per Second: 10,631.73333

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70516

Cumulative Model Updates: 111,940
Cumulative Timesteps: 933,504,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 933504102...
Checkpoint 933504102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,662.53202
Policy Entropy: 3.58845
Value Function Loss: 0.08911

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.63230
Value Function Update Magnitude: 0.67987

Collected Steps per Second: 22,644.65506
Overall Steps per Second: 10,599.99484

Timestep Collection Time: 2.20900
Timestep Consumption Time: 2.51006
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.71906

Cumulative Model Updates: 111,946
Cumulative Timesteps: 933,554,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,733.73990
Policy Entropy: 3.59370
Value Function Loss: 0.08811

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.74315
Value Function Update Magnitude: 0.77814

Collected Steps per Second: 22,674.40653
Overall Steps per Second: 10,744.88701

Timestep Collection Time: 2.20548
Timestep Consumption Time: 2.44864
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.65412

Cumulative Model Updates: 111,952
Cumulative Timesteps: 933,604,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 933604132...
Checkpoint 933604132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,514.83848
Policy Entropy: 3.61412
Value Function Loss: 0.08631

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.62558
Value Function Update Magnitude: 0.71749

Collected Steps per Second: 22,875.67363
Overall Steps per Second: 10,703.24548

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.48615
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.67223

Cumulative Model Updates: 111,958
Cumulative Timesteps: 933,654,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,779.18117
Policy Entropy: 3.59181
Value Function Loss: 0.08723

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.70977

Collected Steps per Second: 22,920.07805
Overall Steps per Second: 10,837.92483

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61638

Cumulative Model Updates: 111,964
Cumulative Timesteps: 933,704,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 933704172...
Checkpoint 933704172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,177.73452
Policy Entropy: 3.57386
Value Function Loss: 0.08624

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.52273
Value Function Update Magnitude: 0.72086

Collected Steps per Second: 22,174.33442
Overall Steps per Second: 10,682.02636

Timestep Collection Time: 2.25504
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.68113

Cumulative Model Updates: 111,970
Cumulative Timesteps: 933,754,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,967.24168
Policy Entropy: 3.57438
Value Function Loss: 0.08775

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.51563
Value Function Update Magnitude: 0.69824

Collected Steps per Second: 22,312.94076
Overall Steps per Second: 10,521.80588

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.51209
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.75375

Cumulative Model Updates: 111,976
Cumulative Timesteps: 933,804,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 933804194...
Checkpoint 933804194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,677.83348
Policy Entropy: 3.58751
Value Function Loss: 0.08681

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.50718
Value Function Update Magnitude: 0.68886

Collected Steps per Second: 22,437.13900
Overall Steps per Second: 10,569.29843

Timestep Collection Time: 2.22889
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.73163

Cumulative Model Updates: 111,982
Cumulative Timesteps: 933,854,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.81079
Policy Entropy: 3.60078
Value Function Loss: 0.08802

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.69956

Collected Steps per Second: 22,500.67880
Overall Steps per Second: 10,575.23712

Timestep Collection Time: 2.22269
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.72916

Cumulative Model Updates: 111,988
Cumulative Timesteps: 933,904,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 933904216...
Checkpoint 933904216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,985.06710
Policy Entropy: 3.59613
Value Function Loss: 0.08776

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.70200

Collected Steps per Second: 21,911.11949
Overall Steps per Second: 10,513.39457

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.47429
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.75660

Cumulative Model Updates: 111,994
Cumulative Timesteps: 933,954,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,964.39351
Policy Entropy: 3.58446
Value Function Loss: 0.09049

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.62070
Value Function Update Magnitude: 0.69747

Collected Steps per Second: 22,606.39452
Overall Steps per Second: 10,582.03118

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.72612

Cumulative Model Updates: 112,000
Cumulative Timesteps: 934,004,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 934004236...
Checkpoint 934004236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,639.85839
Policy Entropy: 3.58489
Value Function Loss: 0.09335

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.68327

Collected Steps per Second: 22,984.27077
Overall Steps per Second: 10,611.96867

Timestep Collection Time: 2.17618
Timestep Consumption Time: 2.53717
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.71336

Cumulative Model Updates: 112,006
Cumulative Timesteps: 934,054,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.58267
Policy Entropy: 3.58608
Value Function Loss: 0.09272

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.54537
Value Function Update Magnitude: 0.68236

Collected Steps per Second: 22,925.09852
Overall Steps per Second: 10,725.14512

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.48261
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.66511

Cumulative Model Updates: 112,012
Cumulative Timesteps: 934,104,288

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 934104288...
Checkpoint 934104288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,094.71255
Policy Entropy: 3.59405
Value Function Loss: 0.09217

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.73658
Value Function Update Magnitude: 0.68125

Collected Steps per Second: 22,427.39135
Overall Steps per Second: 10,729.25535

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.66146

Cumulative Model Updates: 112,018
Cumulative Timesteps: 934,154,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,591.79462
Policy Entropy: 3.57606
Value Function Loss: 0.09419

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.72841
Value Function Update Magnitude: 0.67454

Collected Steps per Second: 23,031.09124
Overall Steps per Second: 10,837.27574

Timestep Collection Time: 2.17202
Timestep Consumption Time: 2.44390
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.61592

Cumulative Model Updates: 112,024
Cumulative Timesteps: 934,204,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 934204326...
Checkpoint 934204326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,505.02284
Policy Entropy: 3.58312
Value Function Loss: 0.09381

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.68269
Value Function Update Magnitude: 0.64960

Collected Steps per Second: 22,726.02015
Overall Steps per Second: 10,709.00311

Timestep Collection Time: 2.20091
Timestep Consumption Time: 2.46974
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.67065

Cumulative Model Updates: 112,030
Cumulative Timesteps: 934,254,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,953.56593
Policy Entropy: 3.56010
Value Function Loss: 0.09874

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.62150
Value Function Update Magnitude: 0.62440

Collected Steps per Second: 22,720.82543
Overall Steps per Second: 10,666.21349

Timestep Collection Time: 2.20106
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.68864

Cumulative Model Updates: 112,036
Cumulative Timesteps: 934,304,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 934304354...
Checkpoint 934304354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,980.15628
Policy Entropy: 3.57138
Value Function Loss: 0.10086

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.55072
Value Function Update Magnitude: 0.61634

Collected Steps per Second: 22,151.72166
Overall Steps per Second: 10,491.15848

Timestep Collection Time: 2.25716
Timestep Consumption Time: 2.50876
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.76592

Cumulative Model Updates: 112,042
Cumulative Timesteps: 934,354,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,973.75282
Policy Entropy: 3.56925
Value Function Loss: 0.10056

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.63281

Collected Steps per Second: 22,407.59968
Overall Steps per Second: 10,583.17250

Timestep Collection Time: 2.23201
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.72580

Cumulative Model Updates: 112,048
Cumulative Timesteps: 934,404,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 934404368...
Checkpoint 934404368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,971.39656
Policy Entropy: 3.57609
Value Function Loss: 0.09761

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.50946
Value Function Update Magnitude: 0.81454

Collected Steps per Second: 22,281.16044
Overall Steps per Second: 10,509.38645

Timestep Collection Time: 2.24450
Timestep Consumption Time: 2.51411
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.75860

Cumulative Model Updates: 112,054
Cumulative Timesteps: 934,454,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526.48216
Policy Entropy: 3.59092
Value Function Loss: 0.09465

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.47112
Value Function Update Magnitude: 0.79632

Collected Steps per Second: 22,511.00439
Overall Steps per Second: 10,581.31845

Timestep Collection Time: 2.22211
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.72739

Cumulative Model Updates: 112,060
Cumulative Timesteps: 934,504,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 934504400...
Checkpoint 934504400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,443.16849
Policy Entropy: 3.57223
Value Function Loss: 0.09386

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.46316
Value Function Update Magnitude: 0.75860

Collected Steps per Second: 22,678.75947
Overall Steps per Second: 10,560.50545

Timestep Collection Time: 2.20568
Timestep Consumption Time: 2.53103
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.73671

Cumulative Model Updates: 112,066
Cumulative Timesteps: 934,554,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,297.82453
Policy Entropy: 3.57073
Value Function Loss: 0.09361

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.44102
Value Function Update Magnitude: 0.68277

Collected Steps per Second: 22,943.62465
Overall Steps per Second: 10,734.54922

Timestep Collection Time: 2.17960
Timestep Consumption Time: 2.47900
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.65860

Cumulative Model Updates: 112,072
Cumulative Timesteps: 934,604,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 934604430...
Checkpoint 934604430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.34050
Policy Entropy: 3.57187
Value Function Loss: 0.09607

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.42320
Value Function Update Magnitude: 0.63824

Collected Steps per Second: 22,671.31324
Overall Steps per Second: 10,711.99875

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.66822

Cumulative Model Updates: 112,078
Cumulative Timesteps: 934,654,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,541.63020
Policy Entropy: 3.56893
Value Function Loss: 0.09601

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.41429
Value Function Update Magnitude: 0.59185

Collected Steps per Second: 22,961.83944
Overall Steps per Second: 10,861.72407

Timestep Collection Time: 2.17787
Timestep Consumption Time: 2.42618
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60406

Cumulative Model Updates: 112,084
Cumulative Timesteps: 934,704,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 934704444...
Checkpoint 934704444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,889.90748
Policy Entropy: 3.56822
Value Function Loss: 0.09600

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.45715
Value Function Update Magnitude: 0.66012

Collected Steps per Second: 22,568.99929
Overall Steps per Second: 10,792.37761

Timestep Collection Time: 2.21640
Timestep Consumption Time: 2.41853
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.63494

Cumulative Model Updates: 112,090
Cumulative Timesteps: 934,754,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,588.73005
Policy Entropy: 3.57267
Value Function Loss: 0.09454

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.49285
Value Function Update Magnitude: 0.63760

Collected Steps per Second: 22,631.35767
Overall Steps per Second: 10,751.14631

Timestep Collection Time: 2.20941
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.65085

Cumulative Model Updates: 112,096
Cumulative Timesteps: 934,804,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 934804468...
Checkpoint 934804468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,836.19901
Policy Entropy: 3.57262
Value Function Loss: 0.09469

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.46902
Value Function Update Magnitude: 0.74004

Collected Steps per Second: 22,236.43998
Overall Steps per Second: 10,673.68780

Timestep Collection Time: 2.24883
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.68498

Cumulative Model Updates: 112,102
Cumulative Timesteps: 934,854,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,438.18248
Policy Entropy: 3.56731
Value Function Loss: 0.09623

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.46334
Value Function Update Magnitude: 0.77348

Collected Steps per Second: 22,346.38369
Overall Steps per Second: 10,520.54815

Timestep Collection Time: 2.23804
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.75374

Cumulative Model Updates: 112,108
Cumulative Timesteps: 934,904,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 934904486...
Checkpoint 934904486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,030.22074
Policy Entropy: 3.57456
Value Function Loss: 0.09768

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.16558
Policy Update Magnitude: 0.45951
Value Function Update Magnitude: 0.68110

Collected Steps per Second: 21,651.11929
Overall Steps per Second: 10,521.49658

Timestep Collection Time: 2.30981
Timestep Consumption Time: 2.44331
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.75313

Cumulative Model Updates: 112,114
Cumulative Timesteps: 934,954,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.13910
Policy Entropy: 3.56719
Value Function Loss: 0.09996

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.61862

Collected Steps per Second: 22,665.45887
Overall Steps per Second: 10,477.94321

Timestep Collection Time: 2.20600
Timestep Consumption Time: 2.56593
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.77193

Cumulative Model Updates: 112,120
Cumulative Timesteps: 935,004,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 935004496...
Checkpoint 935004496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,495.53868
Policy Entropy: 3.56533
Value Function Loss: 0.10117

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.62455

Collected Steps per Second: 22,680.11896
Overall Steps per Second: 10,653.72630

Timestep Collection Time: 2.20651
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.69732

Cumulative Model Updates: 112,126
Cumulative Timesteps: 935,054,540

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,266.14807
Policy Entropy: 3.57561
Value Function Loss: 0.09371

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.60733
Value Function Update Magnitude: 0.64815

Collected Steps per Second: 22,968.01543
Overall Steps per Second: 10,702.61690

Timestep Collection Time: 2.17877
Timestep Consumption Time: 2.49691
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.67568

Cumulative Model Updates: 112,132
Cumulative Timesteps: 935,104,582

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 935104582...
Checkpoint 935104582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,822.67792
Policy Entropy: 3.58615
Value Function Loss: 0.08528

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.15190
Policy Update Magnitude: 0.61079
Value Function Update Magnitude: 0.77751

Collected Steps per Second: 22,719.28321
Overall Steps per Second: 10,861.09155

Timestep Collection Time: 2.20289
Timestep Consumption Time: 2.40512
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60801

Cumulative Model Updates: 112,138
Cumulative Timesteps: 935,154,630

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,106.49634
Policy Entropy: 3.61205
Value Function Loss: 0.07722

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.51650
Value Function Update Magnitude: 0.78818

Collected Steps per Second: 22,990.50021
Overall Steps per Second: 10,841.58885

Timestep Collection Time: 2.17499
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61224

Cumulative Model Updates: 112,144
Cumulative Timesteps: 935,204,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 935204634...
Checkpoint 935204634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,349.45362
Policy Entropy: 3.60899
Value Function Loss: 0.07587

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.51578
Value Function Update Magnitude: 0.76676

Collected Steps per Second: 22,497.88227
Overall Steps per Second: 10,724.57779

Timestep Collection Time: 2.22243
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.66219

Cumulative Model Updates: 112,150
Cumulative Timesteps: 935,254,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.07008
Policy Entropy: 3.61221
Value Function Loss: 0.07128

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.75588

Collected Steps per Second: 22,575.84905
Overall Steps per Second: 10,644.12601

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.48396
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.69987

Cumulative Model Updates: 112,156
Cumulative Timesteps: 935,304,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 935304660...
Checkpoint 935304660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,023.51493
Policy Entropy: 3.62119
Value Function Loss: 0.06713

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.51874
Value Function Update Magnitude: 0.77161

Collected Steps per Second: 22,119.95467
Overall Steps per Second: 10,478.58961

Timestep Collection Time: 2.26230
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.77564

Cumulative Model Updates: 112,162
Cumulative Timesteps: 935,354,702

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,468.00034
Policy Entropy: 3.62684
Value Function Loss: 0.06468

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.66419
Value Function Update Magnitude: 0.81529

Collected Steps per Second: 22,516.33432
Overall Steps per Second: 10,553.29945

Timestep Collection Time: 2.22088
Timestep Consumption Time: 2.51755
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.73842

Cumulative Model Updates: 112,168
Cumulative Timesteps: 935,404,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 935404708...
Checkpoint 935404708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.88174
Policy Entropy: 3.63318
Value Function Loss: 0.06343

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.67255
Value Function Update Magnitude: 0.80194

Collected Steps per Second: 22,136.04372
Overall Steps per Second: 10,579.74951

Timestep Collection Time: 2.26030
Timestep Consumption Time: 2.46893
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.72922

Cumulative Model Updates: 112,174
Cumulative Timesteps: 935,454,742

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,430.53084
Policy Entropy: 3.62752
Value Function Loss: 0.06573

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.57994
Value Function Update Magnitude: 0.75625

Collected Steps per Second: 22,908.28679
Overall Steps per Second: 10,810.15743

Timestep Collection Time: 2.18462
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62953

Cumulative Model Updates: 112,180
Cumulative Timesteps: 935,504,788

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 935504788...
Checkpoint 935504788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,309.85677
Policy Entropy: 3.62927
Value Function Loss: 0.06446

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.69656

Collected Steps per Second: 22,647.22496
Overall Steps per Second: 10,769.79092

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.64410

Cumulative Model Updates: 112,186
Cumulative Timesteps: 935,554,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,002.83456
Policy Entropy: 3.64091
Value Function Loss: 0.06547

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.61106
Value Function Update Magnitude: 0.70278

Collected Steps per Second: 22,989.58979
Overall Steps per Second: 10,829.75917

Timestep Collection Time: 2.17577
Timestep Consumption Time: 2.44299
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.61875

Cumulative Model Updates: 112,192
Cumulative Timesteps: 935,604,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 935604824...
Checkpoint 935604824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,340.94054
Policy Entropy: 3.63339
Value Function Loss: 0.06350

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.16903
Policy Update Magnitude: 0.50772
Value Function Update Magnitude: 0.71034

Collected Steps per Second: 22,734.70843
Overall Steps per Second: 10,677.59682

Timestep Collection Time: 2.20007
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.68439

Cumulative Model Updates: 112,198
Cumulative Timesteps: 935,654,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,411.03436
Policy Entropy: 3.63214
Value Function Loss: 0.06334

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.43640
Value Function Update Magnitude: 0.68368

Collected Steps per Second: 22,744.29378
Overall Steps per Second: 10,681.26009

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68222

Cumulative Model Updates: 112,204
Cumulative Timesteps: 935,704,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 935704854...
Checkpoint 935704854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,645.65081
Policy Entropy: 3.63257
Value Function Loss: 0.06276

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.61761
Value Function Update Magnitude: 0.68383

Collected Steps per Second: 22,896.85397
Overall Steps per Second: 10,860.76232

Timestep Collection Time: 2.18440
Timestep Consumption Time: 2.42080
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60520

Cumulative Model Updates: 112,210
Cumulative Timesteps: 935,754,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,435.03350
Policy Entropy: 3.63859
Value Function Loss: 0.06352

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.75061
Value Function Update Magnitude: 0.72672

Collected Steps per Second: 22,371.37166
Overall Steps per Second: 10,532.91167

Timestep Collection Time: 2.23580
Timestep Consumption Time: 2.51293
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.74873

Cumulative Model Updates: 112,216
Cumulative Timesteps: 935,804,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 935804888...
Checkpoint 935804888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.83927
Policy Entropy: 3.64321
Value Function Loss: 0.06502

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.67465
Value Function Update Magnitude: 0.72644

Collected Steps per Second: 22,301.13344
Overall Steps per Second: 10,574.39303

Timestep Collection Time: 2.24258
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.72954

Cumulative Model Updates: 112,222
Cumulative Timesteps: 935,854,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,901.05013
Policy Entropy: 3.64891
Value Function Loss: 0.06449

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.55124
Value Function Update Magnitude: 0.72355

Collected Steps per Second: 22,451.28034
Overall Steps per Second: 10,599.16629

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.49130
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71924

Cumulative Model Updates: 112,228
Cumulative Timesteps: 935,904,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 935904920...
Checkpoint 935904920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.68226
Policy Entropy: 3.65971
Value Function Loss: 0.06210

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.49195
Value Function Update Magnitude: 0.68358

Collected Steps per Second: 22,267.22027
Overall Steps per Second: 10,510.72728

Timestep Collection Time: 2.24617
Timestep Consumption Time: 2.51240
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.75857

Cumulative Model Updates: 112,234
Cumulative Timesteps: 935,954,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.04427
Policy Entropy: 3.67040
Value Function Loss: 0.06272

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.56962
Value Function Update Magnitude: 0.61039

Collected Steps per Second: 22,681.09625
Overall Steps per Second: 10,592.87725

Timestep Collection Time: 2.20483
Timestep Consumption Time: 2.51608
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.72091

Cumulative Model Updates: 112,240
Cumulative Timesteps: 936,004,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 936004944...
Checkpoint 936004944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,998.23299
Policy Entropy: 3.67224
Value Function Loss: 0.06353

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.63052
Value Function Update Magnitude: 0.61810

Collected Steps per Second: 22,853.50716
Overall Steps per Second: 10,640.44076

Timestep Collection Time: 2.18846
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.70037

Cumulative Model Updates: 112,246
Cumulative Timesteps: 936,054,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,431.97375
Policy Entropy: 3.66965
Value Function Loss: 0.06597

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.62969
Value Function Update Magnitude: 0.66392

Collected Steps per Second: 22,849.07525
Overall Steps per Second: 10,717.04549

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.66808

Cumulative Model Updates: 112,252
Cumulative Timesteps: 936,104,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 936104986...
Checkpoint 936104986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,344.45527
Policy Entropy: 3.66997
Value Function Loss: 0.06600

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.49332
Value Function Update Magnitude: 0.72575

Collected Steps per Second: 22,777.99647
Overall Steps per Second: 10,668.01296

Timestep Collection Time: 2.19563
Timestep Consumption Time: 2.49241
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.68803

Cumulative Model Updates: 112,258
Cumulative Timesteps: 936,154,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,403.76415
Policy Entropy: 3.66333
Value Function Loss: 0.06661

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.53414
Value Function Update Magnitude: 0.77809

Collected Steps per Second: 23,171.17665
Overall Steps per Second: 10,874.56090

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59789

Cumulative Model Updates: 112,264
Cumulative Timesteps: 936,204,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 936204998...
Checkpoint 936204998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,050.13409
Policy Entropy: 3.65162
Value Function Loss: 0.06833

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.53167
Value Function Update Magnitude: 0.76610

Collected Steps per Second: 22,696.05891
Overall Steps per Second: 10,652.61029

Timestep Collection Time: 2.20364
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.69500

Cumulative Model Updates: 112,270
Cumulative Timesteps: 936,255,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,384.57195
Policy Entropy: 3.65355
Value Function Loss: 0.06792

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.45778
Value Function Update Magnitude: 0.77029

Collected Steps per Second: 23,127.72142
Overall Steps per Second: 10,978.03535

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.39322
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.55564

Cumulative Model Updates: 112,276
Cumulative Timesteps: 936,305,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 936305024...
Checkpoint 936305024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.36794
Policy Entropy: 3.65720
Value Function Loss: 0.06672

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.45997
Value Function Update Magnitude: 0.77524

Collected Steps per Second: 22,369.78144
Overall Steps per Second: 10,598.95858

Timestep Collection Time: 2.23543
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.71801

Cumulative Model Updates: 112,282
Cumulative Timesteps: 936,355,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,282.57084
Policy Entropy: 3.66266
Value Function Loss: 0.06792

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.52819
Value Function Update Magnitude: 0.67918

Collected Steps per Second: 22,392.51483
Overall Steps per Second: 10,579.29362

Timestep Collection Time: 2.23405
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.72867

Cumulative Model Updates: 112,288
Cumulative Timesteps: 936,405,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 936405056...
Checkpoint 936405056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.01685
Policy Entropy: 3.65966
Value Function Loss: 0.07035

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.65510

Collected Steps per Second: 22,403.94279
Overall Steps per Second: 10,570.15334

Timestep Collection Time: 2.23362
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.73427

Cumulative Model Updates: 112,294
Cumulative Timesteps: 936,455,098

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.04638
Policy Entropy: 3.64693
Value Function Loss: 0.07580

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.60246
Value Function Update Magnitude: 0.73244

Collected Steps per Second: 21,872.77360
Overall Steps per Second: 10,387.81861

Timestep Collection Time: 2.28704
Timestep Consumption Time: 2.52860
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.81564

Cumulative Model Updates: 112,300
Cumulative Timesteps: 936,505,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 936505122...
Checkpoint 936505122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,598.46590
Policy Entropy: 3.65600
Value Function Loss: 0.07702

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.56629
Value Function Update Magnitude: 0.76703

Collected Steps per Second: 22,013.08035
Overall Steps per Second: 10,710.12430

Timestep Collection Time: 2.27138
Timestep Consumption Time: 2.39710
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.66848

Cumulative Model Updates: 112,306
Cumulative Timesteps: 936,555,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,926.69372
Policy Entropy: 3.64165
Value Function Loss: 0.07576

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.51112
Value Function Update Magnitude: 0.73624

Collected Steps per Second: 23,058.96661
Overall Steps per Second: 10,779.61802

Timestep Collection Time: 2.16913
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.64005

Cumulative Model Updates: 112,312
Cumulative Timesteps: 936,605,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 936605140...
Checkpoint 936605140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,310.70354
Policy Entropy: 3.64963
Value Function Loss: 0.07584

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.64056
Value Function Update Magnitude: 0.75083

Collected Steps per Second: 22,510.11100
Overall Steps per Second: 10,675.73773

Timestep Collection Time: 2.22149
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.68408

Cumulative Model Updates: 112,318
Cumulative Timesteps: 936,655,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,885.43774
Policy Entropy: 3.64255
Value Function Loss: 0.07680

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.76607
Value Function Update Magnitude: 0.81211

Collected Steps per Second: 22,850.72503
Overall Steps per Second: 10,849.78987

Timestep Collection Time: 2.18890
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61004

Cumulative Model Updates: 112,324
Cumulative Timesteps: 936,705,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 936705164...
Checkpoint 936705164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,852.88762
Policy Entropy: 3.63962
Value Function Loss: 0.08108

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.72668
Value Function Update Magnitude: 0.74413

Collected Steps per Second: 22,083.56355
Overall Steps per Second: 10,640.33166

Timestep Collection Time: 2.26449
Timestep Consumption Time: 2.43536
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.69985

Cumulative Model Updates: 112,330
Cumulative Timesteps: 936,755,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,863.77189
Policy Entropy: 3.62725
Value Function Loss: 0.08369

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.56217
Value Function Update Magnitude: 0.71513

Collected Steps per Second: 22,854.74982
Overall Steps per Second: 10,654.37963

Timestep Collection Time: 2.18825
Timestep Consumption Time: 2.50578
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.69403

Cumulative Model Updates: 112,336
Cumulative Timesteps: 936,805,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 936805184...
Checkpoint 936805184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,068.84012
Policy Entropy: 3.62117
Value Function Loss: 0.08536

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.58028
Value Function Update Magnitude: 0.66818

Collected Steps per Second: 22,641.59997
Overall Steps per Second: 10,606.87515

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.50650
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.71562

Cumulative Model Updates: 112,342
Cumulative Timesteps: 936,855,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,351.32373
Policy Entropy: 3.62253
Value Function Loss: 0.08695

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.55928
Value Function Update Magnitude: 0.62833

Collected Steps per Second: 22,303.99591
Overall Steps per Second: 10,586.17791

Timestep Collection Time: 2.24256
Timestep Consumption Time: 2.48228
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.72484

Cumulative Model Updates: 112,348
Cumulative Timesteps: 936,905,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 936905220...
Checkpoint 936905220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,733.92358
Policy Entropy: 3.61357
Value Function Loss: 0.09156

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.55839
Value Function Update Magnitude: 0.59980

Collected Steps per Second: 22,495.96764
Overall Steps per Second: 10,625.42704

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.70758

Cumulative Model Updates: 112,354
Cumulative Timesteps: 936,955,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,381.36487
Policy Entropy: 3.62073
Value Function Loss: 0.09472

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.52977
Value Function Update Magnitude: 0.61262

Collected Steps per Second: 22,958.85872
Overall Steps per Second: 10,701.65347

Timestep Collection Time: 2.17851
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.67367

Cumulative Model Updates: 112,360
Cumulative Timesteps: 937,005,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 937005256...
Checkpoint 937005256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,039.15753
Policy Entropy: 3.61900
Value Function Loss: 0.09434

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.49025
Value Function Update Magnitude: 0.69098

Collected Steps per Second: 22,425.32067
Overall Steps per Second: 10,694.77643

Timestep Collection Time: 2.23034
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.67668

Cumulative Model Updates: 112,366
Cumulative Timesteps: 937,055,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,560.84871
Policy Entropy: 3.62264
Value Function Loss: 0.09332

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.67123

Collected Steps per Second: 23,285.44739
Overall Steps per Second: 10,844.04203

Timestep Collection Time: 2.14795
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.61230

Cumulative Model Updates: 112,372
Cumulative Timesteps: 937,105,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 937105288...
Checkpoint 937105288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.01928
Policy Entropy: 3.62213
Value Function Loss: 0.09333

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.62131
Value Function Update Magnitude: 0.64977

Collected Steps per Second: 22,509.01671
Overall Steps per Second: 10,660.13242

Timestep Collection Time: 2.22160
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.69094

Cumulative Model Updates: 112,378
Cumulative Timesteps: 937,155,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,270.96259
Policy Entropy: 3.61025
Value Function Loss: 0.09070

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.64049
Value Function Update Magnitude: 0.62708

Collected Steps per Second: 23,037.22349
Overall Steps per Second: 10,837.34548

Timestep Collection Time: 2.17127
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.61552

Cumulative Model Updates: 112,384
Cumulative Timesteps: 937,205,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 937205314...
Checkpoint 937205314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,885.48125
Policy Entropy: 3.61224
Value Function Loss: 0.09057

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.52565
Value Function Update Magnitude: 0.67561

Collected Steps per Second: 22,907.48753
Overall Steps per Second: 10,690.63503

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.49500
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.67830

Cumulative Model Updates: 112,390
Cumulative Timesteps: 937,255,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,600.16409
Policy Entropy: 3.60294
Value Function Loss: 0.08935

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.59276
Value Function Update Magnitude: 0.71452

Collected Steps per Second: 22,704.58362
Overall Steps per Second: 10,675.63807

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.48136
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68356

Cumulative Model Updates: 112,396
Cumulative Timesteps: 937,305,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 937305328...
Checkpoint 937305328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,861.41992
Policy Entropy: 3.60832
Value Function Loss: 0.08736

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.54826
Value Function Update Magnitude: 0.77093

Collected Steps per Second: 22,545.22634
Overall Steps per Second: 10,626.33765

Timestep Collection Time: 2.21874
Timestep Consumption Time: 2.48862
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.70736

Cumulative Model Updates: 112,402
Cumulative Timesteps: 937,355,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,432.16237
Policy Entropy: 3.60218
Value Function Loss: 0.08931

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.52827
Value Function Update Magnitude: 0.83721

Collected Steps per Second: 22,811.17031
Overall Steps per Second: 10,707.53258

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.47889
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.67185

Cumulative Model Updates: 112,408
Cumulative Timesteps: 937,405,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 937405374...
Checkpoint 937405374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,902.70731
Policy Entropy: 3.59972
Value Function Loss: 0.09348

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.55411
Value Function Update Magnitude: 0.73254

Collected Steps per Second: 22,175.60899
Overall Steps per Second: 10,619.53007

Timestep Collection Time: 2.25482
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.70849

Cumulative Model Updates: 112,414
Cumulative Timesteps: 937,455,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,701.75433
Policy Entropy: 3.59578
Value Function Loss: 0.09537

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.62148
Value Function Update Magnitude: 0.69662

Collected Steps per Second: 22,509.89315
Overall Steps per Second: 10,562.27277

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.73402

Cumulative Model Updates: 112,420
Cumulative Timesteps: 937,505,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 937505378...
Checkpoint 937505378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,726.75572
Policy Entropy: 3.60507
Value Function Loss: 0.09134

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.62910
Value Function Update Magnitude: 0.79153

Collected Steps per Second: 22,258.35198
Overall Steps per Second: 10,567.85078

Timestep Collection Time: 2.24635
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.73133

Cumulative Model Updates: 112,426
Cumulative Timesteps: 937,555,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.55481
Policy Entropy: 3.58861
Value Function Loss: 0.09007

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.57717
Value Function Update Magnitude: 0.84242

Collected Steps per Second: 22,968.86552
Overall Steps per Second: 10,612.10809

Timestep Collection Time: 2.17686
Timestep Consumption Time: 2.53474
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.71160

Cumulative Model Updates: 112,432
Cumulative Timesteps: 937,605,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 937605378...
Checkpoint 937605378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,250.60691
Policy Entropy: 3.58601
Value Function Loss: 0.09314

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.52178
Value Function Update Magnitude: 0.90525

Collected Steps per Second: 22,905.41546
Overall Steps per Second: 10,665.14078

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.50658
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.69061

Cumulative Model Updates: 112,438
Cumulative Timesteps: 937,655,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,908.20519
Policy Entropy: 3.57284
Value Function Loss: 0.09300

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.90640

Collected Steps per Second: 22,943.75980
Overall Steps per Second: 10,715.42288

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.66729

Cumulative Model Updates: 112,444
Cumulative Timesteps: 937,705,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 937705416...
Checkpoint 937705416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,430.49069
Policy Entropy: 3.57327
Value Function Loss: 0.09300

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.64744
Value Function Update Magnitude: 0.83638

Collected Steps per Second: 22,269.55270
Overall Steps per Second: 10,684.74639

Timestep Collection Time: 2.24549
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.68013

Cumulative Model Updates: 112,450
Cumulative Timesteps: 937,755,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,013.87042
Policy Entropy: 3.56208
Value Function Loss: 0.09511

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.17657
Policy Update Magnitude: 0.59256
Value Function Update Magnitude: 0.84877

Collected Steps per Second: 22,968.83039
Overall Steps per Second: 10,810.14515

Timestep Collection Time: 2.17765
Timestep Consumption Time: 2.44930
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.62695

Cumulative Model Updates: 112,456
Cumulative Timesteps: 937,805,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 937805440...
Checkpoint 937805440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,944.15174
Policy Entropy: 3.57090
Value Function Loss: 0.09363

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.42824
Value Function Update Magnitude: 0.84647

Collected Steps per Second: 22,831.00646
Overall Steps per Second: 10,619.52043

Timestep Collection Time: 2.19070
Timestep Consumption Time: 2.51911
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.70982

Cumulative Model Updates: 112,462
Cumulative Timesteps: 937,855,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,102.97216
Policy Entropy: 3.57857
Value Function Loss: 0.09544

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.46276
Value Function Update Magnitude: 0.81064

Collected Steps per Second: 23,076.34833
Overall Steps per Second: 10,754.92853

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.48400
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.65219

Cumulative Model Updates: 112,468
Cumulative Timesteps: 937,905,490

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 937905490...
Checkpoint 937905490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,433.51671
Policy Entropy: 3.57541
Value Function Loss: 0.09301

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.75445

Collected Steps per Second: 22,128.72493
Overall Steps per Second: 10,553.49616

Timestep Collection Time: 2.25996
Timestep Consumption Time: 2.47876
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.73871

Cumulative Model Updates: 112,474
Cumulative Timesteps: 937,955,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,606.08749
Policy Entropy: 3.55984
Value Function Loss: 0.09639

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.68014
Value Function Update Magnitude: 0.70907

Collected Steps per Second: 22,291.51539
Overall Steps per Second: 10,686.77366

Timestep Collection Time: 2.24444
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.68167

Cumulative Model Updates: 112,480
Cumulative Timesteps: 938,005,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 938005532...
Checkpoint 938005532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,840.60782
Policy Entropy: 3.56371
Value Function Loss: 0.09274

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.17295
Policy Update Magnitude: 0.60828
Value Function Update Magnitude: 0.73278

Collected Steps per Second: 22,204.95121
Overall Steps per Second: 10,667.19065

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.43601
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68821

Cumulative Model Updates: 112,486
Cumulative Timesteps: 938,055,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.79786
Policy Entropy: 3.57813
Value Function Loss: 0.09196

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.67553

Collected Steps per Second: 22,245.14087
Overall Steps per Second: 10,501.08129

Timestep Collection Time: 2.24795
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.76199

Cumulative Model Updates: 112,492
Cumulative Timesteps: 938,105,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 938105548...
Checkpoint 938105548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.13590
Policy Entropy: 3.58670
Value Function Loss: 0.09013

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.66285
Value Function Update Magnitude: 0.65491

Collected Steps per Second: 22,361.30242
Overall Steps per Second: 10,707.35490

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.67380

Cumulative Model Updates: 112,498
Cumulative Timesteps: 938,155,592

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,959.91413
Policy Entropy: 3.59311
Value Function Loss: 0.08852

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.64711
Value Function Update Magnitude: 0.79133

Collected Steps per Second: 22,264.91323
Overall Steps per Second: 10,806.34342

Timestep Collection Time: 2.24757
Timestep Consumption Time: 2.38323
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.63080

Cumulative Model Updates: 112,504
Cumulative Timesteps: 938,205,634

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 938205634...
Checkpoint 938205634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,179.02643
Policy Entropy: 3.59473
Value Function Loss: 0.08722

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.59825
Value Function Update Magnitude: 0.71614

Collected Steps per Second: 21,652.80636
Overall Steps per Second: 10,708.71922

Timestep Collection Time: 2.31056
Timestep Consumption Time: 2.36134
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.67189

Cumulative Model Updates: 112,510
Cumulative Timesteps: 938,255,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,587.88501
Policy Entropy: 3.61272
Value Function Loss: 0.08560

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.60781
Value Function Update Magnitude: 0.69999

Collected Steps per Second: 22,489.89629
Overall Steps per Second: 10,869.45328

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.37825
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.60281

Cumulative Model Updates: 112,516
Cumulative Timesteps: 938,305,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 938305694...
Checkpoint 938305694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,634.84394
Policy Entropy: 3.60546
Value Function Loss: 0.08973

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.79029

Collected Steps per Second: 21,762.27041
Overall Steps per Second: 10,675.77671

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.38623
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.68406

Cumulative Model Updates: 112,522
Cumulative Timesteps: 938,355,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,573.71156
Policy Entropy: 3.61471
Value Function Loss: 0.09056

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.80337

Collected Steps per Second: 22,413.06834
Overall Steps per Second: 10,885.68509

Timestep Collection Time: 2.23093
Timestep Consumption Time: 2.36244
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.59337

Cumulative Model Updates: 112,528
Cumulative Timesteps: 938,405,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 938405702...
Checkpoint 938405702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.36898
Policy Entropy: 3.61608
Value Function Loss: 0.09090

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.46560
Value Function Update Magnitude: 0.86095

Collected Steps per Second: 20,148.46620
Overall Steps per Second: 10,170.93699

Timestep Collection Time: 2.48178
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.91636

Cumulative Model Updates: 112,534
Cumulative Timesteps: 938,455,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,463.75741
Policy Entropy: 3.62082
Value Function Loss: 0.08681

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.92443

Collected Steps per Second: 22,441.09571
Overall Steps per Second: 10,604.05332

Timestep Collection Time: 2.22806
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.71518

Cumulative Model Updates: 112,540
Cumulative Timesteps: 938,505,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 938505706...
Checkpoint 938505706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,765.31198
Policy Entropy: 3.62004
Value Function Loss: 0.08625

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.47531
Value Function Update Magnitude: 0.87110

Collected Steps per Second: 22,096.60420
Overall Steps per Second: 10,557.52078

Timestep Collection Time: 2.26333
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.73710

Cumulative Model Updates: 112,546
Cumulative Timesteps: 938,555,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,168.65672
Policy Entropy: 3.61050
Value Function Loss: 0.08300

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.51498
Value Function Update Magnitude: 0.82566

Collected Steps per Second: 22,956.35863
Overall Steps per Second: 10,833.50944

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.61549

Cumulative Model Updates: 112,552
Cumulative Timesteps: 938,605,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 938605720...
Checkpoint 938605720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777.32068
Policy Entropy: 3.61281
Value Function Loss: 0.08365

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.49334
Value Function Update Magnitude: 0.81495

Collected Steps per Second: 22,608.27779
Overall Steps per Second: 10,644.72091

Timestep Collection Time: 2.21167
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.69735

Cumulative Model Updates: 112,558
Cumulative Timesteps: 938,655,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,611.34611
Policy Entropy: 3.60851
Value Function Loss: 0.07792

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12321
Policy Update Magnitude: 0.46479
Value Function Update Magnitude: 0.77800

Collected Steps per Second: 22,977.00687
Overall Steps per Second: 10,706.73255

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.67089

Cumulative Model Updates: 112,564
Cumulative Timesteps: 938,705,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 938705732...
Checkpoint 938705732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,085.12527
Policy Entropy: 3.61706
Value Function Loss: 0.07785

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.50345
Value Function Update Magnitude: 0.76057

Collected Steps per Second: 22,518.74326
Overall Steps per Second: 10,637.59689

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.48143
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.70313

Cumulative Model Updates: 112,570
Cumulative Timesteps: 938,755,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,496.58097
Policy Entropy: 3.62435
Value Function Loss: 0.07430

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.76557

Collected Steps per Second: 23,090.89981
Overall Steps per Second: 10,749.62913

Timestep Collection Time: 2.16657
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.65393

Cumulative Model Updates: 112,576
Cumulative Timesteps: 938,805,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 938805790...
Checkpoint 938805790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,856.66787
Policy Entropy: 3.63044
Value Function Loss: 0.07650

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.70582
Value Function Update Magnitude: 0.76997

Collected Steps per Second: 22,605.96898
Overall Steps per Second: 10,602.63316

Timestep Collection Time: 2.21216
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.71656

Cumulative Model Updates: 112,582
Cumulative Timesteps: 938,855,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,114.72003
Policy Entropy: 3.63139
Value Function Loss: 0.07186

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.60838
Value Function Update Magnitude: 0.82469

Collected Steps per Second: 22,574.39510
Overall Steps per Second: 10,640.45859

Timestep Collection Time: 2.21649
Timestep Consumption Time: 2.48594
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.70243

Cumulative Model Updates: 112,588
Cumulative Timesteps: 938,905,834

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 938905834...
Checkpoint 938905834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,129.36362
Policy Entropy: 3.63402
Value Function Loss: 0.07092

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.51586
Value Function Update Magnitude: 0.84933

Collected Steps per Second: 22,149.07485
Overall Steps per Second: 10,489.31671

Timestep Collection Time: 2.25842
Timestep Consumption Time: 2.51043
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.76885

Cumulative Model Updates: 112,594
Cumulative Timesteps: 938,955,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,076.79809
Policy Entropy: 3.63789
Value Function Loss: 0.07029

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.50370
Value Function Update Magnitude: 0.81615

Collected Steps per Second: 22,506.77055
Overall Steps per Second: 10,588.62392

Timestep Collection Time: 2.22209
Timestep Consumption Time: 2.50110
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.72318

Cumulative Model Updates: 112,600
Cumulative Timesteps: 939,005,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 939005868...
Checkpoint 939005868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,628.20025
Policy Entropy: 3.63202
Value Function Loss: 0.07399

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.59226
Value Function Update Magnitude: 0.73551

Collected Steps per Second: 22,350.09233
Overall Steps per Second: 10,492.88365

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.52952
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.76799

Cumulative Model Updates: 112,606
Cumulative Timesteps: 939,055,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,292.84408
Policy Entropy: 3.64091
Value Function Loss: 0.07723

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.58725
Value Function Update Magnitude: 0.71320

Collected Steps per Second: 22,776.97676
Overall Steps per Second: 10,579.82798

Timestep Collection Time: 2.19687
Timestep Consumption Time: 2.53270
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.72957

Cumulative Model Updates: 112,612
Cumulative Timesteps: 939,105,936

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 939105936...
Checkpoint 939105936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.84643
Policy Entropy: 3.62468
Value Function Loss: 0.08131

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.61738
Value Function Update Magnitude: 0.71366

Collected Steps per Second: 22,798.80081
Overall Steps per Second: 10,868.91744

Timestep Collection Time: 2.19345
Timestep Consumption Time: 2.40756
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.60101

Cumulative Model Updates: 112,618
Cumulative Timesteps: 939,155,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.10767
Policy Entropy: 3.62431
Value Function Loss: 0.08416

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.65851
Value Function Update Magnitude: 0.66737

Collected Steps per Second: 23,081.81604
Overall Steps per Second: 10,729.57576

Timestep Collection Time: 2.16716
Timestep Consumption Time: 2.49491
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66207

Cumulative Model Updates: 112,624
Cumulative Timesteps: 939,205,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 939205966...
Checkpoint 939205966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.48405
Policy Entropy: 3.62399
Value Function Loss: 0.08553

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.58216
Value Function Update Magnitude: 0.62737

Collected Steps per Second: 22,703.90315
Overall Steps per Second: 10,796.34773

Timestep Collection Time: 2.20323
Timestep Consumption Time: 2.43000
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.63323

Cumulative Model Updates: 112,630
Cumulative Timesteps: 939,255,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,781.46918
Policy Entropy: 3.63880
Value Function Loss: 0.08373

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.69866

Collected Steps per Second: 22,878.37262
Overall Steps per Second: 10,670.45750

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.68752

Cumulative Model Updates: 112,636
Cumulative Timesteps: 939,306,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 939306006...
Checkpoint 939306006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,224.11256
Policy Entropy: 3.62863
Value Function Loss: 0.08068

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.68843
Value Function Update Magnitude: 0.77434

Collected Steps per Second: 22,799.24291
Overall Steps per Second: 10,686.25223

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.48685
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68078

Cumulative Model Updates: 112,642
Cumulative Timesteps: 939,356,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,615.57471
Policy Entropy: 3.64103
Value Function Loss: 0.08305

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.77642
Value Function Update Magnitude: 0.72985

Collected Steps per Second: 22,703.88798
Overall Steps per Second: 10,723.92842

Timestep Collection Time: 2.20297
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.66396

Cumulative Model Updates: 112,648
Cumulative Timesteps: 939,406,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 939406042...
Checkpoint 939406042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220.61734
Policy Entropy: 3.63748
Value Function Loss: 0.08462

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.75051
Value Function Update Magnitude: 0.77662

Collected Steps per Second: 22,018.58197
Overall Steps per Second: 10,606.17711

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.44352
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.71442

Cumulative Model Updates: 112,654
Cumulative Timesteps: 939,456,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,506.59816
Policy Entropy: 3.65029
Value Function Loss: 0.08553

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.72071
Value Function Update Magnitude: 0.77652

Collected Steps per Second: 22,524.70385
Overall Steps per Second: 10,569.60440

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.73301

Cumulative Model Updates: 112,660
Cumulative Timesteps: 939,506,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 939506070...
Checkpoint 939506070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,907.25637
Policy Entropy: 3.62314
Value Function Loss: 0.09161

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.76675
Value Function Update Magnitude: 0.73540

Collected Steps per Second: 22,389.49246
Overall Steps per Second: 10,585.50528

Timestep Collection Time: 2.23346
Timestep Consumption Time: 2.49055
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.72401

Cumulative Model Updates: 112,666
Cumulative Timesteps: 939,556,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.80825
Policy Entropy: 3.62706
Value Function Loss: 0.09392

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.79642
Value Function Update Magnitude: 0.67961

Collected Steps per Second: 23,145.81316
Overall Steps per Second: 10,867.83563

Timestep Collection Time: 2.16117
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60276

Cumulative Model Updates: 112,672
Cumulative Timesteps: 939,606,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 939606098...
Checkpoint 939606098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,500.17046
Policy Entropy: 3.62159
Value Function Loss: 0.09615

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.69944
Value Function Update Magnitude: 0.63806

Collected Steps per Second: 22,708.06478
Overall Steps per Second: 10,660.02156

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.48896
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.69117

Cumulative Model Updates: 112,678
Cumulative Timesteps: 939,656,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,123.93322
Policy Entropy: 3.63624
Value Function Loss: 0.09346

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.65972
Value Function Update Magnitude: 0.69319

Collected Steps per Second: 22,649.57369
Overall Steps per Second: 10,831.29367

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.41034
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61939

Cumulative Model Updates: 112,684
Cumulative Timesteps: 939,706,140

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 939706140...
Checkpoint 939706140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,855.53555
Policy Entropy: 3.63152
Value Function Loss: 0.09682

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.59782
Value Function Update Magnitude: 0.65347

Collected Steps per Second: 22,418.25306
Overall Steps per Second: 10,807.27211

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.39667
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.62744

Cumulative Model Updates: 112,690
Cumulative Timesteps: 939,756,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,946.02417
Policy Entropy: 3.64178
Value Function Loss: 0.09484

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.52953
Value Function Update Magnitude: 0.71336

Collected Steps per Second: 22,918.82308
Overall Steps per Second: 10,795.28200

Timestep Collection Time: 2.18283
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.63425

Cumulative Model Updates: 112,696
Cumulative Timesteps: 939,806,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 939806178...
Checkpoint 939806178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,269.46982
Policy Entropy: 3.62215
Value Function Loss: 0.09522

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.64668

Collected Steps per Second: 22,592.74595
Overall Steps per Second: 10,759.60293

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.64831

Cumulative Model Updates: 112,702
Cumulative Timesteps: 939,856,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.37823
Policy Entropy: 3.64159
Value Function Loss: 0.09163

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.17599
Policy Update Magnitude: 0.49510
Value Function Update Magnitude: 0.61463

Collected Steps per Second: 21,959.08448
Overall Steps per Second: 10,397.37580

Timestep Collection Time: 2.27805
Timestep Consumption Time: 2.53316
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.81121

Cumulative Model Updates: 112,708
Cumulative Timesteps: 939,906,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 939906216...
Checkpoint 939906216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,890.52812
Policy Entropy: 3.62492
Value Function Loss: 0.08717

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.49599
Value Function Update Magnitude: 0.66985

Collected Steps per Second: 22,245.81402
Overall Steps per Second: 10,718.37109

Timestep Collection Time: 2.24833
Timestep Consumption Time: 2.41805
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.66638

Cumulative Model Updates: 112,714
Cumulative Timesteps: 939,956,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,459.20796
Policy Entropy: 3.62699
Value Function Loss: 0.08335

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.54860
Value Function Update Magnitude: 0.70873

Collected Steps per Second: 22,180.38268
Overall Steps per Second: 10,472.89793

Timestep Collection Time: 2.25587
Timestep Consumption Time: 2.52180
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.77767

Cumulative Model Updates: 112,720
Cumulative Timesteps: 940,006,268

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 940006268...
Checkpoint 940006268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,656.74942
Policy Entropy: 3.62178
Value Function Loss: 0.08132

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.61532
Value Function Update Magnitude: 0.66668

Collected Steps per Second: 22,339.23642
Overall Steps per Second: 10,548.97227

Timestep Collection Time: 2.23956
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.74264

Cumulative Model Updates: 112,726
Cumulative Timesteps: 940,056,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,619.94244
Policy Entropy: 3.62615
Value Function Loss: 0.07869

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.49442
Value Function Update Magnitude: 0.62696

Collected Steps per Second: 22,442.40717
Overall Steps per Second: 10,533.56088

Timestep Collection Time: 2.22792
Timestep Consumption Time: 2.51881
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.74673

Cumulative Model Updates: 112,732
Cumulative Timesteps: 940,106,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 940106298...
Checkpoint 940106298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,088.64266
Policy Entropy: 3.61251
Value Function Loss: 0.07748

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.49289
Value Function Update Magnitude: 0.67111

Collected Steps per Second: 22,570.43323
Overall Steps per Second: 10,582.96539

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.72684

Cumulative Model Updates: 112,738
Cumulative Timesteps: 940,156,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.44285
Policy Entropy: 3.60881
Value Function Loss: 0.07724

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.48984
Value Function Update Magnitude: 0.73957

Collected Steps per Second: 23,151.69031
Overall Steps per Second: 10,861.35584

Timestep Collection Time: 2.16114
Timestep Consumption Time: 2.44547
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.60661

Cumulative Model Updates: 112,744
Cumulative Timesteps: 940,206,356

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 940206356...
Checkpoint 940206356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,611.62328
Policy Entropy: 3.61313
Value Function Loss: 0.07913

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.52182
Value Function Update Magnitude: 0.59464

Collected Steps per Second: 22,841.91944
Overall Steps per Second: 10,633.12429

Timestep Collection Time: 2.18896
Timestep Consumption Time: 2.51333
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.70229

Cumulative Model Updates: 112,750
Cumulative Timesteps: 940,256,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,504.54099
Policy Entropy: 3.62560
Value Function Loss: 0.07719

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.47412
Value Function Update Magnitude: 0.52066

Collected Steps per Second: 22,830.57593
Overall Steps per Second: 10,882.13568

Timestep Collection Time: 2.19022
Timestep Consumption Time: 2.40483
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.59505

Cumulative Model Updates: 112,756
Cumulative Timesteps: 940,306,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 940306360...
Checkpoint 940306360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,001.20926
Policy Entropy: 3.63577
Value Function Loss: 0.07518

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.51084
Value Function Update Magnitude: 0.53954

Collected Steps per Second: 21,142.79308
Overall Steps per Second: 10,241.55338

Timestep Collection Time: 2.36544
Timestep Consumption Time: 2.51780
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.88324

Cumulative Model Updates: 112,762
Cumulative Timesteps: 940,356,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.85301
Policy Entropy: 3.64495
Value Function Loss: 0.07469

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.57780
Value Function Update Magnitude: 0.61958

Collected Steps per Second: 22,662.78424
Overall Steps per Second: 10,636.23198

Timestep Collection Time: 2.20653
Timestep Consumption Time: 2.49495
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.70148

Cumulative Model Updates: 112,768
Cumulative Timesteps: 940,406,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 940406378...
Checkpoint 940406378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,474.39230
Policy Entropy: 3.64114
Value Function Loss: 0.07588

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.59205
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 22,752.29752
Overall Steps per Second: 10,686.76216

Timestep Collection Time: 2.19855
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.68074

Cumulative Model Updates: 112,774
Cumulative Timesteps: 940,456,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,897.73974
Policy Entropy: 3.63279
Value Function Loss: 0.07541

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.60124
Value Function Update Magnitude: 0.62570

Collected Steps per Second: 22,632.99977
Overall Steps per Second: 10,757.84178

Timestep Collection Time: 2.20925
Timestep Consumption Time: 2.43871
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.64796

Cumulative Model Updates: 112,780
Cumulative Timesteps: 940,506,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 940506402...
Checkpoint 940506402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.31167
Policy Entropy: 3.62420
Value Function Loss: 0.07711

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.53161
Value Function Update Magnitude: 0.59725

Collected Steps per Second: 21,934.97626
Overall Steps per Second: 10,653.95042

Timestep Collection Time: 2.28038
Timestep Consumption Time: 2.41460
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.69497

Cumulative Model Updates: 112,786
Cumulative Timesteps: 940,556,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,261.27164
Policy Entropy: 3.62781
Value Function Loss: 0.07736

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.52478
Value Function Update Magnitude: 0.66316

Collected Steps per Second: 22,582.19978
Overall Steps per Second: 10,748.63296

Timestep Collection Time: 2.21484
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.65324

Cumulative Model Updates: 112,792
Cumulative Timesteps: 940,606,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 940606438...
Checkpoint 940606438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.09408
Policy Entropy: 3.62613
Value Function Loss: 0.08053

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.51358
Value Function Update Magnitude: 0.66660

Collected Steps per Second: 22,048.26359
Overall Steps per Second: 10,624.44459

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.43955
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.70839

Cumulative Model Updates: 112,798
Cumulative Timesteps: 940,656,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,304.52989
Policy Entropy: 3.62512
Value Function Loss: 0.08244

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.49659
Value Function Update Magnitude: 0.71002

Collected Steps per Second: 22,933.88163
Overall Steps per Second: 10,594.87853

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.54142
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.72360

Cumulative Model Updates: 112,804
Cumulative Timesteps: 940,706,508

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 940706508...
Checkpoint 940706508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,380.40587
Policy Entropy: 3.63470
Value Function Loss: 0.08452

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.51566
Value Function Update Magnitude: 0.74306

Collected Steps per Second: 22,842.24963
Overall Steps per Second: 10,632.50929

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.51424
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.70369

Cumulative Model Updates: 112,810
Cumulative Timesteps: 940,756,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,574.13976
Policy Entropy: 3.63361
Value Function Loss: 0.08987

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.51048
Value Function Update Magnitude: 0.71572

Collected Steps per Second: 22,899.49273
Overall Steps per Second: 10,812.68263

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62623

Cumulative Model Updates: 112,816
Cumulative Timesteps: 940,806,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 940806542...
Checkpoint 940806542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,241.98566
Policy Entropy: 3.62893
Value Function Loss: 0.08914

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.15623
Policy Update Magnitude: 0.47796
Value Function Update Magnitude: 0.68696

Collected Steps per Second: 22,350.14007
Overall Steps per Second: 10,680.09908

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.68217

Cumulative Model Updates: 112,822
Cumulative Timesteps: 940,856,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,497.57121
Policy Entropy: 3.61645
Value Function Loss: 0.09010

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.42987
Value Function Update Magnitude: 0.68513

Collected Steps per Second: 22,833.15309
Overall Steps per Second: 10,698.18780

Timestep Collection Time: 2.18989
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67388

Cumulative Model Updates: 112,828
Cumulative Timesteps: 940,906,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 940906550...
Checkpoint 940906550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,141.21130
Policy Entropy: 3.62062
Value Function Loss: 0.08897

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.55690
Value Function Update Magnitude: 0.68044

Collected Steps per Second: 22,578.41815
Overall Steps per Second: 10,790.35418

Timestep Collection Time: 2.21504
Timestep Consumption Time: 2.41984
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.63488

Cumulative Model Updates: 112,834
Cumulative Timesteps: 940,956,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,314.68326
Policy Entropy: 3.63048
Value Function Loss: 0.09058

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.58317
Value Function Update Magnitude: 0.65132

Collected Steps per Second: 22,742.06954
Overall Steps per Second: 10,606.20863

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.51636
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71554

Cumulative Model Updates: 112,840
Cumulative Timesteps: 941,006,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 941006576...
Checkpoint 941006576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,786.91176
Policy Entropy: 3.63726
Value Function Loss: 0.09058

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.64627

Collected Steps per Second: 22,278.16664
Overall Steps per Second: 10,545.10122

Timestep Collection Time: 2.24453
Timestep Consumption Time: 2.49739
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.74192

Cumulative Model Updates: 112,846
Cumulative Timesteps: 941,056,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,814.04478
Policy Entropy: 3.62985
Value Function Loss: 0.09186

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.51322
Value Function Update Magnitude: 0.68805

Collected Steps per Second: 22,520.00069
Overall Steps per Second: 10,593.18623

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.72002

Cumulative Model Updates: 112,852
Cumulative Timesteps: 941,106,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 941106580...
Checkpoint 941106580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,819.58148
Policy Entropy: 3.61765
Value Function Loss: 0.09025

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.51391
Value Function Update Magnitude: 0.63544

Collected Steps per Second: 22,069.09233
Overall Steps per Second: 10,521.08101

Timestep Collection Time: 2.26679
Timestep Consumption Time: 2.48804
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.75483

Cumulative Model Updates: 112,858
Cumulative Timesteps: 941,156,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,120.29457
Policy Entropy: 3.61810
Value Function Loss: 0.08997

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.17304
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.64791

Collected Steps per Second: 22,005.81320
Overall Steps per Second: 10,468.82708

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.50526
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.77857

Cumulative Model Updates: 112,864
Cumulative Timesteps: 941,206,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 941206632...
Checkpoint 941206632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,259.88276
Policy Entropy: 3.62443
Value Function Loss: 0.08498

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.46758
Value Function Update Magnitude: 0.76997

Collected Steps per Second: 22,479.78278
Overall Steps per Second: 10,597.15828

Timestep Collection Time: 2.22502
Timestep Consumption Time: 2.49492
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.71994

Cumulative Model Updates: 112,870
Cumulative Timesteps: 941,256,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,520.50222
Policy Entropy: 3.61222
Value Function Loss: 0.08526

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.57521
Value Function Update Magnitude: 0.81101

Collected Steps per Second: 22,463.05392
Overall Steps per Second: 10,539.38266

Timestep Collection Time: 2.22659
Timestep Consumption Time: 2.51904
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74563

Cumulative Model Updates: 112,876
Cumulative Timesteps: 941,306,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 941306666...
Checkpoint 941306666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,626.03070
Policy Entropy: 3.60907
Value Function Loss: 0.08717

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.73600

Collected Steps per Second: 22,610.30481
Overall Steps per Second: 10,582.94009

Timestep Collection Time: 2.21191
Timestep Consumption Time: 2.51381
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.72572

Cumulative Model Updates: 112,882
Cumulative Timesteps: 941,356,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,941.46248
Policy Entropy: 3.60667
Value Function Loss: 0.08704

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.49762
Value Function Update Magnitude: 0.75892

Collected Steps per Second: 22,818.47327
Overall Steps per Second: 10,684.14288

Timestep Collection Time: 2.19235
Timestep Consumption Time: 2.48992
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.68227

Cumulative Model Updates: 112,888
Cumulative Timesteps: 941,406,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 941406704...
Checkpoint 941406704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,689.33659
Policy Entropy: 3.60014
Value Function Loss: 0.09065

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.49327
Value Function Update Magnitude: 0.74260

Collected Steps per Second: 22,910.88760
Overall Steps per Second: 10,842.66570

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.42953
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61233

Cumulative Model Updates: 112,894
Cumulative Timesteps: 941,456,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,338.33969
Policy Entropy: 3.59789
Value Function Loss: 0.09338

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.51920
Value Function Update Magnitude: 0.60413

Collected Steps per Second: 22,732.25502
Overall Steps per Second: 10,645.36679

Timestep Collection Time: 2.19961
Timestep Consumption Time: 2.49746
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.69707

Cumulative Model Updates: 112,900
Cumulative Timesteps: 941,506,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 941506716...
Checkpoint 941506716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,903.36884
Policy Entropy: 3.60193
Value Function Loss: 0.09694

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.52894
Value Function Update Magnitude: 0.54889

Collected Steps per Second: 22,244.20685
Overall Steps per Second: 10,517.75348

Timestep Collection Time: 2.24895
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75634

Cumulative Model Updates: 112,906
Cumulative Timesteps: 941,556,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,347.93454
Policy Entropy: 3.62132
Value Function Loss: 0.09483

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.67520
Value Function Update Magnitude: 0.54424

Collected Steps per Second: 22,472.27967
Overall Steps per Second: 10,556.57246

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.51213
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.73771

Cumulative Model Updates: 112,912
Cumulative Timesteps: 941,606,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 941606756...
Checkpoint 941606756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,216.70891
Policy Entropy: 3.62875
Value Function Loss: 0.09474

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.66091
Value Function Update Magnitude: 0.56661

Collected Steps per Second: 22,448.21180
Overall Steps per Second: 10,536.33777

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.51823
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.74567

Cumulative Model Updates: 112,918
Cumulative Timesteps: 941,656,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,358.83640
Policy Entropy: 3.61631
Value Function Loss: 0.10133

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.53441
Value Function Update Magnitude: 0.53308

Collected Steps per Second: 22,867.59996
Overall Steps per Second: 10,917.54092

Timestep Collection Time: 2.18755
Timestep Consumption Time: 2.39444
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.58198

Cumulative Model Updates: 112,924
Cumulative Timesteps: 941,706,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 941706782...
Checkpoint 941706782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.35578
Policy Entropy: 3.59766
Value Function Loss: 0.10474

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.46911
Value Function Update Magnitude: 0.52871

Collected Steps per Second: 22,766.63043
Overall Steps per Second: 10,575.93483

Timestep Collection Time: 2.19664
Timestep Consumption Time: 2.53202
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.72866

Cumulative Model Updates: 112,930
Cumulative Timesteps: 941,756,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,710.31103
Policy Entropy: 3.59610
Value Function Loss: 0.10293

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.43492
Value Function Update Magnitude: 0.56522

Collected Steps per Second: 23,094.98469
Overall Steps per Second: 10,814.27953

Timestep Collection Time: 2.16558
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.62481

Cumulative Model Updates: 112,936
Cumulative Timesteps: 941,806,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 941806806...
Checkpoint 941806806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,824.65118
Policy Entropy: 3.60097
Value Function Loss: 0.09799

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.53723
Value Function Update Magnitude: 0.53817

Collected Steps per Second: 22,848.52602
Overall Steps per Second: 10,709.43600

Timestep Collection Time: 2.18894
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.67009

Cumulative Model Updates: 112,942
Cumulative Timesteps: 941,856,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,349.71725
Policy Entropy: 3.60507
Value Function Loss: 0.09776

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.56808

Collected Steps per Second: 23,199.23025
Overall Steps per Second: 10,882.57046

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.44004
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.59597

Cumulative Model Updates: 112,948
Cumulative Timesteps: 941,906,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 941906836...
Checkpoint 941906836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.86625
Policy Entropy: 3.59938
Value Function Loss: 0.09611

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.56673
Value Function Update Magnitude: 0.55313

Collected Steps per Second: 22,583.89002
Overall Steps per Second: 10,780.65172

Timestep Collection Time: 2.21432
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.63868

Cumulative Model Updates: 112,954
Cumulative Timesteps: 941,956,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,601.56422
Policy Entropy: 3.62329
Value Function Loss: 0.09008

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 23,095.31297
Overall Steps per Second: 10,860.08439

Timestep Collection Time: 2.16624
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.60678

Cumulative Model Updates: 112,960
Cumulative Timesteps: 942,006,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 942006874...
Checkpoint 942006874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,673.17198
Policy Entropy: 3.63786
Value Function Loss: 0.09266

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.59742
Value Function Update Magnitude: 0.59211

Collected Steps per Second: 22,447.37628
Overall Steps per Second: 10,718.97398

Timestep Collection Time: 2.22779
Timestep Consumption Time: 2.43758
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.66537

Cumulative Model Updates: 112,966
Cumulative Timesteps: 942,056,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,542.57592
Policy Entropy: 3.63110
Value Function Loss: 0.09326

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.59380
Value Function Update Magnitude: 0.52319

Collected Steps per Second: 22,568.20323
Overall Steps per Second: 10,765.68995

Timestep Collection Time: 2.21613
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.64568

Cumulative Model Updates: 112,972
Cumulative Timesteps: 942,106,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 942106896...
Checkpoint 942106896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,163.25208
Policy Entropy: 3.61727
Value Function Loss: 0.09778

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.54923
Value Function Update Magnitude: 0.52426

Collected Steps per Second: 21,944.56378
Overall Steps per Second: 10,634.13144

Timestep Collection Time: 2.27865
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70222

Cumulative Model Updates: 112,978
Cumulative Timesteps: 942,156,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,208.37965
Policy Entropy: 3.60613
Value Function Loss: 0.09947

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.52106
Value Function Update Magnitude: 0.58424

Collected Steps per Second: 22,522.11793
Overall Steps per Second: 10,534.03453

Timestep Collection Time: 2.22111
Timestep Consumption Time: 2.52769
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.74880

Cumulative Model Updates: 112,984
Cumulative Timesteps: 942,206,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 942206924...
Checkpoint 942206924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,861.02554
Policy Entropy: 3.60835
Value Function Loss: 0.10131

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.62343

Collected Steps per Second: 22,038.70249
Overall Steps per Second: 10,558.01668

Timestep Collection Time: 2.26928
Timestep Consumption Time: 2.46759
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.73687

Cumulative Model Updates: 112,990
Cumulative Timesteps: 942,256,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,005.14605
Policy Entropy: 3.61854
Value Function Loss: 0.09709

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.54889

Collected Steps per Second: 22,764.38421
Overall Steps per Second: 10,598.72792

Timestep Collection Time: 2.19756
Timestep Consumption Time: 2.52244
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.72000

Cumulative Model Updates: 112,996
Cumulative Timesteps: 942,306,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 942306962...
Checkpoint 942306962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.45450
Policy Entropy: 3.61343
Value Function Loss: 0.09360

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.46790
Value Function Update Magnitude: 0.55833

Collected Steps per Second: 22,544.73861
Overall Steps per Second: 10,605.81392

Timestep Collection Time: 2.21879
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71647

Cumulative Model Updates: 113,002
Cumulative Timesteps: 942,356,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,019.74333
Policy Entropy: 3.61225
Value Function Loss: 0.09381

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.48748
Value Function Update Magnitude: 0.61816

Collected Steps per Second: 23,398.86800
Overall Steps per Second: 10,949.20291

Timestep Collection Time: 2.13788
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.56873

Cumulative Model Updates: 113,008
Cumulative Timesteps: 942,407,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 942407008...
Checkpoint 942407008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,781.41892
Policy Entropy: 3.59171
Value Function Loss: 0.09461

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.52500
Value Function Update Magnitude: 0.81772

Collected Steps per Second: 22,675.91177
Overall Steps per Second: 10,582.14316

Timestep Collection Time: 2.20516
Timestep Consumption Time: 2.52016
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.72532

Cumulative Model Updates: 113,014
Cumulative Timesteps: 942,457,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,114.58690
Policy Entropy: 3.60211
Value Function Loss: 0.09163

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.57178
Value Function Update Magnitude: 0.82853

Collected Steps per Second: 22,361.81737
Overall Steps per Second: 10,538.98286

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.74467

Cumulative Model Updates: 113,020
Cumulative Timesteps: 942,507,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 942507016...
Checkpoint 942507016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,232.40407
Policy Entropy: 3.61321
Value Function Loss: 0.09206

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.80458

Collected Steps per Second: 22,187.27538
Overall Steps per Second: 10,564.05913

Timestep Collection Time: 2.25454
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.73511

Cumulative Model Updates: 113,026
Cumulative Timesteps: 942,557,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.27254
Policy Entropy: 3.61181
Value Function Loss: 0.09215

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.76677

Collected Steps per Second: 22,692.29954
Overall Steps per Second: 10,645.75974

Timestep Collection Time: 2.20383
Timestep Consumption Time: 2.49381
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69765

Cumulative Model Updates: 113,032
Cumulative Timesteps: 942,607,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 942607048...
Checkpoint 942607048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,079.33689
Policy Entropy: 3.61541
Value Function Loss: 0.09448

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.62612
Value Function Update Magnitude: 0.69999

Collected Steps per Second: 22,475.19990
Overall Steps per Second: 10,516.15774

Timestep Collection Time: 2.22548
Timestep Consumption Time: 2.53082
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.75630

Cumulative Model Updates: 113,038
Cumulative Timesteps: 942,657,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.00349
Policy Entropy: 3.61489
Value Function Loss: 0.09357

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.60712
Value Function Update Magnitude: 0.67166

Collected Steps per Second: 23,120.93296
Overall Steps per Second: 10,805.69452

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.46504
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62793

Cumulative Model Updates: 113,044
Cumulative Timesteps: 942,707,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 942707074...
Checkpoint 942707074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,695.15638
Policy Entropy: 3.62106
Value Function Loss: 0.09375

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.67584

Collected Steps per Second: 22,537.36384
Overall Steps per Second: 10,655.26765

Timestep Collection Time: 2.21943
Timestep Consumption Time: 2.47497
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.69439

Cumulative Model Updates: 113,050
Cumulative Timesteps: 942,757,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,840.66969
Policy Entropy: 3.61411
Value Function Loss: 0.09438

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.51028
Value Function Update Magnitude: 0.68724

Collected Steps per Second: 23,036.07808
Overall Steps per Second: 10,830.42255

Timestep Collection Time: 2.17112
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61792

Cumulative Model Updates: 113,056
Cumulative Timesteps: 942,807,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 942807108...
Checkpoint 942807108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,088.70708
Policy Entropy: 3.61328
Value Function Loss: 0.09674

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.51145
Value Function Update Magnitude: 0.69818

Collected Steps per Second: 22,676.69739
Overall Steps per Second: 10,769.79898

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.43800
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.64317

Cumulative Model Updates: 113,062
Cumulative Timesteps: 942,857,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,830.61112
Policy Entropy: 3.61415
Value Function Loss: 0.09638

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.60961
Value Function Update Magnitude: 0.72456

Collected Steps per Second: 22,729.30850
Overall Steps per Second: 10,767.22611

Timestep Collection Time: 2.20042
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.64502

Cumulative Model Updates: 113,068
Cumulative Timesteps: 942,907,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 942907128...
Checkpoint 942907128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,040.12347
Policy Entropy: 3.62060
Value Function Loss: 0.09201

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.58068
Value Function Update Magnitude: 0.68545

Collected Steps per Second: 22,610.02632
Overall Steps per Second: 10,750.85110

Timestep Collection Time: 2.21203
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.65210

Cumulative Model Updates: 113,074
Cumulative Timesteps: 942,957,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,469.98898
Policy Entropy: 3.61504
Value Function Loss: 0.08997

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.66450

Collected Steps per Second: 22,442.31791
Overall Steps per Second: 10,585.13606

Timestep Collection Time: 2.22865
Timestep Consumption Time: 2.49647
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.72512

Cumulative Model Updates: 113,080
Cumulative Timesteps: 943,007,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 943007158...
Checkpoint 943007158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,783.95334
Policy Entropy: 3.61320
Value Function Loss: 0.09246

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.64034
Value Function Update Magnitude: 0.69051

Collected Steps per Second: 22,219.21630
Overall Steps per Second: 10,474.84198

Timestep Collection Time: 2.25111
Timestep Consumption Time: 2.52395
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.77506

Cumulative Model Updates: 113,086
Cumulative Timesteps: 943,057,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.93914
Policy Entropy: 3.59483
Value Function Loss: 0.10041

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.61187
Value Function Update Magnitude: 0.71240

Collected Steps per Second: 22,609.08804
Overall Steps per Second: 10,606.01912

Timestep Collection Time: 2.21168
Timestep Consumption Time: 2.50300
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.71468

Cumulative Model Updates: 113,092
Cumulative Timesteps: 943,107,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 943107180...
Checkpoint 943107180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,104.69800
Policy Entropy: 3.59709
Value Function Loss: 0.10164

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.70934

Collected Steps per Second: 22,333.13505
Overall Steps per Second: 10,517.30160

Timestep Collection Time: 2.23892
Timestep Consumption Time: 2.51535
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75426

Cumulative Model Updates: 113,098
Cumulative Timesteps: 943,157,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,149.64439
Policy Entropy: 3.58467
Value Function Loss: 0.10131

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.49654
Value Function Update Magnitude: 0.69389

Collected Steps per Second: 22,442.76782
Overall Steps per Second: 10,499.92849

Timestep Collection Time: 2.22905
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.76441

Cumulative Model Updates: 113,104
Cumulative Timesteps: 943,207,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 943207208...
Checkpoint 943207208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,088.23927
Policy Entropy: 3.58757
Value Function Loss: 0.09751

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.44663
Value Function Update Magnitude: 0.65428

Collected Steps per Second: 23,017.71391
Overall Steps per Second: 10,721.76240

Timestep Collection Time: 2.17433
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.66789

Cumulative Model Updates: 113,110
Cumulative Timesteps: 943,257,256

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,244.13371
Policy Entropy: 3.57811
Value Function Loss: 0.09990

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.49566
Value Function Update Magnitude: 0.61122

Collected Steps per Second: 22,916.72595
Overall Steps per Second: 10,828.25662

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.43622
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.61847

Cumulative Model Updates: 113,116
Cumulative Timesteps: 943,307,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 943307266...
Checkpoint 943307266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.11991
Policy Entropy: 3.56571
Value Function Loss: 0.10341

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.42070
Value Function Update Magnitude: 0.53650

Collected Steps per Second: 22,910.97337
Overall Steps per Second: 10,657.91669

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.50999
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.69322

Cumulative Model Updates: 113,122
Cumulative Timesteps: 943,357,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,451.78671
Policy Entropy: 3.55324
Value Function Loss: 0.10796

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.52065

Collected Steps per Second: 22,898.66250
Overall Steps per Second: 10,806.12407

Timestep Collection Time: 2.18449
Timestep Consumption Time: 2.44455
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.62904

Cumulative Model Updates: 113,128
Cumulative Timesteps: 943,407,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 943407308...
Checkpoint 943407308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,532.42041
Policy Entropy: 3.54057
Value Function Loss: 0.10903

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.57881
Value Function Update Magnitude: 0.54116

Collected Steps per Second: 22,686.28063
Overall Steps per Second: 10,671.17372

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.68646

Cumulative Model Updates: 113,134
Cumulative Timesteps: 943,457,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,663.70410
Policy Entropy: 3.53576
Value Function Loss: 0.10845

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.47274
Value Function Update Magnitude: 0.51412

Collected Steps per Second: 22,911.40469
Overall Steps per Second: 10,819.42711

Timestep Collection Time: 2.18319
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.62317

Cumulative Model Updates: 113,140
Cumulative Timesteps: 943,507,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 943507338...
Checkpoint 943507338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,664.50582
Policy Entropy: 3.53002
Value Function Loss: 0.11140

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.49939
Value Function Update Magnitude: 0.49558

Collected Steps per Second: 22,329.23408
Overall Steps per Second: 10,716.60551

Timestep Collection Time: 2.24029
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.66790

Cumulative Model Updates: 113,146
Cumulative Timesteps: 943,557,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,045.82029
Policy Entropy: 3.54785
Value Function Loss: 0.11092

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.44088
Value Function Update Magnitude: 0.48901

Collected Steps per Second: 22,841.15070
Overall Steps per Second: 10,801.15903

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.44078
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.63043

Cumulative Model Updates: 113,152
Cumulative Timesteps: 943,607,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 943607376...
Checkpoint 943607376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,593.69372
Policy Entropy: 3.54343
Value Function Loss: 0.11126

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.42240
Value Function Update Magnitude: 0.48176

Collected Steps per Second: 22,029.76467
Overall Steps per Second: 10,651.51731

Timestep Collection Time: 2.27075
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.69642

Cumulative Model Updates: 113,158
Cumulative Timesteps: 943,657,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,348.77716
Policy Entropy: 3.54809
Value Function Loss: 0.10560

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.44102
Value Function Update Magnitude: 0.56930

Collected Steps per Second: 22,431.01897
Overall Steps per Second: 10,571.66855

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.73170

Cumulative Model Updates: 113,164
Cumulative Timesteps: 943,707,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 943707422...
Checkpoint 943707422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,143.59976
Policy Entropy: 3.54649
Value Function Loss: 0.10360

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.46960
Value Function Update Magnitude: 0.55279

Collected Steps per Second: 22,361.33078
Overall Steps per Second: 10,678.03266

Timestep Collection Time: 2.23672
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.68401

Cumulative Model Updates: 113,170
Cumulative Timesteps: 943,757,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,398.15509
Policy Entropy: 3.54559
Value Function Loss: 0.10574

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.45285
Value Function Update Magnitude: 0.51938

Collected Steps per Second: 22,986.44174
Overall Steps per Second: 10,792.61261

Timestep Collection Time: 2.17633
Timestep Consumption Time: 2.45888
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.63521

Cumulative Model Updates: 113,176
Cumulative Timesteps: 943,807,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 943807464...
Checkpoint 943807464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,600.90910
Policy Entropy: 3.53757
Value Function Loss: 0.10859

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.41853
Value Function Update Magnitude: 0.52745

Collected Steps per Second: 22,580.70167
Overall Steps per Second: 10,778.03063

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.64018

Cumulative Model Updates: 113,182
Cumulative Timesteps: 943,857,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,165.40301
Policy Entropy: 3.53483
Value Function Loss: 0.10928

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.43463
Value Function Update Magnitude: 0.53814

Collected Steps per Second: 22,768.46533
Overall Steps per Second: 10,789.35128

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.63661

Cumulative Model Updates: 113,188
Cumulative Timesteps: 943,907,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 943907502...
Checkpoint 943907502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,788.68324
Policy Entropy: 3.53700
Value Function Loss: 0.10278

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.43428
Value Function Update Magnitude: 0.52099

Collected Steps per Second: 22,528.52212
Overall Steps per Second: 10,703.71765

Timestep Collection Time: 2.22012
Timestep Consumption Time: 2.45265
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.67277

Cumulative Model Updates: 113,194
Cumulative Timesteps: 943,957,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,152.89337
Policy Entropy: 3.55140
Value Function Loss: 0.09953

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.50450
Value Function Update Magnitude: 0.49731

Collected Steps per Second: 22,957.82035
Overall Steps per Second: 10,819.49848

Timestep Collection Time: 2.17843
Timestep Consumption Time: 2.44397
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62240

Cumulative Model Updates: 113,200
Cumulative Timesteps: 944,007,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 944007530...
Checkpoint 944007530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,103.93839
Policy Entropy: 3.55361
Value Function Loss: 0.09795

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.50887
Value Function Update Magnitude: 0.48252

Collected Steps per Second: 22,350.62871
Overall Steps per Second: 10,709.74226

Timestep Collection Time: 2.23779
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.67014

Cumulative Model Updates: 113,206
Cumulative Timesteps: 944,057,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.26773
Policy Entropy: 3.53650
Value Function Loss: 0.10091

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.53118
Value Function Update Magnitude: 0.47657

Collected Steps per Second: 22,660.39610
Overall Steps per Second: 10,631.51673

Timestep Collection Time: 2.20729
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.70469

Cumulative Model Updates: 113,212
Cumulative Timesteps: 944,107,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 944107564...
Checkpoint 944107564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,581.74314
Policy Entropy: 3.53268
Value Function Loss: 0.10636

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.50593
Value Function Update Magnitude: 0.43059

Collected Steps per Second: 22,087.71534
Overall Steps per Second: 10,471.51687

Timestep Collection Time: 2.26397
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.77543

Cumulative Model Updates: 113,218
Cumulative Timesteps: 944,157,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,352.46544
Policy Entropy: 3.52821
Value Function Loss: 0.10674

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.55837
Value Function Update Magnitude: 0.41427

Collected Steps per Second: 22,435.27346
Overall Steps per Second: 10,565.64134

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.73478

Cumulative Model Updates: 113,224
Cumulative Timesteps: 944,207,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 944207596...
Checkpoint 944207596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,021.48874
Policy Entropy: 3.53432
Value Function Loss: 0.10535

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.52143
Value Function Update Magnitude: 0.45507

Collected Steps per Second: 22,140.36126
Overall Steps per Second: 10,539.31013

Timestep Collection Time: 2.25841
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.74433

Cumulative Model Updates: 113,230
Cumulative Timesteps: 944,257,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,705.11483
Policy Entropy: 3.53349
Value Function Loss: 0.10064

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.50566
Value Function Update Magnitude: 0.46941

Collected Steps per Second: 23,166.25386
Overall Steps per Second: 10,834.05478

Timestep Collection Time: 2.15900
Timestep Consumption Time: 2.45755
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61655

Cumulative Model Updates: 113,236
Cumulative Timesteps: 944,307,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 944307614...
Checkpoint 944307614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,138.16382
Policy Entropy: 3.52746
Value Function Loss: 0.10460

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.17151
Policy Update Magnitude: 0.44075
Value Function Update Magnitude: 0.56929

Collected Steps per Second: 22,685.68186
Overall Steps per Second: 10,693.79011

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.47178
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.67598

Cumulative Model Updates: 113,242
Cumulative Timesteps: 944,357,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,380.35283
Policy Entropy: 3.52350
Value Function Loss: 0.10471

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.64042

Collected Steps per Second: 22,859.48719
Overall Steps per Second: 10,826.86753

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.61943

Cumulative Model Updates: 113,248
Cumulative Timesteps: 944,407,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 944407632...
Checkpoint 944407632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,369.45200
Policy Entropy: 3.52479
Value Function Loss: 0.10886

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.61722
Value Function Update Magnitude: 0.61261

Collected Steps per Second: 21,699.10881
Overall Steps per Second: 10,666.70077

Timestep Collection Time: 2.30636
Timestep Consumption Time: 2.38544
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.69180

Cumulative Model Updates: 113,254
Cumulative Timesteps: 944,457,678

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,684.95086
Policy Entropy: 3.53773
Value Function Loss: 0.10553

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.15122
Policy Update Magnitude: 0.49961
Value Function Update Magnitude: 0.57453

Collected Steps per Second: 22,291.59167
Overall Steps per Second: 10,753.85629

Timestep Collection Time: 2.24390
Timestep Consumption Time: 2.40746
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.65135

Cumulative Model Updates: 113,260
Cumulative Timesteps: 944,507,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 944507698...
Checkpoint 944507698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,812.94728
Policy Entropy: 3.54692
Value Function Loss: 0.10397

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.52756
Value Function Update Magnitude: 0.58142

Collected Steps per Second: 22,196.81671
Overall Steps per Second: 10,847.16836

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.35843
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61245

Cumulative Model Updates: 113,266
Cumulative Timesteps: 944,557,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,229.03237
Policy Entropy: 3.53520
Value Function Loss: 0.10420

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.52921

Collected Steps per Second: 21,889.61011
Overall Steps per Second: 10,587.14938

Timestep Collection Time: 2.28446
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.72327

Cumulative Model Updates: 113,272
Cumulative Timesteps: 944,607,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 944607736...
Checkpoint 944607736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.33930
Policy Entropy: 3.52111
Value Function Loss: 0.10898

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.46114

Collected Steps per Second: 21,554.03154
Overall Steps per Second: 10,517.83158

Timestep Collection Time: 2.32012
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.75459

Cumulative Model Updates: 113,278
Cumulative Timesteps: 944,657,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,348.00499
Policy Entropy: 3.50441
Value Function Loss: 0.11794

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.40978

Collected Steps per Second: 22,080.92381
Overall Steps per Second: 10,512.59900

Timestep Collection Time: 2.26558
Timestep Consumption Time: 2.49310
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.75867

Cumulative Model Updates: 113,284
Cumulative Timesteps: 944,707,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 944707770...
Checkpoint 944707770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,475.62577
Policy Entropy: 3.49628
Value Function Loss: 0.11862

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.52832
Value Function Update Magnitude: 0.37183

Collected Steps per Second: 22,161.35614
Overall Steps per Second: 10,580.50616

Timestep Collection Time: 2.25672
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.72681

Cumulative Model Updates: 113,290
Cumulative Timesteps: 944,757,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,214.49806
Policy Entropy: 3.51112
Value Function Loss: 0.11546

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.37727

Collected Steps per Second: 22,891.26006
Overall Steps per Second: 10,654.68724

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.50933
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.69427

Cumulative Model Updates: 113,296
Cumulative Timesteps: 944,807,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 944807798...
Checkpoint 944807798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,887.27351
Policy Entropy: 3.53022
Value Function Loss: 0.10752

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.42837

Collected Steps per Second: 22,968.07660
Overall Steps per Second: 10,884.31467

Timestep Collection Time: 2.17798
Timestep Consumption Time: 2.41799
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.59597

Cumulative Model Updates: 113,302
Cumulative Timesteps: 944,857,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,972.91065
Policy Entropy: 3.53441
Value Function Loss: 0.10327

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.46251
Value Function Update Magnitude: 0.47389

Collected Steps per Second: 23,001.77275
Overall Steps per Second: 10,847.00369

Timestep Collection Time: 2.17375
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60957

Cumulative Model Updates: 113,308
Cumulative Timesteps: 944,907,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 944907822...
Checkpoint 944907822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,122.73730
Policy Entropy: 3.53019
Value Function Loss: 0.10670

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.44293
Value Function Update Magnitude: 0.47943

Collected Steps per Second: 22,463.30646
Overall Steps per Second: 10,752.82596

Timestep Collection Time: 2.22639
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.65106

Cumulative Model Updates: 113,314
Cumulative Timesteps: 944,957,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,905.09454
Policy Entropy: 3.52225
Value Function Loss: 0.10444

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.44414
Value Function Update Magnitude: 0.52482

Collected Steps per Second: 22,903.86413
Overall Steps per Second: 10,797.45186

Timestep Collection Time: 2.18365
Timestep Consumption Time: 2.44837
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.63202

Cumulative Model Updates: 113,320
Cumulative Timesteps: 945,007,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 945007848...
Checkpoint 945007848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,366.53244
Policy Entropy: 3.54119
Value Function Loss: 0.10407

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.48776
Value Function Update Magnitude: 0.56182

Collected Steps per Second: 22,670.45426
Overall Steps per Second: 10,724.29783

Timestep Collection Time: 2.20675
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.66492

Cumulative Model Updates: 113,326
Cumulative Timesteps: 945,057,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,449.17248
Policy Entropy: 3.54250
Value Function Loss: 0.10068

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.48199
Value Function Update Magnitude: 0.55994

Collected Steps per Second: 22,817.92009
Overall Steps per Second: 10,822.34062

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.43017
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.62266

Cumulative Model Updates: 113,332
Cumulative Timesteps: 945,107,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 945107904...
Checkpoint 945107904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,890.17898
Policy Entropy: 3.55262
Value Function Loss: 0.10049

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.47832
Value Function Update Magnitude: 0.54557

Collected Steps per Second: 21,711.32756
Overall Steps per Second: 10,412.06285

Timestep Collection Time: 2.30341
Timestep Consumption Time: 2.49968
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.80308

Cumulative Model Updates: 113,338
Cumulative Timesteps: 945,157,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,032.21819
Policy Entropy: 3.53340
Value Function Loss: 0.10486

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.53015
Value Function Update Magnitude: 0.55595

Collected Steps per Second: 22,783.05719
Overall Steps per Second: 10,810.56176

Timestep Collection Time: 2.19567
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.62733

Cumulative Model Updates: 113,344
Cumulative Timesteps: 945,207,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 945207938...
Checkpoint 945207938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,075.33620
Policy Entropy: 3.53550
Value Function Loss: 0.10503

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.55841
Value Function Update Magnitude: 0.52396

Collected Steps per Second: 22,476.51680
Overall Steps per Second: 10,577.96450

Timestep Collection Time: 2.22588
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.72964

Cumulative Model Updates: 113,350
Cumulative Timesteps: 945,257,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,292.41724
Policy Entropy: 3.52252
Value Function Loss: 0.10678

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.48912
Value Function Update Magnitude: 0.50717

Collected Steps per Second: 22,855.86094
Overall Steps per Second: 10,588.47408

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.53470
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.72249

Cumulative Model Updates: 113,356
Cumulative Timesteps: 945,307,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 945307972...
Checkpoint 945307972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,899.15989
Policy Entropy: 3.53009
Value Function Loss: 0.10203

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.42241
Value Function Update Magnitude: 0.54219

Collected Steps per Second: 22,695.71755
Overall Steps per Second: 10,599.38876

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.51470
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.71820

Cumulative Model Updates: 113,362
Cumulative Timesteps: 945,357,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,372.50943
Policy Entropy: 3.51878
Value Function Loss: 0.10213

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.41441
Value Function Update Magnitude: 0.55117

Collected Steps per Second: 22,548.72338
Overall Steps per Second: 10,835.90111

Timestep Collection Time: 2.21840
Timestep Consumption Time: 2.39793
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.61632

Cumulative Model Updates: 113,368
Cumulative Timesteps: 945,408,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 945408004...
Checkpoint 945408004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,417.76841
Policy Entropy: 3.53532
Value Function Loss: 0.10074

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.46848
Value Function Update Magnitude: 0.55494

Collected Steps per Second: 22,054.77340
Overall Steps per Second: 10,632.56649

Timestep Collection Time: 2.26772
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.70385

Cumulative Model Updates: 113,374
Cumulative Timesteps: 945,458,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,997.37292
Policy Entropy: 3.52764
Value Function Loss: 0.10483

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.47371
Value Function Update Magnitude: 0.55978

Collected Steps per Second: 22,250.11134
Overall Steps per Second: 10,852.67615

Timestep Collection Time: 2.24835
Timestep Consumption Time: 2.36121
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60955

Cumulative Model Updates: 113,380
Cumulative Timesteps: 945,508,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 945508044...
Checkpoint 945508044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,200.88944
Policy Entropy: 3.54028
Value Function Loss: 0.10345

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.46580
Value Function Update Magnitude: 0.54367

Collected Steps per Second: 22,033.58375
Overall Steps per Second: 10,716.90452

Timestep Collection Time: 2.27008
Timestep Consumption Time: 2.39713
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.66721

Cumulative Model Updates: 113,386
Cumulative Timesteps: 945,558,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,817.17537
Policy Entropy: 3.52147
Value Function Loss: 0.10453

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.18222
Policy Update Magnitude: 0.36923
Value Function Update Magnitude: 0.60580

Collected Steps per Second: 22,493.90196
Overall Steps per Second: 10,673.64406

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.68500

Cumulative Model Updates: 113,392
Cumulative Timesteps: 945,608,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 945608068...
Checkpoint 945608068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,056.75970
Policy Entropy: 3.55028
Value Function Loss: 0.10324

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.17333
Policy Update Magnitude: 0.38152
Value Function Update Magnitude: 0.61741

Collected Steps per Second: 22,029.14012
Overall Steps per Second: 10,531.13446

Timestep Collection Time: 2.27063
Timestep Consumption Time: 2.47910
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.74973

Cumulative Model Updates: 113,398
Cumulative Timesteps: 945,658,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,861.94718
Policy Entropy: 3.55389
Value Function Loss: 0.10383

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.38479
Value Function Update Magnitude: 0.53123

Collected Steps per Second: 22,775.01818
Overall Steps per Second: 10,884.96682

Timestep Collection Time: 2.19635
Timestep Consumption Time: 2.39916
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.59551

Cumulative Model Updates: 113,404
Cumulative Timesteps: 945,708,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 945708110...
Checkpoint 945708110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,779.23852
Policy Entropy: 3.56419
Value Function Loss: 0.10426

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.48068
Value Function Update Magnitude: 0.52852

Collected Steps per Second: 22,052.30884
Overall Steps per Second: 10,592.85270

Timestep Collection Time: 2.26852
Timestep Consumption Time: 2.45410
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.72262

Cumulative Model Updates: 113,410
Cumulative Timesteps: 945,758,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,418.32975
Policy Entropy: 3.55298
Value Function Loss: 0.10314

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.69976
Value Function Update Magnitude: 0.63874

Collected Steps per Second: 22,706.74695
Overall Steps per Second: 10,663.27428

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.69349

Cumulative Model Updates: 113,416
Cumulative Timesteps: 945,808,184

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 945808184...
Checkpoint 945808184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,357.24765
Policy Entropy: 3.55169
Value Function Loss: 0.10128

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.66640
Value Function Update Magnitude: 0.66746

Collected Steps per Second: 22,303.54180
Overall Steps per Second: 10,542.86366

Timestep Collection Time: 2.24216
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.74330

Cumulative Model Updates: 113,422
Cumulative Timesteps: 945,858,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,154.29553
Policy Entropy: 3.56017
Value Function Loss: 0.09709

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.51780
Value Function Update Magnitude: 0.68560

Collected Steps per Second: 23,336.54355
Overall Steps per Second: 10,764.83663

Timestep Collection Time: 2.14368
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.64717

Cumulative Model Updates: 113,428
Cumulative Timesteps: 945,908,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 945908218...
Checkpoint 945908218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,474.81994
Policy Entropy: 3.55186
Value Function Loss: 0.10110

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.59313
Value Function Update Magnitude: 0.69075

Collected Steps per Second: 22,713.48242
Overall Steps per Second: 10,629.06957

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70615

Cumulative Model Updates: 113,434
Cumulative Timesteps: 945,958,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.08611
Policy Entropy: 3.55325
Value Function Loss: 0.09949

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.67985
Value Function Update Magnitude: 0.57803

Collected Steps per Second: 22,810.99603
Overall Steps per Second: 10,835.62818

Timestep Collection Time: 2.19280
Timestep Consumption Time: 2.42345
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.61625

Cumulative Model Updates: 113,440
Cumulative Timesteps: 946,008,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 946008260...
Checkpoint 946008260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,668.53133
Policy Entropy: 3.56648
Value Function Loss: 0.10303

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.61867
Value Function Update Magnitude: 0.58402

Collected Steps per Second: 22,616.29229
Overall Steps per Second: 10,747.93535

Timestep Collection Time: 2.21212
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.65485

Cumulative Model Updates: 113,446
Cumulative Timesteps: 946,058,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,430.18561
Policy Entropy: 3.59279
Value Function Loss: 0.09683

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.55077
Value Function Update Magnitude: 0.66645

Collected Steps per Second: 21,720.30100
Overall Steps per Second: 10,459.41508

Timestep Collection Time: 2.30236
Timestep Consumption Time: 2.47878
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.78115

Cumulative Model Updates: 113,452
Cumulative Timesteps: 946,108,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 946108298...
Checkpoint 946108298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,471.63168
Policy Entropy: 3.61257
Value Function Loss: 0.09761

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.70245

Collected Steps per Second: 21,962.70959
Overall Steps per Second: 10,651.77409

Timestep Collection Time: 2.27741
Timestep Consumption Time: 2.41834
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.69574

Cumulative Model Updates: 113,458
Cumulative Timesteps: 946,158,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,213.17407
Policy Entropy: 3.61487
Value Function Loss: 0.10039

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.63008
Value Function Update Magnitude: 0.70044

Collected Steps per Second: 22,664.17084
Overall Steps per Second: 10,757.69683

Timestep Collection Time: 2.20736
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.65044

Cumulative Model Updates: 113,464
Cumulative Timesteps: 946,208,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 946208344...
Checkpoint 946208344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.06925
Policy Entropy: 3.61199
Value Function Loss: 0.09928

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.70695
Value Function Update Magnitude: 0.62998

Collected Steps per Second: 22,538.02215
Overall Steps per Second: 10,676.83047

Timestep Collection Time: 2.21874
Timestep Consumption Time: 2.46486
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.68360

Cumulative Model Updates: 113,470
Cumulative Timesteps: 946,258,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,247.85610
Policy Entropy: 3.62138
Value Function Loss: 0.09620

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.17622
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.63589

Collected Steps per Second: 23,163.45289
Overall Steps per Second: 10,925.79239

Timestep Collection Time: 2.15952
Timestep Consumption Time: 2.41882
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.57834

Cumulative Model Updates: 113,476
Cumulative Timesteps: 946,308,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 946308372...
Checkpoint 946308372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,320.60398
Policy Entropy: 3.61744
Value Function Loss: 0.09181

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.16708
Policy Update Magnitude: 0.47342
Value Function Update Magnitude: 0.62905

Collected Steps per Second: 22,434.40785
Overall Steps per Second: 10,709.17897

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.66889

Cumulative Model Updates: 113,482
Cumulative Timesteps: 946,358,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,921.99748
Policy Entropy: 3.61296
Value Function Loss: 0.09851

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.51983
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 22,937.24116
Overall Steps per Second: 10,805.33149

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.44768
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62772

Cumulative Model Updates: 113,488
Cumulative Timesteps: 946,408,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 946408376...
Checkpoint 946408376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,240.74016
Policy Entropy: 3.59481
Value Function Loss: 0.10418

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.62026
Value Function Update Magnitude: 0.61118

Collected Steps per Second: 22,552.75298
Overall Steps per Second: 10,769.86346

Timestep Collection Time: 2.21720
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.64296

Cumulative Model Updates: 113,494
Cumulative Timesteps: 946,458,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.42680
Policy Entropy: 3.59668
Value Function Loss: 0.10271

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.69616
Value Function Update Magnitude: 0.61329

Collected Steps per Second: 22,607.35068
Overall Steps per Second: 10,827.60254

Timestep Collection Time: 2.21282
Timestep Consumption Time: 2.40741
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.62023

Cumulative Model Updates: 113,500
Cumulative Timesteps: 946,508,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 946508406...
Checkpoint 946508406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,906.85147
Policy Entropy: 3.57470
Value Function Loss: 0.10296

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.69706
Value Function Update Magnitude: 0.58951

Collected Steps per Second: 22,164.10247
Overall Steps per Second: 10,754.76571

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.39358
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.64985

Cumulative Model Updates: 113,506
Cumulative Timesteps: 946,558,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,773.06944
Policy Entropy: 3.57744
Value Function Loss: 0.10585

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.49714

Collected Steps per Second: 22,370.74443
Overall Steps per Second: 10,580.22850

Timestep Collection Time: 2.23631
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.72844

Cumulative Model Updates: 113,512
Cumulative Timesteps: 946,608,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 946608442...
Checkpoint 946608442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,801.33448
Policy Entropy: 3.57897
Value Function Loss: 0.10755

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.43843
Value Function Update Magnitude: 0.41210

Collected Steps per Second: 22,201.12366
Overall Steps per Second: 10,517.71475

Timestep Collection Time: 2.25313
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.75598

Cumulative Model Updates: 113,518
Cumulative Timesteps: 946,658,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,551.99852
Policy Entropy: 3.59126
Value Function Loss: 0.10504

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.41923
Value Function Update Magnitude: 0.46718

Collected Steps per Second: 22,777.31497
Overall Steps per Second: 10,775.45278

Timestep Collection Time: 2.19710
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.64426

Cumulative Model Updates: 113,524
Cumulative Timesteps: 946,708,508

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 946708508...
Checkpoint 946708508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,435.32196
Policy Entropy: 3.59521
Value Function Loss: 0.10105

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.52546
Value Function Update Magnitude: 0.60976

Collected Steps per Second: 22,601.16608
Overall Steps per Second: 10,676.10699

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.47256
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68617

Cumulative Model Updates: 113,530
Cumulative Timesteps: 946,758,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,414.22198
Policy Entropy: 3.59244
Value Function Loss: 0.09842

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.53025
Value Function Update Magnitude: 0.62158

Collected Steps per Second: 22,678.15313
Overall Steps per Second: 10,637.01369

Timestep Collection Time: 2.20547
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.70207

Cumulative Model Updates: 113,536
Cumulative Timesteps: 946,808,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 946808554...
Checkpoint 946808554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.97652
Policy Entropy: 3.58204
Value Function Loss: 0.09894

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.48276
Value Function Update Magnitude: 0.63619

Collected Steps per Second: 22,483.85282
Overall Steps per Second: 10,612.06747

Timestep Collection Time: 2.22542
Timestep Consumption Time: 2.48959
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.71501

Cumulative Model Updates: 113,542
Cumulative Timesteps: 946,858,590

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,505.21132
Policy Entropy: 3.56938
Value Function Loss: 0.10406

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.46830
Value Function Update Magnitude: 0.64009

Collected Steps per Second: 23,195.09057
Overall Steps per Second: 10,799.20951

Timestep Collection Time: 2.15640
Timestep Consumption Time: 2.47523
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.63164

Cumulative Model Updates: 113,548
Cumulative Timesteps: 946,908,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 946908608...
Checkpoint 946908608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,839.02982
Policy Entropy: 3.56137
Value Function Loss: 0.10672

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.51726
Value Function Update Magnitude: 0.65857

Collected Steps per Second: 22,374.98238
Overall Steps per Second: 10,624.19029

Timestep Collection Time: 2.23607
Timestep Consumption Time: 2.47318
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.70925

Cumulative Model Updates: 113,554
Cumulative Timesteps: 946,958,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,176.67361
Policy Entropy: 3.55440
Value Function Loss: 0.10680

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.48504
Value Function Update Magnitude: 0.62372

Collected Steps per Second: 21,847.32016
Overall Steps per Second: 10,323.85425

Timestep Collection Time: 2.28879
Timestep Consumption Time: 2.55475
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.84354

Cumulative Model Updates: 113,560
Cumulative Timesteps: 947,008,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 947008644...
Checkpoint 947008644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,075.87476
Policy Entropy: 3.54440
Value Function Loss: 0.10483

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.47892
Value Function Update Magnitude: 0.58160

Collected Steps per Second: 22,303.42438
Overall Steps per Second: 10,699.36782

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.67598

Cumulative Model Updates: 113,566
Cumulative Timesteps: 947,058,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,100.53127
Policy Entropy: 3.54948
Value Function Loss: 0.10481

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.45529
Value Function Update Magnitude: 0.56730

Collected Steps per Second: 22,550.55168
Overall Steps per Second: 10,570.99092

Timestep Collection Time: 2.21857
Timestep Consumption Time: 2.51419
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.73276

Cumulative Model Updates: 113,572
Cumulative Timesteps: 947,108,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 947108704...
Checkpoint 947108704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,531.74603
Policy Entropy: 3.55026
Value Function Loss: 0.10358

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.47831
Value Function Update Magnitude: 0.59479

Collected Steps per Second: 22,222.23210
Overall Steps per Second: 10,601.14612

Timestep Collection Time: 2.25036
Timestep Consumption Time: 2.46687
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.71723

Cumulative Model Updates: 113,578
Cumulative Timesteps: 947,158,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,538.26990
Policy Entropy: 3.55724
Value Function Loss: 0.10515

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.59176
Value Function Update Magnitude: 0.63162

Collected Steps per Second: 22,756.16874
Overall Steps per Second: 10,715.96806

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.66780

Cumulative Model Updates: 113,584
Cumulative Timesteps: 947,208,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 947208732...
Checkpoint 947208732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,880.80098
Policy Entropy: 3.56090
Value Function Loss: 0.10220

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.66666

Collected Steps per Second: 22,346.81895
Overall Steps per Second: 10,597.40425

Timestep Collection Time: 2.23844
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.72021

Cumulative Model Updates: 113,590
Cumulative Timesteps: 947,258,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.80766
Policy Entropy: 3.56350
Value Function Loss: 0.10243

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.48099
Value Function Update Magnitude: 0.64355

Collected Steps per Second: 23,154.04100
Overall Steps per Second: 10,665.44020

Timestep Collection Time: 2.15971
Timestep Consumption Time: 2.52889
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.68860

Cumulative Model Updates: 113,596
Cumulative Timesteps: 947,308,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 947308760...
Checkpoint 947308760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,846.08041
Policy Entropy: 3.54949
Value Function Loss: 0.10494

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.47940
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 22,435.71455
Overall Steps per Second: 10,626.32423

Timestep Collection Time: 2.22921
Timestep Consumption Time: 2.47740
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.70661

Cumulative Model Updates: 113,602
Cumulative Timesteps: 947,358,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,857.00537
Policy Entropy: 3.54825
Value Function Loss: 0.10807

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 22,868.31947
Overall Steps per Second: 10,676.21448

Timestep Collection Time: 2.18661
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.68368

Cumulative Model Updates: 113,608
Cumulative Timesteps: 947,408,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 947408778...
Checkpoint 947408778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,346.17165
Policy Entropy: 3.54460
Value Function Loss: 0.10779

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.59068
Value Function Update Magnitude: 0.55187

Collected Steps per Second: 22,679.12059
Overall Steps per Second: 10,823.20636

Timestep Collection Time: 2.20617
Timestep Consumption Time: 2.41667
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.62284

Cumulative Model Updates: 113,614
Cumulative Timesteps: 947,458,812

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,105.04523
Policy Entropy: 3.56485
Value Function Loss: 0.10467

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.50488
Value Function Update Magnitude: 0.55303

Collected Steps per Second: 23,207.09892
Overall Steps per Second: 10,818.85276

Timestep Collection Time: 2.15477
Timestep Consumption Time: 2.46735
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.62212

Cumulative Model Updates: 113,620
Cumulative Timesteps: 947,508,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 947508818...
Checkpoint 947508818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,743.13935
Policy Entropy: 3.54556
Value Function Loss: 0.10595

Mean KL Divergence: 0.02622
SB3 Clip Fraction: 0.19580
Policy Update Magnitude: 0.47749
Value Function Update Magnitude: 0.57716

Collected Steps per Second: 22,358.46647
Overall Steps per Second: 10,612.83286

Timestep Collection Time: 2.23745
Timestep Consumption Time: 2.47628
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.71373

Cumulative Model Updates: 113,626
Cumulative Timesteps: 947,558,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.05317
Policy Entropy: 3.54669
Value Function Loss: 0.10608

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.17518
Policy Update Magnitude: 0.41080
Value Function Update Magnitude: 0.58151

Collected Steps per Second: 22,057.24066
Overall Steps per Second: 10,654.65937

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.42605
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.69297

Cumulative Model Updates: 113,632
Cumulative Timesteps: 947,608,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 947608846...
Checkpoint 947608846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,805.55427
Policy Entropy: 3.54246
Value Function Loss: 0.10406

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.46401
Value Function Update Magnitude: 0.54777

Collected Steps per Second: 21,388.69058
Overall Steps per Second: 10,640.03340

Timestep Collection Time: 2.33881
Timestep Consumption Time: 2.36268
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.70149

Cumulative Model Updates: 113,638
Cumulative Timesteps: 947,658,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.13866
Policy Entropy: 3.55868
Value Function Loss: 0.10119

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.52175
Value Function Update Magnitude: 0.51826

Collected Steps per Second: 21,672.80023
Overall Steps per Second: 10,576.31936

Timestep Collection Time: 2.30861
Timestep Consumption Time: 2.42215
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.73076

Cumulative Model Updates: 113,644
Cumulative Timesteps: 947,708,904

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 947708904...
Checkpoint 947708904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,853.15239
Policy Entropy: 3.56172
Value Function Loss: 0.09887

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.62761
Value Function Update Magnitude: 0.53811

Collected Steps per Second: 21,069.25411
Overall Steps per Second: 10,597.94458

Timestep Collection Time: 2.37332
Timestep Consumption Time: 2.34496
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71827

Cumulative Model Updates: 113,650
Cumulative Timesteps: 947,758,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,732.85046
Policy Entropy: 3.57716
Value Function Loss: 0.10215

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.69198
Value Function Update Magnitude: 0.55348

Collected Steps per Second: 21,815.05308
Overall Steps per Second: 10,743.56611

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.36214
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.65432

Cumulative Model Updates: 113,656
Cumulative Timesteps: 947,808,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 947808912...
Checkpoint 947808912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,474.02177
Policy Entropy: 3.57332
Value Function Loss: 0.10134

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.63910
Value Function Update Magnitude: 0.56524

Collected Steps per Second: 21,568.29110
Overall Steps per Second: 10,624.18318

Timestep Collection Time: 2.31961
Timestep Consumption Time: 2.38946
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.70907

Cumulative Model Updates: 113,662
Cumulative Timesteps: 947,858,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,741.04239
Policy Entropy: 3.57660
Value Function Loss: 0.10234

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.66231
Value Function Update Magnitude: 0.59206

Collected Steps per Second: 22,314.66814
Overall Steps per Second: 10,718.28563

Timestep Collection Time: 2.24157
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.66679

Cumulative Model Updates: 113,668
Cumulative Timesteps: 947,908,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 947908962...
Checkpoint 947908962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,983.70159
Policy Entropy: 3.56229
Value Function Loss: 0.10408

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.66277
Value Function Update Magnitude: 0.57427

Collected Steps per Second: 22,077.67999
Overall Steps per Second: 10,736.38169

Timestep Collection Time: 2.26654
Timestep Consumption Time: 2.39425
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66079

Cumulative Model Updates: 113,674
Cumulative Timesteps: 947,959,002

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.00427
Policy Entropy: 3.55152
Value Function Loss: 0.10870

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.68631
Value Function Update Magnitude: 0.54850

Collected Steps per Second: 20,963.68404
Overall Steps per Second: 10,368.28900

Timestep Collection Time: 2.38603
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.82433

Cumulative Model Updates: 113,680
Cumulative Timesteps: 948,009,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 948009022...
Checkpoint 948009022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,214.39551
Policy Entropy: 3.55942
Value Function Loss: 0.10545

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.17094
Policy Update Magnitude: 0.54214
Value Function Update Magnitude: 0.63599

Collected Steps per Second: 22,202.07410
Overall Steps per Second: 10,576.38062

Timestep Collection Time: 2.25375
Timestep Consumption Time: 2.47735
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.73111

Cumulative Model Updates: 113,686
Cumulative Timesteps: 948,059,060

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,972.51919
Policy Entropy: 3.57740
Value Function Loss: 0.09762

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.46603
Value Function Update Magnitude: 0.69468

Collected Steps per Second: 22,967.38083
Overall Steps per Second: 10,806.56699

Timestep Collection Time: 2.17883
Timestep Consumption Time: 2.45187
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.63070

Cumulative Model Updates: 113,692
Cumulative Timesteps: 948,109,102

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 948109102...
Checkpoint 948109102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,067.69369
Policy Entropy: 3.59115
Value Function Loss: 0.09142

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.74359

Collected Steps per Second: 22,401.19058
Overall Steps per Second: 10,668.61585

Timestep Collection Time: 2.23354
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.68983

Cumulative Model Updates: 113,698
Cumulative Timesteps: 948,159,136

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,961.97940
Policy Entropy: 3.58670
Value Function Loss: 0.09413

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.64023
Value Function Update Magnitude: 0.69447

Collected Steps per Second: 22,058.36415
Overall Steps per Second: 10,561.85925

Timestep Collection Time: 2.26807
Timestep Consumption Time: 2.46878
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.73686

Cumulative Model Updates: 113,704
Cumulative Timesteps: 948,209,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 948209166...
Checkpoint 948209166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,825.18992
Policy Entropy: 3.58295
Value Function Loss: 0.09767

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.58629
Value Function Update Magnitude: 0.67888

Collected Steps per Second: 22,461.01521
Overall Steps per Second: 10,657.22176

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.46636
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69316

Cumulative Model Updates: 113,710
Cumulative Timesteps: 948,259,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,877.85914
Policy Entropy: 3.56960
Value Function Loss: 0.09849

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.65731

Collected Steps per Second: 22,521.49206
Overall Steps per Second: 10,736.70978

Timestep Collection Time: 2.22063
Timestep Consumption Time: 2.43740
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.65804

Cumulative Model Updates: 113,716
Cumulative Timesteps: 948,309,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 948309194...
Checkpoint 948309194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,278.93451
Policy Entropy: 3.57338
Value Function Loss: 0.09807

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.60669
Value Function Update Magnitude: 0.64552

Collected Steps per Second: 22,528.18411
Overall Steps per Second: 10,628.78527

Timestep Collection Time: 2.21980
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.70496

Cumulative Model Updates: 113,722
Cumulative Timesteps: 948,359,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,456.03778
Policy Entropy: 3.56378
Value Function Loss: 0.09924

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.76111
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 23,253.70873
Overall Steps per Second: 10,859.33646

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.45483
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60562

Cumulative Model Updates: 113,728
Cumulative Timesteps: 948,409,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 948409216...
Checkpoint 948409216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,405.65142
Policy Entropy: 3.55826
Value Function Loss: 0.10488

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.71664
Value Function Update Magnitude: 0.59257

Collected Steps per Second: 22,546.03637
Overall Steps per Second: 10,767.13131

Timestep Collection Time: 2.21884
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.64618

Cumulative Model Updates: 113,734
Cumulative Timesteps: 948,459,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,996.07351
Policy Entropy: 3.54136
Value Function Loss: 0.10728

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.55187
Value Function Update Magnitude: 0.56806

Collected Steps per Second: 22,687.29638
Overall Steps per Second: 10,793.62625

Timestep Collection Time: 2.20511
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.63496

Cumulative Model Updates: 113,740
Cumulative Timesteps: 948,509,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948509270...
Checkpoint 948509270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,844.27654
Policy Entropy: 3.55915
Value Function Loss: 0.10722

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.47535
Value Function Update Magnitude: 0.57966

Collected Steps per Second: 22,521.56426
Overall Steps per Second: 10,774.18700

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.64276

Cumulative Model Updates: 113,746
Cumulative Timesteps: 948,559,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,618.10944
Policy Entropy: 3.56755
Value Function Loss: 0.10126

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.49497
Value Function Update Magnitude: 0.58856

Collected Steps per Second: 23,037.04825
Overall Steps per Second: 10,822.39444

Timestep Collection Time: 2.17120
Timestep Consumption Time: 2.45051
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62171

Cumulative Model Updates: 113,752
Cumulative Timesteps: 948,609,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 948609310...
Checkpoint 948609310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,174.48342
Policy Entropy: 3.56935
Value Function Loss: 0.10029

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.53831
Value Function Update Magnitude: 0.57349

Collected Steps per Second: 21,967.75881
Overall Steps per Second: 10,616.93181

Timestep Collection Time: 2.27743
Timestep Consumption Time: 2.43486
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.71228

Cumulative Model Updates: 113,758
Cumulative Timesteps: 948,659,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,513.39365
Policy Entropy: 3.54503
Value Function Loss: 0.10292

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.58887
Value Function Update Magnitude: 0.56921

Collected Steps per Second: 22,215.58849
Overall Steps per Second: 10,524.53539

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.75175

Cumulative Model Updates: 113,764
Cumulative Timesteps: 948,709,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 948709350...
Checkpoint 948709350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,364.82123
Policy Entropy: 3.54299
Value Function Loss: 0.10865

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.17073
Policy Update Magnitude: 0.47032
Value Function Update Magnitude: 0.55301

Collected Steps per Second: 21,999.89243
Overall Steps per Second: 10,616.40380

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.43812
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71195

Cumulative Model Updates: 113,770
Cumulative Timesteps: 948,759,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,231.81994
Policy Entropy: 3.53812
Value Function Loss: 0.10939

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.46298
Value Function Update Magnitude: 0.56164

Collected Steps per Second: 22,694.53123
Overall Steps per Second: 9,690.23838

Timestep Collection Time: 2.20432
Timestep Consumption Time: 2.95820
PPO Batch Consumption Time: 0.36630
Total Iteration Time: 5.16251

Cumulative Model Updates: 113,776
Cumulative Timesteps: 948,809,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 948809400...
Checkpoint 948809400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.39912
Policy Entropy: 3.55066
Value Function Loss: 0.10444

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11049
Policy Update Magnitude: 0.52282
Value Function Update Magnitude: 0.55413

Collected Steps per Second: 10,987.73550
Overall Steps per Second: 6,673.31669

Timestep Collection Time: 4.55417
Timestep Consumption Time: 2.94435
PPO Batch Consumption Time: 0.32919
Total Iteration Time: 7.49852

Cumulative Model Updates: 113,782
Cumulative Timesteps: 948,859,440

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,917.06870
Policy Entropy: 3.55775
Value Function Loss: 0.09905

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.67590

Collected Steps per Second: 20,453.41260
Overall Steps per Second: 10,085.65733

Timestep Collection Time: 2.44595
Timestep Consumption Time: 2.51436
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.96031

Cumulative Model Updates: 113,788
Cumulative Timesteps: 948,909,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948909468...
Checkpoint 948909468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,352.40181
Policy Entropy: 3.56834
Value Function Loss: 0.10024

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.50998
Value Function Update Magnitude: 0.70323

Collected Steps per Second: 22,406.28666
Overall Steps per Second: 10,587.13162

Timestep Collection Time: 2.23259
Timestep Consumption Time: 2.49239
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.72498

Cumulative Model Updates: 113,794
Cumulative Timesteps: 948,959,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,669.74193
Policy Entropy: 3.57435
Value Function Loss: 0.10297

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.52770
Value Function Update Magnitude: 0.66758

Collected Steps per Second: 22,714.14504
Overall Steps per Second: 10,178.31632

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.71178
PPO Batch Consumption Time: 0.32720
Total Iteration Time: 4.91358

Cumulative Model Updates: 113,800
Cumulative Timesteps: 949,009,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 949009504...
Checkpoint 949009504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,363.88299
Policy Entropy: 3.57105
Value Function Loss: 0.10646

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.62389

Collected Steps per Second: 20,849.99685
Overall Steps per Second: 9,742.47355

Timestep Collection Time: 2.39933
Timestep Consumption Time: 2.73551
PPO Batch Consumption Time: 0.32662
Total Iteration Time: 5.13484

Cumulative Model Updates: 113,806
Cumulative Timesteps: 949,059,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,195.34042
Policy Entropy: 3.55625
Value Function Loss: 0.10458

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.52823
Value Function Update Magnitude: 0.65323

Collected Steps per Second: 19,890.43239
Overall Steps per Second: 10,122.19564

Timestep Collection Time: 2.51417
Timestep Consumption Time: 2.42626
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.94043

Cumulative Model Updates: 113,812
Cumulative Timesteps: 949,109,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 949109538...
Checkpoint 949109538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,999.38947
Policy Entropy: 3.55760
Value Function Loss: 0.10262

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.46388
Value Function Update Magnitude: 0.74052

Collected Steps per Second: 18,811.02413
Overall Steps per Second: 9,833.21440

Timestep Collection Time: 2.65887
Timestep Consumption Time: 2.42757
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 5.08643

Cumulative Model Updates: 113,818
Cumulative Timesteps: 949,159,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,099.52895
Policy Entropy: 3.55600
Value Function Loss: 0.10237

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.49488
Value Function Update Magnitude: 0.70004

Collected Steps per Second: 18,536.04313
Overall Steps per Second: 9,448.14440

Timestep Collection Time: 2.69885
Timestep Consumption Time: 2.59595
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 5.29480

Cumulative Model Updates: 113,824
Cumulative Timesteps: 949,209,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 949209580...
Checkpoint 949209580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,557.13875
Policy Entropy: 3.56190
Value Function Loss: 0.10095

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.77884

Collected Steps per Second: 20,244.72028
Overall Steps per Second: 10,179.37010

Timestep Collection Time: 2.47136
Timestep Consumption Time: 2.44368
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.91504

Cumulative Model Updates: 113,830
Cumulative Timesteps: 949,259,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,816.15932
Policy Entropy: 3.54104
Value Function Loss: 0.10358

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.47334
Value Function Update Magnitude: 0.76851

Collected Steps per Second: 20,122.89324
Overall Steps per Second: 9,955.32104

Timestep Collection Time: 2.48622
Timestep Consumption Time: 2.53923
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 5.02545

Cumulative Model Updates: 113,836
Cumulative Timesteps: 949,309,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 949309642...
Checkpoint 949309642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,939.52117
Policy Entropy: 3.52945
Value Function Loss: 0.10709

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.44736
Value Function Update Magnitude: 0.67080

Collected Steps per Second: 20,110.75911
Overall Steps per Second: 10,093.65390

Timestep Collection Time: 2.48772
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.95658

Cumulative Model Updates: 113,842
Cumulative Timesteps: 949,359,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,229.98088
Policy Entropy: 3.52551
Value Function Loss: 0.10961

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.48731
Value Function Update Magnitude: 0.60725

Collected Steps per Second: 21,299.07856
Overall Steps per Second: 10,224.20056

Timestep Collection Time: 2.34818
Timestep Consumption Time: 2.54355
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.89173

Cumulative Model Updates: 113,848
Cumulative Timesteps: 949,409,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 949409686...
Checkpoint 949409686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,988.47568
Policy Entropy: 3.53399
Value Function Loss: 0.10854

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.42377
Value Function Update Magnitude: 0.60380

Collected Steps per Second: 17,614.11840
Overall Steps per Second: 9,010.23802

Timestep Collection Time: 2.83965
Timestep Consumption Time: 2.71159
PPO Batch Consumption Time: 0.31827
Total Iteration Time: 5.55124

Cumulative Model Updates: 113,854
Cumulative Timesteps: 949,459,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,941.72733
Policy Entropy: 3.55060
Value Function Loss: 0.10185

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.42476
Value Function Update Magnitude: 0.66381

Collected Steps per Second: 16,262.82345
Overall Steps per Second: 7,657.54248

Timestep Collection Time: 3.07622
Timestep Consumption Time: 3.45695
PPO Batch Consumption Time: 0.42416
Total Iteration Time: 6.53317

Cumulative Model Updates: 113,860
Cumulative Timesteps: 949,509,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 949509732...
Checkpoint 949509732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,797.65090
Policy Entropy: 3.55960
Value Function Loss: 0.10254

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.42380
Value Function Update Magnitude: 0.66598

Collected Steps per Second: 14,275.40869
Overall Steps per Second: 6,640.12458

Timestep Collection Time: 3.50337
Timestep Consumption Time: 4.02842
PPO Batch Consumption Time: 0.53831
Total Iteration Time: 7.53179

Cumulative Model Updates: 113,866
Cumulative Timesteps: 949,559,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,288.21072
Policy Entropy: 3.55528
Value Function Loss: 0.10413

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.72531
Value Function Update Magnitude: 0.61444

Collected Steps per Second: 15,033.72354
Overall Steps per Second: 6,975.03686

Timestep Collection Time: 3.32732
Timestep Consumption Time: 3.84426
PPO Batch Consumption Time: 0.50748
Total Iteration Time: 7.17158

Cumulative Model Updates: 113,872
Cumulative Timesteps: 949,609,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 949609766...
Checkpoint 949609766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,579.19804
Policy Entropy: 3.55226
Value Function Loss: 0.10896

Mean KL Divergence: 0.03208
SB3 Clip Fraction: 0.21665
Policy Update Magnitude: 0.64833
Value Function Update Magnitude: 0.60340

Collected Steps per Second: 14,997.71169
Overall Steps per Second: 6,994.61746

Timestep Collection Time: 3.33478
Timestep Consumption Time: 3.81558
PPO Batch Consumption Time: 0.50839
Total Iteration Time: 7.15036

Cumulative Model Updates: 113,878
Cumulative Timesteps: 949,659,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.56574
Policy Entropy: 3.55333
Value Function Loss: 0.10840

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.18632
Policy Update Magnitude: 0.56383
Value Function Update Magnitude: 0.58583

Collected Steps per Second: 15,237.73415
Overall Steps per Second: 7,036.33254

Timestep Collection Time: 3.28317
Timestep Consumption Time: 3.82679
PPO Batch Consumption Time: 0.50935
Total Iteration Time: 7.10995

Cumulative Model Updates: 113,884
Cumulative Timesteps: 949,709,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 949709808...
Checkpoint 949709808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,523.36216
Policy Entropy: 3.56440
Value Function Loss: 0.10662

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.64375

Collected Steps per Second: 15,121.27685
Overall Steps per Second: 7,025.88304

Timestep Collection Time: 3.30686
Timestep Consumption Time: 3.81025
PPO Batch Consumption Time: 0.50510
Total Iteration Time: 7.11711

Cumulative Model Updates: 113,890
Cumulative Timesteps: 949,759,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190.48101
Policy Entropy: 3.54606
Value Function Loss: 0.11259

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.50615
Value Function Update Magnitude: 0.58511

Collected Steps per Second: 16,718.49277
Overall Steps per Second: 8,874.54862

Timestep Collection Time: 2.99190
Timestep Consumption Time: 2.64445
PPO Batch Consumption Time: 0.30750
Total Iteration Time: 5.63634

Cumulative Model Updates: 113,896
Cumulative Timesteps: 949,809,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 949809832...
Checkpoint 949809832 saved!
