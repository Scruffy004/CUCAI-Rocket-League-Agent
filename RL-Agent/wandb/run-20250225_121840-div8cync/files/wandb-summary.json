{"_timestamp":1.740529109635037e+09,"Total Iteration Time":5.636343000001943,"Cumulative Model Updates":113896,"Cumulative Timesteps":949809832,"Value Function Update Magnitude":0.5851144194602966,"PPO Batch Consumption Time":0.3075009187062581,"x_vel":15.16898105584462,"_runtime":89663.9520134,"Timesteps Collected":50020,"_step":37979,"_wandb":{"runtime":89664},"Policy Update Magnitude":0.5061485767364502,"Timestep Consumption Time":2.644446500002232,"y_vel":14.510873937043879,"Collected Steps per Second":16718.492768718712,"Policy Reward":2190.4810115852074,"Timestep Collection Time":2.9918964999997115,"Mean KL Divergence":0.013183408106366793,"Value Function Loss":0.11259221658110619,"SB3 Clip Fraction":0.14324666435519853,"Policy Entropy":3.546064098676046,"Overall Steps per Second":8874.548621328182,"z_vel":-1.9937696516046859}