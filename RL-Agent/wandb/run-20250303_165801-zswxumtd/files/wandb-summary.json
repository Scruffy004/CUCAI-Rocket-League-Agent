{"Policy Entropy":4.4290688037872314,"_step":322064,"Value Function Loss":0.0038496691655988493,"Cumulative Timesteps":988198120,"Timestep Consumption Time":2.4456633999998303,"Collected Steps per Second":20875.119659182485,"Mean KL Divergence":0.002010858695333203,"SB3 Clip Fraction":0.021349999122321606,"PPO Batch Consumption Time":0.2876805861790975,"Policy Reward":90.7349176605406,"_wandb":{"runtime":776072},"z_vel":-23.115013979588436,"_timestamp":1.741042448114681e+09,"Timesteps Collected":50038,"Overall Steps per Second":10332.70918852472,"y_vel":-144.29034469104664,"Timestep Collection Time":2.3970162000000528,"Policy Update Magnitude":0.6846160888671875,"_runtime":776072.0348644,"Value Function Update Magnitude":0.5067351460456848,"Cumulative Model Updates":118490,"x_vel":29.29889686451982,"Total Iteration Time":4.842679599999883}