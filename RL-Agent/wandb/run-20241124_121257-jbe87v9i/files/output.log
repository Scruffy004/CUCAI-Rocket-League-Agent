Created new wandb run! jbe87v9i
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04341
Policy Entropy: 0.84266
Value Function Loss: nan

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10576
Value Function Update Magnitude: 0.10410

Collected Steps per Second: 21,073.62998
Overall Steps per Second: 14,348.81849

Timestep Collection Time: 2.37301
Timestep Consumption Time: 1.11215
PPO Batch Consumption Time: 0.32279
Total Iteration Time: 3.48516

Cumulative Model Updates: 1
Cumulative Timesteps: 50,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04133
Policy Entropy: 0.83034
Value Function Loss: 0.69356

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00087
Policy Update Magnitude: 0.14029
Value Function Update Magnitude: 0.14438

Collected Steps per Second: 23,241.83933
Overall Steps per Second: 13,770.02062

Timestep Collection Time: 2.15224
Timestep Consumption Time: 1.48044
PPO Batch Consumption Time: 0.33060
Total Iteration Time: 3.63267

Cumulative Model Updates: 3
Cumulative Timesteps: 100,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 100030...
Checkpoint 100030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04822
Policy Entropy: 0.82571
Value Function Loss: 0.87171

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04515
Policy Update Magnitude: 0.16760
Value Function Update Magnitude: 0.23004

Collected Steps per Second: 22,224.88737
Overall Steps per Second: 12,732.62413

Timestep Collection Time: 2.25045
Timestep Consumption Time: 1.67773
PPO Batch Consumption Time: 0.31825
Total Iteration Time: 3.92818

Cumulative Model Updates: 6
Cumulative Timesteps: 150,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04291
Policy Entropy: 0.83026
Value Function Loss: 1.49951

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.00867
Policy Update Magnitude: 0.16364
Value Function Update Magnitude: 0.23332

Collected Steps per Second: 22,078.64648
Overall Steps per Second: 12,193.33336

Timestep Collection Time: 2.26572
Timestep Consumption Time: 1.83685
PPO Batch Consumption Time: 0.33113
Total Iteration Time: 4.10257

Cumulative Model Updates: 9
Cumulative Timesteps: 200,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 200070...
Checkpoint 200070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01388
Policy Entropy: 0.84124
Value Function Loss: 1.98569

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.15625
Value Function Update Magnitude: 0.24219

Collected Steps per Second: 21,685.05390
Overall Steps per Second: 12,190.25989

Timestep Collection Time: 2.30647
Timestep Consumption Time: 1.79647
PPO Batch Consumption Time: 0.32748
Total Iteration Time: 4.10295

Cumulative Model Updates: 12
Cumulative Timesteps: 250,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00241
Policy Entropy: 0.85267
Value Function Loss: 2.38570

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01375
Policy Update Magnitude: 0.15653
Value Function Update Magnitude: 0.25318

Collected Steps per Second: 24,090.52093
Overall Steps per Second: 12,957.26734

Timestep Collection Time: 2.07575
Timestep Consumption Time: 1.78355
PPO Batch Consumption Time: 0.32187
Total Iteration Time: 3.85930

Cumulative Model Updates: 15
Cumulative Timesteps: 300,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 300092...
Checkpoint 300092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03978
Policy Entropy: 0.86031
Value Function Loss: 3.15029

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.15597
Value Function Update Magnitude: 0.26247

Collected Steps per Second: 22,444.10500
Overall Steps per Second: 12,355.20206

Timestep Collection Time: 2.22981
Timestep Consumption Time: 1.82080
PPO Batch Consumption Time: 0.33101
Total Iteration Time: 4.05060

Cumulative Model Updates: 18
Cumulative Timesteps: 350,138

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03424
Policy Entropy: 0.86257
Value Function Loss: 2.21297

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.00542
Policy Update Magnitude: 0.15917
Value Function Update Magnitude: 0.27112

Collected Steps per Second: 20,629.32594
Overall Steps per Second: 12,037.00980

Timestep Collection Time: 2.42596
Timestep Consumption Time: 1.73171
PPO Batch Consumption Time: 0.32999
Total Iteration Time: 4.15768

Cumulative Model Updates: 21
Cumulative Timesteps: 400,184

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 400184...
Checkpoint 400184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00951
Policy Entropy: 0.86658
Value Function Loss: 1.41046

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.15184
Value Function Update Magnitude: 0.25607

Collected Steps per Second: 21,925.66009
Overall Steps per Second: 12,244.49346

Timestep Collection Time: 2.28226
Timestep Consumption Time: 1.80448
PPO Batch Consumption Time: 0.33092
Total Iteration Time: 4.08673

Cumulative Model Updates: 24
Cumulative Timesteps: 450,224

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01592
Policy Entropy: 0.87141
Value Function Loss: 0.06813

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01157
Policy Update Magnitude: 0.12041
Value Function Update Magnitude: 0.17912

Collected Steps per Second: 23,499.80523
Overall Steps per Second: 12,660.94750

Timestep Collection Time: 2.12998
Timestep Consumption Time: 1.82344
PPO Batch Consumption Time: 0.33084
Total Iteration Time: 3.95342

Cumulative Model Updates: 27
Cumulative Timesteps: 500,278

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 500278...
Checkpoint 500278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00363
Policy Entropy: 0.85754
Value Function Loss: 0.04910

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01373
Policy Update Magnitude: 0.10297
Value Function Update Magnitude: 0.16038

Collected Steps per Second: 24,080.15168
Overall Steps per Second: 13,024.34133

Timestep Collection Time: 2.07806
Timestep Consumption Time: 1.76398
PPO Batch Consumption Time: 0.33143
Total Iteration Time: 3.84204

Cumulative Model Updates: 30
Cumulative Timesteps: 550,318

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01898
Policy Entropy: 0.82970
Value Function Loss: 0.03671

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.09229
Value Function Update Magnitude: 0.15979

Collected Steps per Second: 22,270.64782
Overall Steps per Second: 12,316.38972

Timestep Collection Time: 2.24574
Timestep Consumption Time: 1.81503
PPO Batch Consumption Time: 0.32786
Total Iteration Time: 4.06077

Cumulative Model Updates: 33
Cumulative Timesteps: 600,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 600332...
Checkpoint 600332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05612
Policy Entropy: 0.81262
Value Function Loss: 0.05360

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.07911
Value Function Update Magnitude: 0.14895

Collected Steps per Second: 21,634.56424
Overall Steps per Second: 12,498.96972

Timestep Collection Time: 2.31241
Timestep Consumption Time: 1.69016
PPO Batch Consumption Time: 0.32296
Total Iteration Time: 4.00257

Cumulative Model Updates: 36
Cumulative Timesteps: 650,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01041
Policy Entropy: 0.80947
Value Function Loss: 0.05034

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.07620
Value Function Update Magnitude: 0.13536

Collected Steps per Second: 22,688.05293
Overall Steps per Second: 12,543.19609

Timestep Collection Time: 2.20424
Timestep Consumption Time: 1.78278
PPO Batch Consumption Time: 0.32914
Total Iteration Time: 3.98702

Cumulative Model Updates: 39
Cumulative Timesteps: 700,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 700370...
Checkpoint 700370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02677
Policy Entropy: 0.80623
Value Function Loss: 0.04885

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00038
Policy Update Magnitude: 0.07642
Value Function Update Magnitude: 0.12453

Collected Steps per Second: 23,049.85730
Overall Steps per Second: 12,704.01512

Timestep Collection Time: 2.16956
Timestep Consumption Time: 1.76684
PPO Batch Consumption Time: 0.32633
Total Iteration Time: 3.93639

Cumulative Model Updates: 42
Cumulative Timesteps: 750,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01337
Policy Entropy: 0.79778
Value Function Loss: 0.03824

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00240
Policy Update Magnitude: 0.07413
Value Function Update Magnitude: 0.10780

Collected Steps per Second: 23,986.70694
Overall Steps per Second: 13,051.88769

Timestep Collection Time: 2.08524
Timestep Consumption Time: 1.74700
PPO Batch Consumption Time: 0.32202
Total Iteration Time: 3.83224

Cumulative Model Updates: 45
Cumulative Timesteps: 800,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 800396...
Checkpoint 800396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04174
Policy Entropy: 0.78808
Value Function Loss: 0.04751

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01447
Policy Update Magnitude: 0.06877
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 22,885.54652
Overall Steps per Second: 12,597.92339

Timestep Collection Time: 2.18636
Timestep Consumption Time: 1.78541
PPO Batch Consumption Time: 0.32336
Total Iteration Time: 3.97177

Cumulative Model Updates: 48
Cumulative Timesteps: 850,432

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01948
Policy Entropy: 0.77950
Value Function Loss: 0.10160

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01852
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.08932

Collected Steps per Second: 22,337.87360
Overall Steps per Second: 12,441.25295

Timestep Collection Time: 2.23960
Timestep Consumption Time: 1.78153
PPO Batch Consumption Time: 0.32466
Total Iteration Time: 4.02114

Cumulative Model Updates: 51
Cumulative Timesteps: 900,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 900460...
Checkpoint 900460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00361
Policy Entropy: 0.77236
Value Function Loss: 0.12897

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.06775
Value Function Update Magnitude: 0.09687

Collected Steps per Second: 23,763.47451
Overall Steps per Second: 12,623.61495

Timestep Collection Time: 2.10592
Timestep Consumption Time: 1.85840
PPO Batch Consumption Time: 0.33772
Total Iteration Time: 3.96432

Cumulative Model Updates: 54
Cumulative Timesteps: 950,504

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00142
Policy Entropy: 0.76523
Value Function Loss: 0.12079

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.00985
Policy Update Magnitude: 0.07510
Value Function Update Magnitude: 0.10930

Collected Steps per Second: 21,002.19845
Overall Steps per Second: 11,952.51751

Timestep Collection Time: 2.38223
Timestep Consumption Time: 1.80367
PPO Batch Consumption Time: 0.32649
Total Iteration Time: 4.18590

Cumulative Model Updates: 57
Cumulative Timesteps: 1,000,536

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1000536...
Checkpoint 1000536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01142
Policy Entropy: 0.75727
Value Function Loss: 0.07076

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01181
Policy Update Magnitude: 0.07369
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 22,372.05898
Overall Steps per Second: 12,628.28848

Timestep Collection Time: 2.23609
Timestep Consumption Time: 1.72533
PPO Batch Consumption Time: 0.33556
Total Iteration Time: 3.96142

Cumulative Model Updates: 60
Cumulative Timesteps: 1,050,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02728
Policy Entropy: 0.74901
Value Function Loss: 0.05178

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01316
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.08626

Collected Steps per Second: 22,949.45685
Overall Steps per Second: 12,635.85950

Timestep Collection Time: 2.17870
Timestep Consumption Time: 1.77829
PPO Batch Consumption Time: 0.32403
Total Iteration Time: 3.95699

Cumulative Model Updates: 63
Cumulative Timesteps: 1,100,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1100562...
Checkpoint 1100562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03064
Policy Entropy: 0.73843
Value Function Loss: 0.04069

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02101
Policy Update Magnitude: 0.06519
Value Function Update Magnitude: 0.07279

Collected Steps per Second: 21,053.93288
Overall Steps per Second: 11,939.24790

Timestep Collection Time: 2.37495
Timestep Consumption Time: 1.81309
PPO Batch Consumption Time: 0.33294
Total Iteration Time: 4.18804

Cumulative Model Updates: 66
Cumulative Timesteps: 1,150,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00488
Policy Entropy: 0.72672
Value Function Loss: 0.04302

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02936
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 24,624.01142
Overall Steps per Second: 13,025.45639

Timestep Collection Time: 2.03216
Timestep Consumption Time: 1.80955
PPO Batch Consumption Time: 0.33294
Total Iteration Time: 3.84171

Cumulative Model Updates: 69
Cumulative Timesteps: 1,200,604

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1200604...
Checkpoint 1200604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00125
Policy Entropy: 0.71582
Value Function Loss: 0.04723

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01389
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 23,239.07128
Overall Steps per Second: 12,721.82549

Timestep Collection Time: 2.15353
Timestep Consumption Time: 1.78034
PPO Batch Consumption Time: 0.32432
Total Iteration Time: 3.93387

Cumulative Model Updates: 72
Cumulative Timesteps: 1,250,650

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1250650...
Checkpoint 1250650 saved!
